[
    {
        "paper_title": "Real-Time Intelligent Anomaly Detection and Prevention System",
        "paper_author": "Gürfidan R.",
        "publication": "Sakarya University Journal of Computer and Information Sciences",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Real-time anomaly detection in network traffic is a method that detects unexpected and anomalous behavior by identifying normal behavior and statistical patterns in network traffic data. This method is used to detect potential attacks or other anomalous conditions in network traffic. Real-time anomaly detection uses different algorithms to detect abnormal activities in network traffic. These include statistical methods, machine learning, and deep learning techniques. By learning the normal behavior of network traffic, these methods can detect unexpected and anomalous situations. Attackers use various techniques to mimic normal patterns in network traffic, making it difficult to detect. Real-time anomaly detection allows network administrators to detect attacks faster and respond more effectively. Real-time anomaly detection can improve network performance by detecting abnormal conditions in network traffic. Abnormal traffic can overuse the network's resources and cause the network to slow down. Real-time anomaly detection detects abnormal traffic conditions, allowing network resources to be used more effectively. In this study, blockchain technology and machine learning algorithms are combined to propose a real-time prevention model that can detect anomalies in network traffic.",
        "affiliation_name": "Isparta University of Applied Sciences",
        "affiliation_city": "Isparta",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Prediction of Cardiovascular Disease Based on Voting Ensemble Model and SHAP Analysis",
        "paper_author": "Akkur E.",
        "publication": "Sakarya University Journal of Computer and Information Sciences",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Globally, cardiovascular diseases (CVD) account for a large number of deaths. Early detection plays a critical role in reducing the mortality rate. Early detection can be achieved by utilizing machine learning algorithms on existing data of patients. Ensemble learning methods are one of the techniques applied to improve the classification performance of ML algorithms. This study suggests a prediction model based on voting ensemble learning for the prediction of CVD. The hyperparameters of classification algorithms are optimized by using grid search. The results of each model are validated by using a 10-fold cross-validation schema. The IEEE Data port dataset is used for all experiments Furthermore, the SHAP technique is employed to interpret the proposed prediction model, including the risk factors that play a role in detecting this disease The proposed model for CVD prediction achieved an accuracy of 0.937 and an AUC-ROC score of 0.936. The model presented in this study has a high classification rate compared to previous similar studies.",
        "affiliation_name": "Turkish Medicines and Medical Devices Agency",
        "affiliation_city": "Cankaya",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Social Media User Opinion Analysis Using Deep Learning and Machine Learning Methods: A Case Study on Airlines",
        "paper_author": "Şencan Ö.A.",
        "publication": "Turkish Journal of Mathematics and Computer Science",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "The rapid surge in social media usage has augmented the significance and value of data available on these platforms. As a result, analyzing community sentiment and opinions related to various topics and events using social media data has become increasingly crucial. However, the sheer volume of data produced on social media platforms surpasses human processing capabilities. Consequently, artificial intelligence-based models be-came frequently employed in social media analysis. In this study, deep learning (DL) and machine learning (ML) methods are applied to assess user opinions regarding airlines, and the effectiveness of these methods in social media analysis is comparatively discussed based on the performance results obtained. Due to the imbalanced na-ture of the dataset, synthetic data is produced using the Synthetic Minority Over-Sampling Technique (SMOTE) to enhance model performance. Before the SMOTE process, the dataset containing 14640 data points expanded to 27534 data points after the SMOTE process. The experimental results demonstrate that Support Vector Machines (SVM) achieved the highest performance among all methods with accuracy, precision, recall, and F-score values of 0.79 in the pre-SMOTE (imbalanced dataset). In contrast, Random Forest (RF) obtained the best performance among all methods, with accuracy, precision, recall, and F-score values of 0.88 in the post-SMOTE (balanced data set). Moreover, experimental findings demonstrate that SMOTE led to performance improvements in ML and DL models, ranging from a minimum of 3% to a maximum of 24% increase in F-Score metric.",
        "affiliation_name": "Gazi Üniversitesi",
        "affiliation_city": "Ankara",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Skin Lesion Classification Using Convolutional Neural Network and ABCRule",
        "paper_author": "Kestek E.",
        "publication": "Turkish Journal of Mathematics and Computer Science",
        "citied_by": "1",
        "cover_date": "2023-12-31",
        "Abstract": "Skin cancer, which can occur in any part of the human skin, is one of the common and serious types of cancer. Accurate diagnosis and segmentation of lesions are crucial to the early diagnosis. Computer-aided diagnosis make important contributions to help doctors in the diagnosis of cancer from skin images. The most important factor for such systems to reveal the accurate results is the correct feature extraction. In this study, a model for the classification of seven types of skin lesions is developed by combining the features of CNN-based feature extraction and the ABCD rule, which is widely used in the clinic. The model is evaluated on HAM10000 well-known dataset. The classification results obtained with different combinations of features and machine learning algorithms are compared. According to the results, the best classification accuracy is obtained with the Cosine Similarity Classifier with 96.4% when the features determined by CNN and the features in the ABCD rule are used together.",
        "affiliation_name": "Bartin Üniversitesi",
        "affiliation_city": "Bartin",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Artificial intelligence (AI) or augmented intelligence? How big data and AI are transforming healthcare: Challenges and opportunities",
        "paper_author": "Moodley K.",
        "publication": "South African medical journal = Suid-Afrikaanse tydskrif vir geneeskunde",
        "citied_by": "2",
        "cover_date": "2023-12-31",
        "Abstract": "The sanctity of the doctor-patient relationship is deeply embedded in tradition - the Hippocratic oath, medical ethics, professional codes of conduct, and legislation - all of which are being disrupted by big data and 'artificial' intelligence (AI). The transition from paper-based records to electronic health records, wearables, mobile health applications and mobile phone data has created new opportunities to scale up data collection. Databases of unimaginable magnitude can be harnessed to develop algorithms for AI and to refine machine learning. Complex neural networks now lie at the core of ubiquitous AI systems in healthcare. A transformed healthcare environment enhanced by innovation, robotics, digital technology, and improved diagnostics and therapeutics is plagued by ethical, legal and social challenges. Global guidelines are emerging to ensure governance in AI, but many low- and middle-income countries have yet to develop context- specific frameworks. Legislation must be developed to frame liability and account for negligence due to robotics in the same way human healthcare providers are held accountable. The digital divide between high- and low-income settings is significant and has the potential to exacerbate health inequities globally.",
        "affiliation_name": "Stellenbosch University, Faculty of Medicine and Health Sciences",
        "affiliation_city": "Cape Town",
        "affiliation_country": "South Africa"
    },
    {
        "paper_title": "PREDICTION OF TEMPERATURE FIELD DISTRIBUTION IN A GAS TURBINE USING A HIGHER ORDER NEURAL NETWORK",
        "paper_author": "Pařez J.",
        "publication": "Acta Polytechnica",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "This paper presents the prediction of temperature field distribution in a single annular section using an artificial neural network (ANN). This temperature distribution is non-uniform on the outer tube due to continuous natural convection and radiation caused by the homogeneous steady-state heating of the inner tube, which represents the hot gas flow path through the turbine. The outer tube represents the case of a gas turbine. This temperature is important for the electronic components attached to the engine or the overall engine deformation. The presented approach allows for a quick estimation of the temperature distribution without the need to perform time consuming computational fluid dynamics (CFD) simulations. This can greatly accelerate the design and development of gas turbines. A machine learning approach is applied to an extensive set of CFD simulations under different operating conditions and geometry setups.",
        "affiliation_name": "Czech Technical University in Prague",
        "affiliation_city": "Prague",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Hyperspectral prediction of pigment content in tomato leaves based on logistic-optimized sparrow search algorithm and back propagation neural network",
        "paper_author": "Zhao J.",
        "publication": "Journal of Agricultural Engineering",
        "citied_by": "3",
        "cover_date": "2023-12-31",
        "Abstract": "Leaf pigment content can reflect the nutrient content of the cultivation medium indirectly. To rapidly and accurately predict the pigment content of tomato leaves, chlorophyll a, chlorophyll b, chlorophyll and carotenoid were extracted from the leaves of tomato seedlings cultured at different nitrogen concentrations. The visible/near-infrared hyperspectral imaging non-destructive measurement technology, 430-900 nm and 950-1650 nm, with total variables of 794, was used to obtain the reflection spectra of leaves. An improved strategy of the sparrow search algorithm (SSA) based on logistic chaotic mapping was proposed, and it optimized the back propagation neural network to predict the pigment content of leaves. Different pretreatment methods were used to effectively improve the prediction accuracy of the model. The results showed that when the nitrogen concentration in the nutrient solution was 302.84 mg·L-1, the pigment content of the leaves reached its maximum. Meanwhile, the inhibition effect of high concentrations was much stronger than that of low concentrations. To address the problem that the SSA is prone to premature convergence due to the reduction of population diversity at the end of the iteration, the initialization of the SSA population by logistic chaotic mapping improves the initial solution quality, convergence speed, and search capacity. The root mean squared error (RMSE), coefficient of determination (R2) and relative percent deviation (RPD) of chlorophyll a were 0.77, 0.77, and 2.08, respectively. The RMSE, R2 and RPD of chlorophyll b were 0.30, 0.66, and 1.71, respectively. The RMSE, R2 and RPD of chlorophyll were 0.88, 0.81, and 2.28, respectively. The RMSE, R2 and RPD of carotenoid were 0.14, 0.75, and 2.00, respectively. Hyperspectral imaging technology combined with machine learning algorithms can achieve rapid and accurate prediction of crop physiological information, providing data support for the precise management of fertilization in facility agriculture, which is conducive to improving the quality and output of tomatoes.",
        "affiliation_name": "Shanxi Agricultural University",
        "affiliation_city": "Taiyuan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Departure Flight Delay Prediction and Visual Analysis Based on Machine Learning",
        "paper_author": "Qi X.",
        "publication": "SAE Technical Papers",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Nowadays, the rapid growth of civil aviation transportation demand has led to more frequent flight delays. The major problem of flight delays is restricting the development of municipal airports. To further improve passenger satisfaction, and reduce economic losses caused by flight delays, environmental pollution and many other adverse consequences, three machine learning algorithms are constructed in current study: random forest (RF), gradient boosting decision tree (GBDT) and BP neural network (BPNN). The departure flight delay prediction model uses the actual data set of domestic flights in the United States to simulate and verify the performance and accuracy of the three models. This model combines the visual analysis system to show the density of departure flight delays between different airports. Firstly, the data set is reprocessed, and the main factors leading to flight delays are selected as sample attributes by principal component analysis. Secondly, the mean absolute error (MAE), mean absolute percentage error (MAPE) and root mean square error (RMSE) were selected as evaluation indexes to compare the prediction results of three different models. The final results show that the departure flight delay prediction model based on BPNN algorithm has faster solution speed and overcomes the over-fitting problem, and has higher prediction accuracy and robustness. Based on the algorithm developed in this paper, the airport system can be planned in a targeted manner, thereby alleviating the pressure of air transportation and reducing flight delays.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning Based Flight State Prediction for Improving UAV Resistance to Uncertainty",
        "paper_author": "Mu J.",
        "publication": "SAE Technical Papers",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Unmanned Aerial Vehicles (UAVs) encounter various uncertainties, including unfamiliar environments, signal delays, limited control precision, and other disturbances during task execution. Such factors can significantly compromise flight safety in complex scenarios. In this paper, to enhance the safety of UAVs amidst these uncertainties, a control accuracy prediction model based on ensemble learning abnormal state detection is designed. By analyzing the historical state data, the trained model can be used to judge the current state and obtain the command tracking control accuracy of the UAV at that instant. Ensemble learning offers superior classification capabilities compared to weak learners, particularly for anomaly detection in flight data. The learning efficacy of support vector machine, random forest classifier is compared and achieving a peak accuracy of 95% for the prediction results using random forest combined with adaboost model. Subsequently, a trajectory planning method leveraging the DWA(Dynamic Window approach) algorithm was designed to mitigate the safety risks associated with uncertain control command tracking. By employing the obtained model of nominal command execution results of UAVs subjected to uncertainty, and by adjusting the original assessment criteria to a probability-weighted comprehensive optimal metric, optimal control commands that factor in uncertainty are derived. The simulation results affirm the effectiveness of the designed method.",
        "affiliation_name": "Hangzhou City University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Aeroengine Gas Path Parameter Trend Prediction Based on LSTM",
        "paper_author": "Liu Y.",
        "publication": "SAE Technical Papers",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Accurately predicting the trend of aero-engine gas path parameters is crucial for ensuring safe flight and enabling condition-based maintenance. However, the demanding and uncertain service environment introduces challenges in dealing with the noisy and non-stationary data collected by engine gas path sensors. Traditional time series models struggle to accurately predicts parameter trends, resulting in insufficient fitting and prediction accuracy. In this paper, we address these challenges by leveraging the characteristics of engine post-flight data and introducing Long Short-Term Memory (LSTM), a type of artificial neural network in deep learning. We construct both single-feature input and multi-feature input LSTM prediction models for six key indicators of engine gas path performance. We analyze the models' capabilities for single-step and multistep predictions. To evaluate the effectiveness of our approach, we compare the LSTM model with the traditional Autoregressive Moving Average (ARMA) model and support vector regression (SVR) method. The results demonstrate that the LSTM model outperforms the traditional ARMA and SVR models in terms of prediction accuracy and stability. This indicates that utilizing LSTM is an effective approach for improving the accuracy of engine gas path parameter prediction. By accurately predicting these parameters, we can enhance flight safety and enable more efficient condition based maintenance.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Yield Prediction and Recommendation of Crops in India’s Northeastern Region Using Machine Learning Regression Models",
        "paper_author": "Sharma N.",
        "publication": "Yuzuncu Yil University Journal of Agricultural Sciences",
        "citied_by": "3",
        "cover_date": "2023-12-31",
        "Abstract": "Agriculture has a big impact on society because it is essential for a large percentage of our food. The issue of hunger is getting worse because of a growing population in many nations, resulting in food shortages or insufficiencies. To meet the world's food needs, it is ever more crucial to provide crop protection, conduct detailed land surveys, and predict crop yields. To calculate the estimated number of crops that are produced in a year, this research focuses on the use of machine learning techniques to predict crop yield and recommend crops with the highest yield and profitability in the Northeast region of India. The crop market's fluctuations in prices may be controlled with the aid of this information. To estimate agricultural crop yields, this study accurately evaluates a range of machine learning regression models, such as Linear Regression, Decision Tree, Random Forest, Gradient Boosting, XGBoost (eXtreme Gradient Boosting), and AdaBoost. With a 0.98 R2 score for the XGBoost and 0.96 for the Random Forest, they performed better than the other models. By evaluating crop yields along with their corresponding market prices and costs, we have determined their profitability. As a result, we have provided recommendations for the top five profitable crops in India’s Northeastern region.",
        "affiliation_name": "Assam down town University",
        "affiliation_city": "Guwahati",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A review of computer-aided classification prediction of Parkinson’s disease based on machine learning",
        "paper_author": "Wen J.Y.",
        "publication": "Journal of Graphics",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Parkinson’s disease (PD) is among the top ten most challenging diseases according to the World Health Organization, placing a substantial burden on patients and their families. Currently, treatment can only offer partial relief from clinical symptoms and cannot achieve a complete cure. Therefore, early auxiliary diagnosis holds significant practical significance for PD patients. This research conducted a comprehensive analysis of computer-aided diagnosis techniques for PD classification prediction both domestically and internationally. It also summarized research endeavors utilizing machine learning models to assist in the early detection of PD, aiming to guide early intervention and prevent disease progression. Common prediction methods involved data preprocessing, feature selection, and classification. Traditional machine learning methods might not be as effective when dealing with large datasets or high data complexity, making deep learning or improved machine learning methods more promising for improving prediction accuracy. Furthermore, there has been a growing focus on diagnosing brain structural images of PD patients with cognitive impairment. Research on cognitive dysfunction followed a progressive trajectory, emphasizing the need for early screening and timely intervention. Future research should further explore computer-assisted diagnostic techniques based on machine learning methods and apply them to the early classification prediction of PD, aiming to enhance the accuracy of medical diagnosis and elevate the quality of diagnosis and treatment.",
        "affiliation_name": "Guangzhou University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A STEP TOWARDS IMO GREENHOUSE GAS REDUCTION GOAL: EFFECTIVENESS OF MACHINE LEARNING BASED CO<inf>2</inf> EMISSION PREDICTION MODEL",
        "paper_author": "Monisha I.I.",
        "publication": "Journal of Naval Architecture and Marine Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Ships are the world’s most economical means of freight transportation, and day by day, it is expanding quickly. The increase in ship transportation activities has resulted in a significant concern about CO2 emissions. International Maritime Organization has agreed to set a goal of reducing the maritime sector’s total gas emissions by at least 50% by 2050. In this regard, a CO2 emission prediction model followed by an emission inventory can play a vital role in decision-making to optimize the ship’s speed, draft, trim, and other influencing parameters under Ship Energy Efficiency Management Plan to decrease carbon emissions during operation. Machine learning, a branch of the data science approach, can be utilized to create effective emission-prediction models. In this research, two machine-learning models have been developed using actual voyage data collected from the noon reports of ships in Bangladesh. The models have been trained with the ship’s speed, engine rpm, wind force, and sea condition during voyages. The models’ performances have been assessed employing the Coefficient of Determination (R2) and Root Mean Square Error (RMSE). The prediction accuracies for the K Nearest Neighbor Regression model and the Light Gradient Boosted Machine Regression model are 84% and 81%, with RMSE of 5.12 and 5.53, respectively.",
        "affiliation_name": "Bangladesh University of Engineering and Technology",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "WSN-IoT Forecast: Wireless Sensor Network Throughput Prediction Framework in Multimedia Internet of Things",
        "paper_author": "Eliviani R.",
        "publication": "Journal of ICT Research and Applications",
        "citied_by": "1",
        "cover_date": "2023-12-31",
        "Abstract": "Accurate throughput predictions can significantly improve the quality of experience (QoE), where QoE denotes a network’s capacity to provide satisfactory service. By increasing the results of good throughput predictions, the best strategy can be planned for managing data transmission networks with the aim of better and faster data transmission, thereby increasing QoE. Consequently, this paper investigates how to predict the throughput of wireless sensor networks utilizing multimedia data. First, we conducted a comparative analysis of relevant prior research on the topic of throughput prediction in Multimedia Internet of Things (Multimedia IoT). We developed a throughput prediction framework for wireless sensor networks based on what we learned from these studies using machine learning. The Throughput Prediction Framework identifies historical throughput data and employs these traits to predict throughput. In the final phase, multiple camera nodes and local servers are utilized to test a framework for throughput prediction. Our analysis demonstrates that WSN-IoT predictions are quite precise. For a 1-second time breakdown, the average absolute percentage error for all investigated scenarios ranges from 1 to 8 percent.",
        "affiliation_name": "Institut Teknologi Bandung",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "An Efficient Intrusion Detection System to Combat Cyber Threats using a Deep Neural Network Model",
        "paper_author": "Ramaiah M.",
        "publication": "Journal of ICT Research and Applications",
        "citied_by": "2",
        "cover_date": "2023-12-31",
        "Abstract": "The proliferation of Internet of Things (IoT) solutions has led to a significant increase in cyber-attacks targeting IoT networks. Securing networks and especially wireless IoT networks against these attacks has become a crucial but challenging task for organizations. Therefore, ensuring the security of wireless IoT networks is of the utmost importance in today’s world. Among various solutions for detecting intruders, there is a growing demand for more effective techniques. This paper introduces a network intrusion detection system (NIDS) based on a deep neural network that utilizes network data features selected through the bagging and boosting methods. The presented NIDS implements both binary and multiclass attack detection models and was evaluated using the KDDCUP 99 and CICDDoS datasets. The experimental results demonstrated that the presented NIDS achieved an impressive accuracy rate of 99.4% while using a minimal number of features. This high level of accuracy makes the presented IDS a valuable tool.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Prediction of hold-up in pulsed disc-doughnut column based on least absolute shrinkage and selection operator regression",
        "paper_author": "Jin L.",
        "publication": "Harbin Gongcheng Daxue Xuebao/Journal of Harbin Engineering University",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "To obtain a predictive equation that provides high applicability and analytical convenience, based on the least absolute shrinkage and selection operator (LASSO). Investigate the effects of pulse intensity, disperse phase velocity, and continuous phase velocity on the hold-up in a pulsed disc-doughnut column with a kerosene-water system using the volume replacement method. Subsequently, several sets of empirical equations from related literature were compared and analyzed with new multivariate quadratic prediction equations fitted using the LASSO method. The results revealed that the prediction equations fitted using the LASSO method fit the experimental data extremely well, and the effect of the parameter on the hold-up in the specific operating range could be quantitatively analyzed by calculating the partial derivatives of the equation for each of the three operating parameters. The results also adapted very well to other literature data, and the average relative deviation of the fitted results from the experimental data was within 20%. This demonstrates that LASSO is a simple and intuitive way to analyze the effect of each parameter on the hold-up.",
        "affiliation_name": "China Institute of Atomic Energy",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Transformer Fault Diagnosis Method Based on Variation Sparrow Search Algorithm and Improved SMOTE Under Unbalanced Samples",
        "paper_author": "Zhu L.",
        "publication": "Gaodianya Jishu/High Voltage Engineering",
        "citied_by": "8",
        "cover_date": "2023-12-31",
        "Abstract": "To solve the problem of poor classification results caused by the serious homogeneity of the sparrow search algorithm and the unbalance of the transformer fault sample, a method of transformer fault diagnosis is proposed. It is based on a variation sparrow search algorithm-support vector machine(VSSA-SVM) and improved synthetic minority over-sampling technique (ISMOTE). Firstly, the dataset is denoised by the Tomek Link, and the center offset weight (COW) is introduced to improve the SMOTE for minority class sample synthesis of the unbalanced dataset, which can obtain the balancing processed transformer fault dataset. Then, a transformer fault diagnosis model based on the variation of the VSSA-SVM is proposed using the idea of mutation. Finally, the dissoived gas anaiysis (DGA) data of 413 cases of the collecting oil-immersed transformers are diagnosed using SSA-SVM, PSO-SVM and VSSA-SVM models, and the diagnosis accuracy results are 81.45%, 88.71% and 96.77% respectively. Additionally, compared to the SMOTE-NND, SVM SMOTE, Borderline-SMOTE, SMOTE and original dataset methods, the diagnosis accuracy of the ISMOTE model is improved by 3.22%, 4.03%, 6.45%, 7.52% and 11.29% respectively. The results show that the proposed method in this paper can be adopted to accurately judge the transformer fault state, and to effectively solve the problem of unbalanced fault data caused by low classification accuracy, which has a certain engineering practical value.",
        "affiliation_name": "Hubei University of Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Resolving the Human-subjects Status of Machine learning’s Crowdworkers",
        "paper_author": "Kaushik D.",
        "publication": "Queue",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "As toward datasets, crowdsourcing (naturalthe focus settingslanguage researchers of MLplatforms.characterized (machineprocessing) have 13,25learning) become Just taskby massivefor of reliant hasthe passage-shiftedNLP on based QA (question answering), more than 15 new datasets containing at least 50k annotations have been introduced since 2016. Prior to 2016, available QA datasets contained orders of magnitude fewer examples.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING-DRIVEN DECISION-MAKING IN SPINAL DISEASE TREATMENT",
        "paper_author": "Sundaramoorthy K.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Aside from people with significant neurological abnormalities, it's unclear whether conservative or surgical therapy of spinal disorders is better for each patient. This research looks into the use of Artificial Intelligence (AI) and Machine Learning (ML) in the therapy of spinal diseases decision-making. A supervised ML was trained and tested using the datasets of 70 patients with goal of accurately predicting the Oswestry Disability Index (ODI) 5 months following operation or the beginning of conservative therapy. In addition, using tenfold cross-validation, created an approach that forecasts the ODI of 5 arbitrarily chosen testing patients. The use of AI in this study also enabled for a comparison of the genuine patient data after 5 months with different treatment forecast, revealing variances of up to 19.6%. In the supervised version used here, ML can detect patients who'd receive from conservative treatment earlier on and, on the other hand, avoid unnecessary delays and painful for patients who'd gain from surgical treatment. Furthermore, despite tiny diagnostic categories, this strategy can be applied in various other fields of medical as an excellent instrument for decision-making when deciding between competing treatments alternatives.",
        "affiliation_name": "Panipat Institute of Engineering &amp; Technology",
        "affiliation_city": "Panipat",
        "affiliation_country": "India"
    },
    {
        "paper_title": "PREDICTION OF LUNG DISEASE SEVERITY BY APPLYING MACHINE AND DEEP LEARNING TECHNIQUES",
        "paper_author": "Guttula S.P.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Virus infected diseases are increasing rapidly. SARS covid -19 is one emerged into human body to extinct the human life. Prediction of the rapid changes and meticulous interpretation of the type of decease is challenging. Various stages of the risk severity prediction and interpretation is challenging. This paper discussed various machine learning algorithms applied on X-radiation chest images to predict the severity of the decease. Significant features are extracted using Principal component analysis (PCA). Bagging, Ada boost, XG boost, KNN machine learning methodologies applied to achieve the reliable performance. Bagging methodology shows dominant performance over other machine learning methodologies with 98.82% precision value and 98.67% accuracy. The F1 score and recall value is significantly good with 98.755 and 98.69 respectively. Bagging methodology is much reliable to interpret X-radiation images for Sars Covid-19 infections.",
        "affiliation_name": "Rabindranath Tagore University",
        "affiliation_city": "Mendua",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine-learning methods based on the texture and non-texture features of MRI for the preoperative prediction of sentinel lymph node metastasis in breast cancer",
        "paper_author": "Wang J.",
        "publication": "Translational Cancer Research",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Background: The establishment of an accurate, stable, and non-invasive prediction model of sentinel lymph node (SLN) metastasis in breast cancer is difficult nowadays. The aim of this work is to identify the optimal machine learning model based on the three-dimensional (3D) image features of magnetic resonance imaging (MRI) for the preoperative prediction of SLN metastasis in breast cancer patients. Methods: A total of 172 patients with histologically proven breast cancer were enrolled retrospectively, including 74 SLN metastasis patients and 98 non-SLN metastasis patients. All of them underwent diffusion-weighted imaging (DWI) magnetic resonance imaging (MRI) scan. Firstly, a total of 10,320 texture and four non-texture features were extracted from the region of interests (ROIs) of image. Twenty-four feature selection methods and 11 classification methods were then evaluated by using 10-fold cross-validation to identify the optimal machine learning model in terms of the mean area under the curve (AUC), accuracy (ACC), and stability. Results: The result showed that the model based on the combination of minimum redundancy maximum relevance (MRMR) + random forest (RF) exhibited the optimal predictive performance (AUC: 0.97±0.03; ACC: 0.89±0.05; stability: 2.94). Moreover, we independently investigated the performance of feature selection methods and classification methods, and observed that L1-support vector machine (L1-SVM) (AUC: 0.80±0.08; ACC: 0.76±0.07) and sequential forward floating selection (SFFS) (stability: 3.04) presented the best average predictive performance and stability among all feature selection methods, respectively. RF (AUC: 0.85±0.11; ACC: 0.80±0.09) and SVM (stability: 8.43) showed the best average predictive performance and stability among all classification methods, respectively. Conclusions: The identified model based on the 3D image features of MRI provides a non-invasive way for the preoperative prediction of SLN metastasis in breast cancer patients.",
        "affiliation_name": "Jinan University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "AN ENSEMBLE APPROACH FOR HARVEST VINTAGE FORECAST WITH MACHINE LEARNING TECHNIQUES: AN EXPERIMENTAL STUDY",
        "paper_author": "Pittala S.K.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "Since crop yield forecasting directly affects the production and security of food, it is an essential part of agricultural research and development. The traditional methods of calculating harvest vintages centered on agriculturalists' explanations and expertise have become increasingly challenging as a result of the rapid ups and downs in soil and climatic state of affairs. Machine-learning techniques have been applied in recent years to find a solution to this issue. This study centers around the utilization of a few AI models, for example, nearest neighbor relapse, closest polynomial relapse, irregular woodland relapse, slope helped tree relapse, and backing vector relapse, for the expectation of farming efficiency. The raw data was transformed into a format that is conducive to machine learning using efficient feature selection techniques. The study's findings showed that, in comparison to other tactics, when choosing features, using an ensemble technique can lead to more accurate predictions. By combining several data sources and machine learning algorithms, the ensemble approach generates a detailed and precise forecast. This work highlights both the benefits of using machine learning techniques to forecast agricultural amount produced and the recompenses of using a collaborative line of attack to feature selection.",
        "affiliation_name": "Shri Vishnu Engineering College For Women",
        "affiliation_city": "Bhimavaram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "EXPLORING THE CAPABILITIES OF DEEP LEARNING FOR ADVANCING CREDIT CARD FRAUD DETECTION: A REVOLUTIONARY APPROACH",
        "paper_author": "Daif A.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "The use of credit cards for both online and in-person purchases has become increasingly prevalent in our daily lives. However, this convenience also exposes users to the risks associated with credit card fraud. Credit card fraud presents a significant challenge for banks, merchants, and consumers, emphasizing the crucial need for the swift and accurate detection of such fraudulent activities. In response to this challenge, recent research has delved into the application of deep learning techniques for credit card fraud detection. This article presents a study that combines a Bi-LSTM (Bidirectional Long Short-Term Memory) with an attention layer to identify fraudulent transaction patterns and achieve a balanced classification of data. The results of this study demonstrate the method's high accuracy, surpassing the performance of other fraud detection approaches. Notably, this innovative approach efficiently identifies critical transactions within input sequences, significantly improving the prediction accuracy for fraudulent transactions. This research provides a unique perspective on the use of deep learning to enhance security in credit card transactions.",
        "affiliation_name": "Laboratoire de Technologie de l'Information et Modélisation",
        "affiliation_city": "Casablanca",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Use of survival support vector machine combined with random survival forest to predict the survival of nasopharyngeal carcinoma patients",
        "paper_author": "Xiao Z.",
        "publication": "Translational Cancer Research",
        "citied_by": "3",
        "cover_date": "2023-12-31",
        "Abstract": "Background: The Cox regression model is not sufficiently accurate to predict the survival prognosis of nasopharyngeal carcinoma (NPC) patients. It is impossible to calculate and rank the importance of impact factors due to the low predictive accuracy of the Cox regression model. So, we developed a system. Using the SEER (The Surveillance, Epidemiology, and End Results) database data on NPC patients, we proposed the use of random survival forest (RSF) and survival-support vector machine (SVM) from the machine learning methods to develop a survival prediction system specifically for NPC patients. This approach aimed to make up for the insufficiency of the Cox regression model. We also used the Cox regression model to validate the development of the nomogram and compared it with machine learning methods. Methods: A total of 1,683 NPC patients were extracted from the SEER database from January 2010 to December 2015. We used R language for modeling work, established the nomogram of survival prognosis of NPC patients by Cox regression model, ranked the correlation of influencing factors by RSF model VIMP (variable important) method, developed a survival prognosis system for NPC patients based on survival-SVM, and used C-index for model evaluation and performance comparison. Results: Although the Cox regression models can be developed to predict the prognosis of NPC patients, their accuracy was lower than that of machine learning methods. When we substituted the data for the Cox model, the C-index for the training set was only 0.740, and the C-index for the test set was 0.721. In contrast, the C index of the survival-SVM model was 0.785. The C-index of the RSF model was 0.729. The importance ranking of each variable could be obtained according to the VIMP method. Conclusions: The prediction results from the Cox model are not as good as those of the RSF method and survival-SVM based on the machine learning method. For the survival prognosis of NPC patients, the machine learning method can be considered for clinical application.",
        "affiliation_name": "Guangxi Medical University",
        "affiliation_city": "Nanning",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Integrating Phylogenetic Analysis and Machine Learning for Enhanced Phenotype Prediction in Oryza Sativa",
        "paper_author": "Kiranmai B.",
        "publication": "International Journal of Agriculture and Biosciences",
        "citied_by": "3",
        "cover_date": "2023-12-31",
        "Abstract": "Genomic selection has revolutionized plant breeding by enabling the efficient and accurate selection of elite genotypes. Traditional approaches require resource-intensive phenotyping at all stages of artificial selection. However, genomic selection reduces this burden by leveraging genotyping data and machine learning techniques to predict agronomically relevant phenotypic traits. In this paper, we present a two-level prediction system that incorporates both phylogenetic analysis and machine learning models to predict the height of Oryza Sativa L. (Rice) plants based on their gene sequences. The only input for our model is a genomic sequence, whose length does not have to be equal to 24 (number of SNPs considered for our model). At the first level, we employ phylogenetic analysis to classify the plants into subpopulations, capturing the inherent genetic diversity within the dataset. This approach addresses the limitations of existing research, as it incorporates population structure information from gene sequences that is often overlooked in machine learning-based approaches. Subsequently, at the second level, we leverage the population structure information and genomic data to train a machine learning model for accurately predicting plant height. We compare and evaluate various methods employed at both levels to identify the most effective approach. Hence our approach of predicting Phenotype with reference to genotype is accurate compared with other existing systems. Two level classification has done well in identifying phenotype and performed well in predicting subpopulation.",
        "affiliation_name": "Keshav Memorial Institute of Technology",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Enhanced System for the Prediction of Vehicle Condition",
        "paper_author": "Cloudin S.",
        "publication": "International Journal of Vehicle Structures and Systems",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "The present-day vehicle monitoring systems retrieve real-time data and problem codes from the car using an OBD-II device and provide the user with this data in unprocessed form. A system that is easy to use is necessary to enable users to understand the status of their car on their own, thereby preventing potentially dangerous collisions. The goal of this research is to create an understandable and user-friendly web application that will allow users to keep an eye on the health of their vehicle. The study explores the idea of the Internet of Vehicles (IoV), imagining a network in which various cars can interact with one another. The research attempts to forecast future vehicle conditions based on current data and classify them as \"Good\", \"Moderate\", or \"Bad\" using machine learning models such as Autoregressive Integrated Moving Average and Ordinal Logistic Regression.",
        "affiliation_name": "KCG College of Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "ASSESSING THE RELATIVE IMPACT OF COLOMBIAN HIGHER EDUCATION INSTITUTIONS USING FUZZY DATA ENVELOPMENT ANALYSIS (FUZZY-DEA) IN STATE EVALUATIONS",
        "paper_author": "Zuluaga R.",
        "publication": "Journal on Efficiency and Responsibility in Education and Science",
        "citied_by": "4",
        "cover_date": "2023-12-31",
        "Abstract": "This research aims to design a helpful methodology for estimating universities’ relative impact on students as a sustainability factor in higher education. To this end, the research methodology implemented a two-stage approach. The first stage involves the relative efficiency analysis of the study units using Fuzzy Data Envelopment Analysis. The second stage consists of a predictive evaluation of the efficiency of the study units. Consequently, among the most relevant results of the research, it is observed that the methodology identifies the institutions that need to strengthen the academic competencies of the industrial engineering program. Additionally, we developed a benchmark analysis called Efficient Route to help inefficient units achieve efficiency, associating efficiency, and sustainability as pillars of higher education processes.",
        "affiliation_name": "Escuela Militar de Cadetes “General José María Córdova” (ESMIC)",
        "affiliation_city": "Bogota",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "ARTIFICIAL INTELLIGENCE FOR SHIP DESIGN PROCESS IMPROVEMENT: A CONCEPTUAL PAPER",
        "paper_author": "Maimun A.",
        "publication": "Journal of Naval Architecture and Marine Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "This paper explores the artificial intelligence (AI) concept for complex engineering design processes in the shipping industry. It is driven by the computer technologies advancement for fast and concurrent tasks processing, machine learnability, and data-centric approach. While AI has been adopted in many industries, it is still lacking the structured approaches for practical implementation. This is especially on the generality of the methodologies and explaining AI to the non-technical members and their preparedness. Therefore, this work proposed a conceptual framework to systematically extract, represent and visualize the ship design knowledge, to develop and deploy the machine learning (ML) models, and to demonstrate the AI-based ship design processes. Comparisons to the generic ship design model were made and discussed to highlight the improvements observed. It is found that while the conventional algorithmic approach procedures were faster in terms of execution time, the stepwise empirical models were often limited by the dataset and the design assumptions with restricted estimation capabilities for solving the nonlinear ship design problems. The findings presented the impact in improving the existing processes and effectively reducing its cycle. Additionally, the approach emphasised on the validated ship design data thus its generalization for fast and wide adoptions at scales.",
        "affiliation_name": "Universiti Teknologi Malaysia",
        "affiliation_city": "Johor Bahru",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "An AutoML-driven Antenna Performance Prediction Model in the Autonomous Driving Radar Manufacturing Process",
        "paper_author": "Bak S.H.",
        "publication": "KSII Transactions on Internet and Information Systems",
        "citied_by": "0",
        "cover_date": "2023-12-31",
        "Abstract": "This paper proposes an antenna performance prediction model in the autonomous driving radar manufacturing process. Our research work is based upon a challenge dataset, Driving Radar Manufacturing Process Dataset, and a typical AutoML machine learning workflow engine, Pycaret open-source Python library. Note that the dataset contains the total 70 data-items, out of which 54 used as input features and 16 used as output features, and the dataset is properly built into resolving the multi-output regression problem. During the data regression analysis and preprocessing phase, we identified several input features having similar correlations and so detached some of those input features, which may become a serious cause of the multicollinearity problem that affect the overall model performance. In the training phase, we train each of output-feature regression models by using the AutoML approach. Next, we selected the top 5 models showing the higher performances in the AutoML result reports and applied the ensemble method so as for the selected models’ performances to be improved. In performing the experimental performance evaluation of the regression prediction model, we particularly used two metrics, MAE and RMSE, and the results of which were 0.6928 and 1.2065, respectively. Additionally, we carried out a series of experiments to verify the proposed model’s performance by comparing with other existing models’ performances. In conclusion, we enhance accuracy for safer autonomous vehicles, reduces manufacturing costs through AutoML-Pycaret and machine learning ensembled model, and prevents the production of faulty radar systems, conserving resources. Ultimately, the proposed model holds significant promise not only for antenna performance but also for improving manufacturing quality and advancing radar systems in autonomous vehicles.",
        "affiliation_name": "Kyonggi University",
        "affiliation_city": "Suwon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Recent advances in metamaterial integrated photonics",
        "paper_author": "Cheben P.",
        "publication": "Advances in Optics and Photonics",
        "citied_by": "19",
        "cover_date": "2023-12-31",
        "Abstract": "Since the invention of the silicon subwavelength grating waveguide in 2006, subwavelength metamaterial engineering has become an essential design tool in silicon photonics. Employing well-established nanometer-scale semiconductor manufacturing techniques to create metamaterials in optical waveguides has allowed unprecedented control of the flow of light in photonic chips. This is achieved through fine-tuning of fundamental optical properties such as modal confinement, effective index, dispersion, and anisotropy, directly by lithographic imprinting of a specific subwavelength grating structure onto a nanophotonic waveguide. In parallel, low-loss mode propagation is readily obtained over a broad spectral range since the subwavelength periodicity effectively avoids losses due to spurious resonances and bandgap effects. In this review we present recent advances achieved in the surging field of metamaterial integrated photonics. After briefly introducing the fundamental concepts governing the propagation of light in periodic waveguides via Floquet–Bloch modes, we review progress in the main application areas of subwavelength nanostructures in silicon photonics, presenting the most representative devices. We specifically focus on off-chip coupling interfaces, polarization management and anisotropy engineering, spectral filtering and wavelength multiplexing, evanescent field biochemical sensing, mid-infrared photonics, and nonlinear waveguide optics and optomechanics. We also introduce a nascent research area of resonant integrated photonics leveraging Mie resonances in dielectrics for on-chip guiding of optical waves, with the first Huygens’ metawaveguide recently demonstrated. Finally, we provide a brief overview of inverse design approaches and machine-learning algorithms for on-chip optical metamaterials. In our conclusions, we summarize the key developments while highlighting the challenges and future prospects. © 2023 Optica Publishing Group",
        "affiliation_name": "Centre de Nanosciences et de Nanotechnologies",
        "affiliation_city": "Palaiseau",
        "affiliation_country": "France"
    },
    {
        "paper_title": "The changing face of circulating tumor DNA (ctDNA) profiling: Factors that shape the landscape of methodologies, technologies, and commercialization",
        "paper_author": "Bronkhorst A.J.",
        "publication": "Medizinische Genetik",
        "citied_by": "7",
        "cover_date": "2023-12-31",
        "Abstract": "Liquid biopsies, in particular the profiling of circulating tumor DNA (ctDNA), have long held promise as transformative tools in cancer precision medicine. Despite a prolonged incubation phase, ctDNA profiling has recently experienced a strong wave of development and innovation, indicating its imminent integration into the cancer management toolbox. Various advancements in mutation-based ctDNA analysis methodologies and technologies have greatly improved sensitivity and specificity of ctDNA assays, such as optimized preanalytics, size-based pre-enrichment strategies, targeted sequencing, enhanced library preparation methods, sequencing error suppression, integrated bioinformatics and machine learning. Moreover, research breakthroughs have expanded the scope of ctDNA analysis beyond hotspot mutational profiling of plasma-derived apoptotic, mono-nucleosomal ctDNA fragments. This broader perspective considers alternative genetic features of cancer, genome-wide characterization, classical and newly discovered epigenetic modifications, structural variations, diverse cellular and mechanistic ctDNA origins, and alternative biospecimen types. These developments have maximized the utility of ctDNA, facilitating landmark research, clinical trials, and the commercialization of ctDNA assays, technologies, and products. Consequently, ctDNA tests are increasingly recognized as an important part of patient guidance and are being implemented in clinical practice. Although reimbursement for ctDNA tests by healthcare providers still lags behind, it is gaining greater acceptance. In this work, we provide a comprehensive exploration of the extensive landscape of ctDNA profiling methodologies, considering the multitude of factors that influence its development and evolution. By illuminating the broader aspects of ctDNA profiling, the aim is to provide multiple entry points for understanding and navigating the vast and rapidly evolving landscape of ctDNA methodologies, applications, and technologies.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "DeepDRP: Prediction of intrinsically disordered regions based on integrated view deep learning architecture from transformer-enhanced and protein information",
        "paper_author": "Yang Z.",
        "publication": "International Journal of Biological Macromolecules",
        "citied_by": "3",
        "cover_date": "2023-12-31",
        "Abstract": "Intrinsic disorder in proteins, a widely distributed phenomenon in nature, is related to many crucial biological processes and various diseases. Traditional determination methods tend to be costly and labor-intensive, therefore it is desirable to seek an accurate identification method of intrinsically disordered proteins (IDPs). In this paper, we proposed a novel Deep learning model for Intrinsically Disordered Regions in Proteins named DeepDRP. DeepDRP employed an innovative TimeDistributed strategy and Bi-LSTM architecture to predict IDPs and is driven by integrated view features of PSSM, Energy-based encoding, AAindex, and transformer-enhanced embeddings including DR-BERT, OntoProtein, Prot-T5, and ESM-2. The comparison of different feature combinations indicates that the transformer-enhanced features contribute far more than traditional features to predict IDPs and ESM-2 accounts for a larger contribution in the pre-trained fusion vectors. The ablation test verified that the TimeDistributed strategy surely increased the model performance and is an efficient approach to the IDP prediction. Compared with eight state-of-the-art methods on the DISORDER723, S1, and DisProt832 datasets, the Matthews correlation coefficient of DeepDRP significantly outperformed competing methods by 4.90 % to 36.20 %, 11.80 % to 26.33 %, and 4.82 % to 13.55 %. In brief, DeepDRP is a reliable model for IDP prediction and is freely available at https://github.com/ZX-COLA/DeepDRP.",
        "affiliation_name": "Changzhou Second People's Hospital",
        "affiliation_city": "Changzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Nucleic acid based point-of-care diagnostic technology for infectious disease detection using machine learning empowered smartphone-interfaced quantitative colorimetry",
        "paper_author": "Biswas S.K.",
        "publication": "International Journal of Biological Macromolecules",
        "citied_by": "5",
        "cover_date": "2023-12-31",
        "Abstract": "We report a nucleic acid-based point of care testing technology for infectious disease detection at resource limited settings by integrating a low-cost portable device with machine learning-empowered quantitative colorimetric analytics that can be interfaced via a smartphone application. We substantiate our proposition by demonstrating the efficacy of this technology in detecting COVID-19 infection from human swab samples, using the RT-LAMP protocol. Comparison with gold standard results from real-time PCR evidences high sensitivity and specificity, ensuring simplicity, portability, and user-friendliness of the technology at the same time. Colorimetric analytics of the reaction output without necessitating the opening of the reaction microchambers enables execution of the complete test workflow without any laboratory control that may otherwise be required stringently for safeguarding against carryover contamination. Seamless sample-to-answer workflow and machine learning-based readout further assures minimal human intervention for the test readout, thus eliminating inevitable inaccuracies stemming from erroneous execution of the test as well as subjectivity in interpreting the outcome. Our results further indicate the possibilities of upgrading the technology to predict the pathogenic load on the infected patients akin to the cyclic threshold value of the real-time PCR, when calibrated with reference to a wide range of ‘training’ data for the machine learner, thereby putting forward the same as viable alternative to the resource-intensive PCR tests that cannot be made readily accessible at underserved community settings.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Enzymatic pretreatment for cellulose nanofiber production: Understanding morphological changes and predicting reducing sugar concentration",
        "paper_author": "Mazega A.",
        "publication": "International Journal of Biological Macromolecules",
        "citied_by": "5",
        "cover_date": "2023-12-31",
        "Abstract": "Enzymatic pretreatment plays a crucial role in producing cellulose nanofibers (CNFs) before fibrillation. While previous studies have explored how treatment severity affects CNF characteristics, there remains a lack of suitable parameters to monitor real-time enzymatic processes and fully comprehend the link between enzymatic action, fibrillation, and CNF properties. This study focuses on evaluating the impact of enzyme charge (using a monocomponent endoglucanase) and treatment time on cellulose fiber morphology and reducing sugar generation. For the first time, a random forest (RF) model is developed to predict reducing sugar concentration based on easily measurable process conditions (e.g., stirrer power consumption) and fiber/suspension characteristics like fines content and apparent viscosity. Polarized light optical microscopy was found to be a suitable technique to evaluate the morphological changes that fibers experience during enzymatic pretreatment. The research also revealed that endoglucanases initially induce surface fibrillation, releasing fine fibers into the suspension, followed by fiber swelling and shortening. Furthermore, the effect of enzymatic pretreatment on resulting CNF characteristics was studied at two fibrillation intensities, indicating that a high enzyme charge and short treatment times (e.g., 90 min) are sufficient to produce CNFs with a nanofibrillation yield of 19–23 % and a cationic demand ranging from 220 to 275 μeq/g. This work introduces a well-modeled enzymatic pretreatment process, unlocking its potential and reducing uncertainties for future upscaling endeavors.",
        "affiliation_name": "Universidade Federal do Parana",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Data-driven supervised machine learning to predict the compressive response of porous PVA/Gelatin hydrogels and in-vitro assessments: Employing design of experiments",
        "paper_author": "Khalvandi A.",
        "publication": "International Journal of Biological Macromolecules",
        "citied_by": "8",
        "cover_date": "2023-12-31",
        "Abstract": "The purpose of this study is to design and evaluate a series of porous hydrogels by considering three independent variables using the Box-Behnken method. Accordingly, concentrations of the constituent macromolecules of the hydrogels, Polyvinyl Alcohol and Gelatin, and concentration of the crosslinking agent are varied to fabricate sixteen different porous samples utilizing the lyophilization process. Subsequently, the porous hydrogels are subjected to a battery of tests, including Fourier Transform Infrared spectroscopy, morphology assessment, pore-size study, porosimetry, uniaxial compression, and swelling measurements. Additionally, in-vitro cell assessments are performed by culturing mouse fibroblast cells (L-929) on the hydrogels, where viability, proliferation, adhesion, and morphology of the L-929 cells are monitored over 24, 48, and 72 h to evaluate the biocompatibility of these biomaterials. To better understand the mechanical behavior of the hydrogels under compressive loadings, Deep Neural Networks (DNNs) are implemented to predict and capture their compressive stress-strain responses as a function of the constituent materials' concentrations and duration of the performed mechanical tests. Overall, this study emphasizes the importance of considering multiple variables in the design of porous hydrogels, provides a comprehensive evaluation of their mechanical and biological properties, and, particularly, implements DNNs in the prediction of the hydrogels' stress-strain responses.",
        "affiliation_name": "Changwon National University",
        "affiliation_city": "Changwon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Evaluation of a dye-decolorizing peroxidase from Comamonas serinivorans for lignin valorization potentials",
        "paper_author": "Sethupathy S.",
        "publication": "International Journal of Biological Macromolecules",
        "citied_by": "8",
        "cover_date": "2023-12-31",
        "Abstract": "Although dye-decolourising peroxidases (DyPs) are well-known for lignin degradation, a comprehensive understanding of their mechanism remains unclear. Therefore, studying the mechanism of lignin degradation by DyPs is necessary for industrial applications and enzyme engineering. In this study, a dye-decolourising peroxidase (CsDyP) gene from C. serinivorans was heterologously expressed and studied for its lignin degradation potential. Molecular docking analysis predicted the binding of 2, 2-azino-bis (3-ethylbenzothiazoline-6-sulfonic acid) (ABTS), veratryl alcohol (VA), 2, 6-dimethylphenol (2, 6- DMP), guaiacol (GUA), and lignin to the substrate-binding pocket of CsDyP. Evaluation of the enzymatic properties showed that CsDyP requires pH 4.0 and 30 °C for optimal activity and has a high affinity for ABTS. In addition, CsDyP is stable over a wide range of temperatures and pH and can tolerate 5.0 mM organic solvents. Low NaCl concentrations promoted CsDyP activity. Further, CsDyP significantly reduced the chemical oxygen demand decolourised alkali lignin (AL) and milled wood lignin (MWL). CsDyP targets the β-O-4, C[dbnd]O, and C[sbnd]C bonds linking lignin's G, S, and H units to depolymerize and produce aromatic compounds. Overall, this study delivers valuable insights into the lignin degradation mechanism of CsDyP, which can benefit its industrial applications and lignin valorization.",
        "affiliation_name": "Faculty of Agriculture",
        "affiliation_city": "Fayoum",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "LSA-ac4C: A hybrid neural network incorporating double-layer LSTM and self-attention mechanism for the prediction of N4-acetylcytidine sites in human mRNA",
        "paper_author": "Lai F.L.",
        "publication": "International Journal of Biological Macromolecules",
        "citied_by": "11",
        "cover_date": "2023-12-31",
        "Abstract": "N4-acetylcytidine (ac4C) is a vital constituent of the epitranscriptome and plays a crucial role in the regulation of mRNA expression. Numerous studies have established correlations between ac4C and the incidence, progression and prognosis of various cancers. Therefore, accurately predicting ac4C sites is an important step towards comprehending the biological functions of this modification and devising effective therapeutic interventions. Wet experiments are primary methods for studying ac4C, but computational methods have emerged as a promising supplement due to their cost-effectiveness and shorter research cycles. However, current models still have inherent limitations in terms of predictive performance and generalization ability. Here, we utilized automated machine learning technology to establish a reliable baseline and constructed a deep hybrid neural network, LSA-ac4C, which combines double-layer Long Short-Term Memory (LSTM) and self-attention mechanism for accurate ac4C sites prediction. Benchmarking comparisons demonstrate that LSA-ac4C exhibits superior performance compared to the current state-of-the-art method, with ACC, MCC and AUROC improving by 2.89 %, 5.96 % and 1.53 %, respectively, on an independent test set. Overall, LSA-ac4C serves as a powerful tool for predicting ac4C sites in human mRNA, thus benefiting research on RNA modification. For the convenience of the research community, a web server has been established at http://tubic.org/ac4C.",
        "affiliation_name": "Tianjin University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Mobile Edge Computing and Machine Learning in the Internet of Unmanned Aerial Vehicles: A Survey",
        "paper_author": "Ning Z.",
        "publication": "ACM Computing Surveys",
        "citied_by": "48",
        "cover_date": "2023-12-31",
        "Abstract": "Unmanned Aerial Vehicles (UAVs) play an important role in the Internet of Things and form the paradigm of the Internet of UAVs, due to their characteristics of flexibility, mobility, and low costs. However, resource constraints such as dynamic wireless channels, limited battery capacities, and computation resources of UAVs make traditional methods inefficient in the Internet of UAVs. The thriving of Mobile Edge Computing (MEC) and Machine Learning (ML) is of great significance and is promising for real-time resource allocation, trajectory design, and intelligent decision making. This survey provides a comprehensive review of key technologies, applications, solutions, and challenges based on the integration of MEC and ML in the Internet of UAVs. First, key technologies of MEC and ML are presented. Then, their integration and major issues in the Internet of UAVs are presented. Furthermore, the applications of MEC and ML in the Internet of UAVs under urban, industrial, and emergency scenarios are discussed. After that, this survey summarizes the current solutions for MEC and ML in the Internet of UAVs based on the considered issues. Finally, some open problems and challenges are discussed.",
        "affiliation_name": "Chongqing University of Posts and Telecommunications",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Continuous Human Action Recognition for Human-machine Interaction: A Review",
        "paper_author": "Gammulle H.",
        "publication": "ACM Computing Surveys",
        "citied_by": "14",
        "cover_date": "2023-12-31",
        "Abstract": "With advances in data-driven machine learning research, a wide variety of prediction models have been proposed to capture spatio-temporal features for the analysis of video streams. Recognising actions and detecting action transitions within an input video are challenging but necessary tasks for applications that require real-time human-machine interaction. By reviewing a large body of recent related work in the literature, we thoroughly analyse, explain, and compare action segmentation methods and provide details on the feature extraction and learning strategies that are used on most state-of-the-art methods. We cover the impact of the performance of object detection and tracking techniques on human action segmentation methodologies. We investigate the application of such models to real-world scenarios and discuss several limitations and key research directions towards improving interpretability, generalisation, optimisation, and deployment.",
        "affiliation_name": "Commonwealth Scientific and Industrial Research Organisation",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Resource-Efficient Convolutional Networks: A Survey on Model-, Arithmetic-, and Implementation-Level Techniques",
        "paper_author": "Lee J.K.",
        "publication": "ACM Computing Surveys",
        "citied_by": "13",
        "cover_date": "2023-12-31",
        "Abstract": "Convolutional neural networks (CNNs) are used in our daily life, including self-driving cars, virtual assistants, social network services, healthcare services, and face recognition, among others. However, deep CNNs demand substantial compute resources during training and inference. The machine learning community has mainly focused on model-level optimizations such as architectural compression of CNNs, whereas the system community has focused on implementation-level optimization. In between, various arithmetic-level optimization techniques have been proposed in the arithmetic community. This article provides a survey on resource-efficient CNN techniques in terms of model-, arithmetic-, and implementation-level techniques, and identifies the research gaps for resource-efficient CNN techniques across the three different level techniques. Our survey clarifies the influence from higher- to lower-level techniques based on our resource efficiency metric definition and discusses the future trend for resource-efficient CNN research.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Resource Management in Mobile Edge Computing: A Comprehensive Survey",
        "paper_author": "Zhang X.",
        "publication": "ACM Computing Surveys",
        "citied_by": "18",
        "cover_date": "2023-12-31",
        "Abstract": "With the evolution of 5G and Internet of Things technologies, Mobile Edge Computing (MEC) has emerged as a major computing paradigm. Compared to cloud computing, MEC integrates network control, computing, and storage to customizable, fast, reliable, and secure distributed services that are closer to the user and data site. Although a popular research topic, MEC resource management comes in many forms due to its emerging nature and there exists little consensus in the community. In this survey, we present a comprehensive review of existing research problems and relevant solutions within MEC resource management. We first describe the major problems in MEC resource allocation when the user applications have diverse performance requirements. We discuss the unique challenges caused by the dynamic nature of the environments and use cases where MEC is adopted. We also explore and categorize existing solutions that address such challenges. We particularly explore traditional optimization-based methods and deep learning-based approaches. In addition, we take a deeper dive into the most popular applications and use cases that adopt MEC paradigm and how MEC provides customized solutions for each use cases, in particular, video analytics applications. Finally, we outline the open research challenges and future directions.1.",
        "affiliation_name": "The City University of New York",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Recent Trends in Task and Motion Planning for Robotics: A Survey",
        "paper_author": "Guo H.",
        "publication": "ACM Computing Surveys",
        "citied_by": "20",
        "cover_date": "2023-12-31",
        "Abstract": "Autonomous robots are increasingly served in real-world unstructured human environments with complex long-horizon tasks, such as restaurant serving and office delivery. Task and motion planning (TAMP) is a recent research method in Artificial Intelligence Planning for these applications. TAMP integrates high-level abstract reasoning with the low-level geometric feasibility check and thus is more comprehensive than traditional task planning methods. While regular TAMP approaches are challenged by different types of uncertainties and the generalization of various applications when implemented in real-world scenarios. This article systematically reviews the most relevant approaches to TAMP and classifies them according to their features and emphasis; it categorizes the challenges and presents online TAMP and machine learning-based TAMP approaches for addressing them.",
        "affiliation_name": "Hunan University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Implementing Data Exfiltration Defense in Situ: A Survey of Countermeasures and Human Involvement",
        "paper_author": "Chung M.H.",
        "publication": "ACM Computing Surveys",
        "citied_by": "7",
        "cover_date": "2023-12-31",
        "Abstract": "In this article we consider the problem of defending against increasing data exfiltration threats in the domain of cybersecurity. We review existing work on exfiltration threats and corresponding countermeasures. We consider current problems and challenges that need to be addressed to provide a qualitatively better level of protection against data exfiltration. After considering the magnitude of the data exfiltration threat, we outline the objectives of this article and the scope of the review. We then provide an extensive discussion of present methods of defending against data exfiltration. We note that current methodologies for defending against data exfiltration do not connect well with domain experts, both as sources of knowledge and as partners in decision-making. However, human interventions continue to be required in cybersecurity. Thus, cybersecurity applications are necessarily socio-technical systems that cannot be safely and efficiently operated without considering relevant human factor issues. We conclude with a call for approaches that can more effectively integrate human expertise into defense against data exfiltration.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "From Anecdotal Evidence to Quantitative Evaluation Methods: A Systematic Review on Evaluating Explainable AI",
        "paper_author": "Nauta M.",
        "publication": "ACM Computing Surveys",
        "citied_by": "157",
        "cover_date": "2023-12-31",
        "Abstract": "The rising popularity of explainable artificial intelligence (XAI) to understand high-performing black boxes raised the question of how to evaluate explanations of machine learning (ML) models. While interpretability and explainability are often presented as a subjectively validated binary property, we consider it a multi-faceted concept. We identify 12 conceptual properties, such as Compactness and Correctness, that should be evaluated for comprehensively assessing the quality of an explanation. Our so-called Co-12 properties serve as categorization scheme for systematically reviewing the evaluation practices of more than 300 papers published in the past 7 years at major AI and ML conferences that introduce an XAI method. We find that one in three papers evaluate exclusively with anecdotal evidence, and one in five papers evaluate with users. This survey also contributes to the call for objective, quantifiable evaluation methods by presenting an extensive overview of quantitative XAI evaluation methods. Our systematic collection of evaluation methods provides researchers and practitioners with concrete tools to thoroughly validate, benchmark, and compare new and existing XAI methods. The Co-12 categorization scheme and our identified evaluation methods open up opportunities to include quantitative metrics as optimization criteria during model training to optimize for accuracy and interpretability simultaneously.",
        "affiliation_name": "Universiteit Twente",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Toward Wearable Sensors: Advances, Trends, and Challenges",
        "paper_author": "He T.",
        "publication": "ACM Computing Surveys",
        "citied_by": "6",
        "cover_date": "2023-12-31",
        "Abstract": "Sensors suitable for wearable devices have many special characteristics compared to other sensors, such as stability, sensitivity, sensor volume, biocompatibility, and so on. With the development of wearable technology, amazing wearable sensors have attracted a lot of attention, and some researchers have done a large number of technology explorations and reviews. However, previous surveys generally were concerned with a specified application and comprehensively reviewed the computing techniques for the signals required by this application, as well as how computing can promote data processing. There is a gap in the opposite direction, i.e., the fundamental data source actively stimulates application rather than from the application to the data, and computing promotes the acquisition of data rather than data processing. To fill this gap, starting with different parts of the body as the source of signal, the fundamental data sources that can be obtained and detected are explored by combining the three sensing principles, as well as discussing and analyzing the existing and potential applications of machine learning in simplifying sensor designs and the fabrication of sensors.",
        "affiliation_name": "Shenzhen MSU-BIT University",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Detecting Mental Distresses Using Social Behavior Analysis in the Context of COVID-19: A Survey",
        "paper_author": "Dhelim S.",
        "publication": "ACM Computing Surveys",
        "citied_by": "8",
        "cover_date": "2023-12-31",
        "Abstract": "Online social media provides a channel for monitoring people's social behaviors from which to infer and detect their mental distresses. During the COVID-19 pandemic, online social networks were increasingly used to express opinions, views, and moods due to the restrictions on physical activities and in-person meetings, leading to a significant amount of diverse user-generated social media content. This offers a unique opportunity to examine how COVID-19 changed global behaviors regarding its ramifications on mental well-being. In this article, we surveyed the literature on social media analysis for the detection of mental distress, with a special emphasis on the studies published since the COVID-19 outbreak. We analyze relevant research and its characteristics and propose new approaches to organizing the large amount of studies arising from this emerging research area, thus drawing new views, insights, and knowledge for interested communities. Specifically, we first classify the studies in terms of feature extraction types, language usage patterns, aesthetic preferences, and online behaviors. We then explored various methods (including machine learning and deep learning techniques) for detecting mental health problems. Building upon the in-depth review, we present our findings and discuss future research directions and niche areas in detecting mental health problems using social media data. We also elaborate on the challenges of this fast-growing research area, such as technical issues in deploying such systems at scale as well as privacy and ethical concerns.",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Rolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Survey on Run-time Power Monitors at the Edge",
        "paper_author": "Zoni D.",
        "publication": "ACM Computing Surveys",
        "citied_by": "7",
        "cover_date": "2023-12-31",
        "Abstract": "Effectively managing energy and power consumption is crucial to the success of the design of any computing system, helping mitigate the efficiency obstacles given by the downsizing of the systems while also being a valuable step towards achieving green and sustainable computing. The quality of energy and power management is strongly affected by the prompt availability of reliable and accurate information regarding the power consumption for the different parts composing the target monitored system. At the same time, effective energy and power management are even more critical within the field of devices at the edge, which exponentially proliferated within the past decade with the digital revolution brought by the Internet of things. This manuscript aims to provide a comprehensive conceptual framework to classify the different approaches to implementing run-time power monitors for edge devices that appeared in literature, leading the reader toward the solutions that best fit their application needs and the requirements and constraints of their target computing platforms. Run-time power monitors at the edge are analyzed according to both the power modeling and monitoring implementation aspects, identifying specific quality metrics for both in order to create a consistent and detailed taxonomy that encompasses the vast existing literature and provides a sound reference to the interested reader.",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "What-is and How-to for Fairness in Machine Learning: A Survey, Reflection, and Perspective",
        "paper_author": "Tang Z.",
        "publication": "ACM Computing Surveys",
        "citied_by": "9",
        "cover_date": "2023-12-31",
        "Abstract": "We review and reflect on fairness notions proposed in machine learning literature and make an attempt to draw connections to arguments in moral and political philosophy, especially theories of justice. We survey dynamic fairness inquiries and further consider the long-term impact induced by current prediction and decision. We present a flowchart that encompasses implicit assumptions and expected outcomes of different fairness inquiries on the data-generating process, the predicted outcome, and the induced impact, respectively. We demonstrate the importance of matching the mission (what kind of fairness to enforce) and the means (which appropriate fairness spectrum to analyze) to fulfill the intended purpose.",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Computer Vision-based Analysis of Buildings and Built Environments: A Systematic Review of Current Approaches",
        "paper_author": "Starzyńska-Grześ M.B.",
        "publication": "ACM Computing Surveys",
        "citied_by": "8",
        "cover_date": "2023-12-31",
        "Abstract": "Analysing 88 sources published from 2011 to 2021, this article presents a first systematic review of the computer vision-based analysis of buildings and the built environment. Its aim is to assess the potential of this research for architectural studies and the implications of a shift to a cross-disciplinarity approach between architecture and computer science for research problems, aims, processes, and applications. To this end, the types of algorithms and data sources used in the reviewed studies are discussed in respect to architectural applications such as a building classification, detail classification, qualitative environmental analysis, building condition survey, and building value estimation. Based on this, current research gaps and trends are identified, with two main research aims emerging. First, studies that use or optimise computer vision methods to automate time-consuming, labour-intensive, or complex tasks when analysing architectural image data. Second, work that explores the methodological benefits of machine learning approaches to overcome limitations of conventional analysis to investigate new questions about the built environment by finding patterns and relationships among visual, statistical, and qualitative data. The growing body of research offers new methods to architectural and design studies, with the article identifying future challenges and directions of research.",
        "affiliation_name": "Royal College of Art",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Representation Bias in Data: A Survey on Identification and Resolution Techniques",
        "paper_author": "Shahbazi N.",
        "publication": "ACM Computing Surveys",
        "citied_by": "32",
        "cover_date": "2023-12-31",
        "Abstract": "Data-driven algorithms are only as good as the data they work with, while datasets, especially social data, often fail to represent minorities adequately. Representation Bias in data can happen due to various reasons, ranging from historical discrimination to selection and sampling biases in the data acquisition and preparation methods. Given that \"bias in, bias out,\"one cannot expect AI-based solutions to have equitable outcomes for societal applications, without addressing issues such as representation bias. While there has been extensive study of fairness in machine learning models, including several review papers, bias in the data has been less studied. This article reviews the literature on identifying and resolving representation bias as a feature of a dataset, independent of how consumed later. The scope of this survey is bounded to structured (tabular) and unstructured (e.g., image, text, graph) data. It presents taxonomies to categorize the studied techniques based on multiple design dimensions and provides a side-by-side comparison of their properties.There is still a long way to fully address representation bias issues in data. The authors hope that this survey motivates researchers to approach these challenges in the future by observing existing work within their respective domains.",
        "affiliation_name": "University of Illinois at Chicago",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Wild Patterns Reloaded: A Survey of Machine Learning Security against Training Data Poisoning",
        "paper_author": "Cinà A.E.",
        "publication": "ACM Computing Surveys",
        "citied_by": "54",
        "cover_date": "2023-12-31",
        "Abstract": "The success of machine learning is fueled by the increasing availability of computing power and large training datasets. The training data is used to learn new models or update existing ones, assuming that it is sufficiently representative of the data that will be encountered at test time. This assumption is challenged by the threat of poisoning, an attack that manipulates the training data to compromise the model's performance at test time. Although poisoning has been acknowledged as a relevant threat in industry applications, and a variety of different attacks and defenses have been proposed so far, a complete systematization and critical review of the field is still missing. In this survey, we provide a comprehensive systematization of poisoning attacks and defenses in machine learning, reviewing more than 100 papers published in the field in the past 15 years. We start by categorizing the current threat models and attacks and then organize existing defenses accordingly. While we focus mostly on computer-vision applications, we argue that our systematization also encompasses state-of-the-art attacks and defenses for other data modalities. Finally, we discuss existing resources for research in poisoning and shed light on the current limitations and open research questions in this research field.",
        "affiliation_name": "Khoury College of Computer Sciences",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Down the Rabbit Hole: Detecting Online Extremism, Radicalisation, and Politicised Hate Speech",
        "paper_author": "Govers J.",
        "publication": "ACM Computing Surveys",
        "citied_by": "23",
        "cover_date": "2023-12-31",
        "Abstract": "Social media is a modern person's digital voice to project and engage with new ideas and mobilise communities - a power shared with extremists. Given the societal risks of unvetted content-moderating algorithms for Extremism, Radicalisation, and Hate speech (ERH) detection, responsible software engineering must understand the who, what, when, where, and why such models are necessary to protect user safety and free expression. Hence, we propose and examine the unique research field of ERH context mining to unify disjoint studies. Specifically, we evaluate the start-to-finish design process from socio-technical definition-building and dataset collection strategies to technical algorithm design and performance. Our 2015-2021 51-study Systematic Literature Review (SLR) provides the first cross-examination of textual, network, and visual approaches to detecting extremist affiliation, hateful content, and radicalisation towards groups and movements. We identify consensus-driven ERH definitions and propose solutions to existing ideological and geographic biases, particularly due to the lack of research in Oceania/Australasia. Our hybridised investigation on Natural Language Processing, Community Detection, and visual-text models demonstrates the dominating performance of textual transformer-based algorithms. We conclude with vital recommendations for ERH context mining researchers and propose an uptake roadmap with guidelines for researchers, industries, and governments to enable a safer cyberspace.",
        "affiliation_name": "The University of Waikato",
        "affiliation_city": "Hamilton",
        "affiliation_country": "New Zealand"
    },
    {
        "paper_title": "Intelligence at the Extreme Edge: A Survey on Reformable TinyML",
        "paper_author": "Rajapakse V.",
        "publication": "ACM Computing Surveys",
        "citied_by": "45",
        "cover_date": "2023-12-31",
        "Abstract": "Machine Learning (TinyML) is an upsurging research field that proposes to democratize the use of Machine Learning and Deep Learning on highly energy-efficient frugal Microcontroller Units (MCUs). Considering the general assumption that TinyML can only run inference, growing interest in the domain has led to work that makes them reformable, i.e., solutions that permit models to improve once deployed. This work presents a survey on reformable TinyML solutions with the proposal of a novel taxonomy. Here, the suitability of each hierarchical layer for reformability is discussed. Furthermore, we explore the workflow of TinyML and analyze the identified deployment schemes, available tools, and the scarcely available benchmarking tools. Finally, we discuss how reformable TinyML can impact a few selected industrial areas and discuss the challenges, and future directions, and its fusion with next-generation AI.",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Strategic Decisions: Survey, Taxonomy, and Future Directions from Artificial Intelligence Perspective",
        "paper_author": "Wu C.",
        "publication": "ACM Computing Surveys",
        "citied_by": "6",
        "cover_date": "2023-12-31",
        "Abstract": "Strategic Decision-Making is always challenging because it is inherently uncertain, ambiguous, risky, and complex. By contrast to tactical and operational decisions, strategic decisions are decisive, pivotal, and often irreversible, which may result in long-term and significant consequences. A strategic decision-making process usually involves many aspects of inquiry, including sensory perception, deliberative thinking, inquiry-based analysis, meta-learning, and constant interaction with the external world. Many unknowns, unpredictabilities, and environmental constraints will shape every aspect of a strategic decision. Traditionally, this task often relies on intuition, reflective thinking, visionary insights, approximate estimates, and practical wisdom. With recent advances in artificial intelligence/machine learning (AI/ML) technologies, we can leverage AI/ML to support strategic decision-making. However, there is still a substantial gap from an AI perspective due to inadequate models, despite the tremendous progress made. We argue that creating a comprehensive taxonomy of decision frames as a representation space is essential for AI because it could offer surprising insights beyond anyone's imaginary boundary today. Strategic decision-making is the art of possibility. This study develops a systematic taxonomy of decision-making frames that consists of six bases, 18 categorical, and 54 elementary frames. We formulate the model using the inquiry method based on Bloom's taxonomy approach. We aim to lay out the computational foundation that is possible to capture a comprehensive landscape view of a strategic problem. Compared with many traditional models, this novel taxonomy covers irrational, non-rational and rational frames capable of dealing with certainty, uncertainty, complexity, ambiguity, chaos, and ignorance.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better",
        "paper_author": "Menghani G.",
        "publication": "ACM Computing Surveys",
        "citied_by": "203",
        "cover_date": "2023-12-31",
        "Abstract": "Deep learning has revolutionized the fields of computer vision, natural language understanding, speech recognition, information retrieval, and more. However, with the progressive improvements in deep learning models, their number of parameters, latency, and resources required to train, among others, have all increased significantly. Consequently, it has become important to pay attention to these footprint metrics of a model as well, not just its quality. We present and motivate the problem of efficiency in deep learning, followed by a thorough survey of the five core areas of model efficiency (spanning modeling techniques, infrastructure, and hardware) and the seminal work there. We also present an experiment-based guide along with code for practitioners to optimize their model training and deployment. We believe this is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support. It is our hope that this survey would provide readers with the mental model and the necessary understanding of the field to apply generic efficiency techniques to immediately get significant improvements, and also equip them with ideas for further research and experimentation to achieve additional gains.",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning for Software Engineering: A Tertiary Study",
        "paper_author": "Kotti Z.",
        "publication": "ACM Computing Surveys",
        "citied_by": "10",
        "cover_date": "2023-12-31",
        "Abstract": "Machine learning (ML) techniques increase the effectiveness of software engineering (SE) lifecycle activities. We systematically collected, quality-assessed, summarized, and categorized 83 reviews in ML for SE published between 2009 and 2022, covering 6,117 primary studies. The SE areas most tackled with ML are software quality and testing, while human-centered areas appear more challenging for ML. We propose a number of ML for SE research challenges and actions, including conducting further empirical validation and industrial studies on ML, reconsidering deficient SE methods, documenting and automating data collection and pipeline processes, reexamining how industrial practitioners distribute their proprietary data, and implementing incremental ML approaches.",
        "affiliation_name": "Athens University of Economics and Business",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Survey of Hallucination in Natural Language Generation",
        "paper_author": "Ji Z.",
        "publication": "ACM Computing Surveys",
        "citied_by": "1322",
        "cover_date": "2023-12-31",
        "Abstract": "Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation, and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before.In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions, and (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, and machine translation. This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Exploring Neuromorphic Computing Based on Spiking Neural Networks: Algorithms to Hardware",
        "paper_author": "Rathi N.",
        "publication": "ACM Computing Surveys",
        "citied_by": "68",
        "cover_date": "2023-12-31",
        "Abstract": "Neuromorphic Computing, a concept pioneered in the late 1980s, is receiving a lot of attention lately due to its promise of reducing the computational energy, latency, as well as learning complexity in artificial neural networks. Taking inspiration from neuroscience, this interdisciplinary field performs a multi-stack optimization across devices, circuits, and algorithms by providing an end-to-end approach to achieving brain-like efficiency in machine intelligence. On one side, neuromorphic computing introduces a new algorithmic paradigm, known as Spiking Neural Networks (SNNs), which is a significant shift from standard deep learning and transmits information as spikes (\"1\"or \"0\") rather than analog values. This has opened up novel algorithmic research directions to formulate methods to represent data in spike-trains, develop neuron models that can process information over time, design learning algorithms for event-driven dynamical systems, and engineer network architectures amenable to sparse, asynchronous, event-driven computing to achieve lower power consumption. On the other side, a parallel research thrust focuses on development of efficient computing platforms for new algorithms. Standard accelerators that are amenable to deep learning workloads are not particularly suitable to handle processing across multiple timesteps efficiently. To that effect, researchers have designed neuromorphic hardware that rely on event-driven sparse computations as well as efficient matrix operations. While most large-scale neuromorphic systems have been explored based on CMOS technology, recently, Non-Volatile Memory (NVM) technologies show promise toward implementing bio-mimetic functionalities on single devices. In this article, we outline several strides that neuromorphic computing based on spiking neural networks (SNNs) has taken over the recent past, and we present our outlook on the challenges that this field needs to overcome to make the bio-plausibility route a successful one.",
        "affiliation_name": "Yale School of Engineering &amp; Applied Science",
        "affiliation_city": "New Haven",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Combining Machine Learning and Semantic Web: A Systematic Mapping Study",
        "paper_author": "Breit A.",
        "publication": "ACM Computing Surveys",
        "citied_by": "33",
        "cover_date": "2023-12-31",
        "Abstract": "In line with the general trend in artificial intelligence research to create intelligent systems that combine learning and symbolic components, a new sub-area has emerged that focuses on combining Machine Learning components with techniques developed by the Semantic Web community - Semantic Web Machine Learning (SWeML). Due to its rapid growth and impact on several communities in thepast two decades, there is a need to better understand the space of these SWeML Systems, their characteristics, and trends. Yet, surveys that adopt principled and unbiased approaches are missing. To fill this gap, we performed a systematic study and analyzed nearly 500 papers published in the past decade in this area, where we focused on evaluating architectural and application-specific features. Our analysis identified a rapidly growing interest in SWeML Systems, with a high impact on several application domains and tasks. Catalysts for this rapid growth are the increased application of deep learning and knowledge graph technologies. By leveraging the in-depth understanding of this area acquired through this study, a further key contribution of this article is a classification system for SWeML Systems that we publish as ontology.",
        "affiliation_name": "SAP SE",
        "affiliation_city": "Walldorf",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A Comprehensive Review of the State-of-the-Art on Security and Privacy Issues in Healthcare",
        "paper_author": "Martínez A.L.",
        "publication": "ACM Computing Surveys",
        "citied_by": "44",
        "cover_date": "2023-12-31",
        "Abstract": "Currently, healthcare is critical environment in our society, which attracts attention to malicious activities and has caused an important number of damaging attacks. In parallel, the recent advancements in technologies, computing systems, and wireless communications are changing healthcare environment by adding different improvements and complexity to it. This article reviews the current state of the literature and provides a holistic view of cybersecurity in healthcare. With this purpose in mind, the article enumerates the main stakeholders and architecture implemented in the healthcare environment, as well as the main security issues (threats, attacks, etc.) produced in healthcare. In this context, this work maps the threats collected with a widely used knowledge-based framework, MITRE ATT&CK, building a contribution not seen so far. This article also enumerates the security mechanisms created to protect healthcare, identifying the principal research lines addressed in the literature, and listing the available public security-focused datasets used in machine-learning to provide security in the medical domain. To conclude, the research challenges that need to be addressed for future research works in this area are presented.",
        "affiliation_name": "Universidad de Murcia",
        "affiliation_city": "Murcia",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Machine Learning Applications in Internet-of-Drones: Systematic Review, Recent Deployments, and Open Issues",
        "paper_author": "Heidari A.",
        "publication": "ACM Computing Surveys",
        "citied_by": "101",
        "cover_date": "2023-12-31",
        "Abstract": "Deep Learning (DL) and Machine Learning (ML) are effectively utilized in various complicated challenges in healthcare, industry, and academia. The Internet of Drones (IoD) has lately cropped up due to high adjustability to a broad range of unpredictable circumstances. In addition, Unmanned Aerial Vehicles (UAVs) could be utilized efficiently in a multitude of scenarios, including rescue missions and search, farming, mission-critical services, surveillance systems, and so on, owing to technical and realistic benefits such as low movement, the capacity to lengthen wireless coverage zones, and the ability to attain places unreachable to human beings. In many studies, IoD and UAV are utilized interchangeably. Besides, drones enhance the efficiency aspects of various network topologies, including delay, throughput, interconnectivity, and dependability. Nonetheless, the deployment of drone systems raises various challenges relating to the inherent unpredictability of the wireless medium, the high mobility degrees, and the battery life that could result in rapid topological changes. In this paper, the IoD is originally explained in terms of potential applications and comparative operational scenarios. Then, we classify ML in the IoD-UAV world according to its applications, including resource management, surveillance and monitoring, object detection, power control, energy management, mobility management, and security management. This research aims to supply the readers with a better understanding of (1) the fundamentals of IoD/UAV, (2) the most recent developments and breakthroughs in this field, (3) the benefits and drawbacks of existing methods, and (4) areas that need further investigation and consideration. The results suggest that the Convolutional Neural Networks (CNN) method is the most often employed ML method in publications. According to research, most papers are on resource and mobility management. Most articles have focused on enhancing only one parameter, with the accuracy parameter receiving the most attention. Also, Python is the most commonly used language in papers, accounting for 90% of the time. Also, in 2021, it has the most papers published.",
        "affiliation_name": "Nişantaşı Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "An Improved K-Nearest Neighbor Algorithm Method Using Finite Boreholes for Predicting Full-Area Geological Features",
        "paper_author": "Zhu J.",
        "publication": "Tunnel Construction",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "The original drilling data collected cannot be deeply excavated and utilized by traditional modeling methods. Therefore, an improved K-nearest neighbor(KNN) algorithm is improved. This is a spatial adaptive interpolation fitting algorithm that is developed based on the original KNN algorithm. It incorporates automatic selection of k-values based on different geological layers and utilizes the original geological data for further analysis. The data from a railway investigation project is selected as a data source to put into the improved KNN algorithm model, successfully obtaining the characteristic k-values of each stratum in the site and accomplishing the geological modeling. By comparing the actual borehole and the borehole predicted by original KNN and improved KNN, it is found that the improved KNN algorithm is more accurate in predicting the thin layers, and the overall accuracy is higher. Compared with the original KNN algorithm and other common classification algorithms, the improved algorithm can obtain better stratum prediction results, especially for the thin stratum, and obtain higher precision and accuracy, which can better guide the prediction of underground 3D space.",
        "affiliation_name": "China Railway Eryuan Engineering Group Co. Ltd.",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning-based design and optimization of high-speed circuits",
        "paper_author": "Melikyan V.",
        "publication": "Machine Learning-based Design and Optimization of High-Speed Circuits",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "This book describes machine learning-based new principles, methods of design and optimization of high-speed integrated circuits, included in one electronic system, which can exchange information between each other up to 128/256/512 Gbps speed. The efficiency of methods has been proven and is described on the examples of practical designs. This will enable readers to use them in similar electronic system designs. The author demonstrates newly developed principles and methods to accelerate communication between ICs, working in non-standard operating conditions, considering signal deviation compensation with linearity self-calibration. The observed circuit types also include but are not limited to mixed-signal, high performance heterogeneous integrated circuits as well as digital cores.",
        "affiliation_name": "Synopsys Incorporated",
        "affiliation_city": "Sunnyvale",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Resonant Frequency Modelling of Microstrip Antennas by Consensus Network and Student’s-T Process",
        "paper_author": "Ren X.",
        "publication": "Applied Computational Electromagnetics Society Journal",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "When modelling and optimizing antennas by machine learning (ML) methods, it is the most time-consuming to obtain the training samples with labels from full-wave electromagnetic simulation software. To address the problem, this paper proposes an optimization method based on the consensus results of multiple independently trained Student’s-T Process (STP) with excellent generalization ability. First, the STP is introduced as a surrogate model to replace the traditional Gaussian Process (GP), and the hyperparameters of the STP model are optimized. Afterwards, a consistency algorithm is used to process the results of multiple independently trained STPs to improve the reliability of the results. Furthermore, an aggregation algorithm is adopted to reduce the error obtained in the consistency results if it is greater than the consistency flag. The effectiveness of the proposed model is demonstrated through experiments with rectangular microstrip antennas (RMSA) and circular microstrip antennas (CMSA). The experimental results show that the use of multiple independently trained STPs can accelerate the antenna design optimization process, and improve modelling accuracy while maintaining modelling efficiency, which has high generalization ability.",
        "affiliation_name": "Guangzhou Maritime University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research on smart classroom learning paths and effect testing and evaluation technology based on machine learning algorithm",
        "paper_author": "Yingchuan H.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "With the maturity and popularization of artificial intelligence technology, all fields in the country have begun to transform towards intelligent and smart applications. This paper establishes a smart classroom learning path based on machine learning based on bottleneck issues such as the difficulty in systematically, completely, and accurately quantifying the subject ability objectives in the construction of smart learning models, the difficulty in obtaining learning behavior data, and the lack of training in learners' problem-solving abilities and creative thinking abilities. , and finally combined with the algorithm model, this result was applied in specific classrooms. Finally, through statistical analysis, the average accuracy reached more than 85%. It provides a foundation for the application of artificial intelligence in the field of education and the development of smart learning, and provides a reference for subsequent research on smart learning models.",
        "affiliation_name": "Wuhan Business University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Identification of Factors Influencing Nighttime Economy Based on Machine Learning Methods",
        "paper_author": "Huo J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-30",
        "Abstract": "In today's relatively weak global economic environment, the nighttime economy, as an important part of urban economic life, can greatly affect the development level of cities. Therefore, studying the influencing factors of the nighttime economy is conducive to promoting its development and driving the development of cities. This article selects the nighttime light data of VIIRS to represent the level of nighttime economic development. Three machine learning methods, namely random forest, support vector machine, and XGBoost, are used to regress and predict the level of nighttime economic development with its influencing factors in 258 cities across the country. Finally, the model with the best regression effect is selected, and the SHAP explanatory analysis method is used to further explain the level of influence of each factor. Conclusion: The economic level and the development level of urban service industry are closely related to the development of urban night economy; large scale industrial enterprises and population density are not the decisive factors for nighttime economic development; each city should discover local characteristic resources to further expand the development space of night economy.",
        "affiliation_name": "University of International Business and Economics",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Methodological study of quantitative immunochromatographic detection based on optimised flow measurement",
        "paper_author": "Zhang S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "Flow measurement immunochromatography has been widely used in the field of medical testing due to its advantages of simplicity, speed, convenience and low cost. The combination of machine vision image processing technology and test strip technology has become a research hotspot for rapid quantitative detection in recent years. This paper reviews the research progress of flow measurement immunochromatography to improve the accuracy in the past five years, evaluates the advantages and disadvantages of flow measurement immunochromatography detection from the perspectives of test strip labelling methods, image segmentation process and deep learning algorithms, and analyses its future development direction.",
        "affiliation_name": "Guilin University of Technology",
        "affiliation_city": "Guilin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Agricultural Technology Knowledge Intelligent Question-Answering System Based on Large Language Model",
        "paper_author": "Wang T.",
        "publication": "Smart Agriculture",
        "citied_by": "5",
        "cover_date": "2023-12-30",
        "Abstract": "[Objective] The rural revitalization strategy presents novel requisites for the extension of agricultural technology. However, the conventional method encounters the issue of a contradiction between supply and demand. Therefore, there is a need for further innovation in the supply form of agricultural knowledge. Recent advancements in artificial intelligence technologies, such as deep learning and large-scale neural networks, particularly the advent of large language models (LLMs), render anthropomorphic and intelligent agricultural technology extension feasible. With the agricultural technology knowledge service of fruit and vegetable as the demand orientation, the intelligent agricultural technology question answering system was built in this research based on LLM, providing agricultural technology extension services, including guidance on new agricultural knowledge and question-and-answer sessions. This facilitates farmers in accessing high-quality agricultural knowledge at their convenience. [Methods] Through an analysis of the demands of strawberry farmers, the agricultural technology knowledge related to strawberry cultivation was categorized into six themes: basic production knowledge, variety screening, interplanting knowledge, pest diagnosis and control, disease diagnosis and control, and drug damage diagnosis and control. Considering the current situation of agricultural technology, two primary tasks were formulated: named entity recognition and question answering related to agricultural knowledge. A training corpus comprising entity type annotations and question-answer pairs was constructed using a combination of automatic machine annotation and manual annotation, ensuring a small yet high-quality sample. After comparing four existing Large Language Models (Baichuan2-13B-Chat, ChatGLM2-6B, Llama 2-13B-Chat, and ChatGPT), the model exhibiting the best performance was chosen as the base LLM to develop the intelligent question-answering system for agricultural technology knowledge. Utilizing a high-quality corpus, pre-training of a Large Language Model and the fine-tuning method, a deep neural network with semantic analysis, context association, and content generation capabilities was trained. This model served as a Large Language Model for named entity recognition and question answering of agricultural knowledge, adaptable to various downstream tasks. For the task of named entity recognition, the fine-tuning method of Lora was employed, fine-tuning only essential parameters to expedite model training and enhance performance. Regarding the question-answering task, the Prompt-tuning method was used to fine-tune the Large Language Model, where adjustments were made based on the generated content of the model, achieving iterative optimization. Model performance optimization was conducted from two perspectives: data and model design. In terms of data, redundant or unclear data was manually removed from the labeled corpus. In terms of the model, a strategy based on retrieval enhancement generation technology was employed to deepen the understanding of agricultural knowledge in the Large Language Model and maintain real-time synchronization of knowledge, alleviating the problem of LLM hallucination. Drawing upon the constructed Large Language Model, an intelligent question-answering system was developed for agricultural technology knowledge. This system demonstrates the capability to generate high-precision and unambiguous answers, while also supporting the functionalities of multi-round question answering and retrieval of information sources. [Results and Discussions] Accuracy rate and recall rate served as indicators to evaluate the named entity recognition task performance of the Large Language Models. The results indicated that the performance of Large Language Models was closely related to factors such as model structure, the scale of the labeled corpus, and the number of entity types. After fine-tuning, the ChatGLM Large Language Model demonstrated the highest accuracy and recall rate. With the same number of entity types, a higher number of annotated corpora resulted in a higher accuracy rate. Fine-tuning had different effects on different models, and overall, it improved the average accuracy of all models under different knowledge topics, with ChatGLM, Llama, and Baichuan values all surpassing 85%. The average recall rate saw limited increase, and in some cases, it was even lower than the values before fine-tuning. Assessing the question-answering task of Large Language Models using hallucination rate and semantic similarity as indicators, data optimization and retrieval enhancement generation techniques effectively reduced the hallucination rate by 10% to 40% and improved semantic similarity by more than 15%. These optimizations significantly enhanced the generated content of the models in terms of correctness, logic, and comprehensiveness. [Conclusion] The pre-trained Large Language Model of ChatGLM exhibited superior performance in named entity recognition and question answering tasks in the agricultural field. Fine-tuning pre-trained Large Language Models for downstream tasks and optimizing based on retrieval enhancement generation technology mitigated the problem of language hallucination, markedly improving model performance. Large Language Model technology has the potential to innovate agricultural technology knowledge service modes and optimize agricultural knowledge extension. This can effectively reduce the time cost for farmers to obtain high-quality and effective knowledge, guiding more farmers towards agricultural technology innovation and transformation. However, due to challenges such as unstable performance, further research is needed to explore optimization methods for Large Language Models and their application in specific scenarios.",
        "affiliation_name": "Ministry of Agriculture of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Agricultural Robots: Technology Progress, Challenges and Trends",
        "paper_author": "Zhao C.",
        "publication": "Smart Agriculture",
        "citied_by": "20",
        "cover_date": "2023-12-30",
        "Abstract": "[Significance] Autonomous and intelligent agricultural machinery, characterized by green intelligence, energy efficiency, and reduced emissions, as well as high intelligence and man-machine collaboration, will serve as the driving force behind global agricultural technology advancements and the transformation of production methods in the context of smart agriculture development. Agricultural robots, which utilize intelligent control and information technology, have the unique advantage of replacing manual labor. They occupy the strategic commanding heights and competitive focus of global agricultural equipment and are also one of the key development directions for accelerating the construction of China's agricultural power. World agricultural powers and China have incorporated the research, development, manufacturing, and promotion of agricultural robots into their national strategies, respectively strengthening the agricultural robot policy and planning layout based on their own agricultural development characteristics, thus driving the agricultural robot industry into a stable growth period. [Progress] This paper firstly delves into the concept and defining features of agricultural robots, alongside an exploration of the global agricultural robot development policy and strategic planning blueprint. Furthermore, sheds light on the growth and development of the global agricultural robotics industry; Then proceeds to analyze the industrial backdrop, cutting-edge advancements, developmental challenges, and crucial technology aspects of three representative agricultural robots, including farmland robots, orchard picking robots, and indoor vegetable production robots. Finally, summarizes the disparity between Chinese agricultural robots and their foreign counterparts in terms of advanced technologies. (1) An agricultural robot is a multi-degree-of-freedom autonomous operating equipment that possesses accurate perception, autonomous decision-making, intelligent control, and automatic execution capabilities specifically designed for agricultural environments. When combined with artificial intelligence, big data, cloud computing, and the Internet of Things, agricultural robots form an agricultural robot application system. This system has relatively mature applications in key processes such as field planting, fertilization, pest control, yield estimation, inspection, harvesting, grafting, pruning, inspection, harvesting, transportation, and livestock and poultry breeding feeding, inspection, disinfection, and milking. Globally, agricultural robots, represented by plant protection robots, have entered the industrial application phase and are gradually realizing commercialization with vast market potential. (2) Compared to traditional agricultural machinery and equipment, agricultural robots possess advantages in performing hazardous tasks, executing batch repetitive work, managing complex field operations, and livestock breeding. In contrast to industrial robots, agricultural robots face technical challenges in three aspects. Firstly, the complexity and unstructured nature of the operating environment. Secondly, the flexibility, mobility, and commoditization of the operation object. Thirdly, the high level of technology and investment required. (3) Given the increasing demand for unmanned and less manned operations in farmland production, China's agricultural robot research, development, and application have started late and progressed slowly. The existing agricultural operation equipment still has a significant gap from achieving precision operation, digital perception, intelligent management, and intelligent decision-making. The comprehensive performance of domestic products lags behind foreign advanced counterparts, indicating that there is still a long way to go for industrial development and application. Firstly, the current agricultural robots predominantly utilize single actuators and operate as single machines, with the development of multi-arm cooperative robots just emerging. Most of these robots primarily engage in rigid operations, exhibiting limited flexibility, adaptability, and functionality. Secondly, the perception of multi-source environments in agricultural settings, as well as the autonomous operation of agricultural robot equipment, relies heavily on human input. Thirdly, the progress of new teaching methods and technologies for human-computer natural interaction is rather slow. Lastly, the development of operational infrastructure is insufficient, resulting in a relatively low degree of \"mechanization\". [Conclusions and Prospects] The paper anticipates the opportunities that arise from the rapid growth of the agricultural robotics industry in response to the escalating global shortage of agricultural labor. It outlines the emerging trends in agricultural robot technology, including autonomous navigation, self-learning, real-time monitoring, and operation control. In the future, the path planning and navigation information perception of agricultural robot autonomy are expected to become more refined. Furthermore, improvements in autonomous learning and cross-scenario operation performance will be achieved. The development of real-time operation monitoring of agricultural robots through digital twinning will also progress. Additionally, cloud-based management and control of agricultural robots for comprehensive operations will experience significant growth. Steady advancements will be made in the innovation and integration of agricultural machinery and techniques.",
        "affiliation_name": "Beijing Academy of Agriculture and Forestry Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Individual Tree Skeleton Extraction and Crown Prediction Method of Winter Kiwifruit Trees",
        "paper_author": "Li Z.",
        "publication": "Smart Agriculture",
        "citied_by": "2",
        "cover_date": "2023-12-30",
        "Abstract": "[Objective] The proliferation of kiwifruit trees severely overlaps, resulting in a complex canopy structure, rendering it impossible to extract their skeletons or predict their canopies using conventional methods. The objective of this research is to propose a crown segmentation method that integrates skeleton information by optimizing image processing algorithms and developing a new scheme for fusing winter and summer information. In cases where fruit trees are densely distributed, achieving accurate segmentation of fruit tree canopies in orchard drone images can efficiently and cost-effectively obtain canopy information, providing a foundation for determining summer kiwifruit growth size, spatial distribution, and other data. Furthermore, it facilitates the automation and intelligent development of orchard management. [Methods] The 4- to 8-year-old kiwifruit trees were chosen and remote sensing images of winter and summer via unmanned aerial vehicles were obtain as the primary analysis visuals. To tackle the challenge of branch extraction in winter remote sensing images, a convolutional attention mechanism was integrated into the PSP-Net network, along with a joint attention loss function. This was designed to boost the network's focus on branches, enhance the recognition and targeting capabilities of the target area, and ultimately improve the accuracy of semantic segmentation for fruit tree branches.For the generation of the skeleton, digital image processing technology was employed for screening. The discrete information of tree branches was transformed into the skeleton data of a single fruit tree using growth seed points. Subsequently, the semantic segmentation results were optimized through mathematical morphology calculations, enabling smooth connection of the branches. In response to the issue of single tree canopy segmentation in summer, the growth characteristics of kiwifruit trees were taken into account, utilizing the outward expansion of branches growing from the trunk.The growth of tree branches was simulated by using morphological expansion to predict the summer canopy. The canopy prediction results were analyzed under different operators and parameters, and the appropriate expansion operators along with their corresponding operation lengths were selected. The skeleton of a single tree was extracted from summer images. By combining deep learning with mathematical morphology methods through the above steps, the optimized single tree skeleton was used as a prior condition to achieve canopy segmentation. [Results and Discussions] In comparison to traditional methods, the accuracy of extracting kiwifruit tree canopy information images at each stage of the process has been significantly enhanced. The enhanced PSP Net was evaluated using three primary regression metrics: pixel accuracy (PA), mean intersection over union ratio (MIoU), and weighted F1 Score (WF1). The PA, MIoU and WF1 of the improved PSP-Net were 95.84%, 95.76% and 95.69% respectively, which were increased by 12.30%, 22.22% and 17.96% compared with U-Net, and 21.39%, 21.51% and 18.12% compared with traditional PSP-Net, respectively. By implementing this approach, the skeleton extraction function for a single fruit tree was realized, with the predicted PA of the canopy surpassing 95%, an MIoU value of 95.76%, and a WF1 of canopy segmentation approximately at 94.07%.The average segmentation precision of the approach surpassed 95%, noticeably surpassing the original skeleton's 81.5%. The average conformity between the predicted skeleton and the actual summer skeleton stand at 87%, showcasing the method's strong prediction performance. Compared with the original skeleton, the PA, MIoU and WF1 of the optimized skeleton increased by 13.2%, 10.9% and 18.4%, respectively. The continuity of the predicted skeleton had been optimized, resulting in a significant improvement of the canopy segmentation index. The solution effectively addresses the issue of semantic segmentation fracture, and a single tree canopy segmentation scheme that incorporates skeleton information could effectively tackle the problem of single fruit tree canopy segmentation in complex field environments. This provided a novel technical solution for efficient and low-cost orchard fine management. [Conclusions] A method for extracting individual kiwifruit plant skeletons and predicting canopies based on skeleton information was proposed. This demonstrates the enormous potential of drone remote sensing images for fine orchard management from the perspectives of method innovation, data collection, and problem solving. Compared with manual statistics, the overall efficiency and accuracy of kiwifruit skeleton extraction and crown prediction have significantly improved, effectively solving the problem of case segmentation in the crown segmentation process.The issue of semantic segmentation fragmentation has been effectively addressed, resulting in the development of a single tree canopy segmentation method that incorporates skeleton information. This approach can effectively tackle the challenges of single fruit tree canopy segmentation in complex field environments, thereby offering a novel technical solution for efficient and cost-effective orchard fine management. While the research is primarily centered on kiwifruit trees, the methodology possesses strong universality. With appropriate modifications, it can be utilized to monitor canopy changes in other fruit trees, thereby showcasing vast application potential.",
        "affiliation_name": "Northwest A&amp;F University",
        "affiliation_city": "Yangling",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Kernel-Induced Matriarch Path Tracking Elephant Herding Optimization Technique for Identification and Classification of Cancer Types Using Support Vector Machines",
        "paper_author": "Senbagamalar L.",
        "publication": "International Journal of Pattern Recognition and Artificial Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "Abnormal cells in the human body that keep on mutating are termed to be cancer in medical terms. There are multiple types of cancer identified in human beings. It is very much essential to identify and classify the type of cancer in its earlier stage. This objective can be satisfied by artificial intelligence which has a subfield of machine learning to create a generalized model that could identify and classify cancer with increased performance. To perform the identification and classification of various cancer types, in this paper, two techniques are adopted. The optimized feature set computation was done using the Kernel-Induced Matriarch path tracking Elephant Herding Optimization (KIM-EHO) and the classification for the given samples was done using the Support Vector Machines (SVM). The proposed techniques are implemented with the benchmark datasets and the results proved that the proposed methodologies outperformed the existing methods in terms of accuracy, specificity, sensitivity and time complexity.",
        "affiliation_name": "Karpagam College of Engineering",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Artificial intelligence and customers’ intention to use robo-advisory in banking services",
        "paper_author": "Piotrowski D.",
        "publication": "Equilibrium. Quarterly Journal of Economics and Economic Policy",
        "citied_by": "13",
        "cover_date": "2023-12-30",
        "Abstract": "Research background:Robo-advisory is a modern and rapidly developing area of implementing artificial intelligence to support customer decision-making. The current significance of robo-advisory to the financial sector is minor or marginal, and boils down to formulating recommendations and implementing investment strategies. However, the ongoing digital transformation of the economy leads us to believe that in the near future this technology will also be much more widely used with banking products. This makes it necessary for banks and other financial institutions to be prepared to offer this service to their customers. Purpose of the article: The aim of this paper is to identify factors significantly influencing bank customers’ intention to use robo-advisory. Identification of robo-advisory acceptance factors may increase the effectiveness of banks' promotional activities regarding such a service. Methods: Empirical data was obtained through a survey conducted on a representative sample of 911 Polish respondents aged 18–65. Using a multilevel ordered logit model and methods based on machine learning algorithms, the authors identified variables relating to the demographic and socio-economic characteristics, behaviors, and attitudes of consumers that primarily determine respondents’ adoption of robo-advisory. Findings & value added: The results of the study indicate that the variables regarding the respondents' attitude towards the use of artificial intelligence in banking services turned out to be the most important from the point of view of acceptance of robo-advisory. Next in terms of importance were the variables presenting respondents' assessments of the ethics of financial services. An important finding is that experience in using basic financial services is not a significant factor when accepting robo-advisory. From the practical perspective, the article provides recommendations on the use of artificial intelligence technology in finance and ethical aspects of the provision of such services by banks.",
        "affiliation_name": "Uniwersytet Mikołaja Kopernika w Toruniu",
        "affiliation_city": "Torun",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Optimizing Neural Networks for Academic Performance Classification Using Feature Selection and Resampling Approach",
        "paper_author": "Supriyadi D.",
        "publication": "Mendel",
        "citied_by": "1",
        "cover_date": "2023-12-30",
        "Abstract": "The features present in large datasets significantly affect the performance of machine learning models. Redundant and irrelevant features will be rejected and cause a decrease in machine learning model performance. This paper proposes HyFeS-ROS-ANN: Hybrid Feature Selection and Resampling combination method for binary classification using artificial neural network multilayer perceptron (MLP). The first stage of this approach is to use a combination of two feature selection methods to select essential features that are highly correlated with model performance. The second stage of this approach is to use a combination of resampling methods to handle unbalanced data classes. Both approaches are applied to the academic performance classification model using the MLP neural network. This research dataset is obtained using three-dimensional (3D) frameworks such as the Big Five Personality to determine the Personality that affects academic performance from the student dimension, the Family Influence Scale (FIS), which measures factors that affect academic performance from the family dimension, and Higher Education Institutions Service Quality (HEISQUAL) to measure service quality and its influence on academic performance from the Education institution dimension. Previous research shows that the CoR-ANN algorithm has a model accuracy rate of 94%. The research results based on the dataset show that our proposed method can improve accuracy by selecting more relevant and essential features in improving model performance. The results show that the features are reduced from 135 to 108, while the HyFS-ROS-ANN model for binary classification accuracy increases to 100%.",
        "affiliation_name": "Telkom University",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Artificial neural network and decision tree-based modelling of non-prosperity of companies",
        "paper_author": "Durica M.",
        "publication": "Equilibrium. Quarterly Journal of Economics and Economic Policy",
        "citied_by": "6",
        "cover_date": "2023-12-30",
        "Abstract": "Research background:Financial distress or non-prosperity prediction has been a widely discussed topic for several decades. Early detection of impending financial problems of the company is crucial for effective risk management and important for all entities involved in the company’s business activities. In this way, it is possible to take the actions in the management of the company and eliminate possible undesirable consequences of these problems. Purpose of the article: This article aims to innovate financial distress prediction through the creation of individual models and ensembles, combining machine learning techniques such as decision trees and neural networks. These models are developed using real data. Beyond serving as an autonomous and universal tool especially useful in the Slovak economic conditions, these models can also represent a benchmark for Central European economies confronting similar economic dynamics. Methods: The prediction models are created using a dataset consisting of more than 20 financial ratios of more than 19 thousand real companies. Partial models are created employing machine learning algorithms, namely decision trees and neural networks. Finally, all models are compared based on a wide range of selected performance metrics. During this process, we strictly use a data mining methodology CRISP-DM. Findings & value added: The research contributes to the evolution of financial prediction and reveals the effectiveness of ensemble modelling in predicting financial distress, achieving an overall predictive ability of nearly 90 percent. Beyond its Slovak origins, this study provides a framework for early financial distress prediction. Although the models are created for diverse industries within the Slovak economy, they could also be useful beyond national borders. Moreover, the CRISP-DM methodological framework enables its adaptability for companies in other countries.",
        "affiliation_name": "University of Žilina",
        "affiliation_city": "Zilina",
        "affiliation_country": "Slovakia"
    },
    {
        "paper_title": "A UWB NLOS identification method under pedestrian occlusion",
        "paper_author": "Wu T.",
        "publication": "Chinese Journal on Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "Ultrawideband (UWB) is a hot technology for indoor positioning with large bandwidth, strong an-ti-interference ability, and high multipath resolution capacity. However, due to the complex indoor environment, UWB signal propagation will inevitably be blocked, resulting in non-line-of-sight (NLOS) propagation, which greatly reduces the accuracy of UWB positioning. Therefore, identifying NLOS signals accurately and discarding or correcting them are important to alleviate the problem of the decline in positioning accuracy. The majority of present NLOS identification work focuses on scenes with building structures such as walls. Further discussion is needed for scenes obscured by pe-destrians. Since the impact of human obstacles on the signals is more complex and cannot be ignored, the NLOS identification under pedestrian occlusion was studied. By comparing a variety of machine learning methods and signal feature combinations, the random forest method based on the three-dimensional features of the first path signal power, the re-ceived signal power, and the measured distance was proposed. These features with fewer dimensions and easy extraction were used to achieve a high identification percentage for NLOS. The experimental results based on the measured data of different devices show that the NLOS identification accuracy based on the proposed method reaches 99.05%, 99.32% and 98.81% respectively.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Innovations in robotic platforms for uniportal thoracic surgery",
        "paper_author": "Tam J.K.C.",
        "publication": "Journal of Thoracic Disease",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "NA",
        "affiliation_name": "National University Health System",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Mechanistic analysis of Th2-type inflammatory factors in asthma",
        "paper_author": "Qin Y.",
        "publication": "Journal of Thoracic Disease",
        "citied_by": "2",
        "cover_date": "2023-12-30",
        "Abstract": "Background: The main pathological features of asthma are widespread chronic inflammation of the airways and restricted ventilation due to airway remodeling, which involves changes in a range of regulatory pathways. While the role of T helper type 2 (Th2)-related inflammatory factors in this process is known, the detailed understanding of how genes affect protein functions during airway remodeling is still lacking. This study aims to fill this knowledge gap by integrating gene expression data and protein function analysis, providing new scientific insights for a deeper understanding of the mechanisms of airway remodeling and for further development of asthma treatment strategies. Methods: In this study, the mechanism of Th2-related inflammatory factors in tracheal remodeling was studied through differentially expressed gene (DEG) screening, enrichment analysis, protein-protein interaction (PPI) network construction, machine learning, and the construction of a line graph model. Results: Our study revealed that S100A14, KRT6A, S100A2, ABCA13, UBE2C, RASSF10, PSCA, PLAT, and TIMP1 may be the key genes for airway remodeling; epithelial-mesenchymal transition (EMT)-related genes GEM, TPM4, SLC6A8, and SNTB1 may be involved in airway remodeling due to asthma; IL6 may affect the occurrence of airway remodeling by binding to UBE2C protein or by regulating GEM genes, respectively; IL6 and IL9 may affect the occurrence of airway remodeling by regulating the downstream Toll-like receptor (TLR) signaling pathway and thus IL6 and IL9 may influence the occurrence of tracheal remodeling by regulating downstream TLR signaling pathways. Conclusions: This study further mined the asthma gene microarray database through bioinformatics analysis and identified key genes and important pathways affecting airway remodeling in asthma patients, providing new ideas to uncover the mechanism of airway remodeling due to asthma and then seek new therapeutic targets.",
        "affiliation_name": "Hainan Medical University",
        "affiliation_city": "Haikou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Rapid evaluation of Ziziphi Spinosae Semen and its adulterants based on the combination of FT-NIR and multivariate algorithms",
        "paper_author": "Li M.x.",
        "publication": "Food Chemistry: X",
        "citied_by": "10",
        "cover_date": "2023-12-30",
        "Abstract": "Ziziphi Spinosae Semen (ZSS) is a valued seed renowned for its sedative and sleep-enhancing properties. However, the price increase has been accompanied by adulteration. In this study, chromaticity analysis and Fourier transform near-infrared (FT-NIR) combined with multivariate algorithms were employed to identify the adulteration and quantitatively predict the adulteration ratio. The findings suggested that the utilization of chromaticity extractor was insufficient for identification of adulteration ratio. The raw spectrum of ZMS and HAS adulterants extracted by FT-NIR was processed by SNV + CARS and 1d + SG + ICO respectively, the average accuracy of machine learning classification model was improved from 77.06 % to 97.58 %. Furthermore, the R2 values of the calibration and prediction set of the two quantitative prediction regression models of adulteration ratio are greater than 0.99, demonstrating excellent linearity and predictive accuracy. Overall, this study demonstrated that FT-NIR combined with multivariate algorithms provided a significant approach to addressing the growing issue of ZSS adulteration.",
        "affiliation_name": "Nanjing University of Chinese Medicine",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Atomic insights into device-scale phase-change memory materials using machine learning potential",
        "paper_author": "Wang G.",
        "publication": "Science Bulletin",
        "citied_by": "4",
        "cover_date": "2023-12-30",
        "Abstract": "NA",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Waves in a forest: a random forest classifier to distinguish between gravitational waves and detector glitches",
        "paper_author": "Shah N.",
        "publication": "Classical and Quantum Gravity",
        "citied_by": "1",
        "cover_date": "2023-12-30",
        "Abstract": "The LIGO-Virgo-KAGRA (LVK) network of gravitational-wave (GW) detectors have observed many tens of compact binary mergers to date. Transient, non-Gaussian noise excursions, known as ‘glitches’, can impact signal detection in various ways. They can imitate true signals as well as reduce the confidence of real signals. In this work, we introduce a novel statistical tool to distinguish astrophysical signals from glitches, using their inferred source parameter posterior distributions as a feature set. By modelling both simulated GW signals and real detector glitches with a gravitational waveform model, we obtain a diverse set of posteriors which are used to train a random forest classifier. We show that random forests can identify differences in the posterior distributions for signals and glitches, aggregating these differences to tell apart signals from common glitch types with high accuracy of over 93%. We conclude with a discussion on the regions of parameter space where the classifier is prone to making misclassifications, and the different ways of implementing this tool into LVK analysis pipelines.",
        "affiliation_name": "Indian Institute of Science Education and Research Pune",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Tea quality estimation based on multi-source information from leaf and soil using machine learning algorithm",
        "paper_author": "Yang B.",
        "publication": "Food Chemistry: X",
        "citied_by": "2",
        "cover_date": "2023-12-30",
        "Abstract": "Mineral nutrients play a significant role in influencing the quality of tea. In order to detect the quantitative relationships between tea quality and mineral elements from the soil and tea plant, samples of soil and tea leaves from 'Baiyeyihao' and 'Huangjinya' cultivars were collected from 160 tea plantations, and these were used to determine 16 types of soil mineral elements, 16 leaf nutrient elements, and 10 key tea quality compositions. Three predictive models including linear regression, multiple linear regression (MLR) and random forest (RF) were applied to predict the main constituents of tea quality. The usage of mineral elements in the soil and tea leaves improved the estimation accuracy of tea quality compositions, the RF performed best for EGCG (R2 = 0.67–0.77), amino acid (R2 = 0.61–0.88), tea polyphenols (R2 = 0.68–0.77) and caffeine (R2 = 0.59–0.68), while the MLR performed well for predicting the soluble sugars (R2 = 0.54–0.84). The multi-source information demonstrated a superior accuracy in predicting the biochemical components of tea when compared to individual mineral elements.",
        "affiliation_name": "Nanjing Agricultural University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sample size and predictive performance of machine learning methods with survival data: A simulation study",
        "paper_author": "Infante G.",
        "publication": "Statistics in Medicine",
        "citied_by": "11",
        "cover_date": "2023-12-30",
        "Abstract": "Prediction models are increasingly developed and used in diagnostic and prognostic studies, where the use of machine learning (ML) methods is becoming more and more popular over traditional regression techniques. For survival outcomes the Cox proportional hazards model is generally used and it has been proven to achieve good prediction performances with few strong covariates. The possibility to improve the model performance by including nonlinearities, covariate interactions and time-varying effects while controlling for overfitting must be carefully considered during the model building phase. On the other hand, ML techniques are able to learn complexities from data at the cost of hyper-parameter tuning and interpretability. One aspect of special interest is the sample size needed for developing a survival prediction model. While there is guidance when using traditional statistical models, the same does not apply when using ML techniques. This work develops a time-to-event simulation framework to evaluate performances of Cox regression compared, among others, to tuned random survival forest, gradient boosting, and neural networks at varying sample sizes. Simulations were based on replications of subjects from publicly available databases, where event times were simulated according to a Cox model with nonlinearities on continuous variables and time-varying effects and on the SEER registry data.",
        "affiliation_name": "Gruppo Ospedaliero San Donato",
        "affiliation_city": "San Donato Milanese",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Detection of Yucca gloriosa in Mediterranean coastal dunes: A comparative analysis of field-based sampling, human interpretation of UAV imagery and deep learning to develop an effective tool for controlling invasive plants",
        "paper_author": "Massetti L.",
        "publication": "Regional Studies in Marine Science",
        "citied_by": "3",
        "cover_date": "2023-12-30",
        "Abstract": "Using UAV imagery is a powerful method for monitoring invasive alien plant species (IAPs), particularly when combined with automatic image analysis conducted by artificial intelligence. To this end, we conducted a pilot study on Yucca gloriosa, an invasive species of coastal dunes spread in central Italy. Specifically, we assessed the agreement in quantifying Y. gloriosa cover between field-based sampling and human visual screening of UAV images captured at different altitudes. Additionally, we examined the concordance among different operators both before and after a training procedure, comparing a simpler and quicker approach (referred to as the “envelope” method) against a seemingly more precise but time-consuming method (referred to as the “leaf by leaf” method). In our current study, we discovered a good concordance not only between operators and field sampling but also among operators, particularly when using the “envelope” method. Furthermore, we assessed the performance of deep learning in identifying Y. gloriosa plants in UAV images compared to visual identification by human operators, achieving an overall accuracy of 96 % for images taken at an altitude of 35 m. Our findings suggest that UAV imagery may serve as a valid alternative to field-based sampling for monitoring IAPs, especially when dealing with plants like Y. gloriosa, which have distinctive morphological characteristics that facilitate identification. Consequently, mapping Y. gloriosa on Mediterranean coastal dunes can be effectively accomplished using UAV images, even though an automated machine-based approach, thereby expediting and enhancing the reliability of alien species monitoring and management.",
        "affiliation_name": "Università di Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Clustering and assessment of precipitation climates using satellite precipitation products and improved machine learning precipitation models",
        "paper_author": "Nosratpour R.",
        "publication": "International Journal of Climatology",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "A deep understanding of the different features of various rainfall regimes is essential for water resources management and meteorological studies. Due to the extensive spatial coverage, satellite precipitation products have afforded researchers an excellent opportunity to investigate various precipitation climates. This study employs cutting-edge satellite precipitation data and improved modelling techniques to innovatively investigate Iran's diverse precipitation climates. By harnessing the power of machine learning (ML), precipitation models were developed that significantly improved the accuracy of satellite-based precipitation estimates. The complexities of Iran's precipitation climates were investigated by combining satellite data and ML models with the K-means++ algorithm. Furthermore, the Mann–Kendall test was employed to scrutinize potential trends in precipitation frequency across varying months and climates to enrich the current body of knowledge further. In addition, a range of probability distribution functions was fitted to the ML precipitation estimates, evaluating the outcomes with the Akaike information criterion (AIC). The results show that both artificial neural network (ANN) and random forest (RF) models improved satellite product correlation results, increasing them from 0.84 to an outstanding 0.93. Moreover, the Mann–Kendall test reveals a positive trend in the frequency of precipitation associated with convective rainfalls during May, as indicated by satellite data, ML models and synoptic precipitation observations. Ultimately, this research holds significant value for water resource management and the ongoing pursuit of refining satellite rainfall products in the context of diverse rainfall regimes.",
        "affiliation_name": "K. N. Toosi University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Unsupervised learning for medical data: A review of probabilistic factorization methods",
        "paper_author": "Neijzen D.",
        "publication": "Statistics in Medicine",
        "citied_by": "5",
        "cover_date": "2023-12-30",
        "Abstract": "We review popular unsupervised learning methods for the analysis of high-dimensional data encountered in, for example, genomics, medical imaging, cohort studies, and biobanks. We show that four commonly used methods, principal component analysis, K-means clustering, nonnegative matrix factorization, and latent Dirichlet allocation, can be written as probabilistic models underpinned by a low-rank matrix factorization. In addition to highlighting their similarities, this formulation clarifies the various assumptions and restrictions of each approach, which eases identifying the appropriate method for specific applications for applied medical researchers. We also touch upon the most important aspects of inference and model selection for the application of these methods to health data.",
        "affiliation_name": "Universitair Medisch Centrum Groningen",
        "affiliation_city": "Groningen",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Application of deep learning algorithms to correct bias in CMIP6 simulations of surface air temperature over the Indian monsoon core region",
        "paper_author": "Sabarinath A.",
        "publication": "International Journal of Climatology",
        "citied_by": "3",
        "cover_date": "2023-12-30",
        "Abstract": "Indian subcontinent witnessed a rise in surface air temperature (SAT) in recent decades, during the summer months of March, April and May. The monsoon core region (MCR) of India experiences a hot and humid climate, with temperatures typically highest in May and June before the onset of the monsoon. Global climate model (GCM) simulations of SAT are very much essential to understand the future climate of Indian MCR. Biases in GCMs simulations are due to insufficient knowledge of parameterizations and various assumptions that are made to simulate the complex interactions between land, ocean and atmosphere. The objective of this study is to correct the bias in the Coupled Model Intercomparison Project Phase 6 (CMIP6)–GCM simulations of SAT during March, April and May months over MCR for the historical period 1985–2014 and shared socio-economic pathways (SSPs) SSP2-4.5 and SSP5-8.5 for the period 2015–2100. SAT dataset of fifth-generation reanalysis (ERA5) of the European Centre for Medium-Range Weather Forecasts (ECMWF) is used as reference dataset to perform bias correction for the historical period. Preliminary investigation of both SAT datasets has shown that there exists considerable warm bias (1.47°C) over the MCR. Bias correction is performed using a one-dimensional convolutional neural network (CNN-1D) and a convolutional long short-term memory network (CNN-LSTM) deep learning algorithm. The performance of these algorithms is evaluated with the statistical metrics such as root-mean-square error (RMSE), normalized root-mean-square error, Nash–Sutcliffe efficiency, mean absolute error, percent bias, correlation coefficient and dynamic time warping. RMSE and percent bias were decreased to 0.35°C and 0.8% with CNN-LSTM algorithm. The CNN-LSTM algorithm also preserves the year-to-year variability of SAT. Hence, CNN-LSTM algorithm is found to be suitable for the bias correction of GCM simulations of SAT with encouraging results.",
        "affiliation_name": "Indian Institute of Technology Madras",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Rapid and comprehensive grade evaluation of Keemun black tea using efficient multidimensional data fusion",
        "paper_author": "Li L.",
        "publication": "Food Chemistry: X",
        "citied_by": "6",
        "cover_date": "2023-12-30",
        "Abstract": "To develop a comprehensive evaluation method for Keemun black tea, we used micro-near-infrared spectroscopy, computer vision, and colorimetric sensor array to collect data. We used support vector machine, least-squares support vector machine (LS-SVM), extreme learning machine, and partial least squares discriminant analysis algorithms to qualitatively discriminate between different grades of tea. Our results indicated that the LS-SVM model with mid-level data fusion attained an accuracy of 98.57% in the testing set. To quantitatively determine flavour substances in black tea, we used support vector regression. The correlation coefficient for the predicted sets of gallic acid, caffeine, epigallocatechin, catechin, epigallocatechin gallate, epicatechin, gallocatechin gallate and total catechins were 0.84089, 0.94249, 0.94050, 0.83820, 0.81111, 0.82670, 0.93230, and 0.93608, respectively. Furthermore, all compounds exhibited residual predictive deviation values exceeding 2. Hence, combining spectral, shape, colour, and aroma data with mid-level data can provide a rapid and comprehensive assessment of Keemun black tea quality.",
        "affiliation_name": "Anhui Agricultural University",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "High-throughput screening of MXenes for hydrogen storage via graph neural network",
        "paper_author": "Cheng J.",
        "publication": "Applied Surface Science",
        "citied_by": "9",
        "cover_date": "2023-12-30",
        "Abstract": "To better understand the recent experiment on hydrogen storage in MXene multilayers [Nature Nanotechnol. 2021, 16, 331], we propose a multiscale workflow to computationally screen 23,857 compounds of MXene for hydrogen storage in near ambient condition. By using density functional theory simulation to produce the dataset, we trained physics-informed atomistic line graph neural networks to predict hydrogen's adsorption performance on MXenes, which is further validated through grand canonical Monte Carlo simulation. As a result, ScYC is identified to exhibit a hydrogen storage capacity of 5.7 wt% at 230 K and 100 bar, showing the promise for hydrogen storage.",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Geographical and varietal origin differentiation of alcoholic beverages through the association between FT-Raman spectroscopy and advanced data processing strategies",
        "paper_author": "Hategan A.R.",
        "publication": "Food Chemistry: X",
        "citied_by": "4",
        "cover_date": "2023-12-30",
        "Abstract": "The present work aimed to test the efficiency of FT-Raman spectroscopy for fruit spirits discrimination by developing differentiation models based on two approaches, namely a supervised statistical method (Partial Least Squares Discriminant Analysis), and a Machine Learning technique (Support Vector Machines). For this purpose, a data set comprising 86 Romanian distillate samples was used, which aimed to be differentiated in terms of the raw material used for production (plum, apple, pear and grape) and county of origin (Cluj, Satu Mare and Salaj). Eight distinct preprocessing methods (autoscale, mean center, variance scaling, smoothing, 1st derivative, 2nd derivative, standard normal variate and Pareto) followed by a feature selection step were applied to identify the meaningful input data based on which the most efficient classification models can be constructed. Both types of models led to accuracy scores greater than 90% in differentiating the distillate samples in terms of geographical and botanical origin.",
        "affiliation_name": "Universitatea Babeș-Bolyai",
        "affiliation_city": "Cluj Napoca",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "Multi visual feature fusion based fog visibility estimation for expressway surveillance using deep learning network",
        "paper_author": "Yang W.",
        "publication": "Expert Systems with Applications",
        "citied_by": "8",
        "cover_date": "2023-12-30",
        "Abstract": "Visibility in foggy weather is of great value for traffic management and pollution monitoring. However, vision-based fog visibility estimation methods are usually based on a single image to approximate the visibility in foggy weather, and most existing data-driven machine learning models struggle to capture effective features and achieve high estimation accuracy due to the severe image degradation caused by reduced visibility and lack of real scene images. Therefore, this paper proposes a novel deep learning framework based on multi visual feature fusion for fog visibility estimation, named VENet, which comprises of two subtask networks (for fog level classification and fog visibility estimation) constructed in a cascade structure. A special feature extractor and an anchor-based regression method (ARM) are proposed to help improve the accuracy. Further, a standard Fog Visibility Estimation Image (FVEI) dataset containing 15,000 images of real fog scenes is established. This dataset greatly bridges the lack of suitable data in the field of vision-based visibility estimation. Extensive experiments have been conducted to demonstrate the performance of the proposed VENet, where the error of fog visibility estimation is less than 5% at 500 m and the fog level classification accuracy is at least 92.3%. In addition, the proposed VENet has been applied on Yunnan Xiangli and Mazhao Expressway surveillance with promising performance in practice.",
        "affiliation_name": "School of Civil and Environmental Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Unraveling the relationship between key aroma components and sensory properties of fragrant peanut oils based on flavoromics and machine learning",
        "paper_author": "Hu B.",
        "publication": "Food Chemistry: X",
        "citied_by": "14",
        "cover_date": "2023-12-30",
        "Abstract": "Key aroma components of 33 fragrant peanut oils with different aroma types were screened by combined using flavoromics and machine learning. A total of 108 volatile compounds were identified and 100 kinds of them were accurately quantified, and 38 compounds out of them were with odorant activity value ≥1. The 33 peanut oils presented varied intensity of ‘fresh peanuts’, ‘roasted nut’, ‘burnt’, ‘over-burnt’, ‘sweet’, ‘peanut butter-like’, ‘puffed food’ and ‘exotic flavor’, and could be classified into four aroma types, namely raw, light, thick and salty. Partial least squares regression analysis, random forest and classification regression tree revealed that 2-acetyl pyrazine had a negative effect on ‘fresh peanuts’ and could distinguish raw flavor samples well; 2-methylbutanal and 4-vinylguaiacol were key compounds of ‘roasted nut’ and had significant differences (P < 0.0001) in thick and raw flavor samples; furfural contributed to the ‘puffed food’ as well as key compound of salty flavor.",
        "affiliation_name": "COFCO",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Prediction of venting gas explosion overpressure based on a combination of explosive theory and machine learning",
        "paper_author": "Xu Q.",
        "publication": "Expert Systems with Applications",
        "citied_by": "6",
        "cover_date": "2023-12-30",
        "Abstract": "Combustible gas is widely used in industry and daily life but presents an unavoidable explosion hazard. Predicting explosion overpressure and guiding engineering design is an effective way to reduce the consequences of explosions. This paper presents a novel approach that integrates explosive theory and data science. Starting from the first principle, a dimensionless mathematical formula was constructed based on the explosive theory. Gas species, gas concentration, container parameters, and ignition position were fully considered by the formula, and built into data sets using machine learning techniques as characteristic parameters. The SVR algorithm, the BP algorithm, and the DNN algorithm all attest to the superiority. And the predictive physical consistency of this method has been proven. Simultaneously, the dataset constructed by this method effectively reduces the number of features. The PSO algorithm was used for parameter optimization based on the DNN algorithm guided by theory for building F-P (First principle) PSO-DNN Model. In the comparison of prediction results, the mean relative error of the F-P PSO-DNN model is 15%, 19% lower than that of the best performing Molkov model.",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A novel hybrid model for stock price forecasting integrating Encoder Forest and Informer",
        "paper_author": "Ren S.",
        "publication": "Expert Systems with Applications",
        "citied_by": "24",
        "cover_date": "2023-12-30",
        "Abstract": "Stock forecasting plays a pivotal role in time series forecasting as it enables informed and effective investment decisions by minimizing risks. In this paper, a novel hybrid model for stock price forecasting is proposed to explore the impact of a decomposition-reconstruction method fused with machine learning models, aiming to enhance the predictive ability of the model. Following the decomposition-prediction-reconstruction principle, the hybrid model incorporates wavelet transform, integrating Encoder Forest (EF) with Informer. To mitigate the influence of long-time series noise on stock forecasting, the original data is decomposed into high-frequency signal components (CD) and low-frequency signal components (CA). The Informer and Encoder Forest are trained to predict the future CA and CD, respectively. The hybrid model is implemented for all stocks in three industries of the china stock market. Several models including MLP, RNN, LSTM, Informer, WT + RNN + DT, WT + LSTM + RF, EMD + Informer + EF, VMD + Informer + EF, CEEMD + Informer + EF, and CEEMDAN + Informer + EF are designed as compared methods to verify the superiority and advancement of the proposed technique. Evaluating the performance of individual models reveals that the prediction accuracy follows the ranking: MLP < RNN < LSTM < Informer. Comparing the results of the hybrid model with those of the individual models demonstrates that the hybrid model improves prediction accuracy. This comparison also indicates that the wavelet transform and tree models can enhance the accuracy of the model without altering the initial ranking of the prediction effect. It is worth noting that WT and EMD-like methods employ different data decomposition approaches, leading to diverse outcomes. Experimental results indicate that WT is better suited for a hybrid model that combines two distinct methods. All experimental results indicated that the proposed hybrid model has higher prediction accuracy, stronger generalization ability, and stronger practicability, which is more suitable for Stock forecasting problems.",
        "affiliation_name": "North China University of Science and Technology",
        "affiliation_city": "Tangshan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Assessment of the level of road crash severity: Comparison of intelligence studies",
        "paper_author": "Shaffiee Haghshenas S.",
        "publication": "Expert Systems with Applications",
        "citied_by": "15",
        "cover_date": "2023-12-30",
        "Abstract": "In measuring road safety, accident severity is a key concern. Crash severity prediction models inform researchers about the severity of a crash based on a variety of criteria. To date, an enormous amount of research has been done on crash severity, and several models have been suggested to forecast crash severity utilizing existing test data or simulated datasets created using regression or classification analysis. In this study, a new approach was developed to determine the level of road crash severity (LRCS) using a large amount of real-existing data (1627 cases) by applying machine learning methods to the roads of Calabria in southern Italy. This study has three main goals: building prediction models based on classification approaches with the highest accuracy; comparing the performance of two supervised learning methods, including artificial neural networks (ANN) and convolutional neural networks (CNN), for predicting the LRCS; as well as determining the role of each of the contributing parameters in the LRCS and presenting a ranking by performing a sensitivity analysis. Finally, based on the accuracy values, it has been found that there isn't a salient difference between the predicted models. But it should be noted that 68.4% accuracy for the testing dataset implies the CNN model was superior to the ANN model, which scored 61.74% accuracy. This is acceptable if the minor variation in modeling accuracy is desired. Also, the results of the sensitivity analysis showed that the number of vehicles and the road element had the highest and lowest effect rates on the LRCS, respectively.",
        "affiliation_name": "Università della Calabria",
        "affiliation_city": "Rende",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Novel insights into the modeling financial time-series through machine learning methods: Evidence from the cryptocurrency market",
        "paper_author": "Khosravi M.",
        "publication": "Expert Systems with Applications",
        "citied_by": "7",
        "cover_date": "2023-12-30",
        "Abstract": "This study proposes a novel approach for modeling financial time series, concentrating on data pre-processing and selecting effective features in conventional and proposed modeling processes. In this context, three selected machine learning methods (including RF, XGBoost, and LSTM) are utilized on the return series of a selected cryptocurrency (bitcoin). The sample data was covered from 16 August 2018 to 22 June 2022. Moreover, three approaches (conventional, intermediate, and proposed) have been considered, each representing a different modeling process. The intermediate approach is a modeling process that only reflects the effect of the specific cross-validation method with purging and embargo operation in the output results (with the same selected features as the conventional process). Comparing the results of proposed and intermediate processes showed the effect of Purging and Embargo operations on decreasing the generalization error, and based on all evaluation metrics, the proposed approach has performed better than other modeling processes. The findings of this study have significant implications for investors, academic researchers, and policymakers.",
        "affiliation_name": "K. N. Toosi University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "An attempt to apply the homotopy method to the domain of machine learning",
        "paper_author": "Liu Y.y.",
        "publication": "Expert Systems with Applications",
        "citied_by": "2",
        "cover_date": "2023-12-30",
        "Abstract": "The most essential purpose of the machine learning field is to minimize the difference between the true value and the predicted value, so that the predicted value can be as close to the true value as possible. For this reason, researchers have proposed a loss function as a criterion for learning, which can generally be connected with optimization learning through the loss function. In the field of machine learning, our commonly used optimization method is gradient descent, because it only needs to solve the first-order derivative, and the calculation complexity is small and the accuracy is within an acceptable range. But gradient descent has a problem that cannot be ignored-divergence. To solve this problem, we propose a homotopy analysis method. The homotopy analysis method can effectively control the convergence by introducing the convergence control parameters without divergence. At the same time, our experiments also show that our algorithm can not only guarantee convergence, but also reduce the number of iterations.",
        "affiliation_name": "China University of Petroleum-Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Q-learning-based hyper-heuristic evolutionary algorithm for the distributed flexible job-shop scheduling problem with crane transportation",
        "paper_author": "Zhang Z.Q.",
        "publication": "Expert Systems with Applications",
        "citied_by": "33",
        "cover_date": "2023-12-30",
        "Abstract": "With the globalization and sustainable development of the modern manufacturing industry, distributed manufacturing and scheduling systems that consider environmental effects have attracted increasing attention. This article addresses the distributed flexible job-shop scheduling problem with crane transportation (DFJSPC) for minimizing the weighted sum of makespan and total energy consumption. In this study, we present a mixed integer linear programming model for DFJSPC and make a first attempt to propose a Q-learning-based hyper-heuristic evolutionary algorithm (QHHEA) for solving such a strongly NP-hard problem. The QHHEA has the following features: (i) a hybrid population initialization method is designed to produce high-quality individuals with certain diversity; (ii) a novel left-shift decoding scheme is added to the decoding scheme to improve the utilization of machine processing and crane transportation resource; (iii) a Q-learning-based high-level strategy is developed to determine the most suitable low-level heuristic (LLH) from a pre-designed set based on valuable information fed by the efficacy of LLHs; (iv) a new state definition and a dynamic adaptive mechanism are used to balance population convergence and diversity; (v) an improved move acceptance method is adopted to avoid falling into local optima and to drive the search behavior toward promising regions. To evaluate the efficiency and effectiveness of the proposed algorithm, extensive experiments and comprehensive comparisons are conducted on a benchmark with 36 instances. The statistical results show that QHHEA outperforms several state-of-the-art algorithms in solving DFJSPC.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Open problems in causal structure learning: A case study of COVID-19 in the UK",
        "paper_author": "Constantinou A.",
        "publication": "Expert Systems with Applications",
        "citied_by": "5",
        "cover_date": "2023-12-30",
        "Abstract": "Causal machine learning (ML) algorithms recover graphical structures that tell us something about cause-and-effect relationships. The causal representation provided by these algorithms enables transparency and explainability, which is necessary for decision making in critical real-world problems. Yet, causal ML has had limited impact in practice compared to associational ML. This paper investigates the challenges of causal ML with application to COVID-19 UK pandemic data. We collate data from various public sources and investigate what the various structure learning algorithms learn from these data. We explore the impact of different data formats on algorithms spanning different classes of learning, and assess the results produced by each algorithm, and groups of algorithms, in terms of graphical structure, model dimensionality, sensitivity analysis, confounding variables, predictive and interventional inference. We use these results to highlight open problems in causal structure learning and directions for future research. To facilitate future work, we make all graphs, models, data sets, and source code publicly available online.",
        "affiliation_name": "Indian Institute of Science Education and Research Bhopal",
        "affiliation_city": "Bhopal",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Hybrid interpretable model using roughset theory and association rule mining to detect interaction terms in a generalized linear model",
        "paper_author": "Mwangi I.K.",
        "publication": "Expert Systems with Applications",
        "citied_by": "6",
        "cover_date": "2023-12-30",
        "Abstract": "In machine learning, interpretability is paramount, and identifying interactions in data is a key component in creating interpretable models. Despite Generalized Linear Models (GLMs) being inherently interpretable due to their usage of interaction detection, they are constrained in their ability to explore the whole sample space for variable interactions and frequently presuppose uniform interactions with the target variable(s). To counter this limitation, we introduce a novel hybrid model named Rough-AssociationRule-Generalized Linear Model (RAGL). The RAGL model leverages Rough Set theory to detect interaction terms via information granulation and subsequently generates decision rules from these terms using association rule mining. These rules encapsulate the detected interactions, converted into binary values and incorporated as new predictive variables in the GLM model. Our study demonstrates that RAGL can discern interactions across a given dataset's sample space and employ important interaction terms for predictive purposes. The efficacy of our proposed model is validated using two benchmark Kaggle datasets – one for heart disease and the other for PIMA and a real weather dataset from Kariki_farm in Juja, Kenya. We juxtapose it against the classical GLM, decision trees, and Naïve Bayes models. Our findings show that RAGL significantly outperforms these models in terms of both accuracy and interpretability, with a predictive accuracy of 92.3% for heart disease and PIMA datasets and 90.5% for the Kariki_farm weather station data. The RAGL model provides an enhanced interpretation of variable interactions within the data compared to the classical GLM model, thus offering more insightful coefficients for feature interpretation. Additionally, it presents lower Bayesian Information Criterion (BIC) and Akaike's Information Criterion (AIC) values than the classical GLM model, suggesting improved model fit and parsimony. Thus, our principal contribution lies in a hybrid, interpretable model that employs Rough Set theory and association rule mining to uncover feature interactions and bolsters the accuracy and interpretability of the GLM model.",
        "affiliation_name": "Zetech University",
        "affiliation_city": "Nairobi",
        "affiliation_country": "Kenya"
    },
    {
        "paper_title": "Selective and collaborative influence function for efficient recommendation unlearning",
        "paper_author": "Li Y.",
        "publication": "Expert Systems with Applications",
        "citied_by": "8",
        "cover_date": "2023-12-30",
        "Abstract": "Recent regulations concerning the Right to be Forgotten have greatly influenced the operation of recommender systems, because users now have the right to withdraw their private data. Besides simply deleting the target data in the database, unlearning the associated data lineage e.g., the learned personal features and preferences in the model, is also necessary for data withdrawal. Existing unlearning methods are mainly devised for generalized machine learning models in classification tasks. In this paper, we first identify two main disadvantages of directly applying existing unlearning methods in the context of recommendation, i.e., (i) unsatisfactory efficiency for large-scale recommendation models and (ii) destruction of collaboration across users and items. To tackle the above issues, we propose a highly efficient recommendation unlearning method based on Selective and Collaborative Influence Function (SCIF). Our proposed method can (i) avoid any kind of retraining which is computationally prohibitive for large-scale systems, (ii) further enhance efficiency by selectively updating user embedding and (iii) preserve the collaboration across the remaining users and items. Furthermore, in order to evaluate the unlearning completeness, we define a Membership Inference Oracle (MIO) that verifies whether the unlearned data points were part of the model's training set, thereby determining if a data point was completely unlearned. Extensive experiments on two benchmark datasets demonstrate that our proposed method can not only greatly enhance unlearning efficiency, but also achieve adequate unlearning completeness. More importantly, our proposed method outperforms the State-Of-The-Art (SOTA) unlearning method regarding comprehensive recommendation metrics.",
        "affiliation_name": "Ant group",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A novel hybrid binary whale optimization algorithm with chameleon hunting mechanism for wrapper feature selection in QSAR classification model:A drug-induced liver injury case study",
        "paper_author": "Zhou R.",
        "publication": "Expert Systems with Applications",
        "citied_by": "6",
        "cover_date": "2023-12-30",
        "Abstract": "High dimensionality is one of the main challenges in Quantitative Structure-Activity Relationship (QSAR) classification modeling, and feature selection as an effective dimensionality reduction method plays an important role in machine learning, particularly in fields such as chemometrics. In this paper, for feature selection in QSAR classification modeling, a hybrid whale optimization algorithm (WOA) with a chameleon hunting mechanism (HWOA-CHM) is proposed, and its binary version is used to find the best subset for wrapper feature selection in the QSAR classification model. First, a chaos weighting factor is introduced and used as a perturbation factor to increase the diversity of populations. Second, a retractable transformation strategy is designed to prevent the HWOA-CHM from falling into a local optimum. Third, the chameleon predation mechanism is introduced to improve the convergence accuracy of the HWOA-CHM. The performance of HWOA-CHM is evaluated and compared with state-of-the-art classical algorithms and well-known WOA variants. Then, a binary HWOA-CHM (BHWOA-CHM) was designed to solve the feature selection, the BHWOA-CHM is validated using the UCI machine learning repository and compared with binary version WOA, and well-known WOA variants in terms of accuracy, number of features, and time. Finally, BHWOA-CHM was used to solve the high-dimensional feature selection problem in the drug-induced liver injury classification model. It has shown excellent results in terms of feature selection compared to other methods. The proposed method effectively improves the robustness of QSAR predictions while reducing the complexity of the feature sets, demonstrating its potential for improving the accuracy of QSAR models.",
        "affiliation_name": "University of Science and Technology Liaoning",
        "affiliation_city": "Anshan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Epileptic multi-seizure type classification using electroencephalogram signals from the Temple University Hospital Seizure Corpus: A review",
        "paper_author": "McCallan N.",
        "publication": "Expert Systems with Applications",
        "citied_by": "12",
        "cover_date": "2023-12-30",
        "Abstract": "Epilepsy is one of the most paramount neurological diseases, affecting about 1% of the world's population. Seizure detection and classification are difficult tasks and are ongoing challenges in biomedical signal processing to enhance medical diagnosis. This paper presents and highlights the unique frequency and amplitude information found within multiple seizure types, including their morphologies, to aid the development of future seizure classification algorithms. Whilst many published works in the literature have reported on seizure detection using electroencephalogram (EEG), there has yet to be an exhaustive review detailing multi-seizure type classification using EEG. Therefore, this paper also includes a detailed review of multi-seizure type classification performance based on the Temple University Hospital Seizure Corpus (TUSZ) dataset for focal and generalised classification, and multi-seizure type classification. Deep learning techniques have a higher overall average performance for focal and generalised classification compared to machine learning techniques, whereas hybrid deep learning approaches have the highest overall average performance for multi-seizure type classification. Finally, this paper also highlights the limitations of the TUSZ dataset and suggests some future work, including the curation of a standardised training and testing dataset from the TUSZ that would allow a proper comparison of classification methods and spur advancement in the field.",
        "affiliation_name": "Ulster University",
        "affiliation_city": "Coleraine",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Fed-ANIDS: Federated learning for anomaly-based network intrusion detection systems",
        "paper_author": "Idrissi M.J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "54",
        "cover_date": "2023-12-30",
        "Abstract": "As computer networks and interconnected systems continue to gain widespread adoption, ensuring cybersecurity has become a prominent concern for organizations, regardless of their scale or size. Meanwhile, centralized machine learning-based Anomaly Detection (AD) methods have shown promising results in improving the accuracy and efficiency of Network Intrusion Detection Systems (NIDS). However, new challenges arise such as privacy concerns and regulatory restrictions that must be tackled. Federated Learning (FL) has emerged as a solution that allows distributed clients to collaboratively train a shared model while preserving the privacy of their local data. In this paper, we propose Fed-ANIDS, a NIDS that leverages AD and FL to address the privacy concerns associated with centralized models. To detect intrusions, we compute an intrusion score based on the reconstruction error of normal traffic using various AD models, including simple autoencoders, variational autoencoders, and adversarial autoencoders. We thoroughly evaluate Fed-ANIDS using various settings and popular datasets, including USTC-TFC2016, CIC-IDS2017, and CSE-CIC-IDS2018. The proposed method demonstrates its effectiveness by achieving high performance in terms of different metrics while preserving the data privacy of distributed clients. Our findings highlight that autoencoder-based models outperform other generative adversarial network-based models, achieving high detection accuracy coupled with fewer false alarms. In addition, the FL framework (FedProx), which is a generalization and re-parametrization of the standard method for FL (FedAvg), achieves better results. The code is available at https://github.com/meryemJanatiIdrissi/Fed-ANIDS.",
        "affiliation_name": "Mohammed VI Polytechnic University",
        "affiliation_city": "Ben Guerir",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "A multi-model ensemble learning framework for imbalanced android malware detection",
        "paper_author": "Zhu H.j.",
        "publication": "Expert Systems with Applications",
        "citied_by": "6",
        "cover_date": "2023-12-30",
        "Abstract": "The continuous malicious software (malware) attacks on smartphones pose a serious threat to the security of users, especially the dominant platform Android. Data-driven methods based on machine learning algorithms are a promising way to defend against that. In this paper, we explore the limitations of this kind of methods in improving the performance of malware detection, e.g., considering each feature in isolation and relying on balanced class data, and propose a multi-model ensemble framework MEFDroid by combining individual predictors, where hybrid deep learning based feature extraction methods are adopted to learn meaningful features from raw data. Besides, a novel fusion scheme is exploited to fuse multi-level representations and mine their correlations to maximize the utilization of original information. To evaluate the effectiveness of the MEFDroid framework, we conduct a step-by-step model justification experiment to investigate how the proposed algorithms (i.e., ESAES, EDAES and EDAFS) enhance the malware detection performance gradually. We also compare the proposed algorithms with classical machine learning methods, conventional sampling solutions for the imbalance problem. Besides, we investigate the reliability of our proposed methods using another public dataset. Our extensive experimental results demonstrate that the target model EDAFS in MEFDroid outperforms others in terms of most metrics, which means that it is an effective alternative solution to detect Android malware.",
        "affiliation_name": "Edward E. Whitacre Jr. College of Engineering",
        "affiliation_city": "Lubbock",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Human-aligned trading by imitative multi-loss reinforcement learning",
        "paper_author": "Ye Z.J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "7",
        "cover_date": "2023-12-30",
        "Abstract": "Research into algorithmic trading using reinforcement learning has been garnering increasing popularity in recent years. While most research work focuses on solving a certain modelling problem or data problem with positive results, we believe that in an application as critical as financial trading, aligning the machine to human behaviours is imperative and should be regarded as the basis of all further improvements before machine algorithms are free to go their own innovative ways. In this paper, we are proposing a trading model whose design principles are based on bringing a machine trading agent close to a human trader. We study areas where human alignment is necessary and introduce as a solution a novel multi-loss function of the model combining supervised learning, single-step and multi-step Q learning, and also inject the paradigm of imitation learning in the training and trading processes. We also introduce a realistic backtesting setup and a holding position-aware profit calculation scheme under which the machine algorithm conducts intra-day trading using minute tick data over a group of U. S. stocks chosen to represent different industrial sectors and liquidity levels. Our model's overall out-performance over a group of baseline models as well as our ablation study results justify the inclusion of individual model features all of which are introduced to bring aspects of the model behaviour more aligned with those of a human trader.",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Cost-aware scheduling systems for real-time workflows in cloud: An approach based on Genetic Algorithm and Deep Reinforcement Learning",
        "paper_author": "Zhang J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "28",
        "cover_date": "2023-12-30",
        "Abstract": "With the development of cloud computing, a growing number of applications are migrating to a cloud environment. In the process, the real-time scheduling of workflows has gradually become a technical challenge, due to the dynamic and uncertain nature of cloud environments and the complex dependencies between sub-tasks of the workflow. Although various methods have been reported up to now, these methods have their respective shortcomings, such as heuristic-based methods are hard to find optimal scheduling scheme and metaheuristic-based methods incur high computational overhead, which often lead to the violation of QoS (Quality of Service) requirements and increases service renting costs of executing workflows. Inspired by the successful application of Deep Reinforcement Learning (DRL) in cloud job scheduling, this paper proposes a real-time workflow scheduling method which combines Genetic Algorithm (GA) and DRL, aiming to reduce both execution cost and response time. To be specific, we design a real-time workflow scheduling algorithm named GA-DQN by combining the global search capability of GA and the environment awareness decision-making capability of DRL to divides scheduling process into two stages. First, the execution scheme of workflow in virtual machine is calculated when workflow arrives. Then, a DRL agent uses this scheme as the feature of workflow to assign workflow to a suitable virtual machine. In this way, the use of DRL to sense environment increases the computational efficiency of GA, and the execution scheme obtained by GA helps DRL to obtain the feature of workflow. On this basis of real world workflow, three groups of simulation experience are carried out to compare GA-DQN with four baseline method which consist of three traditional methods and a state-of-the-art method. The comparison results demonstrate that GA-DQN outperforms the other methods in terms of response time, execution cost, and success rate across different workloads and cloud instance configurations.",
        "affiliation_name": "Shandong University of Technology",
        "affiliation_city": "Zibo",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A novel survival analysis of machine using fuzzy ensemble convolutional based optimal RNN",
        "paper_author": "Sankaranarayanan S.",
        "publication": "Expert Systems with Applications",
        "citied_by": "0",
        "cover_date": "2023-12-30",
        "Abstract": "Survival Analysis is essential in the manufacturing field to determine unnecessary events by the input data. In Survival analysis, predictive maintenance plays a major portion in the identification of machine failures based on incoming input data from diverse equipment or sensors. Therefore, the Deep learning method is exploited for barbarizing the issues of predictive maintenance marginally but these techniques are not quite useful to predict the failure of devices for certain input data which the technique had not learned. Meanwhile, the neural network techniques are capable of predicting the output in accordance with the preceding input feature, the performance was poor when the input features have large variations. As a result, the transformation of input data degrades the performance of the neural network and the algorithm does not support the prediction of machine failure. To overcome such drawback, this paper proposes a novel Sugeno Fuzzy Ensemble Convolutional based War Strategy Algorithm (SFEC-WSA) to classify the device and identify the survival time in accordance with the input features. The proposed SFEC system integrates the process of both the Sugeno fuzzy integral ensemble model and the Attention-based Bidirectional CNN-RNN Deep Model (ABCDM). The SFEC-WSA algorithm is applicable in learning diverse input feature variations thereby predicting the robustness of the input data. The proposed SFEC-WSA analyses several parameters such as vibration, rotation, voltage, and pressure to evaluate the condition of the equipment. The experimentation results revealed that the proposed model effectively predicts large test data and performs better than other approaches.",
        "affiliation_name": "Velammal Institute of Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Developing a deep canonical correlation-based technique for seizure prediction",
        "paper_author": "Vieluf S.",
        "publication": "Expert Systems with Applications",
        "citied_by": "2",
        "cover_date": "2023-12-30",
        "Abstract": "Proof-of-principle studies suggest that seizure prediction from non-invasive device recordings may be feasible. However, the discovery of optimal biomarkers is an ongoing research task. We aim to evaluate seizure-related differences in peripheral neurophysiological recordings by proposing a biomarker that allows classifying between pre-ictal and time-matched inter-ictal data from epilepsy patients. We include 42 pediatric epilepsy patients admitted for continuous video-EEG monitoring at Boston Children's Hospital (21 with tonic-clonic seizures and 21 controls). With a wearable biosensor, we select 45 min of pre-ictal data from seizure patients and 45 min of time-matched data from control patients. We analyze electrodermal activity and heart rate recordings by three different architectures of deep canonical correlation analysis (DCCA)-based autoencoder. The clustering accuracy and improvement over chance are reported. The best DCCA technique is DCCA with a gated recurrent unit with a clustering accuracy of 68.9% and a relative improvement over chance of 37.8%. Clustering accuracy is better than chance for 71% of patients. Seizure prediction utilizing unsupervised clustering based on DCCA analysis of coupled changes in heart rate and electrodermal activity is feasible in a majority of patients with seizures.",
        "affiliation_name": "Paderborn University",
        "affiliation_city": "Paderborn",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Debris: Machine learning, archive archaeology, digital audio waste",
        "paper_author": "Trillo R.A.",
        "publication": "Organised Sound",
        "citied_by": "1",
        "cover_date": "2023-12-30",
        "Abstract": "This article fragments and processes Debris, a project developed to formalise the creative recycling of digital audio byproducts. Debris began as an open call for electronic compositions that take as their point of departure gigabytes of audio material generated through training and calibrating Demiurge, an audio synthesis platform driven by machine learning. The Debris project led us down rabbitholes of structural analysis: what does it mean to work with digital waste, how is it qualified, and what new relationships and methodologies do this foment? To chart the fluid boundaries of Debris and pin down its underlying conceptualisation of sound, this article introduces a framework ranging from archaeomusicology to intertextuality, from actor-network theory to Deleuzian assemblage, from Adornian constellation to swarm intelligence to platform and network topology. This diversity of approaches traces connective frictions that may allow us to understand, from the perspective of Debris, what working with sound means under the regime of machine intelligence. How has machine intelligence fundamentally altered the already shaky diagram connecting humans, creativity and history? We advise the reader to approach the text as a multisensory experience, listening to Debris while navigating the circuitous theoretical alleys below.",
        "affiliation_name": "Hong Kong Baptist University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "System dynamics, machine learning and structural validation",
        "paper_author": "Schoenberg W.",
        "publication": "LIFE: A Transdisciplinary Inquiry",
        "citied_by": "2",
        "cover_date": "2023-12-29",
        "Abstract": "NA",
        "affiliation_name": "Universitetet i Bergen",
        "affiliation_city": "Bergen",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "AGRO-ECOLOGICAL CLASSIFICATION OF AGRICULTURAL LAND USING MACHINE LEARNING, GIS AND REMOTE SENSING DATA",
        "paper_author": "Pavlova A.I.",
        "publication": "Siberian Journal of Life Sciences and Agriculture",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The paper is devoted to agro-ecological classification of agricultural land using modern methods of geo-information data analysis and machine learning. Background. There are few works in the literature, which cover the issues of accuracy of machine learning (MLL) models for agro-ecological grouping of agricultural land. A large number of raster information layers are used to improve the accuracy of land classification from satellite images. This considerably increases the time of training and testing MMOs, producing thematic maps of agricultural land classification. This approach requires considerably high computing resources and a considerable amount of computer RAM. Raster GIS data models occupy a much larger volume than vector models. In this regard, research on automated agro-ecological (grouping, classification) of agricultural land using vector GIS models is of practical importance. Purpose. The aim of the study is to apply GIS methods, remote sensing (ERS) data and machine learning methods for agricultural land grouping. Materials and methods. The materials used were synthesized multispectral high spatial resolution Sentinel-2A images, maps of vegetation indices NDVI (Normalized Difference Vegetation Index), OSAVI (Optimized Soil Adjusted Vegetation Index), EVI2 (Enhanced Vegetation Index2), NDWI (Normalized Difference Water Index), SAVI, PVI, GDVI, MCARI, NDRE, TSAVI; topographic map, ALOS DSM (30 m/pixel) and ALOS PALSAR (12.5 m/pixel) satellite images, soil map and field survey results. Field measurements were carried out using the Triump-2 satellite geodetic receiver and included determination of coordinates of charac-teristic points of land plot boundaries, relief elements, and soil survey. Digital spatial model of land use was created using GIS ArcGIS and QGIS, Python engineering libraries were used in the machine learning process. Results. Agro-ecological grouping of lands was realized by the example of the farm “Zerno Sibiri” of Novosibirsk region using the following machine learning methods: Random Forest (RF) method, Decision Tree (DT), k-nearest neighbours method (KNN). The best accuracy is the RF machine learning model. The accuracy of the model averaged 97.9% (with training 99.9%, testing 98.8%, and cross validation 95.0%). The Root Mean Square Error (RMSE) is 0.006: for training sample 0.001; test sample 0.076; validation sample 0.123 respectively). The mean kappa coefficient was 0.97 (1.00 for the training sample; 0.982 for the test sample, and 0.927 for the validation sample). Conclusion. The offered method of agro-ecological grouping of agricultural lands by means of GIS, RS data and machine learning methods enabled to distinguish informative quantitative indicators of the relief. The main essence of the proposed method is to create a machine learning model (MLM) based on a spatial dataset. The spatial dataset is formed using geoinformation analysis methods and includes: geomorphometric maps, maps of agrometeorological parameters, soil map, on-farm land management map and operational-territorial units of land classification. The application of vector data model allowed for agro-ecological grouping of agricultural lands in automated mode, to accelerate labor-intensive process of raster data recognition, to increase objectivity of the work. The sug-gested method of agro-ecological agro-ecological grouping of lands allows taking into account the totality of relief and soil-ecological conditions indicators with the help of geoinformation analysis methods, remote sensing and machine learning.",
        "affiliation_name": "Novosibirsk State University of Economics and Management",
        "affiliation_city": "Novosibirsk",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Adversarial attacks on face recognition",
        "paper_author": "Yang X.",
        "publication": "Handbook of Face Recognition",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "Face recognition is becoming a prevailing authentication solution in numerous biometric applications thanks to the rapid development of deep neural networks (DNNs) [18, 37, 39]. Empowered by the excellent performance of DNNs, face recognition models are widely deployed in various safety-critical scenarios ranging from finance/payment to automated surveillance systems. Despite its booming development, recent research in adversarial machine learning has revealed that face recognition models based on DNNs are highly vulnerable to adversarial examples [14, 40], which are maliciously generated to mislead a target model.",
        "affiliation_name": "Beijing National Research Center for Information Science and Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The creation of a conscious machine: The quest for artificial intelligence, second edition",
        "paper_author": "Tardy J.E.",
        "publication": "The Creation of a Conscious Machine: The Quest for Artificial Intelligence, Second Edition",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "This book presents a groundbreaking journey into the world of Generative AI technology and offers an in-depth look at the prospect of AI achieving consciousness. The book navigates through various historical and modern perspectives on AI, from ancient myths to the Turing Test to the latest in technological advancements. It covers the theoretical and practical aspects of creating a conscious AI, including the specifications for synthetic consciousness and the integration of AI with human cognition. The book questions whether generative AI can meet the traditional criteria of consciousness and how this might be realized.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "The challenge to AI: Consciousness and ecological general intelligence",
        "paper_author": "Robbins S.E.",
        "publication": "The Challenge to AI: Consciousness and Ecological General Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "This book invites readers to explore the intricate world where AI, consciousness, and human cognition intersect. This groundbreaking book considers the profound differences between man and machine, challenging existing notions in AI and cognitive science. It argues that the key to understanding intelligence lies not in software, but in the hardware of our brain - a complex biochemical system far removed from current AI architectures. Through a deep examination of time, perception, language, and the nature of thought, the book presents a compelling case for the indispensability of biology and consciousness in cognition. To achieve this, to engineer this, will indeed be a challenge for AI.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Enhancing money laundering detection through machine learning: A comparative study of algorithms and feature selection techniques",
        "paper_author": "Mishra S.R.",
        "publication": "AI and Blockchain Applications in Industrial Robotics",
        "citied_by": "3",
        "cover_date": "2023-12-29",
        "Abstract": "Money laundering is a worldwide issue that jeopardizes the stability and integrity of financial institutions. Many countries have implemented anti-money laundering laws and regulations to combat this. The basics of money laundering and its influence on the financial system, as well as existing strategies for detecting and combating it, are covered in this chapter. K- nearest neighbors, random forest, naive bayes, deep neural networks, and evolution metrics are examples of machine learning techniques and algorithms used to identify suspicious transactions. Financial institutions and regulatory bodies can strengthen their ability to detect and prevent money laundering activities and help to protect the integrity of the financial system by utilizing a variety of measures. In this work, the authors have presented a deep comparative analysis among various machine learning algorithms that are used in money laundering detection.",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Quantum innovations at the nexus of biomedical intelligence",
        "paper_author": "Dutt V.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The convergence of quantum technologies and biomedical intelligence is a frontier of boundless potential. The quantum advancements revolutionize disease detection, personalized medicine, and health monitoring frameworks while confronting the pressing challenge of accountability in machine learning systems within the biomedical domain. How do quantum innovations at the nexus of biomedical intelligence redefine biomedical research and healthcare, addressing critical inquiries such as the transformative potential of quantum computing, machine learning, and sensing technologies? Quantum Innovations at the Nexus of Biomedical Intelligence explores the intricate synergy between quantum mechanics and the biomedical domain. This book elucidates the profound implications and applications arising from the fusion of quantum computing, artificial intelligence, and biomedical sciences. This book introduces biomedical engineering, setting the stage for a deep dive into the transformative role of quantum computing and artificial intelligence. As the narrative unfolds, the text navigates the reader through the uncharted territories of quantum-enhanced machine learning, quantum sensing and their profound impact on diagnostics, personalized medicine, and health monitoring frameworks. The intersection of quantum computing and AI in medical advancements and cybersecurity is illuminated, offering a comprehensive understanding of the multifaceted applications of these cutting-edge technologies. The book is a collaborative effort, allowing luminaries from quantum computing, artificial intelligence, biomedicine, bioengineering, molecular biology, and healthcare to share their expertise. Readers will find in-depth discussions on topics ranging from the detection of cardiomegaly using quantum-enhanced deep convolutional neural networks to applying quantum machine learning algorithms in predicting outbreaks of diseases such as dengue fever. The challenges of accountability in machine learning systems are explored beyond mere technical obstacles, establishing a critical dialogue on responsible innovation in this burgeoning field. This book is ideal for researchers, scientists, academics, and professionals across diverse disciplines in quantum innovations within biomedical intelligence. Graduate students and postdoctoral researchers will discover a valuable resource that expands their knowledge and unveils new avenues for research and future investigations.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine learning and quantum computing in biomedical intelligence",
        "paper_author": "Sarangi P.K.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The digital world is replete with data like cyber security data, internet of things (IoT) data, enterprise data, mobile data, health data, and more. To analyse this data brilliantly and develop intelligent and automated applications, everyone has to know artificial intelligence (AI) algorithms, deep learning (DL) and machine learning (ML). Therefore, in today's technology-driven or digital world, no company can afford to ignore artificial intelligence or machine learning. Machine learning is a subfield of artificial intelligence, which is the scientific study of algorithms and statistical models that a computer system utilises to effectively carry out a given task without the need for any explicit instructions. This chapter begins with the basics of machine learning and its diverse range of techniques. This chapter also discusses various classification and clustering methods along with their applications and concludes with some real-world applications and examples and research development using machine learning and quantum computing in healthcare.",
        "affiliation_name": "Chitkara University, Punjab",
        "affiliation_city": "Rajpura",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Hybrid algorithms for medical insights using quantum computing",
        "paper_author": "Kapoor N.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "In the field of medicine, machine learning has become very important. It's helping us identify diseases better, take care of patients more personally, and improve many important parts of healthcare. With more and more medical information available, machine learning, which relies on big sets of data, can make predictions more accurate and help doctors make better decisions. This chapter looks closely at how machine learning is being used in medicine right now. It also talks about how quantum computing could change healthcare. First, it explains different ways machine learning is used and how it's being used in medicine. It talks about things like diagnosing diseases, finding new medicines, and treating patients in a way that's right for them. Then, it explores how machine learning and quantum computing could work together. Quantum computing uses special particles to do many calculations at once. This could help process medical information much faster. Quantum computing could also help simulate how molecules interact, which is important for developing new medicines.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Quantum machine learning for biomedical data analysis",
        "paper_author": "Dankan Gowda V.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The emerging and novel field of utilizing quantum physics in the world of machine learning, with ap¬plications customized for biomedical data, is explored in detail in this chapter. The discussion begins with an introduction to quantum physics and machine learning, before going on to explain how the two fields can work together to revolutionize biomedical data processing. Quantum-enhanced algorithms and their ability to process massive and intricate biomedical datasets are discussed in depth. In applications such as protein folding prediction, genomic data processing, and real-time diagnostics, the inherent parallelism and superposition capabilities of quantum machine learning are on full display. Finally, the technical and ethical difficulties of combining quantum machine learning with biomedical data are assessed in depth. The authors also provide an outlook on the promising interdisciplinary subject of quantum-powered machine learning and its potential to radically alter the field of biomedical research and healthcare solutions.",
        "affiliation_name": "BMS Institute of Technology and Management",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Enhancing elderly health monitoring framework with quantum-assisted machine learning models as micro services",
        "paper_author": "Bhuvaneswari A.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "6",
        "cover_date": "2023-12-29",
        "Abstract": "Monitoring systems for the elderly gather a variety of information, including blood pressure, insulin level, oxygen saturation, and more. Machine learning is a multidisciplinary method for identifying patterns in data by applying mathematical algorithms and iterative computing processes. Machine learning models are implemented as microservice-based architecture, which makes code components more maintain¬able, testable, and of course, responsive. The supervised model, unsupervised model, and reinforcement model are the three machine learning models that are employed as micro-services independently. This study focuses on blood sugar level among other indicators used to monitor older people, because it is the primary factor determining how well each organ functions. In this work, the machine learning model is enhanced with quantum variationally algorithm to improve their efficiency and accuracy. With an accuracy rate of 81%, the quantum assisted unsupervised model performed better than the other two models when it was being executed.",
        "affiliation_name": "Adhiparasakthi Engineering College",
        "affiliation_city": "Melmaruvathur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Personalized medicine through quantum computing: Tailoring treatments in healthcare",
        "paper_author": "Sharma M.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "This chapter explores the transformative intersection of quantum computing and healthcare, particularly in the realm of personalized medicine. The amalgamation of quantum computing and healthcare has ushered in a new era where the unique genetic profile of individuals can be leveraged to craft highly tailored medical treatments. Traditional computing methods often fall short in managing the immense complexity of genetic data, necessitating a paradigm shift. Quantum computing, with its unprecedented computational capabilities, especially in quantum machine learning, emerges as a revolutionary tech¬nology to decipher intricate genetic patterns and streamline the development of personalized treatment approaches. The chapter delineates the objectives of personalized medicine, emphasizing its pivotal role in enhancing treatment efficacy, minimizing adverse effects, tailoring preventive strategies, facilitating drug discovery, and harnessing quantum advantages.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Facilitating global collaboration and knowledge sharing in higher education with generative AI",
        "paper_author": "Yu P.",
        "publication": "Facilitating Global Collaboration and Knowledge Sharing in Higher Education With Generative AI",
        "citied_by": "2",
        "cover_date": "2023-12-29",
        "Abstract": "Chatbots powered by artificial intelligence (AI) have captivated the academic world as tools for human-like interaction across various settings. Within the realm of education, AI-powered chatbots, such as ChatGPT, hold the potential to revolutionize teaching, learning, and research processes. By simulating human conversation through vast data and machine learning algorithms, generative AI has unveiled new opportunities for personalized and adaptive learning experiences. Facilitating Global Collaboration and Knowledge Sharing in Higher Education With Generative AI delves into the promising prospects and challenges of applying generative AI in education while employing a critical interdisciplinary perspective. The book offers comprehensive insights into the transformative effects of generative AI on teaching, learning, and research. However, the application of generative AI in education also brings ethical, pedagogical, and technical challenges to the forefront. Concerns over privacy, data protection, and the impact of automation on human interaction and creativity demand thorough examination and practical solutions. Intended for educators, researchers, and administrators in higher education institutions, as well as policymakers and industry professionals at the intersection of AI and higher education, this book highlights innovative approaches and best practices for integrating generative AI into various educational aspects. It explores the potential of generative AI in fostering global collaboration and knowledge sharing, addressing cross-cultural understanding, and promoting internationalization in educational settings. The book encompasses a wide range of themes, including the impact of AI-generated content on student engagement and performance in online learning environments, ethical implications of automating education through AI-powered chatbots, personalization of learning experiences for diverse student populations, and the challenges of integrating generative AI into traditional classroom settings. Additionally, the book addresses generative AI's potential to enhance accessibility and inclusivity in education for individuals with disabilities, support lifelong learning initiatives, and revolutionize distance education and remote learning. It also delves into its role in promoting intercultural understanding, critical thinking, and global competency.",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning and blockchain integration in industrial robotics: Challenges and opportunities",
        "paper_author": "Gowda V.D.",
        "publication": "AI and Blockchain Applications in Industrial Robotics",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "Machine learning and blockchain have the potential to completely change the landscape of industrial robots. Learning and adaptation give robots an edge in functionality and independence. Blockchain, on the other hand, provides a decentralized and secure platform for information exchange and transaction verification. In this chapter, the authors look at the potential benefits and drawbacks of integrating machine learning and blockchain technology for use in manufacturing robots. The study begins with a brief introduction to machine learning, blockchain, and their respective industrial robot applications. Some of the possibilities and advantages that will be covered in the next sections include better data security, more transparent and auditable decision making, and the use of decentralized control systems. The importance of collaboration between academic institutions, businesses, and government agencies is emphasized in order to speed up the process of mainstreaming machine learning and blockchain integration in industrial robots.",
        "affiliation_name": "Aditya College of Engineering",
        "affiliation_city": "Surampalem",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Intersection of adaptive learning, global collaboration, and knowledge sharing through machine learning in higher education: Empowering education",
        "paper_author": "Thingom C.",
        "publication": "Facilitating Global Collaboration and Knowledge Sharing in Higher Education With Generative AI",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The chapter explores the integration of adaptive learning, global collaboration, and knowledge sharing in higher education, highlighting their transformative impact. Adaptive learning, driven by machine learning algorithms, tailors educational content to individual student needs, ensuring engagement and mastery of subjects. Global collaboration allows students to connect with peers, faculty, and experts worldwide, promoting diverse perspectives and cross-cultural learning. Knowledge sharing, facilitated by digital platforms and machine learning, empowers learners to create, curate, and disseminate knowledge, fostering a culture of collaboration and innovation. The chapter also discusses the challenges and ethical considerations in implementing machine learning in education, emphasizing privacy and data security. It also explores how educators can use data-driven insights to enhance pedagogical strategies.",
        "affiliation_name": "Alliance University",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Intelligent resource allocation and optimization for industrial robotics using AI and blockchain",
        "paper_author": "Vashishth T.K.",
        "publication": "AI and Blockchain Applications in Industrial Robotics",
        "citied_by": "10",
        "cover_date": "2023-12-29",
        "Abstract": "This chapter focuses on the application of intelligent resource allocation and optimization techniques for industrial robotics systems using the synergistic integration of artificial intelligence (AI) and blockchain technologies. Efficient resource allocation is crucial for maximizing the performance and productivity of industrial robotics, and AI-based approaches offer the ability to dynamically allocate resources based on real-time data and system requirements. Additionally, blockchain technology provides a decentralized and secure platform for recording and verifying resource allocation transactions, ensuring transparency and trust in the allocation process. The chapter explores various AI algorithms and models that can be employed for resource allocation and optimization in industrial robotics, including machine learning, evolutionary algorithms, and reinforcement learning. Furthermore, the chapter investigates how blockchain technology can enhance resource allocation and optimization by providing a distributed ledger for recording and verifying resource transactions.",
        "affiliation_name": "IIMT University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Enhancing industrial robotics performance and security with AI and blockchain technologies",
        "paper_author": "Varadam D.",
        "publication": "AI and Blockchain Applications in Industrial Robotics",
        "citied_by": "2",
        "cover_date": "2023-12-29",
        "Abstract": "Industrial robotics are becoming more widely used, but their performance and security must be urgently enhanced to satisfy the needs of contemporary industrial contexts. This chapter focuses on how AI and blockchain technology might improve industrial robotic systems' performance while guaranteeing strong security precautions. The capabilities of industrial robots are greatly enhanced by AI technologies. Robots may improve their performance, gain new abilities, and adapt to changing circumstances by utilising cutting-edge machine learning techniques. Robots may learn from their experiences thanks to the incorporation of AI, which improves their operational effectiveness, precision, and decision-making abilities. AI enables robots to optimise their performance, spot anomalies, and proactively resolve potential difficulties, resulting in increased production and less downtime. This is done through real-time data analysis and predictive analytics. Incorporating blockchain technology also provides an industrial robotics system with a safe and open framework.",
        "affiliation_name": "M. S. Ramaiah University of Applied Sciences",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Algorithmic FinTech pioneering the financial landscape of tomorrow",
        "paper_author": "Aggarwal K.K.",
        "publication": "Algorithmic Approaches to Financial Technology: Forecasting, Trading, and Optimization",
        "citied_by": "4",
        "cover_date": "2023-12-29",
        "Abstract": "Algorithmic FinTech emerges as a pioneering force transforming the financial landscape in an era of fast technical breakthroughs and a new financial worldview. This study examines Algorithmic FinTech in-depth, providing light on its transformational potential, essential applications, and profound impact on the future of finance. Algorithmic FinTech is applying cutting-edge technology such as artificial intelligence, machine learning, and data analytics to optimize financial processes. This chapter examines algorithms' numerous roles in the financial industry, ranging from risk assessment and trading methods to personal financial management and lending solutions. This chapter provides an in-depth introduction to comprehending the transformational potential of Algorithmic FinTech, its applications, and its influence on traditional banking while emphasizing the importance of responsible innovation in ensuring a robust and equitable financial future.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Knowledge-based earth monitoring and prediction systems",
        "paper_author": "Edwin Raja S.",
        "publication": "Novel AI Applications for Advancing Earth Sciences",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "Knowledge-based earth monitoring and prediction system is an innovative tool developed to provide comprehensive insights into Earth's environment and climate. Leveraging advanced methods, artificial intelligence, and machine learning, KEMPS enhances the precision of both short-term and long-term predictions. They combine various statistics resources and expert knowledge to offer valuable insights into the environment and inform selections associated with disaster preparedness, and public coverage. Moreover, research and development of knowledge-based decision support systems for Earth monitoring and prediction will assist users in making informed decisions based on the data. Furthermore, the development of automated forecasting and prediction systems for Earth monitoring and prediction applications should be explored. This way, KEMPS can offer time-applicable, data-based insights and capacity for environmental modifications and forecasts. KEMPS aims to enhance our knowledge of Earth's environmental kingdom, count on changes, and enhance our reaction to global environmental threats.",
        "affiliation_name": "Panimalar Engineering College",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Challenges and opportunities of machine learning in the financial sector",
        "paper_author": "Kour M.",
        "publication": "Algorithmic Approaches to Financial Technology: Forecasting, Trading, and Optimization",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "In the field of finance, machine learning has become a potent instrument that is transforming conventional methods of data analysis, decision-making, and risk management. This study examines how machine learning techniques are applied in the financial sector, discussing the challenges and opportunities of machine learning in the financial sector. Machine learning algorithms have been successfully used in fields including stock market forecasting, credit risk assessment, fraud detection, algorithmic trading, and portfolio optimization by utilising enormous volumes of financial data. However, issues with model robustness, interpretability, data quality, and regulatory compliance continue to be major roadblocks. By analyzing the applications, identifying challenges, and exploring opportunities for further development, this chapter seeks to contribute to the understanding and advancement of machine learning in the financial sector.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "An early warning system for predicting earthquakes",
        "paper_author": "Gnanasekaran T.",
        "publication": "Novel AI Applications for Advancing Earth Sciences",
        "citied_by": "8",
        "cover_date": "2023-12-29",
        "Abstract": "Earthquakes have long pose a vast danger to human existence and infrastructure. Over time, sizeable studies have been performed in the field of earthquake prediction, mainly on the improvement of an early warning machine. This essay aims to discover the background of earthquake prediction, the want for an early warning system, and the advancements made in this vicinity to mitigate the impact of seismic occasions. This chapter offers the development of a complicated and reliable early warning machine that utilizes a combination of seismic information analysis and device learning techniques. The goals of an early warning system for predicting earthquakes are to offer timely statistics to permit suitable actions, reduce the lack of existence and assets, and foster resilience in affected groups. The advancements in era and studies have provided us with the gear and expertise essential to construct a robust and reliable system that can save limitless lives and limit harm to infrastructure.",
        "affiliation_name": "Panimalar Engineering College",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Quantum computing for dengue fever outbreak prediction: Machine learning and genetic hybrid algorithms approach",
        "paper_author": "Chinnathambi D.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "5",
        "cover_date": "2023-12-29",
        "Abstract": "Dengue virus infection originates from the Aedes mosquito species. The authors propose a novel para¬digm to revolutionize dengue fever detection and recommendation systems by leveraging the potential of quantum computing. Using meteorological data and past dengue cases, they create a prediction frame¬work that goes beyond traditional constraints. Quantum machine learning methods are proposed for discovering hidden patterns within enormous datasets, allowing them to identify detailed relationships between environmental conditions and illness occurrences. Traditional machine learning algorithms are all part of our strategy. Quantum optimization techniques further optimize these models, enhancing predictive accuracy while minimizing resource consumption. As we navigate challenges such as data integrity, model validation, and quantum hardware constraints, interdisciplinary collaboration between epidemiologists, quantum scientists, and healthcare experts becomes paramount. The analytical results from data show improvement in more cases of dengue prediction in the various districts of Tamil Nadu.",
        "affiliation_name": "Adhiparasakthi Engineering College",
        "affiliation_city": "Melmaruvathur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Implementation of artificial intelligence in human resource management in Asia-Pacific",
        "paper_author": "Thakur A.",
        "publication": "Exploring the Intersection of AI and Human Resources Management",
        "citied_by": "3",
        "cover_date": "2023-12-29",
        "Abstract": "The amalgamation of pioneering technologies such as artificial intelligence in the human resources (HR) department has revolutionized the conduct of businesses nowadays. The inclusion of AI automates the organization's processes, benefiting the administration. Artificial neural networks, fuzzy logic, expert systems, data mining, machine learning, and genetic algorithms are a few of the techniques for the implementation of AI in HR. The chapter contemplates the role and benefits of artificial intelligence in organizations in the Asia-Pacific region to enhance the efficiency and effectiveness of human resource functions. It emphasizes the market players and use cases in the Asia-Pacific, illustrating the decision-making support solutions to deliver high-end value and profitability. This study also focuses on the trends and challenges in the implementation of AI in organizations to discover new potential and strategize for the future.",
        "affiliation_name": "University of Petroleum and Energy Studies",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Sensory intelligenceintegrating MBA touch into earth observation systems for enhanced machine learning",
        "paper_author": "Saravanan V.",
        "publication": "Novel AI Applications for Advancing Earth Sciences",
        "citied_by": "9",
        "cover_date": "2023-12-29",
        "Abstract": "Sensory intelligence is the capacity of machines to procedure information from their outside and inner environment through the use of sensory fact inputs and making use of system getting-to-know algorithms. This chapter focuses on integrating touch into Earth remark systems to extend the functionality of machines and beautify machine mastering. Standard, the mixing of touch into earth observation systems, presents a way for machines to emerge as more intelligent and higher apprehend and interact with their environment. Machines are capable of soaking up an extra amount of sensory facts and using it to enhance the gadget, studying algorithms to create accurate and reliable fashions. The consequences of this era are some distance-achieving and allow for improved tracking, prediction, and decision-making. With advances in system studying, artificial intelligence, and robotics, the blessings of incorporating touch into earth commentary structures will only keep growing and become more treasured.",
        "affiliation_name": "RMK Engineering College",
        "affiliation_city": "Kavaraipettai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Applications of machine learning in education and skill developments",
        "paper_author": "SivaPadmini P.",
        "publication": "Facilitating Global Collaboration and Knowledge Sharing in Higher Education With Generative AI",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The integration of machine learning (ML) techniques in education and skill development has revolutionized traditional teaching and learning paradigms. This chapter explores transformative applications of ML in education and skill development, focusing on experimental approaches to enhance learning outcomes and skill acquisition. It reviews literature on ML-driven personalized learning, intelligent tutoring systems, educational data mining, and predictive analytics, while discussing challenges and ethical considerations in implementing ML in educational settings. This chapter explores experimental methodologies for evaluating the effectiveness of ML-driven interventions, analyzing case studies and real-world examples. It highlights the design, implementation, and outcomes of these experiments, providing insights into ML's impact on student engagement, knowledge retention, skill advancement, and overall educational quality.",
        "affiliation_name": "Panimalar Engineering College",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Explaining the challenges of accountability in machine learning systems beyond technical obstacles",
        "paper_author": "Palvadi S.K.",
        "publication": "Quantum Innovations at the Nexus of Biomedical Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The ability to make a note regarding machine learning systems decisions for people is becoming increas¬ingly sought after, particularly in situations where decisions have significant repercussions for those affected and where capability in terms of maintaining is required. To increase comprehension based on referred to as \"black box\" mechanism, explaining ability is frequently cited as a technical obstacle in the design of ML systems and decision procedures. The quantities that ML systems aim to optimize must be specified by their users. This leads to the revealing of policy trade-offs that may have previously been hidden or implicit. Important decisions, as well as judgments, help what may need to be explicitly discussed in public debate as ML's use in policy expands.",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Development and application of machine learning algorithms for sentiment analysis in digital manufacturing: A pathway for enhanced customer feedback",
        "paper_author": "Jain V.",
        "publication": "Emerging Technologies in Digital Manufacturing and Smart Factories",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "Customer input has increased as digital manufacturing and smart factories advance. However, standard analysis methods struggle to turn this feedback into useful insights. This research study examined the use of machine learning (ML) sentiment analysis algorithms to improve digital manufacturing customer feedback interpretation. Machine learning, sentiment analysis, and digital industrialization theories underpin the research. Sentiment analysis may reveal nuanced consumer feedback insights that traditional methods miss, according to customer experience management and complex data analytics theories. A specially constructed ML system for sentiment analysis was used to real-world customer feedback data from numerous digital manufacturing enterprises in a case study. This method classified feedback sentiment using natural language processing. The program picked up small changes in client emotions that previous methods missed. These findings imply that machine learning-based sentiment analysis improves digital manufacturing customer feedback interpretation.",
        "affiliation_name": "Sharda University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Fortifying the digital forge: Unleashing cybersecurity in the interconnected world of digital manufacturing",
        "paper_author": "Dodiya K.R.",
        "publication": "Emerging Technologies in Digital Manufacturing and Smart Factories",
        "citied_by": "3",
        "cover_date": "2023-12-29",
        "Abstract": "In our interconnected world, cybersecurity is paramount due to IoT, cloud computing, and automation's impact on manufacturing. This chapter underscores digital manufacturing's dependence on interconnected systems and cloud infrastructure, acknowledging risks like data breaches, IP theft, and operational disruptions. It advocates a comprehensive cybersecurity approach encompassing technical measures, organizational policies, staff training, and incident response. The chapter delves into threats like malware, phishing, ransomware, and supply chain attacks, emphasizing continuous monitoring, threat intelligence, and vulnerability management. Additionally, it explores emerging trends like AI and machine learning in cybersecurity, legacy system security, and collaborative efforts among industry players, government agencies, and cybersecurity experts to safeguard digital manufacturing. This chapter aids manufacturers, security experts, and researchers in building secure systems in our connected digital landscape.",
        "affiliation_name": "Gujarat University",
        "affiliation_city": "Gujarat",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine Learning-Based Predictive Model of Aortic Valve Replacement Modality Selection in Severe Aortic Stenosis Patients",
        "paper_author": "Chokesuwattanaskul R.",
        "publication": "Medical sciences (Basel, Switzerland)",
        "citied_by": "2",
        "cover_date": "2023-12-29",
        "Abstract": "The current recommendation for bioprosthetic valve replacement in severe aortic stenosis (AS) is either surgical aortic valve replacement (SAVR) or transcatheter aortic valve replacement (TAVR). We evaluated the performance of a machine learning-based predictive model using existing periprocedural variables for valve replacement modality selection. We analyzed 415 patients in a retrospective longitudinal cohort of adult patients undergoing aortic valve replacement for aortic stenosis. A total of 72 clinical variables including demographic data, patient comorbidities, and preoperative investigation characteristics were collected on each patient. We fit models using LASSO (least absolute shrinkage and selection operator) and decision tree techniques. The accuracy of the prediction on confusion matrix was used to assess model performance. The most predictive independent variable for valve selection by LASSO regression was frailty score. Variables that predict SAVR consisted of low frailty score (value at or below 2) and complex coronary artery diseases (DVD/TVD). Variables that predicted TAVR consisted of high frailty score (at or greater than 6), history of coronary artery bypass surgery (CABG), calcified aorta, and chronic kidney disease (CKD). The LASSO-generated predictive model achieved 98% accuracy on valve replacement modality selection from testing data. The decision tree model consisted of fewer important parameters, namely frailty score, CKD, STS score, age, and history of PCI. The most predictive factor for valve replacement selection was frailty score. The predictive models using different statistical learning methods achieved an excellent concordance predictive accuracy rate of between 93% and 98%.",
        "affiliation_name": "King Chulalongkorn Memorial Hospital",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "College Translation Teaching in the Era of Artificial Intelligence: Challenges and Solutions",
        "paper_author": "Li F.",
        "publication": "Journal of Higher Education Theory and Practice",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "AI-powered translation technology has greatly improved machine translation quality, posing three major challenges to college translation teaching: students’ perceived anxiety towards translation learning, their dependency on MT technology to complete translation tasks, and traditional teaching assessment methods being rendered ineffective. In response to these challenges, this article proposes that translation instructors pass on to students knowledge concerning MT to reduce their anxiety and turn stress into motivation and help them develop scientifically sound strategies for the use of MT technology to further reduce their anxiety while mitigating their excessive dependency on it. Furthermore, classroom teaching should be reformed by introducing “flipped learning” to ensure that these strategies are implemented under the supervision and guidance of the instructors. The teaching assessment should also be changed to regulate students’ use of the strategies outside the classroom, while at the same time eliminating the adverse effects brought about by MT technology on teaching assessment.",
        "affiliation_name": "Queen's University Belfast",
        "affiliation_city": "Belfast",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Design of Recirculating Aquaculture Monitoring System Based on Internet of Thing and Machine Learning Algorithms",
        "paper_author": "Shodiq M.N.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "Recirculating Aquaculture Systems is a fishery production system that reprocesses water used to meet water quality requirements for aquaculture activities. Several ways to improve water quality are by applying aeration, circulation, and controlling temperature properly. In this research, a system will be developed to monitor the quality of water quality in fishponds with recirculating aquaculture system (RAS) technology. The system consists of smart sensor modules supporting modularity, intelligent aeration system for controlling system, local network system, cloud computing system. Apart from that, the condition of the water environment will be visualized using mobile-based multidimensional data visualization technology. This visualization serves as the delivery of information or knowledge base. Thus, this system is able to anticipate the disruption of cultivation growth. This can also be monitored in real time, maintain the condition of the cultivation environment in order to be maintained according to the quality standards of aquaculture water, and obtain more optimal yields. This study aims to develop a product in the form of a prototype tool that is able to monitor and monitor water quality conditions automatically in order to be able to maintain the quality requirements of brackish water for cultivation using Artificial Intelligence of Thing (AIoT) technology.",
        "affiliation_name": "State Polytechnic of Banyuwangi",
        "affiliation_city": "Banyuwangi",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Association of Serum Liver Enzymes with Brain Amyloidopathy and Cognitive Performance",
        "paper_author": "Han S.W.",
        "publication": "Journal of Alzheimer's Disease Reports",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "Background: Alzheimer's disease (AD) is characterized by amyloid-β (Aβ) plaque accumulation and neurofibrillary tangles in the brain. Emerging evidence has suggested potential interactions between the brain and periphery, particularly the liver, in regulating Aβ homeostasis. Objective: This study aimed to investigate the association of serum liver enzymes with brain amyloidopathy and cognitive performance in patients with complaints of cognitive decline. Methods: A total of 1,036 patients (mean age 74 years, 66.2% female) with subjective cognitive decline, mild cognitive impairment, AD dementia, and other neurodegenerative diseases were included using the Smart Clinical Data Warehouse. Amyloid positron emission tomography (PET) imaging, comprehensive neuropsychological evaluations, and measurements of liver enzymes, including aspartate aminotransferase (AST), alanine aminotransferase (ALT), alkaline phosphatase, total bilirubin, and albumin, were assessed. After propensity score matching, logistic and linear regression analyses were used to investigate the associations between liver enzymes, amyloid status, and cognitive performance. Additionally, a machine learning approach was used to assess the classification performance of liver enzymes in predicting amyloid PET positivity. Results: Lower ALT levels and higher AST-to-ALT ratios were significantly associated with amyloid PET positivity and AD diagnosis. The AST-to-ALT ratio was also significantly associated with poor memory function. Machine learning analysis revealed that the classification performance of amyloid status (AUC = 0.642) for age, sex, and apolipoprotein E ϵ4 carrier status significantly improved by 6.2% by integrating the AST-to-ALT ratio. Conclusions: These findings highlight the potential association of liver function on AD and its potential as a diagnostic and therapeutic implications.",
        "affiliation_name": "Seoul National University Bundang Hospital",
        "affiliation_city": "Seongnam",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "4th International Conference on Engineering and Technology for Sustainable Development, ICET4SD 2021",
        "paper_author": "NA",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "The proceedings contain 67 papers. The topics discussed include: a proposed prototype of TRIZ mobile application in business and management; life cycle cost of mobility electrification with renewable energy in an off-grid rural area: the Karya Jadi Village case in Indonesia; design of recirculating aquaculture monitoring system based on Internet of Thing and machine learning algorithms; state transition diagrams for business process flows testing; crowdfunding in Indonesia: the use of data mining to predict success and failure (a case study); the effect of loading type, anchoring type, and material selection on a MEMS switch design; analysis of the influence of ERP systems on net benefit using PLS-SEM in higher education institutions; and implementation of support vector machine (SVM) based on particle swarm optimization (PSO) with synthetic minority over-sampling technique (SMOTE) on tweet data.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Ontologies in the era of large language models - a perspective",
        "paper_author": "Neuhaus F.",
        "publication": "Applied Ontology",
        "citied_by": "10",
        "cover_date": "2023-12-29",
        "Abstract": "The potential of large language models (LLM) has captured the imagination of the public and researchers alike. In contrast to previous generations of machine learning models, LLMs are general-purpose tools, which can communicate with humans. In particular, they are able to define terms and answer factual questions based on some internally represented knowledge. Thus, LLMs support functionalities that are closely related to ontologies. In this perspective article, I will discuss the consequences of the advent of LLMs for the field of applied ontology.",
        "affiliation_name": "Otto-von-Guericke-Universität Magdeburg",
        "affiliation_city": "Magdeburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Toward the consolidation of a multi-metric-based journal ranking and categorization system for computer science subject areas",
        "paper_author": "Hameed A.",
        "publication": "Profesional de la Informacion",
        "citied_by": "2",
        "cover_date": "2023-12-29",
        "Abstract": "The evaluation of scientific journals poses challenges owing to the existence of various impact measures. This is because journal ranking is a multidimensional construct that may not be assessed effectively using a single metric such as an impact factor. A few studies have proposed an ensemble of metrics to prevent the bias induced by an individual metric. In this study, a multi-metric journal ranking method based on the standardized average index (SA index) was adopted to develop an extended standardized average index (ESA index). The ESA index utilizes six metrics: the CiteScore, Source Normalized Impact per Paper (SNIP), SCImago Journal Rank (SJR), Hirsh index (H-index), Eigenfactor Score, and Journal Impact Factor from three well-known databases (Scopus, SCImago Journal & Country Rank, and Web of Science). Experiments were conducted in two computer science subject areas: (1) artificial intelligence and (2) computer vision and pattern recognition. Comparing the results of the multi-metric-based journal ranking system with the SA index, it was demonstrated that the multi-metric ESA index exhibited high correlation with all other indicators and significantly outperformed the SA index. To further evaluate the performance of the model and determine the aggregate impact of bibliometric indices with the ESA index, we employed unsupervised machine learning techniques such as clustering coupled with principal component analysis (PCA) and t-distributed stochastic neighbor embedding (t-SNE). These techniques were utilized to measure the clustering impact of various bibliometric indicators on both the complete set of bibliometric features and the reduced set of features. Furthermore, the results of the ESA index were compared with those of other ranking systems, including the internationally recognized Scopus, SJR, and HEC Journal Recognition System (HJRS) used in Pakistan. These comparisons demonstrated that the multi-metric-based ESA index can serve as a valuable reference for publishers, journal editors, researchers, policymakers, librarians, and practitioners in journal selection, decision making, and professional assessment.",
        "affiliation_name": "The Islamia University of Bahawalpur",
        "affiliation_city": "Bahawalpur",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Developing a Machine Learning Algorithm to Predict the Probability of Medical Staff Work Mode Using Human-Smartphone Interaction Patterns: Algorithm Development and Validation Study",
        "paper_author": "Chen H.H.",
        "publication": "Journal of medical Internet research",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "BACKGROUND: Traditional methods for investigating work hours rely on an employee's physical presence at the worksite. However, accurately identifying break times at the worksite and distinguishing remote work outside the worksite poses challenges in work hour estimations. Machine learning has the potential to differentiate between human-smartphone interactions at work and off work. OBJECTIVE: In this study, we aimed to develop a novel approach called \"probability in work mode,\" which leverages human-smartphone interaction patterns and corresponding GPS location data to estimate work hours. METHODS: To capture human-smartphone interactions and GPS locations, we used the \"Staff Hours\" app, developed by our team, to passively and continuously record participants' screen events, including timestamps of notifications, screen on or off occurrences, and app usage patterns. Extreme gradient boosted trees were used to transform these interaction patterns into a probability, while 1-dimensional convolutional neural networks generated successive probabilities based on previous sequence probabilities. The resulting probability in work mode allowed us to discern periods of office work, off-work, breaks at the worksite, and remote work. RESULTS: Our study included 121 participants, contributing to a total of 5503 person-days (person-days represent the cumulative number of days across all participants on which data were collected and analyzed). The developed machine learning model exhibited an average prediction performance, measured by the area under the receiver operating characteristic curve, of 0.915 (SD 0.064). Work hours estimated using the probability in work mode (higher than 0.5) were significantly longer (mean 11.2, SD 2.8 hours per day) than the GPS-defined counterparts (mean 10.2, SD 2.3 hours per day; P<.001). This discrepancy was attributed to the higher remote work time of 111.6 (SD 106.4) minutes compared to the break time of 54.7 (SD 74.5) minutes. CONCLUSIONS: Our novel approach, the probability in work mode, harnessed human-smartphone interaction patterns and machine learning models to enhance the precision and accuracy of work hour investigation. By integrating human-smartphone interactions and GPS data, our method provides valuable insights into work patterns, including remote work and breaks, offering potential applications in optimizing work productivity and well-being.",
        "affiliation_name": "Cornell Ann S. Bowers College of Computing and Information Science",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Potential honey bee (Apis mellifera) allergens associated with IgE-mediated allergy- An In-silico study",
        "paper_author": "Anwar S.",
        "publication": "Cellular and Molecular Biology",
        "citied_by": "0",
        "cover_date": "2023-12-29",
        "Abstract": "Allergies due to honeybee venom (HBV) are reported to be the second most common form of allergy to Hymenoptera venom that occurs after being stung. Indeed, 15-20% of people test IgE positive after being stung. However, accurate data on the incidence of honey bee allergens is missing and estimated to be less than 0.001%. Beekeeping is an ancient and widely practiced activity across the Kingdom of Saudi Arabia. Still, studies on the allergenic effect of the different subspecies of honey bees are very rare in Saudi Arabia. Hence, in this study, using the In-silico approach, we aimed to study and evaluate the effect of allergens from honey bees in Ha’il City, Saudi Arabia on IgE-mediated allergies. A list of potential allergens from Apis mellifera was prepared, and the 3D structure was prepared using the SWISS-MODEL web server and the PDB database was used for retrieving the structure of the immunoglobulin E- fragment antigen-binding (IgE-Fab) region. Molecular docking (clusPro webserver) and molecular dynamics (Schrödinger) results revealed that the B2D0J5 protein from Apis mellifera might be the key protein associated with IgE-mediated allergic response. Overall, the identified knowledge can be used for exploring prophylactic vaccine candidates and improving the diagnosis of allergic reactions to honey bees in the Ha’il region of Saudi Arabia.",
        "affiliation_name": "Apeejay Stya University",
        "affiliation_city": "Gurugram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "CT-based radiomics analysis to predict local progression of recurrent colorectal liver metastases after microwave ablation",
        "paper_author": "Hu H.",
        "publication": "Medicine (United States)",
        "citied_by": "3",
        "cover_date": "2023-12-29",
        "Abstract": "The objective of this study is to establish and validate a radiomics nomogram for prediction of local tumor progression (LTP) after microwave ablation (MWA) for recurrent colorectal liver metastases (CRLM) after hepatic resection. We included 318 consecutive recurrent CRLM patients (216 of training while 102 of validation cohort) with contrast-enhanced computerized tomography images treated with MWA between January 2014 and October 2018. Support vector machine-generated radiomics signature was incorporated together with clinical information to establish a radiomics nomogram. Our constructed radiomics signature including 15 features (first-order intensity statistics features, shape and size-based features, gray level size zone/dependence matrix features) performed well in assessing LTP for both cohorts. With regard to its predictive performance, its C-index was 0.912, compared to the clinical or radiomics models only (c-statistic 0.89 and 0.75, respectively) in the training cohort. In the validation cohort, the radiomics nomogram had better performance (area under the curve = 0.89) compared to the radiomics and clinical models (0.85 and 0.69). According to decision curve analysis, our as-constructed radiomics nomogram showed high clinical utility. As revealed by survival analysis, LTP showed worse progression-free survival (3-year progression-free survival 42.6% vs 78.4%, P < .01). High-risk patients identified using this radiomics signature exhibited worse LTP compared with low-risk patients (3-year LTP 80.2% vs 48.6%, P < .01). A radiomics-based nomogram of pre-ablation computerized tomography imaging may be the precious biomarker model for predicting LTP and personalized risk stratification for recurrent CRLM after hepatic resection treated by MWA.",
        "affiliation_name": "Renji Hospital",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of artificial intelligence (machine learning) in additive manufacturing, bio-systems, bio-medicine, and composites",
        "paper_author": "Monfred V.",
        "publication": "Additive Manufacturing for Biocomposites and Synthetic Composites",
        "citied_by": "1",
        "cover_date": "2023-12-29",
        "Abstract": "NA",
        "affiliation_name": "Islamic Azad University, Zanjan Branch",
        "affiliation_city": "Zanjan",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Developing an Artificial Intelligence Solution to Autosegment the Edentulous Mandibular Bone for Implant Planning",
        "paper_author": "Moufti M.A.",
        "publication": "European Journal of Dentistry",
        "citied_by": "11",
        "cover_date": "2023-12-29",
        "Abstract": "Objective Dental implants are considered the optimum solution to replace missing teeth and restore the mouth's function and aesthetics. Surgical planning of the implant position is critical to avoid damage to vital anatomical structures; however, the manual measurement of the edentulous (toothless) bone on cone beam computed tomography (CBCT) images is time-consuming and is subject to human error. An automated process has the potential to reduce human errors and save time and costs. This study developed an artificial intelligence (AI) solution to identify and delineate edentulous alveolar bone on CBCT images before implant placement. Materials and Methods After obtaining the ethical approval, CBCT images were extracted from the database of the University Dental Hospital Sharjah based on predefined selection criteria. Manual segmentation of the edentulous span was done by three operators using ITK-SNAP software. A supervised machine learning approach was undertaken to develop a segmentation model on a U-Net convolutional neural network (CNN) in the Medical Open Network for Artificial Intelligence (MONAI) framework. Out of the 43 labeled cases, 33 were utilized to train the model, and 10 were used for testing the model's performance. Statistical Analysis The degree of 3D spatial overlap between the segmentation made by human investigators and the model's segmentation was measured by the dice similarity coefficient (DSC). Results The sample consisted mainly of lower molars and premolars. DSC yielded an average value of 0.89 for training and 0.78 for testing. Unilateral edentulous areas, comprising 75% of the sample, resulted in a better DSC (0.91) than bilateral cases (0.73). Conclusion Segmentation of the edentulous spans on CBCT images was successfully conducted by machine learning with good accuracy compared to manual segmentation. Unlike traditional AI object detection models that identify objects present in the image, this model identifies missing objects. Finally, challenges in data collection and labeling are discussed, together with an outlook at the prospective stages of a larger project for a complete AI solution for automated implant planning.",
        "affiliation_name": "University of Sharjah",
        "affiliation_city": "Sharjah",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Machine Learning Application for Early Power Analysis Accuracy Improvement: A Case Study for Nets Switching Power",
        "paper_author": "Chentouf M.",
        "publication": "Journal of Integrated Circuits and Systems",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "In the quest for precise power estimation during the early phases of design, the absence of a Standard Parasitic Exchange File (SPEF) with interconnect R/C values poses a significant hurdle. To address this challenge, we introduce a Machine Learning (ML) approach designed to predict net power metrics at the Gate Level without relying on SPEF. Net features are extracted from Electronic Design Automation (EDA) tools, facilitating the training of models for the prediction of Net Switching Power. Notably, the Random Forest model emerges as the most effective, achieving high accuracy by reducing power error from around 20% to a mere 0.1%. Furthermore, our innovative approach enhances efficiency by bypassing the traditional SPEF generation process. This results in a significant 5x reduction in runtime compared to the conventional flow, with a notable decrease from 163.6 minutes to just 33.7 minutes. This substantial acceleration is achieved by skipping the time-intensive synthesis and physical design steps required for SPEF. In summary, our ML-based methodology not only achieves swift and accurate power estimation in the early stages of design but also liberates the process from the constraints of SPEF dependency. This marks a transformative shift in the landscape of power estimation methodologies.",
        "affiliation_name": "Rabat Information Technology Center",
        "affiliation_city": "Rabat",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Data-driven modeling of microstrip reflectarray unit element design",
        "paper_author": "Mahouti P.",
        "publication": "Advanced Metamaterials for Engineers",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Reflectarray antennas (RA) offer a viable alternative to traditional antenna systems, merging the benefits of parabolic reflector antennas and phased array antennas. These antennas comprise a planar array of radiating elements stimulated by a feed antenna, allowing for precise radiation pattern manipulation. Despite their efficacy, their design involves intricate interactions between various variables, posing significant challenges. However, recent advancements in artificial intelligence (AI) and machine learning (ML) techniques are now being applied to circumvent these difficulties. Surrogate modelling, a method incorporating AI, enables the creation of computationally efficient approximations of complex systems like RA. Using ML techniques like regression, artificial neural networks, support vector machines, and Gaussian process regression, these surrogate models predict the RA's performance across different design parameters, thus enabling efficient exploration and optimisation of the design space. The integration of AI and ML methodologies can enhance RA design through computational efficiency, efficient design space exploration, and adaptive and data-driven design, potentially improving the performance and applicability of RAs in modern communication systems.",
        "affiliation_name": "Iskenderun Technical University",
        "affiliation_city": "Iskenderun",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Microwave metamaterial sensors",
        "paper_author": "Bakir M.",
        "publication": "Advanced Metamaterials for Engineers",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "This chapter provides an overview of the current state of research in the field of microwave metamaterial sensors, covering several types of sensors including microfluidic sensors, THz metamaterial sensors, metamaterial absorber-based sensors, and novel approaches such as machine learning or three-dimensional metamaterial-based sensors.",
        "affiliation_name": "Bozok Üniversitesi",
        "affiliation_city": "Yozgat",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "The Yield Improvement of Three-state Products from Biomass Pyrolysis Based on Machine Learning",
        "paper_author": "Yi Z.",
        "publication": "Chemistry and Industry of Forest Products",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "By mining the experimental data in the literatures of fast pyrolysis of lignocellulosic biomass in a bubbling fluidized bed and establishing a random forest (RF) regression model, the yield of bio-oil, biochar, and gas via biomass pyrolysis was predicted based on biomass feedstock characteristics and pyrolysis conditions. Fifteen feature variables were sorted out from five key factors influencing the distribution of biomass pyrolysis products, and seven models were obtained by combining the input variables. All models showed good prediction performance for the three-state products from biomass pyrolysis, with a regression coefficient(R2) greater than 0. 9. Model 6 had the fewest input variables and the highest accuracy, with R2 values of 0. 942 8, 0. 956 1, and 0. 939 1 for the yield predictions of biochar, bio-oil, and biomass pyrolysis gas, and the root mean square errors (RMSE) were 2. 679 1, 2. 939 5, and 3. 108 3, respectively. Contribution analysis of the models revealed that pyrolysis conditions(Ⅴ) were the most important factors affecting the pyrolysis products yield, with contributions degree of 0. 332 7, 0. 220 4, and 0. 214 7 for biochar, bio-oil, and gas yield predictions, respectively. Partial dependence plots(PDP) combined with the distribution boxplots analysis of each feature variable showed that pyrolysis temperature (HT), lignin mass fraction (Lig), and particle size (PS) were the main factors affecting biochar yield. Bio-oil and biomass pyrolysis gas yields were determined by HT, cellulose mass fraction(Cel), hemicellulose mass fraction(Hem), feed rate(FR), and gas flow rate(GFR), which were less affected by Lig and PS. The bio-oil yield could be improved by selecting biomass feedstock with high-quality fractions of cellulose and hemicellulose and increasing gas flow rate appropriately. In addition, the regression models of extreme gradient boosting(XGBoost), support vector machine(SVM), and artificial neural network(ANN) were established, which were compared with the RF regression model. The RF model showed the highest accuracy and good generalization ability for predicting the yield of the three-state products. The research findings promoted a comprehensive understanding of the biomass pyrolysis process and provided theoretical guidance for the control of the of the three-state products yield in biomass fast pyrolysis.",
        "affiliation_name": "Hunan University of Arts and Science",
        "affiliation_city": "Changde",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Building intelligent systems using machine learning and deep learning: Security, applications and its challenges",
        "paper_author": "Sahoo A.K.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "The primary objective of this book is to provide insight into the design and development of the intelligent system. The proposed book volume mainly focuses on a machine learning and deep learning-based intelligent system that would bring out the latest trends in the field of tourism, healthcare, agriculture, etc. This book provides security solutions for the intelligent system in different applications. The technological gaps between the traditional system and intelligent system are mentioned in the book, which will help in better understanding for the implementation of the intelligent system using machine learning (ML) and deep learning (DL) approaches. Although ML and DL have made great achievements in intelligent systems, there are still substantial open challenges that have not been fully studied. The main open challenges of using ML and DL in intelligent systems are: (i) Better performance of the system (ii) Time complexity of the jobs running inside an intelligent system (iii) Managing overload tasks (iv) Providing security towards the system. This book will definitely help academicians, researchers and industry people towards the security, design and development of the intelligent system.",
        "affiliation_name": "NIST University",
        "affiliation_city": "Berhampur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A comparative analysis of machine learning algorithms on intrusion detection systems",
        "paper_author": "Vijayan R.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Internet usage is quite high, and it is also incredibly important in these times. The Internet has been used for domain transactions, file transfers, and a variety of other operations. In addition to these responsibilities, private data has been sent via the internet through various websites as needed. In the middle of transfers and transactions, these websites, online apps, and the internet must be on the watch for assaults. In technical words, it refers to them as packets, and large packets are transferred across an internet network in a second. Furthermore, the likelihood of delivering malicious packets is great. A mechanism is necessary at crucial spots to identify these attacks. So, as part of this study, the proposed system uses machine learning techniques to detect any potentially harmful network activities. These packets might include data that is encrypted or not. The essential concept here is that the system detects any interruption in the network, excluding the decryption of packets. For the implementation, Wireshark, Weka tools, the Anaconda framework, Jupiter, and the Python language have been used in this proposed work. Here, we applied four different algorithms, like Naive Bayes, SVM, KNN, and Random Forest. The accuracy of each algorithm is found, which will prove which algorithm is better for the detection of intrusion.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "An analysis of optical character recognition-based machine translation for low resource languages",
        "paper_author": "Mahesha P.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Natural Language Processing (NLP) is a sub field under artificial intelligence that deals with the communication languages between computers and humans. A major process in NLP is machine translation which is the conversion of input text from one source language to target language without affecting the meaning. The input and output for NLP is natural language text. To implement the system, a new model for machine translation using Optical Character Recognition (OCR) is employed. The system also uses Bidirectional Recurrent Neural Network (BRNN) and dictionary-based approaches for English to Kannada and Marathi language translation. These two low resource languages are spoken in Indian state of Karnataka and Maharashtra respectively. The efficiency of the system is achieved through the improvement of accuracy and learning by comparing with different datasets and inputs.",
        "affiliation_name": "JSS Science and Technology University",
        "affiliation_city": "Mysore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The detection and prevention of phishing threats in OSN using machine learning techniques",
        "paper_author": "Samal S.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "The widespread usage of the web increases the number of social media and online social networks (OSNs) users rapidly. Most of the users of OSNs are unaware of security issues such as privacy violations, identity theft, sexual harassment, etc. Recent studies have shown that OSNs users willingly provide personal information about themselves, including phone number, birth details, educational background, mail id, relationship status, and even present location. The mistreating of this personal information has the potential to hurt consumers both online and offline. When children are the users, these risks increase in severity and easily they become the victim of it. Among the different OSNs cyber threats, phishing is the leading threat which deceives the internet users to reveal their secret information and affects the online users' overall wellbeing and the safety of children in particular. In this chapter, we provide a comprehensive analysis of the various OSNs security and privacy threats and their detection and prevention along with predicted the phishing threats by implementing the approaches of machine learning. Also, a brief summary of current resolutionwhich can better defend the users' of OSN privacy, safety, and protection is discussed. The experimental result demonstrates that after implementing the feature selection methods (FSM) like Information Gain (IG), Chi-square and Anova test on the phishing dataset, the significant features so created able to evaluate the machine learning classifiers such as k-Nearest Neighbor (KNN), Logistic Regression (LR), Decision Tree (DT) and Naive Bayes (NB) efficiently and obtained the performance in terms of accuracy as 99.7% in KNN classifiers for detecting the phishing threat.",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A novel sigmoid butterfly optimization deep learning model for big data classification",
        "paper_author": "Umanesan R.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Big data has gained popularity among the general population and business organizations in recent years. Deep learning and machine learning models, which have recently become available, can be used to analyze large data more effectively. Many different fields have recently begun working with large datasets that contain numerous sets of characteristics. The goal of feature selection models is to minimize noise, repeating features, and undesirable traits that reduce the effectiveness of categorization. It is hard to filter out effective findings for huge datasets from Conventional feature selection (FS) techniques. As far as big data analytics is concerned, FS is essential to handle huge datasets. Big data comprises many characteristics and necessitates a lot of computation; as a result, feature selection approaches using metaheuristic optimization algorithms can be employed to choose the optimal set of features, improving classification performance. Effective feature selection methods can be created using metaheuristic optimization algorithms. In this approach, Apache Spark environment is used to handle big data. This technique is assigned to design and implementa novel sigmoid butterfly optimization algorithm with a deep learning model. A new Sigmoid Butterfly Optimization Algorithm with Optimal Gated Recurrent Unit (SBOA-OGRU) model is suggested for classification. The SBOAOGRU strategy involves constructing a feature selection algorithm. OGRU classification model helps to group the big data. Then, Adam planner is used to tune the GRU model's hyperparameters. Additionally, the Apache Spark platform is used for efficient big data analysis. By utilizing various performance measures across several distinct aspects, the proposed model's results are validated. Additionally, a thorough comparison is made with cutting-edge techniques to demonstrate how well the suggested solutions perform. The experiment's findings showed that the suggested models performed noticeably better than the compared approaches.",
        "affiliation_name": "Vel Tech Rangarajan Dr.Sagunthala R&amp;D Institute of Science and Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Fundamental models in intelligent systems using machine learning and deep learning",
        "paper_author": "Rathi R.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "In the current scenario, we hear news about robots, Artificial Intelligence (AI), or autonomous drones. Some of them are killer drones in the military, destructions caused by AI, joblessness in the future due to robots, and statements that project a negative of AI and its effects on human lives. But there are many cases where we see the benefits of machine learning and deep learning models outweigh these drawbacks, especially in healthcare, human activity monitoring and caring, etc. Despite the vast technological growth and usage of the same, one must know the fundamental models behind such advancements. This chapter presents an overview of different primary models in intelligent systems using machine learning and deep learning. Supervised, unsupervised, and reinforcement models are the basic models that come under machine learning principles. This chapter also explains how deep learning extends these models through the interference of Artificial Neural Networks (ANN) and discusses popular and widely known architecture on deep learning using Convolutional Neural Networks (CNN). The chapter indeed explores how the different models would be useful in various realworld applications, like, computer vision, natural language processing, and robotics. Finally, in the conclusion, a discussion on some of the challenges and future benefits of intelligent systems with reputed machine learning models and models in deep learning is given.",
        "affiliation_name": "Vel Tech Rangarajan Dr.Sagunthala R&amp;D Institute of Science and Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Intelligent systems for future applications using machine learning",
        "paper_author": "Meher A.K.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Data is a collection of raw facts and figures that can be generated from various sources such as social media, health, agriculture, stock markets, weather forecasts, etc. Data from different means of communication is increasing every day, such as Facebook, Twitter, Amazon, LinkedIn, etc. Dealing with the massive amounts of data generated from these sources is now a very difficult task. So, in order to maintain the 5'V concept, we have to use modern tools to process the data. Extracting meaningful data from large amounts of data uses data processing, which uses statistical techniques and algorithms, scientific techniques, different techniques, etc. Data science is a multidisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Data science is released in the market to process large amounts of data and discover unseen patterns, gain meaningful insights, make business decisions, etc. Most of the tools used in the data science industry are Python, Machine Learning, NoSQL, MongoDB, Hadoop, Spark, etc. Fields directly or indirectly related to data science include statistical learning, machine learning, deep learning, machine learning, image processing, signal processing, natural language processing, predictive modeling, etc. If we see a trend of faster global data growth, then we have to consider data science with many tools. Data science provides a method of collecting, cleaning, integrating, analyzing, visualizing, and processing data to create data products. Due to the high availability of data, data science roles such as data scientist, data engineering, data analyst, process owner, business analyst, etc. constantly emerging. Now the demand is even greater. Data science careers are currently among the highest paying careers in the world. Due to its wide application in various industries, there is a growing demand for data scientists who can analyze complex data and communicate the results effectively.",
        "affiliation_name": "Gandhi Institute for Technological Advancement",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A novel approach for requirement-based test case prioritization using machine learning techniques",
        "paper_author": "Behera A.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Most often the entire application functionality needed to be tested out, in case there is a bug fix or change request demand from the clients or end users. Obviously considerable amount of effort and time is required to test out the entire application sanity. In such cases prioritization technique helps to overcome the limitations of regression testing employed for application sanity. Test case prioritization usually means categorically ranking some test cases higher than others. To lower the price of regression test suites and increase the effectiveness of regression testing, requirement-based test case prioritization (RTCP) is adopted by most of the research practioners to prioritize the test cases. A thorough comparative analysis of RTCP methods have been performed and found that selecting the significant factors in RTCP is a challenging task for fulfilling the objective like reducing execution time and the rate of defect detection being increased. To overcome the issues in existing studies, we have considered an additional most useful parameter 'weight' for assigning weightage to business requirement which enhances prioritized scheduling of test cases in RTCP. The purpose of this chapter is to rank the requirement-based test cases as higher priority by selecting the relevant features. For this, the machine learning classifier k-Nearest Neighbor, Decision Tree, Random Forest, Bagging, Support Vector Machine algorithms are being used to evaluate the features for the test case prioritization. The experimental result demonstrates that SVC classifier achieves the best performance among the other classifiers. Thus, early prediction of the requirement based prioritized test cases helps to reduce the cost and time required for regression testing. The experimental result convincingly demonstrates that the proposed prioritization strategy drastically increases the fault discovery rate due to weight factor.",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Deep learning for the closed loop diabetes management system",
        "paper_author": "Kalita D.",
        "publication": "Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "The prevalence of diabetes, a chronic metabolic disease, is considered to reach 463 million individuals globally. In order to improve the care for diabetes, digital health has been extensively implemented recently. To better manage this chronic disease, a tone of data has been generated as a result. Blood sugar levels rise as a result of diabetes, which damages the pancreas's beta cells and reduces the volume of insulin released. Traditionally, the levels of the blood glucose are measured with a fingerstick before manually injecting insulin to treat diabetes. Modern alternatives like insulin pumps including the continuous glucose monitoring devices, which are much simpler and more automated, are replacing them. In addition to the analyzing also improving our information of which deep learning algorithms perform very well with glycemic data, this study seeks to establish a relationship between insulin pump settings and glycemic management. This has led to the widespread adoption of deep learning process, a novel type of machine learning, which gives encouraging results. In this chapter, we have described a full extensive and detailed analysis of deep learning implementations in diabetes. After conducting a thorough literature search, it was discovered that this method is effective in three crucial areas: the detection of diabetes, glucose control, and the identification of different complications for diabetes. It should be noted that among the analyzed literature, numerous deep learning architectures and frameworks have surpassed conventional machine learning methods to attain state-of-theart performance in various numerus tasks relevant to diabetes. The inadequacy of data accessibility and the model interpretability are two significant flaws in the research that is already out there, which we highlight in the interim. These challenges can be quickly solved because of too deep learning's rapid developments and the expansion of data sources, enabling the extensive application of this technology transition in clinical contexts.",
        "affiliation_name": "S.C.B. Medical College &amp; Hospital Orissa",
        "affiliation_city": "Cuttack",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Long-Short-Term Memory Model for Fake News Detection in Nigeria",
        "paper_author": "Esan A.",
        "publication": "Ianna Journal of Interdisciplinary Studies",
        "citied_by": "6",
        "cover_date": "2023-12-28",
        "Abstract": "Background: The advent of technology allows information to be passed through the Internet at a breakneck speed and enables the involvement of many individuals in the use of different social media platforms. Propagation of fake news through the Internet has become rampant due to digitalisation, and the spread of fake news can cause irreparable damage to the victims. The conventional approach to fake news detection is time-consuming, hence introducing fake news detection systems. Existing fake news detection systems have yielded low accuracy and are unsuitable in Nigeria. Objective: This research aims to design and implement a framework for fake news detection using the Long-Short Term Memory (LSTM) model. Methodology: The dataset for the model was obtained from Nigerian dailies and Kaggle and pre-processed by removing punctuation marks and stop words, stemming, tokenisation and one hot representation. Feature extraction was done on the datasets to remove outliers. The locally acquired dataset from Nigeria was balanced using Synthetic Minority Oversampling Techniques (SMOTE) Long-Short Term Memory (LSTM), a variant of Recurrent Neural Network (RNN)-which solved the problem of losing gained knowledge and information over a long period faced by RNN-was used as the detection model This model was implemented using Python 3.9. The model detected fake news by classifying real and fake news approaches. The dataset was fed into the model, and the model classified them as either fake or real news by processing the dataset through input and hidden layers of varying numbers of neurons. accuracy F1 score and detection time were used as the evaluation metrics. The results were then compared to some selected machine learning models and a hybrid of convolutional neural networks and long short-term memory models (CNN-LSTM). Results: The result shows that the LSTM model on a balanced dataset performed best as the two news classes were accurately classified, giving an average detection accuracy of 92.86%, which took the model 0.42 seconds to detect whether news was real or fake. Also, 87.50% average detection accuracy was obtained from an imbalanced dataset. Compared to other machine learning models, SVM and CNN-LSTM gave 81.25% accuracy for imbalanced datasets and 82.14% and 78.57% for balanced datasets, respectively. Conclusion: The outcome of this research shows that the deep learning approach outperformed some machine learning models for fake news detection in terms of performance accuracy. Unique contribution: This work has contributed knowledge by employing an LSTM model for detecting Nigerian fake news using an indigenous dataset. Key Recommendation: Future research should increase the data size of indigenous datasets for fake news detection to achieve improved accuracy.",
        "affiliation_name": "Redeemer‘s University",
        "affiliation_city": "Ede",
        "affiliation_country": "Nigeria"
    },
    {
        "paper_title": "Machine Learning Tabulation Scheme for Fast Chemical Kinetics Computation",
        "paper_author": "Ebrahimi K.",
        "publication": "SAE International Journal of Engines",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "This study proposes a machine learning tabulation (MLT) method that employs deep neural networks (DNNs) to predict ignition delay and knock propensity in spark ignition (SI) engines. The commonly used Arrhenius model and Livengood-Wu integral for fast knock prediction are not accurate enough to account for residual gas species and may require adjustments or modifications to account for specific engine characteristics. Detailed kinetics modeling is computationally expensive, so the MLT approach is introduced to solve these issues. The MLT method uses precalculated thermochemical states of the mixture that are clustered based on a combustion progress variable. Hundreds of DNNs are trained with the stochastic Levenberg-Marquardt (SLM) optimization algorithm, reducing training time and memory requirements for large-scale problems. MLT has high interpolation accuracy, eliminates the need for table storage, and reduces memory requirements by three orders of magnitude. The proposed MLT approach can operate across a wider range of conditions and handle a variety of fuels, including those with complex reaction mechanisms. MLT computational time is independent of the reaction mechanism's size. It demonstrates a remarkable capability to reduce computation time by a factor of approximately 300 when dealing with complex reaction mechanisms comprising 621 species. MLT has the potential to significantly advance our understanding of complex combustion processes and aid in the design of more efficient and environmentally friendly combustion engines. In summary, the MLT approach has acceptable accuracy with less computation cost than detailed kinetics, making it ideal for fast model-based knock detection. This article presents a detailed description of the MLT method, including its workflow, challenges involved in data generation, pre-processing, data classification and regression, and integration into the engine cycle simulation. The results of the study are summarized, which includes validation against kinetics for ignition delay and engine simulation for knock angle prediction. The conclusions are presented along with future work.",
        "affiliation_name": "Gamma Technologies LLC",
        "affiliation_city": "Westmont",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Vehicle Classification System Using the Haar Wavelet Transformation Algorithm and Machine Learning",
        "paper_author": "Ghalela M.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Nowadays, there are an increasing number of vehicles that have developed, resulting in different shapes. Therefore, the variety of vehicle types in traffic flow needs to be monitored by a classification system built-in in machine learning. This vehicle classification research utilized four classes of the vehicle dataset: class 3 “Acura TL Sedan 2012”, class 14 “Audi TTS Coupe 2012”, class 106 “Ford F-450 Super Duty Crew Cab”, and class 134 “Hyundai Sonata Hybrid 2012”. This research aims to evaluate the results of vehicle type classification using the Haar wavelet transformation algorithm as a feature extraction method. The feature extraction results of the first and second levels of the Haar wavelet transformation algorithm were subsequently used as training data for the classification using Support Vector Machine (SVM) and K-Nearest Neighbor (KNN). The highest classification result on the first level of training data was in Weighted KNN and Medium SVM with 0.33%. Moreover, the highest classification of the second level of training data was in Weighted KNN with 0.66%. The highest classification result of the combination training data between the first and second levels was in Weighted KNN with 0.75%.",
        "affiliation_name": "Universitas Muhammadiyah Yogyakarta",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Caries Level Classification Based on Zernike Moment Invariant and Machine Learning",
        "paper_author": "Jusman Y.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "The teeth are one of the essential organs in the human digestive system. Teeth not only help people in the digestive process but also have a vital function for human-sense. Therefore, it is necessary to maintain dental health to avoid caries, the most common dental disease in developed countries. The most recent method to detect caries is using an X-ray machine. However, as technology has developed and advanced, diagnosing dental caries images can be performed using artificial intelligence and image processing. This study utilized four classes (1, 2, 3 and 4) of dental caries images. The raw images encompassed 347 dental caries images, divided into 314 training images and 33 testing images. This study aims to determine the feature extraction process of the Zernike Moment Invariant method and the process and results of dental caries classification with the input of extraction results classified using SVM and KNN. The classification results represented the accuracy of each SVM and KNN model. The highest accuracy of 71.9% was acquired from KNN.",
        "affiliation_name": "Universitas Muhammadiyah Yogyakarta",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Not as simple as we thought: a rigorous examination of data aggregation in materials informatics",
        "paper_author": "Ottomano F.",
        "publication": "Digital Discovery",
        "citied_by": "2",
        "cover_date": "2023-12-28",
        "Abstract": "Recent Machine Learning (ML) developments have opened new perspectives on accelerating the discovery of new materials. However, in the field of materials informatics, the performance of ML estimators is heavily limited by the nature of the available training datasets, which are often severely restricted and unbalanced. Among practitioners, it is usually taken for granted that more data corresponds to better performance. Here, we investigate whether different ML models for property predictions benefit from the aggregation of large databases into smaller repositories. To do this, we probe three different aggregation strategies prioritizing training size, element diversity, and composition diversity. For classic ML models, our results consistently show a reduction in performance under all the considered strategies. Deep Learning models show more robustness, but most changes are not significant. Furthermore, to assess whether this is a consequence of a distribution mismatch between datasets, we simulate the data acquisition process of a single dataset and compare a random selection with prioritizing chemical diversity. We observe that prioritizing composition diversity generally leads to a slower convergence toward better accuracy. Overall, our results suggest caution when merging different data sources and discourage a biased acquisition of novel chemistries when building a training dataset.",
        "affiliation_name": "Department of Materials Science &amp; Engineering",
        "affiliation_city": "Salt Lake City",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Descriptors for phase prediction of high entropy alloys using interpretable machine learning",
        "paper_author": "Zhao S.",
        "publication": "Journal of Materials Chemistry A",
        "citied_by": "8",
        "cover_date": "2023-12-28",
        "Abstract": "Phase prediction enables the rational design of high entropy alloys from a practically infinite unexplored space. However, the reliable and efficient prediction of phases remains a challenge. We establish an accurate, physically interpretable and easily accessible descriptor based two-dimensional (2D) map for phase prediction of high entropy alloys. The descriptors are constructed with an interpretable machine learning algorithm by combining empirical descriptors using arithmetic operations. We demonstrate that these descriptors lead to much greater accuracy for solid solutions or intermetallics, dual phases (FCC, face-centered-cubic and BCC, body-centered-cubic) or single phases (FCC or BCC) compared to commonly used empirical descriptors. The prediction accuracies for crystal or amorphous, and BCC or FCC reach ∼95%. Descriptors with differing length scales that have not been considered for phase prediction are proposed, providing opportunities to clarify the physics underlying the formation and stability of different phases. We validate the approach in three typical high entropy alloys systems via experimental synthesis and characterization, as well as in a group of 14 alloys belonging to 8 new systems outside the initial data. We show that the descriptors can accurately predict the phase structures.",
        "affiliation_name": "State Key Laboratory of Solidification Processing",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Rain event prediction performance based on empirical study",
        "paper_author": "Resti Y.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "The performance of prediction tasks in statistical machine learning, particularly those involving categorical variables or what is referred to as classification tasks, can be evaluated empirically using the resampling method. The multinomial naive Bayes method is a widely used technique for predicting categorical target variables due to its ability to work in high dimensions. The purpose of this study is to evaluate the performance of rain event prediction using empirical data. The proposed resampling method is k-fold cross-validation with several k. At the same time, the statistical machine learning method is multinomial naive Bayes. A high level of confidence in the prediction results on unseen data indicates a high level of prediction performance. Predicting rain events clear is highly beneficial in life, such as agriculture, plantation, aviation, shipping, fisheries, health, sports, etc. The results indicate that multinomial naive Bayes exhibit the very good predictive performance in accuracy, sensitivity, specificity, precision, and F1-score.",
        "affiliation_name": "Universitas Sriwijaya",
        "affiliation_city": "Indralaya",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Wearable Technology in Clinical Practice for Depressive Disorder.",
        "paper_author": "Fedor S.",
        "publication": "New England Journal of Medicine",
        "citied_by": "16",
        "cover_date": "2023-12-28",
        "Abstract": "Wearable Technology for Depressive Disorder Sleep patterns and physical activity can be monitored by wearable technology. The authors describe the state of the art for using data from wearable devices in diagnosing and managing depression.",
        "affiliation_name": "Northeastern University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep learning for platelet transfusion",
        "paper_author": "Li N.",
        "publication": "Blood",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "NA",
        "affiliation_name": "McMaster University",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "The Capability of Deep Learning Model to Predict Ozone Across Continents in China, the United States and Europe",
        "paper_author": "Han W.",
        "publication": "Geophysical Research Letters",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "Data-driven methods have been extensively applied to predict atmospheric compositions. Here, we explore the capability of a deep learning (DL) model to make ozone (O3) predictions across continents in China, the United States (US) and Europe. The DL model was trained and validated with surface O3 observations in China and the US in 2015–2018. The DL model was applied to predict hourly surface O3 over three continents in 2015–2022. Compared to baseline simulations using GEOS-Chem (GC) model, our analysis exhibits mean biases of 2.6 and 4.8 μg/m3 with correlation coefficients of 0.94 and 0.93 (DL); and mean biases of 3.7 and 5.4 μg/m3 with correlation coefficients of 0.95 and 0.92 (GC) in Europe in 2015–2018 and 2019–2022, respectively. The comparable performances between DL and GC indicate the potential of DL to make reliable predictions over spatial and temporal domains where a wealth of local observations for training is not available.",
        "affiliation_name": "California Institute of Technology",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Use of Artificial Intelligence in the Identification and Management of Frailty: A Scoping Review Protocol",
        "paper_author": "Karunananthan S.",
        "publication": "BMJ Open",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Introduction Rapid population ageing and associated health issues such as frailty are a growing public health concern. While early identification and management of frailty may limit adverse health outcomes, the complex presentations of frailty pose challenges for clinicians. Artificial intelligence (AI) has emerged as a potential solution to support the early identification and management of frailty. In order to provide a comprehensive overview of current evidence regarding the development and use of AI technologies including machine learning and deep learning for the identification and management of frailty, this protocol outlines a scoping review aiming to identify and present available information in this area. Specifically, this protocol describes a review that will focus on the clinical tools and frameworks used to assess frailty, the outcomes that have been evaluated and the involvement of knowledge users in the development, implementation and evaluation of AI methods and tools for frailty care in clinical settings. Methods and analysis This scoping review protocol details a systematic search of eight major academic databases, including Medline, Embase, PsycInfo, Cumulative Index to Nursing and Allied Health Literature (CINAHL), Ageline, Web of Science, Scopus and Institute of Electrical and Electronics Engineers (IEEE) Xplore using the framework developed by Arksey and O'Malley and enhanced by Levac et al and the Joanna Briggs Institute. The search strategy has been designed in consultation with a librarian. Two independent reviewers will screen titles and abstracts, followed by full texts, for eligibility and then chart the data using a piloted data charting form. Results will be collated and presented through a narrative summary, tables and figures. Ethics and dissemination Since this study is based on publicly available information, ethics approval is not required. Findings will be communicated with healthcare providers, caregivers, patients and research and health programme funders through peer-reviewed publications, presentations and an infographic. Registration details OSF Registries (https://doi.org/10.17605/OSF.IO/T54G8).",
        "affiliation_name": "Institut de Recherche Bruyère",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Supervised machine learning model to predict mortality in patients undergoing venovenous extracorporeal membrane oxygenation from a nationwide multicentre registry",
        "paper_author": "Lee H.",
        "publication": "BMJ Open Respiratory Research",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Background Existing models have performed poorly when predicting mortality for patients undergoing venovenous extracorporeal membrane oxygenation (VV-ECMO). This study aimed to develop and validate a machine learning (ML)-based prediction model to predict 90-day mortality in patients undergoing VV-ECMO. Methods This study included 368 patients with acute respiratory failure undergoing VV-ECMO from 16 tertiary hospitals across South Korea between 2012 and 2015. The primary outcome was the 90-day mortality after ECMO initiation. The inputs included all available features (n=51) and those from the electronic health record (EHR) systems without preprocessing (n=40). The discriminatory strengths of ML models were evaluated in both internal and external validation sets. The models were compared with conventional models, such as respiratory ECMO survival prediction (RESP) and predicting death for severe acute respiratory distress syndrome on VV-ECMO (PRESERVE). Results Extreme gradient boosting (XGB) (areas under the receiver operating characteristic curve, AUROC 0.82, 95% CI (0.73 to 0.89)) and light gradient boosting (AUROC 0.81 (95% CI 0.71 to 0.88)) models achieved the highest performance using EHR's and all other available features. The developed models had higher AUROCs (95% CI 0.76 to 0.82) than those of RESP (AUROC 0.66 (95% CI 0.56 to 0.76)) and PRESERVE (AUROC 0.71 (95% CI 0.61 to 0.81)). Additionally, we achieved an AUROC (0.75) for 90-day mortality in external validation in the case of the XGB model, which was higher than that of RESP (0.70) and PRESERVE (0.67) in the same validation dataset. Conclusions ML prediction models outperformed previous mortality risk models. This model may be used to identify patients who are unlikely to benefit from VV-ECMO therapy during patient selection.",
        "affiliation_name": "Seoul National University Bundang Hospital",
        "affiliation_city": "Seongnam",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Quantifying Parkinson's disease severity using mobile wearable devices and machine learning: The ParkApp pilot study protocol",
        "paper_author": "Ymeri G.",
        "publication": "BMJ Open",
        "citied_by": "4",
        "cover_date": "2023-12-28",
        "Abstract": "Introduction The clinical assessment of Parkinson's disease (PD) symptoms can present reliability issues and, with visits typically spaced apart 6 months, can hardly capture their frequent variability. Smartphones and smartwatches along with signal processing and machine learning can facilitate frequent, remote, reliable and objective assessments of PD from patients' homes. Aim To investigate the feasibility, compliance and user experience of passively and actively measuring symptoms from home environments using data from sensors embedded in smartphones and a wrist-wearable device. Methods and analysis In an ongoing clinical feasibility study, participants with a confirmed PD diagnosis are being recruited. Participants perform activity tests, including Timed Up and Go (TUG), tremor, finger tapping, drawing and vocalisation, once a week for 2 months using the Mobistudy smartphone app in their homes. Concurrently, participants wear the GENEActiv wrist device for 28 days to measure actigraphy continuously. In addition to using sensors, participants complete the Beck's Depression Inventory, Non-Motor Symptoms Questionnaire (NMSQuest) and Parkinson's Disease Questionnaire (PDQ-8) questionnaires at baseline, at 1 month and at the end of the study. Sleep disorders are assessed through the Parkinson's Disease Sleep Scale-2 questionnaire (weekly) and a custom sleep quality daily questionnaire. User experience questionnaires, Technology Acceptance Model and User Version of the Mobile Application Rating Scale, are delivered at 1 month. Clinical assessment (Movement Disorder Society-Unified Parkinson Disease Rating Scale (MDS-UPDRS)) is performed at enrollment and the 2-month follow-up visit. During visits, a TUG test is performed using the smartphone and the G-Walk motion sensor as reference device. Signal processing and machine learning techniques will be employed to analyse the data collected from Mobistudy app and the GENEActiv and correlate them with the MDS-UPDRS. Compliance and user aspects will be informing the long-term feasibility. Ethics and dissemination The study received ethical approval by the Swedish Ethical Review Authority (Etikprövningsmyndigheten), with application number 2022-02885-01. Results will be reported in peer-reviewed journals and conferences. Results will be shared with the study participants.",
        "affiliation_name": "Akademiskt Specialistcentrum",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "SparsePro: An efficient fine-mapping method integrating summary statistics and functional annotations",
        "paper_author": "Zhang W.",
        "publication": "PLoS Genetics",
        "citied_by": "4",
        "cover_date": "2023-12-28",
        "Abstract": "Identifying causal variants from genome-wide association studies (GWAS) is challenging due to widespread linkage disequilibrium (LD) and the possible existence of multiple causal variants in the same genomic locus. Functional annotations of the genome may help to prioritize variants that are biologically relevant and thus improve fine-mapping of GWAS results. Classical fine-mapping methods conducting an exhaustive search of variant-level causal configurations have a high computational cost, especially when the underlying genetic architecture and LD patterns are complex. SuSiE provided an iterative Bayesian stepwise selection algorithm for efficient fine-mapping. In this work, we build connections between SuSiE and a paired mean field variational inference algorithm through the implementation of a sparse projection, and propose effective strategies for estimating hyperparameters and summarizing posterior probabilities. Moreover, we incorporate functional annotations into fine-mapping by jointly estimating enrichment weights to derive functionally- informed priors. We evaluate the performance of SparsePro through extensive simulations using resources from the UK Biobank. Compared to state-of-the-art methods, SparsePro achieved improved power for fine-mapping with reduced computation time. We demonstrate the utility of SparsePro through fine-mapping of five functional biomarkers of clinically relevant phenotypes. In summary, we have developed an efficient fine-mapping method for integrating summary statistics and functional annotations. Our method can have wide utility in understanding the genetics of complex traits and increasing the yield of functional follow-up studies of GWAS. SparsePro software is available on GitHub at https:// github.com/zhwm/SparsePro.",
        "affiliation_name": "McGill Faculty of Medicine and Health Sciences",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Low-Cost Vibrational Free Energies in Solid Solutions with Machine Learning Force Fields",
        "paper_author": "Tolborg K.",
        "publication": "Journal of Physical Chemistry Letters",
        "citied_by": "2",
        "cover_date": "2023-12-28",
        "Abstract": "The rational design of alloys and solid solutions relies on accurate computational predictions of phase diagrams. The cluster expansion method has proven to be a valuable tool for studying disordered crystals. However, the effects of vibrational entropy are commonly neglected due to the computational cost. Here, we devise a method for including the vibrational free energy in cluster expansions with a low computational cost by fitting a machine learning force field (MLFF) to the relaxation trajectories available from cluster expansion construction. We demonstrate our method for two (pseudo)binary systems, Na1-xKxCl and Ag1-xPdx, for which accurate phonon dispersions and vibrational free energies are derived from the MLFF. For both systems, the inclusion of vibrational effects results in significantly better agreement with miscibility gaps in experimental phase diagrams. This methodology can allow routine inclusion of vibrational effects in calculated phase diagrams and thus more accurate predictions of properties and stability for mixtures of materials.",
        "affiliation_name": "Aalborg University",
        "affiliation_city": "Aalborg",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "IntraCranial pressure prediction AlgoRithm using machinE learning (I-CARE): Training and Validation Study",
        "paper_author": "Fong N.",
        "publication": "Critical Care Explorations",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "OBJECTIVES: Elevated intracranial pressure (ICP) is a potentially devastating complication of neurologic injury. Developing an ICP prediction algorithm to help the clinician adjust treatments and potentially prevent elevated ICP episodes. DESIGN: Retrospective study. SETTING: Three hundred thirty-five ICUs at 208 hospitals in the United States. SUBJECTS: Adults patients from the electronic ICU (eICU) Collaborative Research Database was used to train an ensemble machine learning model to predict the ICP 30 minutes in the future. Predictive performance was evaluated using a left-out test dataset and externally evaluated on the Medical Information Mart for Intensive Care-III (MIMIC-III) Matched Waveform Database. INTERVENTIONS: None. MEASUREMENTS AND MAIN RESULTS: Predictors included age, assigned sex, laboratories, medications and infusions, input/output, Glasgow Coma Scale (GCS) components, and time-series vitals (heart rate, ICP, mean arterial pressure, respiratory rate, and temperature). Each patient ICU stay was divided into successive 95-minute timeblocks. For each timeblock, the model was trained on nontime-varying covariates as well as on 12 observations of time-varying covariates at 5-minute intervals and asked to predict the 5-minute median ICP 30 minutes after the last observed ICP value. Data from 931 patients with ICP monitoring in the eICU dataset were extracted (46,207 timeblocks). The root mean squared error was 4.51 mm Hg in the eICU test set and 3.56 mm Hg in the MIMIC-III dataset. The most important variables driving ICP prediction were previous ICP history, patients' temperature, weight, serum creatinine, age, GCS, and hemodynamic parameters. CONCLUSIONS: IntraCranial pressure prediction AlgoRithm using machinE learning, an ensemble machine learning model, trained to predict the ICP of a patient 30 minutes in the future based on baseline characteristics and vitals data from the past hour showed promising predictive performance including in an external validation dataset.",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "NICE-FF: A non-empirical, intermolecular, consistent, and extensible force field for nucleic acids and beyond",
        "paper_author": "Demir G.İ.",
        "publication": "Journal of Chemical Physics",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "A new non-empirical ab initio intermolecular force field (NICE-FF in buffered 14-7 potential form) has been developed for nucleic acids and beyond based on the dimer interaction energies (IEs) calculated at the spin component scaled-MI-second order Møller-Plesset perturbation theory. A fully automatic framework has been implemented for this purpose, capable of generating well-polished computational grids, performing the necessary ab initio calculations, conducting machine learning (ML) assisted force field (FF) parametrization, and extending existing FF parameters by incorporating new atom types. For the ML-assisted parametrization of NICE-FF, interaction energies of ∼18 000 dimer geometries (with IE < 0) were used, and the best fit gave a mean square deviation of about 0.46 kcal/mol. During this parametrization, atom types apparent in four deoxyribonucleic acid (DNA) bases have been first trained using the generated DNA base datasets. Both uracil and hypoxanthine, which contain the same atom types found in DNA bases, have been considered as test molecules. Three new atom types have been added to the DNA atom types by using IE datasets of both pyrazinamide and 9-methylhypoxanthine. Finally, the last test molecule, theophylline, has been selected, which contains already-fitted atom-type parameters. The performance of NICE-FF has been investigated on the S22 dataset, and it has been found that NICE-FF outperforms the well-known FFs by generating the most consistent IEs with the high-level ab initio ones. Moreover, NICE-FF has been integrated into our in-house developed crystal structure prediction (CSP) tool [called FFCASP (Fast and Flexible CrystAl Structure Predictor)], aiming to find the experimental crystal structures of all considered molecules. CSPs, which were performed up to 4 formula units (Z), resulted in NICE-FF being able to locate almost all the known experimental crystal structures with sufficiently low RMSD20 values to provide good starting points for density functional theory optimizations.",
        "affiliation_name": "İstanbul Teknik Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "PotentialMind: Graph Convolutional Machine Learning Potential for Sb-Te Binary Compounds of Multiple Stoichiometries",
        "paper_author": "Wang G.",
        "publication": "Journal of Physical Chemistry C",
        "citied_by": "9",
        "cover_date": "2023-12-28",
        "Abstract": "Machine learning potential (MLP) has emerged as a powerful tool in materials research and design. However, most MLP methods rely only on a single descriptor generated by mathematical functions instead of mapping the three-dimensional space of the materials structure, and thus this type of potential is typically limited to specific compositions. In this research, we present graph convolutional machine learning potential (GCMLP) software, termed PotentialMind, which can transform three-dimensional atomic structures into vectors comprising nodes, edges, and weights based on multiple descriptors. Using Sb-Te phase change materials as examples, a model named GCMLP-ST suitable for 12 stoichiometries of Sb-Te compounds has been constructed, whose root-mean-square errors for energy and forces are, respectively, 4.51 and 73.13 meV/Å for training data sets and are, respectively, 4.97 and 76.25 meV/Å for unfamiliar testing data sets. Moreover, for the energy-volume curves and radius distribution function by molecular dynamics, the GCMLP-ST model with 10,000 atoms exhibits good agreement with the ab initio molecular dynamics (AIMD) results across crystalline, liquid, and amorphous phases for the six representative Sb-Te material systems, which also exhibit 50 times the computational efficiency of AIMD. With this framework, the architecture of the machine learning model can be customized by deep and transfer learning, extending to other material systems. In addition, benefiting from the high efficiency of PotentialMind molecular dynamics (PMMD), it can be used for real devices, spanning tens of nanoseconds and comprising millions of atoms under different programming conditions that are impossible with AIMD simulations.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reduction of thermal conductivity in carbon nanotubes by fullerene encapsulation from machine-learning molecular dynamics simulations",
        "paper_author": "Lu Y.",
        "publication": "Journal of Applied Physics",
        "citied_by": "2",
        "cover_date": "2023-12-28",
        "Abstract": "The carbon nano-peapod is a representative structure with interlayer van der Waals (vdW) interactions, in which encapsulated fullerene molecules play a critical role in modulating the transport properties of the carbon nanotubes (CNTs). In particular, their influence on the thermal transport characteristics has been the focal point of considerable attention. In this study, we trained an accurate machine learning potential for fullerene-encapsulated CNTs based on the efficient NEP model to investigate their thermal properties. Using equilibrium molecular dynamics simulation along with the spectral decomposition method for thermal conductivity, we find that the thermal conductivity of fullerene-encapsulated CNTs is roughly 55% lower than that of empty CNTs, aligning with experimental observations for CNT bundles with fullerene encapsulation [Kodama et al., Nat. Mater. 16, 892 (2017)]. The research suggests that weak vdW interactions between both the fullerene and CNTs, as well as between fullerene molecules themselves, hinder phonon propagation. The encapsulated fullerene contributes to an increase in phonon scattering within the CNTs, ultimately leading to a reduction in thermal conductivity. We utilized machine learning potential to investigate the structure of fullerene-encapsulated CNTs and their heat transport property. This approach provides valuable insights for performance research of complex systems featuring interlayer vdW interactions.",
        "affiliation_name": "Bohai University",
        "affiliation_city": "Jinzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Kohn-Sham accuracy from orbital-free density functional theory via Δ-machine learning",
        "paper_author": "Kumar S.",
        "publication": "Journal of Chemical Physics",
        "citied_by": "10",
        "cover_date": "2023-12-28",
        "Abstract": "We present a Δ-machine learning model for obtaining Kohn-Sham accuracy from orbital-free density functional theory (DFT) calculations. In particular, we employ a machine-learned force field (MLFF) scheme based on the kernel method to capture the difference between Kohn-Sham and orbital-free DFT energies/forces. We implement this model in the context of on-the-fly molecular dynamics simulations and study its accuracy, performance, and sensitivity to parameters for representative systems. We find that the formalism not only improves the accuracy of Thomas-Fermi-von Weizsäcker orbital-free energies and forces by more than two orders of magnitude but is also more accurate than MLFFs based solely on Kohn-Sham DFT while being more efficient and less sensitive to model parameters. We apply the framework to study the structure of molten Al0.88Si0.12, the results suggesting no aggregation of Si atoms, in agreement with a previous Kohn-Sham study performed at an order of magnitude smaller length and time scales.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Classification of urban rail transit lines and determinants of the ridership from the perspective of land use",
        "paper_author": "Zhang X.",
        "publication": "Progress in Geography",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "The comprehension of the interdependence between urban rail transit ridership and land use is beneficial for rational resource allocation to facilitate the implementation of transit-oriented development (TOD). Existing studies have primarily focused on ridership and the built environment of stations to identify key influencing factors, while there remains a lack of research from a global perspective regarding the dependence of ridership on land use along urban rail transit lines. To this end, this study used multi-source urban geographic data from 36 major cities in China's mainland in 2019 to establish line function and built environment factors that depict land use, and classify line types using the two as clustering features, while also establishing transportation service factors. XGBoost (eXtreme Gradient Boosting) was employed to analyze the influencing factors of ridership across different types of lines. Taking seven supercities such as Beijing, 14 megacities such as Wuhan, and 15 big cities such as Nanning and their urban rail transit systems as research objects, the results show that urban rail transit lines can be categorized into downtown line type Ⅰ, downtown line type II, and suburb line, based on the different service scopes of the lines and variations in urban development levels. The cumulative contribution of the explanatory variables in the top five, which are of utmost importance to ridership, accounts for at least 60% across all three types of lines. Among these, both employment density and the coverage level of line on the downtown area emerged as significant land use explanatory variables shared by all three types of lines. Moreover, it was observed that important explanatory variables exhibited a threshold effect on ridership, with converging thresholds among important variables within the same type of line but notable difference between different types. Therefore, the construction of TOD corridor should align the distribution of employment and residential areas, as well as supporting resources, in accordance with local conditions. The research findings can help understanding the mechanism of land use affecting urban rail transit ridership and provide a reference for promoting the development of corridor TOD.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Physical Insights From the Multidecadal Prediction of North Atlantic Sea Surface Temperature Variability Using Explainable Neural Networks",
        "paper_author": "Liu G.",
        "publication": "Geophysical Research Letters",
        "citied_by": "2",
        "cover_date": "2023-12-28",
        "Abstract": "North Atlantic sea surface temperatures (NASST), particularly in the subpolar region, are among the most predictable in the world's oceans. However, the relative importance of atmospheric and oceanic controls on their variability at multidecadal timescales remain uncertain. Neural networks (NNs) are trained to examine the relative importance of oceanic and atmospheric predictors in predicting the NASST state in the Community Earth System Model 1 (CESM1). In the presence of external forcings, oceanic predictors outperform atmospheric predictors, persistence, and random chance baselines out to 25-year leadtimes. Layer-wise relevance propagation is used to unveil the sources of predictability, and reveal that NNs consistently rely upon the Gulf Stream-North Atlantic Current region for accurate predictions. Additionally, CESM1-trained NNs successfully predict the phasing of multidecadal variability in an observational data set, suggesting consistency in physical processes driving NASST variability between CESM1 and observations.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Discovery of Lead 2-Thiazolylhydrazones with Broad-Spectrum and Potent Antifungal Activity",
        "paper_author": "Oliveira N.J.C.",
        "publication": "Journal of Medicinal Chemistry",
        "citied_by": "3",
        "cover_date": "2023-12-28",
        "Abstract": "Opportunistic fungal infections represent a global health problem, mainly for immunocompromised individuals. New therapeutical options are needed since several fungal strains show resistance to clinically available antifungal agents. 2-Thiazolylhydrazones are well-known as potent compounds against Candida and Cryptococcus species. A scaffold-focused drug design using machine-learning models was established to optimize the 2-thiazolylhydrazone skeleton and obtain novel compounds with higher potency, better solubility in water, and enhanced absorption. Twenty-nine novel compounds were obtained and most showed low micromolar MIC values against different species of Candida and Cryptococcus spp., including Candida auris, an emerging multidrug-resistant yeast. Among the synthesized compounds, 2-thiazolylhydrazone 28 (MIC value ranging from 0.8 to 52.17 μM) was selected for further studies: cytotoxicity evaluation, permeability study in Caco-2 cell model, and in vivo efficacy against Cryptococcus neoformans in an invertebrate infection model. All results obtained indicate the great potential of 28 as a novel antifungal agent.",
        "affiliation_name": "Itä-Suomen yliopisto",
        "affiliation_city": "Kuopio",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Validation Study of the MDS Criteria for the Diagnosis of Multiple System Atrophy in the Mayo Clinic Brain Bank",
        "paper_author": "Sekiya H.",
        "publication": "Neurology",
        "citied_by": "11",
        "cover_date": "2023-12-28",
        "Abstract": "Background and ObjectiveThe second consensus criteria in 2008 have been used in diagnosing multiple system atrophy (MSA). The International Parkinson and Movement Disorder Society (MDS) proposed new diagnostic criteria for MSA in 2022. This study aimed to compare the diagnostic accuracy between these 2 criteria and validate the clinical utility of the newly proposed criteria for MSA.MethodsWe conducted a retrospective autopsy cohort study of consecutive patients with a clinical or pathologic diagnosis of MSA from the Mayo Clinic brain bank between 1998 and 2021. We studied 352 patients (250 pathologically diagnosed MSA and 102 non-MSA); MDS criteria and the second consensus criteria were applied. The sensitivity, specificity, and area under the curve (AUC) of receiver operating characteristic curves were compared between these criteria. Comparison was conducted between clinical subtypes and among clinically challenging cases (those with different clinical diagnoses or those with suspected but undiagnosed MSA before death). We also used machine learning algorithm, eXtreme Gradient Boosting, to identify clinical features contributing diagnostic performance.ResultsThe sensitivity and specificity of clinically established and probable MSA by the MDS criteria were 16% and 99% and 64% and 74%, respectively. The sensitivity and specificity of probable MSA and possible MSA by the second consensus criteria were 72% and 52% and 93% and 21%, respectively. The AUC of MDS clinically probable MSA was the highest (0.69). The diagnostic performance did not differ between clinical subtypes. In clinically challenging cases, MDS clinically established MSA maintained high specificity and MDS clinically probable MSA demonstrated the highest AUC (0.62). MRI findings contributed to high specificity. In addition, combining core clinical features with 2 or more from any of the 13 supporting features and the absence of exclusion criteria also yielded high specificity. Among supporting features, rapid progression was most important for predicting MSA pathology.DiscussionThe MDS criteria showed high specificity with clinically established MSA and moderate sensitivity and specificity with clinically probable MSA. The observation that high specificity could be achieved with clinical features alone suggests that MSA diagnosis with high specificity is possible even in areas where MRI is not readily available.",
        "affiliation_name": "Graduate School of Medicine",
        "affiliation_city": "Kobe",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Internal Variability Increased Arctic Amplification During 1980–2022",
        "paper_author": "Sweeney A.J.",
        "publication": "Geophysical Research Letters",
        "citied_by": "8",
        "cover_date": "2023-12-28",
        "Abstract": "Since 1980, the Arctic surface has warmed four times faster than the global mean. Enhanced Arctic warming relative to the global average warming is referred to as Arctic Amplification (AA). While AA is a robust feature in climate change simulations, models rarely reproduce the observed magnitude of AA, leading to concerns that models may not accurately capture the response of the Arctic to greenhouse gas emissions. Here, we use CMIP6 data to train a machine learning algorithm to quantify the influence of internal variability in surface air temperature trends over both the Arctic and global domains. Application of this machine learning algorithm to observations reveals that internal variability increases the Arctic warming but slows global warming in recent decades, inflating AA since 1980 by 38% relative to the externally forced AA. Accounting for the role of internal variability reconciles the discrepancy between simulated and observed AA.",
        "affiliation_name": "Program for Climate Model Diagnosis and Intercomparison",
        "affiliation_city": "Livermore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Generalized Aerosol Algorithm for Multi-Spectral Satellite Measurement With Physics-Informed Deep Learning Method",
        "paper_author": "Jiang J.",
        "publication": "Geophysical Research Letters",
        "citied_by": "8",
        "cover_date": "2023-12-28",
        "Abstract": "The multi-spectral satellite sensors such as MODIS have a large swath, high spatial resolution, and well onboard calibration, enabling aerosol retrievals with daily global coverage. Despite numerous available bands, MODIS aerosol algorithms over land typically only utilize measurements from 2 to 3 spectral wavelengths to retrieve Aerosol Optical Depth (AOD) based on prescribed aerosol models. To make full use of multi-spectral measurements and prior information, we developed an aerosol algorithm based on physics-informed deep learning (PDL) approach. With physical constraint from radiative transfer simulation, PDL can construct model functions between the whole spectral measurements and each retrieved aerosol parameter separately. AERONET validations in eastern China show that MODIS PDL algorithm can accurately retrieve AOD and fine AOD (R = 0.936) at 1 km resolution and has reliable performance in coarse AOD as well as notable sensitivity to aerosol absorption. The flexible and efficient PDL method provides a generalized algorithm for common multi-spectral satellite measurements.",
        "affiliation_name": "Aerospace Information Research Institute",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Improving Subseasonal-To-Seasonal Prediction of Summer Extreme Precipitation Over Southern China Based on a Deep Learning Method",
        "paper_author": "Lyu Y.",
        "publication": "Geophysical Research Letters",
        "citied_by": "15",
        "cover_date": "2023-12-28",
        "Abstract": "The reliable Subseasonal-to-Seasonal (S2S) forecast of precipitation, particularly extreme precipitation, is critical for disaster prevention and mitigation, which however remains a great challenge for mission agencies and research communities. In this study, a deep learning method based on U-Net with additional atmospheric factor forecasts included is proposed to improve S2S quantitative forecasts of summer precipitation over Southern China. The weighted loss function integrated by mean square error and threat score is introduced to capture extreme precipitation more precisely. Generally, the U-Net model shows promising results in both general statistics and extreme events. Predictor importance analyses show that the U-Net forecast skills at the 1-week lead time mainly arise from synchronous precipitation forecasts, but the contributions made by atmospheric factor forecasts rise rapidly with increasing lead times. Therefore, the channel combining numerical weather prediction model and deep learning framework is demonstrated promising in S2S precipitation forecasts.",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Phase Neural Operator for Multi-Station Picking of Seismic Arrivals",
        "paper_author": "Sun H.",
        "publication": "Geophysical Research Letters",
        "citied_by": "10",
        "cover_date": "2023-12-28",
        "Abstract": "Seismic wave arrival time measurements form the basis for numerous downstream applications. State-of-the-art approaches for phase picking use deep neural networks to annotate seismograms at each station independently, yet human experts annotate seismic data by examining the whole network jointly. Here, we introduce a general-purpose network-wide phase picking algorithm based on a recently developed machine learning paradigm called Neural Operator. Our model, called Phase Neural Operator, leverages the spatio-temporal contextual information to pick phases simultaneously for any seismic network geometry. This results in superior performance over leading baseline algorithms by detecting many more earthquakes, picking more phase arrivals, while also greatly improving measurement accuracy. Following similar trends being seen across the domains of artificial intelligence, our approach provides but a glimpse of the potential gains from fully-utilizing the massive seismic data sets being collected worldwide.",
        "affiliation_name": "Division of Geological and Planetary Sciences",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Weather Systems Connecting Modes of Climate Variability to Regional Hydroclimate Extremes",
        "paper_author": "Chen X.",
        "publication": "Geophysical Research Letters",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Weather system clustering provides a high-level summary of regional meteorological conditions. Most quantitative clustering schemes focus on precipitation alone, which does not sufficiently describe the meteorological conditions driving hydroclimate variability. This study presents the Weather Anomaly Clustering (WAC-hydro), which extends the existing capability of predicting weather systems to predicting hydroclimate variability. Focusing on both precipitation and temperature predictions, WAC-hydro identifies 12 clusters of daily weather anomaly modes in the US Pacific Northwest Puget Sound region during 1981–2020. The influence of El Niño-Southern Oscillation and Madden-Julian Oscillation on regional precipitation can be well approximated by their modulation on the weather clusters. Within each weather cluster, local factors such as topography only play a secondary role in the hydrologic variability. The weather clusters highlight two types of flood-inducing regional weather conditions, one causing floods by inducing positive precipitation anomalies and the other causing floods through combined precipitation and temperature-induced rain-on-snow effect.",
        "affiliation_name": "Pacific Northwest National Laboratory",
        "affiliation_city": "Richland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep Learning-Based Sea Surface Roughness Parameterization Scheme Improves Sea Surface Wind Forecast",
        "paper_author": "Fu S.",
        "publication": "Geophysical Research Letters",
        "citied_by": "2",
        "cover_date": "2023-12-28",
        "Abstract": "Accurate offshore surface wind forecasting is crucial for navigation safety and disaster prevention. However, significant biases exist in forecasting sea surface winds due to the uncertainties in estimating sea surface roughness. In this study, we propose a deep learning-based scheme (DL2023) for estimating sea surface roughness and integrate it into a regionally coupled ocean-atmosphere-wave model. Single-point experiments demonstrate that DL2023 achieves a remarkable 50% reduction in the Root Mean Square Error (RMSE) compared to the four traditional schemes. During five typhoon cases in August 2020, compared to the four traditional schemes, the RMSEs of forecasted surface winds using DL2023 are reduced by 6.02%–14.75%, 11.17%–18.30%, and 11.91%–19.46% at lead times of 24, 48, and 72 hr, respectively. Thus, the DL2023 scheme, trained using data from the Atlantic Ocean, successfully improves the forecast of surface winds over the Northwest Pacific Ocean.",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine-learned interatomic potentials: Recent developments and prospective applications",
        "paper_author": "Eyert V.",
        "publication": "Journal of Materials Research",
        "citied_by": "12",
        "cover_date": "2023-12-28",
        "Abstract": "High-throughput generation of large and consistent ab initio data combined with advanced machine-learning techniques are enabling the creation of interatomic potentials of near ab initio quality. This capability has the potential of dramatically impacting materials research: (i) while classical interatomic potentials have become indispensable in atomistic simulations, such potentials are typically restricted to certain classes of materials. Machine-learned potentials (MLPs) are applicable to all classes of materials individually and, importantly, to any combinations of them; (ii) MLPs are by design reactive force fields. This Focus Issue provides an overview of the state of the art of MLPs by presenting a range of impressive applications including metallurgy, photovoltaics, proton transport, nanoparticles for catalysis, ionic conductors for solid state batteries, and crystal structure predictions. These investigations provide insight into the current challenges, and they present pathways for their solutions, thus setting the stage for exciting perspectives in computational materials research.",
        "affiliation_name": "Naval Nuclear Laboratory",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Optimizing platelet transfusion through a personalized deep learning risk assessment system for demand management",
        "paper_author": "Engelke M.",
        "publication": "Blood",
        "citied_by": "2",
        "cover_date": "2023-12-28",
        "Abstract": "Platelet demand management (PDM) is a resource-consuming task for physicians and transfusion managers of large hospitals. Inpatient numbers and institutional standards play significant roles in PDM. However, reliance on these factors alone commonly results in platelet shortages. Using data from multiple sources, we developed, validated, tested, and implemented a patient-specific approach to support PDM that uses a deep learning–based risk score to forecast platelet transfusions for each hospitalized patient in the next 24 hours. The models were developed using retrospective electronic health record data of 34 809 patients treated between 2017 and 2022. Static and time-dependent features included demographics, diagnoses, procedures, blood counts, past transfusions, hematotoxic medications, and hospitalization duration. Using an expanding window approach, we created a training and live-prediction pipeline with a 30-day input and 24-hour forecast. Hyperparameter tuning determined the best validation area under the precision-recall curve (AUC-PR) score for long short-term memory deep learning models, which were then tested on independent data sets from the same hospital. The model tailored for hematology and oncology patients exhibited the best performance (AUC-PR, 0.84; area under the receiver operating characteristic curve [ROC-AUC], 0.98), followed by a multispecialty model covering all other patients (AUC-PR, 0.73). The model specific to cardiothoracic surgery had the lowest performance (AUC-PR, 0.42), likely because of unexpected intrasurgery bleedings. To our knowledge, this is the first deep learning–based platelet transfusion predictor enabling individualized 24-hour risk assessments at high AUC-PR. Implemented as a decision-support system, deep-learning forecasts might improve patient care by detecting platelet demand earlier and preventing critical transfusion shortages.",
        "affiliation_name": "Medizinischen Fakultät",
        "affiliation_city": "Essen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Intelligent soft self-twisted shape sensor",
        "paper_author": "Li L.",
        "publication": "Physics Letters, Section A: General, Atomic and Solid State Physics",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "This paper introduces an all-fiber flexible soft sensor that combines machine learning methods to acquire the ability to recognize its own twisted shape. The sensor is twisted into various shapes, the recognition accuracy of the shapes can reach 100 %. Unlike existing sensors, which require multiple sensors to form an array, such sensor requires only a single optical fiber MZI (Mach-Zehnder interferometer) embedded inside the flexible material, which makes the sensing structure and wiring connection very simple. At the same time, the sensor presents very good reliability, bend sensitivity and repeatability. Its temperature performance is also investigated. All above highlighting its great potential in intelligent robots, medical rehabilitation, surgical endoscopes, and object recognition.",
        "affiliation_name": "Shandong University of Science and Technology",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An automated detection and classification of brain tumor from MRIs using Water Chaotic Fruitfly Optimization (WChFO) based Deep Recurrent Neural Network (DRNN) An automated detection and classification of brain tumor",
        "paper_author": "Pasupuleti R.M.",
        "publication": "IMAGING",
        "citied_by": "0",
        "cover_date": "2023-12-28",
        "Abstract": "Due to the complexity of the images and dearth of anatomical models, it is highly difficult to accurately represent the various deformations in each component of the medical images. In recent years, a significant number of children and adults have affected from brain tumors, which is one of the most terrible types of disease affects the people around the world. Moreover, the Magnetic Resonance Imaging (MRI) based brain tumor detection is one of a significant study area in the field of medical imaging. Since, the use of computerized methods aids in the detection and treatment of disease by the medical professionals. The development of an automated method for the accurate detection and classification of tumors from brain MRIs. In this framework, a tanh normalization process is used to smooth out the input brain MRIs with less noise artefacts and improved quality. Then, a group feature extraction model is used to extract the relevant features from the normalized image, which includes both Speeded Up Robust Features (SURF) and Grey Level Co-occurrence Matrix (GLCM) features. The Water Chaotic Fruitfly Optimization (WChFO) method is used to identify the best features for increasing the speed of classifier training and testing processes with less time. Moreover, a Deep Recurrent Neural Network (DRNN) model is used to classify the type of brain tumor for accurate early diagnosis and treatment. The most well-known benchmarking datasets, like BRATS and Kaggle, employed for analysis in order to assess the effectiveness and results of the proposed brain tumor diagnosis system. By using the proposed WChFO-DRNN technique, the accuracy of the tumor detection system is increased to 99. 2% with the sensitivity, specificity of 99% and time consumption of 0. 2s.",
        "affiliation_name": "Sreenidhi Institute of Science &amp; Technology",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "FABSA: An aspect-based sentiment analysis dataset of user reviews",
        "paper_author": "Kontonatsios G.",
        "publication": "Neurocomputing",
        "citied_by": "5",
        "cover_date": "2023-12-28",
        "Abstract": "Aspect-based sentiment analysis (ABSA) aims at automatically extracting aspects of entities and classifying the polarity of each extracted aspect. The majority of available ABSA systems heavily rely on manually annotated datasets to train supervised machine learning models. However, the development of such manually curated datasets is a labour-intensive process and therefore existing ABSA datasets cover only a few domains and they are limited in size. In response, we present FABSA (Feedback ABSA), a new large-scale and multi-domain ABSA dataset of feedback reviews. FABSA consists of approximately 10,500 reviews which span across 10 domains. We conduct a number of experiments to evaluate the performance of state-of-the-art deep learning models when applied to the FABSA dataset. Our results demonstrate that ABSA models can generalise across different domains when trained on our FABSA dataset while the performance of the models is enhanced when using a larger training dataset. Our FABSA dataset is publicly available.",
        "affiliation_name": "Chattermill",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Directly-trained Spiking Neural Networks for Deep Reinforcement Learning: Energy efficient implementation of event-based obstacle avoidance on a neuromorphic accelerator",
        "paper_author": "Zanatta L.",
        "publication": "Neurocomputing",
        "citied_by": "3",
        "cover_date": "2023-12-28",
        "Abstract": "Spiking Neural Networks (SNN) promise extremely low-power and low-latency inference on neuromorphic hardware. Recent studies demonstrate the competitive performance of SNNs compared with Artificial Neural Networks (ANN) in conventional classification tasks. In this work, we present an energy-efficient implementation of a Reinforcement Learning (RL) algorithm using SNNs to solve an obstacle avoidance task performed by an Unmanned Aerial Vehicle (UAV), taking a Dynamic Vision Sensor (DVS) as event-based input. We train the SNN directly, improving upon state-of-art implementations based on hybrid (not directly trained) SNNs. For this purpose, we devise an adaptation of the Spatio-Temporal Backpropagation algorithm (STBP) for RL. We then compare the SNN with a state-of-art Convolutional Neural Network (CNN) designed to solve the same task. To this aim, we train both networks by exploiting a photorealistic training pipeline based on AirSim. To achieve a realistic latency and throughput assessment for embedded deployment, we designed and trained three different embedded SNN versions to be executed on state-of-art neuromorphic hardware, targeting state-of-the-art. We compared SNN and CNN in terms of obstacle avoidance performance showing that the SNN algorithm achieves better results than the CNN with a factor of 6× less energy. We also characterize the different SNN hardware implementations in terms of energy and spiking activity.",
        "affiliation_name": "Alma Mater Studiorum Università di Bologna",
        "affiliation_city": "Bologna",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Computationally efficient neural hybrid automaton framework for learning complex dynamics",
        "paper_author": "Wang T.",
        "publication": "Neurocomputing",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "This paper proposes a computationally efficient and effective data-driven modeling framework for dynamical systems. The proposed modeling framework employs a collection of shallow neural networks known as Extreme Learning Machines (ELMs) to model local system behaviors along with data-driven inferred transitions among local models to establish a neural hybrid automaton model. First, the sampled system inputs are mapped to the corresponding feature spaces to obtain data-driven partitions, which subsequently define the transitions and invariants of the neural hybrid automaton model through a novel data-driven mode clustering process. Then, a collection of ELMs are trained to approximate the local dynamics. The learning processes integrate a segmented data merging procedure for location identification and a local dynamics modeling process. The proposed neural hybrid automaton models can capture behaviors of complex dynamical systems with high modeling precision but significantly lower computational complexities in computationally expensive tasks such as training and verification, which are traditionally considered to be computationally expensive tasks for neural network models. A computationally efficient set-valued reachability analysis method which is commonly used in safety verification is then developed based on interval analysis and a novel Split and Combine process. Finally, applications to modeling the limit cycle and human handwritten motions are presented to show the effectiveness and efficiency of our approach.",
        "affiliation_name": "Augusta University",
        "affiliation_city": "Augusta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Tuning N-ary relation extraction as Machine Reading Comprehension",
        "paper_author": "Ren P.",
        "publication": "Neurocomputing",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "Compared with conventional binary relation extraction, n-ary relation extraction is a particularly challenging task due to the presence of multiple entities that span across sentences. Although current methods have achieved remarkable results in this area, they often rely on complex modeling like dependency parsing, which easily suffers from error propagation. To address this predicament, this paper proposes a novel framework for n-ary relation extraction that utilizes Machine Reading Comprehension (MRC) as its foundation. In particular, considering the unnameable relations or sub-relations between multiple entities, we resort to learning continuous prompting questions to make up for the deficiency of natural language questions. Additionally, to alleviate the high semantic similarity between close relation classes, we obtain supplementary prompt messages (i.e., additional knowledge) according to the statistical results for each relation class so as to equip the model with a better capacity to make distinctions. Finally, since the one-turn mechanism of MRC is prone to mistakes, especially in those challenging n-ary tasks, we design a double-check mechanism that generates questions from multi-perspective to ascertain the final relation between all the entities by aggregating the answers to all questions. Our method has demonstrated the most advanced results on n-ary relation extraction datasets through extensive experimentation.",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A hybrid SVM and kernel function-based sparse representation classification for automated epilepsy detection in EEG signals",
        "paper_author": "Wang Q.",
        "publication": "Neurocomputing",
        "citied_by": "7",
        "cover_date": "2023-12-28",
        "Abstract": "Automatic epilepsy detection based on electroencephalography (EEG) is crucial for advancing the diagnosis and treatment of epilepsy. In this paper, we propose a novel classification algorithm called SVM-KSRC, which differs from integrated learning approaches. The algorithm establishes a connection between support vector machine (SVM) and kernel sparse representation classification (KSRC) using support vectors. Specifically, we extract two types of features from the pre-processed EEG signals in this study. During the training phase, these features are utilized to train the SVM model and construct the kernel sparse representation dictionary. We differentiate the SVM part of the features of the test data to determine whether SVM or KSRC should be employed for classifying the test data. Our method is evaluated on two publicly available datasets: University of Bonn dataset and Neurology and Sleep Centre-New Delhi dataset. Through 10 times 10-fold cross validation, our method demonstrates superior performance in epilepsy detection when compared to existing machine learning methods. The experimental results demonstrate that SVM-KSRC is more effective compared to SVM and KSRC used separately. It achieves over 99% accuracy in all binary classification tasks and attains 100% accuracy in certain tasks. The source code is publicly available at https://github.com/Walkeraaa/SVM-KSRC.",
        "affiliation_name": "General Hospital of People's Liberation Army",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Neighborhood contrastive representation learning for attributed graph clustering",
        "paper_author": "Wang T.",
        "publication": "Neurocomputing",
        "citied_by": "5",
        "cover_date": "2023-12-28",
        "Abstract": "Attributed graph clustering is a fundamental task in graph learning field. Because of the high-dimensional node features and the complex non-Euclidean graph structure, it is challenging for attributed graph clustering methods to exploit graph information. Recent studies on graph contrastive learning (GCL) have achieved promising results. However, existing GCL-based methods neither consider a clustering-friendly node representation nor a clustering-oriented loss function, resulting in inferior performance. To this end, we propose NCAGC, a neighborhood contrastive representation learning method for attributed graph clustering task. Specifically, NCAGC constrains the representation learning of similar nodes by a neighborhood contrast module to ensure the compactness in the latent space, thus facilitating the clustering task. Meanwhile, a contrastive self-expression module is present for learning a discriminative self-expression coefficient matrix, which is crucial for the subsequent subspace clustering. Moreover, the two designed modules are trained and optimized jointly, which benefits the node representation learning and clustering to achieve mutual refinement. Extensive experimental results on four attributed graph datasets demonstrate the superiority of NCAGC compared with 16 state-of-the-art methods, which surpasses the sub-optimal method on Cora dataset by 2.1%, 4.3%, and 3.7% in terms of ACC, NMI, and ARI, respectively. Our code and dataset is available at https://github.com/wangtong627/NCAGC-NeuroCom.",
        "affiliation_name": "Nanjing Tech University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Improving stability and transferability of machine learned interatomic potentials using physically informed bounding potentials",
        "paper_author": "Zhou H.",
        "publication": "Journal of Materials Research",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "While machine-learning techniques have shown great progress in advancing the frontier of accuracy and scope in interatomic potentials, they still suffer from a number of drawbacks. Principle among these is an inability to extrapolate outside of the training data which can result in poor transferability or stability issues limiting their usefulness outside of specific scenarios. This is in contrast to traditional potential formalisms such as the Embedded Atom Method (EAM), which have shown excellent transferability thanks to the physical intuition which motivated their creation. We introduce here a modification to the machine-learned Rapid Artificial Neural Network (RANN) formalism which uses an EAM potential to bound the prediction of the energies. This constrains the predicted energies outside the training space, resulting in more stable and transferable potentials. Using zinc as an example, we demonstrate the improved stability and show that this bounding potential improves the quality of the potential within the training data. Graphical abstract: [Figure not available: see fulltext.]",
        "affiliation_name": "Bagley College of Engineering",
        "affiliation_city": "Mississippi State",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A machine-learning potential-based generative algorithm for on-lattice crystal structure prediction",
        "paper_author": "Sotskov V.",
        "publication": "Journal of Materials Research",
        "citied_by": "3",
        "cover_date": "2023-12-28",
        "Abstract": "Abstract: We propose a crystal structure prediction method based on a novel structure generation algorithm and on-lattice machine-learning interatomic potentials. Our algorithm generates atomic configurations with arbitrary supercells by assigning atomic species to sites on the given lattice and evaluates their energy using machine-learned potentials. We demonstrate two advantages of this approach. Firstly, our structure generation algorithm conducts intelligent configurational space sampling, focusing on low-energy structures and reducing computational costs. Secondly, the use of machine-learning interatomic potentials significantly reduces the number of DFT calculations. We demonstrate the efficiency of our method by constructing the convex hull of binary Nb–W, ternary Mo–Ta–W and quaternary Nb–Mo–Ta–W systems. We identify new stable structures not present in the AFLOW database, which we employ as our baseline. Due to the computational efficiency of our method, we anticipate that it can pave the way for the efficient high-throughput discovery of multicomponent materials. Graphical abstract: [Figure not available: see fulltext.]",
        "affiliation_name": "Skolkovo Institute of Science and Technology",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Accelerating training of MLIPs through small-cell training",
        "paper_author": "Meziere J.A.",
        "publication": "Journal of Materials Research",
        "citied_by": "7",
        "cover_date": "2023-12-28",
        "Abstract": "Abstract: While machine-learned interatomic potentials have become a mainstay for modeling materials, designing training sets that lead to robust potentials is challenging. Automated methods, such as active learning and on-the-fly learning, construct reliable training sets, but these processes can be resource-intensive. Current training approaches often use density functional theory calculations that have the same cell size as the simulations that the potential is explicitly trained to model. Here, we demonstrate an easy-to-implement small-cell training protocol and use it to model the Zr-H system. This training leads to a potential that accurately predicts known stable Zr-H phases and reproduces the α - β pure zirconium phase transition in molecular dynamics simulations. Compared to traditional active learning, small-cell training decreased the training time of the α - β zirconium phase transition by approximately 20 times. The potential describes the phase transition with a degree of accuracy similar to that of the large-cell training method. Graphical abstract: [Figure not available: see fulltext.].",
        "affiliation_name": "The College of Physical and Mathematical Sciences",
        "affiliation_city": "Provo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Exploring model complexity in machine learned potentials for simulated properties",
        "paper_author": "Rohskopf A.",
        "publication": "Journal of Materials Research",
        "citied_by": "5",
        "cover_date": "2023-12-28",
        "Abstract": "Machine learning (ML) enables the development of interatomic potentials with the accuracy of first principles methods while retaining the speed and parallel efficiency of empirical potentials. While ML potentials traditionally use atom-centered descriptors as inputs, different models such as linear regression and neural networks map descriptors to atomic energies and forces. This begs the question: what is the improvement in accuracy due to model complexity irrespective of descriptors? We curate three datasets to investigate this question in terms of ab initio energy and force errors: (1) solid and liquid silicon, (2) gallium nitride, and (3) the superionic conductor Li 10 Ge(PS 6 ) 2 (LGPS). We further investigate how these errors affect simulated properties and verify if the improvement in fitting errors corresponds to measurable improvement in property prediction. By assessing different models, we observe correlations between fitting quantity (e.g. atomic force) error and simulated property error with respect to ab initio values. Graphical abstract: [Figure not available: see fulltext.]",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Molecular dynamics simulations using machine learning potential for a-Si:H/c-Si interface: Effects of oxygen and hydrogen on interfacial defect states",
        "paper_author": "Semba T.",
        "publication": "Journal of Materials Research",
        "citied_by": "1",
        "cover_date": "2023-12-28",
        "Abstract": "Molecular dynamics simulations of a-Si:H/c-Si models with and without an oxygen layer at the interface were performed using a machine learning potential (MLP) that was efficiently trained using an on-the-fly scheme with ab initio molecular dynamics. The relaxation processes up to 1 ns at 500 and 700 K were simulated using MLP, and snapshots were evaluated using ab initio calculations to examine the in-gap states that could significantly affect the solar cell performance. The results showed that oxygen atoms passivated surface dangling bonds on c-Si, but simultaneously generated strain-induced in-gap states at the Si–O/a-Si interface. The hydrogen atoms suppressed the recrystallization of a-Si, distributed in a-Si particularly at the Si–O/a-Si interface because of the repulsive potential of the Si–O layer and contributed to the reduction of the in-gap states. Our results support experimental observation where optimization of the a-Si:H/O/c-Si interface could improve the performance of solar cells. Graphical abstract: [Figure not available: see fulltext.]",
        "affiliation_name": "NC State University",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Atomic cluster expansion for Pt–Rh catalysts: From ab initio to the simulation of nanoclusters in few steps",
        "paper_author": "Liang Y.",
        "publication": "Journal of Materials Research",
        "citied_by": "8",
        "cover_date": "2023-12-28",
        "Abstract": "Abstract: Insight into structural and thermodynamic properties of nanoparticles is crucial for designing optimal catalysts with enhanced activity and stability. In this work, we present a semi-automated workflow for parameterizing the atomic cluster expansion (ACE) from ab initio data. The main steps of the workflow are the generation of training data from accurate electronic structure calculations, an efficient fitting procedure supported by active learning and uncertainty indication, and a thorough validation. We apply the workflow to the simulation of binary Pt–Rh nanoparticles that are important for catalytic applications. We demonstrate that the Pt–Rh ACE is able to reproduce accurately a broad range of fundamental properties of the elemental metals as well as their compounds while retaining an outstanding computational efficiency. This enables a direct comparison of atomistic simulations to high-resolution experiments. Graphical abstract: [Figure not available: see fulltext.].",
        "affiliation_name": "Max-Planck-Institut für Eisenforschung GmbH",
        "affiliation_city": "Dusseldorf",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Data governance in the banking sector",
        "paper_author": "Rufo R.C.",
        "publication": "Data Governance: From the Fundamentals to Real Cases",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "The inception of the data management and governance (DM&G) function in the financial industry, led by the chief data officer (CDO), was mainly regulatory driven. However, the world is changing. Communication between people and between them and companies is not the same as those of the past. IT leads communications and millions of data are transferred per minute around the world. Banking industry, as a result of this change, is facing five major challenges: (i) Banks must continue the transformation of their business to better serve their customers in the future. (ii) New players who neither are bankers nor have ever had a branch to open accounts, grant loans, or process insurances have emerged in the banking scenario. (iii) Personalized knowledge by person-to-person contact has changed into a one by data analytics (DA), machine learning (ML), and artificial intelligence (AI). (iv) Sectoral and geographical diversification matters and is differential. (v) The leader was the one who had the best bank managers and now the leader is the one who has more and better data. These major challenges lead to a necessary evolution of the DM&G function market trends, as the critical goal is to become a data-driven bank enabler in the near future. The answer to these main requests to be a data-driven bank is fourfold: data stewardship, Single Data Marketplace ecosystem (SDM), DM&G dashboard, and Data as a Service (DaaS).",
        "affiliation_name": "Banco de Santander",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Conference Proceedings - 2023 6th International Conference on Machine Learning and Natural Language Processing, MLNLP 2023",
        "paper_author": "NA",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "The proceedings contain 42 papers. The topics discussed include: offensive text classification based on Ernie’s dual channel composite model; fake news detection algorithm based on incorporating multi-level features; EEGCN: event evolutionary graph comparison network for multi-modal fake news detection; explainable similar legal cases retrieval based on Siamese network; robust sentiment classification based on the backdoor adjustment; prior knowledge augmentation network for aspect-based sentiment analysis; a multi-dimension and multi-granularity feature fusion method for Chinese microblog sentiment classification; optimization study on weapon-target assignment problem based on intuitionistic fuzzy marine predator algorithm; a novel ranking method for textual adversarial attack; reinforcement learning in natural language processing: a survey; and an application of co-plot analysis: a multidimensional scaling data visualization.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Ensuring Ethical, Transparent, and Auditable Use of Education Data and Algorithms on AutoML",
        "paper_author": "Griep K.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "Automated machine learning (AutoML) creates additional opportunities for less advanced users to build and test their own data mining models. Even though AutoML creates the models for the user, there is still technical knowledge and tools needed to evaluate those models, and due to the black-box nature of the machine learning models, problems can arise with regard to algorithmic biases and fairness. Such biases can escalate in future applications, necessitating a structured approach for fairness evaluation in AutoML. This involves defining fairness criteria, selecting appropriate metrics, assessing fairness across groups, and addressing biases. In the realm of educational data mining, where AutoML is prevalent, biases related to attributes like gender or race can lead to unethical outcomes. Since fairness metrics vary in definition and strength, and some may even contradict others, making fairness evaluation more complex. In this paper, ten fairness metrics were chosen, explored, and implemented on four AutoML tools, Vertex AI, AutoSklearn, AutoKeras, and PyCaret. We identified two open educational datasets and built both prediction and classification models on those AutoML frameworks. We report our work in evaluating different machine learning models created by AutoML and provide discussions about the challenges in evaluating fairness in those models and our effort to mitigate and resolve the problems of algorithmic bias in educational data mining.",
        "affiliation_name": "NC State College of Engineering",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Research on Tibetan-Chinese Neural Machine Translation Integrating Statistical Method",
        "paper_author": "Zhou M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "In recent years, with the emergence of deep learning methods, Neural Machine Translation has become a new research direction of machine translation. Due to the scarcity of digital resources in Tibetan, there is only a small-scale Tibetan-Chinese bilingual parallel corpus to train translation models. In the case of insufficient resources, the performance of Neural Machine Translation decreases significantly. In this regard, considering that the word alignment results in Tibetan-Chinese Statistical Machine Translation are better, and the alignment information in Tibetan-Chinese Neural Machine Translation model is significantly different from that in Tibetan-Chinese Statistical Machine Translation, this paper proposes a Tibetan-Chinese Neural Machine Translation method that integrates statistical methods. We using Statistical Machine Translation method to generate word alignment information of Tibetan-Chinese parallel corpus to supervise the training process of Tibetan-Chinese Neural Machine Translation model to make the model achieve more accurate translation and alignment effect. Experimental results show that this method can effectively improve translation quality in low resource environment.",
        "affiliation_name": "Qinghai Normal University",
        "affiliation_city": "Xining",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Watch Your English Language: Text Normalization from Written Expressions to Spoken Forms",
        "paper_author": "Jiang Y.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "Based on the existing research results for speech-To-Text and methods based on statistical modelling, machine learning, etc., this paper applied the feature engineering method based on machine learning to speech-Totext, converting English text from written expressions into spoken forms. First, I preprocessed the data, including calculating the file structure and contenthad, missing values as well as reformating features. Next I had a look at normalized sentences and overview visualizations. And then I researched the impact of the normalization. Moreover, I researched token classes and their text normalization, which compose of the \"PLAIN\"(modifications), the \"PUNCT\"(punctuation), numerical classes, the \"LETTERS\"(acronyms anhd initials), the \"VERBATIM\"(special symbols) as well as the \"ELECTRONIC\"(websites) class, with the most frequent transformations of each class. Meanwhile, I did a next-neighbour analysis to prove that context matters a lot, inlcuding token class overview-previous vs next, treemap overviews relative percentages, exploration of all neighbour relations. Then, I analysed the transformation statistics, such as sentence length and classes, as well as normalized tokens and where to found them. On the basis of these foundings, I did the feature engineering composing of string length, class-specific token distance, numeric tokens and what's in a name. I also did a case study-A tale of four twos, including the class \"CARDINAL\", \"ORDINAL\", \"LETTERS\", and \"PLAIN\". Ultimately, I evaluated the results with 11.11 MB size test data, getting a extremely high accuracy score of 99.776Additional Key Words and Phrases: Text normalization, Text-To-speechFeature engineering, Tok",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reinforcement Learning in Natural Language Processing: A Survey",
        "paper_author": "Shen Y.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-27",
        "Abstract": "Reinforcement learning (RL) is a powerful technique for learning from data and feedback, but its effective application to natural language processing (NLP) tasks remains an open question. Consequently, this paper first introduces the general concepts of RL and the common approaches. Subsequently, we review the task construction settings and the application of RL for various NLP problems, such as machine translation, dialogue system, and text generation. Finally, we discuss some promising research directions and challenges of RL in NLP. We hope that our work can provide a comprehensive overview and inspire more research on this promising yet challenging topic.",
        "affiliation_name": "Minzu University of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Experimental design of emotion recognition based on machine learning",
        "paper_author": "Yu J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "In this paper, a wrist bracelet was used to measure the subjects' heart rate signals and skin electrical signals, and three types of emotions (positive, neutral and negative) were induced by designing an experimental environment. The heart rate and skin electrical signals corresponding to emotions were collected through the bracelet, and the recognition accuracy of the three types of emotions was finally obtained through data preprocessing and the support vector machine model in machine learning. At present, how to build an experimental environment that can fully induce subjects' emotions is a major difficulty in emotion recognition, so this paper provides a specific emotion recognition environment design and detailed steps. Meanwhile, through a large number of experiments, the kernel function in the support vector machine model, namely Gaussian kernel function, is determined, and grid search is introduced to search for hyperparameter C. To get the optimal parameters and results. A total of 20 people were measured in this experiment. The experimental results obtained by SVM model were positive: The recognition accuracy of skin electrical signal was 0.8422, the recognition accuracy of heart rate signal was 0.8345, and the recognition accuracy of skin electrical signal and heart rate signal feature fusion was 0.8832. Negative: The recognition accuracy of skin electrical signal is 0.9812, the recognition accuracy of heart rate signal is 0.9385, and the recognition accuracy of skin electrical signal and heart rate signal feature fusion is 0.9902. Neutral: The recognition accuracy of skin electrical signal was 0.6403, the recognition accuracy of heart rate signal was 0.5308, and the recognition accuracy of skin electrical signal and heart rate signal feature fusion was 0.5438",
        "affiliation_name": "Harbin University of Commerce",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The effect of sensors locations on the k-means convergence iterations",
        "paper_author": "Abdulrahman R.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "Recently, the research related to the clustering function in Wireless Sensor Networks gain significant attention due to this network's importance in various applications. As a general definition, Clustering is a method of grouping nodes' inefficient patterns in order to achieve a minimum distance among the nodes and thus will affect their energy level and enhance network lifetime. K-means algorithm cconsiders type of a hard type of the machine learning algorithms. The concept of k-means that the nodes reorganize themselves in various groups till it reach the optimum group after entraining a number of iterations. In the previous research related to this field, the some of the research set the convergence iterations to a random value despite the network characteristics such as central node location or nodes location. This may lead to obtain inefficient distribution for the nodes and affect the nodes lifetime by maximizing the distance among the nodes within the single group. Based on this problem, in this paper, an optimization procedure had been implemented under numerous network characteristics e.g. topologies and nodes accounts. The implementation is based on MATLAB. The simulation results introduced that convergence iterations are changeable with the change in the nodes counts in the network and the needed number of clusters.",
        "affiliation_name": "Al-Nahrain University",
        "affiliation_city": "Baghdad",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Assessing distance learning quality during COVID-19 movement restriction by machine learning models",
        "paper_author": "Mostafa S.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "COVID-19 has changed the world in all sectors; schools and universities are also affected. The education sector had to be suspended for some time, and then all universities and schools started distance learning during this pandemic. Transforming into an online method makes it possible to continue the studies and be safe from viruses. The large scale of this method is in education, in which the lectures are delivered remotely via various digital platforms. So far, this change has opened challenges to government regulations, educators, students, families, and administrators. In this paper, we analyze a dataset of surveys that conducted the questionnaire that can help measure the effectiveness of distance learning during pandemics. We perform data analysis and implement four machine learning models: Linear Regression (LR), Neural Network (NN), Decision Forest (DF), and Decision Jangle (DJ). The models are used to estimate the effectiveness of distance learning during the Covid-19 pandemic. The experimental results show that the NN model has the highest accuracy of 86.93% in the data split of 30% training and 70% testing. Nevertheless, the DJ model has achieved an overall highest average accuracy of 85.00% and recall of 47.04%.",
        "affiliation_name": "University of Al Maarif",
        "affiliation_city": "Ramadi",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "A fast and novel deep learning approach for automatic classification of epileptic seizures using spectrograms",
        "paper_author": "Khan M.H.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "Epilepsy has now become a serious global health issue. Approximately 1% of people globally experience epileptic seizures. Predicting seizures before they start helps use medication to avoid them. Using modern computer tools, machine learning, and deep learning techniques, EEG has been used to predict seizures. The main difficulties in designing epilepsy prediction algorithms are feature selection and classification. Automatic detection and prediction of epileptic seizures are carried out much faster through deep learning techniques than traditional approaches. Designing a deep learning network from scratch or using a pre-trained network not only depends on the size, variability of data, complexity of the network, number of layers, network parameters, depth, etc. This work presents A Fast and Novel Deep Learning Approach for the Automatic Classification of Epileptic Seizures using Spectrograms. The seizure data was acquired from the TUH EEG Corpus. Pre-trained networks were used on four sets of spectrogram images of normal and seizure data and reorganized within the networks, tuned on the parameters, such as Convolution layers, Classification layers, etc. The above networks were trained and tested for each set of spectrograms, and the performance was evaluated based on testing accuracy and time for the training and validation process. The proposed method achieved remarkable accuracy with the capability of retrieving the signal information at each instant. Tuned ResNet-18 achieved an average accuracy of 98.9%, with an operating time of 1056 to 3606 seconds, while modified AlexNet proved to be the fastest, with an operating time of 421 to 425 seconds with an average accuracy of 98.2 for various features selected.",
        "affiliation_name": "Aligarh Muslim University",
        "affiliation_city": "Aligarh",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine learning model for managing the insider attacks in big data",
        "paper_author": "Shannaq B.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "6",
        "cover_date": "2023-12-27",
        "Abstract": "In order to formalize information and knowledge about people, devices, applications, and services in the network system, this study provided a model for displaying large data and insider threats. The work's contribution relates to the further advancement of information security theory and practices. extending the types of characteristics needed to identify insiders In order to tackle the issue of insider identification in a huge quantity of data and identify insiders to obtain the greatest performance indicators, a novel way for integrating two classes of algorithms based on expert rules and machine learning methods is given. By enhancing the techniques, models, and algorithms for identifying CN insiders, the obtained findings demonstrate a relative improvement in the security of the chosen computer Network System (NS). employing big data processing and machine learning techniques on 2.1%.",
        "affiliation_name": "University of Buraimi",
        "affiliation_city": "Al Buraimi",
        "affiliation_country": "Oman"
    },
    {
        "paper_title": "A survey of classification methods for chest x-ray pathologies utilizing deep learning",
        "paper_author": "Jassam I.F.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "Any urgent diagnosis of pneumonia can be affected by a chest x-ray (CXR henceforth), which is one of the most common types of radiography. Artificial intelligence (AI) has been employed by most researchers for the automatic detection of the complicated patterns in imaging data and to provide quantitative analysis of radiographic properties as well. In recent years, many advances have taken place, namely in the computer vision domain. As a consequence, these advances enable the researchers to provide in-depth analysis and investigation, especially with the existence of thousands of samples of CXR images. CXR samples and techniques provide a huge support for the radiologists in making crucial decisions while examining hundreds of images from different perspectives. Moreover, time consumption will be reduced because the most urgent cases will be correctly identified in a short period of time. The current study will analyze ten of the well-known deep learning (DL)techniques that tackled identifying CXR images in relation to their actual diagnosis. Each technique will be briefly addressed regarding data preparation, methodology, and model design. Furthermore, the accuracy measure generated by each model will be compared to the dataset used. It is hoped that the current study will be a reliable resource for DL to strategies in depicting CXR images in the medical domain.",
        "affiliation_name": "Imam Ja'afar Al-Sadiq University",
        "affiliation_city": "Baghdad",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Evaluating machine learning-based stroke prediction models in imbalanced data challenges",
        "paper_author": "Dawd L.N.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "A stroke occurs when a blood clot or bleeding in the brain leads to potential permanent damage in areas such as mobility, cognition, vision, or speech. Strokes are considered medical emergencies and can result in long-term neurological impairments or, in severe cases, death. The majority of strokes can be categorized as either ischemic embolic or hemorrhagic. Ischemic embolic strokes occur when a blood clot forms in another part of the body, often the heart, and travels through the bloodstream to block narrower arteries in the brain. A hemorrhagic stroke refers to a type of brain stroke characterized by the leakage or rupture of a blood vessel in the brain. Stroke affects a significant portion of individuals aged 65 and above and is the second leading cause of death globally. It can result in heart damage, often referred to as a \"heart attack.\"Strokes incur substantial medical expenses, can cause long-term disabilities, and in some cases, may lead to fatalities. Approximately one stroke is fatal every four minutes; 80% of strokes can be lessened if there is early detection of stroke or prediction of its occurrence. The results show that all the algorithms have a considerably high level of stroke prediction accuracy. The AdaBoost has the highest accuracy score of 93.7%, the random forest has the second-highest accuracy score of 91.8%, and the logistic regression has the third-highest accuracy score of 89.9%, while the decision tree has the lowest accuracy score of 89.5%.",
        "affiliation_name": "University of Al Maarif",
        "affiliation_city": "Ramadi",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "2nd International Conference on Emerging Technology Trends in Internet of Things and Computing, TIOTC 2022",
        "paper_author": "NA",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "The proceedings contain 21 papers. The topics discussed include: the effect of sensors locations on the K-means convergence iterations; an enhanced LED cipher algorithm performance for data security in IoT systems; a review of cryptocurrencies: tether and Ethereum; a comparison study of TCP/IP and named data networking protocol; evaluating machine learning-based stroke prediction models in imbalanced data challenges; assessing distance learning quality during COVID-19 movement restriction by machine learning models; a fast and novel deep learning approach for automatic classification of epileptic seizures using spectrograms; machine learning model for managing the insider attacks in big data; and generating an integrated SWOT strategy from the SERVQUAL survey results-the need for a comparative assessment of telecommunication companies in Oman.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Diagnostic Accuracy of Artificial Intelligence Compared to Histopathologic Examination in Assessment of Oral Cancer A Systematic Review and Meta-Analysis",
        "paper_author": "Aditya A.",
        "publication": "Journal of Indian Academy of Oral Medicine and Radiology",
        "citied_by": "0",
        "cover_date": "2023-12-27",
        "Abstract": "Screening and early detection of oral cancer have always proved to be a diagnostic dilemma and challenging for oral physicians. Artificial intelligence (AI) has lately emerged as a promising new tool in this area. The aim of this systematic review was to explore the accuracy of AI-based technology compared to gold standard routine histopathological examination in the diagnosis of oral cancer. The study was carried out using PRISMA guidelines. Studies published between 1-1-2000 and 31-12-2022, searched using three databases (PubMed, DOAJ, and Google Scholar) were reviewed, and data extraction was conducted from selected eight studies by two independent reviewers. Meta-analysis was carried out among studies with similar outcomes. Pooled sensitivity of AI was found to be 0.83 (95% CI: 0.80-0.86). This value was statistically significant (P < 0.05). However, heterogeneity (I 2) value was 92%, indicating high heterogeneity. Our review and meta-analysis indicated that AI was efficient in diagnosing oral malignant and premalignant lesions when compared to the gold standard, i.e. histopathological examination.",
        "affiliation_name": "Dr. D. Y. Patil Dental College &amp; Hospital",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Classification of solid waste generation areas in the greater accra region using machine learning algorithms",
        "paper_author": "Chapman-Wardy C.",
        "publication": "Model Assisted Statistics and Applications",
        "citied_by": "1",
        "cover_date": "2023-12-27",
        "Abstract": "Solid waste management has become a challenge for developing countries mainly because of surging economic activities, rapid urbanisation and rise in community living standards. Many researchers have identified its related problems and have recommended solutions while others have established models to forecast the amount of solid waste generated over a period. However, an efficient and effective management of solid waste requires adequate categorisation of solid waste generation areas to aid in the provision of area-specific or targeted solutions for each categorised area. In this study, we used primary data on some important socio-demographic variables (household size, house type, predominant religion of household, age and educational level of household head, residency type household waste disposal method, frequency of waste collection etc) and the amount of solid waste generated from 2102 households in Greater Accra Region, Ghana. We assessed the classification performances of a traditional statistical classifiers and some selected machine learning algorithms in classifying the surveyed areas in Greater Accra into low, medium, and high solid waste generation areas. The Support Vector Machine with the Cubic Kernel was found to be the best performing classifier with a Specificity of 86%, Sensitivity, Precision and Accuracy of 73% and Area under the curve (AUC) of 0.90. The Support Vector Machine with the Cubic Kernel is therefore recommended as a suitable algorithm for the categorisation of solid waste generation areas. Stakeholders responsible for solid waste management could leverage on the evidence from this study to categorise their waste generation areas and to proffer targeted community-based interventions.",
        "affiliation_name": "University of Ghana",
        "affiliation_city": "Accra",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Quantifying the role of genome size and repeat content in adaptive variation and the architecture of flowering time in Amaranthus tuberculatus",
        "paper_author": "Kreiner J.M.",
        "publication": "PLoS Genetics",
        "citied_by": "3",
        "cover_date": "2023-12-27",
        "Abstract": "Genome size variation, largely driven by repeat content, is poorly understood within and among populations, limiting our understanding of its significance for adaptation. Here we characterize intraspecific variation in genome size and repeat content across 186 individuals of Amaranthus tuberculatus, a ubiquitous native weed that shows flowering time adaptation to climate across its range and in response to agriculture. Sequence-based genome size estimates vary by up to 20% across individuals, consistent with the considerable variability in the abundance of transposable elements, unknown repeats, and rDNAs across individuals. The additive effect of this variation has important phenotypic consequences- individuals with more repeats, and thus larger genomes, show slower flowering times and growth rates. However, compared to newly-characterized gene copy number and polygenic nucleotide changes underlying variation in flowering time, we show that genome size is a marginal contributor. Differences in flowering time are reflected by genome size variation across sexes and marginally, habitats, while polygenic variation and a gene copy number variant within the ATP synthesis pathway show consistently stronger environmental clines than genome size. Repeat content nonetheless shows non-neutral distributions across the genome, and across latitudinal and environmental gradients, demonstrating the numerous governing processes that in turn influence quantitative genetic variation for phenotypes key to plant adaptation.",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "MOF-GRU: A MOFid-Aided Deep Learning Model for Predicting the Gas Separation Performance of Metal-Organic Frameworks",
        "paper_author": "Li W.",
        "publication": "ACS Applied Materials and Interfaces",
        "citied_by": "4",
        "cover_date": "2023-12-27",
        "Abstract": "The remarkable versatility of metal-organic frameworks (MOFs) stems from their rich chemical information, leading to numerous successful applications. However, identifying optimal MOFs for specific tasks necessitates a thorough assessment of their chemical attributes. Conventional machine learning approaches for MOF prediction have relied on intricate chemical and structural details, hampering rapid evaluations. Drawing inspiration from recent advancements exemplified by Snurr et al., wherein a text string was used to represent a MOF (MOFid), we introduce a MOFid-aided deep learning model, named the MOF-GRU model. This model, founded on natural language processing principles and utilizing the gated recurrent unit architecture, leverages the serialized text string representation of metal-organic frameworks (MOFs) to forecast gas separation performance. Through a focused study on CH4/N2 separation, we substantiate the efficacy of this approach. Comparative assessments against traditional machine learning techniques underscore our model’s superior predictive accuracy and its capacity to handle extensive data sets adeptly. The MOF-GRU model remarkably uncovers latent structure-performance relationships with only MOF sequences, obviating the necessity for intricate three-dimensional (3D) structural information. Overall, this model’s judicious design empowers efficient data utilization, thereby hastening the discovery of high-performance materials tailored for gas separation applications.",
        "affiliation_name": "Tarim University",
        "affiliation_city": "Aral",
        "affiliation_country": "China"
    },
    {
        "paper_title": "More Than 30000-fold Field Enhancement of Terahertz Nanoresonators Enabled by Rapid Inverse Design",
        "paper_author": "Lee H.T.",
        "publication": "Nano Letters",
        "citied_by": "4",
        "cover_date": "2023-12-27",
        "Abstract": "The rapid development of 6G communications using terahertz (THz) electromagnetic waves has created a demand for highly sensitive THz nanoresonators capable of detecting these waves. Among the potential candidates, THz nanogap loop arrays show promising characteristics but require significant computational resources for accurate simulation. This requirement arises because their unit cells are 10 times smaller than millimeter wavelengths, with nanogap regions that are 1 000 000 times smaller. To address this challenge, we propose a rapid inverse design method using physics-informed machine learning, employing double deep Q-learning with an analytical model of the THz nanogap loop array. In ∼39 h on a middle-level personal computer, our approach identifies the optimal structure through 200 000 iterations, achieving an experimental electric field enhancement of 32 000 at 0.2 THz, 300% stronger than prior results. Our analytical model-based approach significantly reduces the amount of computational resources required, offering a practical alternative to numerical simulation-based inverse design for THz nanodevices.",
        "affiliation_name": "Ulsan National Institute of Science and Technology",
        "affiliation_city": "Ulsan",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Transferable Implicit Solvation via Contrastive Learning of Graph Neural Networks",
        "paper_author": "Airas J.",
        "publication": "ACS Central Science",
        "citied_by": "6",
        "cover_date": "2023-12-27",
        "Abstract": "Implicit solvent models are essential for molecular dynamics simulations of biomolecules, striking a balance between computational efficiency and biological realism. Efforts are underway to develop accurate and transferable implicit solvent models and coarse-grained (CG) force fields in general, guided by a bottom-up approach that matches the CG energy function with the potential of mean force (PMF) defined by the finer system. However, practical challenges arise due to the lack of analytical expressions for the PMF and algorithmic limitations in parameterizing CG force fields. To address these challenges, a machine learning-based approach is proposed, utilizing graph neural networks (GNNs) to represent the solvation free energy and potential contrasting for parameter optimization. We demonstrate the effectiveness of the approach by deriving a transferable GNN implicit solvent model using 600,000 atomistic configurations of six proteins obtained from explicit solvent simulations. The GNN model provides solvation free energy estimations much more accurately than state-of-the-art implicit solvent models, reproducing configurational distributions of explicit solvent simulations. We also demonstrate the reasonable transferability of the GNN model outside of the training data. Our study offers valuable insights for deriving systematically improvable implicit solvent models and CG force fields from a bottom-up perspective.",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Nitrogen-Containing Functional Groups Dominate the Molecular Absorption of Water-Soluble Humic-Like Substances in Air From Nanjing, China Revealed by the Machine Learning Combined FT-ICR-MS Technique",
        "paper_author": "Hong Y.",
        "publication": "Journal of Geophysical Research: Atmospheres",
        "citied_by": "1",
        "cover_date": "2023-12-27",
        "Abstract": "The light absorption capacity of water-soluble humic-like substances (HULISWS) at the molecular level is crucial for reducing the uncertainties in modeling the radiative forcing. This study proposed a machine learning approach to allocate the light absorption coefficient at 365 nm (Abs365) of HULISWS into 8084 Fourier transform-ion cyclotron resonance mass spectrometry (FT-ICR-MS) detached molecular markers and their potential functional groups. The ML model showed an acceptable uncertainty (<5%) to the whole Abs365 value based on the prediction errors. The results showed that five critical light-absorbing molecules (C4H6O4NS, C8H6O4NS, C11H15O3N2, C12H15O3N2, and C19H21O6) could explain 74% (±3%) of the variation of Abs365 in the winter, whereas no crucial light-absorbing molecules were found in the summer. Besides, the nitrogen-containing functional groups were found to dominate (61% ± 8%) the molecular absorption near the 365 nm of the spectrum. This work illustrated how functional groups affect the absorption of HULISWS, providing critical information for future research of HULISWS on the molecular level.",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Geometric Deep Learning for Structure-Based Ligand Design",
        "paper_author": "Powers A.S.",
        "publication": "ACS Central Science",
        "citied_by": "15",
        "cover_date": "2023-12-27",
        "Abstract": "A pervasive challenge in drug design is determining how to expand a ligand─a small molecule that binds to a target biomolecule─in order to improve various properties of the ligand. Adding single chemical groups, known as fragments, is important for lead optimization tasks, and adding multiple fragments is critical for fragment-based drug design. We have developed a comprehensive framework that uses machine learning and three-dimensional protein-ligand structures to address this challenge. Our method, FRAME, iteratively determines where on a ligand to add fragments, selects fragments to add, and predicts the geometry of the added fragments. On a comprehensive benchmark, FRAME consistently improves predicted affinity and selectivity relative to the initial ligand, while generating molecules with more drug-like chemical properties than docking-based methods currently in widespread use. FRAME learns to accurately describe molecular interactions despite being given no prior information on such interactions. The resulting framework for quality molecular hypothesis generation can be easily incorporated into the workflows of medicinal chemists for diverse tasks, including lead optimization, fragment-based drug discovery, and de novo drug design.",
        "affiliation_name": "Department of Bioengineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neural Networks Push the Limits of Luminescence Lifetime Nanosensing",
        "paper_author": "Ming L.",
        "publication": "Advanced Materials",
        "citied_by": "4",
        "cover_date": "2023-12-27",
        "Abstract": "Luminescence lifetime-based sensing is ideally suited to monitor biological systems due to its minimal invasiveness and remote working principle. Yet, its applicability is limited in conditions of low signal-to-noise ratio (SNR) induced by, e.g., short exposure times and presence of opaque tissues. Herein this limitation is overcome by applying a U-shaped convolutional neural network (U-NET) to improve luminescence lifetime estimation under conditions of extremely low SNR. Specifically, the prowess of the U-NET is showcased in the context of luminescence lifetime thermometry, achieving more precise thermal readouts using Ag2S nanothermometers. Compared to traditional analysis methods of decay curve fitting and integration, the U-NET can extract average lifetimes more precisely and consistently regardless of the SNR value. The improvement achieved in the sensing performance using the U-NET is demonstrated with two experiments characterized by extreme measurement conditions: thermal monitoring of free-falling droplets, and monitoring of thermal transients in suspended droplets through an opaque medium. These results broaden the applicability of luminescence lifetime-based sensing in fields including in vivo experimentation and microfluidics, while, hopefully, spurring further research on the implementation of machine learning (ML) in luminescence sensing.",
        "affiliation_name": "Universidad Complutense de Madrid",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Machine Learning Driven Channel Thickness Optimization in Dual-Layer Oxide Thin-Film Transistors for Advanced Electrical Performance",
        "paper_author": "Lee J.",
        "publication": "Advanced Science",
        "citied_by": "2",
        "cover_date": "2023-12-27",
        "Abstract": "Machine learning (ML) provides temporal advantage and performance improvement in practical electronic device design by adaptive learning. Herein, Bayesian optimization (BO) is successfully applied to the design of optimal dual-layer oxide semiconductor thin film transistors (OS TFTs). This approach effectively manages the complex correlation and interdependency between two oxide semiconductor layers, resulting in the efficient design of experiment (DoE) and reducing the trial-and-error. Considering field effect mobility (Formula presented.) and threshold voltage (Vth) simultaneously, the dual-layer structure designed by the BO model allows to produce OS TFTs with remarkable electrical performance while significantly saving an amount of experimental trial (only 15 data sets are required). The optimized dual-layer OS TFTs achieve the enhanced field effect mobility of 36.1 cm2 V−1 s−1 and show good stability under bias stress with negligible difference in its threshold voltage compared to conventional IGZO TFTs. Moreover, the BO algorithm is successfully customized to the individual preferences by applying the weight factors assigned to both field effect mobility (Formula presented.) and threshold voltage (Vth).",
        "affiliation_name": "Graduate School of Convergence Science and Technology",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "3D Printed Conformal Strain and Humidity Sensors for Human Motion Prediction and Health Monitoring via Machine Learning",
        "paper_author": "Hou Y.",
        "publication": "Advanced Science",
        "citied_by": "18",
        "cover_date": "2023-12-27",
        "Abstract": "Wearable sensors have garnered considerable attention due to their flexibility and lightweight characteristics in the realm of healthcare applications. However, developing robust wearable sensors with facile fabrication and good conformity remains a challenge. In this study, a conductive graphene nanoplate-carbon nanotube (GC) ink is synthesized for multi jet fusion (MJF) printing. The layer-by-layer fabrication process of MJF not only improves the mechanical and flame-retardant properties of the printed GC sensor but also bolsters its robustness and sensitivity. The direction of sensor bending significantly impacts the relative resistance changes, allowing for precise investigations of joint motions in the human body, such as those of the fingers, wrists, elbows, necks, and knees. Furthermore, the data of resistance changes collected by the GC sensor are utilized to train a support vector machine with a 95.83% accuracy rate for predicting human motions. Due to its stable humidity sensitivity, the sensor also demonstrates excellent performance in monitoring human breath and predicting breath modes (normal, fast, and deep breath), thereby expanding its potential applications in healthcare. This work opens up new avenues for using MJF-printed wearable sensors for a variety of healthcare applications.",
        "affiliation_name": "Singapore Centre for 3D Printing",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Natural Products Derived Porous Carbons for CO<inf>2</inf> Capture",
        "paper_author": "Khosrowshahi M.S.",
        "publication": "Advanced Science",
        "citied_by": "29",
        "cover_date": "2023-12-27",
        "Abstract": "As it is now established that global warming and climate change are a reality, international investments are pouring in and rightfully so for climate change mitigation. Carbon capture and separation (CCS) is therefore gaining paramount importance as it is considered one of the powerful solutions for global warming. Sorption on porous materials is a promising alternative to traditional carbon dioxide (CO2) capture technologies. Owing to their sustainable availability, economic viability, and important recyclability, natural products-derived porous carbons have emerged as favorable and competitive materials for CO2 sorption. Furthermore, the fabrication of high-quality value-added functional porous carbon-based materials using renewable precursors and waste materials is an environmentally friendly approach. This review provides crucial insights and analyses to enhance the understanding of the application of porous carbons in CO2 capture. Various methods for the synthesis of porous carbon, their structural characterization, and parameters that influence their sorption properties are discussed. The review also delves into the utilization of molecular dynamics (MD), Monte Carlo (MC), density functional theory (DFT), and machine learning techniques for simulating adsorption and validating experimental results. Lastly, the review provides future outlook and research directions for progressing the use of natural products-derived porous carbons for CO2 capture.",
        "affiliation_name": "Iran University of Science and Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Multi-Layered Triboelectric Nanogenerators with Controllable Multiple Spikes for Low-Power Artificial Synaptic Devices",
        "paper_author": "Park Y.J.",
        "publication": "Advanced Science",
        "citied_by": "9",
        "cover_date": "2023-12-27",
        "Abstract": "In the domains of wearable electronics, robotics, and the Internet of Things, there is a demand for devices with low power consumption and the capability of multiplex sensing, memory, and learning. Triboelectric nanogenerators (TENGs) offer remarkable versatility in this regard, particularly when integrated with synaptic transistors that mimic biological synapses. However, conventional TENGs, generating only two spikes per cycle, have limitations when used in synaptic devices requiring repetitive high-frequency gating signals to perform various synaptic plasticity functions. Herein, a multi-layered micropatterned TENG (M-TENG) consisting of a polydimethylsiloxane (PDMS) film and a composite film that includes 1H,1H,2H,2H-perfluorooctyltrichlorosilane/BaTiO3/PDMS are proposed. The M-TENG generates multiple spikes from a single touch by utilizing separate triboelectric charges at the multiple friction layers, along with a contact/separation delay achieved by distinct spacers between layers. This configuration allows the maximum triboelectric output charge of M-TENG to reach up to 7.52 nC, compared to 3.69 nC for a single-layered TENG. Furthermore, by integrating M-TENGs with an organic electrochemical transistor, the spike number multiplication property of M-TENGs is leveraged to demonstrate an artificial synaptic device with low energy consumption. As a proof-of-concept application, a robotic hand is operated through continuous memory training under repeated stimulations, successfully emulating long-term plasticity.",
        "affiliation_name": "Ulsan National Institute of Science and Technology",
        "affiliation_city": "Ulsan",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Leveraging emerging technologies to enable environmental monitoring and accountability in conflict zones",
        "paper_author": "Zwijnenburg W.",
        "publication": "International Review of the Red Cross",
        "citied_by": "4",
        "cover_date": "2023-12-27",
        "Abstract": "The growth of access to the internet, wide availability of smart phones and increased public access to remote sensing data from hundreds of satellite systems have spurred a revolution in tracking the linkages between armed conflict and environmental damage. Over the last decade, a growing community of open-source investigative experts, environmentalists, academics and civil society groups have applied these methods to document war crimes, human rights violations and environmental degradation. These developments have created new opportunities for building accountability and transparency. The wealth of data on conflict-linked environmental damage has already been successfully leveraged to address acute and long-term environmental health risks and inform humanitarian response and post-conflict environmental assessments in Iraq, Syria and Ukraine. There are, however, larger questions on how to best make use of these data streams and information layers, and how to navigate the opportunities and limitations of these developments. This article will outline the new developments in this field and provide recommendations to ensure that data is used responsibly and effectively to strengthen accountability for environmental damages as a result of armed conflict.",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Correction: Exploration on the mechanism of therapeutic and toxic bidirectional effects of Haizao Yuhu decoction based on machine learning and data mining (Medical Data Mining, (2023), 6, 4, 21, 10.53388/MDM202306021)",
        "paper_author": "Chen Y.H.",
        "publication": "Medical Data Mining",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Medical Data Mining published an article entitled Exploration on the mechanism of therapeutic and toxic bidirectional effects of Haizao Yuhu decoction based on machine learning and data mining on 05 September 2023. The proof of this article was confirmed by author on 05 September 2023 without any questions. But on 11 September, 2023, the authors contacted the editorial office to state that the following formula is missing at the end of first paragraph in the section “The stability test of the network”, the error was not found and corrected during the article processing (formula presented) The editorial office considers this correction request to be accordance with the policy of Medical Data Mining and agrees to make the correction. So the full content of first paragraph in the section “The stability test of the network” should be as follows: The performance of the multi-layer network depends on its stability, namely invulnerability. When some nodes in the network are destroyed, the network still maintains connectivity. The invulnerability of the network is widely used in complex microbial communities or flora communities. We introduced this invulnerability measurement to the multilayer network, which can reflect the biological significance of the integrity and stability of the multilayer network of the HYD in the treatment of goiter and causing DILI. The detailed principle and calculation formula were recorded in the article of Wu et al. [16]. The specific calculation formula was: (Formula presented).",
        "affiliation_name": "Beijing University of Chinese Medicine",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Exploration on the mechanism of therapeutic and toxic bidirectional effects of Haizao Yuhu decoction based on machine learning and data mining",
        "paper_author": "Chen Y.H.",
        "publication": "Medical Data Mining",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Objective: To explore the bidirectional mechanism of Haizao Yuhu decoction (HYD) on goiter and drug-induced liver injury (DILI) based on machine learning and data mining. Methods: Firstly, compounds of HYD were selected from the TCMSP, TCMIP, and BATMAN databases, then the TCMSP was used to acquire the targets of compounds. Targets of goiter and DILI were obtained from the GeneCards database. Secondly, common targets of “HYD-goiter” and “HYD-DILI” as well as related compounds were used to construct the networks and perform Random Walk with Restart (RWR) algorithm and network stability test. Finally, core targets in the “HYD-goiter” and “HYD-DILI” networks were used for molecular docking with core compounds and searched for validation on PubChem, and the relevant experimental data of our group were quoted to verify the analysis results. Results: There were 22 intersection targets of HYD and DILI, 326 of HYD and goiter. RWR analysis showed that MAPK1, MAPK3, AKT1, etc. may be the core targets of HYD treating goiter, RELA, TNF, IL4, etc. may be the core targets of the bidirectional effect, and eckol may be the core compound in bidirectional effect. Network stability test indicated that the HYD had a high stability on treating goiter and playing a bidirectional effect. The core targets and core compounds docked well, and 37.3% of targets had been confirmed by experiments and 29.8% core targets had been confirmed. Our previous experimental result confirmed that the HYD could treat goiter usefully by reducing the expression levels of PI3K and AKT mRNA, and down-regulating the expression of Cyclin D1 and Bcl-2 mRNA. Conclusion: HYD containing “sargassum-liquorice” combination may have a bidirectional effect on treating goiter and causing DILI. We offered a new way for more explorations on the therapeutic and toxic bidirectional mechanisms based on machine learning and data mining.",
        "affiliation_name": "Beijing University of Chinese Medicine",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Artificial intelligence in oncologic imaging",
        "paper_author": "Cappello G.",
        "publication": "Multimodality Imaging and Intervention in Oncology",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Artificial intelligence (AI) is a branch of computer science dedicated to the development of computer algorithms to accomplish tasks traditionally associated with human intelligence. A device mimics cognitive functions, i.e., learning and problem solving, is powered by AI. A popular form of AI is machine learning.",
        "affiliation_name": "Candiolo Cancer Institute-FPO- IRCCS",
        "affiliation_city": "Candiolo",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Lung and mediastinal cancer",
        "paper_author": "Larici A.R.",
        "publication": "Multimodality Imaging and Intervention in Oncology",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Computed tomography (CT) with iodine-based contrast medium and 18-fluorine-fluorodeoxyglucose positron emission tomography/computed tomography ( Artificial intelligence (AI) is a branch of computer science dedicated to the development of computer algorithms to accomplish tasks traditionally associated with human intelligence. A device mimics cognitive functions, i.e., learning and problem solving, is powered by AI. A popular form of AI is machine learning.18 F-FDG PET/CT) play a crucial role in the diagnosis and staging of lung cancer and mediastinal neoplasms. Magnetic resonance imaging (MRI) with gadolinium-based contrast medium is a complementary tool to CT in lung cancer staging and is extremely useful for the differential diagnosis of mediastinal malignancies. Multimodality imaging also provides key information to guiding interventional diagnostic and therapeutic procedures in the field of lung cancer. Percutaneous ablation therapies (radiofrequency ablation, microwaves and cryoablation) have been widely employed as effective and safe therapeutic options in patients not candidates or refusing surgery. In this context, CT and 18 F-FDG PET/CT are essential for the assessment of adequate tumour ablation, identification of complications, and timely detection of eventual recurrence. Furthermore, other new interventional techniques are emerging as promising options for the locoregional administration of chemotherapeutic agents. This chapter provides an overview of morphological and functional imaging features and applications in the diagnosis and staging of lung and mediastinal malignancies as well as in the assessment of lung cancer after interventional treatments. Interventional diagnostic and treatment options for lung cancer will be discussed, focusing on the multidisciplinary approach and novelties in the field.",
        "affiliation_name": "Fondazione Policlinico Universitario Agostino Gemelli IRCCS",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Machine learning crash course for engineers",
        "paper_author": "Hossain E.",
        "publication": "Machine Learning Crash Course for Engineers",
        "citied_by": "3",
        "cover_date": "2023-12-26",
        "Abstract": "?Machine Learning Crash Course for Engineers is a reader-friendly introductory guide to machine learning algorithms and techniques for students, engineers, and other busy technical professionals. The book focuses on the application aspects of machine learning, progressing from the basics to advanced topics systematically from theory to applications and worked-out Python programming examples. It offers highly illustrated, step-by-step demonstrations that allow readers to implement machine learning models to solve real-world problems. This powerful tutorial is an excellent resource for those who need to acquire a solid foundational understanding of machine learning quickly.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Boise",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "INFORMATION SYSTEM FOR ASSESSING THE INFORMATIVENESS OF AN EPIDEMIC PROCESS FEATURES",
        "paper_author": "Bazilevych K.O.",
        "publication": "System Research and Information Technologies",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "The primary objective of this study is to assess the informativeness of various parameters influencing epidemic processes utilizing the Shannon and Kull-back–Leibler methods. These methods were selected based on their foundation in the principles of information theory and their extensive application in machine learning, statistics, and other relevant domains. A comparative analysis was performed between the results acquired from both methods, and an information system was designed to facilitate the uploading of data samples and the calculation of factor informativeness impacting the epidemic processes. The findings revealed that certain features, such as “Chronic lung disease,” “Chronic kidney disease,” and “Weakened immunity,” did not carry significant information for further analysis and hindered the forecasting process, as per the data set examined. The developed information system efficiently supports the assessment of feature informativeness, thereby aiding in the comprehensive analysis of epidemic processes and enabling the visualization of the results. This study contributes to the current body of knowledge by providing specific examples of applying the described algorithmic models, comparing various methods and their outcomes, and developing a supportive tool for analyzing epidemic processes.",
        "affiliation_name": "National Aerospace University “Kharkiv Aviation Institute”",
        "affiliation_city": "Kharkiv",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "METHODOLOGY OF THE COUNTRIES’ ECONOMIC DEVELOPMENT DATA ANALYSIS",
        "paper_author": "Donets V.V.",
        "publication": "System Research and Information Technologies",
        "citied_by": "1",
        "cover_date": "2023-12-26",
        "Abstract": "The paper examines the issue of improving the methods of identification of economic objects and their analysis using algorithms of intelligent data processing. The use of the developed methodology in the economic analysis allows for improvement in the quality of management. It can be the basis for creating decision support systems to prevent potentially dangerous changes in the economic status of the research object. In this work, an improved method of c-means data clustering with agent-oriented modification is proposed, and a radial-basis neural network and its extension are proposed to determine whether the obtained clusters are relevant and to analyze the informativeness of state variables and obtain a subset of informa-tive variables. The effect of applying data compression using an autoencoder on the accuracy of the methods is also considered. According to the results of testing of the developed methodology, it was proved that the probability of incorrect determina-tion of the state was reduced when identifying the states of economic systems, and a reduced value of the error of the third kind was obtained when classifying the states of objects.",
        "affiliation_name": "Simon Kuznets Kharkiv National University of Economics",
        "affiliation_city": "Kharkiv",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "MODELING CRYPTOCURRENCY MARKET DYNAMICS USING MACHINE LEARNING TOOLS",
        "paper_author": "Martjanov D.I.",
        "publication": "System Research and Information Technologies",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "The article analyzes the dynamics of the cryptocurrency market (Bitcoin) using econometric estimation tools based on machine learning models. The forecasting method is improved based on time series decomposition and lagged shifts of financial indicators. An ensemble of short-term forecast models for the Bitcoin exchange rate is built, and its accuracy is analyzed and compared to individual component models. Time series models are used along with calculated financial indicators (ADODS, NATR, TRANGE, ATR, OBV, RSI, ADTV). The absolute de-viation of the short-term forecast amounted to $9.5, which is 0.06% of the absolute value.",
        "affiliation_name": "Stepan Gzhytskyi National University of Veterinary Medicine and Biotechnologies of Lviv",
        "affiliation_city": "Lviv",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "A MULTI-LEVEL DECISION-MAKING FRAMEWORK FOR HEART-RELATED DISEASE PREDICTION AND RECOMMENDATION",
        "paper_author": "Sharma V.",
        "publication": "System Research and Information Technologies",
        "citied_by": "2",
        "cover_date": "2023-12-26",
        "Abstract": "The precise prediction of health-related issues is a significant challenge in healthcare, with heart-related diseases posing a particularly threatening global health problem. Accurate prediction and recommendation for heart-related diseases are crucial for timely and effective treatment solutions. The primary objective of this study is to develop a classification model capable of accurately identifying heart diseases and providing appropriate recommendations for patients. The proposed system utilizes a multilevel-based classification mechanism employing Support Vector Machines. It aims to categorize heart diseases by analyzing patient’s vital parameters. The performance of the proposed model was evaluated by testing it on a dataset con-taining patient records. The generated recommendations are based on a comprehensive assessment of the severity of clinical features exhibited by patients, including estimating the associated risk of both clinical features and the disease itself. The predictions were evaluated using three metrics: accuracy, specificity, and the receiver operating characteristic curve. The proposed Multilevel Support Vector Machine (MSVM) classification model achieved an accuracy rate of 94.09% in detecting the severity of heart disease. This makes it a valuable tool in the medical field for providing timely diagnosis and treatment recommendations. The proposed model presents a promising approach for accurately predicting heart-related diseases and highlights the potential of soft computing techniques in healthcare. Future research could focus on further enhancing the proposed model’s accuracy and applicability.",
        "affiliation_name": "Graphic Era Deemed to be University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Harnessing the power of artificial intelligence and data science",
        "paper_author": "Sakthivel V.",
        "publication": "Advancement of Data Processing Methods for Artificial and Computing Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Artificial intelligence (AI) and data science have a massive contribution by transforming the present world into a revolutionary step through their application in various fields to solve the most common problems. It gives the machines to exhibit human-like characteristics such as learning and problem-solving. Data science is the field of study of large amounts of data to discover previously unknown patterns and extract meaningful knowledge by combining domain expertise, using modern tools and techniques, and knowledge of mathematics and statistics. AI and data science are becoming much more important for the healthcare industry. It is helpful in getting better and faster diagnoses than humans. AI and data science applications in the domain of finance are huge. Time-series analysis and forecasting are useful tools for making quick and quality decisions that are for solving challenging real-time financial problems like stock market predictions. In today's world chatbots are used to make effective communication with its user. The use of chatbots is huge as they are universally used on various websites for providing information and guidance by interacting and explaining to human users how the company or product works with a quick and meaningful response. A virtual assistant is a digital assistant that recognizes simple voice commands and completes tasks for the user. This is also an application of AI and data science that enables virtual assistants to listen to the user's command, interpret it, and perform the task. It gives the users the power to set an alarm, play music from Spotify, make calls, send messages, make a shopping list, or provide information such as weather, facts from Wikipedia, search meaning of a word from the dictionary, etc., by browsing the web with just a simple natural language voice command. There are many more real-life applications, such as e-mail spam filtering, Recommendation systems, autocomplete, face recognition, etc.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Big data analytics with artificial intelligence: A comprehensive investigation",
        "paper_author": "Malik S.",
        "publication": "Advancement of Data Processing Methods for Artificial and Computing Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "The amount of digital data is expanding rapidly because of the quick advancements in digital technologies. As a result, several sources, including social media, smartphones, sensors, etc., produce a lot of data. Emerging technologies like the Internet of Things (IoT) and recent developments in sensor networks have allowed for the collection of vast amounts of data. Such vast kinds of data that cannot be stored and processed by traditional relational databases and analytical methods are called big data. More effective techniques with high analytical accuracy are required for the investigation of such vast amounts of data. It is consequently necessary to develop fresh tools and analytical methods to find patterns from massive datasets. Big data is swiftly created from a variety of sources and formats. To effectively leverage quickly changing data, novel analytical methods must now be able to identify correlations between them. In big data analytics, artificial intelligence (AI) techniques like machine learning, knowledge-based, and decision-making algorithms can produce results that are more accurate, quicker, and scalable. Despite this interest, we are not aware of any comprehensive analysis of the various artificial intelligence algorithms for big data analytics. The main objective of the current survey is to examine artificial intelligence-based big data analytics research. Well-known databases like ScienceDirect, IEEEXplore, ACM Digital Library, and SpringerLink are used to choose relevant research articles. \"Big data Analytics\", \"Artificial intelligence\", \"Big data Analytics\" and \"Machine Learning\", keywords are used to search the related research papers for the period 2017-2022. The AI techniques which are used to investigate the research papers are knowledge based, machine learning, search methods, and decision-making categories. In each category, several articles are investigated. This chapter also compares the selected AI-driven big data analytics techniques in terms of scalability, precision, efficiency, and privacy.",
        "affiliation_name": "Uttaranchal University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Efficient blurred and deblurred image classification using machine learning approach",
        "paper_author": "Udayakumar E.",
        "publication": "Advancement of Data Processing Methods for Artificial and Computing Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Images can be deteriorated for a variety of reasons. For instance, blurry images are produced by out-of-focus optics, while noise is produced by variations in electrical imaging systems. The blurred image classification and deblurring approach provided here uses DWT. After classifying the blurry image, there are ways to deblurring the given blurry image. The aim of blur image classification is finding blurred or unblurred images from input images. The deblurring of the photographs is presented toward the conclusion. This suggested deblurred image categorization and deblurred image can produce the best results. Finally, we evaluate the parameter analysis. This proposed scheme uses textural feature-based image classification using a neural network using a machine learning approach. Texture features are removed using the Gray level co-occurrence matrix, and the artificial neural network is advanced for the classification of images into dissimilar classes.",
        "affiliation_name": "Amity University Tashkent",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Role of big data analytics in the cloud applications",
        "paper_author": "Sakthivel V.",
        "publication": "Advancement of Data Processing Methods for Artificial and Computing Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "One of the most popular technologies which are relevant in today's IT industry would be cloud computing and big data analytics. Data are extremely large and can be used to analyze underlying trends, patterns, and correlations, which can be of business value is called big data. The datasets are so large that their volumes increase exponentially over time. The process of analyzing patterns in big data using advanced analytical techniques is called big data analytics. Whereas, cloud computing is the provision of computational services on demand, over the Internet. These services and the data stored are run on remote servers present in data centers across the world. These two concepts may seem to be very different from each other, but we can combine these two technologies to provide various services to people all over the Internet. Cloud Computing is now enabling the big data industry to achieve what it has not been able to in the past. To achieve the goals of big data analytics, cloud computing can be used as a platform. In cloud computing, the data which is remotely stored is processed in real-time, interpreted, and delivered appropriately to users. This improves the quality of customer services companies provide to their customers. Cloud can take in huge amounts of data and analyze it in a fraction of seconds. Moreover, since the type of data used in big data analytics is not always organized or in a standard format, the artificial intelligence and machine learning technologies of cloud computing can be used to convert the data into a standard format. This can prove to be very effective and economical for business enterprises. It is because traditional on-premise data centers are harder to manage and need a lot of maintenance by companies. Therefore, as an organization grows, it is better to shift its business model toward cloud. With these two technologies combined, companies can achieve economies of scale with minimal investment and improve overall customer experience.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Tyre Defect Detection using Deep Learning Technique",
        "paper_author": "Pathmanaban P.",
        "publication": "International Journal of Vehicle Structures and Systems",
        "citied_by": "2",
        "cover_date": "2023-12-26",
        "Abstract": "Tyre defects can pose safety hazards and increase maintenance costs. To address this issue, tyre defect detection using digital image processing and convolutional neural networks (CNN) has gained increasing attention recently. Given many manufactured items, the final quality inspection of mass-produced tyres is challenging. Quality aspects include materials, geometry, appearance and final functionality of the tyre. Visually, tyres are characterized by formal features such as annotations and barcodes, which are necessary for identifying the product. A high-quality product has a visually defect-free appearance. Digitizing the final quality inspection before the product leaves the factory is crucial to ensuring high quality. The industrial revolution strongly emphasizes automation, machine learning, sensory systems, digitization and data visualization, all of which are part of Industry 4.0 processes. Visual inspection of tyres is crucial to safe driving during and after the quality grading process. This study proposes a novel modified deep learning technique for inspecting tyres, achieving an average precision of 82.39% and detecting tyres at an average of 1.158 seconds, making them ideal for industrial use.",
        "affiliation_name": "Easwari Engineering College",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Towards a greener electrosynthesis: pairing machine learning and 3D printing for rapid optimisation of anodic trifluoromethylation",
        "paper_author": "Gupta N.K.",
        "publication": "RSC Sustainability",
        "citied_by": "4",
        "cover_date": "2023-12-26",
        "Abstract": "Applying electro-organic synthesis in flow configuration can potentially reduce the pharmaceutical industry's carbon footprint and simplify the reaction scale-up. However, the optimisation of such reactions has remained challenging due to the convoluted interplay between various input experimental parameters. Herein, we demonstrate the advantage of integrating a machine learning (ML) algorithm within an automated flow microreactor setup to assist in the optimisation of anodic trifluoromethylation without transition metal catalysts. The ML algorithm is able to optimise six reaction parameters concurrently and increase the reaction yield of anodic trifluoromethylation by >270% within two iterations. Furthermore, we discovered that suppression of electrode fouling and even higher reaction yields could be achieved by integrating 3D-printed metal electrodes into the microreactor. By coupling multiple analytical tools such as AC voltammetry, kinetic modelling, and gas chromatography, we gained holistic insights into the trifluoromethylation reaction mechanism, including potential sources of faradaic efficiency and reactant losses. More importantly, multiple electrochemical and non-electrochemical steps involved in this process are elucidated. Our findings highlight the potential of synergistically combining ML-assisted flow systems with advanced analytical tools to rapidly optimise complex electrosynthetic reactions sustainably.",
        "affiliation_name": "School of Chemistry, Chemical Engineering and Biotechnology",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Vibration Analysis and Predictive Maintenance on Gearbox of Lathe Machine Using Machine Learning",
        "paper_author": "Soetadi R.K.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-26",
        "Abstract": "In the Industry 4.0 era, the use of digital technologies to improve manufacturing chain efficiency and product quality through connectivity and digitization. The goal of this study is to use predictive maintenance using machine learning methods to avert unexpected engine. Maintenance strives to reduce and eliminate the number of failures that occur during manufacturing. Predictive Maintenance is the practice of monitoring the status of rotating equipment in order to discover early failures and prevent catastrophic breakdowns in critical components of a manufacturing chain. The implementation of predictive maintenance in machine learning algorithms can be used to perform lifetime detection activities with rotation (rpm) and usage time parameters. Machine learning can make predictions based on a specified data set. The results showed that the remaining service life of the gearbox component was 8411 hours and the vibration conditions produced by the gearbox were still at a satisfactory level according to the ISO 10816. Linear regression algorithms established their capacity to forecast a value by inputting RPM data and the length of time of use. We calculate the gearbox's RUL is 8414 hours. format.",
        "affiliation_name": "Universitas Muhammadiyah Malang",
        "affiliation_city": "Malang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "International Scientific and Practical Conference \"Railway Transport and Technologies\", RTT 2021",
        "paper_author": "NA",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "The proceedings contain 307 papers. The topics discussed include: improving the acceptance inspection technology for brake units of railway cars during routine uncoupling repair; web service for recognizing spam using machine learning methods; entropy models of network infrastructures; application for classifying network traffic using neural networks; classification of network traffic using machine learning methods; logistics of oil cargo transportation by rail; conceptual method for the development of management systems for fire and transport resources of forest protection services; modeling of wear and contact fatigue development processes in the ‘wheel/rail’ system; model of the ALSN transceiver with an orthogonally carrier code-frequency signal; modeling the dynamics of passenger traffic in road transport for the regional road network; and assessment of the competitive gap between the development indicators of international and Russian station complexes.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Fake news detection using machine learning techniques",
        "paper_author": "Bilal S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Access to news in our time has become very easy, for a person only has to browse social media and will be in direct contact with everything that is going on in the world. Still, despite these positives, many news and information spread are fake and unreal, aiming to mislead public opinion. In this paper, we study fake news detection with machine learning. Right now, we live in a world of misinformation and fake news. The goal of this study is to detect fake news using recurrent neural networks. AI (Artificial Intelligence) and ML (Machine Learning)-based counterfeit news detectors are crucial for companies and media to predict whether circulating news is fake or not automatically. In this study, we analyze thousands of news texts to detect if they are fake or not. Our model is a type of artificial neural network known as LSTM or long short-term memory network which is type of recurrent neural networks. The primary purpose is to classify the news and achieve good results at the end of the project.",
        "affiliation_name": "Donskoj Gosudarstvennyj Tehniceskij Universitet",
        "affiliation_city": "Rostov-on-Don",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Web service for recognizing spam using machine learning methods",
        "paper_author": "Zhulev A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "The Internet these days is a vital necessity for almost every person. The widespread distribution of this technology entails various violations of information security. One of which is the distribution of spam messages. This article describes a web service for recognizing spam. The developed web service allows to collect, mark up and preprocess data. The architecture of the system and its individual components was designed. Also, a model has been developed for finding spam messages based on LSTM. It was trained and tested.",
        "affiliation_name": "Kutafin Moscow State Law University",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Using the module \"analytics and machine learning\" in LMS moodle at training students of specialty \"rolling stock\"",
        "paper_author": "Sergeev K.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-26",
        "Abstract": "The Moodle LMS distance learning system, thanks to its open source code and wide capabilities, is popular all over the world, including in Russia. This article discusses the application of the add-on \"Moodle Learning Analytics\"(Analytics and machine learning) in the Moodle LMS when teaching students specialty \"Rolling stock\", significantly expanding its capabilities, providing a rich range of analytical data. The main features of this add-on are shown. Specific recommendations for setting up and operating \"Moodle Learning Analytics\"are given.",
        "affiliation_name": "Russian University of Transport",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Classification of network traffic using machine learning methods",
        "paper_author": "Nazarenko E.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-26",
        "Abstract": "Studies by scientists several years ago showed that the ineffectiveness of detecting and mitigating the damage of DDoS attacks is directly related to persistent configuration errors and wasted time, as well as a lack of tools that monitor the dynamics of the network without constant human intervention. This has led to use of stand-alone solutions that can operate based on traffic behavior and characteristics. In this sense, decision making using machine learning-based methods was highly flexible in the classification process, which improved the detection of malicious traffic. The article discusses a number of machine learning methods, provides algorithm settings and provides quality metrics for a number of experiments.",
        "affiliation_name": "Kutafin Moscow State Law University",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Clinical Informatics Approaches to Facilitate Cancer Data Sharing",
        "paper_author": "Aneja S.",
        "publication": "Yearbook of Medical Informatics",
        "citied_by": "3",
        "cover_date": "2023-12-26",
        "Abstract": "Objectives: Despite growing enthusiasm surrounding the utility of clinical informatics to improve cancer outcomes, data availability remains a persistent bottleneck to progress. Difficulty combining data with protected health information often limits our ability to aggregate larger more representative datasets for analysis. With the rise of machine learning techniques that require increasing amounts of clinical data, these barriers have magnified. Here, we review recent efforts within clinical informatics to address issues related to safely sharing cancer data. Methods: We carried out a narrative review of clinical informatics studies related to sharing protected health data within cancer studies published from 2018-2022, with a focus on domains such as decentralized analytics, homomorphic encryption, and common data models. Results: Clinical informatics studies that investigated cancer data sharing were identified. A particular focus of the search yielded studies on decentralized analytics, homomorphic encryption, and common data models. Decentralized analytics has been prototyped across genomic, imaging, and clinical data with the most advances in diagnostic image analysis. Homomorphic encryption was most often employed on genomic data and less on imaging and clinical data. Common data models primarily involve clinical data from the electronic health record. Although all methods have robust research, there are limited studies showing wide scale implementation. Conclusions: Decentralized analytics, homomorphic encryption, and common data models represent promising solutions to improve cancer data sharing. Promising results thus far have been limited to smaller settings. Future studies should be focused on evaluating the scalability and efficacy of these methods across clinical settings of varying resources and expertise.",
        "affiliation_name": "Yale School of Medicine",
        "affiliation_city": "New Haven",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "7-Methoxy-4-methylcoumarin: Standard Molar Enthalpy of Formation Prediction in the Gas Phase Using Machine Learning and Its Comparison to the Experimental Data",
        "paper_author": "Díaz-Sánchez F.",
        "publication": "ACS Omega",
        "citied_by": "1",
        "cover_date": "2023-12-26",
        "Abstract": "Experimentally, the standard molar enthalpy of formation in the crystalline phase at 298.15 K, ΔfHm°(cr) for 7-methoxy-4-methylcoumarin (7M4MC) was calculated by traditional linear regression, which was obtained by combustion calorimetry. Similarly, the standard molar enthalpy of sublimation was determined through the standard molar enthalpy of fusion and by the standard molar enthalpy of vaporization, from differential scanning calorimetry and thermogravimetry, respectively; lately using these results, the standard molar enthalpy of formation in the gas phase was calculated at 298.15 K, ΔfHm°(g). In addition ML was used to predict the standard molar enthalpy of formation in the gas phase for the 7M4MC, constructing an experimental data set containing three kinds of functional groups: esters, coumarins, and aromatic compounds. The procedure was performed by using multiple linear regression algorithms and stochastic gradient descent with a R2 of 0.99. The obtained models were used to compare those predicted values versus experimental for coumarins, resulting in an average error rate of 9.0%. Likewise, four homodesmic reactions were proposed and predicted with the multiple linear regression algorithm of ML obtaining good results.",
        "affiliation_name": "Benemérita Universidad Autónoma de Puebla",
        "affiliation_city": "Puebla",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Controllable Copolymerization of Polymeric Micelles for the Construction of Supramolecular Chains",
        "paper_author": "Yao Y.",
        "publication": "Macromolecules",
        "citied_by": "2",
        "cover_date": "2023-12-26",
        "Abstract": "Supramolecular polymerization of nanoparticles is attracting considerable attention for preparing one-dimensional (1D) nanostructures with controllable geometries and promising properties. However, so far, little is known about the supramolecular copolymerization of polymeric micelles, including the general rules and polymerization kinetics. Herein, we demonstrate a supramolecular copolymerization of micelles with various activities into supramolecular chains with controllable lengths and sequences including random, block, and alternate. It is also found that micelles with extremely low activity can act as supramolecular chain stoppers to terminate the polymerization. Since accurate statistical data on supramolecular copolymerization is crucial for revealing the mechanism and building a theoretical model, we propose a machine learning-based image recognition method. This method can precisely differentiate various micellar subunits in the supramolecular copolymer chains. A theoretical kinetic model is proposed, and the kinetic studies reveal that diffusion of the micelles plays a dominant role in supramolecular copolymerization. This work enriches the supramolecular polymerization of micelles and provides theoretical guidance for the engineering of 1D nanostructures with controllable structures.",
        "affiliation_name": "Shanghai Key Laboratory of Advanced Polymeric Materials",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of Ion Mobility Spectrometry and the Derived Collision Cross Section in the Analysis of Environmental Organic Micropollutants",
        "paper_author": "Song X.C.",
        "publication": "Environmental Science and Technology",
        "citied_by": "6",
        "cover_date": "2023-12-26",
        "Abstract": "Ion mobility spectrometry (IMS) is a rapid gas-phase separation technique, which can distinguish ions on the basis of their size, shape, and charge. The IMS-derived collision cross section (CCS) can serve as additional identification evidence for the screening of environmental organic micropollutants (OMPs). In this work, we summarize the published experimental CCS values of environmental OMPs, introduce the current CCS prediction tools, summarize the use of IMS and CCS in the analysis of environmental OMPs, and finally discussed the benefits of IMS and CCS in environmental analysis. An up-to-date CCS compendium for environmental contaminants was produced by combining CCS databases and data sets of particular types of environmental OMPs, including pesticides, drugs, mycotoxins, steroids, plastic additives, per- and polyfluoroalkyl substances (PFAS), polycyclic aromatic hydrocarbons (PAHs), polychlorinated biphenyls (PCBs), and polybrominated diphenyl ethers (PBDEs), as well as their well-known transformation products. A total of 9407 experimental CCS values from 4170 OMPs were retrieved from 23 publications, which contain both drift tube CCS in nitrogen (DTCCSN2) and traveling wave CCS in nitrogen (TWCCSN2). A selection of publicly accessible and in-house CCS prediction tools were also investigated; the chemical space covered by the training set and the quality of CCS measurements seem to be vital factors affecting the CCS prediction accuracy. Then, the applications of IMS and the derived CCS in the screening of various OMPs were summarized, and the benefits of IMS and CCS, including increased peak capacity, the elimination of interfering ions, the separation of isomers, and the reduction of false positives and false negatives, were discussed in detail. With the improvement of the resolving power of IMS and enhancements of experimental CCS databases, the practicability of IMS in the analysis of environmental OMPs will continue to improve.",
        "affiliation_name": "College of Sciences, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning-Assisted Automatically Electrochemical Addressable Cytosensing Arrays for Anticancer Drug Screening",
        "paper_author": "Zhang J.",
        "publication": "Analytical Chemistry",
        "citied_by": "7",
        "cover_date": "2023-12-26",
        "Abstract": "The high-throughput and accurate screening of anticancer drugs is crucial to the preclinical assessment of candidate drugs and remains challenging. Herein, an automatically electrochemical addressable cytosensor (AEAC) for the efficient screening of anticancer drugs is reported. This sensor consists of sectionalized laser-induced graphene arrays decorated by the rhombohedral TiO2 and spherical Pt nanoparticles (LIG-TiO2-Pt) with high electrocatalytic activity for H2O2 and a homemade Ag/Pt electrode couple fixed onto the robot arm. The immobilization of laminin on the surface of LIG-TiO2-Pt can promote its biocompatibility for the growth and proliferation of various tumor cells, which empowers the in situ monitoring of H2O2 directly released from these live cells for drug screening. A machine learning (ML) algorithm is employed to eliminate the possible random or systematic errors of AEAC, realizing rapid, high-throughput, and accurate prediction of different types of anticancer drugs. This ML-assisted AEAC provides a powerful approach to accelerate the evolution of sensing-served tumor therapy.",
        "affiliation_name": "Wuhan Business University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine and Deep Learning Dominate Recent Innovations in Sensors, Signals and Imaging Informatics",
        "paper_author": "Baumgartner C.",
        "publication": "Yearbook of Medical Informatics",
        "citied_by": "1",
        "cover_date": "2023-12-26",
        "Abstract": "Objectives: This review presents research papers highlighting notable developments and trends in sensors, signals, and imaging informatics (SSII) in 2022. Method: We performed a bibliographic search in PubMed combining Medical Subject Heading (MeSH) terms and keywords to create particular queries for sensors, signals, and imaging informatics. Only papers published in journals containing greater than three articles in the search query were considered. Using a three-point Likert scale (1 = not include, 2 = perhaps include, 3 = include), we reviewed the titles and abstracts of all database results. Only articles that scored three times Likert scale 3, or two times Likert scale 3, and one time Likert scale 2 were considered for full paper review. On this pre-selection, only papers with a total of at least eight points of the three section co-editors were considered for external review. Based on the external reviewers, we selected the top two papers representing significant research in SSII. Results: Among the 469 returned papers published in 2022 in the various areas of SSII, 90, 31, and 348 papers for sensors, signals, and imaging informatics, and then, the full review process selected the two best papers. From the 469 papers, the section co-editors identified 29 candidate papers with at least 8 Likert points in total, of which 9 were nominated as the best contributions after a full paper assessment. Five external reviewers evaluated the nominated papers, and the two highest-scoring papers were selected based on the overall scores of all external reviewers. A consensus of the International Medical Informatics Association (IMIA) Yearbook editorial board finally approved the nominated papers. Machine and deep learning-based techniques continue to be the dominant theme in this field. Conclusions: Sensors, signals, and imaging informatics is a dynamic field of intensive research with increasing practical applications to support medical decision-making on a personalized basis.",
        "affiliation_name": "Peter L. Reichertz Institut für Medizinische Informatik",
        "affiliation_city": "Braunschweig",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Intersecting Pathways in Bioinformatics and Translational Informatics: A One Health Perspective on Key Contributions and Future Directions",
        "paper_author": "Benton M.L.",
        "publication": "Yearbook of Medical Informatics",
        "citied_by": "1",
        "cover_date": "2023-12-26",
        "Abstract": "Objectives: To identify and summarize the top bioinformatics and translational informatics (BTI) papers published in 2022 for the International Medical Informatics Association (IMIA) Yearbook 2023. Methods: We conducted a comprehensive literature search to identify the top BTI papers, resulting in a set of ten candidate papers. The candidates were reviewed by the section co-editors and external reviewers to select the top three papers from 2022. Results: From a total of 558 papers, we identified a final candidate list of ten BTI papers for peer-review. These papers apply new statistical frameworks and experimental designs to better capture individual variability in disease and incorporate data that captures differences between single cells and across environmental exposures. In addition, they highlight the importance of model generalization across diverse cohorts and scalability to large medical centers. Conclusions: We note several important trends in the candidate top BTI papers this year, including a continued focus on developing accurate and scalable computational models to predict disease risk across diverse cohorts and new strategies to capture the molecular heterogeneity of disease.",
        "affiliation_name": "School of Engineering &amp; Computer Science",
        "affiliation_city": "Waco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Security and Privacy in Machine Learning for Health Systems: Strategies and Challenges",
        "paper_author": "de Aguiar E.J.",
        "publication": "Yearbook of Medical Informatics",
        "citied_by": "3",
        "cover_date": "2023-12-26",
        "Abstract": "Objectives: Machine learning (ML) is a powerful asset to support physicians in decision-making procedures, providing timely answers. However, ML for health systems can suffer from security attacks and privacy violations. This paper investigates studies of security and privacy in ML for health. Methods: We examine attacks, defenses, and privacy-preserving strategies, discussing their challenges. We conducted the following research protocol: starting a manual search, defining the search string, removing duplicated papers, filtering papers by title and abstract, then their full texts, and analyzing their contributions, including strategies and challenges. Finally, we collected and discussed 40 papers on attacks, defense, and privacy. Results: Our findings identified the most employed strategies for each domain. We found trends in attacks, including universal adversarial perturbation (UAPs), generative adversarial network (GAN)-based attacks, and DeepFakes to generate malicious examples. Trends in defense are adversarial training, GAN-based strategies, and out-of-distribution (OOD) to identify and mitigate adversarial examples (AE). We found privacy-preserving strategies such as federated learning (FL), differential privacy, and combinations of strategies to enhance the FL. Challenges in privacy comprehend the development of attacks that bypass fine-tuning, defenses to calibrate models to improve their robustness, and privacy methods to enhance the FL strategy. Conclusions: In conclusion, it is critical to explore security and privacy in ML for health, because it has grown risks and open vulnerabilities. Our study presents strategies and challenges to guide research to investigate issues about security and privacy in ML applied to health systems.",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Boosting Graph Neural Networks with Molecular Mechanics: A Case Study of Sigma Profile Prediction",
        "paper_author": "Abranches D.O.",
        "publication": "Journal of Chemical Theory and Computation",
        "citied_by": "4",
        "cover_date": "2023-12-26",
        "Abstract": "Sigma profiles are quantum-chemistry-derived molecular descriptors that encode the polarity of molecules. They have shown great performance when used as a feature in machine learning applications. To accelerate the development of these models and the construction of large sigma profile databases, this work proposes a graph convolutional network (GCN) architecture to predict sigma profiles from molecule structures. To do so, the usage of molecular mechanics (force field atom types) is explored as a computationally inexpensive node-level featurization technique to encode the local and global chemical environments of atoms in molecules. The GCN models developed in this work accurately predict the sigma profiles of assorted organic and inorganic compounds. The best GCN model here reported, obtained using Merck molecular force field (MMFF) atom types, displayed training and testing set coefficients of determination of 0.98 and 0.96, respectively, which are superior to previous methodologies reported in the literature. This performance boost is shown to be due to both the usage of a convolutional architecture and node-level features based on force field atom types. Finally, to demonstrate their practical applicability, we used GCN-predicted sigma profiles as the input to machine learning models previously developed in the literature that predict boiling temperatures and aqueous solubilities. Using the predicted sigma profiles as input, these models were able to compute both physicochemical properties using significantly less computational resources and displayed only a slight decrease in performance when compared with sigma profiles obtained from quantum chemistry methods.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Notre Dame",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Accelerated Organic Crystal Structure Prediction with Genetic Algorithms and Machine Learning",
        "paper_author": "Kadan A.",
        "publication": "Journal of Chemical Theory and Computation",
        "citied_by": "8",
        "cover_date": "2023-12-26",
        "Abstract": "We present a high-throughput, end-to-end pipeline for organic crystal structure prediction (CSP)─the problem of identifying the stable crystal structures that will form from a given molecule based only on its molecular composition. Our tool uses neural network potentials to allow for efficient screening and structural relaxation of generated crystal candidates. Our pipeline consists of two distinct stages: random search, whereby crystal candidates are randomly generated and screened, and optimization, where a genetic algorithm (GA) optimizes this screened population. We assess the performance of each stage of our pipeline on 21 molecules taken from the Cambridge Crystallographic Data Centre’s CSP blind tests. We show that random search alone yields matches for ≈50% of targets. We then validate the potential of our full pipeline, making use of the GA to optimize the root-mean-square deviation between crystal candidates and the experimentally derived structure. With this approach, we are able to find matches for ≈80% of candidates with 10-100 times smaller initial population sizes than when using random search. Lastly, we run our full pipeline with an ANI model that is trained on a small data set of molecules extracted from crystal structures in the Cambridge Structural Database, generating ≈60% of targets. By leveraging machine learning models trained to predict energies at the density functional theory level, our pipeline has the potential to approach the accuracy of ab initio methods and the efficiency of empirical force fields.",
        "affiliation_name": "College of Liberal Arts and Sciences",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Oxygen Vacancy Formation Energy in Metal Oxides: High-Throughput Computational Studies and Machine-Learning Predictions",
        "paper_author": "Baldassarri B.",
        "publication": "Chemistry of Materials",
        "citied_by": "10",
        "cover_date": "2023-12-26",
        "Abstract": "The oxygen vacancy formation energy (ΔEvf) governs defect concentrations alongside the entropy and is a useful metric to perform materials selection for a variety of applications. However, density functional theory (DFT) calculations of ΔEvf come at a greater computational cost than the typical bulk calculations available in materials databases due to the involvement of multiple vacancy-containing supercells. As a result, available repositories of direct calculations of ΔEvf remain relatively scarce, and the development of machine-learning models capable of delivering accurate predictions is of interest. In the present work, we address both such points. We first report the results of new high-throughput DFT calculations of oxygen vacancy formation energies of the different unique oxygen sites in over 1000 different oxide materials, with a large portion of the calculations, and of the discussion, focusing on perovskite-type and pyrochlore-type oxides. Together, the over 2500 ΔEvf calculations form the largest data set of directly computed oxygen vacancy formation energies to date, to our knowledge. We then utilize such a data set to train random forest models with different sets of features, examining both novel features introduced in this work and ones previously employed in the literature. We demonstrate the benefits of including features that contain information specific to the vacancy site and account for both cation identity and oxidation state and achieve a mean absolute error upon prediction of ∼0.3 eV/O, which is comparable to the accuracy observed upon comparison of DFT computations of oxygen vacancy formation energy and experimental results. Finally, we exemplify the predictive power of the developed models in the search for new compounds for solar-thermochemical water-splitting applications, finding over 250 new AA′BB′O6 double perovskite candidates.",
        "affiliation_name": "Robert R. McCormick School of Engineering and Applied Science",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Interfacial Electron Transfer in Chemical and Biological Transformation of Pollutants in Environmental Catalysis",
        "paper_author": "Chen J.J.",
        "publication": "Environmental Science and Technology",
        "citied_by": "6",
        "cover_date": "2023-12-26",
        "Abstract": "Interfacial electron transfer (IET) is essential for chemical and biological transformation of pollutants, operative across diverse lengths and time scales. This Perspective presents an array of multiscale molecular simulation methodologies, supplemented by in situ monitoring and imaging techniques, serving as robust tools to decode IET enhancement mechanisms such as interface molecular modification, catalyst coordination mode, and atomic composition regulation. In addition, three IET-based pollutant transformation systems, an electrocatalytic oxidation system, a bioelectrochemical spatial coupling system, and an enzyme-inspired electrocatalytic system, were developed, demonstrating a high effect in transforming and degrading pollutants. To improve the effectiveness and scalability of IET-based strategies, the refinement of these systems is necessitated through rigorous research and theoretical exploration, particularly in the context of practical wastewater treatment scenarios. Future endeavors aim to elucidate the synergy between biological and chemical modules, edit the environmental functional microorganisms, and harness machine learning for designing advanced environmental catalysts to boost efficiency. This Perspective highlights the powerful potential of IET-focused environmental remediation strategies, emphasizing the critical role of interdisciplinary research in addressing the urgent global challenge of water pollution.",
        "affiliation_name": "CAS Key Laboratory Of Urban Pollutant Conversion",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Tuning the Through-Plane Lattice Thermal Conductivity in van der Waals Structures through Rotational (Dis)ordering",
        "paper_author": "Eriksson F.",
        "publication": "ACS Nano",
        "citied_by": "12",
        "cover_date": "2023-12-26",
        "Abstract": "It has recently been demonstrated that MoS2 with irregular interlayer rotations can achieve an extreme anisotropy in the lattice thermal conductivity (LTC), which is, for example, of interest for applications in waste heat management in integrated circuits. Here, we show by atomic-scale simulations based on machine-learned potentials that this principle extends to other two-dimensional materials, including C and BN. In all three materials, introducing rotational disorder drives the through-plane LTC to the glass limit, while the in-plane LTC remains almost unchanged compared to those of the ideal bulk materials. We demonstrate that the ultralow through-plane LTC is connected to the collapse of their transverse acoustic modes in the through-plane direction. Furthermore, we find that the twist angle in periodic moiré structures representing rotational order provides an efficient means for tuning the through-plane LTC that operates for all chemistries considered here. The minimal through-plane LTC is obtained for angles between 1 and 4° depending on the material, with the biggest effect in MoS2. The angular dependence is correlated with the degree of stacking disorder in the materials, which in turn is connected to the slip surface. This provides a simple descriptor for predicting the optimal conditions at which the LTC is expected to become minimal.",
        "affiliation_name": "Bohai University",
        "affiliation_city": "Jinzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Integrating Augmented In Situ Measurements and a Spatiotemporal Machine Learning Model To Back Extrapolate Historical Particulate Matter Pollution over the United Kingdom: 1980-2019",
        "paper_author": "Liu R.",
        "publication": "Environmental Science and Technology",
        "citied_by": "4",
        "cover_date": "2023-12-26",
        "Abstract": "Historical PM2.5 data are essential for assessing the health effects of air pollution exposure across the life course or early life. However, a lack of high-quality data sources, such as satellite-based aerosol optical depth before 2000, has resulted in a gap in spatiotemporally resolved PM2.5 data for historical periods. Taking the United Kingdom as an example, we leveraged the light gradient boosting model to capture the spatiotemporal association between PM2.5 concentrations and multi-source geospatial predictors. Augmented PM2.5 from PM10 measurements expanded the spatiotemporal representativeness of the ground measurements. Observations before and after 2009 were used to train and test the models, respectively. Our model showed fair prediction accuracy from 2010 to 2019 [the ranges of coefficients of determination (R2) for the grid-based cross-validation are 0.71-0.85] and commendable back extrapolation performance from 1998 to 2009 (the ranges of R2 for the independent external testing are 0.32-0.65) at the daily level. The pollution episodes in the 1980s and pollution levels in the 1990s were also reproduced by our model. The 4-decade PM2.5 estimates demonstrated that most regions in England witnessed significant downward trends in PM2.5 pollution. The methods developed in this study are generalizable to other data-rich regions for historical air pollution exposure assessment.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Optimal Surrogate Models for Predicting the Elastic Moduli of Metal-Organic Frameworks via Multiscale Features",
        "paper_author": "Lee J.",
        "publication": "Chemistry of Materials",
        "citied_by": "6",
        "cover_date": "2023-12-26",
        "Abstract": "Evaluating the mechanical stability of metal-organic frameworks (MOFs) is essential for their successful application in various fields. Therefore, the objective of this study was to develop optimal machine learning (ML) models for predicting the bulk and shear moduli of MOFs. Considering the effects of global (such as porosity and topology) and local features (including metal nodes and organic linkers) on the mechanical stability of MOFs, we developed multiscale features that can incorporate both types of features. To this end, we first explored descriptors representing the global and local features of MOFs from data sets of previous studies in which elastic moduli were computed. We then assessed the performance of various combinations of these descriptors to determine the optimal multiscale features for predicting the elastic moduli. The optimal surrogate models trained using multiscale features exhibited R2 values of 0.868 and 0.824 for bulk and shear moduli, respectively. Furthermore, the surrogate models outperformed the prior benchmarks. Finally, through model interpretation, we discovered that for similar pore sizes, metal nodes are the most dominant factor affecting the mechanical properties of MOFs. We anticipate that our approach will be a valuable tool for future research on the discovery of mechanically robust MOFs for various industrial applications.",
        "affiliation_name": "Pohang University of Science and Technology",
        "affiliation_city": "Pohang",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A Flexible Self-Powered Noncontact Sensor with an Ultrawide Sensing Range for Human-Machine Interactions in Harsh Environments",
        "paper_author": "Dai N.",
        "publication": "ACS Nano",
        "citied_by": "11",
        "cover_date": "2023-12-26",
        "Abstract": "Noncontact human-machine interactions (HMIs) provide a hygienic and intelligent approach to communicate between humans and machines. However, current noncontact HMIs are generally hampered by the interaction distance, and they lack the adaptability to environmental interference such as high humidity conditions. Here, we explore a self-powered electret-based noncontact sensor (ENS) with moisture-resisting ability and ultrawide sensing range exceeding 2.5 m. A megascopic air-bubble structure is designed to enhance charge-storage stability and charge-recovery ability of the ENS based on the heterocharge-synergy effect in electrets. Besides, multilayer electret films are introduced to strengthen the electric field by utilizing the electrostatic field superposition effect. Thanks to the above improved performances of the ENS, we demonstrate various noncontact HMI applications in harsh environments, including noncontact appliances, a moving trajectory and accidental fall tracking system, and a real-time machine learning-assisted gesture recognition system with accuracy as high as 99.21%. This research expands the way for noncontact sensor design and may further broaden applications in noncontact HMIs.",
        "affiliation_name": "Shenzhen Institute of Advanced Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Stone-Wales Decorated Phagraphene: A Potential Candidate for Supercapacitor Electrodes and Thermal Transport",
        "paper_author": "Ghosh M.",
        "publication": "ACS Applied Electronic Materials",
        "citied_by": "4",
        "cover_date": "2023-12-26",
        "Abstract": "Carbon-based electrical double-layer capacitors or EDLC supercapacitors have recently gained much attention due to their cost-effectiveness, environment friendliness, and stable energy supply. However, the total capacitance of the supercapacitors is limited by the quantum capacitance (QC) of the electrodes. In this work, we have addressed the effect of defect-induced modifications of QC of EDLC supercapacitors by introducing Stone-Wales (SW) defects in pristine phagraphene. The stability of the structure has been confirmed in terms of its dynamical, thermal, and mechanical attributes. A systematic investigation of the electronic and transport properties of SW-decorated phagraphene has been carried out using density functional theory calculations and machine learning approaches. The electronic nature of the structure becomes metallic due to the change in the local symmetry with a modified orbital contribution near the Fermi energy. Besides, a significantly high Debye temperature (2606 K) indicates good thermal transport of the system. The lattice thermal conductivity of the structure was calculated using a machine learning interatomic potential (MLIP) approach. Good thermal conductivity strengthens their potential in next-generation device applications. Interestingly, large specific surface area (SSA), high density of states (DOS) near Fermi energy, and good electrical conductivity of these structures indicate their suitability as supercapacitor electrodes. Considerably high QC and total surface storage charge calculations suggest their applications as anodes in asymmetric supercapacitors. We believe these results will deliver valuable insights into the understanding of carbon-based two-dimensional (2D) metallic structures.",
        "affiliation_name": "University of Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Wearable and Cost-Effective Pressure Sensor Based on a Carbon Nanotube/Polyurethane Sponge for Motion Detection and Gesture Recognition",
        "paper_author": "Wang F.",
        "publication": "ACS Applied Electronic Materials",
        "citied_by": "9",
        "cover_date": "2023-12-26",
        "Abstract": "Flexible pressure sensors are important for various fields including human-machine interaction, motion detection, and gesture recognition. In this study, a piezoresistive pressure sensor is developed using a composite material of carbon nanotubes and a polyurethane sponge. The sensor is fabricated through a dipping-drying method, which enables the carbon nanotubes (CNTs) to adhere to the skeleton of the polyurethane sponge (PUS). The sensor obtained displays superior features: excellent sensitivity (2.7% kPa-1), prompt response (response/recovery time of 60/100 ms), and remarkable long-term stability demonstrated by a consistent response signal during loading/unloading cycles with the range of 0-100 kPa at 0.1 Hz for a period of 18,000 s. In addition, the sensor was placed on different parts of the human body to detect human motion signals. It has been demonstrated that the sensor can effectively capture these diverse signals to distinguish between different motion states. Additionally, the sensor can accurately convey the Morse code of the 26 letters of the alphabet and the 10 Arabic numerals through regular pressing. Finally, a sensory glove was created using the sensors, which is used to express the gestures of Arabic numerals 0-9. A deep-learning algorithm based on the Inception Network has achieved a high-accuracy (99.5%) gesture recognition for 10 gestures. This work offers a cost-effective and simple way to produce flexible pressure sensors that can be employed in various applications, including human motion detection, wearable devices, gesture recognition, and human-machine interaction.",
        "affiliation_name": "Anhui Jianzhu University",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Topological Data Analysis of Nanoscale Roughness of Layer-by-Layer Polyelectrolyte Samples Using Machine Learning",
        "paper_author": "Aglikov A.S.",
        "publication": "ACS Applied Electronic Materials",
        "citied_by": "5",
        "cover_date": "2023-12-26",
        "Abstract": "The surface roughness of layer-by-layer (LbL) polyelectrolytes is studied by atomic force microscopy (AFM) and analyzed with novel methods including topological data analysis (TDA) and machine learning (ML) to correlate multiscale roughness with the number of bilayers and to recognize the types of polyelectrolytes (PEs). LbL PEs composed of one to four bilayers of (1) polyethylenimine (PEI)/poly(sodium 4-styrenesulfonate) (PSS), (2) PEI/poly(acrylic acid) (PAA), and (3) PEI/MXene rigid flakes are deposited on a smooth silicon wafer. With a growing number of bilayers, the roughness changes from a smooth surface to an equilibrium rough profile. The AFM study of the surface morphology demonstrates that surface roughness is multiscale, with smaller features imposed on larger ones. Roughness data is filtered from measurement resolution artifacts, and several methods are applied: correlation length, statistics of the distribution of extremes in trimmed images, and TDA barcodes and persistence diagrams of simplexes in 8D data space. An ML algorithm is used to determine the number of bilayers in a PE. Roughness analysis indicates a gradual transition from a smooth to a rough surface with saturation at three to four bilayers and the existence of multiscale roughness invariance.",
        "affiliation_name": "College of Engineering &amp; Applied Science",
        "affiliation_city": "Milwaukee",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Molecular Free Energies, Rates, and Mechanisms from Data-Efficient Path Sampling Simulations",
        "paper_author": "Lazzeri G.",
        "publication": "Journal of Chemical Theory and Computation",
        "citied_by": "15",
        "cover_date": "2023-12-26",
        "Abstract": "Molecular dynamics is a powerful tool for studying the thermodynamics and kinetics of complex molecular events. However, these simulations can rarely sample the required time scales in practice. Transition path sampling overcomes this limitation by collecting unbiased trajectories and capturing the relevant events. Moreover, the integration of machine learning can boost the sampling while simultaneously learning a quantitative representation of the mechanism. Still, the resulting trajectories are by construction non-Boltzmann-distributed, preventing the calculation of free energies and rates. We developed an algorithm to approximate the equilibrium path ensemble from machine-learning-guided path sampling data. At the same time, our algorithm provides efficient sampling, mechanism, free energy, and rates of rare molecular events at a very moderate computational cost. We tested the method on the folding of the mini-protein chignolin. Our algorithm is straightforward and data-efficient, opening the door to applications in many challenging molecular systems.",
        "affiliation_name": "Frankfurt Institute for Advanced Studies",
        "affiliation_city": "Frankfurt am Main",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Triboelectric Nanogenerator Assisted by Machine Learning",
        "paper_author": "Yang D.",
        "publication": "ACS Applied Electronic Materials",
        "citied_by": "13",
        "cover_date": "2023-12-26",
        "Abstract": "In the era of the Internet of Things (IoT), the development of an intelligent sensor system with a sustainable power supply, convenient deployment, and versatile use has emerged as an urgent challenge. Triboelectric nanogenerators (TENGs) stand out as some of the most promising energy solutions in this context. They possess the capability of directly transforming mechanical stimuli into electrical signals, making them highly valuable for self-powered sensor applications. Sensors based on a TENG exhibit the advantages of uncomplicated structures and remarkable instantaneous power density, thereby serving as a critical component in the construction of intelligent sensor systems. In parallel, machine learning (ML), with its attributes of cost-effectiveness, short development cycles, and robust data processing and predictive capabilities, has matured over more than five decades to meet the research requirements of various disciplines. ML demonstrates exceptional prowess in managing the substantial volume of electrical signals generated by a TENG. This paper presents a comprehensive overview of recent advancements in signal processing and intelligent identification within sensor systems based on a TENG. The technical characteristics and research status of this convergence are explored across five key domains: traffic safety, environmental monitoring, information security, motion tracking, and human-computer interaction. Finally, this paper delves into the current challenges and future development trends within this field, offering an analytical perspective on how to enhance its prospects and ultimately opening up a broader landscape for potential applications. We believe that the fusion of ML technology and TENG sensors will catalyze the rapid evolution of intelligent sensor networks in the foreseeable future, providing valuable insights for other research domains as well.",
        "affiliation_name": "Shaanxi University of Science and Technology",
        "affiliation_city": "Xinyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "CellBiAge: Improved single-cell age classification using data binarization",
        "paper_author": "Yu D.",
        "publication": "Cell Reports",
        "citied_by": "2",
        "cover_date": "2023-12-26",
        "Abstract": "Aging is a major risk factor for many diseases. Accurate methods for predicting age in specific cell types are essential to understand the heterogeneity of aging and to assess rejuvenation strategies. However, classifying organismal age at single-cell resolution using transcriptomics is challenging due to sparsity and noise. Here, we developed CellBiAge, a robust and easy-to-implement machine learning pipeline, to classify the age of single cells in the mouse brain using single-cell transcriptomics. We show that binarization of gene expression values for the top highly variable genes significantly improved test performance across different models, techniques, sexes, and brain regions, with potential age-related genes identified for model prediction. Additionally, we demonstrate CellBiAge's ability to capture exercise-induced rejuvenation in neural stem cells. This study provides a broadly applicable approach for robust classification of organismal age of single cells in the mouse brain, which may aid in understanding the aging process and evaluating rejuvenation methods.",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Providence",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Development of white matter fiber covariance networks supports executive function in youth",
        "paper_author": "Bagautdinova J.",
        "publication": "Cell Reports",
        "citied_by": "2",
        "cover_date": "2023-12-26",
        "Abstract": "During adolescence, the brain undergoes extensive changes in white matter structure that support cognition. Data-driven approaches applied to cortical surface properties have led the field to understand brain development as a spatially and temporally coordinated mechanism that follows hierarchically organized gradients of change. Although white matter development also appears asynchronous, previous studies have relied largely on anatomical tract-based atlases, precluding a direct assessment of how white matter structure is spatially and temporally coordinated. Harnessing advances in diffusion modeling and machine learning, we identified 14 data-driven patterns of covarying white matter structure in a large sample of youth. Fiber covariance networks aligned with known major tracts, while also capturing distinct patterns of spatial covariance across distributed white matter locations. Most networks showed age-related increases in fiber network properties, which were also related to developmental changes in executive function. This study delineates data-driven patterns of white matter development that support cognition.",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Estimation of the mechanical properties of oil palm shell aggregate concrete by novel AO-XGB model",
        "paper_author": "Feng Y.",
        "publication": "Steel and Composite Structures",
        "citied_by": "1",
        "cover_date": "2023-12-25",
        "Abstract": "Due to the steadily declining supply of natural coarse aggregates, the concrete industry has shifted to substituting coarse aggregates generated from byproducts and industrial waste. Oil palm shell is a substantial waste product created during the production of palm oil (OPS). When considering the usage of OPSC, building engineers must consider its uniaxial compressive strength (UCS). Obtaining UCS is expensive and time-consuming, machine learning may help. This research established five innovative hybrid AI algorithms to predict UCS. Aquila optimizer (AO) is used with methods to discover optimum model parameters. Considered models are artificial neural network (AO-ANN), adaptive neuro-fuzzy inference system (AO-ANFIS), support vector regression (AO-SVR), random forest (AO-RF), and extreme gradient boosting (AO-XGB). To achieve this goal, a dataset of OPS-produced concrete specimens was compiled. The outputs depict that all five developed models have justifiable accuracy in USC estimation process, showing the remarkable correlation between measured and estimated UCS and models' usefulness. All in all, findings depict that the proposed AO-XGB model performed more suitable than others in predicting UCS of OPSC (with R2, RMSE, MAE, VAF and A15-index at 0.9678, 1.4595, 1.1527, 97.6469, and 0.9077). The proposed model could be utilized in construction engineering to ensure enough mechanical workability of lightweight concrete and permit its safe usage for construction aims.",
        "affiliation_name": "Shahid Beheshti University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "GDPR-oriented intelligent checking method of privacy policies compliance",
        "paper_author": "Li X.",
        "publication": "Chinese Journal of Network and Information Security",
        "citied_by": "2",
        "cover_date": "2023-12-25",
        "Abstract": "The implementation of the EU’s General Data Protection Regulation (GDPR) has resulted in the imposition of over 300 fines since its inception in 2018. These fines include significant penalties for prominent companies like Google, which were penalized for their failure to provide transparent and comprehensible privacy policies. The GDPR, known as the strictest data protection laws in history, has made companies worldwide more cautious when offering cross-border services, particularly to the European Union. The regulation's territorial scope stipulates that it applies to any company providing services to EU citizens, irrespective of their location. This implies that companies worldwide, including domestic enterprises, are required to ensure compliance with GDPR in their privacy policies, especially those involved in international operations. To meet this requirement, an intelligent detection method was introduced. Machine learning and automation technologies were utilized to automatically extract privacy policies from online service companies. The policies were converted into a standardized format with a hierarchical structure. Through natural language processing, the privacy policies were classified, allowing for the identification of relevant GDPR concepts. In addition, a constructed GDPR taxonomy was used in the detection mechanism to identify any missing concepts as required by GDPR. This approach facilitated intelligent detection of GDPR-oriented privacy policy compliance, providing support to domestic enterprises while they provided cross-border services to EU users. Analysis of the corpus samples reveals the current situation that mainstream online service companies generally fail to meet GDPR compliance requirements.",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Survey on Knowledge-Driven Multimodal Semantic Understanding",
        "paper_author": "Zheng Y.",
        "publication": "Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence",
        "citied_by": "1",
        "cover_date": "2023-12-25",
        "Abstract": "Multimodal learning methods based on deep learning model achieve excellent semantic understanding performance in static, controllable and simple scenarios. However, their generalization ability in dynamic, open and other complex scenarios is still unsatisfactory. Human-like knowledge is introduced into multimodal semantic understanding methods in recent research, yielding impressive results. To gain deeper understanding of the current research progress in knowledge-driven multimodal semantic understanding, two main types of multimodal knowledge representation frameworks are summarized based on systematic investigation and analysis of relevant methods in this paper. The two main types of multimodal knowledge representation frameworks are relational and aligned, respectively. Several representative applications are discussed, including image-text matching, object detection, semantic segmentation, and vision-and-language navigation. In addition, the advantages and disadvantages of the current methods and the possible development trend in the future are concluded.",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research Advances on Theory of Open-Environment Machine Learning",
        "paper_author": "Yuan X.",
        "publication": "Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-25",
        "Abstract": "In an open environment, machine learning is faced with various challenges, including varying category sets, non-identically distributed data and noise interference. These challenges can result in a significant decline in the performance of traditional machine learning systems built under the closed-world assumption. Therefore, open-environment machine learning is a research focus on artificial intelligence. In this paper, the current status and recent important advances in the theoretical study of open-environment machine learning are discussed from the perspectives of generalization, optimization, robustness and performance measurement. For generalization theory, the advances on the generalization performance analysis of open-set detection, transfer/meta learning and sparse learning approaches are introduced. For optimization theory, the advances on the theoretical analysis of random and sparse optimization, online and continual optimization, as well as distributed and federated optimization approaches are introduced. For robustness theory, the advances on robust learning under adversarial samples, random noise and noisy labels are introduced. For performance measurement, a number of widely used performance measurement criterions for open-environment machine learning are introduced. Finally, some prospects on the theoretical research trends of open-environment machine learning are provided.",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Progress in Attribution⁃Guided Adaptive Visual Perception and Structure Understanding",
        "paper_author": "Zhang Z.",
        "publication": "Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-25",
        "Abstract": "Machines extract human-understandable information from the environment via adaptive perception to build intelligent system in open-world scenarios. Derived from the class-agnostic characteristics of attribute knowledge, attribution-guided perception methods and models are established and widely studied. In this paper, the tasks involved in attribution-guided adaptive visual perception and structure understanding are firstly introduced, and their applicable scenarios are analyzed. The representative research on four key aspects is summarized. Basic visual attribute knowledge extraction methods cover low-level geometric attributes and high-level cognitive attributes. Attribute knowledge-guided weakly-supervised visual perception includes weakly supervised learning and unsupervised learning under data label restrictions. Image self-supervised learning covers self-supervise contrastive learning and unsupervised commonality learning. Structured representation and understanding of scene images and their applications are introduced as well. Finally, challenges and potential research directions are discussed, such as the construction of large-scale benchmark datasets with multiple attributes, multimodal attribute knowledge extraction, scene generalization of attribute knowledge perception models, the development of lightweight attribute knowledge-guided models and the practical applications of scene image representation.",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Optimal deep machine learning framework for vibration mitigation of seismically-excited uncertain building structures",
        "paper_author": "Rad A.B.",
        "publication": "Structural Engineering and Mechanics",
        "citied_by": "1",
        "cover_date": "2023-12-25",
        "Abstract": "Deep extreme learning machine (DELM) and multi-verse optimization algorithms (MVO) are hybridized for designing an optimal and adaptive control framework for uncertain buildings. In this approach, first, a robust model predictive control (RMPC) scheme is developed to handle the problem uncertainty. The optimality and adaptivity of the proposed controller are provided by the optimal determination of the tunning weights of the linear programming (LP) cost function for clustered external loads using the MVO. The final control policy is achieved by collecting the clustered data and training them by DELM. The efficiency of the introduced control scheme is demonstrated by the numerical simulation of a ten-story benchmark building subjected to earthquake excitations. The results represent the capability of the proposed framework compared to robust MPC (RMPC), conventional MPC (CMPC), and conventional DELM algorithms in structural motion control.",
        "affiliation_name": "University of Tabriz",
        "affiliation_city": "Tabriz",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Non - destructive Identification of Soybean Varieties Based on Near Infrared Hyperspectral Technique and GBDT",
        "paper_author": "Zhou C.",
        "publication": "Journal of the Chinese Cereals and Oils Association",
        "citied_by": "3",
        "cover_date": "2023-12-25",
        "Abstract": "The variety of soybean is directly related to the quality and oil yield of soybean products,and the detection of protein and fat content in soybeans is mainly used to achieve the identification of soybean varieties. This identification method destroys the essence of soybeans,and has the problems of high detection cost,low efficiency and poor accuracy. Based on hyperspectral imaging technology and machine learning theory,the non - destructive rapid identification method of soybean varieties was studied. Hyperspectral raw images and spectral datasets of 4 varieties (200 grains of each variety,a total of 800 grains)of soybeans were collected and established. The collected hyperspectral data were filtered and denoised by normalization,mean centralization,wavelet transform,S - G smoothing filtering and vector normalization,and a nondestructive testing model of soybean seed grain based on KNN,RF and GBDT was established. The experimental comparison indicated that the detection model using principal component analysis combined with GBDT had the highest accuracy,and the recognition accuracy can reach 99. 58% .",
        "affiliation_name": "TaiZhou University",
        "affiliation_city": "Linhai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research Progress of Metabolomics Techniques Combined with Machine Learning Algorithm in Wound Age Estimation",
        "paper_author": "Ma X.Y.",
        "publication": "Fa yi xue za zhi",
        "citied_by": "0",
        "cover_date": "2023-12-25",
        "Abstract": "损伤时间推断是法医学实践中的重要内容，准确推断损伤时间是国内外法医学者亟待解决的科学问题。代谢组学技术可以有效检测机体受到体内外刺激因素作用产生的内源性代谢物，描述生物体内代谢物的动态变化，具有操作性强、检测效率高、定量结果准确等优势。机器学习算法对高维数据集的处理具有独特优势，能够有效挖掘生物信息，真实反映机体生理、疾病或损伤状态，是高效处理高通量大数据的新型技术手段。本文综述了代谢组学技术与机器学习算法的研究现状和自身优势，探讨应用代谢组学技术结合机器学习算法在法医学损伤时间推断研究中的应用前景，为法医学损伤时间推断研究提供新思路。.",
        "affiliation_name": "Ministry of Public Security of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Evaluating Machine Learning Methods of Analyzing Multiclass Metabolomics",
        "paper_author": "Gong Y.",
        "publication": "Journal of Chemical Information and Modeling",
        "citied_by": "7",
        "cover_date": "2023-12-25",
        "Abstract": "Multiclass metabolomic studies have become popular for revealing the differences in multiple stages of complex diseases, various lifestyles, or the effects of specific treatments. In multiclass metabolomics, there are multiple data manipulation steps for analyzing raw data, which consist of data filtering, the imputation of missing values, data normalization, marker identification, sample separation, classification, and so on. In each step, several to dozens of machine learning methods can be chosen for the given data set, with potentially hundreds or thousands of method combinations in the whole data processing chain. Therefore, a clear understanding of these machine learning methods is helpful for selecting an appropriate method combination for obtaining stable and reliable analytical results of specific data. However, there has rarely been an overall introduction or evaluation of these methods based on multiclass metabolomic data. Herein, detailed descriptions of these machine learning methods in multiple data manipulation steps are reviewed. Moreover, an assessment of these methods was performed using a benchmark data set for multiclass metabolomics. First, 12 imputation methods for imputing missing values were evaluated based on the PSS (Procrustes statistical shape analysis) and NRMSE (normalized root-mean-square error) values. Second, 17 normalization methods for processing multiclass metabolomic data were evaluated by applying the PMAD (pooled median absolute deviation) value. Third, different methods of identifying markers of multiclass metabolomics were evaluated based on the CWrel (relative weighted consistency) value. Fourth, nine classification methods for constructing multiclass models were assessed using the AUC (area under the curve) value. Performance evaluations of machine learning methods are highly recommended to select the most appropriate method combination before performing the final analysis of the given data. Overall, detailed descriptions and evaluation of various machine learning methods are expected to improve analyses of multiclass metabolomic data.",
        "affiliation_name": "State Key Laboratory of Quality Research in Chinese Medicine",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "LPATH: A Semiautomated Python Tool for Clustering Molecular Pathways",
        "paper_author": "Bogetti A.T.",
        "publication": "Journal of Chemical Information and Modeling",
        "citied_by": "6",
        "cover_date": "2023-12-25",
        "Abstract": "The pathways by which a molecular process transitions to a target state are highly sought-after as direct views of a transition mechanism. While great strides have been made in the physics-based simulation of such pathways, the analysis of these pathways can be a major challenge due to their diversity and variable lengths. Here, we present the LPATH Python tool, which implements a semiautomated method for linguistics-assisted clustering of pathways into distinct classes (or routes). This method involves three steps: 1) discretizing the configurational space into key states, 2) extracting a text-string sequence of key visited states for each pathway, and 3) pairwise matching of pathways based on a text-string similarity score. To circumvent the prohibitive memory requirements of the first step, we have implemented a general two-stage method for clustering conformational states that exploits machine learning. LPATH is primarily designed for use with the WESTPA software for weighted ensemble simulations; however, the tool can also be applied to conventional simulations. As demonstrated for the C7eq to C7ax conformational transition of the alanine dipeptide, LPATH provides physically reasonable classes of pathways and corresponding probabilities.",
        "affiliation_name": "University of Pittsburgh",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Artificial Intelligence Agents for Materials Sciences",
        "paper_author": "Oliveira O.N.",
        "publication": "Journal of Chemical Information and Modeling",
        "citied_by": "5",
        "cover_date": "2023-12-25",
        "Abstract": "The artificial intelligence (AI) tools based on large-language models may serve as a demonstration that we are reaching a groundbreaking new paradigm in which machines themselves will generate knowledge autonomously. This statement is based on the assumption that the ability to master natural languages is the ultimate frontier for this new paradigm and perhaps an essential step to achieving the so-called general artificial intelligence. Autonomous knowledge generation implies that a machine will be able, for instance, to retrieve and understand the contents of the scientific literature and provide interpretations for existing data, allowing it to propose and address new scientific problems. While one may assume that the continued development of AI tools exploiting large-language models, with more data used for training, may lead these systems to learn autonomously, this learning can be accelerated by devising human-assisted strategies to deal with specific tasks. For example, strategies may be implemented for AI tools to emulate the analysis of multivariate data by human experts or in identifying and explaining patterns in temporal series. In addition to generic AI tools, such as Chat AIs, one may conceive personal AI agents, potentially working together, that are likely to serve end users in the near future. In this perspective paper, we discuss the development of this type of agent, focusing on its architecture and requirements. As a proof-of-concept, we exemplify how such an AI agent could work to assist researchers in materials sciences.",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "From Black Boxes to Actionable Insights: A Perspective on Explainable Artificial Intelligence for Scientific Discovery",
        "paper_author": "Wu Z.",
        "publication": "Journal of Chemical Information and Modeling",
        "citied_by": "7",
        "cover_date": "2023-12-25",
        "Abstract": "The application of Explainable Artificial Intelligence (XAI) in the field of chemistry has garnered growing interest for its potential to justify the prediction of black-box machine learning models and provide actionable insights. We first survey a range of XAI techniques adapted for chemical applications and categorize them based on the technical details of each methodology. We then present a few case studies to illustrate the practical utility of XAI, such as identifying carcinogenic molecules and guiding molecular optimizations, in order to provide chemists with concrete examples of ways to take full advantage of XAI-augmented machine learning for chemistry. Despite the initial success of XAI in chemistry, we still face the challenges of developing more reliable explanations, assuring robustness against adversarial actions, and customizing the explanation for different applications and needs of the diverse scientific community. Finally, we discuss the emerging role of large language models like GPT in generating natural language explanations and discusses the specific challenges associated with them. We advocate that addressing the aforementioned challenges and actively embracing new techniques may contribute to establishing machine learning as an indispensable technique for chemistry in this digital era.",
        "affiliation_name": "College of Pharmaceutical Sciences, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Applying Large Graph Neural Networks to Predict Transition Metal Complex Energies Using the tmQM_wB97MV Data Set",
        "paper_author": "Garrison A.G.",
        "publication": "Journal of Chemical Information and Modeling",
        "citied_by": "5",
        "cover_date": "2023-12-25",
        "Abstract": "Machine learning (ML) methods have shown promise for discovering novel catalysts but are often restricted to specific chemical domains. Generalizable ML models require large and diverse training data sets, which exist for heterogeneous catalysis but not for homogeneous catalysis. The tmQM data set, which contains properties of 86,665 transition metal complexes calculated at the TPSSh/def2-SVP level of density functional theory (DFT), provided a promising training data set for homogeneous catalyst systems. However, we find that ML models trained on tmQM consistently underpredict the energies of a chemically distinct subset of the data. To address this, we present the tmQM_wB97MV data set, which filters out several structures in tmQM found to be missing hydrogens and recomputes the energies of all other structures at the ωB97M-V/def2-SVPD level of DFT. ML models trained on tmQM_wB97MV show no pattern of consistently incorrect predictions and much lower errors than those trained on tmQM. The ML models tested on tmQM_wB97MV were, from best to worst, GemNet-T > PaiNN ≈ SpinConv > SchNet. Performance consistently improves when using only neutral structures instead of the entire data set. However, while models saturate with only neutral structures, more data continue to improve the models when including charged species, indicating the importance of accurately capturing a range of oxidation states in future data generation and model development. Furthermore, a fine-tuning approach in which weights were initialized from models trained on OC20 led to drastic improvements in model performance, indicating transferability between ML strategies of heterogeneous and homogeneous systems.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting Anti-inflammatory Peptides by Ensemble Machine Learning and Deep Learning",
        "paper_author": "Guan J.",
        "publication": "Journal of Chemical Information and Modeling",
        "citied_by": "12",
        "cover_date": "2023-12-25",
        "Abstract": "Inflammation is a biological response to harmful stimuli, aiding in the maintenance of tissue homeostasis. However, excessive or persistent inflammation can precipitate a myriad of pathological conditions. Although current treatments such as NSAIDs, corticosteroids, and immunosuppressants are effective, they can have side effects and resistance issues. In this backdrop, anti-inflammatory peptides (AIPs) have emerged as a promising therapeutic approach against inflammation. Leveraging machine learning methods, we have the opportunity to accelerate the discovery and investigation of these AIPs more effectively. In this study, we proposed an advanced framework by ensemble machine learning and deep learning for AIP prediction. Initially, we constructed three individual models with extremely randomized trees (ET), gated recurrent unit (GRU), and convolutional neural networks (CNNs) with attention mechanism and then used stacking architecture to build the final predictor. By utilizing various sequence encodings and combining the strengths of different algorithms, our predictor demonstrated exemplary performance. On our independent test set, our model achieved an accuracy, MCC, and F1-score of 0.757, 0.500, and 0.707, respectively, clearly outperforming other contemporary AIP prediction methods. Additionally, our model offers profound insights into the feature interpretation of AIPs, establishing a valuable knowledge foundation for the design and development of future anti-inflammatory strategies.",
        "affiliation_name": "National Yang Ming Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Designed Local Electric Fields─Promising Tools for Enzyme Engineering",
        "paper_author": "Siddiqui S.A.",
        "publication": "JACS Au",
        "citied_by": "10",
        "cover_date": "2023-12-25",
        "Abstract": "Designing efficient catalysts is one of the ultimate goals of chemists. In this Perspective, we discuss how local electric fields (LEFs) can be exploited to improve the catalytic performance of supramolecular catalysts, such as enzymes. More specifically, this Perspective starts by laying out the fundamentals of how local electric fields affect chemical reactivity and review the computational tools available to study electric fields in various settings. Subsequently, the advances made so far in optimizing enzymatic electric fields through targeted mutations are discussed critically and concisely. The Perspective ends with an outlook on some anticipated evolutions of the field in the near future. Among others, we offer some pointers on how the recent data science/machine learning revolution, engulfing all science disciplines, could potentially provide robust and principled tools to facilitate rapid inference of electric field effects, as well as the translation between optimal electrostatic environments and corresponding chemical modifications.",
        "affiliation_name": "Shiv Nadar Institution of Eminence deemed to be University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine Learning-Assisted Engineering of Light, Oxygen, Voltage Photoreceptor Adduct Lifetime",
        "paper_author": "Hemmer S.",
        "publication": "JACS Au",
        "citied_by": "0",
        "cover_date": "2023-12-25",
        "Abstract": "Naturally occurring and engineered flavin-binding, blue-light-sensing, light, oxygen, voltage (LOV) photoreceptor domains have been used widely to design fluorescent reporters, optogenetic tools, and photosensitizers for the visualization and control of biological processes. In addition, natural LOV photoreceptors with engineered properties were recently employed for optimizing plant biomass production in the framework of a plant-based bioeconomy. Here, the understanding and fine-tuning of LOV photoreceptor (kinetic) properties is instrumental for application. In response to blue-light illumination, LOV domains undergo a cascade of photophysical and photochemical events that yield a transient covalent FMN-cysteine adduct, allowing for signaling. The rate-limiting step of the LOV photocycle is the dark-recovery process, which involves adduct scission and can take between seconds and days. Rational engineering of LOV domains with fine-tuned dark recovery has been challenging due to the lack of a mechanistic model, the long time scale of the process, which hampers atomistic simulations, and a gigantic protein sequence space covering known mutations (combinatorial challenge). To address these issues, we used machine learning (ML) trained on scarce literature data and iteratively generated and implemented experimental data to design LOV variants with faster and slower dark recovery. Over the three prediction-validation cycles, LOV domain variants were successfully predicted, whose adduct-state lifetimes spanned 7 orders of magnitude, yielding optimized tools for synthetic (opto)biology. In summary, our results demonstrate ML as a viable method to guide the design of proteins even with limited experimental data and when no mechanistic model of the underlying physical principles is available.",
        "affiliation_name": "Leibniz Institute for Interactive Materials",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "From nature to industry: Harnessing enzymes for biocatalysis",
        "paper_author": "Buller R.",
        "publication": "Science",
        "citied_by": "116",
        "cover_date": "2023-12-25",
        "Abstract": "Biocatalysis harnesses enzymes to make valuable products. This green technology is used in countless applications from bench scale to industrial production and allows practitioners to access complex organic molecules, often with fewer synthetic steps and reduced waste. The last decade has seen an explosion in the development of experimental and computational tools to tailor enzymatic properties, equipping enzyme engineers with the ability to create biocatalysts that perform reactions not present in nature. By using (chemo)-enzymatic synthesis routes or orchestrating intricate enzyme cascades, scientists can synthesize elaborate targets ranging from DNA and complex pharmaceuticals to starch made in vitro from CO2-derived methanol. In addition, new chemistries have emerged through the combination of biocatalysis with transition metal catalysis, photocatalysis, and electrocatalysis. This review highlights recent key developments, identifies current limitations, and provides a future prospect for this rapidly developing technology.",
        "affiliation_name": "Codexis, Inc.",
        "affiliation_city": "Redwood City",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Performance augmentation and machine learning-based modeling of wavy corrugated solar air collector embedded with thermal energy storage: Support vector machine combined with Monte Carlo simulation",
        "paper_author": "Zayed M.E.",
        "publication": "Journal of Energy Storage",
        "citied_by": "42",
        "cover_date": "2023-12-25",
        "Abstract": "At present, artificial intelligence methods have been effectively utilized for predicting the complex performance of storage-based solar thermal technologies for cooling/heating applications. It is crucial to have accurate energy storage-based sustainable system estimation, which would contribute to increased operational time, thus maximizing the overall efficiency of solar energy-based storage systems. Hence, this work introduces a comparative experimental investigation and support vector machine (SVM) modeling on a wavy corrugated solar air collector (WCSAC) with and without using a paraffin wax storage container. Experiments on the WCSAC were performed under three air flow rates of 0.540, 1.68, and 3.72 kg/min and two paraffin layer thicknesses of 2 cm and 4 cm, respectively. Moreover, improved SVM models implemented in MATLAB software are developed for predicting the thermal performance parameters; including air temperature ratio, average air temperature, convective heat transfer coefficient, and energy efficiency for the WCSAC. The optimal solution of the SVM modeling is developed by incorporating the Karush-Kuhn-Tucker conditions and several kernel functions. In addition, a sensitivity analysis is also conducted to explore the significance of model input parameters (air inlet temperature, time, solar irradiance, air flowrate, PCM layer thickness) on the output parameters prediction using the Monte Carlo simulation technique. The experimental results presented that the daily energy efficiencies of the WCSAC equipped with 4 cm paraffin layer thickness are 24.0 %, 20.39 %, and 16.37 % higher than that of the WCSAC without PCM at airflow rates of 3.72, 1.68, and 0.54 kg/min, respectively. Moreover, the connective heat transfer coefficient of the WCSAC with PCM is more than 1.20 times that yielded with the WCSAC without PCM. Additionally, the SVM simulations showed that the optimal solution of the SVM model is developed by incorporating the Karush-Kuhn-Tucker conditions and Lagrangian function kernel function, which revealed a superior accuracy with the highest coefficient of determination of 0.990 and 0.950 for training and test processes, respectively.",
        "affiliation_name": "Faculty of Industrial Education",
        "affiliation_city": "Sohag",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Solar air heater with underground latent heat storage system for greenhouse heating: Performance analysis and machine learning prediction",
        "paper_author": "Badji A.",
        "publication": "Journal of Energy Storage",
        "citied_by": "8",
        "cover_date": "2023-12-25",
        "Abstract": "The increasing demand for renewable energy sources in greenhouse heating, driven by the high cost of fossil fuels, has prompted the exploration of various alternatives, such as solar collectors, heat pumps, biomass, and cogeneration systems. This study aimed to establish an optimal environment for plant growth by employing a unique solar air heater and an underground latent heat storage system with a packed bed of phase change material unit (CaCl2-6H2O). Conducted in a double-span greenhouse in Ghardaia, Algeria, characterized by a semi-arid climate, the research utilized two distinct machine learning algorithms to predict the heating system's thermal behavior accurately. An experimental assessment of climatic parameters revealed that the greenhouse equipped with the heating system maintained an air temperature 57 % higher than that of a conventional greenhouse during the nighttime. The use of phase change materials resulted in the release of only 20 kJ of energy at night, indicating the potential to meet 30 % of the greenhouse's energy requirements during nighttime. Utilizing artificial neural networks, this study accurately predicted internal greenhouse parameters with and without LTES. The Nonlinear Autoregressive Exogenous (NARX) model exhibited high accuracy in prediction, with an R2 value of 0.9986 in both cases, while the Recurrent Neural Network (RNN) model showed acceptable performance, achieving an R2 value of 0.9893. These results underscore the potential of ANN models in advancing thermal energy storage technologies and their applicability in sustainable agriculture. This research significantly contributes to thermal energy storage systems and their benefits for sustainable agriculture.",
        "affiliation_name": "Université de Ghardaia",
        "affiliation_city": "Ghardaia",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "A critical review of future aspects of digitalization next generation Li-ion batteries manufacturing process",
        "paper_author": "Dammala P.K.",
        "publication": "Journal of Energy Storage",
        "citied_by": "10",
        "cover_date": "2023-12-25",
        "Abstract": "As the world rushes to expedient the growing demands for energy utilization and storage solutions, Lithium-ion batteries (LIBs) are dominating in almost every sector of the battery systems. Recent research and development in the continuing energy revolution have demonstrated that LIBs are a viable technology for portable gadgets and Electric Vehicles(EV). This is primarily owing to their exceptional performance capabilities and reasonably favorable cell durability. Nevertheless, the optimization of manufacturing electrodes is a crucial factor in guaranteeing the producing top of the line LIBs. The production of LIBs is a complicated system because of the interdependent electrochemical kinetics involved in their chemistry. It has become one of the challenging aspects due to the continuous update of new materials and methodologies. The introduction of digital tools to overcome challenges can optimize these parameters of manufacturing LIBs which are being researched and reaching a phase of implementation in the related industry. Typical state-of-art manufacturing of batteries is a sequence of interdependent steps like slurry preparation, coating and drying, electrode cutting, calendering, stacking, pouch cell formation, electrolyte filling, sealing, and testing, which need precise control. Optimization of the process for each dependent parameter with cautiousness and reorganize them to adopt new innovative battery technologies, which takes a painstaking effort and machine handling to implement. Automation using Machine learning (ML), the Internet of Things (IoT), and Artificial Intelligence (AI) are the ultra-modern approach to the manufacturing process. Digitalization of these techniques provides profitable manufacturing and guides cell prototyping and advanced cell chemistry to the new manufacturing tools in a virtual way. Hence, designing tools and prototyping costs can be reduced. This paper looks at both experimental and computational approaches to make a smooth transition in the process of battery manufacturing.",
        "affiliation_name": "Vrije Universiteit Brussel",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Data-driven rapid lifetime prediction method for lithium-ion batteries under diverse fast charging protocols",
        "paper_author": "Chen D.",
        "publication": "Journal of Energy Storage",
        "citied_by": "8",
        "cover_date": "2023-12-25",
        "Abstract": "Accurate lithium-ion battery lifetime prediction is essential for equipment maintenance and safety assurance in practical applications. The influence of different charge protocols on the lifetime varies greatly, which raises tremendous challenges for rapid lifetime prediction. In this paper, a comprehensive data-driven rapid lifetime prediction method for batteries under diverse fast charging protocols is proposed. It straightforwardly establishes the relationship between the charging conditions and the impacts on battery lifetime. A deep neural network model with the Bayesian optimization algorithm for hyperparameter search (BOA-DNN) and three traditional shallow machine learning algorithms consisting of support vector machine (SVM), Gaussian process regression (GPR), and extreme gradient boosting (XGBoost) are employed. The verification is performed on an authoritative and popular dataset with 69 types of distinct fast charging conditions. The eventual results indicate that the proposed approach has attained reliable performance of battery lifetime degradation trajectory and battery end-of-life (EOL) prediction, in which the BOA-DNN model outperforms SVM, GPR, and XGBoost. Especially in battery EOL prediction, the prediction mean absolute percentage error of the BOA-DNN model is below 3.58%.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Thermal performance of microchannel heat sink integrated with porous medium, slip coefficient and phase change material and machine learning approach",
        "paper_author": "Farahani S.D.",
        "publication": "Journal of Energy Storage",
        "citied_by": "2",
        "cover_date": "2023-12-25",
        "Abstract": "In this study, the thermal performance (TP) of the microchannel heat sink (MCHS) under the influence of the slip coefficient on the microchannel wall, the use of porous medium (PM) and phase change material (PCM), and the changes in the geometrical parameters and the shape of the microchannel have been discussed. The flow and energy equations were solved using the finite volume method. The validation of the melting process, slip coefficient, and porous medium with the previous literature demonstrate the high accuracy of the numerical solution, with the difference between the results being <8 %. The results indicate that using a wavy microchannel can improve TP by approximately10.6 % and 5 % compared to smooth and converging microchannels. Additionally, using non-Newtonian fluids with a power characteristic of 0.53 leads to improved TP about 2.8 % by reducing shear stress compared to Newtonian fluids. Furthermore, the presence of slip on the microchannel wall influences the flow pattern, resulting in reduced convection resistance and improved TP about 3.2–3.8 %. The highest TP was observed at a slip coefficient of 0.00001. Incorporating PM in the microchannel (either in the center or around it) can enhance TP by approximately 8–15 % compared to the base state, with greater improvements observed when PM is placed around the microchannel. The type of PM material and the porosity coefficient significantly impact TP. Varying the cross-sectional shape of the microchannel (square, rhombus, and triangle) has a substantial effect on improving TP compared to a circular cross-section, with the highest TP (with a 71 % increase) observed in microchannels with a square cross-section. Lastly, the use of PCM and PM on the active surface leads to a significant TP improvement of over 80 % compared to the base state. Using the Group Method of Data Handling algorithm, thermal resistance was estimated with an R-square value of 0.94 to validate the available data.",
        "affiliation_name": "Cihan University-Erbil",
        "affiliation_city": "Erbil",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Parametric analysis of a PCM-based heat sink for electronic device thermal management",
        "paper_author": "Khadem Z.",
        "publication": "Journal of Energy Storage",
        "citied_by": "8",
        "cover_date": "2023-12-25",
        "Abstract": "Integrating conventional Heat Sinks with Phase Change Materials (HS-PCM) is a novel strategy for the thermal management of electronic devices. Although various studies attempted to investigate the impact of PCM on the operating temperature of electronic devices, the influence of PCM properties on the performance of the HS-PCM system remained unknown. Therefore, in the present study, an accurate three-dimensional HS-PCM system is designed and simulated to evaluate the effect of PCM properties, including thermal conductivity, enthalpy, specific heat capacity, and liquidus temperature, on the operating temperature of this system. In this order, the HS-PCM system is simulated at multiple operating conditions during both the working and cooling phases. Notably, an experimental setup is fabricated to compare the numerical outputs against the experimental data. Additionally, the Support Vector Regression with Hybrid (HSVR) kernels is used to predict the performance of the HS-PCM system. The hyperparameters of this machine learning model are optimized by implementing Grey Wolf Optimizer (GWO). It is found that raising the liquidus temperature of the PCM can have a minor impact on the working duration of the chipset while it dramatically impacts the cooling process of the system. Also, increasing the enthalpy and heat capacity of the PCM has a favorable effect on the working time of the chipset but extends the cooling process. Thermal conductivity is the only parameter which its enhancement has a positive impact on both the working and cooling duration of the chipset. Raising the thermal conductivity of the PCM from 0.05 W/(m·K) to 0.8 W/(m·K) improves the working duration of the chipset from 22 min to 24 min. Based on the outcomes, the most effective factor on the working time of the chipset is the enthalpy, followed by heat capacity, thermal conductivity, and the liquidus point of the PCM. According to the findings, the GWO-HSVR model can accurately forecast the outcomes of the HS-PCM system at the both working and cooling phases. In the testing process of the model, the values of R2 for the working and cooling phases are calculated to be 0.99174 and 0.99775, respectively.",
        "affiliation_name": "Quchan University of Technology",
        "affiliation_city": "Quchan",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Shedding light on the black box of a neural network used to detect prostate cancer in whole slide images by occlusion-based explainability",
        "paper_author": "Gallo M.",
        "publication": "New Biotechnology",
        "citied_by": "2",
        "cover_date": "2023-12-25",
        "Abstract": "Diagnostic histopathology faces increasing demands due to aging populations and expanding healthcare programs. Semi-automated diagnostic systems employing deep learning methods are one approach to alleviate this pressure. The learning models for histopathology are inherently complex and opaque from the user's perspective. Hence different methods have been developed to interpret their behavior. However, relatively limited attention has been devoted to the connection between interpretation methods and the knowledge of experienced pathologists. The main contribution of this paper is a method for comparing morphological patterns used by expert pathologists to detect cancer with the patterns identified as important for inference of learning models. Given the patch-based nature of processing large-scale histopathological imaging, we have been able to show statistically that the VGG16 model could utilize all the structures that are observable by the pathologist, given the patch size and scan resolution. The results show that the neural network approach to recognizing prostatic cancer is similar to that of a pathologist at medium optical resolution. The saliency maps identified several prevailing histomorphological features characterizing carcinoma, e.g., single-layered epithelium, small lumina, and hyperchromatic nuclei with halo. A convincing finding was the recognition of their mimickers in non-neoplastic tissue. The method can also identify differences, i.e., standard patterns not used by the learning models and new patterns not yet used by pathologists. Saliency maps provide added value for automated digital pathology to analyze and fine-tune deep learning systems and improve trust in computer-based decisions.",
        "affiliation_name": "Masaryk University",
        "affiliation_city": "Brno",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Acid groups decorated bimetal-organic catalyst for advanced oxidation technology at full pH range",
        "paper_author": "Wang L.",
        "publication": "Journal of Alloys and Compounds",
        "citied_by": "7",
        "cover_date": "2023-12-25",
        "Abstract": "As a wastewater treatment technology, the activity of advanced oxidation process (AOPs) is strongly dependent on pH value. Herein, considering the low activity of AOPs under alkaline conditions, the acid organic ligand (nitrilotriacetic acid, NTA) was chosen to design Co-NTA metal-organic catalyst for efficient photo-Fenton reaction at full pH range. The experimental results indicate the acid ligands in Co-NTA offers more·OH that can achieve high activity under alkaline conditions. To further enhance the electron injection ability and redox cycles of Co(II)/Co(III), Ferrocene (Fc) nanoparticles was introduced to form bimetallic organic catalyst Fc-Co-NTA. The mechanism study indicates that the synergistic effect between Co-NTA and Fc promotes the activation of potassium persulfate and improves the stability of the catalyst under extreme pH conditions, while the π-π interaction between TC and Fc-Co-NTA can improve the electron injection capability and accelerate the production of·OH/SO4•-, so as to accelerate the redox cycles of Fe(II)/Fe(III) and Co(II)/Co(III), bringing about prolonged carrier lifetime and better photocatalytic activity. The possible degradation pathway of TC was investigated by Fukui function and LC-MS. A machine learning model is used to optimize the synthesis and photocatalytic parameters of Fc-Co-NTA. This study provides a new design idea to prepare highly efficient and stable photo-Fenton advanced oxidation technology at full pH range.",
        "affiliation_name": "Baicheng Normal University",
        "affiliation_city": "Baicheng",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Iron and aluminum based beaded sorbents for removing arsenic and fluorine from water: Application of machine learning for material selection",
        "paper_author": "Guo F.",
        "publication": "Journal of Industrial and Engineering Chemistry",
        "citied_by": "4",
        "cover_date": "2023-12-25",
        "Abstract": "In this study, the waste reuse of water purification plant sludge (WPS) and coal mine drainage sludge (CMDS) was carried out and synthesized into beaded adsorbents BWPS and BCMDS. The WPS is rich in aluminum, and the aluminum-based adsorbent has a good adsorption effect on the fluoride in water. CMDS is rich in iron and calcium, arsenic can be removed from water using this device. The experiments mainly probed the pollutant-removing effects of two beaded adsorbents on fluoride and arsenic in water. According to the Langmuir isotherm equation, the maximum adsorption capacities (Qmax) of F- on BWPS and BCMDS are 0.90 and 0.65 mg g−1, and the Qmax of As (V) are 9.87 and 14.88 mg g−1, respectively. With a range of pH 4 ∼ 10 in experiments, increasing pH decreased the pseudo-second-order rate (K2) of F- and As(V) adsorbed on the beaded adsorbents. The mechanism for removing F- by BWPS is physical adsorption, on BCMDS are ion exchange and precipitation, and for As(V) are physisorption and precipitation. In the desorption experiments, the results indicated that both adsorbents can be reused. In addition, it is combined with XGBoost and SHapley Additive exPlanations (SHAP), to predict the adsorption capacity. Data preprocessing and model training improved the prediction accuracy, resulting in a final RMSE of 0.429 and an average prediction accuracy of 91%. Through the evaluation index (EI) select the final adsorbent, the results showed that the choice of adsorbent was unchanged in general conditions and expert surveys, however, in some specific scenarios can be changed.",
        "affiliation_name": "Hoseo University",
        "affiliation_city": "Asan",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A multifidelity neural network (MFNN) for constitutive modeling of complex soil behaviors",
        "paper_author": "Su M.",
        "publication": "International Journal for Numerical and Analytical Methods in Geomechanics",
        "citied_by": "7",
        "cover_date": "2023-12-25",
        "Abstract": "The development and calibration of soil models under the framework of plasticity is notoriously challenging given the prismatic features in soil's shear behaviors. Data-driven deep neural networks (DNNs) offer an alternative approach to this formidable task. However, classical DNN models struggle to accurately capture soil mechanical responses using limited training data. To address this issue, a unified multifidelity neural network (MFNN) is proposed to leverage the accuracy of high-fidelity experimental datasets and the abundance of low-fidelity datasets synthesized using the modified Cam-clay (MCC) model. The MFNN model can automatically learn the correlation between the low-fidelity and high-fidelity datasets, and has been applied to predicting the mechanical responses of over-consolidated and anisotropically consolidated clays, cement-treated clays, silts sheared under varying temperatures, and suction-controlled unsaturated soils. The results demonstrate significantly improved prediction capabilities of MFNN compared to purely data-driven DNNs. The proposed MFNN framework holds encouraging promise to revolutionize constitutive modeling of complex soil behaviors.",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A hybrid ensemble machine learning model for detecting APT attacks based on network behavior anomaly detection",
        "paper_author": "Saini N.",
        "publication": "Concurrency and Computation: Practice and Experience",
        "citied_by": "12",
        "cover_date": "2023-12-25",
        "Abstract": "A persistent, targeted cyber attack is called an advanced persistent threat (APT) attack. The attack is mainly launched to gain sensitive information, take over the system, and for financial gain, which creates nowadays more hurdles and challenges for the organization in preventing, detecting, and recovering from such attacks. Due to the nature of APT attacks, it is difficult to detect them quickly. Therefore machine learning techniques come into these research areas. This study uses deep and machine learning models such as random forest, decision tree, convolutional neural network, multilayer perceptron and so forth to categorize and effectively detect APT attacks by utilizing publicly accessible datasets. The datasets used in this study are CSE-CIC-IDS2018, CIC-IDS2017, NSL-KDD, and UNSW-NB15. This study proposes the hybrid ensemble machine learning model, a mixed approach of random forest and XGBoost classifiers. It has obtained the maximum prediction accuracy of 98.92%, 99.91%, 99.24%, and 97.11% for datasets CSE-CIC-IDS2018, CIC-IDS2017, NSL-KDD, and UNSW-NB15, with a false positive rate of 0.52%, 0.12%, 0.62%, and 5.29% respectively. These results are compared to other closely related recent studies in the literature. Our experiment's findings show that our model has performed significantly better for all datasets.",
        "affiliation_name": "Manipal Institute of Technology",
        "affiliation_city": "Manipal",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Efficacy of machine learning algorithms in estimating emissions in a dual fuel compression ignition engine operating on hydrogen and diesel",
        "paper_author": "Venkatesh S N.",
        "publication": "International Journal of Hydrogen Energy",
        "citied_by": "21",
        "cover_date": "2023-12-25",
        "Abstract": "Emission created by combustion of fossil fuels are a major concern of the world for the past few decades. The stringent emission norms have impacted the automobile manufacturers to work on exhaust emissions and its impact. This research focused on using machine learning regression models to evaluate the efficacy of experimental results for a dual fuel compression ignition (CI) engine operating on hydrogen and diesel. In the present study, engine emissions were estimated using 29 regression algorithms. A total of 5 input data namely, concentration of hydrogen, engine load, diesel intake, speed and equivalence ratio were considered in the study to estimate various emissions like oxides of nitrogen (NOx), carbon dioxide (CO2), hydrocarbon (HC) and smoke. Correlation coefficient, mean absolute error, root mean squared error, relative absolute error and root relative squared error were adopted as the performance metrics in the present study. Amongst the algorithms considered, pace regression, radial basis function regressor, multilayer perceptron regressor and alternating model tree produced the highest correlation coefficient of 0.9985, 0.8958, 0.9950 and 0.9256 in estimating the engine emissions like CO2, smoke, NOx and HC respectively. Additionally, an attempt was made to establish an individual algorithm that can estimate all the emissions was identified as multilayer perceptron regressor with correlation coefficient values of 0.9977 (CO2), 0.9950 (NOx), 0.8501(smoke) and 0.8731(HC) respectively.",
        "affiliation_name": "İstinye Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Classification of white blood cells based on modified U-Net and SVM",
        "paper_author": "Balasubramanian K.",
        "publication": "Concurrency and Computation: Practice and Experience",
        "citied_by": "4",
        "cover_date": "2023-12-25",
        "Abstract": "Manual investigation of blood cell count is sometimes erroneous due to interoperability error, fatigue error, requiring expert skill and time consuming too. In particular, investigation of white blood cell (WBC) gains importance in identifying diseases like leukemia, leukopenia, etc. WBC does not possess regular structure because they move throughout the blood stream and hence analyzing WBC and its types for structure and shape is quite challenging. To aid in hematology, this work provides classification of WBC classification based on modified U-Net and support vector machines (SVM). A modified U-Net architecture is developed to segment WBC followed by feature extraction and classification by radial basis function-support vector machine (RBF-SVM). Experiments indicated that the modified U Net segmentation can detect the WBC nucleus with a dice similarity coefficient of 0.972. The proposed U-Net-SVM can recognize WBCs in Raabin-WBC, LISC, and BCCD datasets with an accuracy of 99.45%, 98.62%, and 98.81%, respectively. Further investigation on leukemia dataset, ALL-IDB2, revealed an accuracy of 99.42% with 100% sensitivity and specificity. The proposed model can be used to investigate WBCs and hence provide a great support to the hematologists in analyzing the blood smear for various disease identifications.",
        "affiliation_name": "Dr. N.G.P. Institute of Technology",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Detecting coronal mass ejections with machine learning methods",
        "paper_author": "Vida K.",
        "publication": "Proceedings of the International Astronomical Union",
        "citied_by": "0",
        "cover_date": "2023-12-23",
        "Abstract": "Flares on the Sun are often associated with ejected plasma: these events are known as coronal mass ejections (CMEs). These events, although are studied in detail on the Sun, have only a few dozen known examples on other stars, mainly detected using the Doppler-shifted absorption/emission features in Balmer lines and tedious manual analysis. We present a possibility to find stellar CMEs with the help of high-resolution solar spectra.",
        "affiliation_name": "Eötvös Loránd Tudományegyetem",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "Characterizing Solar Spicules and their Role in Solar Wind Production using Machine Learning and the Hough Transform",
        "paper_author": "Sadeghi R.",
        "publication": "Proceedings of the International Astronomical Union",
        "citied_by": "0",
        "cover_date": "2023-12-23",
        "Abstract": "Solar winds originate from the Sun and can be classified as fast or slow. Fast solar winds come from coronal holes at the solar poles, while slow solar winds may originate from the equatorial region or streamers. Spicules are jet-like structures observed in the Sun’s chromosphere and transition region. Some spicules exhibit rotating motion, potentially indicating vorticity and Alfvén waves. Machine learning and the Hough algorithm were used to analyze over 3000 frames of the Sun, identifying spicules and their characteristics. The study found that rotating spicules, accounting for 21% at the poles and 4% at the equator, play a role in energy transfer to the upper solar atmosphere. The observations suggest connections between spicules, mini-loops, magnetic reconnection, and the acceleration of fast solar winds. Understanding these small-scale structures is crucial for comprehending the origin and heating of the fast solar wind.",
        "affiliation_name": "Payame Noor University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Predicting the Emergence of Solar Active Regions Using Machine Learning",
        "paper_author": "Kasapis S.",
        "publication": "Proceedings of the International Astronomical Union",
        "citied_by": "0",
        "cover_date": "2023-12-23",
        "Abstract": "To create early warning capabilities for upcoming Space Weather disturbances, we have selected a dataset of 61 emerging active regions, which allows us to identify characteristic features in the evolution of acoustic power density to predict continuum intensity emergence. For our study, we have utilized Doppler shift and continuum intensity observations from the Helioseismic and Magnetic Imager (HMI) onboard the Solar Dynamics Observatory (SDO). The local tracking of 30.66 × 30.66-degree patches in the vicinity of active regions allowed us to trace the evolution of active regions starting from the pre-emergence state. We have developed a machine learning model to capture the acoustic power flux density variations associated with upcoming magnetic flux emergence. The trained Long Short-Term Memory (LSTM) model is able to predict 5 hours ahead whether, in a given area of the solar surface, continuum intensity values will decrease. The performed study allows us to investigate the potential of the machine learning approach to predict the emergence of active regions using acoustic power maps as input.",
        "affiliation_name": "New Jersey Institute of Technology",
        "affiliation_city": "Newark",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neural approaches for writing assistant tasks",
        "paper_author": "Skurzhanskyi O.H.",
        "publication": "Bulletin of the Taras Shevchenko National University of Kyiv. Physics and Mathematics",
        "citied_by": "0",
        "cover_date": "2023-12-23",
        "Abstract": "The article is devoted to the analysis of tasks for building a writing assistant, one of the most prominent fields of natural language processing and artificial intelligence in general. Specifically, we explore monolingual local sequence transduction tasks: grammatical and spelling errors correction, text simplification, paraphrase generation. To give a better understanding of the considered tasks, we show examples of expected rewrites. Then we take a deep look at such key aspects as existing publicly available datasets and their training splits, quality metrics for high quality evaluation, and modern solutions based primarily on neural networks. For each task, we analyze its main peculiarities and how they influence the state-of-the-art models. Eventually, we investigate the most eloquent shared features for the whole group of tasks in general and for approaches that provide solutions to them.",
        "affiliation_name": "Taras Shevchenko National University of Kyiv",
        "affiliation_city": "Kyiv",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "A Survey of Learning-based Automated Program Repair",
        "paper_author": "Zhang Q.",
        "publication": "ACM Transactions on Software Engineering and Methodology",
        "citied_by": "16",
        "cover_date": "2023-12-23",
        "Abstract": "Automated program repair (APR) aims to fix software bugs automatically and plays a crucial role in software development and maintenance. With the recent advances in deep learning (DL), an increasing number of APR techniques have been proposed to leverage neural networks to learn bug-fixing patterns from massive opensource code repositories. Such learning-based techniques usually treat APR as a neural machine translation (NMT) task, where buggy code snippets (i.e., source language) are translated into fixed code snippets (i.e., target language) automatically. Benefiting from the powerful capability of DL to learn hidden relationships from previous bug-fixing datasets, learning-based APR techniques have achieved remarkable performance. In this article, we provide a systematic survey to summarize the current state-of-the-art research in the learning-based APR community. We illustrate the general workflow of learning-based APR techniques and detail the crucial components, including fault localization, patch generation, patch ranking, patch validation, and patch correctness phases. We then discuss the widely adopted datasets and evaluation metrics and outline existing empirical studies. We discuss several critical aspects of learning-based APR techniques, such as repair domains, industrial deployment, and the open science issue. We highlight several practical guidelines on applying DL techniques for future APR studies, such as exploring explainable patch generation and utilizing code features. Overall, our article can help researchers gain a comprehensive understanding about the achievements of the existing learning-based APR techniques and promote the practical application of these techniques.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Identifying Reading Fluency in Pupils with and without Dyslexia Using a Machine Learning Model on Texts Assessed with a Readability Application",
        "paper_author": "Žabkar J.",
        "publication": "Center for Educational Policy Studies Journal",
        "citied_by": "3",
        "cover_date": "2023-12-23",
        "Abstract": "Measurement of readability is an important tool for assessing reading disorders such as dyslexia. Among the screening procedures for dyslexia is the reading fluency test, which is defined as the ability to read with speed, accuracy and proper expression. The reading fluency test often consists of a sequence of unrelated written texts ranging from simple short sentences to more difficult and longer paragraphs. In psychological testing instruments, subjective text assessment is often replaced by objective readability formulas, e.g., the Automated Readability Index. Readability formulas extract multiple features from a given text and output a score indicating the difficulty of the text. The aim of the pre-sent study is to build a machine learning model that discriminates between pupils identified with dyslexia and a control group without dyslexia based on fluency in oral reading of texts assessed with a readability application developed within the project For the Quality of Slovenian Textbooks. We focus on differentiation between both groups of pupils by analysing data obtained from transcriptions of audio recordings of oral reading. The empirical study was conducted with 27 pupils aged 8 and 9 with officially diagnosed dyslexia and a control group without identified dyslexia.",
        "affiliation_name": "Univerza v Ljubljani",
        "affiliation_city": "Ljubljana",
        "affiliation_country": "Slovenia"
    },
    {
        "paper_title": "Artificial intelligence-enabled ophthalmoscopy for papilledema: a systematic review protocol",
        "paper_author": "Rambabu L.",
        "publication": "International Journal of Surgery Protocols",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Papilledema is a pathology delineated by the swelling of the optic disc secondary to raised intracranial pressure (ICP). Diagnosis by ophthalmoscopy can be useful in the timely stratification of further investigations, such as magnetic resonance imaging or computed tomography to rule out pathologies associated with raised ICP. In resource-limited settings, in particular, access to trained specialists or radiological imaging may not always be readily available, and accurate fundoscopy-based identification of papilledema could be a useful tool for triage and escalation to tertiary care centres. Artificial intelligence (AI) has seen a rise in neuro-ophthalmology research in recent years, but there are many barriers to the translation of AI to clinical practice. The objective of this systematic review is to garner and present a comprehensive overview of the existing evidence on the application of AI in ophthalmoscopy for papilledema, and to provide a valuable perspective on this emerging field that sits at the intersection of clinical medicine and computer science, highlighting possible avenues for future research in this domain.",
        "affiliation_name": "Department of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Image processing for autonomous vehicle based on deep learning",
        "paper_author": "Raut T.",
        "publication": "Research Trends in Artificial Intelligence: Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The automation industry is rapidly growing and coming up with new and improved techniques for reducing time and efforts. One such example is the autonomous cars which are said to be the future of the automobile industry since they would be driver less, very efficient and relieve the stress of daily commuting [1]. Advances in technology using the AI and deep learning techniques help in improving the safety of the passengers and also in minimizing the efforts of the driver. For the study of autonomous vehicles, a lot of data needs to be collected, some of which include warning signals, speed limits, obstacles, collision avoidance, etc. This paper shows how IoT devices i.e. cameras and LiDAR sensors help in data collection, how deep learning is a solution, and how image recognition methods that use deep learning can help in object or any obstacle detection. An image processing algorithm based on deep learning is proposed in which the image perception can be made by an optical camera communication technique that can be used for collecting the data. Hence it will highlight how deep learning is used in the field of image processing or image recognition.",
        "affiliation_name": "Vishwakarma Institute of Information Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Paradigm shift of online education system due to COVID-19 pandemic: A sentiment analysis using machine learning",
        "paper_author": "Chapke P.P.",
        "publication": "Research Trends in Artificial Intelligence: Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The COVID-19 epidemic has completely altered the environment and every aspect of every individual. The most affected part is the education system and the stakeholders associated with it. Organizations are currently being forced to adapt and alter their strategies in response to the new situation created by the COVID-19 epidemic. The proposed study gathers tweets on online schooling from social media sites like Twitter and Facebook comments in order to conduct a thorough sentiment analysis (SA) during the epidemic. The current study utilizes techniques for natural language processing (NLP) and machine learning (ML) to extract subjective data, establish polarity, and identify how people felt about the educational system prior to and following the COVID-19 crisis. The first step in the proposed study is to retrieve tweets using Twitter APIs before they are ready for rigorous preprocessing. One filtering method is Information Gain (IG). We will identify and examine the latent causes of the unpleasant feelings. We'll look at the machine-learning classification algorithm at the end. The proposed model will analyse the perceptions of people about the online educational system during COVID-19.",
        "affiliation_name": "C.O. E.T.",
        "affiliation_city": "Amravati",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Digital twin and its applications",
        "paper_author": "Wani K.",
        "publication": "Research Trends in Artificial Intelligence: Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Digital twin technology is an important part of the industry 4.0 revolution. Digital twins is a concept of integrating different smart technologies including integration of data and digitization. The vision of the digital twin technology is based on the philosophy that any component, assembly, system, process, product, or even environment can be replicated in terms of form, functionality and several other parameters in a digital way throughout different phases of its lifecycle. The Digital Twin concept is based on the highly growing information and communication technologies alongside conventional methods for getting better interconnection and integration amongst all the entities involved in a particular phase of the product lifecycle. The Internet of things (IOT) and artificial intelligence (AI) are crucial parts of the Industry 4.0 revolution. IOT proposes to embed electronics, sensors, network connectivity and different software platforms with products. Better integration between the physical and digital world is achieved by a strong network infrastructure that facilitates remote sensing, monitoring and even controlling of connected systems. This technology provides users with many benefits such as increased efficiency, reduced downtime, improvement in precision and accuracy along with cost saving.",
        "affiliation_name": "Symbiosis International (Deemed University)",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Ontology based information retrieval by using semantic query",
        "paper_author": "Deshmukh R.R.",
        "publication": "Research Trends in Artificial Intelligence: Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The volume of data is increasing quickly in the modern day. Effective information retrieval techniques are needed to extract important facts from such a large collection of information. As a result, retrieval of information is the process of gathering valid data from a variety of sources. The majority of the time, information is retrieved from the internet using search queries. The aim of this research is to explore various issues existing in information retrieval techniques and to propose new techniques to overcome existing challenges in the field of Information retrieval. Modern information retrieval methods have been examined, and it was discovered that they do not take semantic keyword knowledge into account when returning results. The semantic web is a development of the internet that enables computers to comprehend human inquiries in terms of their intent and produce pertinent responses. This research mainly focuses on Ontology-Based Information Retrieval which can support semantic similarity and retain the view of an approximate search in a document repository using machine learning techniques. Further, this research works explores an adaptive update model for retrieving the information and proposes a semantic search model for the given user query. The objective of ontology-based semantic web information search is to increase the accuracy, precision and recall of user queries.",
        "affiliation_name": "H.V.P. M's COET",
        "affiliation_city": "Amravati, Maharashtra",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Impact of automation, artificial intelligence and deep learning on agriculture crop yield",
        "paper_author": "Ramteke P.L.",
        "publication": "Research Trends in Artificial Intelligence: Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Every nation is concerned about the growing problem of agriculture automation. It is challenging to supply the food needs of the existing population due to rising numbers, frequent climate change, and scarce resources. Farmers are forced to wreak havoc on the land by applying dangerous pesticides more often since their old techniques cannot keep up with the growing demand. As a result, agricultural practices are significantly impacted, and the land gradually loses its fertility and becomes unproductive. The agriculture sector can benefit from technology like Artificial Intelligence (AI), deep learning, the Internet of Things (IoT), embedded systems, and automation. Artificial neural networks, the Internet of Things, fuzzy logic, machine learning, and other technologies may all be used to automate agricultural systems. Artificial intelligence technology is advancing quickly, and as a result, its employment is in a wide range of fields. Utilizing clever technologies, the agricultural industry has become able to regulate the field environment that is essential to the care of every plant. A suitable atmosphere and appropriate irrigation are provided by the plant's identification and suitable circumstances. In order to increase agriculture yields, it has become important to manage crops in controlled settings like greenhouses that can enhance the output. This chapter focuses on the use of artificial intelligence and IoT technology to improve the productivity of agricultural enterprises. AI technologies might help farmers overcome problems like weeds, pests, and climatic variability that lower output. Numerous uses of AI are now being deployed, such as automatic machine changes for weather forecasting and pest detection. The goal of implementing AI and IoT is to increase the possibility of producing healthy crops by recognizing damaged crops and crop yield growth.",
        "affiliation_name": "University Amravati, Maharashtra",
        "affiliation_city": "Amravati, Maharashtra",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A deep learning approach using an ensemble model to autocreate an image-based hip fracture registry",
        "paper_author": "Oosterhoff J.H.F.",
        "publication": "OTA International",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Objectives:With more than 300,000 patients per year in the United States alone, hip fractures are one of the most common injuries occurring in the elderly. The incidence is predicted to rise to 6 million cases per annum worldwide by 2050. Many fracture registries have been established, serving as tools for quality surveillance and evaluating patient outcomes. Most registries are based on billing and procedural codes, prone to under-reporting of cases. Deep learning (DL) is able to interpret radiographic images and assist in fracture detection; we propose to conduct a DL-based approach intended to autocreate a fracture registry, specifically for the hip fracture population.Methods:Conventional radiographs (n = 18,834) from 2919 patients from Massachusetts General Brigham hospitals were extracted (images designated as hip radiographs within the medical record). We designed a cascade model consisting of 3 submodules for image view classification (MI), postoperative implant detection (MII), and proximal femoral fracture detection (MIII), including data augmentation and scaling, and convolutional neural networks for model development. An ensemble model of 10 models (based on ResNet, VGG, DenseNet, and EfficientNet architectures) was created to detect the presence of a fracture.Results:The accuracy of the developed submodules reached 92%-100%; visual explanations of model predictions were generated through gradient-based methods. Time for the automated model-based fracture-labeling was 0.03 seconds/image, compared with an average of 12 seconds/image for human annotation as calculated in our preprocessing stages.Conclusion:This semisupervised DL approach labeled hip fractures with high accuracy. This mitigates the burden of annotations in a large data set, which is time-consuming and prone to under-reporting. The DL approach may prove beneficial for future efforts to autocreate construct registries that outperform current diagnosis and procedural codes. Clinicians and researchers can use the developed DL approach for quality improvement, diagnostic and prognostic research purposes, and building clinical decision support tools.",
        "affiliation_name": "Faculteit Techniek, Bestuur en Management, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "The development of the smart factory during the Industry 4.0 period under the study of system thinking",
        "paper_author": "Zhou Z.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Following introducing the Industrial Revolution 4.0 framework in 2013, many industrialised nations have implemented this new industrial paradigm. The smart factory is a fundamental concept imperative for successfully implementing the Fourth Industrial Revolution. Many scholars and specialists contend that the ongoing advancement of smart factories will transform the industrial structure. This study aims to examine the status of smart factories, exploring the development and management of the smart factory during the Industry 4.0 period under the study of system thinking. This work extensively explores the distinctive notion and presents individual anecdotes regarding the development, execution, arrangement, and administration of intelligent factories by individuals. The research employs multiple methodologies, such as system thinking of relevant literature and systematic analysis of the proposed complex project. The findings suggest that incorporating intricate system thinking, appropriate technology integration, efficient simulation and machine learning employment, and a responsive monitoring and feedback mechanism are crucial in establishing and managing intelligent manufacturing facilities. External factors and governing constraints need to be considered during the lifecycle of treating complexity. This report offers a thorough and analytical evaluation of developing the smart factory during the Fourth Industrial Revolution, serving as a scholarly resource for further exploration of related subject areas. A further investigation plans to consider deep data collection.",
        "affiliation_name": "Tianfu College of SWUFE",
        "affiliation_city": "Mianyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A 3D CNN Model with 3d CBAM Layer for Micro-Expression Recognition",
        "paper_author": "Xiao B.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Facial microexpression recognition in videos is a popular area of computer vision research. Microexpressions are non-verbal expressions of human emotions that often appear when people try to hide or control their emotions.There are many facial expression recognition methods in related fields, but micro-expression recognition in videos has not been accurate enough. This paper aims to study micro-expression recognition technology, which can effectively identify small and short-lived expression changes on human faces. This study proposes a micro-expression recognition method based on computer vision and machine learning by analyzing facial features and spatio-Temporal feature extraction. First, we collected a video dataset containing micro-expressions and performed preprocessing and feature extraction on them. Then, we use more advanced methods in the field and methods proposed by the team to train and test the model to recognize multiple micro-expression categories. Experimental results show that our method achieves higher accuracy and more stable performance in micro-expression recognition tasks.",
        "affiliation_name": "Tianjin University of Technology",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application Methods and Practices of Deep Learning in Network Intrusion Detection",
        "paper_author": "Wei S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "In the realm of cybersecurity, this study presents a novel approach to intrusion detection by harnessing the power of artificial intelligence (AI) and machine learning (ML). We delve into the critical domain of network intrusion detection, emphasizing the significance of our research. Existing methodologies face challenges, prompting the need for advanced solutions. Our work addresses this gap by employing an innovative method. Beginning with the collection and preprocessing of extensive network traffic data, we extract key features crucial for characterizing network behavior. Our approach utilizes a deep learning model to effectively categorize network behavior, distinguishing between normal traffic and malicious attacks. Through rigorous experimental validation against established technologies, we demonstrate substantial improvements in key metrics such as accuracy, recall, and F1 score. Beyond performance metrics, we explore the practical deployment potential of our approach in real-world network environments. This research contributes to the ongoing discourse on effective intrusion detection solutions driven by AI and ML in the realm of network security. In conclusion, our study not only enhances the understanding of network intrusion detection but also provides a robust and efficient solution for bolstering cybersecurity in an increasingly interconnected world.",
        "affiliation_name": "Wuzhou University",
        "affiliation_city": "Wuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Real-Time detection method of edge iot proxy network intrusion based on PSO-ELM",
        "paper_author": "Wang X.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The edge IoT proxy network involves a large number of devices, which are large and widely distributed, making the monitoring and detection of abnormal states complex. Therefore, a real-Time intrusion detection method based on Particle Swarm Optimization (PSO) for Extreme Learning Machine (ELM) edge IoT proxy network is proposed. This method first determines whether the intrusion interference items captured by the network host meet the optimal adaptive conditions through particle boundary coordinates, ensuring that each data sample corresponds only to one optimal fitness value. Then, according to the optimization expression of the particle swarm optimization algorithm, the intrusion interference information is recorded and extracted, and real-Time detection is carried out using information parameters. The method also includes two key steps: promoting information aggregation and recording behavioral item indexing. Among them, the directional features of information aggregation are determined based on whether the transmission direction of communication data is the same as the transmission direction of intrusion risk items, while the recording of behavior item indexes requires a numerical matching relationship between the directional information aggregation conditions and the sampling results of intrusion samples. In summary, this method combines particle swarm optimization algorithm and edge IoT proxy network to achieve real-Time detection and recording of intrusion objects. The experimental results show that this method can accurately detect the frequency of edge IoT proxy network intrusion, indicating that the application effect of this method is ideal.",
        "affiliation_name": "Ltd. Marketing Service Center (Capital Intensive Center",
        "affiliation_city": "Urumqi",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research on the Application of Artificial Intelligence Technology in Emergency Repair and Power Restoration of Residential Areas under Heavy Rain Disaster Weather",
        "paper_author": "Wen Y.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "With the frequent occurrence of rainstorm disaster events, the power supply system is facing great challenges.This paper discusses how artificial intelligence technology can help power system to quickly repair and stable operation in rainstorm disaster. Firstly, the application of UAV combined with image recognition technology in damage location is introduced in detail. Combining meteorological information, power sensors, and geographic information systems, machine learning models can predict vulnerable areas of power systems during heavy rainfall. In addition, real-Time grid data analysis further employs support vector machines to predict potential points of failure. The integrated application of these technologies not only improves the accuracy and efficiency of emergency repair, but also provides innovative solutions for the stable operation of power systems in extreme weather conditions.",
        "affiliation_name": "State Grid Henan Marketing Service Center",
        "affiliation_city": "Zhangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Classification of BGP Anomalies Using GRU with BGP Update Messages",
        "paper_author": "Ji Y.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "With the increasing reliance on the Internet, its reliability and security have become major concerns. The Border Gateway Protocol (BGP) is susceptible to anomalies such as hijacking, configuration errors, and denial-of-service attacks, which can pose significant threats to the performance and reliability of the Internet. However, with the methods for the BGP anomalies classification, the operators can understand the cause of anomalies and take action to solve the problems. Recently, various techniques have been proposed for classifying BGP anomalies utilizing machine learning models. Nevertheless, we have identified some limitations of these classification models that raise doubts regarding their applicability in real-world scenarios for classifying new anomalies. In order to better classify BGP anomalies with high accuracy and efficiency, we introduce Gate Recurrent Unit (GRU) to classify BGP anomalies based on the features selected from BGP update messages. Notably, our method boasts a leaner parameter set and converges more rapidly compared to alternative approaches. Experimental results demonstrate that our method outperforms other methods, with the performance of the precision, recall and F1-score are 100%, 77% and 87% respectively.",
        "affiliation_name": "Ltd",
        "affiliation_city": "Jiangsu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research on emotion recognition of autistic children based on electrocutaneous signals and electrocardiogram signals",
        "paper_author": "Xie L.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Aiming at the problem that explicit emotional characteristics and a single physiological modality are not enough to support robust emotion recognition in autistic children, this paper proposes a random forest emotion classification algorithm based on implicit measurements (electrodermal signals and electrocardiogram signals). Through artificial induction, the physiological signals of the four emotions (happy, sad, scared, and angry) of the subjects were collected. Gaussian smoothing was performed on the electrocutaneous signals, and wavelet noise reduction processing and feature extraction were performed on the electrocardiographic signals to obtain physiological emotional indicators. Five types of machines were used to obtain the physiological emotional indicators. Learning methods perform sentiment classification on sentiment indicators, in which random forest shows good classification accuracy. Then, based on the grid search algorithm of the sklearn library, different combinations of key parameters of the random forest classifier were performed, and the optimal parameter combination was determined through five-fold cross-validation, and the ROC curve was used to measure its performance. The results show that the dual-modal emotion recognition based on random forest can classify four emotions with a maximum accuracy of 92.86%.",
        "affiliation_name": "Dongguan University of Technology",
        "affiliation_city": "Dongguan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Cross-language Emotion Analysis Based on Deep Learning and Performance Improvement in English Translation",
        "paper_author": "Ju L.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Due to the grammar, semantics, and cultural differences between languages, cross linguistic sentiment analysis and English translation tasks are quite challenging. Deep learning, as a neural network-based machine learning method, demonstrates powerful feature extraction and classification capabilities. This article focuses on cross linguistic sentiment analysis, aiming to use computer technology to automatically identify and understand emotional tendencies and perspectives in different languages. To this end, we propose a deep learning model that integrates Convolutional Neural Networks (CNN) and Long Short Term Memory Networks (LSTM). This model can capture local features of text and effectively process contextual information, achieving sentiment classification through fully connected layers. The experimental results show that this method not only improves the accuracy of sentiment analysis, but also significantly reduces errors in English translation, thereby enhancing the accuracy and fluency of long sentence translation. This cross linguistic sentiment analysis model based on deep learning provides a new and effective solution for language processing tasks.",
        "affiliation_name": "Dalian Polytechnic University",
        "affiliation_city": "Dalian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The role of machine intelligence in agriculture: A case study",
        "paper_author": "Ramteke P.L.",
        "publication": "Research Trends in Artificial Intelligence: Internet of Things",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "India's GDP is heavily reliant on agricultural products and business management. Therefore, it is crucial for the agriculture industry to comprehend the most common uses of artificial intelligence (AI) through case studies. To increase its production, this industry must overcome a number of obstacles, such as soil treatment, plant disease and pest effects, crop management, farmers' innovative methods, and the use of technology. The major ideas behind AI in agriculture are its adaptability, excellence, accuracy, and economy. It is critical to examine AI applications for managing soil, crops, and the environment, and plant or leaf diseases. Food security continues to be seriously threatened by deforestation and poor soil conditions, both of which harm the economy. The application's advantages, constraints, and methods for employing expert systems to increase productivity are all given particular attention. Businesses are utilizing robots and automation to assist farmers in developing more effective weed control strategies for their crops. See & Spray, a robot created by Blue River Technology, is said to use computer vision to monitor and accurately spray weeds on cotton plants. Crop and Soil Monitoring - Businesses are using deep learning and computer vision algorithms to interpret data taken by drones and/or software-based technologies to monitor the health of crops and soil. Crop sustainability and weather forecasting are accomplished via satellite systems. A Colorado-based startup employs satellites and machine learning algorithms to examine agricultural sustainability, forecast weather, and assess farms for the presence of diseases and pests. Utilizing predictive analytics, machine learning models are being created to monitor and forecast various environmental factors, such as weather variations. Drones and computer vision are used for crop analysis, while machine learning is used for identifying soil flaws.",
        "affiliation_name": "Symbiosis Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Simulation of Dynamic Evaluation Model for College English Online Teaching Based on Machine Learning Algorithms",
        "paper_author": "Yao X.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "College English online teaching is based on the integration of information technology, network technology, and disciplines. Based on the height of the times, it carefully examines the trend of social development, and proposes an action strategy to address the needs of future talent cultivation and the numerous problems faced by college English education, as well as to determine the direction and breakthrough of current education reform. It is an inevitable trend of modern education reform and development. This article conducts research on the simulation of a dynamic evaluation model for college English online teaching based on the ML (Machine Learning) algorithm. The research results indicate that among 20 students, 88% of the high group had longer online learning time than the low group. It can be fully explained that the improvement of students' grades is highly correlated with their online learning time, that is, students with longer online learning time have a greater improvement in their grades than students with less online learning time. Under the conditions of modern information technology, utilizing database networks and statistical techniques, combined with the theoretical achievements of testing and evaluation, corresponding dynamic evaluation systems are developed to conduct human-machine cooperation dynamic evaluation of teaching data at different stages. This can quickly and accurately reflect the development status of individual and group skills of learners, and provide targeted information for comprehensively promoting teaching reform.",
        "affiliation_name": "Henan Vocational College of Agriculture",
        "affiliation_city": "Zhongmu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Development and Application of Virtual Simulation Teaching System for Mechanical Disassembly Based on Unity3D",
        "paper_author": "Xu J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The disassembly and assembly process of reducer, engine and other mechanisms, as well as the display of parts' working process, are important components in emerging engineering education, especially for some basic courses such as \"Mechanical Design\"and \"Principle of Machinery\". To solve the problems of the difficulty of disassembly and assembly of mechanisms, high risk factors of experiments, high cost of experimental equipment and poor teaching effect, a virtual simulation experimental platform was developed based on unity3D. The experimental platform is a fully functional and interaction-friendly experimental platform integrates teaching, experiment, curriculum design and after-class review. This platform includes built-in virtual simulation models such as decelerator, and supports the import and editing of external model resources, which fully meets students' diversified needs of cognizing parts and structure. Through the practical application of this system, students have gained a deeper understanding of the disassembly process of mechanisms and the relationships between components. This virtual simulation experimentation platform effectively enhances students' enthusiasm for learning, engagement, and learning efficiency.\"",
        "affiliation_name": "China University of Geosciences",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Construction of English Big Data Corpus under Artificial Intelligence Translation",
        "paper_author": "Li W.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The construction of English big data corpora plays an important role in the field of artificial intelligence, providing key support for improving the performance of machine translation systems and training language models. This article explores the key issues and challenges of artificial intelligence in building English big data corpora, and proposes corresponding solutions. Firstly, we discussed the construction pattern of big data corpora. In view of this, the construction of big data corpora under artificial intelligence translation can be carried out from four aspects: sharing mode based on third-party open-source data, crowdsourcing translation, machine closed-loop learning mode, and human-machine collaboration mode. The future translation teaching can also rely on the construction of corpora as an important part of translation intelligence. By comprehensively considering these aspects, this article aims to provide comprehensive guidance and methods for the construction of English big data corpora, and promote the continuous development of artificial intelligence translation technology.",
        "affiliation_name": "Yunnan University",
        "affiliation_city": "Kunming",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An Exploration of an Intelligent Teaching Evaluation Model Based on Multimodality",
        "paper_author": "Guo X.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "With the popularity of online learning platforms, more and more people are using them to learn knowledge. The platforms provide multiple modes of data uploading, thus generating a large amount of data in different modalities. However it is urgent to fully multiple modal data to analyze and assess the learning effect of each student. In the field of education and teaching, many studies only use individual modal data to analyze and evaluate students using machine learning or deep learning algorithms, however, this approach does not analyze the data in a comprehensive way, so using multimodal data to construct a comprehensive and personalized approach is very helpful for students and teachers. In this paper, we make full use of the complementary and integrated information between different modalities to explore a comprehensive, accurate, and personalized approach to assessing teaching and learning, including the areas of discussion forums, workspaces, and course evaluations, in order to promote the development of intelligent science education.",
        "affiliation_name": "Beijing Economic Management Vocational College",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An Improved FFS Model for Student Grade Prediction",
        "paper_author": "Liu H.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "An improved FFS (Filter-enhanced-Fruit Fly Optimization Algorithm-Synthetic Minority Over-Sampling Technique) method is proposed to solve the sample imbalance problem in predicting students' grades. This method can enhance and filter the sampled data and improve the accuracy of model in predicting minority students' grades. for the problem that traditional machine learning models often lack interpretability, Shapley value based on cooperative game is used to explain the decision-making process of the model, and the important factors affecting students' performance can be obtained. Compared to the baseline models, FFS have significantly improved accuracy and f1 value for a few classes, and the average improvement is 3.94% and 16.3%, which proves the superiority of the proposed method for unbalanced data prediction. Finally shapes framework is used to explain the decision-making process of our model, and the important factors affecting students' achievement are also obtained.",
        "affiliation_name": "Shihezi University",
        "affiliation_city": "Shihezi",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Teaching Research Based on Linux Network Operating System",
        "paper_author": "Wei X.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "With the rapid development of computer technology, VM(virtual machine) is increasingly used to assist computer teaching. VM technology allows multiple independent virtual operating system instances to be created on a single physical computer, which provides great flexibility and efficiency for Linux operating system education. The application of VM in the teaching of Linux operating system has become an important and effective educational tool. In this paper, a teaching environment based on LNOS (Linux network operating system) is built by using VM, and a task-driven LNOS teaching mode is designed. Through this task-driven teaching mode, students will be able to apply their knowledge in the real network environment, gain practical experience and improve their problem-solving ability and self-confidence. This model can also encourage students to actively participate and better understand the principle and application of LNOS. VM improves learning efficiency, reduces costs, provides a consistent experimental environment, enhances security, provides practical experience, and provides scalability.",
        "affiliation_name": "Changchun Humanities and Sciences College",
        "affiliation_city": "Changchun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Opportunities and Challenges of Generative Artificial Intelligence in Facilitating Learning for Chinese University Students",
        "paper_author": "Ma S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "With the emergence of Artificial Intelligence in General Chat (AIGC), represented by ChatGPT, collaborative learning tasks between university students and machines have become a new norm in higher education. Simply prohibiting this new wave of technology cannot fundamentally address its challenges. This article presents the results of a survey investigating Chinese university students' perspectives on generative artificial intelligence technologies, such as ChatGPT, in supporting their learning. It analyzes the opportunities and challenges presented by this technology. Universities need to adapt to this transformation by altering the nature of student assignments and the methods of assessment. Additionally, they must effectively leverage the advantages of students conveniently acquiring knowledge through AIGC and the opportunity for personalized tutoring across various subjects. Striking the right balance between opportunities and challenges is crucial for creating a more productive and beneficial learning environment. Ultimately, this adaptation will better prepare education for the developments and changes in the era of artificial intelligence.",
        "affiliation_name": "Chongqing Normal University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Educational Data Mining: Uncovering Determinants of Course Success",
        "paper_author": "Yu J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Through comprehensive visual analysis of students' personal demographic information, course-specific details, and students' interactive data with courses, coupled with machine learning algorithm modeling, it has been discerned that different course modules, students from diverse geographic origins and educational backgrounds, as well as the level of deprivation in students' residential areas, all exert an influence on students' ultimate course grades. Elevated levels of student engagement with course materials and a higher rate of on-time assignment submissions are conducive to students achieving success in their course grades. This discovery holds significant implications for instructors in terms of classroom management, timely student interventions during the learning process, and enhancing course completion rates.",
        "affiliation_name": "Chongqing College of Electronic Engineering",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Study on the Neuro-aesthetic Indicator Choice for Machine learning in the view of Aesthetic Education Effect Evaluation",
        "paper_author": "Shao J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Aesthetic education strongly emphasizes fostering a harmonious integration between internal spirit and external form, employing diverse forms and methods to enrich individuals' minds subtly. Nevertheless, the practical implementation of aesthetic education curricula faces a challenge in evaluating the effectiveness of learning outcomes. In recent years, advancements in cognitive neuroscience have yielded significant insights into aesthetic Cognition and experience. Researchers have quantitatively explored human aesthetics using EEG, near-infrared spectroscopy, and functional magnetic resonance imaging technologies. This approach offers a fresh perspective and methodology for advancing contemporary theories and practices in aesthetic education. By adopting the neurocognitive science research paradigm, this study compared the self-report with the neuro-aesthetic indicator on 96 ink paintings from 19 people. The result of how the brain responds to visual stimuli can guide the development of aesthetic machine learning in the future and enhance the evaluation of learning outcomes in aesthetic education courses.",
        "affiliation_name": "Shanghai Institute of Visual Arts",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Design optimization under uncertainty",
        "paper_author": "Hu W.",
        "publication": "Design Optimization Under Uncertainty",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "This book introduces the fundamentals of probability, statistical, and reliability concepts, the classical methods of uncertainty quantification and analytical reliability analysis, and the state-of-the-art approaches of design optimization under uncertainty (e.g., reliability-based design optimization and robust design optimization). The topics include basic concepts of probability and distributions, uncertainty quantification using probabilistic methods, classical reliability analysis methods, time-variant reliability analysis methods, fundamentals of deterministic design optimization, reliability-based design optimization, robust design optimization, other methods of design optimization under uncertainty, and engineering applications of design optimization under uncertainty.",
        "affiliation_name": "State Key Laboratory of Fluid Power and Mechatronic Systems",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Artificial neural networks outperform linear regression in estimating 9-month patient-reported outcomes after upper extremity fractures with increasing number of variables",
        "paper_author": "Brinkman N.",
        "publication": "OTA International",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "Objective:To compare performance between linear regression (LR) and artificial neural network (ANN) models in estimating 9-month patient-reported outcomes (PROs) after upper extremity fractures using various subsets of early mental, social, and physical health variables.Methods:We studied 734 patients with isolated shoulder, elbow, or wrist fracture who completed demographics, mental and social health measures, and PROs at baseline, 2-4 weeks, and 6-9 months postinjury. PROs included 3 measures of capability (QuickDASH, PROMIS-UE-PF, PROMIS-PI) and one of pain intensity. We developed ANN and LR models with various selections of variables (20, 23, 29, 34, and 54) to estimate 9-month PROs using a training subset (70%) and internally validated them using another subset (15%). We assessed the accuracy of the estimated value being within one MCID of the actual 9-month PRO value in a test subset (15%).Results:ANNs outperformed LR in estimating 9-month outcomes in all models except the 20-variable model for capability measures and 20-variable and 23-variable models for pain intensity. The accuracy of ANN versus LR in the primary model (29-variable) was 83% versus 73% (Quick-DASH), 68% versus 65% (PROMIS-UE-PF), 66% versus 62% (PROMIS-PI), and 78% versus 65% (pain intensity). Mental and social health factors contributed most to the estimations.Conclusion:ANNs outperform LR in estimating 9-month PROs, particularly with a larger number of variables. Given the otherwise relatively comparable performance, aspects such as practicality of collecting greater sets of variables, nonparametric distribution, and presence of nonlinear correlations should be considered when deciding between these statistical methods.",
        "affiliation_name": "Dell Medical School",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Graph-level Anomaly Detection via Deep Metric Learning",
        "paper_author": "Yu L.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Graph-level Anomaly Detection (GAD) is a crucial subset of anomaly detection that aims to identify abnormal graphs with atypical nodes and structural features. Although extensive machine learning-based methods have been proposed to improve GAD, fundamental challenges of sample imbalance, distinguishable feature representation of graphs, and evaluation paradigms to identify anomalous graphs still exist. In light of these challenges, we re-consider GAD tasks from another perspective and propose a novel end-to-end method to spot graph anomalies. Specifically, we first generate graph pairs based on the traversal matching strategy as our training data to address the sample imbalance between normal and anomalous graphs. Then, we utilize a powerful Graph Isomorphism Network (GIN) combined with Siamese network architecture, which is a classical application of deep metric learning, to build a simple and end-to-end framework to learn more comprehensive graph-level representations capable of distinguishing between normal and anomalous graphs. Finally, we design a straightforward yet efficient evaluation paradigm named \"The Jury\" to identify anomalous graphs. Extensive experiments conducted on ten real-world datasets from various areas,e.g., social networks, molecular structures, and protein anomalies, demonstrate that the proposed method can effectively detect graph-level anomalies and performs competitively against other state-of-the-art methods.",
        "affiliation_name": "Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Outlier Exposure with Focal Loss for Out-of-distribution Detection",
        "paper_author": "Chen Q.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Out-of-Distribution (OOD) detection is of great importance especially when deploying machine learning models in an open-world setting. Outlier Exposure is one of the popular and effective methods for OOD detection, which utilizes an auxiliary dataset of outliers for teaching the network better representations. Moreover, Focal Loss was proposed to address the problem of imbalanced datasets, for object detection and related tasks, emphasizing the point that the learning ability of a model varies across different classes and instances, and thus should lead to corresponding modulation of the loss. In this paper, we bring Focal Loss into OOD detection and present a simple approach called Outlier Exposure with Focal Loss by introducing a focusing parameter into vanilla OE. Extensive experimental results on common benchmarks demonstrate the effectiveness of our method.",
        "affiliation_name": "The University of Nottingham Malaysia Campus",
        "affiliation_city": "Semenyih",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Multi-source information comprehensive malicious domain name detection based on convolutional neural network",
        "paper_author": "Xie P.Y.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "As the communication carrier of malware, viruses and malicious servers, malicious domain names pose a threat to social public information security. Aiming at the problem that the characteristics of malicious domain names change all the time, which leads to a low accuracy of traditional malicious domain name detection models, this paper proposes a multi-source information comprehensive malicious domain name detection model based on convolutional neural network. Firstly, different types of features in Domain Name System are divided into five categories, and a convolutional neural network framework is designed for each category to reduce the mutual influence between different types of features. Secondly, perform feature extraction is carried out and corresponding weights are trained, and multiple classification results are fused by decision pool to capture information among various features. Finally, the experimental results show that our scheme has higher prediction accuracy than other machine learning algorithms.",
        "affiliation_name": "Computer Network Information Center Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A machine learning-based admissions support system with a case study on D.K.M. College for Women, Vellore",
        "paper_author": "Vasumathy M.",
        "publication": "Design and Implementation of Higher Education Learners' Learning Outcomes (HELLO)",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Building efficient higher education systems is tough for India and other developing countries, especially when it comes to female students. Despite the government's efforts, India did not gain anything from its superb and creative educational policy. The Indian government is cognizant of the particular challenges the current global situation poses for the higher education industry. At Vellore's D.K.M. College for Women, the post-graduation admission rate has considerably declined over the last 12 months. The work is largely focused on the identification of concerns, obstacles, and declining factors of post-graduation admittance from the perspectives of students, parents, teaching staffs, and management. The architecture for the course recommender system and the information flow across it are proposed in this chapter. This approach forecasts the ideal subject pairing, or the subjects that pupils will be most interested in. Here, the authors use a learning management system like Moodle to gather information from students about their course preferences.",
        "affiliation_name": "Dhanabhagiyam Krishnasamy Mudaliar College for Women",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A flexible lightweight self-powered wireless metal detector enabled by triboelectric discharge effect",
        "paper_author": "Wang H.",
        "publication": "Device",
        "citied_by": "6",
        "cover_date": "2023-12-22",
        "Abstract": "Traditional metal detectors are relatively expensive, bulky, and inflexible, and they require an external power source; all of this limits their usage. Here, we present a self-powered wireless metal detector enabled by the triboelectric discharge effect, inductive coupling, and a signal modulation strategy. The device can convert mechanical triggers into wireless electromagnetic waves that contain information on nearby metals. Based on this strategy, we fabricated two prototypes with different sizes and different trigger modes, thus showing the capabilities and scalability for metal detection under different scenarios. In addition, because of the differences in the waveforms of the electromagnetic (EM) waves triggered by different types of metal, the device can also recognize the type of metal with the assistance of a trained machine learning model.",
        "affiliation_name": "The Hong Kong University of Science and Technology (Guangzhou)",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The Good, the Bad, and the Missing: Neural Code Generation for Machine Learning Tasks",
        "paper_author": "Shin J.",
        "publication": "ACM Transactions on Software Engineering and Methodology",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Machine learning (ML) has been increasingly used in a variety of domains, while solving ML programming tasks poses unique challenges due to the fundamental difference in the nature and the construct of general programming tasks, especially for developers who do not haveML backgrounds. Automatic code generation that produces a code snippet from a natural language description can be a promising technique to accelerate ML programming tasks. In recent years, although many deep learning-based neural code generation models have been proposed with high accuracy, the fact that most of them are mainly evaluated on general programming tasks calls into question their effectiveness and usefulness in ML programming tasks. In this article, we set out to investigate the effectiveness of existing neural code generation models on ML programming tasks. For our analysis, we select six state-of-the-art neural code generation models and evaluate their performance on four widely used ML libraries, with newly created 83K pairs of natural-language described ML programming tasks. Our empirical study reveals some good, bad, and missing aspects of neural code generation models on ML tasks, with a few major ones listed below. (Good) Neural code generation models perform significantly better on ML tasks than on non-ML tasks with an average difference of 10.6 points in BLEU-4 scores. (Bad) More than 80% of the generated code is semantically incorrect. (Bad) Code generation models do not have significance in improving developers' completion time. (Good) The generated code can help developers write correct code by providing developers with clues for using correct APIs. (Missing) The observation from our user study reveals the missing aspects of code generation for ML tasks, e.g., decomposing code generation for divide-and-conquer into API sequence identification and API usage generation.",
        "affiliation_name": "York University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Electroencephalography microstates as novel functional biomarkers for insomnia disorder",
        "paper_author": "Guo Y.",
        "publication": "General Psychiatry",
        "citied_by": "3",
        "cover_date": "2023-12-22",
        "Abstract": "Background Insomnia disorder (ID) is one of the most common mental disorders. Research on ID focuses on exploring its mechanism of disease, novel treatments and treatment outcome prediction. An emerging technique in this field is the use of electroencephalography (EEG) microstates, which offer a new method of EEG feature extraction that incorporates information from both temporal and spatial dimensions. Aims To explore the electrophysiological mechanisms of repetitive transcranial magnetic stimulation (rTMS) for ID treatment and use baseline microstate metrics for the prediction of its efficacy. Methods This study included 60 patients with ID and 40 age-matched and gender-matched good sleep controls (GSC). Their resting-state EEG microstates were analysed, and the Pittsburgh Sleep Quality Index (PSQI) and polysomnography (PSG) were collected to assess sleep quality. The 60 patients with ID were equally divided into active and sham groups to receive rTMS for 20 days to test whether rTMS had a moderating effect on abnormal microstates in patients with ID. Furthermore, in an independent group of 90 patients with ID who received rTMS treatment, patients were divided into optimal and suboptimal groups based on their median PSQI reduction rate. Baseline EEG microstates were used to build a machine-learning predictive model for the effects of rTMS treatment. Results The class D microstate was less frequent and contribute in patients with ID, and these abnormalities were associated with sleep onset latency as measured by PSG. Additionally, the abnormalities were partially reversed to the levels observed in the GSC group following rTMS treatment. The baseline microstate characteristics could predict the therapeutic effect of ID after 20 days of rTMS, with an accuracy of 80.13%. Conclusions Our study highlights the value of EEG microstates as functional biomarkers of ID and provides a new perspective for studying the neurophysiological mechanisms of ID. In addition, we predicted the therapeutic effect of rTMS on ID based on the baseline microstates of patients with ID. This finding carries great practical significance for the selection of therapeutic options for patients with ID.",
        "affiliation_name": "Inner Mongolia University of Science and Technology",
        "affiliation_city": "Baotou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Forecasting 24ĝ€¯h averaged PM2.5 concentration in the Aburrá Valley using tree-based machine learning models, global forecasts, and satellite information",
        "paper_author": "Pérez-Carrasquilla J.S.",
        "publication": "Advances in Statistical Climatology, Meteorology and Oceanography",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "We develop a framework to forecast 24ĝ€¯h averaged particulate matter (PM2.5) concentrations 4ĝ€¯d in advance in ground-based stations over the metropolitan area of the Aburrá Valley, Colombia. The input variables are gathered from a highly diverse set of sources, including in situ real-time PM2.5 observations, meteorological forecasts from the Global Forecasting System (GFS), aerosol optical depth (AOD) forecasts from the European Copernicus Atmosphere Monitoring Service (CAMS), and the Moderate Resolution Imaging Spectroradiometer (MODIS) active fire products. We compare the performance of two tree-based machine learning (ML) methods, random forests (RFs) and gradient boosting (GB), with linear regression as a baseline for error metrics. One of the disadvantages of tree-based models is their inability to make skillful predictions out of the domain in which the models were trained. To address that problem, we implement piecewise linear regression learners within the models. Additionally, to enhance the performance of the models, we use a customized loss function that considers the probability distribution of the target values. Tree-based models highly outperform the linear regression, with GB showing the best results in most of the 19 stations used in this study. We also test two approaches for the multi-step output problem, a direct multi-output (MO) scheme and a recursive (RC) scheme, with the GB-MO approach showing the best results. According to the performance analysis, the predictability is less for values away from the mean and decreases between 06:00ĝ€¯LT (local time) and the early afternoon, when the expansion of the boundary layer occurs. To contribute to understanding the sources of predictability and uncertainty of air quality in the city, we perform a feature importance analysis revealing that the relevance of the different independent variables is a function of the lead time. Particularly, apart from the past concentrations, the variables that most affect the predictability are the forecasted aerosol optical depth (AOD), the integrated fire radiative power over a forecasted back trajectory (BT-IFRP), and the predicted planetary boundary layer height (PBLH). In the testing period, the models showed the ability to forecast poor-air-quality events in the valley with more than 1ĝ€¯d of anticipation. This study serves as a framework for developing and evaluating the ML-based air quality forecasting models over the Andean region.",
        "affiliation_name": "College of Computer, Mathematical, &amp; Natural Sciences",
        "affiliation_city": "College Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep learning for quality control of surface physiographic fields using satellite Earth observations",
        "paper_author": "Kimpson T.",
        "publication": "Hydrology and Earth System Sciences",
        "citied_by": "3",
        "cover_date": "2023-12-22",
        "Abstract": "A purposely built deep learning algorithm for the Verification of Earth System ParametERization (VESPER) is used to assess recent upgrades to the global physiographic datasets underpinning the quality of the Integrated Forecasting System (IFS) of the European Centre for Medium-Range Weather Forecasts (ECMWF), which is used in both numerical weather prediction and climate reanalyses. A neural network regression model is trained to learn the mapping between the surface physiographic dataset, plus the main meteorologic fields from ERA5, and the MODIS satellite skin temperature observations. Once trained, this tool is applied to rapidly assess the quality of upgrades to the physiographic fields used by land surface schemes. Upgrades which improve the prediction accuracy of the machine learning tool indicate a reduction in the errors in the surface fields used as input to the surface parameterization schemes. Conversely, incorrect specifications of the surface fields decrease the accuracy with which VESPER can make predictions. We apply VESPER to assess the accuracy of recent upgrades to the permanent lake and glacier covers, as well as of planned upgrades to represent seasonally varying water bodies (i.e. ephemeral lakes). We show that, for grid cells where the lake fields have been updated, the prediction accuracy of VESPER in the land surface temperature (as quantified by the mean absolute error) improves by 0.37K on average, whilst for the subset of points where the lakes have been completely removed and replaced with bare ground, the improvement is 0.83K. We also show that updates to the glacier cover improve the prediction accuracy by 0.22K. We highlight how neural networks such as VESPER can assist the research and development of surface parameterizations and their input physiography to better represent Earth's surface coupled processes in weather and climate models.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A hybrid spatiotemporal deep belief network and sparse representation-based framework reveals multilevel core functional components in decoding multitask fmri signals",
        "paper_author": "Song L.",
        "publication": "Network Neuroscience",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Decoding human brain activity on various task-based functional brain imaging data is of great significance for uncovering the functioning mechanism of the human mind. Currently, most feature extraction model-based methods for brain state decoding are shallow machine learning models, which may struggle to capture complex and precise spatiotemporal patterns of brain activity from the highly noisy fMRI raw data. Moreover, although decoding models based on deep learning methods benefit from their multilayer structure that could extract spatiotemporal features at multiscale, the relatively large populations of fMRI datasets are indispensable, and the explainability of their results is elusive. To address the above problems, we proposed a computational framework based on hybrid spatiotemporal deep belief network and sparse representations to differentiate multitask fMRI (tfMRI) signals. Using a relatively small cohort of tfMRI data as a test bed, our framework can achieve an average classification accuracy of 97.86% and define the multilevel temporal and spatial patterns of multiple cognitive tasks. Intriguingly, our model can characterize the key components for differentiating the multitask fMRI signals. Overall, the proposed framework can identify the interpretable and discriminative fMRI composition patterns at multiple scales, offering an effective methodology for basic neuroscience and clinical research with relatively small cohorts.",
        "affiliation_name": "Northwest University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "BrainPy, a flexible, integrative, efficient, and extensible framework for general-purpose brain dynamics programming",
        "paper_author": "Wang C.",
        "publication": "eLife",
        "citied_by": "10",
        "cover_date": "2023-12-22",
        "Abstract": "Elucidating the intricate neural mechanisms underlying brain functions requires integrative brain dynamics modeling. To facilitate this process, it is crucial to develop a general-purpose programming framework that allows users to freely define neural models across multiple scales, efficiently simulate, train, and analyze model dynamics, and conveniently incorporate new modeling approaches. In response to this need, we present BrainPy. BrainPy leverages the advanced just-in-time (JIT) compilation capabilities of JAX and XLA to provide a powerful infrastructure tailored for brain dynamics programming. It offers an integrated platform for building, simulating, training, and analyzing brain dynamics models. Models defined in BrainPy can be JIT compiled into binary instructions for various devices, including Central Processing Unit, Graphics Processing Unit, and Tensor Processing Unit, which ensures high-running performance comparable to native C or CUDA. Additionally, BrainPy features an extensible architecture that allows for easy expansion of new infrastructure, utilities, and machine-learning approaches. This flexibility enables researchers to incorporate cutting-edge techniques and adapt the framework to their specific needs.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A study on the classification approach and characteristics of oily skin in young Chinese females",
        "paper_author": "Yang X.",
        "publication": "China Surfactant Detergent and Cosmetics",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Oily skincare is one of the common problems confronting young Chinese females. Currently, skin type characterization is largely based on self-reports and qualitative assessments by dermatologists. Quantitative classification approach for oily skin totally based on the non-invasive skin measurement devices has not been reported in the literatures. In this study, based on box-plot data and machine learning clustering algorithms for 2000 Chinese female subjects（mean aged 25.90±2.61）, non-invasive, objective, and quantitative classification approach for oily skin were initially established and compared with dermatologists’ empirical results for mutual corroboration. On this basis, this study quantitatively collected data on skin barrier, chromaticity, elasticity, acne and other indicators through a multifunctional probe tester and a facial skin imaging system, analyzed the accompanying characteristics of oily skin and susceptible skin problems, clarified the characteristics of oily skin in young Chinese females, and evaluated the risk level of acne and sensitivity of oily skin, with a view to providing scientific care and guidance for Chinese young females with oily skin groups. The results show that the box-plot classification method based on facial hydro-oil distribution is superior to the other two types of methods. The accompanying characteristics of oily skin are poor barrier, dull complexion, less elasticity, more acne and pores. In addition, the risk of acne-prone skin is significantly higher in oily skin based on odds ratio.",
        "affiliation_name": "Beijing Technology and Business University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Estimates of PM2.5 Concentration Based on Aerosol Optical Thickness Data Using Ensemble Learning with Support Vector Machine and Decision Tree",
        "paper_author": "Sangpradid S.",
        "publication": "Environmental Research, Engineering and Management",
        "citied_by": "3",
        "cover_date": "2023-12-22",
        "Abstract": "Air pollution, particularly fine particulate matter with a diameter of 2.5 micrometers or less (PM2.5), is a significant public health concern in many regions worldwide, including the northeastern region of Thailand. This study investigates the correlation between PM2.5 concentrations and meteorological spatial datasets such as surface relative humidity (SRH), surface wind speed (SPD), visibility (Vis), surface temperature (ST), and aerosol optical thickness (AOT) in the region. GIS techniques and the inverse distance weighting technique were used to create spatial maps of the meteorological datasets and ground station PM2.5 measurements. Pearson correlation analysis was performed to examine the relationship between PM2.5 and the meteorological datasets. Decision tree and support vector machine (SVM) algorithms were employed to estimate PM2.5 concentrations based on the spatial datasets. The results showed that Vis and ST have a moderate positive linear relationship with PM2.5, while AOT has a moderate negative linear relationship. SRH and SPD have weak relationships with PM2.5. The decision tree and SVM algorithms demonstrated a strong positive correlation between estimated and measured PM2.5 concentrations. The study shows that machine learning algorithms can be effective tools for estimating PM2.5 concentration based on AOT data, and feature selection can improve model performance. Ensemble learning could be employed to further improve model performance, particularly in regions with high spatial variability. Overall, the study provides a promising approach for estimating PM2.5 concentration using machine learning algorithms and AOT data.",
        "affiliation_name": "Valaya Alongkorn Rajabhat University",
        "affiliation_city": "Pathum Thani",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Classifying Religious Trends for Iraqi Politicians Tweets on social media Using Machine Learning Techniques",
        "paper_author": "Jalil A.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Social media is considered one of the most important means of communication between influencers such as (politicians) and the masses, and it is also considered one of the most influential means on public opinion. Analyzing of social media contents are an important task for decision makers in many situations. One of these situations is the opinion of Iraqi politicians toward religion. Knowing these opinions effect the decision making and it can be used for prediction of the behavior of politicians. In this work, an approach was proposed for extracting the religion trends of Iraqi politicians. A dataset of 149,864 tweets for 101 Iraqi politicians were collected. Five classifiers were trained and tested on a collected dataset of 29,022 tweets that classified into religion and non-religion. These classifiers are K-nearest neighbor (KNN), random Forest, gradient boosting, gaussian naive bayes and linear support vector machine. The results show that the best classifier was SVM. The classifier was used to classify Iraqi politicians' dataset of 149,864 tweets of 101 Iraqi politicians for extracting the opinion of them to religion. Also, the religious discourse usage rate was calculated for each politician in the database. The results were 98%, 97.31%, 98.7%, 98.01% and 0.1457 for accuracy, precision, recall, f-measure and mean squared error respectively.",
        "affiliation_name": "University of Alkafeel",
        "affiliation_city": "Najaf",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Ranking the Final Results of Deep Learning for Cell Image Segmentation",
        "paper_author": "Aljawaheri K.K.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "In our contemporary days, relying on machine learning has become a matter that we see permeates all life sciences and engineering, and there is no doubt that the exploitation of machine learning in various medical matters, the most important of which is the early detection of types of cancerous diseases, which has become an imperative due t o its relevance to human life, in this research paper we will address Incorporating both machine learning in early detection of cervical cancer and then applying the recommendation system to the final results and comparing them with traditional results, and here it should be noted that after 80 years of the invention of the Pap test, this test is still the most used method. Cell pathologists search for microscopic abnormalities inside and beside the cells, and here in this paper, we introduce deep learning techniques for cell fragmentation, as these techniques are able to detect abnormal cell clusters with the high overlap rate of digital photos for conventional Pap smears. Our method of research relies on ignoring low-load images by applying a system of advice to the results received. In the database, there are images from real cervical swabs from 113 fields of view that contain abnormal cells, and there are 96 swabs containing normal cells out of millions of cells. The results of our search on cells show an accuracy ratio (MAP = 0.924) and it works faster than the currently tiring methods.",
        "affiliation_name": "The Islamic University, Najaf",
        "affiliation_city": "Najaf",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "A Genetic Algorithm based Auto-Encoder based Approach for Intrusion Detection System",
        "paper_author": "Mahdi N.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The purpose of intrusion detection systems is to improve software and system security. The challenge of attack detection has already been addressed through supervised and unsupervised machine learning approaches. Although the previous methods lead to models that are very accurate on the observed samples, the new methods provide robust models on the unobserved samples. The accuracy of the new methods is equal to the accuracy of the observed samples. In this paper, we apply a deep neural network-based auto-encoder to the GA-AE-IDS (Automatic Encryption Detection System-Genetic Algorithm) intrusion detection system. Basically, the GA-AE-IDS is a light intrusion detection system that can be used online. In this paper, weighted datasets are processed in GA. First, auto-encoder neural networks are initialized; then GA-based weight optimization is performed on the system. The experimental results reflect that the proposed method can detect most attacks with good accuracy. It has also accelerated the training and testing process, and in dense samples has improved by about 4.9% compared to the base paper. Also, the AUC criterion in dense and sparse samples obtained from the proposed method has been improved by 5 and 8%, respectively.",
        "affiliation_name": "Imam Reza International University",
        "affiliation_city": "Mashhad",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Filtering Context-aware Collaborative for Mobile Users Learning",
        "paper_author": "Altaher A.W.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "While nearly seventy five of customers prefer a cell phone -friendly web site, ninety six of customers say they've encountered sites that have been sincerely not designed for cell phone. That is both a big problem and a massive possibility for corporations in search of to engage with cell phone users. The trouble: cell phone users don't recognize wherein to appearance to find information they want. It's usually a good idea to have ensemble algorithms to build a more comprehensive machine learning model such as combining content-based filtering. This paper goals to offer Proposed learning user interests framework which is answer this questions: computerized, personalized, context-aware occasion notification method Learns user pursuits Recommends new records the usage of collaborative filtering. Efficient context-aware architecture for classifying and delivering activities to cell users based on specified subscriptions.",
        "affiliation_name": "Imam Alkadhim University College",
        "affiliation_city": "Baghdad",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Stroke Type Classification Model based on Risk Factors Using Resilient Backpropagation Neural Networks",
        "paper_author": "Annas S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Stroke is a disease among the top 10 causes of death in the world and Indonesia. Stroke is divided into two, namely ischemic stroke and hemorrhagic stroke. Stroke can happen to anyone at any age with the characteristics of blood vessels experiencing blockage or rupture resulting in a crisis of blood supply that carries oxygen to the brain. The risk factors for stroke are the same as heart disease or other blood vessel diseases such as hypertension, diabetes, and cholesterol. One way to prevent stroke is to minimize several diseases that cause clogged or ruptured blood vessels. This study aims to predict the results of the classification of stroke types based on 6 factors, namely age, gender, cholesterol levels, length of stay (LOS), history, and blood sugar levels of stroke patients. The classification method chosen is one part of machine learning, namely the resilient backpropagation neural network (RBNN) because it is in accordance with the type of data used. The results showed that the prediction results of stroke type classification using six predictors were included in the good category and reached the optimum at the use of 5 nodes in the hidden layer and the resulting error was 9.26. The results of the evaluation of classification predictions using the confusion matrix also get good results, namely with an accuracy of 80% and an F1-score of 82% with a precision of 72% and a sensitivity of 95%. This result will be more optimal if there is the handling of imbalanced data.",
        "affiliation_name": "Universitas Negeri Makassar",
        "affiliation_city": "Makassar",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Develop an Unsupervised Attention-based LSTM Network Algorithm for Forecasting Infectious Disease",
        "paper_author": "Abotaleb M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Time series Due to better algorithms, more accessible data, and higher computing power over the past ten years, forecasting has become more popular. It is used in a variety of industries, including as financial time series, weather forecasting, and medical diagnostics. In this study, we provide a model of the mechanism governing attention, which enables attended input to be provided to the model in place of actual input. In order for the model to produce more precise predictions, it seeks to demonstrate a fresh perspective on the data. The experiments were conducted with the (encoder-decoder) LSTM model as well to demonstrate the usefulness and superiority of the suggested strategy. The obtained results demonstrate that, when compared to the (encoder-decoder) LSTM base model, the proposed approach could reduce the mean square error (RMSE=9819.05), relative root mean square error (RRMSE=99.09), and coefficient of determination (R Square=0.96). The obtained results support the suggested approach's efficacy, superiority, and importance in predicting SARS-CoV-2 infection cases.",
        "affiliation_name": "University of Alkafeel",
        "affiliation_city": "Najaf",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Realistic material property prediction using domain adaptation based machine learning",
        "paper_author": "Hu J.",
        "publication": "Digital Discovery",
        "citied_by": "7",
        "cover_date": "2023-12-22",
        "Abstract": "Materials property prediction models are usually evaluated using random splitting of datasets into training and test datasets, which not only leads to over-estimated performance due to inherent redundancy, typically existent in material datasets, but also deviate from the common practice of materials scientists: they are usually interested in predicting properties for a known subset of related out-of-distribution (OOD) materials rather than universally distributed samples. Feeding such target material formulae/structures to the machine learning models should improve the prediction performance while most current machine learning (ML) models neglect this information. Here we propose to use domain adaptation (DA) to enhance current ML models for property prediction and evaluate their performance improvements in a set of five realistic application scenarios. Our systematic benchmark studies show that there exist DA models that can significantly improve the OOD test set prediction performance while standard ML models and most of the other DA techniques cannot improve or even deteriorate the performance. Our benchmark datasets and DA code can be freely accessed at https://github.com/Little-Cheryl/MatDA.",
        "affiliation_name": "Michigan Engineering",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Automatic Lung Cancer Recognition in Chest CT-Scan Images Using SVM Classifier",
        "paper_author": "Elham Mohammed Thabit A.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Lung cancer has frequently surfaced as among the most lethal diseases that humanity has ever known. Early tumor identification is crucial in saving. X-rays and MRI scans may not be as successful as computed tomography (CT) scanning of the lungs in determining the presence of cancer. This study's key goals are to identify cancerous lung nodules from the provided inputs lung images and categorize lung cancer according to severity. This study applies cutting-edge machine learning techniques (SVM) to locate the Normal, Benign and Malignant lung cancer by training and extracting aspects of the CT images. SVM deep learning approaches offers the advantage of being able to handle random batches of data with large dimensionality. With each characteristic as input, the SVM's efficiency is tracked. The extracted findings reveal the superior performance of the SVM technique to predict the malignant CT images with high accuracy value reach to 100 %. The proposed technique to predict and identification of malignant CT images based on SVM machine learning considered as promising strategy to detect and categorize lung cancer in early phases.",
        "affiliation_name": "University of Kerbala",
        "affiliation_city": "Karbala",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Fuzzy Techniques in Concrete Powder Mix Designing",
        "paper_author": "Ridha A.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Water cement ratio It is a method consisting of more than one attempt in order to obtain a product that contains a mixture of ideal components involved in the production and formation of high-performance and cohesion concrete. There are many methods for making and designing concrete mixtures in contemporary studies and researches that are approved at the present time, but one of the most important, well-known and most widely used is the methodologies derived from the method of the three equations. Compressive strength is one of the most important characteristics of concrete, as it determines the concrete class. The concrete block represents the expected compressive strength is necessary for the use of concrete structures. primary feature of its durability and safety. Deep learning has recently received a lot of Concentration, the future of modern prospects for this technology is brighter. Machine learning algorithms have advanced to the point that they can recognize patterns that are difficult for humans to recognize. This has sparked interest in data mining on enormous datasets. We want to use Recent developments and achievements in machine learning approaches to formulation of concrete mixes creation in our study. In order to enhance the possibility of the ideal structure designed for an artificial neural network, an integrated database of concrete specifications and features with corresponding destructive laboratory tests was created. The architecture of an artificial neural network has been translated In a mathematical equation consisting of employed in real-world applications”.",
        "affiliation_name": "University of Alkafeel",
        "affiliation_city": "Najaf",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Design and Analysis of a Dc Motor Speed Drive with Generalized Regression Neural Network (GRNN) And Invasive Weed Optimization (IWO) Algorithms",
        "paper_author": "Mthboob M.H.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "This advanced research focuses on designing and analyzing a DC motor speed drive with Generalized Regression Neural Network (GRNN) and Invasive Weed Optimization (IWO) Algorithms using MATLAB/SIMULINK as a simulation aid. The DC motor speed drive is designed for fast dynamic speed and current response in all four quadrants of the motor's torque-speed plane. The DC motor's mathematical model is used for characterizing the system; IWO controllers are designed and tuned with methods including (MATLAB tuning, particle swarm optimization (PSO), and Internal Model Control). Two control strategies, single loop IWO and cascaded PI loops, were studied. The cascaded DC motor speed control was used for developing the DC motor's speed drive, which was tuned for a current loop bandwidth of 2π.600 rads/s, and a current limiting logic was implanted in the current loop of the controller. The PMDC machine's speed was controlled using the voltage control method with a Full bridge DC-DC power converter. Metal-oxide-semiconductor field-effect transistor (MOSFET) was used as the switch. The switching was done using the Unipolar Pulse Width Modulation technique due to its positive effect on the motor's current ripples. The use of active damping and active resistance in the speed and current loop was done to improve the drive performance. After tuning the controllers, the IWO-tuned single-loop GRNN controller had a better response than the MATLAB-tuned single-loop GRNN controller. GRNN-IWO gave a well-damped response with minimal overshoot compared to the MATLAB tuned IWO with an accuracy of 98.85%. Likewise, the cascade PI controller gains were obtained, and the controller yielded a well-damped response with negligible overshoot. The drive current limiting mechanism also ensured the rated continuous current of the motor was not exceeded during continuous operation. The cascade GRNN-IWO controller is shown to have excellent load disturbance rejection capacity with zero steady-state error. With the full bridge converter, the motor operated in both forward and reversed directions.",
        "affiliation_name": "Wasit University",
        "affiliation_city": "Wasit",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Hyper-parameter Tuning for the Long Short-Term Memory Algorithm",
        "paper_author": "Makarovskikh T.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "This research focuses on hyperparameter optimization for LSTM to forecast SARS-CoV-2 infection cases in the Russian Federation, aiming to determine the best combination of parameters for a well-fitting model. Using LSTM's capability to analyze relationships within time series data, a bidirectional LSTM-based method is introduced for predicting daily infection cases. The study evaluates nearly 10 unique forecasting models and conducts a comprehensive analysis and comparison of their results. The Bidirectional LSTM model proves to be a reliable approach for forecasting daily SARS-CoV-2 infection cases in Russia, displaying the highest prediction accuracy among the tested models.",
        "affiliation_name": "University of Alkafeel",
        "affiliation_city": "Najaf",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Lessons From Optimal Localization of Telecommunications Drones in Fifth Generation Networks Based on Unsupervised Machine Learning Methods",
        "paper_author": "Hasan S.H.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Fifth generation mobile 5G networks are used in many countries. Despite the advantages such as high speed, low delay, high security and privacy, there are still challenges such as lack of full coverage, especially in remote areas. Drones with the ability to fly to any possible place have been a way to overcome the challenge of not having complete coverage in the fifth generation. But in order to provide proper coverage in fifth generation networks, the position of these drones should be determined optimally. In such a way that the maximum coverage in the network occurs with the lowest energy consumption. Choosing the right place for the optimal localization of UAVs is one of the important activities in strategic planning for the maximum coverage of fifth generation networks. The positioning of UAVs is a multi-criteria decision, which includes quantitative and qualitative localization criteria. Due to the complexity of positioning in fifth generation networks, traditional positioning methods cannot be used effectively. Using methods based on machine learning can help in this field. Methods based on machine learning have shown their superiority in many research fields. The main goal of this research is to investigate the methods based on machine learning in the optimal localization of drones in order to provide optimal coverage with the least energy consumption.",
        "affiliation_name": "University of Alkafeel",
        "affiliation_city": "Najaf",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Detection of Chronic Diseases Based on the Principles of Deep and Machine Learning",
        "paper_author": "Ulsada A.A.A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Continuing care is referred to as a chronic disease. The most widespread and expensive medical illnesses worldwide are chronic diseases. Chronic diseases can result in hospitalization, long-term impairment, worse quality of life, and even death. These conditions include cancer, diabetes, hypertension, stroke, heart disease, respiratory conditions, and kidney diseases. In reality, the greatest cause of mortality and disability worldwide is chronic illnesses. In this paper, we present deep-based and machine-based models to diagnose chronic diseases, this system includes several stages, namely the stage of data pre-processing and the stage of disease detection, which is carried out in two ways, the first depending on a deep Convolution Neural Network (CNN) and the second based on five machine learning algorithms: Stochastic Gradient Descent (SGD), Naïve Bayes (NB), K-Nearest Neighbor (KNN), Logistic Regression (LR), and Decision Tree (DT). The proposed model works on three data sets, namely (Pima Indians Diabetes Dataset, Cardiovascular Disease dataset, and UCI Heart Disease Data) to classify heart, diabetes, and kidney diseases. The experimental results proved the capability of the suggested system to classify the aforementioned diseases with an ideal accuracy of 100% using the CNN in the first model, and an accuracy of 94% in the second model using the SGD and LR algorithms.",
        "affiliation_name": "Karabük Üniversitesi",
        "affiliation_city": "Karabuk",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "A Hybrid Model Between A One-Dimensional Convolution Neural Network and Machine Learning Algorithms for Arabic Sign Language Word Recognition",
        "paper_author": "Altememe M.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "The Arabic Sign Language is the way of communicating between people who suffer from hearing impairment in Arabic countries. According to the reports of the World Health Organization, the number of people suffering from hearing impairment in the Arab region was increased, and that produces a gap between society and hearing-impaired people in education and learning, work, using social media, communicating with others, etc. So, automatic sign language interpreters became a pressing necessity to reduce this gap and minimize their isolation. In this paper, a hybrid combination of modified Convolution Neural networks and machine learning classifiers is suggested. This proposal recognizes both the sign language alphabets and the symbolic sign language (words). A new dataset was created from the current dataset images and images that stemmed from video or captured by a camera. Images are preprocessed and then the features extracted by using Linear Discriminant Analysis are used as input to one dimension convolution neural network that uses one of the three machine learning classifiers (Naive Bayes, Decision Trees, and Random Forest) instead of a neural network.The proposal algorithm performance was tested with various challenges and gives the very promised accuracy reached up to 99.9% for recognition of alphabets and words, and the possibility to work efficiently in real-time.",
        "affiliation_name": "University of Kufa",
        "affiliation_city": "Kufa",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Detecting and diagnosing faults in PV systems based on machine learning techniques using MATLAB",
        "paper_author": "Zamzeer A.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "In recent years, the energy generated by the photovoltaic array has gained exceptional importance with the global demand for clean energy. Various photovoltaic (PV) faults may emerge due to external working conditions like potential damages associated with the manufacture, transit, or installation, leading to multiple levels of deterioration, power loss, or fire danger. Among these conditions are the temperature of the environment, the solar irradiance, and the variation of the load. Different types of faults in PV modules that result from these conditions are the main problems in this research. Thus, the main idea of the proposed work is to detect and diagnose specific types of faults that can be occurred in the PV system using an artificial neural network (ANN). This early operation is more potent for bypassing any error during the PV work and reducing any losses in the power of the PV system. The dataset of faults is determined from a new model of the photovoltaic cell, which is designed using a MATLAB/SIMULINK environment. The photovoltaic cell consists of three parallel strings with three series modules, and each module contains 20 photovoltaic cells with a series connection. Four parameters (V-load in Volt, I-load in Ampere, Irradiance in W/m2, and Temperature in Celsius) in this model are determined under different conditions (five temperature values, three irradiance values, and three-time events), which are repeated for all considered faults. These four parameters are used in the proposed ANN as effective features in the training and testing phases. Also, this network has eight outputs, one for each fault. The performance of the proposed network is evaluated by implementing it with three different numbers of hidden layers and the same dataset of faults. The simulation results view a significant percentage of fault detecting and diagnosing accuracy, ranging between 95% as a minimum and 98% as a maximum. The estimated RMSE shows that the training phase gains 0.193, and the testing phase has 0.365.",
        "affiliation_name": "Wasit University",
        "affiliation_city": "Wasit",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Named entity recognition for natural language understanding using BERT model",
        "paper_author": "Kumar S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Understanding natural languages are a very complex task for machines. Named entity recognition (NER) helps to understand natural language. NER aims to find mentions of specific identifiers in the text that belong to present semantic kinds such as person, place, organisation, time, money etc. In this paper a BERT (Bidirectional Encoder Representation from Transformation) model is trained with NER that improved the understanding of NLP. BERT is a transformer-based technique. It is trained and tested on CoNLL-2003 English dataset. The Proposed BERT based model gives 98.52% on English CoNLL-2003 NER dataset that is 4% greater than baseline models. The proposed BERT based NER model performed better results than other existing models. So, this features can enhance NLP applications in future like automatic text summarization, information retrieval systems, machine translation, machine reading comprehension, text classification etc.",
        "affiliation_name": "Gautam Buddha University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Drone detection using YOLO",
        "paper_author": "Patil S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "The paper intends to build a drone detection system using machine learning and deep learning algorithms. The system could differentiate between a drone and other flying objects like a different type of bird and recognize it. It also covers the various algorithms implemented for the development of drone detection systems. The research work uses YOLO algorithm as it is very efficient and widely used algorithm. Using the YoloV4 model, 85% of accuracy is obtained by classifying the images of the military drones in the 'aeroplane' category. It is one of the classes 'coco' dataset files. YoloV4 algorithm detects the drones which are based on deep convolutional neural networks. YoloV4 model is one of the most tested and stable versions of the YOLO. Once the drone is identified by the model, it will switch on the alarm to indicate drone detection.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Design patterns in machine learning",
        "paper_author": "Armyanova M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "The Artificial intelligence (AI) affects almost every field of modern technologies. The Machine learning is used as one of the most successful methods for developing AI. The Machine learning techniques combine mathematics and software development practices. The development experience at the architecture and design level can be encapsulated as patterns, to be reused and the expert experience to be brought to all developers in this relatively new technology. Design patterns are available in the domain of machine learning too. The research aim is to study the design patterns and to discover the advantages and disadvantages of their application.",
        "affiliation_name": "University of Economics - Varna",
        "affiliation_city": "Varna",
        "affiliation_country": "Bulgaria"
    },
    {
        "paper_title": "Evaluation of the pesticides trending trade in India using machine learning and data analytic",
        "paper_author": "Malik I.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "In agriculture, pesticides are a crucial tool for boosting crop productivity and safeguarding crops from disease and pests. However, excessive pesticide usage has had negative effects on the ecosystem. Even though the need for pesticides in agriculture has been rising every year, scientists have worked to limit their exposure. Because pesticide usage is growing in agriculture and other industries for a variety of reasons, the global trade in pesticides has been growing every year. Few persons made the false claim that the usage of pesticides is restricted. In this study, the pesticides dataset from the previous six years - which only includes pesticides imported into India in the previous six years - is processed and used to indicate the consumption of pesticides. The commerce in pesticides is expanding quickly in India as a result of growing pesticide consumption and the accuracy of the result is 86%. This dataset is handled using Python's data analytics package and the Support vector machine (SVM) machine learning algorithm. Data analysis is used in this study to determine the pesticide trade market. The market sees an increase in pesticide consumption every year, which is highly bad for the environment. Following data analysis, findings indicate that both pesticide consumption and import of pesticides are increasing in India. Herbicides, a kind of pesticide intended to eliminate weeds (unwanted plants)., are being employed less frequently by researchers. In this study, weeds and crop plants are distinguished using Keras' CNN model, and then herbicides are sprayed over the weeds rather than the crop when the findings are obtained. This model is trained using a training folder with two subfolders, one for crop and one for weed. To assess the model's efficacy, a test folder that has two subfolders and is similar to the training folder is used, 92% of the model is accurate.",
        "affiliation_name": "Gautam Buddha University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Improvisation of Reddit flair detection using TF-IDF and countvectorizer",
        "paper_author": "Singhal M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "The internet has become an essential part of everyone. Through the internet, many tasks are made easier, like online payments. With the increase in the number of internet users, the data is also increasing. People are fond of social media platforms like Facebook, Instagram, Reddit and Twitter. Reddit, a social networking website that provides a platform for users to create posts, discussion groups, etc., generates a massive amount of data daily. This data needs to be organized and analyzed to label it and divide it into specific categories. Posts on this social networking platform are organized with the help of categories defined by Reddit and are known as \"subreddits\". Through this study, an effort has been made to design a model that can detect the flair (category) of a Reddit post. The dataset is collected from the Reddit Application Program Interface using PRAW Library. This requires word embedding; that is, words that have a meaning similar to each other are represented analogously. Word embedding is done using techniques like Countvectorizer and TF-IDF. For the prediction of the flairs various algorithms are used, such as Logistic Regression, Decision Tree, Random Forest, Gaussian Naive Bayes, etc. The results of this study illustrate the importance of the proposed work. The dataset for this study is self-scraped from Reddit API where the instance with even a single blank column was removed. There is limited research done on flair identification on the Reddit dataset, which add-ons the uniqueness of the research done.",
        "affiliation_name": "Bharati Vidyapeeth's College of Engineering, New Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Identification and evaluation of machine learning classification algorithm to predict the efficacy of gRNA in CRISPR/Cas9 genome editing system using WEKA",
        "paper_author": "Bhardwaj A.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Genome editing is a novel technique to precisely manipulate genomic nucleotide in various organisms. The type II CRISPR/Cas9 system which is a part of the adaptive immune system of S. Pyogenes bacteria have governed this generation of genome engineering as it is straightforward to program and use. In a CRISPR/Cas system, the short gRNA sequence (20bp) controls the quality (accuracy and precision) of DNA cleavage. Even though various machine learning classifier algorithms are already being developed to evaluate the efficiency of gRNA and to predict off-targets but, there exist a discrepancy between predictions and experimentally observed results. A comprehensive analysis is required to identify a reliable CRISPR/Cas prediction algorithm. In this study, we aim to filter efficient classifier for evaluating CRISPR gRNA efficiency by exploring various classification algorithms on experimentally verified datasets of CRISPR. Also, we did a comparative study of their performances using machine learning software, WEKA. By using a 10-fold cross validation on the CRISPR dataset with 5310 instances and 9 attributes, we assessed the performance of 10 different machine learning algorithms by comparing their execution speed, completion time, precision, accurately and misclassified incidents, kappa statistics (K), mean absolute error, root mean square error, and true values of the confusion matrix. Our analysis suggests that tree-based classification algorithms have better potential to predict the efficiency of sgRNA in case of CRISPR genome editing system. In this research, we elaborate on the application of artificial intelligence to categorize and assess the features of gRNA to predict its efficacy and precision.",
        "affiliation_name": "Gautam Buddha University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Analytical study of machine learning techniques on the smart home energy consumption",
        "paper_author": "Singh T.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "In the present time, the demand of energy is increasing rapidly. The heavy demand of energy is in the smart cities domain as there are number of sub domains like Smart Homes, Smart Transportation, Smart Healthcare, etc. So, as the result the domain is opening the new research direction for the industrialist, researchers, and scientists. They are attracting towards the domain of smart city for different kinds of research projects. The primary concern of this paper is to focus on the energy consumption of smart homes. In this paper different Machine Learning (ML) and Deep Learning (DL) models are being implemented and the results are analyzed to check the performance of the different models on the dataset of smart home energy consumption. This study found that the Random Forest is predicting the energy consumption with lowest error with 0.6616, 0.4377, 0.3171 RMSE, MSE, and MAE respectively. The performance of the models is being evaluated in the terms of Root Mean Square Error (RMSE), Mean Square Error (MSE), and Mean Absolute Error (MAE). This study found that the most suited model for energy consumption data in smart city is Random Forest.",
        "affiliation_name": "Gautam Buddha University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Vision-based atopic dermatitis detection",
        "paper_author": "Madake J.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Atopic dermatitis is a chronic disease that makes skin red and itchy. The atopic dermatitis extremity is primarily evaluated on visual inspection by medical practitioners. There is no standard and automated method for evaluating atopic dermatitis severity. This paper proposes atopic dermatitis detection using computer vision and machine learning-based techniques. The proposed method combines feature extraction using GLCM-based Haralick features and Light Gradient Boosting Machine Classifier. This paper represents the effectiveness of using a computer vision-based approach for atopic dermatitis detection with a medium-scale dataset and its potential for dermatitis classification with 83% accuracy.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine learning technique based fake news detection",
        "paper_author": "Sutradhar B.K.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "False news has received attention from both the general public and the scholarly world. Such false information has the ability to affect public perception, giving nefarious groups the chance to influence the results of public events like elections. Anyone can share fake news or facts about anyone or anything for their personal gain or to cause someone trouble. Also, information varies depending on the part of the world it is shared on. Thus, in this paper, we have trained a model to classify fake and true news by utilizing the 1876 news data from our collected dataset. We have preprocessed the data to get clean and filtered texts by following the Natural Language Processing approaches. Our research conducts 3 popular Machine Learning (Stochastic gradient descent, Naïve Bayes, Logistic Regression,) and 2 Deep Learning (Long-Short Term Memory, ASGD Weight-Dropped LSTM, or AWD-LSTM) algorithms. After we have found our best Naive Bayes classifier with 56% accuracy and an F1-macro score of an average of 32%.",
        "affiliation_name": "Daffodil International University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Performance evaluation of ensemble methods for predictive analysis: An experiment for smart cities",
        "paper_author": "Siddiqui F.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Ensembles of individually trained models (such as various decision trees combined together) are said to have more effective and accurate results than any of the respective individual model when tested on the same data set instances. In this paper, authors have conducted an evaluation to measure the authenticity of this theory, for which authors have trained some individual classification models such as KNN classifier and SVM classifier along with a decision tree classifier and then the respective ensembles of those individual classifiers and a random forest classifier (an ensemble of various decision trees combined into an individual model). For training/fitting the models authors have used three real world datasets and then compared the predicted results from both the classifiers' categories. Research specifies that the ensemble methods give out more accurate predictions and they outperform their individual classifier models in almost every simulation which can be a great prediction based analysis for smart cities.",
        "affiliation_name": "Jamia Hamdard",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Prediction of Blight ticket compliance using different regression and classification models",
        "paper_author": "Mundargi Z.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Blight is a term closely associated with many cities nowadays. There are various properties which are vacant, with broken and damaged houses, not maintained properly and thus creating unhealthy surroundings. Such properties are termed as Blighted properties. In cities and suburbs, lesser property annoyances like overgrown lawns, unremoved trash, insufficient street lighting, and other neglectful behaviours are also referred to as blight. It turns out to be a major issue for those countries and citizens as it involves unhealthy surroundings, less land for more population, maintenance cost to be paid by the government, etc. This issue is visible more among US countries like Detroit. In this paper, the features on which this blight ticket is issued by the government to the owner of the property are discussed based on various machine learning models. These are then evaluated and compared to get a proper conclusion.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Personalized travel recommendation system: Hybrid model based on ratings and image analysis",
        "paper_author": "Bailke P.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Choosing a tourist place for vacation is very important, as a user spends a lot of money and efforts to choose a location wisely. To alleviate this effort, a travel recommendation system is introduced. However, the current recommendation system falls short of providing a perfect tourist location because there are different types of users, each with their own preferences. So here, a user needs a personalized recommendation system. This paper focuses mainly on creating a machine-learning system that is a travel recommender system. It recommends a particular tourist place in two different ways. The first is based on ratings given by other users, and the second is based on previous images of places that users have previously visited. This machine learning model can be further linked to a website using Flask to make it easier for people to use it and search for their favorite destination. This system recommends a tourist attraction based on two factors: first, the ratings of each location given by other users, and second, the images users prefer. This paper mainly focuses on using SVD, LDA, and OpenCV.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Face mask detector for preventing the transmission of disease",
        "paper_author": "Malik I.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Face masks are used to prevent the spread of disease. Covid19 is a major example, where individuals are required to wear masks in public places to stop the sickness from spreading. The SARS-CoV-2 virus outbreak, which killed people, began in 2019. Tiny droplets from the lips or nose of a person who has COVID-19 can pass the illness to another person when they cough or breathe. There were limited medical resources and no vaccines to cure the disease. This led to hundreds of thousands of deaths worldwide. The only non-pharmaceutical way suggested by WHO to prevent the spread of this virus was to wear masks. Nowadays it has been asked by Many providers of public assistance have to wear masks in order to provide their services. Face mask identification has therefore become a meticulous effort to aid the worldwide civilization. This paper provides a solution to solve this problem of face mask detection using machine learning algorithms such as CNN (Convolutional Neural Network), TensorFlow, Keras, and OpenCV. This model detects the face from the image and identifies whether a person is wearing a face mask properly or not. Accuracy of the model is 96%. Using the Sequential Convolutional Neural Network model values of parameters is optimized in order to detect whether a person is wearing a face mask properly or not these parameters are also used to prevent our model from over-fitting.",
        "affiliation_name": "Gautam Buddha University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Au@Ag Nanocube-Coated Polystyrene Microspheres as Hierarchical SERS Substrates for Trace Detection of As<sup>5+</sup>",
        "paper_author": "Guan H.",
        "publication": "ACS Applied Nano Materials",
        "citied_by": "4",
        "cover_date": "2023-12-22",
        "Abstract": "The plasmon coupling properties of assembled metal nanogap structures are highly sensitive to the distance, shape, orientation, and configuration of faceted nanoparticles. However, the orientation control of nanoparticles is usually limited to in-plane configurations. In this paper, Au@Ag nanocubes (NCs) with sharp edges and corners were assembled on a polystyrene (PS) microsphere array as a hierarchical surface-enhanced Raman spectroscopy (SERS) substrate via a facile self-assembly technique. The Au@Ag NC monolayer undergoes an out-of-plane reconstruction and forms V-shaped nanogaps under the modulation of the PS microsphere array curved surface. This unique V-shaped nanogap can generate electromagnetic fields stronger than those of traditional parallel gaps and make it easier for target molecules to diffuse into the nanogaps. The three-dimensional (3D) SERS substrates have a wider spectral response and 20 times higher SERS activity than those of the Au@Ag NC monolayer films on flat substrates. The high sensitivity was demonstrated by the detection limit down to 10-9 M for 4-MBA with a substrate enhancement factor up to 3.1 × 107. Furthermore, the optimized 3D SERS substrate was applied to determine As5+ in water with detection limits as low as 10-8 M assisted by machine learning, indicating that the 3D SERS substrates have promising applications in food safety, environmental monitoring, and biological diagnosis.",
        "affiliation_name": "Dalian Minzu University",
        "affiliation_city": "Dalian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Storage and Learning Phase Transitions in the Random-Features Hopfield Model",
        "paper_author": "Negri M.",
        "publication": "Physical Review Letters",
        "citied_by": "5",
        "cover_date": "2023-12-22",
        "Abstract": "The Hopfield model is a paradigmatic model of neural networks that has been analyzed for many decades in the statistical physics, neuroscience, and machine learning communities. Inspired by the manifold hypothesis in machine learning, we propose and investigate a generalization of the standard setting that we name random-features Hopfield model. Here, P binary patterns of length N are generated by applying to Gaussian vectors sampled in a latent space of dimension D a random projection followed by a nonlinearity. Using the replica method from statistical physics, we derive the phase diagram of the model in the limit P,N,D→∞ with fixed ratios α=P/N and αD=D/N. Besides the usual retrieval phase, where the patterns can be dynamically recovered from some initial corruption, we uncover a new phase where the features characterizing the projection can be recovered instead. We call this phenomena the learning phase transition, as the features are not explicitly given to the model but rather are inferred from the patterns in an unsupervised fashion.",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Connecting the dots with Hum: Unlocking data potential for publishers",
        "paper_author": "Simis L.",
        "publication": "Information Services and Use",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "This paper is based on a presentation by Dustin Smith at the APE 2023 Conference. Publishers struggle to gain a single view of audiences. As a consequence, they extract insights from inconsistent data sources. A customer data platform (CDP) and natural language processing engine help publishers solve these challenges. By integrating data, analyzing content, and using machine learning to understand individuals, publishers can personalize experiences, support key business cases, and tap into data's full potential.",
        "affiliation_name": "Hum",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Prophy: An automated reviewer finder to improve the efficiency, diversity and quality of reviews",
        "paper_author": "Harvey D.",
        "publication": "Information Services and Use",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "Peer review is under pressure. Without fair, transparent and efficient peer review we cannot ensure the right proposals get funded and the correct manuscripts get published. In the era of Open Access, which is driving an exponential increase in the number of submitted publications, how we carry out peer review is becoming increasingly important and how we find reviewers is coming under scrutiny. The current methods are slow and produce bias pools of reviewers. As such we need an improved way. At Prophy we have developed a state-of-the-art referee finder that can find experts to review any manuscript from any scientific field in seconds. Then through post-processing filters we can find appropriate candidate referees who are most likely to review a paper, whilst highlighting important conflicts of interest through our complex citation networks. These methods can ensure fair and independent experts who can review interdisciplinary papers from any discipline. These methods are being delivered through APIs and the editorial workflow of editors ensure the right people get access to these tools. Finally, as large-language models improve, so does Prophy and as such we will be looking to drive real innovation in this area in years to come.",
        "affiliation_name": "Prophy Sàrl",
        "affiliation_city": "St Sulpice",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "A Scalable and Stacked Ensemble Approach to Improve Intrusion Detection in Clouds",
        "paper_author": "Ghazi M.R.",
        "publication": "Information Technology and Control",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "The availability of automated data collection techniques and the growth in the amount of data collected from cloud network traffic and cloud resource activities has transformed into a big data challenge, compelling the en-gagement of big data tools to handle, manage, and interpret it. A single classification method may fail to execute successfully for the amount of acquired data. Despite being more complex and consuming more computational resources, the research shows that stacking-based ensemble Machine Learning (ML) methodologies perform better in data classification approaches than single classifiers. This research proposes Intrusion Detection Systems (IDS), both based on the ensemble of ML algorithms built on the Stacked Generalization Approach (SGA) and big data technology. The suggested approaches are tested and assessed on NSL-KDD and UNSW-NB15 datasets, utilizing a Gain Ration (GR) based Feature Selection (FS) approach, J48, OneR, Support Vector Machine (SVM), Random Forest (RF), Multi-layer Perceptron (MLP) and Extreme Gradient Boosting (XGBoost) classifiers and Apache Spark, a prominent big data processing platform. The first technique involves storing data on HDFS, while the second involves selecting the most suitable subset of base classifiers for stacking. A thorough performance investigation reveals that our proposed model outperforms other current IDS models either in terms of accuracy or FPR or other performance metrics, in discovering intrusions for the Cloud.",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "DECISION-MAKING BASED ON MACHINE LEARNING TECHNIQUES: A CASE STUDY",
        "paper_author": "Pouabe P.S.E.",
        "publication": "Polish Journal of Management Studies",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "Decision-making in companies is often based on the managers' personal experience. However, their consequences can have an impact on the development of the daily activities. To illustrate the managerial impact of decision-making, the biggest African power utility company based in South Africa will be analyzed. Various data such as annual productivity and energy sales were extracted over 15 years from his annual reports and two artificial neural network techniques named Levenberg-Marquardt and Scaled Conjugate Gradient used to analyze them. It emerged from the results obtained that between 2018 and 2020 the company experienced good growth which could extend until 2025 in the best-case scenario or else will drop again to reach its 2020 well-being state. Thus, the obtained results could be used to reinforce the decision-making and to determine the moment when decisions should be taken to prevent the demise of the company.",
        "affiliation_name": "University of Johannesburg",
        "affiliation_city": "Johannesburg",
        "affiliation_country": "South Africa"
    },
    {
        "paper_title": "Multidisciplinary Performance Enhancement on a Fixed-wing Unmanned Aerial Vehicle via Simultaneous Morphing Wing and Control System Design",
        "paper_author": "Eraslan Y.",
        "publication": "Information Technology and Control",
        "citied_by": "3",
        "cover_date": "2023-12-22",
        "Abstract": "Aerial vehicle design process usually aims to maximize performance in a specific flight phase regarding a particular topic such as aerodynamics, flight qualities, or control. This paper proposes a multidisciplinary enhancement both in aerodynamics and longitudinal autonomous flight performance (LAFP) via modern simultaneous design methodology conducted with a novel morphing idea. In this regard, the main wing of a fixed-wing unmanned aerial vehicle (UAV) is redesigned with wingtips capable of altering its taper ratio which results in a semi-tapered planform. The dynamic model of morphing aircraft is constituted from data obtained by numerical and analytical approaches for a number of morphing scenarios. The LAFP is identified as the sum of trajectory tracking parameters which are rise time, settling time, and maximum overshoot, while aerodynamic performance is defined as lift-to-drag ratio. A hierarchically structured control system is designed and the proportional-integral-differential (PID) controller coefficients and the taper ratio of the morphing wingtip are optimized via the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm. The k-Nearest Neighbor (k-NN) machine learning algorithm is also conducted to expand the data limited within the investigated range of morphing scenarios so as to have higher accuracy in optimization. Finally, flight simulations of the morphing UAV with optimal wing and control system design are carried out, closed-loop responses are examined in the presence of the von-Karman turbulence model, and the obtained satisfactory results are presented for both disciplines.",
        "affiliation_name": "Iskenderun Technical University",
        "affiliation_city": "Iskenderun",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Apply Physical System Model and Computer Algorithm to Identify Osmanthus Fragrans Seed Vigor Based on Hyperspectral Imaging and Convolutional Neural Network",
        "paper_author": "Qiu C.",
        "publication": "Information Technology and Control",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "Rapid identification of seed vitality plays key roles in the cultivation of the agricultural and forestry crops. This study discusses the use of compose a specular like technology, the computer algorithm and the feasibility of the physical system identification under different osmanthus seed vigor, in order to improve the ability to rec-ognize. Two varieties of Osmanthus seeds (JinQiGui and RiXiangGui) were artificially aged and then hyper-spectral data were collected. Multivariate scattering correction (MSC) and competitive adaptive reweighted sampling algorithm (CARS) were used for spectral preprocessing and feature wavelength selection, respec-tively. The extreme learning machine (ELM) and k-nearest neighbor (KNN) were used to establish the spectral discriminant model, and convolutional neural network was used in the computer image discriminant model. When MSC+CARS is combined with the above Discriminative model, nearly 100% recognition can be achieved with fewer bands. Compared with machine learning model, image-depth learning model can get higher model accuracy for different vigor JQG and RXG without complex preprocessing. These results indicate that hyper-spectral imaging technology can effectively distinguish different vigor of Osmanthus fragrans seeds based on computer technology and physical system. Combining deep neural networks with image information is of great importance for research and development of portable high precision seed vitality spectral imagers.",
        "affiliation_name": "Guangdong University of Science and Technology",
        "affiliation_city": "Dongguan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Towards a Combination of Metrics for Machine Translation",
        "paper_author": "Mosbah M.",
        "publication": "Journal of Information and Organizational Sciences",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "In this scholar, we compare three metrics for machine translation, from English to French and vice versa, and we give some combination formulas based on some schemes, algorithms, and machine learning tools. As an experimental dataset, we consider 10 English and French theses abstracts published in the web with four free in charge machine translation systems. Five combinations, with the same implicit weights, are considered namely: (BLEU+NIST), (BLEU+ (1-WER)), (NIST+(1-WER)), (BLEU+NIST+(1-WER)), and (FR(BLEU)+FR(NIST)+FR(WER)). These combinations are also considered differently through generating weights parameters on the basis of regression. The results of 12 formulas are computed and compared then in total. According to the obtained results, average regression combinations based on machine learning step are the best, especially with the three basic metrics, followed by average WER metric in the case of English to French. For French to English, (FR(BLEU)+FR(NIST)+FR(WER)) combination is the best followed respectively by the average regression combination with both first parameters (Reg(α,β)) and average BLEU basic metric. Another performance criterion is considered here, in the second position, namely: the number of times, over the 10 abstracts, where the formula is the best. Based on the obtained results, combination with regression based on the first and the last parameters (Reg(α,γ)) outperforms the others, in the case of English to French, with 3 times followed by Reg(β,γ), Reg(α,β,γ), NIST+(1-WER), and the basic metrics (BLEU, NIST, and WER) with 2 times for each of them. For French to English, the basic WER metric outperforms the others with three times followed by BLEU, (BLEU+ (1-WER)), (FR(BLEU)+FR(NIST)+FR(WER)), and Reg(α,γ) with 2 times for each of them. To note that there is a room of improvement for the combinations with1.0914 in the case of English to French and 1.01 in the case of French to English.",
        "affiliation_name": "Université 20 Août 1955-Skikda",
        "affiliation_city": "Skikda",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "Accelerating and enhancing the generation of socioeconomic data to inform forced displacement policy and response",
        "paper_author": "Brock P.M.",
        "publication": "Data and Policy",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "There are now an estimated 114 million forcibly displaced people worldwide, some 88% of whom are in low- and middle-income countries. For governments and international organizations to design effective policies and responses, they require comparable and accessible socioeconomic data on those affected by forced displacement, including host communities. Such data is required to understand needs, as well as interactions between complex drivers of displacement and barriers to durable solutions. However, high-quality data of this kind takes time to collect and is costly. Can the ever-increasing volume of open data and evolving innovative techniques accelerate and enhance its generation? Are there applications of alternative data sources, advanced statistics, and machine-learning that could be adapted for forced displacement settings, considering their specific legal and ethical dimensions? As a catalytic bridge between the World Bank and UNHCR, the Joint Data Center on Forced Displacement convened a workshop to answer these questions. This paper summarizes the emergent messages from the workshop and recommendations for future areas of focus and ways forward for the community of practice on socioeconomic data on forced displacement. Three recommended areas of future focus are: enhancing and optimizing household survey sampling approaches; estimating forced displacement socioeconomic indicators from alternative data sources; and amplifying data accessibility and discoverability. Three key features of the recommended approach are: strong complementarity with the existing data-collection-to-use-pipeline; data responsibility built-in and tailored to forced displacement contexts; and iterative assessment of operational relevance to ensure continuous focus on improving outcomes for those affected by forced displacement.",
        "affiliation_name": "The World Bank, USA",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "How accurately can one predict drug binding modes using AlphaFold models?",
        "paper_author": "Karelina M.",
        "publication": "eLife",
        "citied_by": "26",
        "cover_date": "2023-12-22",
        "Abstract": "Computational prediction of protein structure has been pursued intensely for decades, motivated largely by the goal of using structural models for drug discovery. Recently developed machine-learning methods such as AlphaFold 2 (AF2) have dramatically improved protein structure prediction, with reported accuracy approaching that of experimentally determined structures. To what extent do these advances translate to an ability to predict more accurately how drugs and drug candidates bind to their target proteins? Here, we carefully examine the utility of AF2 protein structure models for predicting binding poses of drug-like molecules at the largest class of drug targets, the G-protein-coupled receptors. We find that AF2 models capture binding pocket structures much more accurately than traditional homology models, with errors nearly as small as differences between structures of the same protein determined experimentally with different ligands bound. Strikingly, however, the accuracy of ligand-binding poses predicted by computational docking to AF2 models is not significantly higher than when docking to traditional homology models and is much lower than when docking to structures determined experimentally without these ligands bound. These results have important implications for all those who might use predicted protein structures for drug discovery.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Recovery of Brine Resources Through Crown-Passivated Graphene, Silicene, and Boron Nitride Nanosheets Based on Machine-Learning Structural Predictions",
        "paper_author": "Abdulazeez I.",
        "publication": "ACS Applied Nano Materials",
        "citied_by": "10",
        "cover_date": "2023-12-22",
        "Abstract": "The rising global demand for brine resources necessitates the exploration of alternative sources to complement existing natural sources. It is imperative to explore innovative approaches, such as emerging machine learning-aided tools, to ensure sustainable and secure brine resources. We proposed a kernel support vector regression (k-SVR), and Gaussian process regression (GPR) based on several feature engineering selectivity approaches that were employed for modeling adsorption energy (kcal/mol). For this purpose, two different scenarios of crown-embedded 2D materials using first-principles density functional theory simulations were obtained. Subsequently, ensemble machine learning (ML) was employed to improve the accuracy of prediction skills of the 2D materials. The data for the successful creation of ion transmission channels utilizing 9-crown-3 (distance within cavity O9-O6 = 3.105 Å, O3-O6 = 2.934 Å, O3-O9 = 2.961 Å) and 12-crown-4 (distance within cavity O3-O9 = 4.538 Å, O6-O12 = 3.223 Å) molecules on graphene, hexagonal boron nitride, and silicene nanosheets were used in this study. The predictive results proved that GPR-C1 with a numerical comparison of RMSE = 0.096, NSE = 0.9610 in the training phase and RMSE = 0.6630, NSE = 0.911 in the testing phase outperformed the other model combinations. The study also proposed federated learning for reliable modeling and recovery of complex and poor selectivity of brine resources. The present study utilizes ML algorithms to provide insights into brine resource recovery, which contributes to multiple sustainable development goals, addressing environmental, economic, and social dimensions of sustainable development.",
        "affiliation_name": "King Fahd University of Petroleum and Minerals",
        "affiliation_city": "Dhahran",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Fruit Freshness Monitoring Employing Chemiresistive Volatile Organic Compound Sensor and Machine Learning",
        "paper_author": "Mahata B.",
        "publication": "ACS Applied Nano Materials",
        "citied_by": "9",
        "cover_date": "2023-12-22",
        "Abstract": "The work highlights the assessment of fruit freshness through the incorporation of a chemiresistive gas sensor and machine learning. For this purpose, SnO2 nanosheets were synthesized through a low-temperature hydrothermal route. The sensor device was fabricated by integrating a synthesized nanomaterial with interdigitated electrodes. Fruits, including apple, guava, grape, and orange, were taken for analysis, and associated emitted volatiles were considered as the freshness indicator. Fruit samples were stored at room temperature, and systematic sensing measurements were performed at different time intervals (0, 24, 48, and 72 h) to estimate the freshness level. Initially, the responses of the sensor attained from apple, guava, orange, and grape samples were 1.7, 2.5, 6.4, and 2.2, respectively. A neural network-based regression model was employed for the determination of storage duration of fruits in a quantitative manner. The model displayed notable success in prediction, with an average error of less than 10%. Thus, the approach has great potential to develop a smart sensor system to monitor fruit freshness with a real-time outlook.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Harnessing the power of machine learning in sport consumer behavior research",
        "paper_author": "Du J.",
        "publication": "Sports Sponsorship and Branding: Global Perspectives and Emerging Trends",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "NA",
        "affiliation_name": "Florida State University",
        "affiliation_city": "Tallahassee",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Sports sponsorship and branding: Global perspectives and emerging trends",
        "paper_author": "Leng H.K.",
        "publication": "Sports Sponsorship and Branding: Global Perspectives and Emerging Trends",
        "citied_by": "0",
        "cover_date": "2023-12-22",
        "Abstract": "This book takes a close look at branding and sponsorship in sport in the age of digital media. It examines how branding and sponsorship have evolved in response to the challenges and opportunities of new technologies. Featuring the work of leading international sport business researchers from four continents and twelve countries, the book explores key contemporary topics including esports, name and image likeness (NIL) rights, viewer experience, machine learning, social media use by athletes, sport migration, and the impact of COVID-19. It presents cutting-edge cases and new data across sports and events, including the Olympics, the NBA, international football, the rafting world championships, and collegiate sports. The book is an essential resource for advanced students, researchers, practitioners, and policymakers working in sport business and management, sport marketing, digital marketing, marketing communications, or brand management.",
        "affiliation_name": "University of Georgia",
        "affiliation_city": "Athens",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep learning(s) in gaming disorder through the user-avatar bond: A longitudinal study using machine learning",
        "paper_author": "Stavropoulos V.",
        "publication": "Journal of Behavioral Addictions",
        "citied_by": "8",
        "cover_date": "2023-12-22",
        "Abstract": "Background and aims: Gaming disorder [GD] risk has been associated with the way gamers bond with their visual representation (i.e., avatar) in the game-world. More specifically, a gamer’s relationship with their avatar has been shown to provide reliable mental health information about the user in their offline life, such as their current and prospective GD risk, if appropriately decoded. Methods: To contribute to the paucity of knowledge in this area, 565 gamers (Mage 5 29.3 years; SD 510.6) were assessed twice, six months apart, using the User-Avatar-Bond Scale (UABS) and the Gaming Disorder Test. A series of tuned and untuned artificial intelligence [AI] classifiers analysed concurrently and prospectively their responses. Results: Findings showed that AI models learned to accurately and automatically identify GD risk cases, based on gamers’ reported UABS score, age, and length of gaming involvement, both concurrently and longitudinally (i.e., six months later). Random forests outperformed all other AIs, while avatar immersion was shown to be the strongest training predictor. Conclusion: Study outcomes demonstrated that the user-avatar bond can be translated into accurate, concurrent and future GD risk predictions using trained AI classifiers. Assessment, prevention, and practice implications are discussed in the light of these findings.",
        "affiliation_name": "National and Kapodistrian University of Athens",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Online thermal field prediction for metal additive manufacturing of thin walls",
        "paper_author": "Tang Y.",
        "publication": "Journal of Manufacturing Processes",
        "citied_by": "2",
        "cover_date": "2023-12-22",
        "Abstract": "Various data-driven modeling methods have been developed to predict the thermal field in metal additive manufacturing (AM). The generalization capability of these models has been shown with simulation, but rarely tested with online physical printing. Instead, this paper aims to study a practical issue in metal AM, i.e., how to predict the thermal field of yet-to-print parts online when only a few sensors are available. This work proposes an online thermal field prediction method using mapping and reconstruction, which could be integrated into a metal AM process for online performance control. Based on the similarity of temperature curves (curve segments of a temperature profile of one point), the thermal field mapping applies an artificial neural network to estimate the temperature curves of points on the yet-to-print layer from measured temperatures of certain points on the previously printed layer. With measured/predicted temperature profiles of several points on the same layer, the thermal field reconstruction proposes a reduced order model (ROM) to construct the temperature profiles of all points on the same layer, which could be used to build the temperature field of the entire layer. The training of ROM is performed with an extreme learning machine (ELM) for computational efficiency. Fifteen wire arc AM experiments and nine simulations are designed for thin walls with a fixed length and unidirectional printing of each layer. The test results indicate that the proposed prediction method could construct the thermal field of a yet-to-print layer within 0.1 s on a low-cost desktop computer (Intel Core i7-3770 CPU @ 3.40GHz processor, 24.0 GB RAM). Meanwhile, the method has acceptable generalization capability in most cases from lower layers to higher layers in the same simulation, as well as from one simulation to a new simulation on different AM process parameters. More importantly, after fine-tuning the proposed method with limited experimental data, the relative errors of all predicted temperature profiles on a new experiment are sufficiently small, which demonstrates the applicability and generalization of the proposed thermal field prediction method in online applications for metal AM.",
        "affiliation_name": "Simon Fraser University",
        "affiliation_city": "Burnaby",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Modern Potentiometric Biosensing Based on Non-Equilibrium Measurement Techniques",
        "paper_author": "Mou J.",
        "publication": "Chemistry - A European Journal",
        "citied_by": "3",
        "cover_date": "2023-12-22",
        "Abstract": "Modern potentiometric sensors based on polymeric membrane ion-selective electrodes (ISEs) have achieved new breakthroughs in sensitivity, selectivity, and stability and have extended applications in environmental surveillance, medical diagnostics, and industrial analysis. Moreover, nonclassical potentiometry shows promise for many applications and opens up new opportunities for potentiometric biosensing. Here, we aim to provide a concept to summarize advances over the past decade in the development of potentiometric biosensors with polymeric membrane ISEs. This Concept article articulates sensing mechanisms based on non-equilibrium measurement techniques. In particular, we emphasize new trends in potentiometric biosensing based on attractive dynamic approaches. Representative examples are selected to illustrate key applications under zero-current conditions and stimulus-controlled modes. More importantly, fruitful information obtained from non-equilibrium measurements with dynamic responses can be useful for artificial intelligence (AI). The combination of ISEs with advanced AI techniques for effective data processing is also discussed. We hope that this Concept will illustrate the great possibilities offered by non-equilibrium measurement techniques and AI in potentiometric biosensing and encourage further innovations in this exciting field.",
        "affiliation_name": "Yantai Institute of Coastal Zone Research, Chinese Academy of Sciences",
        "affiliation_city": "Yantai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Optimizing Perovskite Thin-Film Parameter Spaces with Machine Learning-Guided Robotic Platform for High-Performance Perovskite Solar Cells",
        "paper_author": "Zhang J.",
        "publication": "Advanced Energy Materials",
        "citied_by": "21",
        "cover_date": "2023-12-22",
        "Abstract": "Simultaneously optimizing the processing parameters of functional thin films remains a challenge. The design and utilization of a fully automated platform called SPINBOT is presented for the engineering of solution-processed functional thin films. The SPINBOT is capable of performing experiments with high sampling variability through the unsupervised processing of hundreds of substrates with exceptional experimental control. Through the iterative optimization process enabled by the Bayesian optimization (BO) algorithm, the SPINBOT explores an intricate parameter space, continuously improving the quality and reproducibility of the produced thin films. This machine learning (ML)-guided reliable SPINBOT platform enables the acceleration of the optimization process of perovskite solar cells via a simple photoluminescence characterization of films. As a result, this study arrives at an optimal film that, when processed into a solar cell in an ambient atmosphere, immediately yields a champion power conversion efficiency (PCE) of 21.6% with satisfactory performance reproducibility. The unsealed devices retain 90% of their initial efficiency after 1100 h of continuous operation at 60–65 °C under metal-halide lamps. It is anticipated that the integration of robotic platforms with the intelligent algorithm will facilitate the widespread adoption of effective autonomous experimentation to address the evolving needs and constraints within the materials science research community.",
        "affiliation_name": "Lawrence Berkeley National Laboratory",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Enhanced Visualization and Interpretation of XMCD-PEEM Data Using SOM-RPM Machine Learning",
        "paper_author": "Wong S.Y.",
        "publication": "Advanced Materials Interfaces",
        "citied_by": "1",
        "cover_date": "2023-12-22",
        "Abstract": "Photoemission electron microscopy (PEEM) is a powerful technique for surface characterization that provides detailed information on the chemical and structural properties of materials at the nanoscale. In this study, the potential is explored using a machine learning algorithm called self-organizing map with a relational perspective map (SOM-RPM) for visualizing and analyzing complex PEEM-generated datasets. The application of SOM-RPM is demonstrated using synchrotron-based X-ray magnetic circular dichroism (XMCD)-PEEM data acquired from a pyrrhotite sample. Traditional visualization approaches for XMCD-PEEM data may not fully capture the complexity of the sample, especially in the case of heterogeneous materials. By applying SOM-RPM to the XMCD-PEEM data, a colored topographic map is created that represents the spectral similarities and dissimilarities among the pixels. This approach allows for a more intuitive and easily interpretable representation of the data without the need of data binning or spectral smoothing. The results of the SOM-RPM analysis are compared to the conventional visualization approach, highlighting the advantages of SOM-RPM in revealing features that are not readily observable in the conventional method. This study suggests that the SOM-RPM approach can be used complimentarily for other PEEM-based measurements, such as core level and valence band X-ray photoelectron spectroscopy.",
        "affiliation_name": "College of Science and Engineering",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Bridging the Gap: Electrode Microstructure and Interphase Characterization by Combining ToF-SIMS and Machine Learning",
        "paper_author": "Lombardo T.",
        "publication": "Advanced Materials Interfaces",
        "citied_by": "5",
        "cover_date": "2023-12-22",
        "Abstract": "This article presents a new analytical methodology to analyze large (hundreds of µm) battery electrode microstructures by mapping the spatial distribution of the main phases (e.g., active material and carbon-binder domain) and degradation products (solid- or cathode-electrolyte interphase) formed during cycling. The methodology can be used for a better understanding of the relationships between electrode architecture and degradation, paving the way toward the analysis of interphases spatial distribution and their correlations to the electrode formulation, microstructure, and cycling conditions. This work is based on time-of-flight secondary ion mass spectrometry (ToF-SIMS), and focuses on analyzing large 2D electrode cross-sections at both the microstructure and single particle/agglomerate level. It also shows that this analysis can be expanded to 3D electrode microstructures when combining ToF-SIMS and devoted machine learning procedures, which can be of particular interest to the 3D electrochemical modeling community.",
        "affiliation_name": "Justus-Liebig-Universität Gießen",
        "affiliation_city": "Giessen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Kirigami-Inspired 3D-Printable MXene Organohydrogels for Soft Electronics",
        "paper_author": "Zhuo F.",
        "publication": "Advanced Functional Materials",
        "citied_by": "41",
        "cover_date": "2023-12-22",
        "Abstract": "Conductive hydrogels are compelling materials for the development of soft electronics; however, their essential attributes such as high sensitivity, excellent stretchability, and environmental stability have rarely been achieved simultaneously in one hydrogel. Herein, a Kirigami-inspired strategy is proposed to improve organohydrogel sensitivity without sacrificing their mechanical stretchability and environmental stability. The organohydrogels with multiple interpenetrating networks are synthesized by introducing sodium alginate nanofibrils and conductive MXene nanoflakes into polymer double networks infiltrated with glycerol–water mixtures, featuring remarkable stretchability (>5000%), good sensitivity, and water retention (>30 days). The Kirigami structures are further applied to enhance strain sensitivity, achieving a gauge factor of 29.1, which is ≈5.5 times that of an unstructured organohydrogel. Using the Kirigami-inspired sensors, a durable glove is developed for grabbing underwater objects through operating a robotic arm, demonstrating a subaqueous interactive human–machine interfacing.Meanwhile, by integrating the wearable sensor with a machine learning algorithm, a wearable Morse code intelligent recognition system is demonstrated, enabling real-time conversion of Morse code signs into speech with superior recognition accuracy (>99%) and fast response time (≈17 ms). This work offers a new route to synthesize highly sensitive, stretchable, and extremely tolerant organohydrogels, providing a promising platform for next-generation soft electronics.",
        "affiliation_name": "College of Information Science and Electronic Engineering, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning enabled quantification of stochastic active metadamping in acoustic metamaterials",
        "paper_author": "Chatterjee T.",
        "publication": "Journal of Sound and Vibration",
        "citied_by": "8",
        "cover_date": "2023-12-22",
        "Abstract": "System uncertainties often lead to deviation from the anticipated behaviour of acoustic metamaterials (AMs) and thus, make their intended design ineffective. Therefore, in this study, the effect of stochastic parameters on a recently developed phenomenon in AMs, known as active metadamping is quantified using machine learning (ML). The enhancement of damping in an active feedback-controlled metamaterial over an equivalent uncontrolled counterpart is defined as active metadamping. Metadamping enables a metamaterial to dissipate energy faster in addition to its inherent bandgap characteristics. The ML technique, Gaussian process is used as the surrogate model to capture the stochastic dynamics of the active AM. A trade-off in the spatial attenuation and temporal energy dissipation characteristics is observed while velocity-feedback control is applied within the resonating units of the metamaterial. The overall dissipation and the decay ratio increase around five times in the controlled case; whereas, the attenuation bandwidth reduces or even vanishes. Most importantly, the results elucidate that metadamping is robust to the uncertainty of the system parameters, unlike the energy and the decay amplitude for the controlled case. Additionally, Gaussian process is able to capture the behaviour of active AMs by using only 1% computational cost as compared to that of the Monte Carlo simulations.",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Artificial intelligence for edge computing",
        "paper_author": "Srivatsa M.",
        "publication": "Artificial Intelligence for Edge Computing",
        "citied_by": "2",
        "cover_date": "2023-12-21",
        "Abstract": "It is undeniable that the recent revival of artificial intelligence (AI) has significantly changed the landscape of science in many application domains, ranging from health to defense and from conversational interfaces to autonomous cars. With terms such as \"Google Home\", \"Alexa\", and \"ChatGPT\" becoming household names, the pervasive societal impact of AI is clear. Advances in AI promise a revolution in our interaction with the physical world, a domain where computational intelligence has always been envisioned as a transformative force toward a better tomorrow. Depending on the application family, this domain is often referred to as Ubiquitous Computing, Cyber-Physical Computing, or the Internet of Things. The underlying vision is driven by the proliferation of cheap embedded computing hardware that can be integrated easily into myriads of everyday devices from consumer electronics, such as personal wearables and smart household appliances, to city infrastructure and industrial process control systems. One common trait across these applications is that the data that the application operates on come directly (typically via sensors) from the physical world. Thus, from the perspective of communication network infrastructure, the data originate at the network edge. From a performance standpoint, there is an argument to be made that such data should be processed at the point of collection. Hence, a need arises for Edge AI -- a genre of AI where the inference, and sometimes even the training, are performed at the point of need, meaning at the edge where the data originate. The book is broken down into three parts: core problems, distributed problems, and other cross-cutting issues. It explores the challenges arising in Edge AI contexts. Some of these challenges (such as neural network model reduction to fit resource-constrained hardware) are unique to the edge environment. They need a novel category of solutions that do not parallel more typical concerns in mainstream AI. Others are adaptations of mainstream AI challenges to the edge space. An example is overcoming the cost of data labeling. The labeling problem is pervasive, but its solution in the IoT application context is different from other contexts. This book is not a survey of the state of the art. With thousands of publications appearing in AI every year, such a survey is doomed to be incomplete on arrival. It is also not a comprehensive coverage of all the problems in the space of Edge AI. Different applications pose different challenges, and a more comprehensive coverage should be more application specific. Instead, this book covers some of the more endemic challenges across the range of IoT/CPS applications. To offer coverage in some depth, we opt to cover mainly one or a few representative solutions for each of these endemic challenges in sufficient detail, rather that broadly touching on all relevant prior work. The underlying philosophy is one of illustrating by example. The solutions are curated to offer insight into a way of thinking that characterizes Edge AI research and distinguishes its solutions from their more mainstream counterparts.",
        "affiliation_name": "IBM Thomas J. Watson Research Center",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Communication efficient distributed learning",
        "paper_author": "Singh N.",
        "publication": "Artificial Intelligence for Edge Computing",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Communication bottleneck has been identified as a significant issue in large-scale training of machine learning models over a network. Recently, several approaches have been proposed to mitigate this issue, using gradient compression and infrequent communication based techniques. This chapter summarizes two communication efficient algorithms, Qsparse-local-SGD and SQuARM-SGD, for distributed and decentralized settings, respectively. These algorithms utilize composed sparsification and quantization operators for aggressive compression, along with local iteration for communication efficiency. We provide theoretical convergence guarantees for these algorithms for smooth non-convex objectives. We also review extensive numerical experiments of our methods for training ResNet architectures and compare them against the state-of-the-art methods in their respective settings. The content of this chapter is based on the papers: Basu et al. (Qsparse-local-SGD: Distributed SGD with quantization, sparsification and local computations. In: NeurIPS, 2019), Basu et al. (IEEE J Sel Areas Inf Theory 1(1):217-226, 2020), Singh et al. (SPARQ-SGD: Event-triggered and compressed communication in decentralized optimization. In: IEEE Control and Decision Conference (CDC), 2020), Singh et al. (IEEE Trans Autom Control, 2022), Singh et al. (IEEE J Sel Areas Inf Theory 2(3):954-969, 2021).",
        "affiliation_name": "UCLA Samueli School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Joint service placement and request scheduling at the edge",
        "paper_author": "He T.",
        "publication": "Artificial Intelligence for Edge Computing",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "This chapter focuses on the joint allocation of multiple types of resources when trying to run machine learning applications on edge computing platforms. To have the maximum applicability, the machine learning workloads will be simply modeled as demands for various types of resources (storage, communication, computation), and the resource allocation algorithms are designed to optimally satisfy these demands within the limited resource capacities of edge clouds. Different problem formulations differ in terms of the performance objective, the types of resources considered, and the forms of resource constraints, which all originate from the different application scenarios of interest. These differences in turn lead to differences in the problem complexities and the applicable solutions.",
        "affiliation_name": "IBM Thomas J. Watson Research Center",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Out of distribution detection",
        "paper_author": "Lee W.H.",
        "publication": "Artificial Intelligence for Edge Computing",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Deep learning has gained tremendous success in transforming many data mining and machine learning tasks. Popular deep learning techniques are inapplicable to out of distribution detection (OOD) due to some unique characteristics of anomalies. OOD records are rare, heterogeneous, boundless, and prohibitively high costs for collecting large-scale OOD data. OOD records leads to false predictions for AI models. It reduces user confidence in AI products. However, recent studies in OOD detection either assume the existence of OOD records or require the retraining of the model, limiting their application in practice. In this chapter, we introduce NeuralFP (Neuralfp: out-of-distribution detection using fingerprints of neural networks. In: 2020 25th International Conference on Pattern Recognition (ICPR), 2021) for OOD detection without requiring any access to OOD records by constructing non-linear fingerprints of neural network models. The key idea of NeuralFP is to exploit the different behavior in how the neural network model responds to normal data versus OOD data. Specifically, NeuralFP builds autoencoders for each layer of the neural network model and then analyzes the error distribution of the autocoders in reconstructing the training set to identify OOD records. We show the effectiveness of NeuralFP in detecting OOD records as well as its advantages over previous approaches through comprehensive experiments on multiple real-world datasets. For practical adoption of NeuralFP, we provide useful guidelines for parameter selection.",
        "affiliation_name": "IBM Thomas J. Watson Research Center",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Coreset-based data reduction for machine learning at the edge",
        "paper_author": "Lu H.",
        "publication": "Artificial Intelligence for Edge Computing",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "This chapter covers the issue of reducing the communication cost for machine learning at the edge from the perspective of data compression. Unlike traditional data compression schemes that aim at supporting the reconstruction of the original data, here the compression only needs to support the learning of the models that need to be learned from the original data, in order to support AI applications in a bandwidth-limited edge network. This lowered goal opens the door to a variety of application-specific lossy compression schemes designed to support machine learning. The focus in this chapter is on a subset of such schemes that can construct a weighted dataset much smaller than the original dataset that can function as a replacement of the original dataset in learning tasks, known as coreset. It reviews the history of coresets and their limitations, and then details two recently proposed improvements on (1) robust coreset construction and (2) integration of coreset construction and quantization.",
        "affiliation_name": "ByteDance Ltd.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Diffusion of Innovation on Auditor Adoption of Artificial Intelligence and Machine Learning",
        "paper_author": "Handoko B.L.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The industrial revolution (4.0) has seen a rapid advancement in technology. The existence of machine learning and artificial intelligence is one of them. By automating most audit processes with AI, auditors can increase efficiency and accuracy. AI-powered technology reduces human error risk while speeding up the auditing process. The outcome is more timely and accurate information sent to the management. Nonetheless, auditors were still using artificial intelligence and machine learning in very small amounts. Furthermore, specialized research on this subject is still scarce. We wish to investigate this research gap. We study what influences artificial intelligence and machine learning adoption by auditors. Based on Diffusion of Innovation Theory, we employ constructs or variables. Structural equation modeling partial least squares is used in data analysis for our quantitative research. By giving questionnaires to Jakarta public accounting firms' auditors, we can gather primary data. We use the statistical method of partial least squares for structural equation modeling when analyzing data. The software we use is SMART PLS version 4. The findings of our study show that the relative advantage, compatibility, trialability, and observability of each have a big impact on the auditor's adoption of artificial intelligence and machine learning.",
        "affiliation_name": "Bina Nusantara University",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Leveraging rule-based model and machine learning transformer for mining aspect-based financial opinions in colloquial language",
        "paper_author": "Chu C.C.F.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "This paper presents a practical approach to develop an aspect-based opinion mining system for a low-resource language. Our design aims to harness the strengths of rule-based model and transformer-based model to accurately extract fine grained named entity relationship pairs from discussion board messages written in colloquial Cantonese language. The rule-based model provides an effective and low-computational-resource method for identifying candidate pairs while the transformer-based model will further examine the validity of the pairs using natural language inference method with custom-made data modelling structures. The overall system architecture, proposed data modelling structures together with a practical data annotation method are addressed. Our empirical data reflects that most discussion board opinions are expressed with the use of jargon and alias which cannot be handled by using typical lexicon and off-the-shelf pre-trained transformer-based model. The result from our prototype system demonstrates a satisfactory performance for extracting fine grained financial opinions from colloquial Cantonese commentaries.",
        "affiliation_name": "The Hang Seng University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "ICSeB 2023 - 2023 7th International Conference on Software and e-Business",
        "paper_author": "NA",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The proceedings contain 12 papers. The topics discussed include: TRGAN: a time-dependent generative adversarial network for synthetic transactional data generation; a blockchain based decentralized Zakat collection and distribution platform; assessment of the proposed pain management application using SWOT analysis and six thinking hats; diffusion of innovation on auditor adoption of artificial intelligence and machine learning; the impact of social media advertising on Vietnamese students’ online course purchasing decisions: a case study in the Mekong Delta; the influence of risk perception on online shopping decision of consumers: a case study of social media platforms in Vietnam; and study on the influence of shopping experience on the repeat purchase intention of Vietnamese consumers through electronic commerce platforms.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Machine/Deep Learning for obfuscated malware Detection",
        "paper_author": "Abid M.N.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The protection of digital systems and sensitive data has become paramount due to the appearance of new intelligent cybersecurity threats. The landscape of cyber threats is constantly evolving, becoming more sophisticated and diverse by the day. This dynamic environment challenges security measures, demanding constant vigilance and innovation to safeguard against emerging risks. This research represents an advancement in fortifying defenses against obfuscated malware. Its goal is to elevate the accuracy of detecting and classifying these sophisticated threats, bolstering our ability to identify and mitigate their impact effectively. The core objective is to differentiate between harmful and benign memory dumps using various deep/machine learning models. The models are designed to specialize in identifying obfuscated malware, especially malware that skillfully conceals its presence to evade detection and removal, thereby countering a range of threats, including spyware, ransomware, and Trojan horse malware. As a result, we could deploy various types of ML/DL algorithms with more than 85% precision in multiclass overlapping and imbalanced data. In addition, different types of data balancing were exploited, and each technique and its effect on the results were evaluated separately.",
        "affiliation_name": "Université d’Echahid Hamma Lakhdar – El-oued",
        "affiliation_city": "El Oued Province",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "Real-time Analytics in Financial Market Forecasting: A Big Data Approach",
        "paper_author": "Balbaa M.E.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-21",
        "Abstract": "The dynamism and complexity inherent in today's financial markets necessitate sophisticated predictive analytics tools that can facilitate decision-making in real-time. However, traditional forecasting methodologies often fall short in harnessing the vast volumes of real-time data generated by these markets. This study introduces a transformative approach, known as the Real-time Big Data Financial Forecasting Model (<Formula format=\"inline\"><TexMath><?TeX $RBD{F}^{2M}$ ?></TexMath><File name=\"a00 - inline1\"type=\"gif\"/></Formula>), which amalgamates real-time analytics, big data technologies, and machine learning algorithms to predict financial market trends. Through a robust computational architecture that efficiently processes and analyzes high-frequency trading data, the RBDF^2M model aims to provide accurate and timely forecasts of asset price movements. Employing time-series analysis techniques, particularly Autoregressive Integrated Moving Average (ARIMA) and Long Short-Term Memory (LSTM) networks, this model is tested across multiple financial instruments to evaluate its predictive efficacy. Our results indicate a substantial improvement in forecast accuracy compared to conventional methodologies, along with significant reductions in computational latency. The research further explores the implications of these findings, notably the potential for augmented trading strategies and risk management protocols. Finally, the paper discusses the ethical considerations associated with the deployment of such advanced predictive systems in financial markets, arguing for the necessity of regulatory frameworks to mitigate the risks of market manipulation and systemic failure.",
        "affiliation_name": "International Islamic Academy of Uzbekistan",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Developing a Dynamic Decision-Support Framework for Higher Education Management Systems through Real-time Information Extraction",
        "paper_author": "Pantin R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-21",
        "Abstract": "In the changing world of education, it is crucial for institutions to have the ability to make well informed decisions based on data. This paper presents an innovative Decision Support Framework (DDSF), for managing higher education systems. The DDSF utilizes real time information extraction to improve the decision-making process. It combines data analytics and user centric design to provide insights to education administrators. By gathering data from sources like records, financial reports and social media analytics the DDSF uses natural language processing (NLP) and machine learning (ML) algorithms to extract and interpret real time information. This information is then organized in a manner for analysis. The framework is adaptable allowing for the inclusion of emerging data streams ensuring relevance and usefulness. To evaluate the effectiveness of the DDSF we conducted a pilot study at a university. The results indicated improvements in meeting student needs optimizing resource allocation and enhancing operational efficiency. The framework also enables policy development by foreseeing challenges and identifying opportunities, within the education sector. The DDSF brings about a way of managing education by providing a strong platform for institutions to succeed in a competitive and constantly evolving environment. It emphasizes the significance of extracting real time information to guide planning and operational excellence. Future studies will concentrate on expanding the framework, for use, across institutions and incorporating analytics to improve foresight abilities.",
        "affiliation_name": "Tashkent State University of Economics",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "The Future of Bitcoin Price Predictions Integrating Deep Learning and the Hybrid Model Method",
        "paper_author": "Belalova G.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Over the past few decades, recurrent neural networks, particularly the Long Short-Term Memory (LSTM) architecture, have undergone several refinements. These networks have emerged as the go-to models for numerous machine learning challenges, especially those involving sequential data. One such application is the prediction of Bitcoin prices, a cryptocurrency that stands at the forefront of blockchain technology. This paper delves into the intricacies of forecasting Bitcoin prices using a suite of models, with a keen emphasis on the LSTM architecture, renowned for its prowess in handling tasks with long-term dependencies. Our exploration encompasses traditional time series models like ARIMA, neural network variants such as ANN and Transformer-based models, and even hybrid combinations. Specifically, our LSTM model, augmented with peephole connections, demonstrates its capability to learn and predict Bitcoin price fluctuations. We source our data from the Bitcoin Price Index and aim to gauge the accuracy with which these models can predict Bitcoin's price trajectory. Furthermore, our experiments involve the deployment of an \"adam\"-optimized Recurrent Neural Network (RNN) and Long Short-Term Memory (LSTM) network, revealing insights into their predictive performances.",
        "affiliation_name": "Tashkent State University of Economics",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Comparative Analysis of Machine Learning Algorithms for Inflation Rate Classification and Economic Trend Forecasting",
        "paper_author": "Khashimova N.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Predictive modeling of inflation rates is critical for economic policy and risk management. This study compares the efficacy of K-Nearest Neighbors (KNN) and logistic regression algorithms in classifying inflation into 'Low,' 'Medium,' and 'High' categories, which are essential for monitoring and managing economic stability. Through meticulous preprocessing, including outlier removal, normalization, and imputation, the dataset was refined for accurate analysis. The study established inflation thresholds using empirical data and economic theory to create structured categories. The EDA revealed the fluctuating nature of inflation and its long-term trends, providing a clear picture of economic conditions. Logistic regression demonstrated a higher accuracy rate and better performance metrics over KNN, suggesting it as a superior model for inflation classification. The findings emphasize the importance of precise model selection in economic forecasting and propose logistic regression as a robust tool for policy-makers and economists in strategic economic planning.",
        "affiliation_name": "Tashkent State University of Economics",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Machine Learning Algorithms to Detect Illicit Accounts on Ethereum Blockchain",
        "paper_author": "Obi-Okoli C.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The rapid growth and psudonomity inherent in blockchain technology such as in Bitcoin and Ethereum has marred its original intent to reduce dependant on centralised system, but created an avenue for illicit activities, including fraud, phishing, scams, etc. This undermines the reputation of blockchain network, giving rise to the need to identify these illicit activities within the blockchain network. This current work tackles this crucial problem by investigating and implementing six machine learning algorithms with a particular emphasis on striking a balance between accuracy, precision and recall. The novelty of the work lies in the utilising of the synthetic minority over-sampling technique to handle data imbalance. Thus, increasing the accuracy of the light gradient boosting machine classifier to 98.4%. The outcome of this work holds great potential for enhancing the security and credibility of blockchain ecosystems paving the way for a more secure and dependable digital future in the age of decentralised and trustless systems.",
        "affiliation_name": "Manchester Metropolitan University",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Machine Learning for Malware Detection in Network Traffic",
        "paper_author": "Omopintemi A.H.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "5",
        "cover_date": "2023-12-21",
        "Abstract": "Developing advanced and efficient malware detection systems is becoming significant in light of the growing threat landscape in cybersecurity. This work aims to tackle the enduring problem of identifying malware and protecting digital assets from cyber-attacks. Conventional methods frequently prove ineffective in adjusting to the ever-evolving field of harmful activity. As such, novel approaches that improve precision while simultaneously taking into account the ever-changing landscape of modern cybersecurity problems are needed. To address this problem this research focuses on the detection of malware in network traffic. This work proposes a machine-learning-based approach for malware detection, with particular attention to the Random Forest (RF), Support Vector Machine (SVM), and Adaboost algorithms. In this paper, the model's performance was evaluated using an assessment matrix. Included the Accuracy (AC) for overall performance, Precision (PC) for positive predicted values, Recall Score (RS) for genuine positives, and the F1 Score (SC) for a balanced viewpoint. A performance comparison has been performed and the results reveal that the built model utilizing Adaboost has the best performance. The TPR for the three classifiers performs over 97% and the FPR performs < 4% for each of the classifiers. The created model in this paper has the potential to help organizations or experts anticipate and handle malware. The proposed model can be used to make forecasts and provide management solutions in the network's everyday operational activities.",
        "affiliation_name": "Oxford Brookes University",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Quantum Assisted Architectures for Wireless Systems, the Case of Quantum 6G",
        "paper_author": "Mohammed A.A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The development of a quantum-based architecture for wireless systems is required to respond to the growing need for faster and more effective communication. Quantum computing offers a huge promise for improving wireless communication networks due to its ability to perform complex computations and simulations in a fraction of the time compared to classical computing. With a focus on Quantum 6G, this paper examines the foundations of quantum computing, the state of conventional wireless systems, and the potential for quantum-assisted wireless systems. This paper also analyzes future research areas and briefly discusses the newly developing topic of quantum machine learning in the context of 6G. It starts with reviewing Quantum 6G, covering facets like its effectiveness and security. It also explores the challenges and constraints of managing wireless resources with quantum assistance. This study seeks to explore these issues in order to advance knowledge of quantum 6G networks and encourage additional investigation into this exciting area.",
        "affiliation_name": "King Fahd University of Petroleum and Minerals",
        "affiliation_city": "Dhahran",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Parallel Approaches in Deep Learning: Use Parallel Computing",
        "paper_author": "Rakhimov M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "In the present context, the rise of artificial intelligence (AI) has brought to light the importance of expediting processes due to the advancement in AI. This issue holds significance across various domains of machine learning. Consequently, all sectors linked to deep learning, a crucial facet of artificial intelligence, are experiencing continuous advancements. To illustrate, tasks associated with training such as the multiplication of extensive matrices or the manipulation of images to extricate vital features can lead to an increase in time consumption. It is common knowledge that dealing with substantial data quantities demands a considerable amount of time. The primary focus of this research revolves around significantly enhancing the time efficiency of deep learning procedures. While it is a recognized fact that graphics processing units (GPUs) deliver notably quicker outcomes for specific data handling tasks in comparison to a computer's central processing unit (CPU), this study delves into heterogeneous computing systems in cases where GPUs are inaccessible. Herein, we investigate strategies for attaining elevated processing speed through the utilization of advanced technologies. Ultimately, this study culminates by presenting comparative findings derived from di-verse approaches, accompanied by crucial recommendations for future endeavors.",
        "affiliation_name": "Tashkent University of Information Technologies named after Muhammad al-Khwarizmi",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Lung Cancer Prediction Using the Algorithms for Calculating Estimates",
        "paper_author": "Alimkulov N.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Lung cancer has been and remains the leading cause of cancer-related death worldwide. Early detection and diagnosis of lung cancer significantly improves the survival chances of patients, it has been regularly emphasized by researchers. Machine learning algorithms are increasingly used in the medical field to detect lung cancer, but the low interpretability of these models is a significant problem. The article proposes an approach for early detection of lung cancer using machine learning algorithms through the algorithms for calculating estimates. Data from the Kaggle platform was used as a dataset. The developed program achieved 93% accuracy in determining the quality function.",
        "affiliation_name": "Andijan State University",
        "affiliation_city": "Andizhan",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Intelligent Systems Applications in Inclusive Education Management: A Systematic Mapping Study",
        "paper_author": "Akbarova S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Inclusive education management is a crucial field that strives to provide equal access to education for all students, regardless of their background or ability. The recent advancements in intelligent systems and artificial intelligence (AI) technologies have spurred interest in their application in the realm of inclusive education management. In this systematic mapping study, we present a comprehensive overview of the current state-of-the-art in intelligent systems applications for inclusive education management. Our primary contribution is the development of a content taxonomy that categorizes the different types of intelligent systems used in inclusive education management, and the identification of the areas where these systems can make a significant impact. Our rigorous review of the literature included peer-reviewed articles, conference proceedings, and other relevant sources. We found that personalized learning, student support, teacher training, and accessibility are among the areas where intelligent systems can enhance the inclusivity of education management. Our study also revealed that machine learning, natural language processing, and computer vision are the most commonly utilized intelligent systems in this domain. Our findings shed light on the current trends and future directions of intelligent systems applications in inclusive education management, which can inform educators, researchers, and policymakers in their efforts to improve education equity and accessibility.",
        "affiliation_name": "Tashkent State University of Economics",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "A systematic mapping study of leveraging Intelligent Systems Applications in human capital development: In the example of developing professional communicative competence of economics students in English",
        "paper_author": "Jamalova G.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Developing professional communicative competence is vital for economics students, preparing them for effective communication in their future careers. Despite its significance, a research gap exists regarding the use of intelligent systems to enhance this competence in economics students. To fill this gap, this systematic mapping study investigates intelligent systems applications in human capital development, focusing on professional communicative competence development for economics students in English. The study involves a rigorous literature search and screening process, revealing diverse approaches and techniques to harness intelligent systems for human capital development. By synthesizing and analyzing these findings, this paper systematically maps the current landscape of intelligent systems' use in developing professional communicative competence among economics students. The results indicate that intelligent systems applications, including natural language processing, machine learning, and artificial intelligence, offer substantial potential to improve human capital development programs. They provide personalized, adaptive, and interactive learning experiences. Additionally, the study underscores the importance of incorporating pedagogical and instructional design principles when developing intelligent systems applications for human capital development. In summary, this systematic mapping study offers insights and recommendations for researchers, educators, and practitioners interested in leveraging intelligent systems for human capital development, especially in cultivating professional communicative competence among economics students in English. Moreover, it lays the groundwork for future empirical studies assessing the effectiveness of intelligent systems applications in this context.",
        "affiliation_name": "International Islamic Academy of Uzbekistan",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Distributed Deep Learning-based Model for Large Image Data Classification",
        "paper_author": "Nurnoby M.F.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Artificial intelligence has shown great potential in a variety of applications, from natural language models to audio visual recognition, classification, and manipulation. AI Researchers have to work with massive amount of collected data for use in machine learning, raising some challenges in effectively managing and utilizing the collected data in the training phase to develop and iterate on more accurate, and more generalized models. In this paper we conducted a review on parallel and distributed machine learning methods and challenges. We also propose a distributed and scalable deep learning model architecture which can span across multiple processing nodes. We tested the model on the MIT Indoor dataset, to evaluate the performance and scalability of the model using multiple hardware nodes, and showed the scaling characteristics of the different model using different model sizes. We find that distributed training is 80% faster using 2 GPUs than 1 GPU. We also find that the model keeps the benefits of distributed training such as speed and accuracy regardless of its size or training batch size.",
        "affiliation_name": "King Fahd University of Petroleum and Minerals",
        "affiliation_city": "Dhahran",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Categorization of Digital Pathology Image using Deep Learning model",
        "paper_author": "Guia S.S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Computer-aided detection and diagnosis have transformed the medical research landscape, particularly in colorectal carcinoma. This paper introduces a novel approach to address the multi-class challenge in colorectal cancer detection using a fully convolutional network augmented with a pre-trained convolutional neural network and a spatial attention module. Specifically, the proposed model employs ResNet-50 in the contracting path of the fully convolutional network, leading to dimensionality reduction and feature extraction. A unique dimensionality reduction technique utilizing standard deviation is introduced to optimize data representation while managing computational complexity. The model's architectural design involves a carefully curated head part with fourteen layers, including a dropout layer and dense layers with rectified linear units and softmax activation functions for accurate image categorization. The proposed approach demonstrates promising results in addressing the challenges associated with colorectal cancer detection in digital pathology, showcasing the potential of deep learning and attention mechanisms in enhancing classification accuracy.",
        "affiliation_name": "Université d’Echahid Hamma Lakhdar – El-oued",
        "affiliation_city": "El Oued Province",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "Distributed Intrusion Detection Systems Based on Deep Learning Techniques and Boosting Ensemble",
        "paper_author": "Ayub M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "With the rapid advancement in technologies nowadays, new data is constantly and frequently being generated, processed, and stored for various applications. To ease up managing these huge collections of data, distributed systems are utilized. Distributed systems have the ability to be easily scaled and managed from different locations across the globe. One of the drawbacks of large systems is the difficulty faced when attempting to secure them. In this paper, we investigate the use and effects of different Deep Learning (DL) techniques such as CNN, BiGRU+Attention, and LGBM. We made use of two distributed training frameworks for the training of models in a distributed manner. The performance of various techniques is analyzed based on different evaluation criteria using the latest IDS dataset. Experimental results show that the models presented here are robust and efficient enough to detect different kinds of attack types with almost 100% accuracy. However, we observed that when the attack type increase from 3 to 5 the model accuracy drops from 99.9% to 96.34% for LGBM. Performance trade-off between centralized and distributed training is analyzed and observed that the same accuracy can be achieved in DIDS, but with differences in training time. Inferencing time shows very insignificant differences. The results of LGBM show that the duration, port numbers, packet size and number, and TCP flags are the most influential features in DIDS. Furthermore, we have shown the applicability of CNN and BiGRU with attention mechanisms for DIDS, as well as the deployment of two frameworks for distributed machine learning. More than that, LGBM has shown the most superior performance among all models in all types of classification. It is anticipated that this research will act as a guide for further research in DIDS.",
        "affiliation_name": "King Fahd University of Petroleum and Minerals",
        "affiliation_city": "Dhahran",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "The Impact of Artificial Neural Network Architecture on Network Attack Detection",
        "paper_author": "Xoliyarov F.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Artificial Neural Networks (ANNs) have emerged as a powerful tool for network attack detection due to their ability to learn complex patterns and behaviors. The architecture of an ANN plays a critical role in determining its performance and effectiveness in detecting network attacks. This article explores the impact of ANN architecture on network attack detection, highlighting different types of architectures used in the field of cybersecurity. It discusses the advantages and disadvantages of these architectures, along with the challenges associated with their usage. By understanding the significance of ANN architecture, security professionals can make informed decisions to enhance network defense mechanisms and protect against evolving cyber threats.",
        "affiliation_name": "Tashkent University of Information Technologies named after Muhammad al-Khwarizmi",
        "affiliation_city": "Tashkent",
        "affiliation_country": "Uzbekistan"
    },
    {
        "paper_title": "Machine learning in medicine-focus on radiology",
        "paper_author": "Lian J.",
        "publication": "Machine Learning, Medical AI and Robotics: Translating Theory into the Clinic",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "NA",
        "affiliation_name": "The University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Machine learning: Applications in ophthalmology",
        "paper_author": "Chau C.Y.C.",
        "publication": "Machine Learning, Medical AI and Robotics: Translating Theory into the Clinic",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "NA",
        "affiliation_name": "Prince of Wales Hospital Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Machine learning, medical AI and robotics: Translating theory into the clinic",
        "paper_author": "Vardhanabhuti V.",
        "publication": "Machine Learning, Medical AI and Robotics: Translating Theory into the Clinic",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "This book explores the latest breakthroughs in medical technology, focusing specifically on artificial intelligence (AI) and robotics. It reveals how these advancements are transforming the healthcare landscape and reshaping the future of medicine. The goal of this book is to provide a multidisciplinary perspective from experts in various medical subspecialties, examining the current and potential applications of medical AI and robotics. The authors guide readers through cutting-edge research and real-world examples, showcasing how AI is revolutionizing disease diagnosis, drug discovery, personalized treatment plans, and prevention. It also discusses emerging technologies such as wearables and highlights the emergence of medical robots that assist in complex surgeries and provide patient care.",
        "affiliation_name": "Chinese University of Hong Kong, Faculty of Medicine",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Deep learning approaches for affective computing in text",
        "paper_author": "Cabada R.Z.",
        "publication": "Advanced Applications of Generative AI and Natural Language Processing Models",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The field of natural language processing (NLP) is one of the first to be addressed since artificial intelligence emerged. NLP has made remarkable advances in recent years thanks to the development of new machine learning techniques, particularly novel deep learning methods such as LSTM networks and transformers. This chapter presents an overview of how deep learning techniques have been applied to NLP in the area of affective computing. The chapter examines traditional and novel deep learning architectures developed for natural language processing (NLP) tasks. These architectures comprise recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and the cutting-edge transformers. Moreover, a methodology for NLP method training and fine-tuning is presented. The chapter also integrates Python code that demonstrates two NLP case studies specializing in the educational domain for text classification and sentiment analysis. In both cases, the transformer-based machine learning model (BERT) produced the best results.",
        "affiliation_name": "Tecnológico Nacional de México",
        "affiliation_city": "Mexico City",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Advanced applications of generative AI and natural language processing models",
        "paper_author": "Obaid A.J.",
        "publication": "Advanced Applications of Generative AI and Natural Language Processing Models",
        "citied_by": "29",
        "cover_date": "2023-12-21",
        "Abstract": "The rapid advancement of technology in Artificial Intelligence (AI), specifically in Natural Language Processing (NLP) and generative AI, presents a challenge for academic scholars to remain informed with the most current information and with the latest techniques and applications. The lack of comprehensive resources also hinders researchers' ability to gain a deep understanding of these subjects and effectively implement these technologies. Advanced Applications of Generative AI and Natural Language Processing Models is a comprehensive resource which offers an effective solution by investigating cutting-edge developments in NLP and generative AI. It provides insights into how these technologies function, their benefits, and the associated challenges. This book serves as a vital reference for deepening knowledge of advanced NLP techniques and staying updated on the latest advancements in generative AI for students, researchers, and professionals in AI, NLP, and computer science. It uses real-world examples and practical applications to empower scholars to apply their knowledge and solve complex problems. Advanced Applications of Generative AI and Natural Language Processing Models is a complete guide that equips researchers with the knowledge needed to utilize NLP and generative AI, including deep learning for NLP, generative models for text generation, language modeling and sentiment analysis, machine translation and multilingual models, ethical considerations in NLP, conversational AI applications, and case studies and real-world applications.",
        "affiliation_name": "Dhaanish Ahmed College of Engineering",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Fine-grained independent approach for workout classification using integrated metric transfer learning",
        "paper_author": "Bose S.R.",
        "publication": "Advanced Applications of Generative AI and Natural Language Processing Models",
        "citied_by": "27",
        "cover_date": "2023-12-21",
        "Abstract": "Physical activity helps manage weight and stay healthy. It becomes more critical during a pandemic since outside activities are restricted. Using tiny wearable sensors and cutting-edge machine intelligence to track physical activity can help fight obesity. This study introduces machine learning and wearable sensor methods to track physical activity. Daily physical activities are typically unstructured and unplanned, and sitting or standing may be more common than others (walking stairs upstairs down). No activity categorization system has examined how class imbalance affects machine learning classifier performance. Fitness can boost cardiovascular capacity, focus, obesity prevention, and life expectancy. Dumbbells, yoga mats, and horizontal bars are used for home fitness. Home gym-goers utilise social media to learn fitness, but its effectiveness is limited.",
        "affiliation_name": "Dhaanish Ahmed College of Engineering",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The synergy of management information systems and predictive analytics for marketing",
        "paper_author": "Dominic M.L.",
        "publication": "Data-Driven Decision Making for Long-Term Business Success",
        "citied_by": "15",
        "cover_date": "2023-12-21",
        "Abstract": "In the ever-evolving landscape of modern marketing, the convergence of management information systems (MIS) and predictive analytics has become a potent force. This chapter explores the transformative potential of combining MIS infrastructure with predictive analytics techniques to reshape marketing management. Predictive analytics, utilizing historical data and machine learning, empowers organizations to forecast future trends, customer behavior, and market dynamics. MIS, as the information backbone, facilitates the collection, processing, and dissemination of data for strategic decision-making. Marketing, once reliant on intuition, has transitioned into a data-driven discipline. This synergy enables businesses to not only understand past performance but also anticipate and respond to the dynamic demands of the marketplace. However, seizing this opportunity is not without challenges. Success hinges on the alignment of techni¬cal capabilities, organizational structure, and strategic vision with the digital landscape's evolution.",
        "affiliation_name": "Dhaanish Ahmed College of Engineering",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Predicting Effects of a Digital Stress Intervention for Patients With Depressive Symptoms: Development and Validation of Meta-Analytic Prognostic Models Using Individual Participant Data",
        "paper_author": "Harrer M.",
        "publication": "Journal of Consulting and Clinical Psychology",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Objective: Digital stress interventions could be helpful as an “indirect” treatment for depression, but it remains unclear for whomthis is a viable option. In this study, we developed models predicting individualized benefits of a digital stress intervention on depressive symptoms at 6-month follow-up. Method: Data of N = 1,525 patients with depressive symptoms (Center for Epidemiological Studies’ Depression Scale, CES-D ≥ 16) from k = 6 randomized trials (digital stress intervention vs. waitlist) were collected. Prognostic models were developed using multilevel least absolute shrinkage and selection operator and boosting algorithms, and were validated using bootstrap bias correction and internal–external cross-validation. Subsequently, expected effects among those with and without a treatment recommendation were estimated based on clinically derived treatment assignment cut points. Results: Performances ranged from R2 = 21.0%–23.4%, decreasing only slightly after model optimism correction (R2 = 17.0%–19.6%). Predictions were greatly improved by including an interim assessment of depressive symptoms (optimism-corrected R2 = 32.6%–35.6%). Using a minimally important difference of d = −0.24 as assignment cut point, approximately 84.6%–93.3%of patients are helped by this type of intervention, while the remaining 6.7%–15.4% would experience clinically negligible benefits (δˆ = −0.02 to −0.19). Using reliable change as cut point, a smaller subset (39.3%–46.2%) with substantial expected benefits (δˆ = −0.68) receives a treatment recommendation. Conclusions: Metaanalytic prognostic models applied to individual participant data can be used to predict differential benefits of a digital stress intervention as an indirect treatment for depression. While most patients seem to benefit, the developed models could be helpful as a screening tool to identify those for whom a more intensive depression treatment is needed.",
        "affiliation_name": "Leuphana Universität Lüneburg",
        "affiliation_city": "Luneburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A Prognostic Index to Predict Symptom and Functional Outcomes of a Coached, Web-Based Intervention for Trauma-Exposed Veterans",
        "paper_author": "Hallenbeck H.W.",
        "publication": "Psychological Services",
        "citied_by": "1",
        "cover_date": "2023-12-21",
        "Abstract": "Researchers at the Department of Veterans Affairs (VA) have studied interventions for posttraumatic stress disorder and co-occurring conditions in both traditional and digital formats. One such empirically supported intervention is web skills training in affective and interpersonal regulation (webSTAIR), a coached, 10-module web program based on STAIR. To understand which patient characteristics were predictive of webSTAIR outcomes in a sample of trauma-exposed veterans (N = 189), we used machine learning (ML) to develop a prognostic index from among 18 baseline characteristics (i.e., demographic, military, trauma history, and clinical) to predict posttreatment posttraumatic stress disorder severity, depression severity, and psychosocial functioning impairment. We compared the ML models to a benchmark of linear regression models in which the only predictor was the baseline severity score of the outcome measure. The ML and “severity-only” models performed similarly, explaining 39%–45% of the variance in outcomes. This suggests that baseline symptom severity and functioning are strong indicators for webSTAIR outcomes in veterans, with higher severity indicating worse prognosis, and that the other variables examined did not contribute significant added predictive signal. Findings also highlight the importance of comparing ML models to an appropriate benchmark. Future research with larger samples could potentially detect smaller patient-level effects as well as effects driven by other types of variables (e.g., therapeutic process variables). As a transdiagnostic, digital intervention, webSTAIR can potentially serve a diverse veteran population with varying trauma histories and may be best conceptualized as a beneficial first step of a stepped care model for those with heightened symptoms or impairment.",
        "affiliation_name": "College of Science",
        "affiliation_city": "Tucson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "VEVCC program for concatenation of volcanic events based on cross-correlation analysis",
        "paper_author": "Dairoh D.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Volcanic eruptions pose a significant risk to communities located near active volcanoes. Disaster mitigation and risk reduction efforts rely on detecting and monitoring volcanic activity as early as possible. This article introduces VEVCC, a MATLAB-based application designed to precisely identify and extract volcanic seismic events from continuous data streams. VEVCC's primary objective is to facilitate the creation of an Excel file containing the arrival times of detected events, which can then be used for various purposes, such as early warning disaster mitigation and automated event identification via machine learning techniques. VEVCC utilizes cross-correlation algorithms to identify volcanic seismic events. It separates these events from background noise and other sources of seismicity, allowing for the construction of a clean and informative dataset. The extracted data is a valuable resource for estimating the frequency of volcanic events and evaluating patterns of volcanic activity. VEVCC's time-stamped event data is indispensable for improving early warning systems, real-time surveillance, and automated event identification. We tested the program on the Merapi volcano datasets during a 1998 campaign for a broadband experiment with the capability to extract the events automatically. Further machine-learning models and algorithms enhance the automatic recognition of volcanic events.",
        "affiliation_name": "Universitas Gadjah Mada",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Assessment of the energy systems resilience using artificial intelligence methods",
        "paper_author": "Massel L.",
        "publication": "E3S Web of Conferences",
        "citied_by": "5",
        "cover_date": "2023-12-21",
        "Abstract": "Recently, in Western Europe, a direction defined by the term \"Resilience\" has been of great interest. Issues of energy and environmental security are of great importance in resilience research the article discusses an approach to assessing the resilience of energy systems within the framework of the concept of situational management. It is proposed to use artificial intelligence methods: semantic (cognitive) modeling and machine learning the choice of LSTM as a machine learning model is justified. A method for qualitative and quantitative assessment of the resilience of energy systems has been developed. An example of this method application o assess the resilience of the electric power system of the Siberian Federal District (Russia) in low-water conditions at the Angara-Yenisei cascade of hydroelectric power stations is given.",
        "affiliation_name": "Melentiev Energy Systems Institute of Siberian Branch of the Russian Academy of Sciences",
        "affiliation_city": "Irkutsk",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Unveiling Key Predictors for Early Heart Attack Detection using Machine Learning and Explainable AI Technique with LIME",
        "paper_author": "Paudel P.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "6",
        "cover_date": "2023-12-21",
        "Abstract": "The prominence of cardiovascular diseases, particularly heart attacks, as a leading cause of global mortality is highlighted, with an increasing number of deaths attributed to cardiovascular diseases over the years. Amidst these challenges, artificial intelligence (AI) and machine learning (ML) technologies emerge as powerful tools in healthcare. This study conducts a comparative analysis of predictive features extracted from diverse classification algorithms, including AdaBoost Classifier (ABC), Random Forest (RF), Gradient Boosting Classifier(GBC) and Light Gradient-Boosting Machine (LGBM), aiming to identify common patterns in predictive outcomes. LGBM emerges as the standout performer among classification algorithms, boasting a remarkable average training accuracy of 99.33%. Results demonstrate comparable precision, recall, and F1 scores among RF, GB, and LGBM, while ABC lags behind. The study reveals from eXplainable AI technique that consistent attribution of importance to attributes like \"kcm\"and \"troponin\"across all methods for classifying \"Attack\"instances, indicating their pivotal role in prediction. The research underscores the potential clinical application of machine learning for heart attack diagnosis and suggests the adoption of various deep learning techniques to enhance predictive performance.",
        "affiliation_name": "Institute of Engineering Pulchowk",
        "affiliation_city": "Kathmandu",
        "affiliation_country": "Nepal"
    },
    {
        "paper_title": "Strategic Placement of Intrusion Detection Systems in IoT Mesh Networks through Machine Learning",
        "paper_author": "Perala S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The usage of Bluetooth Low Energy (BLE) mesh networks in Internet of Things (IoT) applications, such as healthcare gives it several advantages such as resilience to network disrupts and better coverage. However, mesh networks are prone to complex attacks, comprising multiple individual attacks like Denial of Service (DoS), Man-in-the-Middle (MitM) and so on. These are referred to as multi-stage attacks that can drastically deteriorate the network's performance. The need to detect such attacks has been well investigated and several Intrusion Detection Systems (IDS) for detecting and mitigating attacks in mesh networks have been developed. However, the deployment of IDS for monitoring intrusions is costly in terms of computations and the power required. Hence, achieving the maximum probability of intrusion detection through strategic placement for a given limited number of IDS is the challenge. In this paper, Machine Learning (ML)-based analysis is proposed to determine the suitable positions for the IDS on relay nodes of the BLE mesh network. In comparison to the graph theoretical methodology proposed in the prior art, the approach discussed in this paper considers practical aspects, such as the network topology, underlying routing protocol, routing path of the application and variation in the traffic metrics with and without attack.",
        "affiliation_name": "IIIT Bangalore",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Chemometric sensing of stereoisomeric compound mixtures with a redox-responsive optical probe",
        "paper_author": "Formen J.S.S.K.",
        "publication": "Chemical Science",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The analysis of mixtures of chiral compounds is a common task in academic and industrial laboratories typically achieved by laborious and time-consuming physical separation of the individual stereoisomers to allow interference-free quantification, for example using chiral chromatography coupled with UV detection. Current practice thus impedes high-throughput and slows down progress in countless chiral compound development projects. Here we describe a chemometric solution to this problem using a redox-responsive naphthoquinone that enables chromatography-free click chemistry sensing of challenging mixtures. The achiral probe covalently binds amino alcohols within a few minutes at room temperature and generates characteristic UVA and CDA spectra that are intentionally altered via sodium borohydride reduction to provide a second, strikingly different chiroptical data set (UVB and CDB). Chemometric partial least squares processing of the chiroptical outputs then enables spectral deconvolution and accurate determination of individual analyte concentrations. The success of this approach is demonstrated with 35 samples covering considerably varied total analyte amounts and stereoisomeric ratios. All chemicals and machine learning algorithms are readily available and can be immediately adapted by any laboratory.",
        "affiliation_name": "Georgetown University",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Recognizing Entity Types via Properties",
        "paper_author": "Shi D.",
        "publication": "Frontiers in Artificial Intelligence and Applications",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "The mainstream approach to the development of ontologies is merging ontologies encoding different information, where one of the major difficulties is that the heterogeneity motivates the ontology merging but also limits high-quality merging performance. Thus, the entity type (etype) recognition task is proposed to deal with such heterogeneity, aiming to infer the class of entities and etypes by exploiting the information encoded in ontologies. In this paper, we introduce a property-based approach that allows recognizing etypes on the basis of the properties used to define them. From an epistemological point of view, it is in fact properties that characterize entities and etypes, and this definition is independent of the specific labels and hierarchical schemas used to define them. The main contribution consists of a set of property-based metrics for measuring the contextual similarity between etypes and entities, and a machine learning-based etype recognition algorithm exploiting the proposed similarity metrics. Compared with the state-of-the-art, the experimental results show the validity of the similarity metrics and the superiority of the proposed etype recognition algorithm.",
        "affiliation_name": "Università di Trento",
        "affiliation_city": "Trento",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Data Efficient and Stability Indicated Sampling for Developing Reactive Machine Learning Potential to Achieve Ultralong Simulation in Lithium-Metal Batteries",
        "paper_author": "Xu L.",
        "publication": "Journal of Physical Chemistry C",
        "citied_by": "2",
        "cover_date": "2023-12-21",
        "Abstract": "Modeling the formation of the solid-liquid interphase (SEI) is challenging due to its strict requirements of both simulation accuracy and length. Machine learning potential (MLP)-based molecular dynamics (MD) simulation is expected to play a role in this field, while currently its use is hindered by sampling efficiency and simulation stability. In this work, we tackle these two challenges together. We propose the stability-indicated sampling (SIS) algorithm for efficiently sampling training data using physical information (temperature). Unlike previous strategies, our method does not need prior knowledge of reaction networks or training multiple MLPs for uncertainty estimation. Our approach shows superior sampling efficiency without requirements of the diversity of initial training data, to realize >10 ns MLPMD simulation using an ab initio MD (AIMD) trajectory of just a few ps. We introduce the concept underlying instability consistency by showing the accuracy of reaction mechanisms, and the radial distribution function (RDF) can be improved by SIS-MLPMD, although their information is not explicitly used in our sampling decision. Furthermore, we show that long-time MLPMD simulation of lithium-metal batteries (LMB) can reproduce not only some well-known SEI components, including LiF, Li2O, LiOH, LiS, and incomplete N-S bond breaking in high-concentration systems, but also ionic aggregation structures of LiF, which is not shown in our AIMD training data but matches previous experimental results. Our work is expected to help accelerate future investigations, especially for efficient sampling fine-tuning data for pretrained MLPs and for studying long-time (≥ns scale) reaction dynamics in interfacial problems.",
        "affiliation_name": "Samsung Research",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Wearable Biosensing to Predict Imminent Aggressive Behavior in Psychiatric Inpatient Youths with Autism",
        "paper_author": "Imbiriba T.",
        "publication": "JAMA Network Open",
        "citied_by": "3",
        "cover_date": "2023-12-21",
        "Abstract": "Importance: Aggressive behavior is a prevalent and challenging issue in individuals with autism. Objective: To investigate whether changes in peripheral physiology recorded by a wearable biosensor and machine learning can be used to predict imminent aggressive behavior before it occurs in inpatient youths with autism. Design, Setting, and Participants: This noninterventional prognostic study used data collected from March 2019 to March 2020 from 4 primary care psychiatric inpatient hospitals. Enrolled participants were 86 psychiatric inpatients with confirmed diagnoses of autism exhibiting operationally defined self-injurious behavior, emotion dysregulation, or aggression toward others; 16 individuals were not included (18.6%) because they would not wear the biosensor (8 individuals) or were discharged before an observation could be made (8 individuals). Data were analyzed from March 2020 through October 2023. Main Outcomes and Measures: Research staff performed live behavioral coding of aggressive behavior while inpatient study participants wore a commercially available biosensor that recorded peripheral physiological signals (cardiovascular activity, electrodermal activity, and motion). Logistic regression, support vector machines, neural networks, and domain adaptation were used to analyze time-series features extracted from biosensor data. Area under the receiver operating characteristic curve (AUROC) values were used to evaluate the performance of population- and person-dependent models. Results: There were 70 study participants (mean [range; SD] age, 11.9 [5-19; 3.5] years; 62 males [88.6%]; 1 Asian [1.4%], 5 Black [7.1%], 1 Native Hawaiian or Other Pacific Islander [1.4%], and 63 White [90.0%]; 5 Hispanic [7.5%] and 62 non-Hispanic [92.5%] among 67 individuals with ethnicity data). Nearly half of the population (32 individuals [45.7%]) was minimally verbal, and 30 individuals (42.8%) had an intellectual disability. Participant length of inpatient hospital stay ranged from 8 to 201 days, and the mean (SD) length was 37.28 (33.95) days. A total of 429 naturalistic observational coding sessions were recorded, totaling 497 hours, wherein 6665 aggressive behaviors were documented, including self-injury (3983 behaviors [59.8%]), emotion dysregulation (2063 behaviors [31.0%]), and aggression toward others (619 behaviors [9.3%]). Logistic regression was the best-performing overall classifier across all experiments; for example, it predicted aggressive behavior 3 minutes before onset with a mean AUROC of 0.80 (95% CI, 0.79-0.81). Conclusions and Relevance: This study replicated and extended previous findings suggesting that machine learning analyses of preceding changes in peripheral physiology may be used to predict imminent aggressive behaviors before they occur in inpatient youths with autism. Further research will explore clinical implications and the potential for personalized interventions..",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Automatic cell-type harmonization and integration across Human Cell Atlas datasets",
        "paper_author": "Xu C.",
        "publication": "Cell",
        "citied_by": "33",
        "cover_date": "2023-12-21",
        "Abstract": "Harmonizing cell types across the single-cell community and assembling them into a common framework is central to building a standardized Human Cell Atlas. Here, we present CellHint, a predictive clustering tree-based tool to resolve cell-type differences in annotation resolution and technical biases across datasets. CellHint accurately quantifies cell-cell transcriptomic similarities and places cell types into a relationship graph that hierarchically defines shared and unique cell subtypes. Application to multiple immune datasets recapitulates expert-curated annotations. CellHint also reveals underexplored relationships between healthy and diseased lung cell states in eight diseases. Furthermore, we present a workflow for fast cross-dataset integration guided by harmonized cell types and cell hierarchy, which uncovers underappreciated cell types in adult human hippocampus. Finally, we apply CellHint to 12 tissues from 38 datasets, providing a deeply curated cross-tissue database with ∼3.7 million cells and various machine learning models for automatic cell annotation across human tissues.",
        "affiliation_name": "Department of Physics",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Should scientists delegate their writing to ChatGPT?",
        "paper_author": "Basgier C.",
        "publication": "Nature",
        "citied_by": "6",
        "cover_date": "2023-12-21",
        "Abstract": "Letter to the Editor.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Moiré synaptic transistor with room-temperature neuromorphic functionality",
        "paper_author": "Yan X.",
        "publication": "Nature",
        "citied_by": "39",
        "cover_date": "2023-12-21",
        "Abstract": "Moiré quantum materials host exotic electronic phenomena through enhanced internal Coulomb interactions in twisted two-dimensional heterostructures 1–4. When combined with the exceptionally high electrostatic control in atomically thin materials 5–8, moiré heterostructures have the potential to enable next-generation electronic devices with unprecedented functionality. However, despite extensive exploration, moiré electronic phenomena have thus far been limited to impractically low cryogenic temperatures 9–14, thus precluding real-world applications of moiré quantum materials. Here we report the experimental realization and room-temperature operation of a low-power (20 pW) moiré synaptic transistor based on an asymmetric bilayer graphene/hexagonal boron nitride moiré heterostructure. The asymmetric moiré potential gives rise to robust electronic ratchet states, which enable hysteretic, non-volatile injection of charge carriers that control the conductance of the device. The asymmetric gating in dual-gated moiré heterostructures realizes diverse biorealistic neuromorphic functionalities, such as reconfigurable synaptic responses, spatiotemporal-based tempotrons and Bienenstock–Cooper–Munro input-specific adaptation. In this manner, the moiré synaptic transistor enables efficient compute-in-memory designs and edge hardware accelerators for artificial intelligence and machine learning.",
        "affiliation_name": "Robert R. McCormick School of Engineering and Applied Science",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mentor–trainee dialogue on proper use of AI tools",
        "paper_author": "Yoshida K.",
        "publication": "Nature",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Machine learning of kinetic energy densities with target and feature smoothing: Better results with fewer training data",
        "paper_author": "Manzhos S.",
        "publication": "Journal of Chemical Physics",
        "citied_by": "5",
        "cover_date": "2023-12-21",
        "Abstract": "Machine learning (ML) of kinetic energy functionals (KEFs), in particular kinetic energy density (KED) functionals, is a promising way to construct KEFs for orbital-free density functional theory (DFT). Neural networks and kernel methods including Gaussian process regression (GPR) have been used to learn Kohn-Sham (KS) KED from density-based descriptors derived from KS DFT calculations. The descriptors are typically expressed as functions of different powers and derivatives of the electron density. This can generate large and extremely unevenly distributed datasets, which complicates effective application of ML techniques. Very uneven data distributions require many training datapoints, can cause overfitting, and can ultimately lower the quality of an ML KED model. We show that one can produce more accurate ML models from fewer data by working with smoothed density-dependent variables and KED. Smoothing palliates the issue of very uneven data distributions and associated difficulties of sampling while retaining enough spatial structure necessary for working within the paradigm of KEDF. We use GPR as a function of smoothed terms of the fourth order gradient expansion and KS effective potential and obtain accurate and stable (with respect to different random choices of training points) kinetic energy models for Al, Mg, and Si simultaneously from as few as 2000 samples (about 0.3% of the total KS DFT data). In particular, accuracies on the order of 1% in a measure of the quality of energy-volume dependence B ′ = E V 0 − Δ V − 2 E V 0 + E ( V 0 + Δ V ) Δ V / V 0 2 (where V0 is the equilibrium volume and ΔV is a deviation from it) are obtained simultaneously for all three materials.",
        "affiliation_name": "Institute of Science Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "What was the Turing test actually about?",
        "paper_author": "Gonçalves B.",
        "publication": "Nature",
        "citied_by": "1",
        "cover_date": "2023-12-21",
        "Abstract": "Letter to the Editor.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "GPT-Assisted Learning of Structure-Property Relationships by Graph Neural Networks: Application to Rare-Earth-Doped Phosphors",
        "paper_author": "Zhang X.",
        "publication": "Journal of Physical Chemistry Letters",
        "citied_by": "4",
        "cover_date": "2023-12-21",
        "Abstract": "Two challenges facing machine learning tasks in materials science are data set construction and descriptor design. Graph neural networks circumvent the need for empirical descriptors by encoding geometric information in graphs. Large language models have shown promise for database construction via text extraction. Here, we apply OpenAI’s Generative Pre-trained Transformer 4 (GPT-4) and the Crystal Graph Convolutional Neural Network (CGCNN) to the problem of discovering rare-earth-doped phosphors for solid-state lighting. We used GPT-4 to datamine the chemical formulas and emission wavelengths of 264 Eu2+-doped phosphors from 274 articles. A CGCNN model was trained on the acquired data set, achieving a test R2 of 0.77. Using this model, we predicted the emission wavelengths of over 40 000 inorganic materials. We also used transfer learning to fine-tune a bandgap-predicting CGCNN model for emission wavelength prediction. The workflow requires minimal human supervision and is generalizable to other fields.",
        "affiliation_name": "Shanghai Institute of Ceramics, Chinese Academy of Sciences",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Enhancing Opioid Bioactivity Predictions through Integration of Ligand-Based and Structure-Based Drug Discovery Strategies with Transfer and Deep Learning Techniques",
        "paper_author": "Provasi D.",
        "publication": "Journal of Physical Chemistry B",
        "citied_by": "6",
        "cover_date": "2023-12-21",
        "Abstract": "The opioid epidemic has cast a shadow over public health, necessitating immediate action to address its devastating consequences. To effectively combat this crisis, it is crucial to discover better opioid drugs with reduced addiction potential. Artificial intelligence-based and other machine learning tools, particularly deep learning models, have garnered significant attention in recent years for their potential to advance drug discovery. However, using these tools poses challenges, especially when training samples are insufficient to achieve adequate prediction performance. In this study, we investigate the effectiveness of transfer learning in building robust deep learning models to enhance ligand bioactivity prediction for each individual opioid receptor (OR) subtype. This is achieved by leveraging knowledge obtained from pretraining a model using supervised learning on a larger data set of bioactivity data combined with ligand-based and structure-based molecular descriptors related to the entire OR subfamily. Our studies hold the potential to advance opioid research by enabling the rapid identification of novel chemical probes with specific bioactivities, which can aid in the study of receptor function and contribute to the future development of improved opioid therapeutics.",
        "affiliation_name": "Icahn School of Medicine at Mount Sinai",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Adaptive Sampling Methods for Molecular Dynamics in the Era of Machine Learning",
        "paper_author": "Kleiman D.E.",
        "publication": "Journal of Physical Chemistry B",
        "citied_by": "10",
        "cover_date": "2023-12-21",
        "Abstract": "Molecular dynamics (MD) simulations are fundamental computational tools for the study of proteins and their free energy landscapes. However, sampling protein conformational changes through MD simulations is challenging due to the relatively long time scales of these processes. Many enhanced sampling approaches have emerged to tackle this problem, including biased sampling and path-sampling methods. In this Perspective, we focus on adaptive sampling algorithms. These techniques differ from other approaches because the thermodynamic ensemble is preserved and the sampling is enhanced solely by restarting MD trajectories at particularly chosen seeds rather than introducing biasing forces. We begin our treatment with an overview of theoretically transparent methods, where we discuss principles and guidelines for adaptive sampling. Then, we present a brief summary of select methods that have been applied to realistic systems in the past. Finally, we discuss recent advances in adaptive sampling methodology powered by deep learning techniques, as well as their shortcomings.",
        "affiliation_name": "The Grainger College of Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Interatomic Potentials for Reactive Hydrogen Dynamics at Metal Surfaces Based on Iterative Refinement of Reaction Probabilities",
        "paper_author": "Stark W.G.",
        "publication": "Journal of Physical Chemistry C",
        "citied_by": "12",
        "cover_date": "2023-12-21",
        "Abstract": "The reactive chemistry of molecular hydrogen at surfaces, notably dissociative sticking and hydrogen evolution, plays a crucial role in energy storage and fuel cells. Theoretical studies can help to decipher underlying mechanisms and reaction design, but studying dynamics at surfaces is computationally challenging due to the complex electronic structure at interfaces and the high sensitivity of dynamics to reaction barriers. In addition, ab initio molecular dynamics, based on density functional theory, is too computationally demanding to accurately predict reactive sticking or desorption probabilities, as it requires averaging over tens of thousands of initial conditions. High-dimensional machine learning-based interatomic potentials are starting to be more commonly used in gas-surface dynamics, yet robust approaches to generate reliable training data and assess how model uncertainty affects the prediction of dynamic observables are not well established. Here, we employ ensemble learning to adaptively generate training data while assessing model performance with full uncertainty quantification (UQ) for reaction probabilities of hydrogen scattering on different copper facets. We use this approach to investigate the performance of two message-passing neural networks, SchNet and PaiNN. Ensemble-based UQ and iterative refinement allow us to expose the shortcomings of the invariant pairwise-distance-based feature representation in the SchNet model for gas-surface dynamics.",
        "affiliation_name": "Faculty of Science, Engineering and Medicine",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Accelerated Scheme to Predict Ring-Opening Polymerization Enthalpy: Simulation-Experimental Data Fusion and Multitask Machine Learning",
        "paper_author": "Toland A.",
        "publication": "Journal of Physical Chemistry A",
        "citied_by": "9",
        "cover_date": "2023-12-21",
        "Abstract": "Ring-opening enthalpy (ΔHROP) is a fundamental thermodynamic quantity controlling the polymerization and depolymerization of an important class of recyclable polymers, namely, those created from ring-opening polymerization (ROP). Highly accurate first-principles-based computational methods to compute ΔHROP are computationally too demanding to efficiently guide the design of depolymerizable polymers. In this work, we develop a generalizable machine-learning model that was trained on experimental measurements and reliably computed simulation results of ΔHROP (the latter provides a pathway to systematically increase the chemical diversity of the data). Predictions of ΔHROP using this machine-learning model require essentially no time while the prediction accuracy is about ∼8 kJ/mol, approaching the well-known chemical accuracy. We hope that this effort will contribute to the future development of new depolymerizable polymers.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Uncertainty-guided cross learning via CNN and transformer for semi-supervised honeycomb lung lesion segmentation",
        "paper_author": "Yun-Yun D.",
        "publication": "Physics in Medicine and Biology",
        "citied_by": "3",
        "cover_date": "2023-12-21",
        "Abstract": "Objective. Deep learning networks such as convolutional neural networks (CNN) and Transformer have shown excellent performance on the task of medical image segmentation, however, the usual problem with medical images is the lack of large-scale, high-quality pixel-level annotations, which is a very time-consuming and laborious task, and its further leads to compromised the performance of medical image segmentation under limited annotation conditions. Approach. In this paper, we propose a new semi-supervised learning method, uncertainty-guided cross learning, which uses a limited number of annotated samples along with a large number of unlabeled images to train the network. Specifically, we use two networks with different learning paradigms, CNN and Transformer, for cross learning, and use the prediction of one of them as a pseudo label to supervise the other, so that they can learn from each other, fully extract the local and global features of the images, and combine explicit and implicit consistency regularization constraints with pseudo label methods. On the other hand, we use epistemic uncertainty as a guiding message to encourage the model to learn high-certainty pixel information in high-confidence regions, and minimize the impact of erroneous pseudo labels on the overall learning process to improve the performance of semi-supervised segmentation methods. Main results. We conducted honeycomb lung lesion segmentation experiments using a honeycomb lung CT image dataset, and designed several sets of comparison experiments and ablation experiments to validate the effectiveness of our method. The final experimental results show that the Dice coefficient of our proposed method reaches 88.49% on the test set, and our method achieves state-of-the-art performance in honeycomb lung lesion segmentation compared to other semi-supervised learning methods. Significance. Our proposed method can effectively improve the accuracy of segmentation of honeycomb lung lesions, which provides an important reference for physicians in the diagnosis and treatment of this disease.",
        "affiliation_name": "Shaanxi Provincial People's Hospital",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Semi-supervised contrast learning-based segmentation of choroidal vessel in optical coherence tomography images",
        "paper_author": "Liu X.",
        "publication": "Physics in Medicine and Biology",
        "citied_by": "2",
        "cover_date": "2023-12-21",
        "Abstract": "Objective. Choroidal vessels account for 85% of all blood vessels in the eye, and the accurate segmentation of choroidal vessels from optical coherence tomography (OCT) images provides important support for the quantitative analysis of choroid-related diseases and the development of treatment plans. Although deep learning-based methods have great potential for segmentation, these methods rely on large amounts of well-labeled data, and the data collection process is both time-consuming and laborious. Approach. In this paper, we propose a novel asymmetric semi-supervised segmentation framework called SSCR, based on a student-teacher model, to segment choroidal vessels in OCT images. The proposed framework enhances the segmentation results with uncertainty-aware self-integration and transformation consistency techniques. Meanwhile, we designed an asymmetric encoder-decoder network called Pyramid Pooling SegFormer (APP-SFR) for choroidal vascular segmentation. The network combines local attention and global attention information to improve the model’s ability to learn complex vascular features. Additionally, we proposed a boundary repair module that enhances boundary confidence by utilizing a repair head to re-predict selected fuzzy points and further refines the segmentation boundary. Main results. We conducted extensive experiments on three different datasets: the ChorVessel dataset with 400 OCT images, the Meibomian Glands (MG) dataset with 400 images, and the U2OS Cell Nucleus Dataset with 200 images. The proposed method achieved an average Dice score of 74.23% on the ChorVessel dataset, which is 2.95% higher than the fully supervised network (U-Net) and outperformed other comparison methods. In both the MG dataset and the U2OS cell nucleus dataset, our proposed SSCR method achieved average Dice scores of 80.10% and 87.26%, respectively. Significance. The experimental results show that our proposed methods achieve better segmentation accuracy than other state-of-the-art methods. The method is designed to help clinicians make rapid diagnoses of ophthalmic diseases and has potential for clinical application.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting micro/nanoscale colloidal interactions through local neighborhood graph neural networks",
        "paper_author": "Filiatraut A.N.",
        "publication": "Journal of Applied Physics",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Understanding interparticle interactions has been one of the most important topics of research in the field of micro/nanoscale materials. Many significant characteristics of such materials directly stem from the way their building blocks interact with each other. In this work, we investigate the efficacy of a specific category of Machine Learning (ML) methods known as interaction networks in predicting interparticle interactions within colloidal systems. We introduce and study Local Neighborhood Graph Neural Networks (LN-GNNs), defined according to the local environment of colloidal particles derived from particle trajectory data. The LN-GNN framework is trained for unique categories of particle neighborhood environments in order to predict interparticle interactions. We compare the performance of the LN-GNN to a baseline interaction network with a simpler architecture and to an Instance-Based ML algorithm, which is computationally more expensive. We find that the prediction performance of LN-GNN measured as an average normalized mean absolute error outperforms the baseline interaction network by a factor of 2-10 for different local neighborhood configurations. Furthermore, LN-GNN’s performance turns out to be very comparable to the instance-based ML framework while being an order of magnitude less expensive in terms of the required computation time. The results of this work can provide the foundations for establishing accurate models of colloidal particle interactions that are derived from real particle trajectory data.",
        "affiliation_name": "Miami University",
        "affiliation_city": "Oxford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Models for Predicting Long-Term Visual Acuity in Highly Myopic Eyes",
        "paper_author": "Wang Y.",
        "publication": "JAMA Ophthalmology",
        "citied_by": "4",
        "cover_date": "2023-12-21",
        "Abstract": "Importance: High myopia is a global concern due to its escalating prevalence and the potential risk of severe visual impairment caused by pathologic myopia. Using artificial intelligence to estimate future visual acuity (VA) could help clinicians to identify and monitor patients with a high risk of vision reduction in advance. Objective: To develop machine learning models to predict VA at 3 and 5 years in patients with high myopia. Design, Setting, and Participants: This retrospective, single-center, cohort study was performed on patients whose best-corrected VA (BCVA) at 3 and 5 years was known. The ophthalmic examinations of these patients were performed between October 2011 and May 2021. Thirty-four variables, including general information, basic ophthalmic information, and categories of myopic maculopathy based on fundus and optical coherence tomography images, were collected from the medical records for analysis. Main Outcomes and Measures: Regression models were developed to predict BCVA at 3 and 5 years, and a binary classification model was developed to predict the risk of developing visual impairment at 5 years. The performance of models was evaluated by discrimination metrics, calibration belts, and decision curve analysis. The importance of relative variables was assessed by explainable artificial intelligence techniques. Results: A total of 1616 eyes from 967 patients (mean [SD] age, 58.5 [14.0] years; 678 female [70.1%]) were included in this analysis. Findings showed that support vector machines presented the best prediction of BCVA at 3 years (R2= 0.682; 95% CI, 0.625-0.733) and random forest at 5 years (R2= 0.660; 95% CI, 0.604-0.710). To predict the risk of visual impairment at 5 years, logistic regression presented the best performance (area under the receiver operating characteristic curve = 0.870; 95% CI, 0.816-0.912). The baseline BCVA (logMAR odds ratio [OR], 0.298; 95% CI, 0.235-0.378; P <.001), prior myopic macular neovascularization (OR, 3.290; 95% CI, 2.209-4.899; P <.001), age (OR, 1.578; 95% CI, 1.227-2.028; P <.001), and category 4 myopic maculopathy (OR, 4.899; 95% CI, 1.431-16.769; P =.01) were the 4 most important predicting variables and associated with increased risk of visual impairment at 5 years. Conclusions and Relevance: Study results suggest that developing models for accurate prediction of the long-term VA for highly myopic eyes based on clinical and imaging information is feasible. Such models could be used for the clinical assessments of future visual acuity..",
        "affiliation_name": "Graduate School of Medical and Dental Sciences",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Stability Trends in disubstituted Cobaltocenium Based on the Analysis of the Machine Learning Models",
        "paper_author": "Wetthasinghe S.T.",
        "publication": "Journal of Physical Chemistry A",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "Cobaltocenium derivatives have shown great potential as components of anion exchange membranes in fuel cells because they exhibit excellent thermal and alkaline stability under operating conditions while allowing for high anion mobility. The properties of the cobaltocenium-anion complexes can be chemically tuned through the substituent groups on the cyclopentadienyl (Cp) rings of the cation CoCp2+. However, the synthesis and characterization of the full range of possible derivatives are very challenging and time-consuming, and while the computational tools can greatly expedite this process, full screening of the electronic structure at a high level of theory is still computationally intensive. Therefore, in this work, we consider the machine learning (ML) modeling as a tool of predicting stability of disubstituted [CoCp2]OH complexes measured by their bond-dissociation energy (BDE). The relevant process here is the dissociation of the cobaltocenium-hydroxide complex into fragments [CoCpY′]OH and CpY, where Y and Y′ each represent one out of 42 substituent groups of experimental interest. In agreement with the previous ML study of 120 mono- and selected disubstituted species [Wetthasinghe et al. J. Chem. Phys. A (2022) 126], our analysis of the data set expanded to all possible disubstituted cobaltoceniums, points to the highest occupied and lowest unoccupied molecular orbitals, along with the Hirshfeld charge on the singly substituted benzene, to be the key features predicting the BDE of the unseen complexes. Based on the examination of the outliers, the acidity of substituents ((CO)NH2 in our case) is found to be of special significance for the cobaltocenium stability and for the model development. Moreover, we demonstrate that upon the data set refinement, the conventional ML models are capable of predicting the BDE close to 1 kcal/mol based on the properties of just the fragments, thereby greatly reducing the total number of species and of the computational time of each calculation. Such fragment-based “combinatorial” approach to the BDE modeling is noteworthy, since the geometry optimization of complexes in solution is conceptually challenging and computationally demanding, even when leveraging high-performance computing resources.",
        "affiliation_name": "University of South Carolina",
        "affiliation_city": "Columbia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Rational Atom Substitution to Obtain Efficient, Lead-Free Photocatalytic Perovskites Assisted by Machine Learning and DFT Calculations",
        "paper_author": "Li X.",
        "publication": "Angewandte Chemie - International Edition",
        "citied_by": "6",
        "cover_date": "2023-12-21",
        "Abstract": "Inorganic lead-free halide perovskites, devoid of toxic or rare elements, have garnered considerable attention as photocatalysts for pollution control, CO2 reduction and hydrogen production. In the extensive perovskite design space, factors like substitution or doping level profoundly impact their performance. To address this complexity, a synergistic combination of machine learning models and theoretical calculations were used to efficiently screen substitution elements that enhanced the photoactivity of substituted Cs2AgBiBr6 perovskites. Machine learning models determined the importance of d10 orbitals, highlighting how substituent electron configuration affects electronic structure of Cs2AgBiBr6. Conspicuously, d10-configured Zn2+ boosted the photoactivity of Cs2AgBiBr6. Experimental verification validated these model results, revealing a 13-fold increase in photocatalytic toluene conversion compared to the unsubstituted counterpart. This enhancement resulted from the small charge carrier effective mass, as well as the creation of shallow trap states, shifting the conduction band minimum, introducing electron-deficient Br, and altering the distance between the B-site cations d band centre and the halide anions p band centre, a parameter tuneable through d10 configuration substituents. This study exemplifies the application of computational modelling in photocatalyst design and elucidating structure–property relationships. It underscores the potential of synergistic integration of calculations, modelling, and experimental analysis across various applications.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Universal Polarization Transformations: Spatial Programming of Polarization Scattering Matrices Using a Deep Learning-Designed Diffractive Polarization Transformer",
        "paper_author": "Li Y.",
        "publication": "Advanced Materials",
        "citied_by": "11",
        "cover_date": "2023-12-21",
        "Abstract": "Controlled synthesis of optical fields having nonuniform polarization distributions presents a challenging task. Here, a universal polarization transformer is demonstrated that can synthesize a large set of arbitrarily-selected, complex-valued polarization scattering matrices between the polarization states at different positions within its input and output field-of-views (FOVs). This framework comprises 2D arrays of linear polarizers positioned between isotropic diffractive layers, each containing tens of thousands of diffractive features with optimizable transmission coefficients. After its deep learning-based training, this diffractive polarization transformer can successfully implement NiNo = 10 000 different spatially-encoded polarization scattering matrices with negligible error, where Ni and No represent the number of pixels in the input and output FOVs, respectively. This universal polarization transformation framework is experimentally validated in the terahertz spectrum by fabricating wire-grid polarizers and integrating them with 3D-printed diffractive layers to form a physical polarization transformer. Through this set-up, an all-optical polarization permutation operation of spatially-varying polarization fields is demonstrated, and distinct spatially-encoded polarization scattering matrices are simultaneously implemented between the input and output FOVs of a compact diffractive processor. This framework opens up new avenues for developing novel devices for universal polarization control and may find applications in, e.g., remote sensing, medical imaging, security, material inspection, and machine vision.",
        "affiliation_name": "UCLA Samueli School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A machine learning and live-cell imaging tool kit uncovers small molecules induced phospholipidosis",
        "paper_author": "Hu H.",
        "publication": "Cell Chemical Biology",
        "citied_by": "4",
        "cover_date": "2023-12-21",
        "Abstract": "Drug-induced phospholipidosis (DIPL), characterized by excessive accumulation of phospholipids in lysosomes, can lead to clinical adverse effects. It may also alter phenotypic responses in functional studies using chemical probes. Therefore, robust methods are needed to predict and quantify phospholipidosis (PL) early in drug discovery and in chemical probe characterization. Here, we present a versatile high-content live-cell imaging approach, which was used to evaluate a chemogenomic and a lysosomal modulation library. We trained and evaluated several machine learning models using the most comprehensive set of publicly available compounds and interpreted the best model using SHapley Additive exPlanations (SHAP). Analysis of high-quality chemical probes extracted from the Chemical Probes Portal using our algorithm revealed that closely related molecules, such as chemical probes and their matched negative controls can differ in their ability to induce PL, highlighting the importance of identifying PL for robust target validation in chemical biology.",
        "affiliation_name": "Biomedicinskt centrum",
        "affiliation_city": "Uppsala",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Predicting Exporters with Machine Learning",
        "paper_author": "Micocci F.",
        "publication": "World Trade Review",
        "citied_by": "0",
        "cover_date": "2023-12-21",
        "Abstract": "In this contribution, we exploit machine learning techniques to evaluate whether and how close firms are to become successful exporters. First, we train various algorithms using financial information on both exporters and non-exporters in France in 2010-2018. Thus, we show that it is possible to predict the distance non-exporters are from export status. In particular, we find that a Bayesian Additive Regression Tree with Missingness In Attributes (BART-MIA) performs better than other techniques with an accuracy of up to 0.90. Predictions are robust to changes in definitions of exporters and in the presence of discontinuous exporting activity. Eventually, we discuss how our exporting scores can be helpful for trade promotion, trade credit, and assessing aggregate trade potential. For example, back-of-the-envelope estimates show that a representative firm with just below-average exporting scores needs up to 44% more cash resources and up to 2.5 times more capital to get to foreign markets.",
        "affiliation_name": "Scuola IMT Alti Studi Lucca",
        "affiliation_city": "Lucca",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Research progress of brain imaging in cognitive behavioral therapy for depression",
        "paper_author": "He M.",
        "publication": "Chinese Journal of Behavioral Medicine and Brain Science",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "The prevalence and recurrence rate of depressive disorder are high, while the recognition and cure rate are low. Early intervention can improve the quality of life of patients with depression. In clinical practice, it has been found that psychological treatments can effectively improve the symptoms and prognosis of depression.Cognitive behavior therapy(CBT) has been widely used in the treatment of depression, however, its mechanisms are still unclear. In this paper, the neuroimaging studies of patients with depression before and after CBT were summarized, and the structural or functional changes of different brain regions in patients with depression before and after CBT were described. The findings suggest that CBT improved depressive symptoms by increasing gray matter volume, activation level, and functional connectivity strength in the dorsolateral prefrontal cortex, reducing activation levels in the amygdala and parahippocampal gyrus, and restoring abnormal brain network activity or functional connectivity. Larger gray matter volume in anterior cingulate gyrus and higher activation levels in hippocampus and amygdala before treatment can effectively predict the effect of CBT in depressed patients. In the future, machine learning could be combined with brain imaging data to more accurately predict the effectiveness of CBT in treating depression.",
        "affiliation_name": "Xinxiang Medical University",
        "affiliation_city": "Xinxiang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Real-Time Identification Method of Stratum Characteristics During Shield Tunnelling",
        "paper_author": "Qiao G.",
        "publication": "Chinese Journal of Underground Space and Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "In order to solve the problem that the geological condition in front of the cutterhead is not clear in the shield construction process, this study proposes a stratigraphic classification model using machine leaning technology based on the relationship between shield parameters and geological characteristics. Shield parameters are dynamic response of geological characteristics during shield tunnelling. The transformed shield parameters, specific thrust and specific torque are used to reveal the changes of geological characteristics. CART model and random forest model are developed to predict stratigraphic categories during shield advancing. The operation parameters of shield in Pazhou railway project are collected and fed to machine learning-based model for training and prediction. The results show that the accuracy of CART prediction model and random forest model are 81% and 85%, respectively. There is a small error on the boundary of local adjacent categories, which meets the actual engineering requirements and can provide reference for the construction of similar projects.",
        "affiliation_name": "Ltd.",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Imbalanced Multiclass Medical Data Classification based on Learning Automata and Neural Network",
        "paper_author": "Soleimani M.",
        "publication": "EAI Endorsed Transactions on AI and Robotics",
        "citied_by": "22",
        "cover_date": "2023-12-20",
        "Abstract": "Data classification in the real world is often faced with the challenge of data imbalance, where there is a significant difference in the number of instances among different classes. Dealing with imbalanced data is recognized as a challenging problem in data mining, as it involves identifying minority-class data with a high number of errors. Therefore, the selection of unique and appropriate features for classifying data with smaller classes poses a fundamental challenge in this research. Nowadays, due to the widespread presence of imbalanced medical data in many real-world problems, the processing of such data has gained attention from researchers. The objective of this research is to propose a method for classifying imbalanced medical data. In this paper, the hypothyroidism dataset from the UCI repository is used. In the feature selection stage, a support vector machine algorithm is used as a cost function, and the wrapper algorithm is employed as a search strategy to achieve an optimal subset of features. The proposed method achieves high accuracy, reaching 99.6% accuracy for data classification through the optimization of a neural network using learning automata.",
        "affiliation_name": "Clemson University College of Engineering, Computing and Applied Sciences",
        "affiliation_city": "Clemson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Parkinson Disease Genetics Extended to African and Hispanic Ancestries in the VA Million Veteran Program",
        "paper_author": "Pankratz N.",
        "publication": "Neurology: Genetics",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "Background and Objectives Nearly all genetic analyses of Parkinson disease (PD) have been in populations of European ancestry. We sought to test the ability of a machine learning method to extract accurate PD diagnoses from an electronic medical record (EMR) system, to see whether genetic variants identified in European populations generalize to individuals of African and Hispanic ancestries, and to compare the rates of PD across ancestries. Methods A machine learning method using natural language processing was applied to EMRs of US veterans participating in the VA Million Veteran Program (MVP) to identify individuals with PD. These putative cases were vetted via blind chart review by a movement disorder specialist. A polygenic risk score (PRS) of 90 established genetic variants whose genotypes were imputed from a customized Axiom Biobank Array was evaluated in different case groups. Results The EMR prediction scores had a distinct trimodal distribution, with 97% of the high group and only 30% of the middle group having a credible diagnosis of PD. Using the 3,542 cases from the high group matched 4:1 to controls, the PRS was highly predictive in individuals of European ancestry (n = 3,137 cases; OR = 1.82; p = 8.01E-48), and nearly identical effect sizes were seen in individuals of African (n = 184; OR = 2.07; p = 3.4E-4) and Hispanic ancestries (n = 221; OR = 2.13; p = 3.9E-6). The PRS was much less predictive for the 2,757 European ancestry cases who had an ICD code for PD but for whom the machine learning method had a lower confidence in their diagnosis. No novel ancestry-specific genetic variants were identified. Individuals with African ancestry had one-quarter the rate of PD compared with European or Hispanic ancestries aged 60–70 years and one half the rate in the 70–80 years age range. African American cases had a higher proportion of their DNA originating in Europe compared with African American controls. Discussion Machine learning can reliably classify PD using data from a large EMR. Larger studies of non-European populations are required to confirm the generalizability of PD risk variants identified in populations of European ancestry and the increased risk coming from a higher proportion of European DNA in African Americans.",
        "affiliation_name": "VA Boston Healthcare System",
        "affiliation_city": "West Roxbury",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning in Robotics with Fog/Cloud Computing and IoT",
        "paper_author": "Singh K.D.",
        "publication": "EAI Endorsed Transactions on AI and Robotics",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "Robotics has been transformed by machine learning (ML), enabling intelligent and adaptive autonomous systems. By delivering massive computational resources and real-time data, fog/cloud computing and the Internet of Things boost ML-based robotics. Intelligent and linked robotics have emerged from fog/cloud computing, IoT, and machine learning. Robots using distributed computing, real-time IoT data, and advanced machine learning algorithms could alter industries and improve automation. To maximize its potential, this revolutionary combination must overcome several obstacles. This paper discusses the benefits and drawbacks of integrating technologies. It offer rapid model training and deployment for robots ML algorithms like deep learning and reinforcement learning. Case studies demonstrate how this combination might enhance robotics across industries. This study discusses the benefits and drawbacks of fog/cloud computing, IoT, and machine learning in robots. We propose solutions for security and privacy, resource management, latency and bandwidth, interoperability, energy efficiency, data quality, and bias. By proactively addressing these difficulties, we can establish a secure, efficient, and privacy-conscious robotic ecosystem where robots seamlessly interact with the physical world, improving productivity, safety, and human-robot collaboration. As these technologies progress, appropriate integration and ethical principles are needed to maximize their benefits to society.",
        "affiliation_name": "Chitkara University, Punjab",
        "affiliation_city": "Rajpura",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Machine Learning Based Investigative Analysis for Predicting the Critical Temperature of Superconductors",
        "paper_author": "Shams F.A.",
        "publication": "EAI Endorsed Transactions on AI and Robotics",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "INTRODUCTION: Ever since the initial discovery of superconductivity, the fundamental concept and the complex relationship between critical temperature and superconductive materials have been subject to extensive investigation. However, identifying superconductors at normal temperatures remains a significant challenge, and there are still significant gaps in our understanding of this unique phenomenon, particularly regarding the fundamental criteria used to estimate critical temperature. OBJECTIVES: To address this knowledge gap, a plethora of machine learning (ML) techniques have been developed in this work to model critical temperatures, given the inherent difficulty in predicting them using traditional methods. METHODS: Additionally, the limitations of the standard empirical formula in determining the temperature range require the development of more advanced and viable methods. This article presents an investigative analysis of the performance achieved by different supervised machine learning algorithms when used with three different feature selection techniques. RESULTS: The stacking model used in this work is found to be the best performer among all the algorithms tested, as reflected by the Root Mean Squared Error (RMSE) of 9.68, R2 score of 0.922, Mean Absolute Error (MAE) score of 5.383, and Mean Absolute Percentage Error (MAPE) score of 4.575. CONCLUSION: Therefore, it is observed that ML algorithms can contribute significantly in the domain of predictive analysis of modeling critical temperatures in superconductors and can assist in developing a robust computer-aided system to aid the education personnel and research scientists to further assess the performance of the ML models.",
        "affiliation_name": "Islamic University of Technology",
        "affiliation_city": "Gazipur",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Session-based recommender systems using deep learning",
        "paper_author": "Ravanmehr R.",
        "publication": "Session-Based Recommender Systems Using Deep Learning",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "This book focuses on the widespread use of deep neural networks and their various techniques in session-based recommender systems (SBRS). It presents the success of using deep learning techniques in many SBRS applications from different perspectives. For this purpose, the concepts and fundamentals of SBRS are fully elaborated, and different deep learning techniques focusing on the development of SBRS are studied. The book is well-modularized, and each chapter can be read in a stand-alone manner based on individual interests and needs. In the first chapter of the book, definitions and concepts related to SBRS are reviewed, and a taxonomy of different SBRS approaches is presented, where the characteristics and applications of each class are discussed separately. The second chapter starts with the basic concepts of deep learning and the characteristics of each model. Then, each deep learning model, along with its architecture and mathematical foundations, is introduced. Next, chapter 3 analyses different approaches of deep discriminative models in session-based recommender systems. In the fourth chapter, session-based recommender systems that benefit from deep generative neural networks are discussed. Subsequently, chapter 5 discusses session-based recommender systems using advanced/hybrid deep learning models. Eventually, chapter 6 reviews different learning-to-rank methods focusing on information retrieval and recommender system domains. Finally, the results of the investigations and findings from the research review conducted throughout the book are presented in a conclusive summary. This book aims at researchers who intend to use deep learning models to solve the challenges related to SBRS. The target audience includes researchers entering the field, graduate students specializing in recommender systems, web data mining, information retrieval, or machine/deep learning, and advanced industry developers working on recommender systems.",
        "affiliation_name": "Islamic Azad University, Central Tehran Branch",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Analysing data from capacitive floor sensors for human gait assessment using artificial neural networks",
        "paper_author": "Hoffmann R.",
        "publication": "Analysing Data from Capacitive Floor Sensors for Human Gait Assessment Using Artificial Neural Networks",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Gait analysis is valuable in medical research and diagnosis, by delivering information that helps in choosing methods of intervention and rehabilitation that are beneficial for a patient. In gait laboratories, cameras or IMUs are often used to gather gait patterns. This thesis explores the possibility of using sensors below the floor as a gait data source. These sensors measure changes in the electrical capacitance to recognise steps. The construction is designed for indoor environments and is hidden under common flooring layer types. Therefore, it is very robust and suitable for practical use in daily clinical routine. A formal framework was developed to represent the measurements, considering the special characteristics of this floor sensor. The data were then used as input for artificial neural networks that were applied on classification and regression tasks. In a feature construction and extraction approach, the spatial spread of footfalls was derived and used with a feed-forward neural network. Then, in a feature learning approach, the time series data was transformed into a local receptive field, and used with a recurrent neural network. Three studies were conducted for the goals to distinguish between people with low and high risk of falling, to estimate age, and to recognise walking challenges as an external gait intervention. The combination of a robust and hidden floor sensor and machine learning opens up the prospect of future applications in health and care.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A short introduction to artificial intelligence: Methods, success stories, and current limitations",
        "paper_author": "Heitzinger C.",
        "publication": "Introduction to Digital Humanism: A Textbook",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "This chapter gives an overview of the most important methods in artificial intelligence (AI). The methods of symbolic AI are rooted in logic, and finding possible solutions by search is a central aspect. The main challenge is the combinatorial explosion in search, but the focus on the satisfiability problem of propositional logic (SAT) since the 1990s and the accompanying algorithmic improvements have made it possible to solve problems on the scale needed in industrial applications. In machine learning (ML), self-learning algorithms extract information from data and represent the solutions in convenient forms. ML broadly consists of supervised learning, unsupervised learning, and reinforcement learning. Successes in the 2010s and early 2020s such as solving Go, chess, and many computer games as well as large language models such as ChatGPT are due to huge computational resources and algorithmic advances in ML. Finally, we reflect on current developments and draw conclusions.",
        "affiliation_name": "Technische Universität Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Unmet need in rheumatology: reports from the Advances in Targeted Therapies meeting, 2023",
        "paper_author": "Winthrop K.L.",
        "publication": "Annals of the Rheumatic Diseases",
        "citied_by": "8",
        "cover_date": "2023-12-20",
        "Abstract": "The Advances in Targeted Therapies meets annually, convening experts in the field of rheumatology to both provide scientific updates and identify existing scientific gaps within the field. To review the major unmet scientific needs in rheumatology. The 23rd annual Advances in Targeted Therapies meeting convened with more than 100 international basic scientists and clinical researchers in rheumatology, immunology, infectious diseases, epidemiology, molecular biology and other specialties relating to all aspects of immune-mediated inflammatory diseases. We held breakout sessions in five rheumatological disease-specific groups including: rheumatoid arthritis (RA), psoriatic arthritis (PsA), axial spondyloarthritis (axSpa), systemic lupus erythematosus (SLE), systemic sclerosis (SSc) and vasculitis, and osteoarthritis (OA). In each group, experts were asked to identify and prioritise current unmet needs in clinical and translational research. An overarching theme across all disease states is the continued need for clinical trial design innovation with regard to therapeutics, endpoint and disease endotypes. Within RA, unmet needs comprise molecular classification of disease pathogenesis and activity, pre-/early RA strategies, more refined pain profiling and innovative trials designs to deliver on precision medicine. Continued scientific questions within PsA include evaluating the genetic, immunophenotypic, clinical signatures that predict development of PsA in patients with psoriasis, and the evaluation of combination therapies for difficult-to-treat disease. For axSpA, there continues to be the need to understand the role of interleukin-23 (IL-23) in pathogenesis and the genetic relationship of the IL-23-receptor polymorphism with other related systemic inflammatory diseases (eg, inflammatory bowel disease). A major unmet need in the OA field remains the need to develop the ability to reliably phenotype and stratify patients for inclusion in clinical trials. SLE experts identified a number of unmet needs within clinical trial design including the need for allowing endpoints that reflect pharmacodynamic/ functional outcomes (eg, inhibition of type I interferon pathway activation; changes in urine biomarkers). Lastly, within SSc and vasculitis, there is a lack of biomarkers that predict response or disease progression, and that allow patients to be stratified for therapies. There remains a strong need to innovate clinical trial design, to identify systemic and tissue-level biomarkers that predict progression or response to therapy, endotype disease, and to continue developing therapies and therapeutic strategies for those with treatment-refractory disease. This document, based on expert consensus, should provide a roadmap for prioritising scientific endeavour in the field of rheumatology.",
        "affiliation_name": "OHSU School of Medicine",
        "affiliation_city": "Portland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Value-sensitive software design: Ethical deliberation in agile development processes",
        "paper_author": "Zuber N.",
        "publication": "Introduction to Digital Humanism: A Textbook",
        "citied_by": "3",
        "cover_date": "2023-12-20",
        "Abstract": "This chapter discusses the integration of ethical deliberations within agile software development processes. It emphasizes the importance of considering ethical implications during the development of software, not just AI. The chapter proposes modes of reflection and deliberation that include disclosive, weighing, and applicative modes of contemplation. It argues that these three kinds of thinking are guided by different normative values. The chapter suggests that agile development is an excellent starting point for implementing ethical deliberations, as it allows for continuous reflection and learning. It also proposes that development teams can perform this task themselves up to a point with proper guidance. This section further discusses the potential of agile processes to naturally accommodate ethical deliberation. However, it also acknowledges the challenges associated with implementing agile processes, especially in the context of machine learning models.",
        "affiliation_name": "Ludwig-Maximilians-Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Large-scale field data-based battery aging prediction driven by statistical features and machine learning",
        "paper_author": "Wang Q.",
        "publication": "Cell Reports Physical Science",
        "citied_by": "20",
        "cover_date": "2023-12-20",
        "Abstract": "Accurately predicting battery aging is critical for mitigating performance degradation during battery usage. While the automotive industry recognizes the importance of utilizing field data for battery performance evaluation and optimization, its practical implementation faces challenges in data collection and the lack of field data-based prognosis methods. To address this, we collect field data from 60 electric vehicles operated for over 4 years and develop a robust data-driven approach for lithium-ion battery aging prediction based on statistical features. The proposed pre-processing methods integrate data cleaning, transformation, and reconstruction. In addition, we introduce multi-level screening techniques to extract statistical features from historical usage behavior. Utilizing machine learning, we accurately predict aging trajectories and worst-lifetime batteries while quantifying prediction uncertainty. This research emphasizes a field data-based framework for battery health management, which not only provides a vital basis for onboard health monitoring and prognosis but also paves the way for battery second-life evaluation scenarios.",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Optimizing geographic locations for electric vehicle battery recycling preprocessing facilities in California",
        "paper_author": "Haynes M.W.",
        "publication": "RSC Sustainability",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "Spent lithium-ion batteries (LIBs) at end of life pose several safety risks. Specifically, LIBs have the potential to self-ignite during transport, release toxic compounds during incineration, and can leach contaminants into landfills. Spent LIBs, which are classified as hazardous waste, are also subject to numerous policies and require disposal by certified personnel and companies. These requirements result in an increase in transport costs and volume compared to other waste. Efforts to improve LIB recycling focus primarily on reducing costs to make recycling economically profitable. The greatest emphasis is placed on improving recycling technologies; however, transport costs significantly impact the total cost of LIB recycling. Here, we provide a procedure for choosing an unsupervised machine learning clustering heuristic to identify optimal locations for LIB recycling preprocessing facilities in California. The identified decentralized facility locations minimize the transportation distance and the cost of shipping spent electric vehicle batteries between end-use sector facilities and potential second-use locations.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting Football Match Outcomes With Machine Learning Approaches",
        "paper_author": "Choi B.S.",
        "publication": "Mendel",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "The increasing use of data-driven approaches has led to the development of models to predict football match outcomes. However, predicting match outcomes accurately remains a challenge due to the sport’s inherent unpredictability. In this study, we have investigated the usage of different machine learning models in predicting the outcome of English Premier League matches. We assessed the performance of random forest, logistic regression, linear support vector classifier and extreme gradient boosting models for binary and multiclass classification. These models are trained with datasets obtained using different sampling techniques. The result showed that the models performed better when trained with dataset obtained using a balanced sampling technique for binary classification. Additionally, the models’ predictions were evaluated by conducting simulation on football betting profits based on the 2022-2023 EPL season. The model achieved the highest accuracy is the binary class random forest, but the model provided the highest football betting profit is the binary class logistic regression.",
        "affiliation_name": "Multimedia University",
        "affiliation_city": "Cyberjaya",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Multimodal analysis of disinformation and misinformation",
        "paper_author": "Wilson A.",
        "publication": "Royal Society Open Science",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "The use of disinformation and misinformation campaigns in the media has attracted much attention from academics and policy-makers. Multimodal analysis or the analysis of two or more semiotic systems - language, gestures, images, sounds, among others - in their interrelation and interaction is essential to understanding dis-/misinformation efforts because most human communication goes beyond just words. There is a confluence of many disciplines (e.g. computer science, linguistics, political science, communication studies) that are developing methods and analytical models of multimodal communication. This literature review brings research strands from these disciplines together, providing a map of the multi- and interdisciplinary landscape for multimodal analysis of dis-/misinformation. It records the substantial growth starting from the second quarter of 2020 - the start of the COVID-19 epidemic in Western Europe - in the number of studies on multimodal dis-/misinformation coming from the field of computer science. The review examines that category of studies in more detail. Finally, the review identifies gaps in multimodal research on dis-/misinformation and suggests ways to bridge these gaps including future cross-disciplinary research directions. Our review provides scholars from different disciplines working on dis-/misinformation with a much needed bird's-eye view of the rapidly emerging research of multimodal dis-/misinformation.",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Initial Coin Offering Prediction Comparison Using Ridge Regression, Artificial Neural Network, Random Forest Regression, and Hybrid ANN-Ridge",
        "paper_author": "Tran T.K.",
        "publication": "Mendel",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Can machine learning take a prediction to win an investment in ICO (Initial Coin Offering)? In this research work, our objective is to answer this question. Four popular and lower computational demanding approaches including Ridge regression (RR), Artificial neural network (ANN), Random forest regression (RFR), and a hybrid ANN-Ridge regression are compared in terms of accuracy metrics to predict ICO value after six months. We use a dataset collected from 109 ICOs that were obtained from the cryptocurrency websites after data preprocessing. The dataset consists of 12 fields covering the main factors that affect the value of an ICO. One-hot encoding technique is applied to convert the alphanumeric form into a binary format to perform better predictions; thus, the dataset has been expanded to 128 columns and 109 rows. Input data (variables) and ICO value are non-linear dependent. The Artificial neural network algorithm offers a bio-inspired mathematical model to solve the complex non-linear relationship between input variables and ICO value. The linear regression model has problems with overfitting and multicollinearity that make the ICO prediction inaccurate. On the contrary, the Ridge regression algorithm overcomes the correlation problem that independent variables are highly correlated to the output value when dealing with ICO data. Random forest regression does avoid overfitting by growing a large decision tree to minimize the prediction error. Hybrid ANN-Ridge regression leverages the strengths of both algorithms to improve prediction accuracy. By combining ANN’s ability to capture complex non-linear relationships with the regularization capabilities of Ridge regression, the hybrid can potentially provide better predictive performance compared to using either algorithm individually. After the training process with the cross-validation technique and the parameter fitting process, we obtained several models but selected three of the best in each algorithm based on metrics of RMSE (Root Mean Square Error), R2 (R-squared), and MAE (Mean Absolute Error). The validation results show that the presented Ridge regression approach has an accuracy of at most 99% of the actual value. The Artificial neural network predicts the ICO value with an accuracy of up to 98% of the actual value after six months. Additionally, the Random forest regression and the hybrid ANN-Ridge regression improve the predictive accuracy to 98% actual value.",
        "affiliation_name": "VSB – Technical University of Ostrava",
        "affiliation_city": "Ostrava",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Exploring emotions in Bach chorales: A multi-modal perceptual and data-driven study",
        "paper_author": "Parada-Cabaleiro E.",
        "publication": "Royal Society Open Science",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "The relationship between music and emotion has been addressed within several disciplines, from more historico-philosophical and anthropological ones, such as musicology and ethnomusicology, to others that are traditionally more empirical and technological, such as psychology and computer science. Yet, understanding the link between music and emotion is limited by the scarce interconnections between these disciplines. Trying to narrow this gap, this data-driven exploratory study aims at assessing the relationship between linguistic, symbolic and acoustic features - extracted from lyrics, music notation and audio recordings - and perception of emotion. Employing a listening experiment, statistical analysis and unsupervised machine learning, we investigate how a data-driven multi-modal approach can be used to explore the emotions conveyed by eight Bach chorales. Through a feature selection strategy based on a set of more than 300 Bach chorales and a transdisciplinary methodology integrating approaches from psychology, musicology and computer science, we aim to initiate an efficient dialogue between disciplines, able to promote a more integrative and holistic understanding of emotions in music.",
        "affiliation_name": "Johannes Kepler University Linz",
        "affiliation_city": "Linz",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Exploring Hybrid Models For Short-Term Local Weather Forecasting in IoT Environment",
        "paper_author": "Tran T.K.",
        "publication": "Mendel",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "This paper explores using and hybridizing simple prediction models to maximize the accuracy of local weather prediction while maintaining low computational effort and the need to process and acquire large volumes of data. A hybrid RF-LSTM model is proposed and evaluated in this research paper for the task of short-term local weather forecasting. The local weather stations are built within an acceptable radius of the measured area and are designed to provide a short period of forecasting-usually within one hour. The lack of local weather data might be problematic for an accurate short-term valuable prediction in sustainable applications like agriculture, transportation, energy management, and daily life. Weather forecasting is not trivial because of the non-linear nature of time series. Thus, traditional forecasting methods cannot predict the weather accurately. The advantage of the ARIMA model lies in forecasting the linear part, while the SVR model indicates the non-linear characteristic of the weather data. Both non-linear and linear approaches can represent the combined model. The hybrid ARIMA-SVR model strengthens the matched points of the ARIMA model and the SVR model in weather forecasting. The LSTM and random forest are both popular algorithms used for regression problems. LSTM is more suitable for tasks involving sequential data with long-term dependencies. Random Forest leverages the wisdom of crowds by combining multiple decision trees, providing robust predictions, and reducing overfitting. Hybrid Random forest-LSTM potentially leverages the robustness and feature importance of Random Forest along with the ability of LSTM to capture sequential dependencies. The comparison results show that the hybrid RF-LSTM model reduces the forecasting errors in metrics of MAE, R-squared, and RMSE. The proposed hybrid model can also capture the actual temperature trend in its prediction performance, which makes it even more relevant for many other possible decision-making steps in sustainable applications. Furthermore, this paper also proposes the design of a weather station based on a real-time edge IoT system. The RF-LSTM leverages the parallelized characteristics of each decision tree in the forest to accelerate the training process and faster inferences. Thus, the hybrid RF-LSTM model offers advantages in terms of faster execution speed and computational efficiency in both PC and Raspberry Pi boards. However, the RF-LSTM consumes the highest peak memory usage due to being a combination of two different models.",
        "affiliation_name": "VSB – Technical University of Ostrava",
        "affiliation_city": "Ostrava",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Environmental controls of winter soil carbon dioxide fluxes in boreal and tundra environments",
        "paper_author": "Mavrovic A.",
        "publication": "Biogeosciences",
        "citied_by": "3",
        "cover_date": "2023-12-20",
        "Abstract": "The carbon cycle in Arctic-boreal regions (ABRs) is an important component of the planetary carbon balance, with growing concerns about the consequences of ABR warming for the global climate system. The greatest uncertainty in annual carbon dioxide (CO2) budgets exists during winter, primarily due to challenges with data availability and limited spatial coverage in measurements. The goal of this study was to determine the main environmental controls of winter CO2 fluxes in ABRs over a latitudinal gradient (45 to 69 N) featuring four different ecosystem types: closed-crown coniferous boreal forest, open-crown coniferous boreal forest, erect-shrub tundra, and prostrate-shrub tundra. CO2 fluxes calculated using a snowpack diffusion gradient method (n=560) ranged from 0 to 1.05 gCm2d-1. To assess the dominant environmental controls governing CO2 fluxes, a random forest machine learning approach was used. We identified soil temperature as the main control of winter CO2 fluxes with 68 % of relative model importance, except when soil liquid water occurred during 0 °C curtain conditions (i.e., Tsoil≈0 °C and liquid water coexist with ice in soil pores). Under zero-curtain conditions, liquid water content became the main control of CO2 fluxes with 87 % of relative model importance. We observed exponential regressions between CO2 fluxes and soil temperature in fully frozen soils (RMSE=0.024 gCm-2d-1; 70.3 % of mean FCO2) and soils around the freezing point (RMSE=0.286 gCm-2d-1; 112.4 % of mean FCO2). FCO2 increases more rapidly with Tsoil around the freezing point than at Tsoil<5 °C. In zero-curtain conditions, the strongest regression was found with soil liquid water content (RMSE=0.137 gCm-2d-1; 49.1 % of mean FCO2). This study shows the role of several variables in the spatio-temporal variability in CO2 fluxes in ABRs during winter and highlights that the complex vegetation-snow-soil interactions in northern environments must be considered when studying what drives the spatial variability in soil carbon emissions during winter.",
        "affiliation_name": "Itä-Suomen yliopisto",
        "affiliation_city": "Kuopio",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Global dryland aridity changes indicated by atmospheric, hydrological, and vegetation observations at meteorological stations",
        "paper_author": "Shi H.",
        "publication": "Hydrology and Earth System Sciences",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "In the context of global warming, an increase in atmospheric aridity and global dryland expansion under the future climate has been expected in previous studies. However, this conflicts with observed greening over drylands and the insignificant increase in hydrological and ecological aridity from the ecohydrology perspective. Combining climatic, hydrological, and vegetation data, this study evaluated global dryland aridity changes at meteorological stations from 2003 to 2019. A decoupling between atmospheric, hydrological, and vegetation aridity was found. Atmospheric aridity represented by the vapor pressure deficit (VPD) increased, hydrological aridity indicated by machine-learning-based precipitation minus evapotranspiration (P-ET) data did not change significantly, and ecological aridity represented by the leaf area index (LAI) decreased. P-ET showed nonsignificant changes in most of the dominant combinations of the VPD, LAI, and P-ET. This study highlights the added value of using station-scale data to assess dryland change as a complement to results based on coarse-resolution reanalysis data and land surface models.",
        "affiliation_name": "The Grainger College of Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Comparing quantile regression forest and mixture density long short-term memory models for probabilistic post-processing of satellite precipitation-driven streamflow simulations",
        "paper_author": "Zhang Y.",
        "publication": "Hydrology and Earth System Sciences",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "Deep learning (DL) and machine learning (ML) are widely used in hydrological modelling, which plays a critical role in improving the accuracy of hydrological predictions. However, the trade-off between model performance and computational cost has always been a challenge for hydrologists when selecting a suitable model, particularly for probabilistic post-processing with large ensemble members. This study aims to systematically compare the quantile regression forest (QRF) model and countable mixtures of asymmetric Laplacians long short-term memory (CMAL-LSTM) model as hydrological probabilistic post-processors. Specifically, we evaluate their ability in dealing with biased streamflow simulations driven by three satellite precipitation products across 522 nested sub-basins of the Yalong River basin in China. Model performance is comprehensively assessed using a series of scoring metrics from both probabilistic and deterministic perspectives. Our results show that the QRF model and the CMAL-LSTM model are comparable in terms of probabilistic prediction, and their performances are closely related to the flow accumulation area (FAA) of the sub-basin. The QRF model outperforms the CMAL-LSTM model in most sub-basins with smaller FAA, while the CMAL-LSTM model has an undebatable advantage in sub-basins with FAA larger than 60000km2 in the Yalong River basin. In terms of deterministic predictions, the CMAL-LSTM model is preferred, especially when the raw streamflow is poorly simulated and used as input. However, setting aside the differences in model performance, the QRF model with 100-member quantiles demonstrates a noteworthy advantage by exhibiting a 50% reduction in computation time compared to the CMAL-LSTM model with the same ensemble members in all experiments. As a result, this study provides insights into model selection in hydrological post-processing and the trade-offs between model performance and computational efficiency. The findings highlight the importance of considering the specific application scenario, such as the catchment size and the required accuracy level, when selecting a suitable model for hydrological post-processing.",
        "affiliation_name": "Samueli School of Engineering",
        "affiliation_city": "Irvine",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Machine Learning Approach to Identify Optimal Cultivation Practices for Sustainable apple Production in Precision Agriculture in Morocco",
        "paper_author": "Ed-Daoudi R.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Precision agriculture techniques have been increasingly adopted worldwide to optimize cultivation practices and achieve sustainable crop production. In this study, we developed a Machine Learning approach to identify optimal cultivation practices for sustainable apple production in precision agriculture in the Msemrir town Morocco. We collected a dataset of cultivation practices and apple yield and size data from 10 farms in the town and used correlation-based feature selection and three Machine Learning algorithms (Linear Regression, Decision Tree, and Random Forest) to develop predictive models. The results showed that irrigation, fertilization, and pruning are the most important cultivation practices for apple production in the region, and the Random Forest model performed the best in predicting apple yield and size based on the selected practices. The use of Machine Learning techniques can help farmers optimize cultivation practices and achieve sustainable apple production by reducing inputs such as water and fertilizer and minimizing environmental impact. Moreover, the use of precision agriculture techniques can help farmers meet consumer demand for sustainable and high-quality apple products.",
        "affiliation_name": "Faculty of Science, Ibn Tofail University",
        "affiliation_city": "Kenitra",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Data-driven traffic incident detection in urban roads based on machine learning algorithms",
        "paper_author": "Ayou M.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Known issues such as traffic congestion, pollution, and travel delays are mainly caused by incidents in urban roads, so incidents need to be detected for better management. This paper describes various machine learning algorithms for incident detection, like Support Vector Machine (SVM), Random Forest (RF) and long short-term memory network (LSTM). To assess the effectiveness of these models, simulated data were generated through the utilization of the open-source software SUMO. And the obtained results show that the LSTM achieve a good performance when it’s compared to SVM and Random Forest.",
        "affiliation_name": "Aix Marseille Université",
        "affiliation_city": "Marseille",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Text extraction and recognition method for license plates",
        "paper_author": "Moussaoui H.",
        "publication": "E3S Web of Conferences",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Text extraction from images has always been challenging, especially if the image is taken under bad conditions, like lightning and noise that can influence text detection and recognition. This paper introduces a novel text extraction and recognition technique applied to the case study license plates. The main idea of this study is to detect the license plate in an input image and try to figure out the original country of the car based on the license plate. To accomplish this task, we first started collecting images from the internet, which were about 100 images. Afterward, we extracted the license plate using machine learning methods. Subsequently, we applied k-means clustering as well as thresholding in order to segment the extracted license plate and make the character recognition task easier. Thereafter, a sequence of techniques were applied, such as resizing and cropping the image to limit the wanted area of the desired character we want to extract. The last part of the proposed method is reading the text from the image using EasyOcr method, and using the function find in order to search for the character or the word. his proposed method achieved satisfactory results in detection where we achieved an accuracy of 87%, and a recognition of 97%. As for finding the ‘word’ part, the algorithm succeeded in all the examples.",
        "affiliation_name": "Université Sidi Mohamed Ben Abdellah",
        "affiliation_city": "Fez",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Exploring Machine Learning contribution in COVID-19 cure and management: Predicting Mortality and Vaccine Efficacy: A survey",
        "paper_author": "Essamlali I.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "The SARS-CoV-2 virus, responsible for the COVID-19 pandemic, has left an indelible mark on a global scale. This illness, exhibiting a spectrum of mild to severe symptoms, has triggered a widespread health crisis. Within this context, Machine Learning has emerged as a versatile tool, playing a pivotal role in pandemic management. It has found applications in predicting virus transmission patterns, analyzing medical imaging data, and exploring potential therapeutic avenues. This comprehensive paper delves into the multifaceted involvement of Machine Learning in COVID-19 research, spanning from data aggregation to vaccine advancement. Furthermore, we delve into the ethical and societal dimensions inherent in leveraging Machine Learning for pandemic-related inquiries. In conclusion, we spotlight promising avenues for future exploration and advancement in this burgeoning field.",
        "affiliation_name": "Hassan II University of Casablanca",
        "affiliation_city": "Casablanca",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "A survey on AI Approaches for Internet of Things Devices Failure Prediction",
        "paper_author": "Khattach O.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "The use of Internet of Things (IoT) devices has experienced a substantial surge in various sectors, including manufacturing, healthcare, agriculture, and transportation. Nonetheless, the susceptibility of these devices to failures has emerged as a significant concern, contributing to costly periods of inactivity and diminished productivity. Consequently, the development of sophisticated and precise techniques for forecasting device failures in advance has become imperative. This research paper thoroughly investigates and analyses the most recent advancements and scholarly inquiries pertaining to the implementation of artificial intelligence methodologies, notably machine learning and deep learning, in the realm of predicting and averting IoT device failures. These AI-based approaches can be trained on extensive historical datasets, enabling the detection of distinctive patterns and anomalies that serve as potential precursors to device malfunctions. By incorporating these innovative failure prediction techniques into their operations, organizations can actively identify and address potential issues, thereby minimizing the adverse repercussions of device failures on their overall performance and functionality.",
        "affiliation_name": "Université Mohammed Premier Oujda",
        "affiliation_city": "Oujda",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Deep learning for parking spaces prediction in the context of smart and sustainable cities: a systematic literature review",
        "paper_author": "Soumana A.N.H.",
        "publication": "E3S Web of Conferences",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "The search for solutions to mitigate traffic congestion is a major challenge for densely populated cities. Studies have shown that more than 40% of traffic jams are caused by prolonged searching for parking spaces in crowded cities. Therefore, predicting the availability of parking spaces in advance is a crucial step in helping drivers quickly find free spaces and thus reduce traffic jams and their negative impacts on the environment, economy, and public health. Various approaches have been proposed to solve traffic congestion related problems. Deep learning, a technique in machine learning, has seen increasing use and has shown much effectiveness compared to other machine learning techniques for predicting parking space availability. In this study, we analyzed the use of deep learning techniques through a systematic literature review. The review process included formulating the research question, establishing search strategies, as well as data extraction and analysis. As a result, we identified four major families of deep learning techniques commonly used for predicting parking space availability. Additionally, we observed that recurrent neural networks and convolutional neural networks are the most widely used techniques.",
        "affiliation_name": "Université Ibn Zohr",
        "affiliation_city": "Agadir",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "A Method for Calibration of a Particle Concentration Measurement System with Artificial Intelligence",
        "paper_author": "Janke J.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "In history, many particle concentration measurement instruments operate by determining the mass concentration (e.g., filtering and mass determination). Therefore, the laws and rules concerning air pollution today are primarily based on the principle of mass concentration. The mass- (or volume-) concentration means how much of the particle mass (in percentage) from the total mass of the particles is in a defined size range. However, modern particle concentration measurement devices, in particular, optical devices, primarily operate by determining the number concentration (e.g., light scattering or light blockage). The number concentration indicates how many particles (in percentage) of the total number of particles are in a defined size range. These devices have a much higher sampling rate and resolution. In order to meet the legal requirements based on the mass concentration, the conversion from the number concentration to the mass concentration is necessary. Technically, such conversion would be possible assuming that all the particles have the same material density and are completely spherical in shape. However, both are not the case in most practical applications. The shape of particles usually deviates from the sphere, and their material density can differ in different size classes. In addition, humidity has an influence on the size of the particles. In this work, a machine learning approach for the calibration of particle concentration measurement system is proposed for a relatively stable particle composition from applications such as street fine dust. The novelty lies in the conversion rules from the number concentration to the mass concentration by means of a neural network. For this, the neural network must be trained with a reference device, which primarily determines the mass concentration. The proposed method enables wider adoption of optical devices for particle concentration measurement and the results are comparable with the mass concentration, used for laws and rules.",
        "affiliation_name": "Fachhochschule Osnabrück",
        "affiliation_city": "Osnabruck",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Exploring proten’s conformational space by using encoding layer supervised auto-encoder",
        "paper_author": "Chen G.L.",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Protein function is related to its structure and dynamic change. Molecular dynamics simulation is an important tool for studying protein dynamics by exploring its conformational space, however, conformational sampling is a nontrivial issue, because of the risk of missing key details during sampling. In recent years, deep learning methods, such as auto-encoder, can couple with MD to explore conformational space of protein. After being trained with the MD trajectories, auto-encoder can generate new conformations quickly by inputting random numbers in low dimension space. However, some problems still exist, such as requirements for the quality of the training set, the limitation of explorable area and the undefined sampling direction. In this work, we build a supervised auto-encoder, in which some reaction coordinates are used to guide conformational exploration along certain directions. We also try to expand the explorable area by training through the data generated by the model. Two multi-domain proteins, bacteriophage T4 lysozyme and adenylate kinase, are used to illustrate the method. In the case of the training set consisting of only under-sampled simulated trajectories, the supervised auto-encoder can still explore along the given reaction coordinates. The explored conformational space can cover all the experimental structures of the proteins and be extended to regions far from the training sets. Having been verified by molecular dynamics and secondary structure calculations, most of the conformations explored are found to be plausible. The supervised auto-encoder provides a way to efficiently expand the conformational space of a protein with limited computational resources, although some suitable reaction coordinates are required. By integrating appropriate reaction coordinates or experimental data, the supervised auto-encoder may serve as an efficient tool for exploring conformational space of proteins.",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning in molecular simulations of biomolecules",
        "paper_author": "Guan X.Y.",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Molecular simulation has already become a powerful tool for studying life principles at a molecular level. The past 50-year researches show that molecular simulation has been able to quantitatively characterize the kinetic and thermodynamic properties of complex molecular processes, such as protein folding and conformational changes. In recent years, the application of machine learning algorithms represented by deep learning has further promoted the development of molecular simulation. This work reviews machine learning methods in biomolecular simulation, focusing on the important progress made by machine learning algorithms in improving the accuracy of molecular force fields, the efficiency of molecular simulation conformation sampling, and also the processing of high-dimensional simulation data. The future researches to further overcome the bottleneck of accuracy and efficiency of molecular simulation, expand the scope of molecular simulation, and realize the integration of computational simulation and experimental based on machine learning technique is prospected.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Preface to the special topic: Machine learning in biomolecular simulations",
        "paper_author": "NA",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Progress in protein pK<inf>a</inf> prediction",
        "paper_author": "Luo F.F.",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "The pH value represents the acidity of the solution and plays a key role in many life events linked to human diseases. For instance, the β-site amyloid precursor protein cleavage enzyme, BACE1, which is a major therapeutic target of treating Alzheimer’s disease, functions within a narrow pH region around 4.5. In addition, the sodium-proton antiporter NhaA from Escherichia coli is activated only when the cytoplasmic pH is higher than 6.5 and the activity reaches a maximum value around pH 8.8. To explore the molecular mechanism of a protein regulated by pH, it is important to measure, typically by nuclear magnetic resonance, the binding affinities of protons to ionizable key residues, namely pKa values, which determine the deprotonation equilibria under a pH condition. However, wet-lab experiments are often expensive and time consuming. In some cases, owing to the structural complexity of a protein, pKa measurements become difficult, making theoretical pKa predictions in a dry laboratory more advantageous. In the past thirty years, many efforts have been made to accurately and fast predict protein pKa with physics-based methods. Theoretically, constant pH molecular dynamics (CpHMD) method that takes conformational fluctuations into account gives the most accurate predictions, especially the explicit-solvent CpHMD model proposed by Huang and coworkers (2016 J. Chem. Theory Comput. 12 5411) which in principle is applicable to any system that can be described by a force field. However, lengthy molecular simulations are usually necessary for the extensive sampling of conformation. In particular, the computational complexity increases significantly if water molecules are included explicitly in the simulation system. Thus, CpHMD is not suitable for high-throughout computing requested in industry circle. To accelerate pKa prediction, Poisson-Boltzmann (PB) or empirical equation-based schemes, such as H++ and PropKa, have been developed and widely used where pKa values are obtained via one-structure calculations. Recently, artificial intelligence (AI) is applied to the area of protein pKa prediction, which leads to the development of DeepKa by Huang laboratory (2021 ACS Omega 6 34823), the first AI-driven pKa predictor. In this paper, we review the advances in protein pKa prediction contributed mainly by CpHMD methods, PB or empirical equation-based schemes, and AI models. Notably, the modeling hypotheses explained in the review would shed light on future development of more powerful protein pKa predictors.",
        "affiliation_name": "Jimei University",
        "affiliation_city": "Xiamen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning identified genetic features associated with HIV sequences in the monocytes",
        "paper_author": "Peng X.",
        "publication": "Chinese Medical Journal",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "NA",
        "affiliation_name": "The State Key Laboratory for Diagnosis and Treatment of Infectious Diseases",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A multicenter study of the clinicopathological characteristics and a risk prediction model of early-stage breast cancer with hormone receptor-positive/human epidermal growth factor receptor 2-low expression",
        "paper_author": "Xin L.",
        "publication": "Chinese Medical Journal",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Background: In light of the significant clinical benefits of antibody-drug conjugates in clinical trials, the human epidermal growth factor receptor 2 (HER2)-low category in breast cancers has gained increasing attention. Therefore, we studied the clinicopathological characteristics of Chinese patients with hormone receptor (HR)-positive/HER2-low early-stage breast cancer and developed a recurrence risk prediction model. Methods: Female patients with HR-positive/HER2-low early-stage breast cancer treated in 29 hospitals of the Chinese Society of Breast Surgery (CSBrS) from Jan 2015 to Dec 2016 were enrolled. Their clinicopathological data and prognostic information were collected, and machine learning methods were used to analyze the prognostic factors. Results: In total, 25,096 patients were diagnosed with breast cancer in 29 hospitals of CSBrS from Jan 2015 to Dec 2016, and clinicopathological data for 6486 patients with HER2-low early-stage breast cancer were collected. Among them, 5629 patients (86.79%) were HR-positive. The median follow-up time was 57 months (4, 76 months); the 5-year disease-free survival (DFS) rate was 92.7%, and the 5-year overall survival (OS) rate was 97.7%. In total, 412 cases (7.31%) of metastasis were observed, and 124 (2.20%) patients died. Multivariate Cox regression analysis revealed that T stage, N stage, lymphovascular thrombosis, Ki-67 index, and prognostic stage were associated with recurrence and metastasis (P <0.05). A recurrence risk prediction model was established using the random forest method and exhibited a sensitivity of 81.1%, specificity of 71.7%, positive predictive value of 74.1%, and negative predictive value of 79.2%. Conclusion: Most of patients with HER2-low early-stage breast cancer were HR-positive, and patients had favorable outcome; tumor N stage, lymphovascular thrombosis, Ki-67 index, and tumor prognostic stage were prognostic factors. The HR-positive/HER2-low early-stage breast cancer recurrence prediction model established based on the random forest method has a good reference value for predicting 5-year recurrence events. Registritation: ChiCTR.org.cn, ChiCTR2100046766.",
        "affiliation_name": "Peking University First Hospital",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Computer simulation and machine learning of polymer collapse and critical adsorption phase transitions",
        "paper_author": "Luo Q.R.",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Collapse and critical adsorption of polymers are two crucial phase transitions in polymer science, both are accompanied by significant changes in polymer conformation. In this paper, Langevin dynamics and dynamic Monte Carlo methods are used to simulate the collapse and critical adsorption of polymer, respectively, and corresponding phase transition temperatures are estimated. Meanwhile, a large number of polymer conformations at different temperatures are obtained. In the machine learning method, a large number of extended random coil and collapsed spherical, desorption and adsorption conformations are used to train the neural network, so that the neural network can learn the characteristics of different states of the polymer, and it can quickly and accurately analyze the polymer conformations at different temperatures and obtain the corresponding collapse phase transition temperature and critical adsorption temperature. The results demonstrate that machine learning can correctly calculate the phase transition temperature of polymer system, which provides new ideas and methods for machine learning technology in the study of polymer phase transitions.",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Virtual screening of drugs targeting PD-L1 protein",
        "paper_author": "Lin K.D.",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Monoclonal antibody inhibitors targeting PD-1/PD-L1 immune checkpoints are gradually entering the market and have achieved certain positive effects in the treatments of various types of tumors. However, with the expansion of application, the limitations of antibody drugs and problems such as excessive homogenization of research gradually appear, making small-molecule inhibitors the new focus of researchers. This study aims to use ligand-based and structure-based binding activity prediction methods to achieve virtual screening of small-molecule inhibitors targeting PD-L1, thereby helping to accelerate the development of small molecule drugs. A dataset of PD-L1 small-molecule inhibitory activity from relevant research literature and patents is collected and activity judgment classification models with intensity prediction regression models are constructed based on different molecular featurization methods and machine learning algorithms. The two types of models filter 68 candidate compounds with high PD-L1 inhibitory activity from a large drug-like small molecule screening pool (ZINC15). Ten of these compounds not only have good drug similarities and pharmacokinetics, but also exhibit comparable binding affinities and similar mechanisms of action with previous reported hotspot compounds in molecular docking. This phenomenon is further verified in subsequent molecular dynamics simulation and the estimation of binding free energy. In this study, a virtual screening workflow integrating ligand-based method and structure-based method is developed, and potential PD-L1 small-molecule inhibitors are effectively screened from large compound databases, which is expected to help accelerate the application and expansion of tumor immunotherapy.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Transition state searching for complex biomolecules: Algorithms and machine learning",
        "paper_author": "Yang J.Y.",
        "publication": "Wuli Xuebao/Acta Physica Sinica",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Transition state is a key concept for chemists to understand and fine-tune the conformational changes of large biomolecules. Due to its short residence time, it is difficult to capture a transition state via experimental techniques. Characterizing transition states for a conformational change therefore is only achievable via physics-driven molecular dynamics simulations. However, unlike chemical reactions which involve only a small number of atoms, conformational changes of biomolecules depend on numerous atoms and therefore the number of their coordinates in our 3D space. The searching for their transition states will inevitably encounter the curse of dimensionality, i.e. the reaction coordinate problem, which invokes the invention of various algorithms for solution. Recent years, new machine learning techniques and the incorporation of some of them into the transition state searching methods emerged. Here, we first review the design principle of representative transition state searching algorithms, including the collective-variable (CV)-dependent gentlest ascent dynamics, finite temperature string, fast tomographic, travelling-salesman based automated path searching, and the CV-independent transition path sampling. Then, we focus on the new version of TPS that incorporates reinforcement learning for efficient sampling, and we also clarify the suitable situation for its application. Finally, we propose a new paradigm for transition state searching, a new dimensionality reduction technique that preserves transition state information and combines gentlest ascent dynamics.",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Combining human intelligence and machine learning for fact-checking: Towards a hybrid human-in-the-loop framework",
        "paper_author": "Barbera D.L.",
        "publication": "Intelligenza Artificiale",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Online misinformation is posing a serious threat for the modern society. Assessing the veracity of online information is a complex problem which nowadays is addressed by heavily relying on trained fact-checking experts. This solution is not scalable, and due to the importance of the problem the issue gained the attention of the scientific community, which proposed many based on Artificial Intelligence and Machine Learning methods. Despite the efforts made, the effectiveness of such approaches is not yet enough to allow them to be used without supervision. In this position paper, we propose a hybrid human-in-the-loop framework for fact-checking: we address the misinformation issue by relying on a combination of automatic Artificial Intelligence methods, crowdsourcing ones, and experts. We study the single components of the framework as well as their interactions, and we propose an interleaving of the different components which we believe will serve as a useful starting point for the future research towards effective and scalable fact-checking.",
        "affiliation_name": "Università degli Studi di Udine",
        "affiliation_city": "Udine",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Machine learning-based business risk analysis for big data: A case study of Pakistan",
        "paper_author": "Nazir M.",
        "publication": "International Journal of Computational Economics and Econometrics",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "In finance, machine learning helps the business by improving its abilities and flexibility to prevent risks, errors and to accept such challenges. This research analyses and forecasts the interest rate risk of Pakistan using machine learning models. It took a ten-year financial dataset of Pakistan investment bonds from the State Bank of Pakistan website. In this study, a framework was proposed and four different models were developed to forecast the interest rates: neural network, bootstrap aggregated regression trees, cascade-forward neural network, and radial basis neural network. Subsequently, these models were run under four different scenarios: forecasting with original, generated, LASSO extracted and weighted average features. In addition, the outcomes of these models were compared with four performance metrics: mean absolute percentage error, daily peak mean absolute percentage error, mean absolute error, and root mean square error. Overall, the results showed that radial basis neural network provided the best forecasting.",
        "affiliation_name": "Maynooth University",
        "affiliation_city": "Maynooth",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Research on the Adaptation of face Shapes and men's suit Collar types Based on PSO-LSSVM",
        "paper_author": "Zhou Y.",
        "publication": "Journal of Silk",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "Personalization is on the rise in the consumer clothing market since it enables individuals to enhance their figures by selecting outfits that complement their body types. Various garment recommendation systems have been developed, and a considerable amount of research has been conducted on garment fit. In selecting clothing, the appropriate coordination between the face and collar is important, as it improves the overall appearance. However, the current recommendations of it are primarily based on subjective experience, which could not be quantified and accurately expressed. In view of this problem, developing a model that accurately predicts face/collar compatibility makes sense. The commonly used methods for prediction are neural networks and support vector machine (SVM). Nevertheless, the predictive results of many of the methods are unsatisfactory due to the limited sample size. LSSVM is one of the improved algorithms of the standard SVM, and has unique advantages in the identification and prediction of small samples and nonlinear data. Considering the significant influence of parameter combinations on prediction abilities, PSO is frequently applied to optimize the parameters instead of determining them empirically. To investigate the complex fitness visual relationship between face shape and collar shape, we first classified facial and suit collar shapes. Facial classification was based on temporal facial index, zygomatic width index, morphological facial index and jawline. And collar classification was based on the width and shape of lapels. So male facial shapes were finally divided into 12 different types, while suit lapel shapes were divided into 20 types. On this basis, 240 experimental samples were created by using 3D virtual fitting technology for evaluating the visual fit of various face shapes and collar combinations in a questionnaire experiment. Then the PSO-LSSVM algorithm model was developed by analyzing the questionnaire experiment results. The combination of face and collar was taken as the input value of the model and the subjective visual evaluation as the output value. Additionally, the prediction model proposed was compared against PSO- RBF method to further verify the improvements achieved by this method. It is found that different face shapes fit different suit lapels: round faces are suitable for single-breasted men' s suits with normal and narrow barge head; square faces are suitable for double-breasted men' s suits with normal and wide barge head; long faces are suitable for men' s suits with normal barge head; oval faces fit all collar shapes basically; and single- breasted, low-profile suits are unsuitable for almost any face shape. Based on the results of the subjective questionnaire fit score, the PSO-LSSVM prediction model and PSO-RBF neural network model for the compatibility of male face shapes and male suit collar shapes were established respectively. The result of the PSO-LSSVM algorithm and PSO-RBF shows that the root mean square error of the PSO-LSSVM is 0. 077 6 and the average absolute error is 0. 057 3, which reduces the root mean square error by 0. 041 1 and the average absolute error by 0. 037 6 compared to the latter. It indicates that the PSO- LSSVM model has a higher prediction accuracy. We use a non-contact measurement approach to classify male facial shapes into 12 categories, providing reference for machine learning based on facial classification. Meanwhile, the framework can be reference for consumers in the selection of suits. It also offers a benchmark for companies in the marketing of new products, as well as in the area of personalization.",
        "affiliation_name": "Zhejiang Sci-Tech University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Exploring the reliability of inpatient EMR algorithms for diabetes identification",
        "paper_author": "Lee S.",
        "publication": "BMJ Health and Care Informatics",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Introduction Accurate identification of medical conditions within a real-time inpatient setting is crucial for health systems. Current inpatient comorbidity algorithms rely on integrating various sources of administrative data, but at times, there is a considerable lag in obtaining and linking these data. Our study objective was to develop electronic medical records (EMR) data-based inpatient diabetes phenotyping algorithms. Materials and methods A chart review on 3040 individuals was completed, and 583 had diabetes. We linked EMR data on these individuals to the International Classification of Disease (ICD) administrative databases. The following EMR-data-based diabetes algorithms were developed: (1) laboratory data, (2) medication data, (3) laboratory and medications data, (4) diabetes concept keywords and (5) diabetes free-text algorithm. Combined algorithms used or statements between the above algorithms. Algorithm performances were measured using chart review as a gold standard. We determined the best-performing algorithm as the one that showed the high performance of sensitivity (SN), and positive predictive value (PPV). Results The algorithms tested generally performed well: ICD-coded data, SN 0.84, specificity (SP) 0.98, PPV 0.93 and negative predictive value (NPV) 0.96; medication and laboratory algorithm, SN 0.90, SP 0.95, PPV 0.80 and NPV 0.97; all document types algorithm, SN 0.95, SP 0.98, PPV 0.94 and NPV 0.99. Discussion Free-text data-based diabetes algorithm can yield comparable or superior performance to a commonly used ICD-coded algorithm and could supplement existing methods. These types of inpatient EMR-based algorithms for case identification may become a key method for timely resource planning and care delivery.",
        "affiliation_name": "Alberta Health Services",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Structure Seer - a machine learning model for chemical structure elucidation from node labelling of a molecular graph",
        "paper_author": "Sapegin D.A.",
        "publication": "Digital Discovery",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "The identification of a compound's chemical structure remains one of the most crucial everyday tasks in chemistry. Among the vast range of existing analytical techniques NMR spectroscopy remains one of the most powerful tools. As a step towards structure prediction from experimental NMR spectra, this article introduces a novel machine-learning (ML) Structure Seer model that is designed to provide a quantitative probabilistic prediction on the connectivity of the atoms based on the information on the elemental composition of the molecule along with a list of atom-attributed isotropic shielding constants, obtained via quantum chemical methods based on a Hartree-Fock calculation. The utilization of shielding constants in the approach instead of NMR chemical shifts helps overcome challenges linked to the relatively limited sizes of datasets comprising reliably measured spectra. Additionally, our approach holds significant potential for scalability, as it can harness vast amounts of information on known chemical structures for the model's learning process. A comprehensive evaluation of the model trained on the QM9 and custom dataset derived from the PubChem database was conducted. The trained model was demonstrated to have the capability of accurately predicting up to 100% of the bonds for selected compounds from the QM9 dataset, achieving an impressive average accuracy rate of 37.5% for predicted bonds in the test fold. The application of the model to the tasks of NMR peak attribution, structure prediction and identification is discussed, along with prospective strategies of prediction interpretation, such as similarity searches and ranking of isomeric structures.",
        "affiliation_name": "Kingston University",
        "affiliation_city": "Kingston Upon Thames",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Unveiling practical considerations for reliable and standardized SERS measurements: lessons from a comprehensive review of oblique angle deposition-fabricated silver nanorod array substrates",
        "paper_author": "Zhao Y.",
        "publication": "Chemical Society Reviews",
        "citied_by": "22",
        "cover_date": "2023-12-20",
        "Abstract": "Recently, there has been an exponential growth in the number of publications focusing on surface-enhanced Raman scattering (SERS), primarily driven by advancements in nanotechnology and the increasing demand for chemical and biological detection. While many of these publications have focused on the development of new substrates and detection-based applications, there is a noticeable lack of attention given to various practical issues related to SERS measurements and detection. This review aims to fill this gap by utilizing silver nanorod (AgNR) SERS substrates fabricated through the oblique angle deposition method as an illustrative example. The review highlights and addresses a range of practical issues associated with SERS measurements and detection. These include the optimization of SERS substrates in terms of morphology and structural design, considerations for measurement configurations such as polarization and the incident angle of the excitation laser, and exploration of enhancement mechanisms encompassing both intrinsic properties induced by the structure and materials, as well as extrinsic factors arising from wetting/dewetting phenomena and analyte size. The manufacturing and storage aspects of SERS substrates, including scalable fabrication techniques, contamination control, cleaning procedures, and appropriate storage methods, are also discussed. Furthermore, the review delves into device design considerations, such as well arrays, flow cells, and fiber probes, and explores various sample preparation methods such as drop-cast and immersion. Measurement issues, including the effect of excitation laser wavelength and power, as well as the influence of buffer, are thoroughly examined. Additionally, the review discusses spectral analysis techniques, encompassing baseline removal, chemometric analysis, and machine learning approaches. The wide range of AgNR-based applications of SERS, across various fields, is also explored. Throughout the comprehensive review, key lessons learned from collective findings are outlined and analyzed, particularly in the context of detailed SERS measurements and standardization. The review also provides insights into future challenges and perspectives in the field of SERS. It is our hope that this comprehensive review will serve as a valuable reference for researchers seeking to embark on in-depth studies and applications involving their own SERS substrates.",
        "affiliation_name": "University of Georgia College of Engineering",
        "affiliation_city": "Athens",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "What's New in Musculoskeletal Tumor Surgery",
        "paper_author": "Gazendam A.",
        "publication": "Journal of Bone and Joint Surgery",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "NA",
        "affiliation_name": "McMaster University",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine learning analysis of the T cell receptor repertoire identifies sequence features of self-reactivity",
        "paper_author": "Textor J.",
        "publication": "Cell Systems",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "The T cell receptor (TCR) determines specificity and affinity for both foreign and self-peptides presented by the major histocompatibility complex (MHC). Although the strength of TCR interactions with self-pMHC impacts T cell function, it has been challenging to identify TCR sequence features that predict T cell fate. To discern patterns distinguishing TCRs from naive CD4+ T cells with low versus high self-reactivity, we used data from 42 mice to train a machine learning (ML) algorithm that identifies population-level differences between TCRβ sequence sets. This approach revealed that weakly self-reactive T cell populations were enriched for longer CDR3β regions and acidic amino acids. We tested our ML predictions of self-reactivity using retrogenic mice with fixed TCRβ sequences. Extrapolating our analyses to independent datasets, we predicted high self-reactivity for regulatory T cells and slightly reduced self-reactivity for T cells responding to chronic infections. Our analyses suggest a potential trade-off between TCR repertoire diversity and self-reactivity. A record of this paper's transparent peer review process is included in the supplemental information.",
        "affiliation_name": "McGill University Research Centre on Complex Traits",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Deep learning and CRISPR-Cas13d ortholog discovery for optimized RNA targeting",
        "paper_author": "Wei J.",
        "publication": "Cell Systems",
        "citied_by": "13",
        "cover_date": "2023-12-20",
        "Abstract": "Effective and precise mammalian transcriptome engineering technologies are needed to accelerate biological discovery and RNA therapeutics. Despite the promise of programmable CRISPR-Cas13 ribonucleases, their utility has been hampered by an incomplete understanding of guide RNA design rules and cellular toxicity resulting from off-target or collateral RNA cleavage. Here, we quantified the performance of over 127,000 RfxCas13d (CasRx) guide RNAs and systematically evaluated seven machine learning models to build a guide efficiency prediction algorithm orthogonally validated across multiple human cell types. Deep learning model interpretation revealed preferred sequence motifs and secondary features for highly efficient guides. We next identified and screened 46 novel Cas13d orthologs, finding that DjCas13d achieves low cellular toxicity and high specificity—even when targeting abundant transcripts in sensitive cell types, including stem cells and neurons. Our Cas13d guide efficiency model was successfully generalized to DjCas13d, illustrating the power of combining machine learning with ortholog discovery to advance RNA targeting in human cells.",
        "affiliation_name": "Innovative Genomics Institute",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Printed High-Adhesion Flexible Electrodes Based on an Interlocking Structure for Self-Powered Intelligent Movement Monitoring",
        "paper_author": "Huang K.",
        "publication": "ACS Applied Materials and Interfaces",
        "citied_by": "6",
        "cover_date": "2023-12-20",
        "Abstract": "Two-dimensional transition metal carbide nitrides (MXenes) have been extensively explored in diverse areas, such as electrochemical energy storage and flexible electronics. Although the solution-processed MXene-based device has made significant achievements, it is still a challenge to develop large-scale and high-resolution printing methods for flexible printed electronics. In this work, we reported a novel strategy of a porous interlocking structure to obtain flexible MXene/laser-induced graphene (LMX) composite electrodes with enhanced adhesion and high printing resolution. In comparison to traditional printed MXene electrodes, the LMX electrode with an interlocking interface possesses enhanced mechanical properties (adhesive strength of 2.17 MPa) and comparable electrical properties (0.68 S/mm). Furthermore, owing to the outstanding stability and flexibility, the LMX-based triboelectric nanogenerator (TENG) can be used as a self-powered sensor to monitor finger-bending movement. A support vector machine (SVM)-assisted self-powered motion sensor can distinguish the bending angle with high recognition accuracy and can effectively identify different angles. The successful experience of directly printing flexible electrodes with excellent mechanical and electrical properties can be promoted to other solution-processed two-dimensional materials. Our strategy opens up a promising perspective to develop flexible and printed electronics.",
        "affiliation_name": "Minjiang University",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Computationally Designed Molecules Modulate ALS-Related Amyloidogenic TDP-43<inf>307-319</inf> Aggregation",
        "paper_author": "Liu X.",
        "publication": "ACS Chemical Neuroscience",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Abnormal cytosolic aggregation of TAR DNA-binding protein of 43 kDa (TDP-43) is observed in multiple diseases, including amyotrophic lateral sclerosis (ALS), frontotemporal lobar degeneration, and Alzheimer’s disease. Previous studies have shown that TDP-43307-319 located at the C-terminal of TDP-43 can form higher-order oligomers and fibrils. Of particular interest are the hexamers that adopt a cylindrin structure that has been strongly correlated to neurotoxicity. In this study, we use the joint pharmacophore space (JPS) model to identify and generate potential TDP-43 inhibitors. Five JPS-designed molecules are evaluated using both experimental and computational methods: ion mobility mass spectrometry, thioflavin T fluorescence assay, circular dichroism spectroscopy, atomic force microscopy, and molecular dynamics simulations. We found that all five molecules can prevent the amyloid fibril formation of TDP-43307-319, but their efficacy varies significantly. Furthermore, among the five molecules, [AC0101] is the most efficient in preventing the formation of higher-order oligomers and dissociating preformed higher-order oligomers. Molecular dynamics simulations show that [AC0101] both is the most flexible and forms the most hydrogen bonds with the TDP-43307-319 monomer. The JPS-designed molecules can insert themselves between the β-strands in the hexameric cylindrin structure of TDP-43307-319 and can open its structure. Possible mechanisms for JPS-designed molecules to inhibit and dissociate TDP-43307-319 oligomers on an atomistic scale are proposed.",
        "affiliation_name": "UC Santa Barbara College of Engineering",
        "affiliation_city": "Santa Barbara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances in ligand-specific biosensing for structurally similar molecules",
        "paper_author": "Xi C.",
        "publication": "Cell Systems",
        "citied_by": "3",
        "cover_date": "2023-12-20",
        "Abstract": "The specificity of biological systems makes it possible to develop biosensors targeting specific metabolites, toxins, and pollutants in complex medical or environmental samples without interference from structurally similar compounds. For the last two decades, great efforts have been devoted to creating proteins or nucleic acids with novel properties through synthetic biology strategies. Beyond augmenting biocatalytic activity, expanding target substrate scopes, and enhancing enzymes' enantioselectivity and stability, an increasing research area is the enhancement of molecular specificity for genetically encoded biosensors. Here, we summarize recent advances in the development of highly specific biosensor systems and their essential applications. First, we describe the rational design principles required to create libraries containing potential mutants with less promiscuity or better specificity. Next, we review the emerging high-throughput screening techniques to engineer biosensing specificity for the desired target. Finally, we examine the computer-aided evaluation and prediction methods to facilitate the construction of ligand-specific biosensors.",
        "affiliation_name": "McKelvey School of Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Amorphous Chloride Solid Electrolytes with High Li-Ion Conductivity for Stable Cycling of All-Solid-State High-Nickel Cathodes",
        "paper_author": "Li F.",
        "publication": "Journal of the American Chemical Society",
        "citied_by": "30",
        "cover_date": "2023-12-20",
        "Abstract": "Solid electrolytes (SEs) are central components that enable high-performance, all-solid-state lithium batteries (ASSLBs). Amorphous SEs hold great potential for ASSLBs because their grain-boundary-free characteristics facilitate intact solid-solid contact and uniform Li-ion conduction for high-performance cathodes. However, amorphous oxide SEs with limited ionic conductivities and glassy sulfide SEs with narrow electrochemical windows cannot sustain high-nickel cathodes. Herein, we report a class of amorphous Li-Ta-Cl-based chloride SEs possessing high Li-ion conductivity (up to 7.16 mS cm-1) and low Young’s modulus (approximately 3 GPa) to enable excellent Li-ion conduction and intact physical contact among rigid components in ASSLBs. We reveal that the amorphous Li-Ta-Cl matrix is composed of LiCl43-, LiCl54-, LiCl65- polyhedra, and TaCl6- octahedra via machine-learning simulation, solid-state 7Li nuclear magnetic resonance, and X-ray absorption analysis. Attractively, our amorphous chloride SEs exhibit excellent compatibility with high-nickel cathodes. We demonstrate that ASSLBs comprising amorphous chloride SEs and high-nickel single-crystal cathodes (LiNi0.88Co0.07Mn0.05O2) exhibit ∼99% capacity retention after 800 cycles at ∼3 C under 1 mA h cm-2 and ∼80% capacity retention after 75 cycles at 0.2 C under a high areal capacity of 5 mA h cm-2. Most importantly, a stable operation of up to 9800 cycles with a capacity retention of ∼77% at a high rate of 3.4 C can be achieved in a freezing environment of −10 °C. Our amorphous chloride SEs will pave the way to realize high-performance high-nickel cathodes for high-energy-density ASSLBs.",
        "affiliation_name": "CAS Key Laboratory of Materials for Energy Conversion",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Active Learning Guided Computational Discovery of Plant-Based Redoxmers for Organic Nonaqueous Redox Flow Batteries",
        "paper_author": "Jain A.",
        "publication": "ACS Applied Materials and Interfaces",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Organic nonaqueous redox flow batteries (O-NRFBs) are promising energy storage devices due to their scalability and reliance on sourceable materials. However, finding suitable redox-active organic molecules (redoxmers) for these batteries remains a challenge. Using plant-based compounds as precursors for these redoxmers can decrease their costs and environmental toxicity. In this computational study, flavonoid molecules have been examined as potential redoxmers for O-NRFBs. Flavone and isoflavone derivatives were selected as catholyte (positive charge carrier) and anolyte (negative charge carrier) molecules, respectively. To drive their redox potentials to the opposite extremes, in silico derivatization was performed using a novel algorithm to generate a library of > 40000 candidate molecules that penalizes overly complex structures. A multiobjective Bayesian optimization based active learning algorithm was then used to identify best redoxmer candidates in these search spaces. Our study provides methodologies for molecular design and optimization of natural scaffolds and highlights the need of incorporating expert chemistry awareness of the natural products and the basic rules of synthetic chemistry in machine learning.",
        "affiliation_name": "Argonne National Laboratory",
        "affiliation_city": "Lemont",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Landslide susceptibility assessment in multiple urban slope settings with a landslide inventory augmented by InSAR techniques",
        "paper_author": "Chen L.",
        "publication": "Engineering Geology",
        "citied_by": "16",
        "cover_date": "2023-12-20",
        "Abstract": "Landslide susceptibility assessment (LSA) evaluates the likelihood of landslide occurrences and can help mitigate and prevent landslide risks. Recently, there have been vast applications of data-driven LSA methods owing to the increased availability of high-quality satellite data and landslide inventories. However, two issues remain to be addressed, as follows: (a) Items in a landslide inventory are mainly historical landslides from the interpretation of optical images and site investigation, resulting in predictive models trained with these items being insensitive to undetectable slope movements, such as slow-moving landslides that have not yet occurred; (b) Most study areas contain a variety of landslide-prone geographical settings that a single model can not accommodate well. Considering the complex landslide causes in Hong Kong with a land area of approximately 1108 km2, we proposed the utilization of multi-temporal InSAR techniques to generate weak landslide samples from slopes with ground surface movements for landslide inventory augmentation; and meta-learn intermediate representations for the fast adaptation of LSA models corresponding to different landslide-prone geographical settings. Besides, we performed feature permutation to identify dominant landslide-predisposing factors. The LSA results in Hong Kong revealed that slope deformation in several mountainous areas is closely associated with the occurrence of recorded landslides. By augmenting the landslide inventory using InSAR techniques, the proposed method enhanced the LSA models' capacity to identify slow-moving landslides and achieved better statistical performance. The discussion highlights that slope and stream power index (SPI) are the key landslide-predisposing factors in Hong Kong, but the dominant landslide-predisposing factors will vary under different geographical conditions. By comparison with the methods that treat LSA as a binary classification problem, such as support vector machine, multilayer perceptron, deep belief network, and random forest based LSA methods, the proposed method entails a fast-learning strategy and outperforms these methods in data-driven model evaluation indicators, e.g., by 3–6% in accuracy, 2–6% in precision, 1–2% in recall, 3–5% in F1-score, and approximately 10% in Cohen Kappa. The information about the relative importance of landslide predisposing factors, derived through feature permutation, can foster guidance for targeted landslide prevention schemes, such as constructing and maintaining slope consolidation facilities in areas where slope is the dominant landslide-predisposing factor.",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Seismogenic structures and earthquake mechanisms in the Changning area, China: Insights from seismicity and tomography",
        "paper_author": "Zhao Y.",
        "publication": "Tectonophysics",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "The Changning area, located in southwestern Sichuan Basin, China, was previously known to be a seismically inactive region. However, in recent years, the region has experienced an increase in the rate of seismic activity. To gain a better understanding of the seismogenic structures and earthquake mechanisms in the region, we deployed 298 short-period seismic stations and collected 47 days of continuous waveform data following the 2019 Ms 6.0 Changning earthquake. Using a machine-learning-based earthquake location workflow (LOC-FLOW; Zhang et al., 2022), we detected and located over 60,000 seismic events. These events were then used for three-dimensional Vp and Vs inversion using a double-difference tomography method (tomoDD). The results show that the earthquake distribution has distinct zoning characteristics with different mechanisms. In the Changning-Shuanghe anticline, most earthquakes are distributed in areas with large velocity and Vp/Vs gradients, typically occurring in regions with high velocity and low Vp/Vs, where tectonic stresses are prone to accumulate. Long-term water injections may promote fault activation in the southeast of Changning anticline. Earthquakes around the salt mining well were found to occur in sedimentary cover, indicating that the basement fault has not been activated but rather acts as a fluid-flowing path. In the Changning shale gas block, earthquakes showed different triggering mechanisms, accompanied by different velocity characteristics. The spatial variations in earthquake locations and velocity characteristics can be explained by the terrain at shallow depths, syncline structures, and the distribution of fluids and gas reservoirs. Our study provides new insights into the detailed seismogenic structures and earthquake mechanisms in the Changning area. These findings can be used to improve earthquake hazard assessment in the region.",
        "affiliation_name": "Geological Survey of Japan",
        "affiliation_city": "Tsukuba",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "FlexiPulse: A machine-learning-enabled flexible pulse sensor for cardiovascular disease diagnostics",
        "paper_author": "Ma Z.",
        "publication": "Cell Reports Physical Science",
        "citied_by": "15",
        "cover_date": "2023-12-20",
        "Abstract": "Recently, the flexible pulse sensor has emerged as a promising candidate for real-time and population-wide monitoring of cardiovascular health. However, most current technologies are prohibitively expensive, lack clinical validation, or are not designed to diagnose cardiovascular disease (CVD) events. Here, we present the development of FlexiPulse, a low-cost, clinically validated, intelligent, flexible pulse detection system for CVD monitoring and diagnostics. The porous graphene-based FlexiPulse is prepared by eco-friendly and economical laser direct-engraving techniques and is feasible for mass production. FlexiPulse achieves high accuracy (>93%), as confirmed by clinical techniques, enabling it to precisely detect subtle changes in cardiovascular status. Furthermore, incorporating machine-learning algorithms in FlexiPulse allows it to perform independent clinical assessments of actual CVD events, including atrial fibrillation and atrial septal defect, with an average accuracy of 98.7%. We believe that FlexiPulse has the potential to promote remote monitoring and in-home care, thereby advancing precision medicine and personalized healthcare significantly.",
        "affiliation_name": "Prince of Wales Hospital Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "A Robust Voice Pathology Detection System Based on the Combined BiLSTM–CNN Architecture",
        "paper_author": "Amami R.",
        "publication": "Mendel",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "Voice recognition systems have become increasingly important in recent years due to the growing need for more efficient and intuitive human-machine interfaces. The use of Hybrid LSTM networks and deep learning has been very successful in improving speech detection systems. The aim of this paper is to develop a novel approach for the detection of voice pathologies using a hybrid deep learning model that combines the Bidirectional Long Short-Term Memory (BiLSTM) and the Convolutional Neural Network (CNN) architectures. The proposed model uses a combination of temporal and spectral features extracted from speech signals to detect the different types of voice pathologies. The performance of the proposed detection model is evaluated on a publicly available dataset of speech signals from individuals with various voice pathologies(MEEI database). The experimental results showed that the hybrid BiLSTM-CNN model outperforms several classifiers by achieving an accuracy of 98.86%. The proposed model has the potential to assist health care professionals in the accurate diagnosis and treatment of voice pathologies, and improving the quality of life for affected individuals.",
        "affiliation_name": "Faculty of Science",
        "affiliation_city": "Zagazig",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Combining transformer-based model and GCN to predict ICD codes from clinical records",
        "paper_author": "Lu P.",
        "publication": "Knowledge-Based Systems",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Automatic International Classification of Diseases (ICD) coding is a method of automatically classifying diseases through a computer program based on rules of etiology and clinical presentation, and representing them through codes, which are widely used to assist in medical reimbursement and reporting of patient health status. With the application of machine learning and deep learning, the accuracy of automatic ICD coding methods has improved considerably. However, this has been accompanied by problems such as insufficient pre-training of text in the models and increased computational complexity along with improved prediction accuracy. In this work we propose an approach called TF-GCN to counter this problem. Firstly, a more accurate and concise feature representation is obtained by feature extraction of both clinical records and ICD codes through the transformer-based model. Secondly, the node features, document features, and relationships between them in the obtained clinical records are input to the GCN for training. Next, a pseudo labeling attention mechanism is added to eliminate the noise generated in the feature extraction process. Finally, the features of the clinical records are compared with the features of the ICD codes for similarity to obtain the classification results. This can not only reduce computational redundancy, but also obtain more accurate classification features. In the real-world MIMIC-III dataset, we compare the proposed algorithm with 11 automatic ICD coding methods to validate the performance of TF-GCN. According to experimental findings, our suggested strategy outperforms the standard evaluation metrics Mif (0.589), MiAUC (0.989), and P@8 (0.758).",
        "affiliation_name": "Lanzhou University of Technology",
        "affiliation_city": "Lanzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Generative adversarial mediation network: A novel generative learning approach to causal mediation analysis",
        "paper_author": "Zhang J.",
        "publication": "Knowledge-Based Systems",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "Casual mediation analysis (CMA) plays an essential role in various fields of social sciences. However, traditional models have restrictive parametric settings and strong random assumptions, which can be inflexible due to general nonlinearity, heterogeneity, and complex noise effects in many applications. Motivated by the similarities between the CMA and image-to-image translation that were thought to be unrelated initially, this paper proposes a novel prototype called the Generative Adversarial Mediation Network (GAMN), to explore the generative learning approach in the context of CMA. Thanks to a new encoding scheme for random terms, carefully designed partially linear architecture and inherent advantages of the generative learning framework, GAMN can flexibly handle nonlinear covariate effects and effectively model complex noise and heterogeneous mediating mechanisms with minimal model assumptions. Thus, when encountering intricate data patterns, the counterfactuals relating to treatment effects in CMA can be efficiently inferred, providing more promising mediation results. Experiments conducted on both synthetic and realistic datasets demonstrate that, compared with state-of-the-arts, GAMN can achieve notably more accurate estimations of out-of-sample predictions and treatment/mediation effects, which further illustrate the utility and advantages of our method. With the novel reinterpretations and solid theoretical results, this study also substantially broadens insights into developing mediation models from a machine-learning perspective.",
        "affiliation_name": "Zhongnan University of Economics and Law",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Parallel encoder–decoder framework for image captioning",
        "paper_author": "Saeidimesineh R.",
        "publication": "Knowledge-Based Systems",
        "citied_by": "5",
        "cover_date": "2023-12-20",
        "Abstract": "Recent progress in deep learning has led to successful utilization of encoder–decoder frameworks inspired by machine translation in image captioning models. The stacking of layers in encoders and decoders has made it possible to use several modules in encoders and decoders. However, just one type of module in encoder or decoder has been used in stacked models. In this research, we propose a parallel encoder–decoder framework that aims to take advantage of multiple of types modules in encoders and decoders, simultaneously. This framework contains augmented parallel blocks, which include stacking modules or non-stacked ones. Then, the results of the blocks are integrated to extract higher-level semantic concepts. This general idea is not limited to image captioning and can be customized for many applications that utilize encoder–decoder frameworks. We evaluated our proposed method on the MS-COCO dataset and achieved state-of-the-art results. We got 149.92 for CIDEr-D metric outperforming state-of-the-art image captioning models.",
        "affiliation_name": "University of Isfahan",
        "affiliation_city": "Isfahan",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Investigating correlations between physical properties and fire suppression performance of fluorinated and fluorine-free foams using a novel firefighting foam database",
        "paper_author": "Sudol P.E.",
        "publication": "Colloids and Surfaces A: Physicochemical and Engineering Aspects",
        "citied_by": "8",
        "cover_date": "2023-12-20",
        "Abstract": "Aqueous film-forming foams (AFFF) contain fluorinated surfactants, a class of perfluoroalkyl substances (PFAS) which have been shown to cause damage to the environment and human health. This has necessitated their replacement on military sites by the year 2024. But to date, no fluorine-free replacement firefighting formulation has showed comparable performance to AFFF. Fire extinction performance is measured in tandem with formulation physical properties, but whether various physical properties and fire suppression are correlated is poorly understood. Herein, we present the curation of a large amount of physical property and fire suppression data collected in-house. Chemometric regression was used to ascertain correlations between the critical micelle concentration (CMC) of both individual surfactant solutions and multi-component formulations and their corresponding (1) solution surface tension, (2) interfacial tension with heptane, and (3) fuel-induced foam degradation using heptane and (4) gasoline. After evaluating several algorithms, promising correlations are found between CMC and foam degradation on heptane and gasoline using locally weighted regression (LWR), as indicated by a large R2 of cross-validation (R2CV) from ∼0.6–0.9. Solutions with CMCs from ∼0.01–0.1 wt percent (%) exhibit the longest degradation times, whereas solutions with CMCs outside of this range had considerably faster degradation. This correlation is new but explains only 90% or less of the variation in the data partly because foam degradation is induced by fuel, which the CMC does not consider. However, this work will serve as a basis for future machine learning endeavors to predict fire suppression performance based on chemical structure.",
        "affiliation_name": "U.S. Naval Research Laboratory",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Calibrating machine learning approaches for probability estimation: A comprehensive comparison",
        "paper_author": "Ojeda F.M.",
        "publication": "Statistics in Medicine",
        "citied_by": "8",
        "cover_date": "2023-12-20",
        "Abstract": "Statistical prediction models have gained popularity in applied research. One challenge is the transfer of the prediction model to a different population which may be structurally different from the model for which it has been developed. An adaptation to the new population can be achieved by calibrating the model to the characteristics of the target population, for which numerous calibration techniques exist. In view of this diversity, we performed a systematic evaluation of various popular calibration approaches used by the statistical and the machine learning communities for estimating two-class probabilities. In this work, we first provide a review of the literature and, second, present the results of a comprehensive simulation study. The calibration approaches are compared with respect to their empirical properties and relationships, their ability to generalize precise probability estimates to external populations and their availability in terms of easy-to-use software implementations. Third, we provide code from real data analysis allowing its application by researchers. Logistic calibration and beta calibration, which estimate an intercept plus one and two slope parameters, respectively, consistently showed the best results in the simulation studies. Calibration on logit transformed probability estimates generally outperformed calibration methods on nontransformed estimates. In case of structural differences between training and validation data, re-estimation of the entire prediction model should be outweighted against sample size of the validation data. We recommend regression-based calibration approaches using transformed probability estimates, where at least one slope is estimated in addition to an intercept for updating probability estimates in validation studies.",
        "affiliation_name": "Universitäre Herz- und Gefäßzentrum UKE Hamburg GmbH",
        "affiliation_city": "Hamburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A multi-method approach with machine learning to evaluating the distribution and intensity of prehistoric land use in Eastern Iberia",
        "paper_author": "Cegielski W.",
        "publication": "Quaternary International",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "The present study seeks to better understand the coupling of social and biophysical systems during the late Pleistocene and Holocene, a period characterized by changing interglacial conditions as well as human population expansion and intensified ecosystem management. The approach consists of a combination of patch-based archaeological survey methods, sediment column sampling for paleoenvironmental data, geospatial analysis, and machine learning for chronological unmixing, allowing the systematic evaluation of the distribution and intensity of prehistoric land use in the study area of eastern Mediterranean Iberia. Occupational and Land Use Intensity maps developed from continuous distributions of surface artifacts as well as a summed probability density curve developed from 14C dates indicate low but steady human presence in the study area during the Middle Paleolithic and Upper Paleolithic with a marked decrease of human presence across the Pleistocene/Holocene boundary. The Early (and Middle) Neolithic saw the most ubiquitous and intensive occupation of the study area followed by a significant decline during the Late Neolithic/Chalcolithic. The charcoal analysis also supports this pattern. Early Neolithic farming strategies may not have been damaging initially during the climatic regime of the Early Holocene but exacerbated the impacts of higher temperatures and summer droughts, with a loss of the most productive farmland, seen at the onset of the Late Neolithic. Similar boom-bust population trends have been documented throughout Europe during these same time spans and may indicate a recursive interaction or “coupling” between global and regional climate events and human land use strategies.",
        "affiliation_name": "University of Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A machine learning method for prediction of remaining useful life of supercapacitors with multi-stage modification",
        "paper_author": "Guo F.",
        "publication": "Journal of Energy Storage",
        "citied_by": "10",
        "cover_date": "2023-12-20",
        "Abstract": "Stable and accurate prediction of the remaining useful life (RUL) of supercapacitors is of great significance for the safe operation and economic maximization of the energy storage system based on supercapacitors. For the phenomenon of unstable discharge capacity of supercapacitor during the cycling, a multi-stage (MS) prediction model based on empirical mode decomposition (EMD) and gated recurrent unit (GRU) neural network is proposed. The prediction model is based on multi-feature inputs with high correlation, and the final output is obtained through EMD reconstruction. The modification process ensures the stability of the model to predict the discharge capacity during the cycling of the supercapacitor. Compared with the traditional seven prediction models, the root mean square error is reduced by 80 %, and the goodness of fit is increased by 6 %. Our method has higher stability and prediction accuracy, while satisfying the high compatibility between the features and models, and provides a feasible strategy for the application of supercapacitors in energy storage systems.",
        "affiliation_name": "Hunan Agricultural University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Explainable machine learning to uncover hydrogen diffusion mechanism in clinopyroxene",
        "paper_author": "Li A.",
        "publication": "Chemical Geology",
        "citied_by": "3",
        "cover_date": "2023-12-20",
        "Abstract": "Estimating the water content of mantle-derived magma using clinopyroxene (cpx) phenocrysts serves as a valuable constraint on the water budget in deep Earth. Intricate magma processes and the high hydrogen diffusion rate necessitate careful evaluations of whether the water content in cpx preserves its original state. Machine learning (ML) has been utilized to develop a classifier for judging hydrogen diffusion in cpx. Nevertheless, the opaqueness and complexity of most ML models hinder a clear understanding of their classification principles. To elucidate the mechanistic basis of the ML model, the Shapley theory is integrated to determine the contributions of major elements of cpx as features in a linear additive manner. This study achieves superior classification performance using an extreme gradient boosting model and innovatively presents a quantitative evaluation of feature importance at the sample level for each observation. The results indicate that Na plays a predominant role in the diffusion process surpassing other major elements and its associated hydrogen can easily diffuse out of cpx. Our model also identifies various hydrogen association modes in different elemental compositions and puts constraints on the properties of incorporated hydrogen with non-lattice forming elements in cpx. The findings demonstrate that the application of explainable ML methods in mineralogy holds significant potential for advancing the comprehension of geological phenomena.",
        "affiliation_name": "School of Earth Sciences, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Design approaches for Li-ion battery packs: A review",
        "paper_author": "Cicconi P.",
        "publication": "Journal of Energy Storage",
        "citied_by": "12",
        "cover_date": "2023-12-20",
        "Abstract": "Nowadays, battery design must be considered a multi-disciplinary activity focused on product sustainability in terms of environmental impacts and cost. The paper reviews the design tools and methods in the context of Li-ion battery packs. The discussion focuses on different aspects, from thermal analysis to management and safety. The paper aims to investigate what has been achieved in the last twenty years to understand current and future trends when designing battery packs. The goal is to analyze the methods for defining the battery pack's layout and structure using tools for modeling, simulations, life cycle analysis, optimization, and machine learning. The target concerns electric and hybrid vehicles and energy storage systems in general. The paper makes an original classification of past works defining seven levels of design approaches for battery packs. The final discussion analyzes the correlation between the changes in the design methods and the increasing demand for battery packs. The outcome of this paper allows the reader to analyze the evolutions of the design methods and practices in battery packs and to understand future developments.",
        "affiliation_name": "Università degli Studi Roma Tre",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Land surface and air temperature dynamics: The role of urban form and seasonality",
        "paper_author": "Naserikia M.",
        "publication": "Science of the Total Environment",
        "citied_by": "32",
        "cover_date": "2023-12-20",
        "Abstract": "Due to the scarcity of air temperature (Ta) observations, urban heat studies often rely on satellite-derived Land Surface Temperature (LST) to characterise the near-surface thermal environment. However, there remains a lack of a quantitative understanding on how LST differs from Ta within urban areas and what are the controlling factors of their interaction. We use crowdsourced air temperature measurements in Sydney, Australia, combined with urban landscape data, Local Climate Zones (LCZ), high-resolution satellite imagery, and machine learning to explore the influence of urban form and fabric on the interaction between Ta and LST. Results show that LST and Ta have distinct spatiotemporal characteristics, and their relationship differs by season, ecological infrastructure, and building morphology. We found greater seasonal variability in LST compared to Ta, along with more pronounced intra-urban spatial variability in LST, particularly in warmer seasons. We also observed a greater temperature difference between LST and Ta in the built environment compared to the natural LCZs, especially during warm days. Natural LCZs (areas with mostly dense and scattered trees) showed stronger LST-Ta relationships compared to built areas. In particular, we observe that built areas with higher building density (where the heat vulnerability is likely more pronounced) show insignificant or negative relationships between LST- Ta in summer. Our results also indicate that surface cover, distance from the ocean, and seasonality significantly influence the distribution of hot and cold spots for LST and Ta. The spatial distribution for Ta hot spots does not always overlap with LST. We find that relying solely on LST as a direct proxy for the urban thermal environment is inappropriate, particularly in densely built-up areas and during warm seasons. These findings provide new perspectives on the relationship between surface and canopy temperatures and how these relate to urban form and fabric.",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Revisiting the dynamics of gaseous ammonia and ammonium aerosols during the COVID-19 lockdown in urban Beijing using machine learning models",
        "paper_author": "Lyu Y.",
        "publication": "Science of the Total Environment",
        "citied_by": "3",
        "cover_date": "2023-12-20",
        "Abstract": "The concentration of atmospheric ammonia (NH3) in urban Beijing substantially decreased during the COVID-19 lockdown (24 January to 3 March 2020), likely due to the reduced human activities. However, quantifying the impact of anthropogenic interventions on NH3 dynamics is challenging, as both meteorology and chemistry mask the real changes in observed NH3 concentrations. Here, we applied machine learning techniques based on random forest models to decouple the impacts of meteorology and emission changes on the gaseous NH3 and ammonium aerosol (NH4+) concentrations in Beijing during the lockdown. Our results showed that the meteorological conditions were unfavorable during the lockdown and tended to cause an increase of 8.4 % in the NH3 concentration. In addition, significant reductions in NOx and SO2 emissions could also elevate NH3 concentrations by favoring NH3 gas-phase partitioning. However, the observed NH3 concentration significantly decreased by 35.9 % during the lockdown, indicating a significant reduction in emissions or enhanced chemical sinks. Rapid gas-to-particle conversion was indeed found during the lockdown. Thus, the observed reduced NH3 concentrations could be partially explained by the enhanced transformation into NH4+. Therefore, the sum of NH3 and NH4+ (collectively, NHx) is a more reliable tracer than NH3 or NH4+ alone to estimate the changes in NH3 emissions. Compared to that under the scenario without lockdowns, the NHx concentration decreased by 26.4 %. We considered that this decrease represents the real decrease in NH3 emissions in Beijing due to the lockdown measures, which was less of a decrease than that based on NH3 only (35.9 %). This study highlights the importance of considering chemical sinks in the atmosphere when applying machine learning techniques to link the concentrations of reactive species with their emissions.",
        "affiliation_name": "National Satellite Meteorological Center Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning Clustering Analysis Towards Educator’s Readiness to Adopt Augmented Reality as a Teaching Tool",
        "paper_author": "Sangodiah A.",
        "publication": "Mendel",
        "citied_by": "0",
        "cover_date": "2023-12-20",
        "Abstract": "The advanced digital revolution has shifted conventional teaching and learning into digital education. In consistency with digital education, Augmented Reality (AR) applications started to shine in the education industry for their ability to create conducive teaching and learning environments, especially in remote learning during the COVID-19 pandemic. Movement Control Order (MCO) implemented in the year 2020 has led to emergency remote teaching and learning without much prepa-ration for all educators and learners. Throughout these few years, most educators got familiar with digital teaching tools and online teaching platforms. Hence, this study aims to explore educators’ readiness to adopt AR as a teaching tool in their teaching during the endemic period. A quantitative approach via questionnaire has been distributed to the Private Higher Education Institutions (PHEIs) in the states of Selangor and Kuala Lumpur. Machine learning using a clustering tech-nique was used to find patterns between the demographics of educators towards the AR perception of educators. The results revealed that educators’ perceptions of AR technology are influenced by their familiarity with it, their personal beliefs, and their attitudes toward technology. This study provides an insightful overview of the benefits of AR applications in education and the implications of the adoption of AR in Malaysian schools and educational institutions. It also highlights the importance of motivating educators and students to embrace AR as an enhancement learning tool, providing a valuable discussion for the government, learning institutions, and educators on the implementation of AR in Malaysia.",
        "affiliation_name": "University of Sanya",
        "affiliation_city": "Sanya",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Zooplankton as a suitable tool for microplastic research",
        "paper_author": "Alfonso M.B.",
        "publication": "Science of the Total Environment",
        "citied_by": "19",
        "cover_date": "2023-12-20",
        "Abstract": "In recent years, significant efforts have been dedicated to measuring and comprehending the impact of microplastics (MPs) in the ocean. Despite harmonization guidelines for MPs research, discrepancies persist in the applied methodologies and future challenges, mostly for the smaller fractions (< 100 μm). Whether intentional or accidental, ingesting plastic particles by zooplankton can lead to incorporating this pollutant into aquatic food chains. Therefore, zooplankton can serve as a suitable proxy tool for assessing the presence of plastic particles in ocean waters. However, reliable information is essential for conducting experimental laboratory studies on the impact of MPs ingestion by zooplankton organisms. Using zooplankton as a research tool for MPs offers numerous advantages, including similar sampling methodologies and study techniques as MPs and particle data integration over space and time. The scientific community can gain novel perspectives by merging zooplankton studies with MPs research. This review explores key aspects of using zooplankton as a tool for MPs research in water samples, encompassing various views such as particles ingestion in natural environments, particle quantification in zooplankton samples (past and future), ecotoxicological and toxicology model studies. By leveraging the potential of zooplankton research, advancements can be made in developing innovative techniques for MPs analysis.",
        "affiliation_name": "Kyushu University, Research Institute for Applied Mechanics",
        "affiliation_city": "Kasuga",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Remotely sensed evidence of the divergent climate impacts of wind farms on croplands and grasslands",
        "paper_author": "Liu N.",
        "publication": "Science of the Total Environment",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "To mitigate climate change, the utilization of wind energy has rapidly expanded over the last two decades. However, when producing clean electricity, wind farms (WFs) may in turn alter the local climate by interfering in land surface-atmosphere interactions. Currently, China and the United States have the highest wind energy capacities globally. Thus, quantitatively analyzing the impacts of WFs on land surface temperature (LST) between the two countries is valuable to deeply understand the climate impact of WF. In this study, we use the moderate-resolution imaging spectroradiometer (MODIS) time series from 2001 to 2018 to reveal the impacts of 186 WFs (76 in China and 110 in the US) on local LSTs. The remote sensing observations reveal that WFs generally lead to warming impacts in both countries, with stronger effects in the US compared to China. During the daytime, WFs in the US exhibit a significant warming effect of 0.08 °C (p < 0.05), while the impact in China is nonsignificant (0.06 °C, p = 0.15). At night, the warming impacts in the US are approximately 1.7 times greater than in China (0.19 °C vs. 0.11 °C). Differences in the LST impacts between the two countries are primarily driven by cropland WFs, which cause more significant cooling effects in China (−0.34 °C in the daytime and − 0.19 °C at night, p < 0.01) compared to the US. However, these differences are not significant for grassland WFs. Moreover, the impacts of WFs on croplands' LSTs are strongly correlated with their evapotranspiration impacts, likely influenced by irrigation practices. In addition to evapotranspiration, a machine learning model suggests that background climate and terrain factors can alter the LST impacts. Our observations in the two largest WF-deployment countries provide a new understanding of the climate impacts of WFs, which should be considered in the fields of wind and renewable energy deployment.",
        "affiliation_name": "South China Botanical Garden",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Spatiotemporal-aware machine learning approaches for dissolved oxygen prediction in coastal waters",
        "paper_author": "Liang W.",
        "publication": "Science of the Total Environment",
        "citied_by": "15",
        "cover_date": "2023-12-20",
        "Abstract": "Coastal waters face increasing threats from hypoxia, which can have severe consequences for marine life and fisheries. This study aims to develop a machine learning approach for hypoxia monitoring by investigating the effectiveness of four tree-based models, considering spatiotemporal effects in model prediction, and adopting the SHapley Additive exPlanations (SHAP) approach for model interpretability, using the long-term climate and marine monitoring dataset in Tolo Harbour (Zone 1) and Mirs Bay (Zone 2), Hong Kong. The LightBoost model was found to be the most effective for predicting dissolved oxygen (DO) concentrations using spatiotemporal datasets. Considering spatiotemporal effects improved the model's bottom DO prediction performance (R2 increase 0.30 in Zone1 and 0.68 in Zone 2), although the contributions from temporal and spatial factors varied depending on the complexity of physical and chemical processes. This study focused not only on error estimates but also on model interpretation. Using SHAP, we propose that hypoxia is largely influenced by hydrodynamics, but anthropogenic activities can increase the bias of systems, exacerbating chemical reactions and impacting DO levels. Additionally, the high relative importance of silicate (Zone 1:0.11 and Zone 2: 0.19) in the model suggests that terrestrial sources, particularly submarine groundwater discharge, are important factors influencing coastal hypoxia. This is the first machine learning effort to consider spatiotemporal effects in four dimensions to predict DO concentrations, and we believe it contributes to the development of a forecasting tool for alarming hypoxia, combining real-time data and machine learning models in the near future.",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Identifying changes in flood characteristics and their causes from an event-based perspective in the Central Taihu Basin",
        "paper_author": "Luo S.",
        "publication": "Science of the Total Environment",
        "citied_by": "7",
        "cover_date": "2023-12-20",
        "Abstract": "Increasing rainstorms induced by climate change and modification in the land surface due to urbanization have greatly altered floods at different spatio-temporal scales. However, investigating flood events in urbanized plains is challenging as anthropogenic behaviors can change river flow without rainfall. In addition, while the frequency and magnitude of floods have been well examined, knowledge about variations in the rate of flood change is still limited. To fill these gaps, we proposed a scheme that focused on flood responses to rainfall to detect changes in flood characteristics in the Central Taihu Basin, a highly urbanized region in the Yangtze River Delta of China. Four characteristic metrics were adopted to summarize the flood hydrograph, including the peak, increment, rising rate, and falling rate. We then examined trends of these metrics based on the selected rainfall-flood events from ten hydrological stations during 1970–2020. Subsequently, the reduction method was used to separate the impacts of regional climate change and human activities on flood characteristics alterations. Furthermore, the importance of fifteen factors was quantified by the random forest model. We found that there is a significant upward trend in the evolution of flood characteristics, except for the increment of floods. Flood characteristics exhibit higher values when rainfall accumulates, indicating stronger responses of floods to a large amount of rainfall. The results also show that human activities dominate and impact the peak, rising rate, and falling rate of floods more than climate change. Meanwhile, although cumulative precipitation is the most important factor, flood characteristics are also susceptible to anthropogenic factors, such as land use change and hydraulic engineering construction. Our findings, which provide insights into flood event identification and enhance the understanding of regional flood changes, will serve as a reference for water resource management and flood mitigation in urbanized areas.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Soil carbon sequestration potential of cultivated lands and its controlling factors in China",
        "paper_author": "Wang S.",
        "publication": "Science of the Total Environment",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "Understanding soil organic carbon (SOC) stocks and carbon sequestration potential in cultivated lands can have significant benefit for mitigating climate change and emission reduction. However, there is currently a lack of spatially explicit information on this topic in China, and our understanding of the factors that influence both saturated SOC level (SOCS) and soil organic carbon density (SOCD) remains limited. This study predicted SOCS and SOCD of cultivated lands across mainland China based on point SOC measurements, and mapped its spatial distribution using environmental variables as predictors. Based on the differentiation between SOCS and SOCD, the soil organic carbon sequestration potentials (SOCP) of cultivated land were calculated. Boosted regression trees (BRT), random forest (RF), and support vector machine (SVM) were evaluated as prediction models, and the RF model presented the best performance in predicting SOCS and SOCD based on 10-fold cross-validation. A total of 991 topsoil (0–20 cm) SOC measurements and 12 environmental variables explaining topography, climate, organism, soil properties, and human activity were used as predictors in the model. Both SOCS and SOCD suggested higher SOC levels in northeast China and lower levels in central China. The cultivated lands in China had the potential to sequester about 2.13 ± 0.96 kg m−2 (3.25 Pg) SOC in the top 20 cm soil depth. Northeastern China had the largest SOCP followed by Northern China, and Southwestern China had the lowest SOCP. The primary environmental variables that affected the spatial variation of SOCS were mean annual temperature, followed by clay content and normalized difference vegetation index (NDVI). The assessment and mapping of SOCP in China's cultivated lands holds significance importance as it can provide valuable insights to policymakers and researchers about SOCP, and aid in formulating climate change mitigation strategies.",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Exploring statistical and machine learning techniques to identify factors influencing indoor radon concentration",
        "paper_author": "Dicu T.",
        "publication": "Science of the Total Environment",
        "citied_by": "4",
        "cover_date": "2023-12-20",
        "Abstract": "Radon is a radioactive gas with a carcinogenic effect. The malign effect on human health is, however, mostly influenced by the level of exposure. Dangerous exposure occurs predominantly indoors where the level of indoor radon concentration (IRC) is, in its turn, influenced by several factors. The current study aims to investigate the combined effects of geology, pedology, and house characteristics on the IRC based on 3132 passive radon measurements conducted in Romania. Several techniques for evaluating the impact of predictors on the dependent variable were used, from univariate statistics to artificial neural network and random forest regressor (RFR). The RFR model outperformed the other investigated models in terms of R2 (0.14) and RMSE (0.83) for the radon concentration, as a dependent continuous variable. Using IRC discretized into two classes, based on the median (115 Bq/m3), an AUC-ROC value of 0.61 was obtained for logistic regression and 0.62 for the random forest classifier. The presence of cellar beneath the investigated room, the construction period, the height above the sea level or the floor type are the main predictors determined by the models used.",
        "affiliation_name": "Universitatea Tehnica din Cluj-Napoca",
        "affiliation_city": "Cluj Napoca",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "Evaluating the impact of the Central Chile Mega Drought on debris cover, broadband albedo, and surface drainage system of a Dry Andes glacier",
        "paper_author": "Podgórski J.",
        "publication": "Science of the Total Environment",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "In recent years, Chile has experienced an extraordinary drought that has had significant impacts on both the livelihoods of people and the environment, including the Andean glaciers. This study focuses on analyzing the surface processes of Universidad Glacier, a benchmark glacier for the Dry Andes. Multiple remote sensing datasets are used alongside a novel spectral index designed for mapping of rock material located on the glacier's surface. Our findings highlight the precarious state of the glacier, which serves as a crucial water source for the region. The glacier exhibits locally varied debris accumulation and margin retreat. The most significant impacts are observed on the tongue and secondary accumulation cirques, with the latter at risk of disappearing. The debris cover on the tongue is expanding, reaching higher elevations, and is accompanied by glacier retreat, especially at higher altitudes. The equilibrium line is rapidly shifting upglacier, although the mid-season snow cover still frequently reaches the 2013 equilibrium line, even in 2020. Changes in stream density on the glacier tongue indicate an increased water supply in this area, likely due to enhanced melting of glacial ice. These observed processes align well with meteorological data obtained from reanalysis products. The behavior of dust and debris is influenced by precipitation amount, while the rate of retreat is linked to air temperature.",
        "affiliation_name": "Université du Québec à Trois-Rivières",
        "affiliation_city": "Trois-Rivieres",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Using unmanned aerial vehicles (UAVs) and machine learning techniques for the assessment of Posidonia debris and marine (plastic) litter on coastal ecosystems",
        "paper_author": "Zaaboub N.",
        "publication": "Regional Studies in Marine Science",
        "citied_by": "3",
        "cover_date": "2023-12-20",
        "Abstract": "Due to the dynamics of the littoral zone and continuous inputs from tidal oscillations, riverine sources, anthropogenic activity, and inputs from extreme events, the use of unmanned aerial vehicles (UAVs) for assessing marine litter and Posidonia deposits on beaches has become a necessity. In recent years, Posidonia oceanica beach wracks (banquette) along Mediterranean coasts have increased and are often associated with marine litter items, mostly plastic. In our study, we attempted to list marine litter and categorize the items from pictures The results show an abundance of plastic debris at the Kerkennah site, where the average value of plastic deposits exceeds 100 items per 170 m of beach length. In the second step, we used UAVs for 3D mapping of Posidonia deposits and identification of marine litter classes. The orthomosaic was used for rapid Posidonia volume quantification on beaches. Machine learning was employed to assess MML (Marine-Macro Litter) abundance based on the orthophotos assembly. In the following step, we proceeded with ortho-mosaic creation and delimitation of the study area for the identification and analysis of macroplastics and other items using processed data. Our findings and image processing demonstrate that the K-nearest neighbor (KNN) approach yields excellent results compared to in situ quantification and assessment along the Kerkennah transect for four tests of macro plastic identification and quantification. The error of using UAVs was calculated with an average value of 6.3%, with bottle shape identification being the dominant result.",
        "affiliation_name": "Italian Institute for Environmental Protection and Research",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Exploring the role of microbial proteins in controlling environmental pollutants based on molecular simulation",
        "paper_author": "Wu J.",
        "publication": "Science of the Total Environment",
        "citied_by": "11",
        "cover_date": "2023-12-20",
        "Abstract": "Molecular simulation has been widely used to study microbial proteins' structural composition and dynamic properties, such as volatility, flexibility, and stability at the microscopic scale. Herein, this review describes the key elements of molecular docking and molecular dynamics (MD) simulations in molecular simulation; reviews the techniques combined with molecular simulation, such as crystallography, spectroscopy, molecular biology, and machine learning, to validate simulation results and bridge information gaps in the structure, microenvironmental changes, expression mechanisms, and intensity quantification; illustrates the application of molecular simulation, in characterizing the molecular mechanisms of interaction of microbial proteins with four different types of contaminants, namely heavy metals (HMs), pesticides, dyes and emerging contaminants (ECs). Finally, the review outlines the important role of molecular simulations in the study of microbial proteins for controlling environmental contamination and provides ideas for the application of molecular simulation in screening microbial proteins and incorporating targeted mutagenesis to obtain more effective contaminant control proteins.",
        "affiliation_name": "Fushun Petrochemical Company",
        "affiliation_city": "Fushun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Evaluation of pollutant removal efficiency of urban stormwater wet ponds and the application of machine learning algorithms",
        "paper_author": "Yang Y.",
        "publication": "Science of the Total Environment",
        "citied_by": "7",
        "cover_date": "2023-12-20",
        "Abstract": "Wet ponds have been extensively used for controlling stormwater pollutants, such as sediment and nutrients, in urban watersheds. The removal of pollutants relies on a combination of physical, chemical, and biological processes. It is crucial to assess the performance of wet ponds in terms of removal efficiency and develop an effective modeling scheme for removal efficiency prediction to optimize water quality management. To achieve this, a two-year field program was conducted at two wet ponds in Calgary, Alberta, Canada to evaluate the wet ponds' performance. Additionally, machine learning (ML) algorithms have been shown to provide promising predictions in datasets with intricate interactions between variables. In this study, the generalized linear model (GLM), partial least squares (PLS) regression, support vector machine (SVM), random forest (RF), and K-nearest neighbors (KNN) were applied to predict the outflow concentrations of three key pollutants: total suspended solids (TSS), total nitrogen (TN), and total phosphorus (TP). Generally, the concentrations of inflow pollutants in the two study ponds are highly variable, and a wide range of removal efficiencies are observed. The results indicate that the concentrations of TSS, TN, and TP decrease significantly from the inlet to outlet of the ponds. Meanwhile, inflow concentration, rainfall characteristics, and wind are important indicators of pond removal efficiency. In addition, ML algorithms can be an effective approach for predicting outflow water quality: PLS, GLM, and SVM have shown strong potential to capture the dynamic interactions in wet ponds and predict the outflow concentration. This study highlights the complexity of pollutant removal dynamics in wet ponds and demonstrates the potential of data-driven outflow water quality prediction.",
        "affiliation_name": "The City of Calgary",
        "affiliation_city": "Calgary",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Deep learning framework for forecasting en route airspace emissions considering temporal-spatial correlation",
        "paper_author": "Wan J.",
        "publication": "Science of the Total Environment",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "The air transport system is currently in a rapid development stage, accurate forecasting emissions is critical for identifying and mitigating its environmental impact. Accurate forecasting depends not only on temporal features from historical air traffic data but also on the influence of spatial factors. This paper proposes a deep learning-based forecasting framework for en route airspace emissions. It combines three-channel networks: a graph convolutional network, a gated recurrent unit, and the attention mechanism, in order to extract the spatial, temporal, and global temporal dynamics trends, respectively. The model is evaluated with real-world datasets, and the experimental results outperform existing state-of-the-art benchmarks on different evaluation metrics and forecasting horizons in complex airspace networks. Our method provides an alternative for forecasting air traffic emissions using publicly available traffic flow data. Furthermore, we propose an extension index that can be taken as an early warning indicator for stakeholders to monitor air traffic emissions.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A deep learning model for reconstructing centenary water storage changes in the Yangtze River Basin",
        "paper_author": "Wang J.",
        "publication": "Science of the Total Environment",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "Since 2002, the Gravity Recovery and Climate Experiment (GRACE) and its Follow-On mission (GRACE-FO) have facilitated highly accurate observations of changes in total water storage anomalies (TWSA). However, limited observations of TWSA derived from GRACE in the Yangtze River Basin (YRB) have hindered our understanding of its long-term variability. In this paper, we present a deep learning model called RecNet to reconstruct the climate-driven TWSA in the YRB from 1923 to 2022. The RecNet model is trained on precipitation, temperature, and GRACE observations with a weighted mean square error (WMSE) loss function. The performance of the RecNet model is validated and compared against GRACE data, water budget estimates, hydrological models, drought indices, and existing reconstruction datasets. The results indicate that the RecNet model can successfully reconstruct historical water storage changes, surpassing the performance of previous studies. In addition, the reconstructed datasets are utilized to assess the frequency of extreme hydrological conditions and their teleconnections with major climate patterns, including the El Niño-Southern Oscillation, Indian Ocean Dipole, Pacific Decadal Oscillation, and North Atlantic Oscillation. Independent component analysis is employed to investigate individual climate patterns' unique or combined influence on TWSA. We show that the YRB exhibits a notable vulnerability to extreme events, characterized by a recurrent occurrence of diverse extreme dry/wet conditions throughout the past century. Wavelet coherence analysis reveals significant coherence between the climate patterns and TWSA across the entire basin. The reconstructed datasets provide valuable information for studying long-term climate variability and projecting future droughts and floods in the YRB, which can inform effective water resource management and climate change adaptation strategies.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Nitrate prediction in groundwater of data scarce regions: The futuristic fresh-water management outlook",
        "paper_author": "Mahlknecht J.",
        "publication": "Science of the Total Environment",
        "citied_by": "13",
        "cover_date": "2023-12-20",
        "Abstract": "Nitrate contamination in groundwater poses a significant threat to water quality and public health, especially in regions with limited data availability. This study addresses this challenge by employing machine learning (ML) techniques to predict nitrate (NO3−-N) concentrations in Mexico's groundwater. Four ML algorithms—Extreme Gradient Boosting (XGB), Boosted Regression Trees (BRT), Random Forest (RF), and Support Vector Machines (SVM)—were executed to model NO3−-N concentrations across the country. Despite data limitations, the ML models achieved robust predictive performances. XGB and BRT algorithms demonstrated superior accuracy (0.80 and 0.78, respectively). Notably, this was achieved using ∼10 times less information than previous large-scale assessments. The novelty lies in the first-ever implementation of the ‘Support Points-based Split Approach’ during data pre-processing. The models considered initially 68 covariates and identified 13–19 significant predictors of NO3−-N concentration spanning from climate, geomorphology, soil, hydrogeology, and human factors. Rainfall, elevation, and slope emerged as key predictors. A validation incorporated nationwide waste disposal sites, yielding an encouraging correlation. Spatial risk mapping unveiled significant pollution hotspots across Mexico. Regions with elevated NO3−-N concentrations (>10 mg/L) were identified, particularly in the north-central and northeast parts of the country, associated with agricultural and industrial activities. Approximately 21 million people, accounting for 10 % of Mexico's population, are potentially exposed to elevated NO3−-N levels in groundwater. Moreover, the NO3−-N hotspots align with reported NO3−-N health implications such as gastric and colorectal cancer. This study not only demonstrates the potential of ML in data-scarce regions but also offers actionable insights for policy and management strategies. Our research underscores the urgency of implementing sustainable agricultural practices and comprehensive domestic waste management measures to mitigate NO3−-N contamination. Moreover, it advocates for the establishment of effective policies based on real-time monitoring and collaboration among stakeholders.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Davis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "High-resolution mapping of regional VOCs using the enhanced space-time extreme gradient boosting machine (XGBoost) in Shanghai",
        "paper_author": "Lu B.",
        "publication": "Science of the Total Environment",
        "citied_by": "5",
        "cover_date": "2023-12-20",
        "Abstract": "The accurate estimation of highly spatiotemporal volatile organic compounds (VOCs) is of great significance to establish advanced early warning systems and regulate air pollution control. However, the estimation of high spatiotemporal VOCs remains incomplete. Here, the space-time extreme gradient boost model (STXGB) was enhanced by integrating spatiotemporal information to obtain the spatial resolution and overall accuracy of VOCs. To this end, meteorological, topographical and pollutant emissions, was input to the STXGB model, and regional hourly 300 m VOCs maps for 2020 in Shanghai were produced. Our results show that the STXGB model achieve good hourly VOCs estimations performance (R2 = 0.73). A further analysis of SHapley Additive exPlanation (SHAP) regression indicate that local interpretations of the STXGB models demonstrate the strong contribution of emissions on mapping VOCs estimations, while acknowledging the important contribution of space and time term. The proposed approach outperforms many traditional machine learning models with a lower computational burden in terms of speed and memory.",
        "affiliation_name": "Leibniz Institute for Tropospheric Research",
        "affiliation_city": "Leipzig",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Probing the bioconcentration and metabolism disruption of bisphenol A and its analogues in adult female zebrafish from integrated AutoQSAR and metabolomics studies",
        "paper_author": "Chen P.",
        "publication": "Science of the Total Environment",
        "citied_by": "2",
        "cover_date": "2023-12-20",
        "Abstract": "Plenty of emerging bisphenol A (BPA) substitutes rise to wait for assessment of bioconcentration and metabolism disruption. Computational methods are useful to fill the data gap in chemical risk assessment, such as automated quantitative structure-activity relationship (AutoQSAR). It is not clear how AutoQSAR performs in predicting the bioconcentration factor (BCF) in adult zebrafish. Herein, AutoQSAR was used to predict the logBCFs of BPA, bisphenol AF (BPAF), bisphenol B, bisphenol F and bisphenol S (BPS). For the test set, a linear relationship was shown between the observed and predicted logBCFs with a slope of 0.97. The predicted logBCFs of these five bisphenols were quite close to their experimental data with a slope of 0.94, suggesting better performance than directed message passing neural networks and EPI Suite with a slope of 0.69 and 0.61, respectively. Thus, AutoQSAR is powerful in modeling logBCFs in fish with minimal time and expertise. To link bioconcentration with metabolic effects, female zebrafish were exposed to BPA, BPAF and BPS for metabolomics analysis. BPA caused a significant disturbance in amino acid metabolism, while BPAF and BPS significantly altered another three metabolic pathways, showing chemical-specific responses. BPAF with the highest logBCF elicited the strongest metabolomic responses reflected by the metabolic effect level index, followed by BPA and BPS. Thus, BPAF and BPS elicited higher or similar metabolism disruption compared with BPA in female zebrafish, respectively, reflecting consequences of bioconcentration.",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Enose design and structures from statistical analysis to application in robotic: A compressive review",
        "paper_author": "Moshayedi A.J.",
        "publication": "EAI Endorsed Transactions on AI and Robotics",
        "citied_by": "21",
        "cover_date": "2023-12-20",
        "Abstract": "Since 1982, the olfactory system of creatures has piqued the interest of academics who seek to create a comparable system. Despite its mysterious nature, the first stage has been successfully completed with the development of the ENose. Its extended applications have opened new doors for researchers, ranging from food quality testing to bomb detection and even, more recently, identifying those infected with the coronavirus. In this talk, we will review the structure and sensor behaviour of the ENose, as well as its applications, such as odour source localization and various applications in agriculture. The challenge of odour identification has prompted researchers to employ robots with sensors to investigate and locate odour sources. The present study aims to synthesize documented research and provide a fresh perspective on odour localization research efforts and tests conducted. The study highlights previous attempts to equip robots with sensors to explore the real indoor or outdoor environment. Initially, a review was conducted to investigate various aspects of the sector and the obstacles involved.",
        "affiliation_name": "Clemson University College of Engineering, Computing and Applied Sciences",
        "affiliation_city": "Clemson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Holistic, Interdisciplinary and Socially Engaged Approach to Translator Education Learning through Meaningful Projects",
        "paper_author": "Mastela O.",
        "publication": "Miedzy Oryginalem a Przekladem",
        "citied_by": "1",
        "cover_date": "2023-12-20",
        "Abstract": "In the face of the contemporary market for translation services, it is becoming increasingly apparent that translation pedagogy should holisti-cally embrace the teaching and learning process by integrating as many in-and out-of-classroom activities as possible into the real-life experience of students, thus leading them to acquire broadly defined skills and com-petences that are vital in the translation profession (cf. EMT Competence Framework 2022). A holistic approach to translation teaching and learning may be also reflected in an attempt to reconcile the two extremes of ‘creativity’ and ‘automaticity’ in translation, i.e., the creative contribution of the translator as an intermediary in intercultural communication on the one hand, and the requirement to know and use the latest technologies (CAT tools, machine translation, terminology databases, etc.), on the other hand. A holistic approach may also be associated with socially engaged pedagogy and the application of Project Based Learning (PBL), based on constructivist premises that we acquire knowledge by participating in intersubjective interactions. The paper attempts to show how translation teachers may holistically respond to the above-mentioned needs by using PBL methods and socially relevant interdisciplinary content in their teaching of the art and craft of translation.",
        "affiliation_name": "Uniwersytet Jagielloński",
        "affiliation_city": "Krakow",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Simultaneous enhancement in mechanical and corrosion properties of Al-Mg-Si alloys using machine learning",
        "paper_author": "Feng X.",
        "publication": "Journal of Materials Science and Technology",
        "citied_by": "30",
        "cover_date": "2023-12-20",
        "Abstract": "Al-Mg-Si alloys with high strength and good corrosion resistance are regarded as desirable materials for all-aluminum vehicles. However, the traditional trial-and-error experimental methods are insufficient to address the trade-off between strength and corrosion resistance. In this work, a non-dominated sorting genetic machine-learning algorithm (NSGA-II) was employed to optimize the chemical composition, so as to simultaneously improve the strength and corrosion resistance. Three high-performance Al-Mg-Si alloys with low Mg, Si, and Cu contents were successfully developed, where the yield strength (YS), ultimate tensile strength (UTS), and the elongation (δ) reached 375–380 MPa, 410–416 MPa, and 13.7%–15.2%, respectively. Compared with higher-Cu-content 6013 alloy, the YS and UTS of the present alloys increase by about 60 MPa, and the intergranular corrosion resistance is also significantly improved. Microstructure characterization demonstrated that β'' and QP phases introduced a significant synergistic precipitation strengthening effect; the dispersoids formed by trace Mn, Cr, Fe, Zr, and Ti contributed dispersion strengthening effect; and the good pitting corrosion resistance is attributed to lower Mg and Si contents.",
        "affiliation_name": "University of Science and Technology Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning-Assisted High-Throughput SERS Classification of Cell Secretomes",
        "paper_author": "Plou J.",
        "publication": "Small",
        "citied_by": "25",
        "cover_date": "2023-12-20",
        "Abstract": "During the response to different stress conditions, damaged cells react in multiple ways, including the release of a diverse cocktail of metabolites. Moreover, secretomes from dying cells can contribute to the effectiveness of anticancer therapies and can be exploited as predictive biomarkers. The nature of the stress and the resulting intracellular responses are key determinants of the secretome composition, but monitoring such processes remains technically arduous. Hence, there is growing interest in developing tools for noninvasive secretome screening. In this regard, it has been previously shown that the relative concentrations of relevant metabolites can be traced by surface-enhanced Raman scattering (SERS), thereby allowing label-free biofluid interrogation. However, conventional SERS approaches are insufficient to tackle the requirements imposed by high-throughput modalities, namely fast data acquisition and automatized analysis. Therefore, machine learning methods were implemented to identify cell secretome variations while extracting standard features for cell death classification. To this end, ad hoc microfluidic chips were devised, to readily conduct SERS measurements through a prototype relying on capillary pumps made of filter paper, which eventually would function as the SERS substrates. The developed strategy may pave the way toward a faster implementation of SERS into cell secretome classification, which can be extended even to laboratories lacking highly specialized facilities.",
        "affiliation_name": "Centro de Investigación Biomédica en Red de Cáncer",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "A natural language processing approach to uncover patterns among online ratings of otolaryngologists",
        "paper_author": "Vasan V.",
        "publication": "Journal of Laryngology and Otology",
        "citied_by": "8",
        "cover_date": "2023-12-20",
        "Abstract": "Background Patients increasingly use physician rating websites to evaluate and choose potential healthcare providers. A sentiment analysis and machine learning approach can uniquely analyse written prose to quantitatively describe patients' perspectives from interactions with their physicians. Methods Online written reviews and star scores were analysed from Healthgrades.com using a natural language processing sentiment analysis package. Demographics of otolaryngologists were compared and a multivariable regression for individual words was performed. Results This study analysed 18 546 online reviews of 1240 otolaryngologists across the USA. Younger otolaryngologists (aged less than 40 years) had higher sentiment and star scores compared with older otolaryngologists (p < 0.001). Male otolaryngologists had higher sentiment and star scores compared with female otolaryngologists (p < 0.001). 'Confident', 'kind', 'recommend' and 'comfortable' were words associated with positive reviews (p < 0.001). Conclusion Positive bedside manner was strongly reflected in better reviews, and younger age and male gender of the otolaryngologist were associated with better sentiment and star scores.",
        "affiliation_name": "Icahn School of Medicine at Mount Sinai",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Rapid quantitative analysis of raw rocks by LIBS coupled with feature-based transfer learning",
        "paper_author": "Rao Y.",
        "publication": "Journal of Analytical Atomic Spectrometry",
        "citied_by": "4",
        "cover_date": "2023-12-19",
        "Abstract": "Quantitative analysis of rock samples using laser-induced breakdown spectroscopy (LIBS) is a challenging task due to the significant differences in spectra between pressed pellet samples and rock samples, with pressed pellet samples usually exhibiting stronger spectral lines. The predictive ability of LIBS quantitative analysis models for rock samples is poorer compared to that for pressed pellet samples, and quantitative analysis models constructed using pressed pellet samples cannot be directly applied to predict the composition of rock samples. To address the issue, a quantitative analysis method for raw rocks based on feature transfer learning using transfer component analysis (TCA) is proposed in this paper. By establishing a feature mapping relationship between pressed pellet samples and rock samples, the differences between data features are reduced, thus enabling the training of a more quantitative analysis model. The transfer learning was introduced into a multivariate regression machine learning model for training using pressed pellet samples, which successfully addresses the problem of prediction accuracy of rock sample element contents. In this model, all data were mapped to a high-dimensional reproducing kernel Hilbert space, and a subset of the most similar features was selected to train the quantitative analysis model. Upon testing the model with independent rock samples, the difference between the predicted and true values was significantly reduced. The model yielded a root mean square error of prediction (RMSEP) of 3.7131, 1.0185, 0.2985, 13.0439, and 1.5450 for Si, Al, Fe, Ca, and Mg in rock samples, respectively. These results indicate that LIBS coupled with the transfer learning algorithm can effectively eliminate the differences between the spectra of the pressed pellet and the raw rock and provide another idea for in situ LIBS detection.",
        "affiliation_name": "Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Out-of-distribution Detection in Time-series Domain: A Novel Seasonal Ratio Scoring Approach",
        "paper_author": "Belkhouja T.",
        "publication": "ACM Transactions on Intelligent Systems and Technology",
        "citied_by": "1",
        "cover_date": "2023-12-19",
        "Abstract": "Safe deployment of time-series classifiers for real-world applications relies on the ability to detect the data that is not generated from the same distribution as training data. This task is referred to as out-of-distribution (OOD) detection. We consider the novel problem of OOD detection for the time-series domain. We discuss the unique challenges posed by time-series data and explain why prior methods from the image domain will perform poorly. Motivated by these challenges, this article proposes a novel Seasonal Ratio Scoring (SRS) approach. SRS consists of three key algorithmic steps. First, each input is decomposed into class-wise semantic component and remainder. Second, this decomposition is employed to estimate the class-wise conditional likelihoods of the input and remainder using deep generative models. The seasonal ratio score is computed from these estimates. Third, a threshold interval is identified from the in-distribution data to detect OOD examples. Experiments on diverse real-world benchmarks demonstrate that the SRS method is well-suited for time-series OOD detection when compared to baseline methods.",
        "affiliation_name": "Voiland College of Engineering and Architecture",
        "affiliation_city": "Pullman",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Dielectrophoretic enrichment of live chemo-resistant circulating-like pancreatic cancer cells from media of drug-treated adherent cultures of solid tumors",
        "paper_author": "Rane A.",
        "publication": "Lab on a Chip",
        "citied_by": "4",
        "cover_date": "2023-12-19",
        "Abstract": "Due to low numbers of circulating tumor cells (CTCs) in liquid biopsies, there is much interest in enrichment of alternative circulating-like mesenchymal cancer cell subpopulations from in vitro tumor cultures for utilization within molecular profiling and drug screening. Viable cancer cells that are released into the media of drug-treated adherent cancer cell cultures exhibit anoikis resistance or anchorage-independent survival away from their extracellular matrix with nutrient sources and waste sinks, which serves as a pre-requisite for metastasis. The enrichment of these cell subpopulations from tumor cultures can potentially serve as an in vitro source of circulating-like cancer cells with greater potential for scale-up in comparison with CTCs. However, these live circulating-like cancer cell subpopulations exhibit size overlaps with necrotic and apoptotic cells in the culture media, which makes it challenging to selectively enrich them, while maintaining them in their suspended state. We present optimization of a flowthrough high frequency (1 MHz) positive dielectrophoresis (pDEP) device with sequential 3D field non-uniformities that enables enrichment of the live chemo-resistant circulating cancer cell subpopulation from an in vitro culture of metastatic patient-derived pancreatic tumor cells. Central to this strategy is the utilization of single-cell impedance cytometry with gates set by supervised machine learning, to optimize the frequency for pDEP, so that live circulating cells are selected based on multiple biophysical metrics, including membrane physiology, cytoplasmic conductivity and cell size, which is not possible using deterministic lateral displacement that is solely based on cell size. Using typical drug-treated samples with low levels of live circulating cells (<3%), we present pDEP enrichment of the target subpopulation to ∼44% levels within 20 minutes, while rejecting >90% of dead cells. This strategy of utilizing single-cell impedance cytometry to guide the optimization of dielectrophoresis has implications for other complex biological samples.",
        "affiliation_name": "University of Virginia School of Engineering and Applied Science",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Perspectives of physics-based machine learning strategies for geoscientific applications governed by partial differential equations",
        "paper_author": "Degen D.",
        "publication": "Geoscientific Model Development",
        "citied_by": "5",
        "cover_date": "2023-12-19",
        "Abstract": "An accurate assessment of the physical states of the Earth system is an essential component of many scientific, societal, and economical considerations. These assessments are becoming an increasingly challenging computational task since we aim to resolve models with high resolutions in space and time, to consider complex coupled partial differential equations, and to estimate uncertainties, which often requires many realizations. Machine learning methods are becoming a very popular method for the construction of surrogate models to address these computational issues. However, they also face major challenges in producing explainable, scalable, interpretable, and robust models. In this paper, we evaluate the perspectives of geoscience applications of physics-based machine learning, which combines physics-based and data-driven methods to overcome the limitations of each approach taken alone. Through three designated examples (from the fields of geothermal energy, geodynamics, and hydrology), we show that the non-intrusive reduced-basis method as a physics-based machine learning approach is able to produce highly precise surrogate models that are explainable, scalable, interpretable, and robust.",
        "affiliation_name": "Fraunhofer Research Institution for Energy Infrastructures and Geotechnologies - IEG",
        "affiliation_city": "Bochum",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "%V<inf>Bur</inf> index and steric maps: from predictive catalysis to machine learning",
        "paper_author": "Escayola S.",
        "publication": "Chemical Society Reviews",
        "citied_by": "31",
        "cover_date": "2023-12-19",
        "Abstract": "Steric indices are parameters used in chemistry to describe the spatial arrangement of atoms or groups of atoms in molecules. They are important in determining the reactivity, stability, and physical properties of chemical compounds. One commonly used steric index is the steric hindrance, which refers to the obstruction or hindrance of movement in a molecule caused by bulky substituents or functional groups. Steric hindrance can affect the reactivity of a molecule by altering the accessibility of its reactive sites and influencing the geometry of its transition states. Notably, the Tolman cone angle and %VBur are prominent among these indices. Actually, steric effects can also be described using the concept of steric bulk, which refers to the space occupied by a molecule or functional group. Steric bulk can affect the solubility, melting point, boiling point, and viscosity of a substance. Even though electronic indices are more widely used, they have certain drawbacks that might shift preferences towards others. They present a higher computational cost, and often, the weight of electronics in correlation with chemical properties, e.g. binding energies, falls short in comparison to %VBur. However, it is worth noting that this may be because the steric index inherently captures part of the electronic content. Overall, steric indices play an important role in understanding the behaviour of chemical compounds and can be used to predict their reactivity, stability, and physical properties. Predictive chemistry is an approach to chemical research that uses computational methods to anticipate the properties and behaviour of these compounds and reactions, facilitating the design of new compounds and reactivities. Within this domain, predictive catalysis specifically targets the prediction of the performance and behaviour of catalysts. Ultimately, the goal is to identify new catalysts with optimal properties, leading to chemical processes that are both more efficient and sustainable. In this framework, %VBur can be a key metric for deepening our understanding of catalysis, emphasizing predictive catalysis and sustainability. Those latter concepts are needed to direct our efforts toward identifying the optimal catalyst for any reaction, minimizing waste, and reducing experimental efforts while maximizing the efficacy of the computational methods.",
        "affiliation_name": "Hiroshima University",
        "affiliation_city": "Higashihiroshima",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "MissModal: Increasing Robustness to Missing Modality in Multimodal Sentiment Analysis",
        "paper_author": "Lin R.",
        "publication": "Transactions of the Association for Computational Linguistics",
        "citied_by": "4",
        "cover_date": "2023-12-19",
        "Abstract": "When applying multimodal machine learning in downstream inference, both joint and coordinated multimodal representations rely on the complete presence of modalities as in training. However, modal-incomplete data, where certain modalities are missing, greatly reduces performance in Multimodal Sentiment Analysis (MSA) due to varying input forms and semantic information deficiencies. This limits the applicability of the predominant MSA methods in the real world, where the completeness of multimodal data is uncertain and variable. The generation-based methods attempt to generate the missing modality, yet they require complex hierarchical archi-tecture with huge computational costs and struggle with the representation gaps across different modalities. Diversely, we propose a novel representation learning approach named MissModal, devoting to increasing robustness to missing modality in a classification approach. Specifically, we adopt constraints with geometric contrastive loss, distribution distance loss, and sentiment semantic loss to align the representations of modal-missing and modal-complete data, without impacting the sentiment inference for the complete modal-ities. Furthermore, we do not demand any changes in the multimodal fusion stage, high-lighting the generality of our method in other multimodal learning systems. Extensive experiments demonstrate that the proposed method achieves superior performance with minimal computational costs in various missing modal-ities scenarios (flexibility), including severely missing modality (efficiency) on two public MSA datasets.",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning: a new direction for assisting the application of deep brain stimulation",
        "paper_author": "Chaoshi N.",
        "publication": "National Medical Journal of China",
        "citied_by": "0",
        "cover_date": "2023-12-19",
        "Abstract": "In recent years, deep brain stimulation has been widely used in the treatment of various difficult diseases of the nervous system. The rapid development of machine learning algorithms has greatly promoted the application and development of deep brain stimulation. Machine learning can help in preoperative screening of surgical candidates, outcome prediction and surgical planning. It can assist target localization during operation. More importantly, the local field potential signals recorded by macroscopic electrodes can be analyzed in real time after surgery, which provides a basis for the development of a closed‑loop stimulation system. Of course, the application of machine learning also has its limitations and challenges, such as dimensionality reduction of high‑dimensional data, development and validation of new models and etc, which need to be further explored and improved.",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A data-driven method for modelling dissipation rates in stratified turbulence",
        "paper_author": "Lewin S.F.",
        "publication": "Journal of Fluid Mechanics",
        "citied_by": "1",
        "cover_date": "2023-12-19",
        "Abstract": "We present a deep probabilistic convolutional neural network (PCNN) model for predicting local values of small-scale mixing properties in stratified turbulent flows, namely the dissipation rates of turbulent kinetic energy and density variance, and. Inputs to the PCNN are vertical columns of velocity and density gradients, motivated by data typically available from microstructure profilers in the ocean. The architecture is designed to enable the model to capture several characteristic features of stratified turbulence, in particular the dependence of small-scale isotropy on the buoyancy Reynolds number, where is the kinematic viscosity and is the background buoyancy frequency, the correlation between suitably locally averaged density gradients and turbulence intensity and the importance of capturing the tails of the probability distribution functions of values of dissipation. Empirically modified versions of commonly used isotropic models for and that depend only on vertical derivatives of density and velocity are proposed based on the asymptotic regimes and, and serve as an instructive benchmark for comparison with the data-driven approach. When trained and tested on a simulation of stratified decaying turbulence which accesses a range of turbulent regimes (associated with differing values of), the PCNN outperforms assumptions of isotropy significantly as decreases, and additionally demonstrates improvements over the fitted empirical models. A differential sensitivity analysis of the PCNN facilitates a comparison with the theoretical models and provides a physical interpretation of the features enabling it to make improved predictions.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Amherst",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Potential therapeutic implications of histidine catabolism by the gut microbiota in NAFLD patients with morbid obesity",
        "paper_author": "Quesada-Vázquez S.",
        "publication": "Cell Reports Medicine",
        "citied_by": "16",
        "cover_date": "2023-12-19",
        "Abstract": "The gut microbiota contributes to the pathophysiology of non-alcoholic fatty liver disease (NAFLD). Histidine is a key energy source for the microbiota, scavenging it from the host. Its role in NAFLD is poorly known. Plasma metabolomics, liver transcriptomics, and fecal metagenomics were performed in three human cohorts coupled with hepatocyte, rodent, and Drosophila models. Machine learning analyses identified plasma histidine as being strongly inversely associated with steatosis and linked to a hepatic transcriptomic signature involved in insulin signaling, inflammation, and trace amine-associated receptor 1. Circulating histidine was inversely associated with Proteobacteria and positively with bacteria lacking the histidine utilization (Hut) system. Histidine supplementation improved NAFLD in different animal models (diet-induced NAFLD in mouse and flies, ob/ob mouse, and ovariectomized rats) and reduced de novo lipogenesis. Fecal microbiota transplantation (FMT) from low-histidine donors and mono-colonization of germ-free flies with Enterobacter cloacae increased triglyceride accumulation and reduced histidine content. The interplay among microbiota, histidine catabolism, and NAFLD opens therapeutic opportunities.",
        "affiliation_name": "Norwich Research Park",
        "affiliation_city": "Norwich",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Machine Learning Algorithms for Intelligent Decision Recognition and Quantification of Cr(III) in Chromium Speciation",
        "paper_author": "Lu Y.",
        "publication": "Analytical Chemistry",
        "citied_by": "4",
        "cover_date": "2023-12-19",
        "Abstract": "Cr(III) is a common oxidation state of chromium, and its presence in the environment can occur naturally or as a result of human activities, such as industrial processes, mining, and waste disposal. This article explores the application of machine learning algorithms for the intelligent decision recognition and quantification of Cr(III) in chromium speciation. Three different machine learning models, namely, the Decision Tree (DT) model, the PCA-SVM (Principal Component Analysis-Support Vector Machine) model, and the LDA (Linear Discriminant Analysis) model, were employed and evaluated for accurate and efficient classification of chromium concentrations based on their fluorescence responses. Furthermore, stepwise multiple linear regression analysis was utilized to achieve a more precise quantification of trivalent chromium concentrations through fluorescence visualization. The results demonstrate the potential of machine learning algorithms in accurately detecting and quantifying Cr(III) in chromium speciation with implications for environmental and industrial applications in chromium detection and quantification. The findings from this research pave the way for further exploration and implementation of these models in real-world scenarios, offering valuable insights into various environmental and industrial contexts.",
        "affiliation_name": "Beijing Key Laboratory of Materials Utilization of Nonmetallic Minerals and Solid Wastes",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning Modeling Based on Microbial Community for Prediction of Natural Attenuation in Groundwater",
        "paper_author": "Zhang X.",
        "publication": "Environmental Science and Technology",
        "citied_by": "3",
        "cover_date": "2023-12-19",
        "Abstract": "Natural attenuation is widely adopted as a remediation strategy, and the attenuation potential is crucial to evaluate whether remediation goals can be achieved within the specified time. In this work, long-term monitoring of indigenous microbial communities as well as benzene, toluene, ethylbenzene, and xylene (BTEX) and chlorinated aliphatic hydrocarbons (CAHs) in groundwater was conducted at a historic pesticide manufacturing site. A machine learning approach for natural attenuation prediction was developed with random forest classification (RFC) followed by either random forest regression (RFR) or artificial neural networks (ANNs), utilizing microbiological information and contaminant attenuation rates for model training and cross-validation. Results showed that the RFC could accurately predict the feasibility of natural attenuation for both BTEX and CAHs, and it could successfully identify the key genera. The RFR model was sufficient for the BTEX natural attenuation rate prediction but unreliable for CAHs. The ANN model showed better performance in the prediction of the attenuation rates for both BTEX and CAHs. Based on the assessments, a composite modeling method of RFC and ANN was proposed, which could reduce the mean absolute percentage errors. This study reveals that the combined machine learning approach under the synergistic use of field microbial data has promising potential for predicting natural attenuation.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Coal and Gangue Classification Based on Laser-Induced Breakdown Spectroscopy and Deep Learning",
        "paper_author": "Xu M.",
        "publication": "ACS Omega",
        "citied_by": "4",
        "cover_date": "2023-12-19",
        "Abstract": "During the extraction and processing of coal, a large amount of solid waste, collectively known as gangue, is produced. This gangue has a low carbon content but a high ash content, accounting for approximately 15 to 20% of the total coal yield. Before coal is used, coal and gangue must be effectively separated to reduce the gangue content in the raw coal and improve the efficiency of coal utilization. This study introduces a classification method for coal and gangue based on a combination of laser-induced breakdown spectroscopy (LIBS) and deep learning. The method employs Gramian angular summation fields (GASF) to convert 1D spectral data into 2D time-series data, visualizing them as 2D images, before employing a novel deep learning model─GASF-CNN─for coal and gangue classification. GASF-CNN enhances model focus on critical features by introducing the SimAM attention mechanism, and additionally, the fusion of various levels of spectral features is achieved through the introduction of residual connectivity. GASF-CNN was trained and tested using a spectral data set containing coal and gangue. Comparative experimental results demonstrate that GASF-CNN outperforms other machine learning and deep learning models across four evaluation metrics. Specifically, it achieves 98.33, 97.06, 100, and 98.51% in the accuracy, recall, precision, and F1 score metrics, respectively, thereby achieving an accurate classification of coal and gangue.",
        "affiliation_name": "College of Information Science and Engineering, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Pan-viral serology uncovers distinct virome patterns as risk predictors of hepatocellular carcinoma and intrahepatic cholangiocarcinoma",
        "paper_author": "Do W.L.",
        "publication": "Cell Reports Medicine",
        "citied_by": "5",
        "cover_date": "2023-12-19",
        "Abstract": "This study evaluates the pan-serological profiles of hepatocellular carcinoma (HCC) and intrahepatic cholangiocarcinoma (iCCA) compared to several diseased and non-diseased control populations to identify risk factors and biomarkers of liver cancer. We used phage immunoprecipitation sequencing, an anti-viral antibody screening method using a synthetic-phage-displayed human virome epitope library, to screen patient serum samples for exposure to over 1,280 strains of pathogenic and non-pathogenic viruses. Using machine learning methods to develop an HCC or iCCA viral score, we discovered that both viral scores were positively associated with several liver function markers in two separate at-risk populations independent of viral hepatitis status. The HCC score predicted all-cause mortality over 8 years in patients with chronic liver disease at risk of HCC, while the viral hepatitis status was not predictive of survival. These results suggest that non-hepatitis viral infections may contribute to HCC and iCCA development and could be biomarkers in at-risk populations.",
        "affiliation_name": "Chulabhorn Research Institute",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Predicting Impact Outcomes and Maximum Spreading of Drop Impact on Heated Nanostructures Using Machine Learning",
        "paper_author": "Au-Yeung L.",
        "publication": "Langmuir",
        "citied_by": "2",
        "cover_date": "2023-12-19",
        "Abstract": "Accurate prediction of droplet behavior upon impact on a heated nanostructured surface is vital for various industrial applications. In this study, we leverage multiple data-driven machine learning (ML) techniques to model the impact outcome and droplet spreading, employing existing experimental data. Our approach incorporates a comprehensive range of critical control parameters, such as the impact velocity (V), surface temperature (Ts), nanopillars’ packing fraction (ϕ), and surface roughness (r). We obtain optimal results when utilizing the artificial neural network classification (ANNC) to construct a phase diagram that encompasses all of the experimental impact behaviors. Additionally, we utilize the support vector regression (SVR) method to model the maximum spreading factor (βmax) as a function of the Weber number (We), defined as the ratio of droplet kinetic to surface energy, and Ts for each surface combination. Consistent with previous experimental observations, our results illustrate that nanostructures not only introduce distinct impact behaviors, such as central jetting, but also influence the boundaries among the deposition, rebound, and splashing regimes within the phase diagram. An increase in ϕ at a constant r promotes deposition and spreading events, while increasing r at a constant ϕ results in enhanced heat transfer to promote the Leidenfrost effect for the rebound regime and a greater disturbance of the liquid lamella to trigger splashing. The SVR prediction reveals the existence of a We-number threshold governed by the nanostructure parameters. Beyond this threshold, the maximum spreading factor (βmax) of a spreading droplet becomes independent of the surface temperature (Ts) as We increases, suggesting that fluid properties are likely the dominating factors influencing the spreading dynamics in the extreme We range.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Integrated omics landscape of hepatocellular carcinoma suggests proteomic subtypes for precision therapy",
        "paper_author": "Xing X.",
        "publication": "Cell Reports Medicine",
        "citied_by": "19",
        "cover_date": "2023-12-19",
        "Abstract": "Patients with hepatocellular carcinoma (HCC) at the same clinical stage can have extremely different prognoses, and molecular subtyping provides an opportunity for individualized precision treatment. In this study, genomic, transcriptomic, proteomic, and phosphoproteomic profiling of primary tumor tissues and paired para-tumor tissues from HCC patients (N = 160) are integrated. Proteomic profiling identifies three HCC subtypes with different clinical prognosis, which are validated in three publicly available external validation sets. A simplified panel of nine proteins associated with metabolic reprogramming is further identified as a potential subtype-specific biomarker for clinical application. Multi-omics analysis further reveals that three proteomic subtypes have significant differences in genetic alterations, microenvironment dysregulation, kinase-substrate regulatory networks, and therapeutic responses. Patient-derived cell-based drug tests (N = 26) show personalized responses for sorafenib in three proteomic subtypes, which can be predicted by a machine-learning response prediction model. Overall, this study provides a valuable resource for better understanding of HCC subtypes for precision clinical therapy.",
        "affiliation_name": "The First Affiliated Hospital, Zhejiang University School of Medicine",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Digital capitalism and new institutionalism",
        "paper_author": "Frolov D.",
        "publication": "Digital Capitalism and New Institutionalism",
        "citied_by": "2",
        "cover_date": "2023-12-19",
        "Abstract": "Modern institutional economics was created to study the institutions of pre-digital economies and is based on reductionist approaches. But digital capitalism is producing institutions of unprecedented complexity. This book argues, therefore, that not only the economic institutions themselves but also the theoretical foundations for studying those institutions must now be adapted to digital capitalism. The book focuses on the institutional complexity of digital capitalism, developing an interdisciplinary framework which brings together cutting-edge theoretical approaches from philosophy (first of all, object-oriented ontology), sociology (especially actor-network theory), evolutionary biology, and cognitive science. In particular, the book outlines a new approach to the study of institutional evolution, based on extended evolutionary synthesis - a new paradigm in evolutionary biology, which is now replacing neo-Darwinism. The book develops an enactivist notion of extended cognition and cognitive institutions, rejecting the individualistic and mechanistic understanding of economic rationality in digital environments. The author experiments with new philosophical approaches to investigate institutional complexity, for example, the ideas of the flat ontology and the assemblage theory. The flat ontology approach is applied to the study of human-robot institutions, as well as to thinking about post-anthropocentric institutional design. Assemblage thinking allows for a new (much less idealistic) look at blockchain and smart cities. Blockchain as digital institutional technology is considered in the book not from the viewpoint of minimizing transaction costs (as is customary in the modern institutional economics), but by using the theory of transaction value which focuses on improving the quality of digital transactions. The book includes a wide range of examples ranging from metaverses, cryptocurrencies, and big data to robot rules, smart contracts, and machine learning algorithms. Written for researchers in institutional economics and other social sciences, this interdisciplinary book is essential reading for anyone interested in the interplay of institutional and digital change.",
        "affiliation_name": "Volgograd State Technical University",
        "affiliation_city": "Volgograd",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "The role of a human-machine interaction (hmi) system on the medical devices",
        "paper_author": "Shahraki Z.A.",
        "publication": "Human Machine Interface: Making Healthcare Digital",
        "citied_by": "1",
        "cover_date": "2023-12-19",
        "Abstract": "Today, with the expansion of the population, an increase in various diseases can be seen this phenomenon grows the risk of contracting unknown diseases in the world. Therefore, in recent years, more attention has been paid to the development of new methods for the diagnosis and treatment of patients, which can be referred to efforts made to develop new medicines and diagnostic tools. With using these tools and new technologies, such as artificial intelligence, patients' data with great accuracy are collected and analyzed; a huge transformation in the field of treatment is tacked place. The design of intelligent medical devices has a high impact on the faster recognition and treatment of patients. On the other hand, making a relationship between patients and medical devices can have a positive effect on the treatment of patients. Patients who can feel relaxed and comfortable during the treatment will put more effort into their own treatment. A smart medical device, which has a friendly user interface with the patient, has a positive role in the treatment of patients. Patient experience is a part of user experience that describes the interaction between patients and medical devices. In the concept of patient experiences, the experience of illness and also the way of healthcare are examined. So, the role of human-machine interaction (HMI) systems should not be ignored in the field of treatment. In the field of treatment, HMI refers to facilitating communication between humans and machines. So, the goal of the designing system based on HMI is important to encourage patients to seek treatment and give them hope for life during their treatment period according to their age conditions. For example, the patient's age is an important criterion that should be considered in the design of a human-computer interaction system. Also, the gender of patients plays a role in communicating between patients and medical devices. On other hand, the role of artificial intelligence in designing human-computer interaction systems cannot be ignored. This type of system can prevent disease by checking the patient's condition, predicting the patient's condition during the treatment period based on the patient's personality, and also can decide using decision-making systems. Also, recommender systems can use intelligent medical devices to treat patients according to the predictions made. Accurate diagnosis of medical devices according to the physical and mental conditions of the patient is an important point that affects HMI systems. Actually, an HMI system should be able to identify patients' mental states by using powerful sensors and facial image processing in order to be a user-friendly interface for the medical system. In this chapter, various factors and their solutions that can play a role in the design of an HMI system are examined.",
        "affiliation_name": "Shiraz University",
        "affiliation_city": "Shiraz",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Intelligent healthcare supply chain",
        "paper_author": "Kalaria C.",
        "publication": "Human Machine Interface: Making Healthcare Digital",
        "citied_by": "1",
        "cover_date": "2023-12-19",
        "Abstract": "The healthcare sector remains actively focused on innovative medicines and treatments to improve the quality and longevity of human lives. Merely, the development of such innovations is not enough but making them available to the end consumer is imperative and that's where the HSC comes into the picture. As per the report, global medicine consumption crossed 4.5 trillion doses a year, with over 50% of people take more than at least one daily dose of medicines, HSC management is vital for human lives. The Healthcare Supply Chain (HSC) is the most critical operation as it demands integrity, agility, resilience and cost-effectiveness. The legacy supply chain is not capable to handle the challenges of counterfeiting, geopolitical issues, disruptions due to pandemics and scarcity of skilled manpower to deliver products and services to the end consumers. Worldwide Covid-19 pandemic disruption has further strengthened the quest to revamp the HSC by making it more resilient and intelligent. Technologies like deep learning (DL) human-machine interface (HMI), machine learning (ML), blockchain, robotics, cloud computing, AI, big data analytics (BDA), Digital Twins, Industry 4.0, IoT and control towers aid for developing end-to-end intelligent, integrated and data-driven supply chain.",
        "affiliation_name": "Narsee Monjee Institute of Management Studies University, Shirpur",
        "affiliation_city": "Shirpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Regulatory perspective: Human-machine interfaces",
        "paper_author": "Patel A.",
        "publication": "Human Machine Interface: Making Healthcare Digital",
        "citied_by": "0",
        "cover_date": "2023-12-19",
        "Abstract": "By drawing novel and significant ideas from the enormous quantity of data created during the daily provision of healthcare, human-machine interfaces (HMI) possess the capacity to revolutionize the way that healthcare is provided. But because of their intricacy and the continuous statistics nature of their creation, they also raise certain issues that should be taken into account. Traditionally, the FDA evaluates medical devices using a premarket process that is appropriate but not intended for adaptive HMI systems. The extremely repetitive, autonomous, and adaptable character of these tools necessitates a novel, total product lifecycle (TPLC) regulation strategy that supports a quick loop of product innovation and permits these instruments to advance continuously while offering reliable protection. This chapter describes the regulatory perspective and potential approach to developing safe and quality HMI technologies for patients. It describes current regulations, standards for categorizing risks, a framework for weighing benefits and risks, rules for managing risks, and product life cycle approaches. Further, a description of guiding principles for the creation of good machine learning practice (GMLP) would aid in promoting high, secure, and reliable medical equipment using HMI technologies. It details the kind of adjustment that is envisaged as well as the approach used to accomplish such modifications in a regulated way that minimizes hazards to individuals.",
        "affiliation_name": "Shree S. K. Patel College of Pharmaceutical Education &amp; Research",
        "affiliation_city": "Mehsana",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Breaking the silence: Brain-computer interface for communication",
        "paper_author": "Nikam P.L.",
        "publication": "Human Machine Interface: Making Healthcare Digital",
        "citied_by": "0",
        "cover_date": "2023-12-19",
        "Abstract": "A hardware and software communications system called a \"brain activity\" is used in brain-computer interfaces (BCI). To command computers or other external devices. BCI assists in providing communication ability to severely disabled people, whether they are completely disabled or \"trapped\" by neurological disabilities or certain musculoskeletal diseases. A BCI system functions by capturing brain signals, classifying the signals using machine learning methods, and executing an action that is computer-controlled. ECoG stands for \"electrocorticography, \" which is providing an increase in interest as a recording method for BCI use since it is more suitable for fundamental neuroscience studies and the subsequent prospects for translation. Electron encephalographic signals are contrasted with those obtained from the scalp (EEG). The signal acquisition stage of a generic BCI system record includes processing artefacts and noise reduction for brain signals. The pre-processing stage gets the signals ready for further processing by putting them in the right format. The signals from the brain that have been recorded serve as discriminatory data during the step of feature extraction. The signal is measured and then converted into a vector that contains useful and discriminative characteristics from the observed signals. This information must be extracted, which is an extremely difficult task. Brain signals from a limited number of brain activities are combined with other signals, and things cross over in time and space. One of the biggest issues with BCI high-dimensional feature vectors are used in the design to enhance the classification of the signals, pertinent characteristics, and feature-based classification. This research aims to make a better suggestion. BCIs based on electroencephalographic potentials or oscillations are ready to undergo large clinical studies and commercial production as an adjunct or a major assisted communication device for paralysed and locked-in patient. A series of studies using BOLD response regulation with functional magnetic resonance imaging (fMRI) and near infrared spectroscopy demonstrated a tight correlation between voluntary changes in brain metabolism and behaviour.",
        "affiliation_name": "Galgotias University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Human-machine interaction in leveraging the concept of telemedicine",
        "paper_author": "Israni D.K.",
        "publication": "Human Machine Interface: Making Healthcare Digital",
        "citied_by": "4",
        "cover_date": "2023-12-19",
        "Abstract": "Since the invention of the computer, several investigations and research projects in the area of human-machine interaction (HMI) have been carried out to continuously enhance the communication between human operators and automated systems. HMI has gained popularity in a variety of industries one of them being healthcare. The concept of \"anywhere, anytime healthcare\" is changing client attitudes and fostering a new wave of Telemedicine. Telemedicine is the practice of providing therapeutic services remotely via two-way, real-time audio and video communication between a patient and a medical specialist. There are various technological advances in human-machine interactions like artificial intelligence (AI), machine learning (ML), Blockchain, Big Data, and The Internet of medical things (IoMT) that can be utilized in telemedicine. Presently portable telemedicine monitoring devices and Telerobots collect vital life physiological signs; Ambient Assisted Living (AAL), a new development in technology that allows remote patient monitoring; the latest sensor technologies, where a person's vital data can be collected, and bio-information can be wirelessly or online transmitted to medical databases and healthcare specialists are being used in many countries. This review focuses on the human-machine interaction in leveraging the concept of telemedicine that provide a smart triage of patients and remote monitoring.",
        "affiliation_name": "L.J. Institute of Pharmacy and Research Center, Ahmedabad",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Computational nanotoxicology and its applications",
        "paper_author": "Jabeen S.",
        "publication": "Computational Toxicology for Drug Safety and a Sustainable Environment",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The trial on non-testing approaches for nanostructured materials and the prediction of toxicity that may cause cell disruption is needed for the risk assessment, to recognize, evaluate, and categorize possible risks. Another tactic for examining the toxicologic characteristics of a nanostructure is using in silico methods that interpret how nano-specific structures correlate to noxiousness and permit its prediction. Nanotoxicology is the study of the toxicity of nanostructures and has been broadly functional in medical research to predict the toxicity in numerous biotic systems. Exploring biotic systems through in vivo and in vitro approaches is affluent and time-consuming. However, computational toxicology is a multi-discipline ground that operates In silico strategies and algorithms to inspect the toxicology of biotic systems and also has gained attention for many years. Molecular dynamics (MD) simulations of biomolecules such as proteins and deoxyribonucleic acid (DNA) are prevalent for considering connections between biotic systems and chemicals in computational toxicology. This chapter summarizes the works predicting nanotoxicological endpoints using (ML) machine learning models. Instead of looking for mechanistic clarifications, the chapter plots the ways that are followed, linking biotic features concerning exposure to nanostructure materials, their physicochemical features, and the commonly predicted conclusions. The outcomes and conclusions obtained from the research, and review papers from indexing databases like SCOPUS, Web of Science, and PubMed were studied and included in the chapter. The chapter maps current models developed precisely for nanostructures to recognize the threat potential upon precise exposure circumstances. The authors have provided computational nano-toxicological effects with the collective vision of applied machine learning tools.",
        "affiliation_name": "Integral University",
        "affiliation_city": "Lucknow",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Toxicology studies of anisole and glyoxylic acid derivatives by computational methods",
        "paper_author": "Gupta S.",
        "publication": "Computational Toxicology for Drug Safety and a Sustainable Environment",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Toxicology is a domain imbricating biology, chemistry, pharmacology, and medicine that involves observing and analyzing inauspicious consequences of chemical exposure on living beings thus identifying and manifesting toxins and toxicants. Progress in computer sciences and hardware in combination with equally remarkable growth in molecular biology and chemistry are providing toxicology with a reigning new tool case. This tool case of computational models assures to enhance the efficacy by which the hazards and risks of environmental chemicals are driven. In this study, we investigated two compounds namely: Phenylgloxylic acid (PGA) and 4-ethynyl anisole (MOPA) experimentally as well as quantum chemically. Density functional theory was employed to investigate the tilted compounds theoretically. All the Quantum chemical calculations were performed by implying the Density functional theory technique, B3LYP method and 6-311++G (d, p) basis set. The reactive areas of the molecule were obtained by Fukui functions. The ADME properties and drug-likeness nature of the derivatives were obtained by SwissADME Tool [1]. Molecular docking studies were also performed with different receptor proteins to study the best ligand-protein interactions. The biological study-drug-likeness was also performed to check the drug like nature of the molecule.",
        "affiliation_name": "Isabella Thoburn College",
        "affiliation_city": "Lucknow",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The Technological Emergence of AutoML: A Survey of Performant Software and Applications in the Context of Industry",
        "paper_author": "Scriven A.",
        "publication": "Foundations and Trends in Information Systems",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "With most technical fields, there exists a delay between fundamental academic research and practical industrial uptake. Whilst some sciences have robust and well-established processes for commercialisation, such as the pharmaceutical practice of regimented drug trials, other fields face transitory periods in which fundamental academic advancements diffuse gradually into the space of commerce and industry. For the still relatively young field of Automated/Autonomous Machine Learning (AutoML/AutonoML), that transitory period is under way, spurred on by a burgeoning interest from broader society. Yet, to date, little research has been undertaken to assess the current state of this dissemination and its uptake. Thus, this review makes two primary contributions to knowledge around this topic. Firstly, it provides the most up-to-date and comprehensive survey of existing AutoML tools, both open-source and commercial. Secondly, it motivates and outlines a framework for assessing whether an AutoML solution designed for real-world application is’performant’; this framework extends beyond the limitations of typical academic criteria, considering a variety of stakeholder needs and the human-computer interactions required to service them. Thus, additionally supported by an extensive assessment and comparison of academic and commercial case-studies, this review evaluates mainstream engagement with AutoML in the early 2020s, identifying obstacles and opportunities for accelerating future uptake.",
        "affiliation_name": "University of Technology Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Glaucoma Prediction Models Based on Ocular and Systemic Findings",
        "paper_author": "Landau Prat D.",
        "publication": "Ophthalmic Research",
        "citied_by": "3",
        "cover_date": "2023-12-18",
        "Abstract": "Introduction: Our aim was to explore the impact of various systemic and ocular findings on predicting the development of glaucoma. Methods: Medical records of 37,692 consecutive patients examined at a single medical center between 2001 and 2020 were analyzed using machine learning algorithms. Systemic and ocular features were included. Univariate and multivariate analyses followed by CatBoost and Light gradient-boosting machine prediction models were performed. Main outcome measures were systemic and ocular features associated with progression to glaucoma. Results: A total of 7,880 patients (mean age 54.7 ± 12.6 years, 5,520 males [70.1%]) were included in a 3-year prediction model, and 314 patients (3.98%) had a final diagnosis of glaucoma. The combined model included 185 systemic and 42 ocular findings, and reached an ROC AUC of 0.84. The associated features were intraocular pressure (48.6%), cup-to-disk ratio (22.7%), age (8.6%), mean corpuscular volume (MCV) of red blood cell trend (5.2%), urinary system disease (3.3%), MCV (2.6%), creatinine level trend (2.1%), monocyte count trend (1.7%), ergometry metabolic equivalent task score (1.7%), dyslipidemia duration (1.6%), prostate-specific antigen level (1.2%), and musculoskeletal disease duration (0.5%). The ocular prediction model reached an ROC AUC of 0.86. Additional features included were age-related macular degeneration (10.0%), anterior capsular cataract (3.3%), visual acuity (2.0%), and peripapillary atrophy (1.3%). Conclusions: Ocular and combined systemic-ocular models can strongly predict the development of glaucoma in the forthcoming 3 years. Novel progression indicators may include anterior subcapsular cataracts, urinary disorders, and complete blood test results (mainly increased MCV and monocyte count).",
        "affiliation_name": "Chaim Sheba Medical Center Israel",
        "affiliation_city": "Tel Hashomer tel Aviv",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Heterogeneous Instruction Set Architecture for RRAM-enabled In-memory Computing",
        "paper_author": "Zhou H.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "RRAM-enabled in-memory computing (IMC) is regarded as a promising solution for breaking the von Neumann bottleneck. Using RRAM-based IMC to construct heterogeneous computing systems can fully leverage the advantages of both digital and IMC platforms. Critical challenges are effectively managing the dataflows between the digital system and the analog IMC and providing a standard for communication. In this paper, from the perspective of hardware instruction execution, we designed a general RRAM-enabled analog instruction set architecture compatible with digital computing. These instructions adopted the vector-based computing concepts in RISC-V, and the examples compatible with RISC-V vector extension are demonstrated in detail. A tile-processing unit-array three-level architecture is also devolved to support the instruction execution. The hardware estimations are performed on 65 nm technology. Results indicate that the total activated power of the activated processing unit is 8.64 mW which is 4.9 times smaller than PUMA and 33.4 times smaller than ISAAC. The energy efficiency reaches 1190.7 GOPS/W, 1.42 × and 3.12 × compared with PUMA and ISAAC, respectively. Furthermore, as the analog and digital computing frequency increases, the peak energy efficiency can reach 40 TOPS/W which enables the future general use of the IMC-based heterogeneous system.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Non-idealities and Design Solutions for Analog Memristor-Based Content-Addressable Memories",
        "paper_author": "Manea P.P.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Memristor-based analog Content Addressable Memories (aCAMs) offer robust parallel pattern look-up capabilities, significantly enhancing the scope of In-Memory Computing applications. This paper presents challenges of these analog circuits, which may occur during the inference, and proposes solutions to overcome them. Precisely, we investigate the impact of temperature-dependent behavior, CMOS process variations and memristor telegraph read noise. We demonstrate that one challenging issue affecting memristors analog computing applications, namely telegraph read noise, is not a significant problem in aCAM. We introduce a framework that accounts for these combined distortions to define variability-aware aCAM windows and estimate the bit resolution of a CAM cell. Using this framework we estimate the bit resolution to 2 bits before applying compensating measures and to 4 bits afterwards. We study how variations affect the inference accuracy of the IRIS classification dataset using our novel torchCAM model. We introduce a streamlined aCAM design featuring a memristor comparator for simplified input-to-reference comparison and a novel cell architecture with two symmetrical memristor comparator units.",
        "affiliation_name": "Rheinisch-Westfälische Technische Hochschule Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A Reconfigurable and Machine Learning attack resistant strong PUF based on Arbiter Mechanism and SOT-MRAM",
        "paper_author": "Li P.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "This paper presents a strong physical unclonable function (PUF) based on the arbiter mechanism and spin orbit torque magnetic random access memory (SOT-MRAM). This proposed PUF can be easily reconfigured, with 232 challenge-response pairs (CRPs) generated during each reconfiguration. Meanwhile, the proposed PUF shows a strong resistance against typical machine learning modeling attacks.",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Crop improvement strategies and principles of selective breeding",
        "paper_author": "Singha S.",
        "publication": "Water-Soil-Plant-Animal Nexus in the Era of Climate Change",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Introducing new crop varieties, crop improvement, and selective breeding enable contemporary agri¬culture to alleviate food poverty, increase crop production, and enhance product quality. This chapter covers selective breeding, genetically modified crops, genetic resource conservation, and upcoming technologies. Selective breeding discusses heritability, gene frequency, dominance, and epistasis to predict genetic progress. Agricultural innovation involves genetic variety and variation to develop robust and high-performing crop types. Mass selection, pedigree selection, and recurrent selection for trait enhancement are investigated. Marker-assisted and genomic selection are tested for breeding speed and accuracy. The chapter covers genetically modified crops, agricultural improvement, and genetic resource conservation for sustainable agriculture. Gene editing, synthetic biology, and machine learning may boost agricultural yields. According to the abstract, crop development and selective breeding are es¬sential for food security, sustainability, climate change, and agricultural demands.",
        "affiliation_name": "Kristu Jayanti College",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The intersection of learning, of the growth mindset, and of the emotions: A junction designed by knowledge and artificial intelligence",
        "paper_author": "Mengalli N.M.",
        "publication": "AI and Emotions in Digital Society",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "This chapter was written based on qualitative and exploratory studies by reading current reports and articles at the time of writing. The objective of writing the chapter was to provide support for the countless reflections of researchers and professionals in areas that use disruptive technologies as a strategy. In the investigation, it was realized that it was a prosperous field for all areas; after all, the human being is the protagonist and artificial intelligence can be supporting people. However, it is a new topic and requires a lot of research. In the final considerations, among the conclusions, it emerges that science fiction in books and films highlight a reality in which human emotion and feeling exist and that the plot with disruptive technologies does not overshadow people's behavior because the focus on professions of the future must be human beings interacting with machines.",
        "affiliation_name": "Faculdade São Bernardo do Campo",
        "affiliation_city": "Sao Bernardo do Campo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Surveillance of age and gender with ML: A knowledge based statistical analysis for next gen software products",
        "paper_author": "Rastogi R.",
        "publication": "Federated Learning and AI for Healthcare 5.0",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Gender and age classification is a major role for many purposes in the world. Humans have god-gifted facilities to recognize any gender and their age, but they cannot notice all the people, so the author team has trained the machine to work at those which are not capable of recognizing by simply seeing the people. Nowadays, the age and gender classification have a major role in the market, surveillance, security, etc. This research work for age and gender detection is different from the other project for facial recognition. As in this research, fisherface algorithm has been used which is very easy and accurate, and which simply works on the basis of facial recognition. The authors have used an audience dataset which is today's most demanding dataset as it is a self-updated dataset, and easily available on the open source. It basically depends on the deep learning in which openCv is used for the implementation of the given algorithm and dataset. As it does not require any complex calculations to recognize the faces, it is very fast and easy to use as compared to the other projects.",
        "affiliation_name": "HCL Technologies Ltd.",
        "affiliation_city": "Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Federated learning and AI for Healthcare 5.0",
        "paper_author": "Hassan A.",
        "publication": "Federated Learning and AI for Healthcare 5.0",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "The Healthcare sector is experiencing a change in thinking with the advent of Healthcare 5.0, bringing forth improved patient care and system efficiency. However, this transformation poses significant challenges. The growing digitization of healthcare systems raises concerns about the security and privacy of patient data, making seamless data sharing and collaboration increasingly complex tasks. Additionally, as the volume of healthcare data expands exponentially, efficient handling and analysis become vital for optimizing healthcare delivery and patient outcomes. Addressing these multifaceted issues is crucial for healthcare professionals, IT experts, data scientists, and researchers seeking to fully harness the potential of Healthcare 5.0. Federated Learning and AI for Healthcare 5.0 presents a comprehensive solution to the pressing challenges in the digitalized healthcare industry; it dives into the principles of Healthcare 5.0 and explores practical implementation through cloud computing, data analytics, and federated learning. Readers will gain profound insights into the role of cloud computing in managing vast amounts of healthcare data, such as electronic health records and real-time analytics. Cloud-based frameworks, architectures, and relevant use cases are explored to optimize healthcare delivery and improve patient outcomes. Federated Learning and AI for Healthcare 5.0 encourages readers to take initiative and address the security and privacy concerns of cloud-based healthcare systems. It offers invaluable strategies, including security primitives, trust-based architectures, privacy models, and compliance standards, ensuring the protection of sensitive patient data while enabling secure data sharing and collaboration within the healthcare ecosystem. In-depth exploration of federated learning in healthcare empowers professionals with a comprehensive understanding of this distributed machine learning approach, preserving data privacy during analysis. Through practical case studies and simulations, readers gain actionable insights to implement federated learning models and frameworks, bringing tangible improvements to real-world healthcare 5.0 scenarios. The book explores emerging technologies like quantum computing, blockchain-based FL cloud services, and intelligent SaaS APIs, envisioning a future where these innovations redefine healthcare 5.0 and lead to groundbreaking advancements. Federated Learning and AI for Healthcare 5.0 serves as an indispensable resource, empowering healthcare professionals, IT experts, data scientists, and academicians to navigate the complexities of modern healthcare, leveraging innovative technologies to revolutionize patient care and system efficiency. With its comprehensive approach and practical insights, this book stands at the forefront of advancing Healthcare 5.0 into a more secure, efficient, and patient-centric era.",
        "affiliation_name": "Amity University Kolkata",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Application domains of federated learning in healthcare 5.0",
        "paper_author": "Kumar T.A.",
        "publication": "Federated Learning and AI for Healthcare 5.0",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Federated learning has emerged as a game-changing approach in machine learning, allowing high- quality centralised models to be trained across a network of decentralised clients. Federated Learning is defined by the collaborative learning process that involves a large number of customers, each of whom contributes insights from their localised datasets. This collaborative approach is critical in cases where data privacy and network constraints are critical. This research focuses on the unique learning algo¬rithms built for this situation. Individual clients autonomously compute model changes based on their local data at each iteration, then communicate these modifications to a central server. These client-side updates are subsequently aggregated by the central server, resulting in the construction of an updated global model. The challenge in this situation is to train models efficiently while dealing with clients who have inconsistent and slow network connections.",
        "affiliation_name": "IFET College of Engineering",
        "affiliation_city": "Viluppuram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Applications of pipelining with ML to authenticate emotions in textual contents",
        "paper_author": "Varshney Y.",
        "publication": "Federated Learning and AI for Healthcare 5.0",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "This research chapter aims to provide a smart approach for Human - Machine Interaction develop¬ment using emotion detection on textual content. These texts can be anything like reviews, tweets, and any form of passage. As the machine is being advanced so that all the performance and commands are given in the text form. This is necessary to analyze the textual content for getting better performance and making the machines smarter. As the customers share their views on social media through the reviews, this mechanism is now spread across all the organization. Nowadays, the number of reviews and tweets are increasing and there is a necessity to analyze the data for further results. In this research, the team analyzes the tweets content in the forms of emotions in which there are multiple forms of the emotions. The machine learning approach is used with tf-idf vectorization for more accuracy. In the presented research, the team performs four machine learning algorithms for analysis; these include Naive Bayes and support vector machine.",
        "affiliation_name": "ABES Engineering College",
        "affiliation_city": "Ghaziabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "AI-powered healthcare system to fight the COVID-19 pandemic on federated learning",
        "paper_author": "Gnanamurthy S.",
        "publication": "Federated Learning and AI for Healthcare 5.0",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The COVID-19 pandemic has caused several healthcare-related problems around the world. The pan¬demic has highlighted the shortcomings of employing current digital healthcare tools to manage public health emergencies. As a result, the COVID-19 issue has forced countries and research organizations to reassess healthcare delivery solutions to continue supplies while people stay at home or practice social isolation. Innumerable works of fiction have attempted to anticipate stock market returns and volatility using AI and machine learning. There is a dearth of a comprehensive overview of the various research orientations, discoveries, methodological methods, and contributions in the field of AI applications in finance. This research replicates realistic scenarios using a real COVID-19 dataset and evaluates issues such as model repetition delays, assuring the model's reliability and applicability. According to research findings, using this technology will enable medical professionals to detect coronavirus disease, achieve multiparty involvement in training, and improve data protection.",
        "affiliation_name": "Kuppam Engineering College",
        "affiliation_city": "Kuppam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Healthcare 5.0: Intelligent lung cancer disease prediction model using blockchain¬based federated learning method",
        "paper_author": "Dhanasekaran P.",
        "publication": "Federated Learning and AI for Healthcare 5.0",
        "citied_by": "2",
        "cover_date": "2023-12-18",
        "Abstract": "Healthcare 4.0 is a term coined by the healthcare sector in response to this transformation. In the present investigation, the authors present a blockchain-based federation learning strategy for smart healthcare, where the edge nodes control the blockchain to avoid a single point of failures and the MIoT gadgets use federated instruction to fully utilize the distributed medical information. The proposed intelligent system uses federated deep extreme neural networks for lung illness prediction. Additionally, for improved lung disease prediction, the proposed model is strengthened using a fused scaled deep extreme machine learn¬ing algorithm. The merged scaled federated deep extreme predictive machine learning model is utilized to verify the best cancer illness predictions in the smart healthcare sector 5.0 that has been provided. The results of the indicated fused balanced federation extreme deep learning methodology was 98.3%.",
        "affiliation_name": "Dr. N.G.P. Institute of Technology",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Multivariate regression trees as an \"explainable machine learning\" approach to explore relationships between hydroclimatic characteristics and agricultural and hydrological drought severity: case of study Cesar River basin",
        "paper_author": "Paez-Trujilo A.",
        "publication": "Natural Hazards and Earth System Sciences",
        "citied_by": "2",
        "cover_date": "2023-12-18",
        "Abstract": "The typical drivers of drought events are lower than normal precipitation and/or higher than normal evaporation. The region's characteristics may enhance or alleviate the severity of these events. Evaluating the combined effect of the multiple factors influencing droughts requires innovative approaches. This study applies hydrological modelling and a machine learning tool to assess the relationship between hydroclimatic characteristics and the severity of agricultural and hydrological droughts. The Soil Water Assessment Tool (SWAT) is used for hydrological modelling. Model outputs, soil moisture and streamflow, are used to calculate two drought indices, namely the Soil Moisture Deficit Index and the Standardized Streamflow Index. Then, drought indices are utilised to identify the agricultural and hydrological drought events during the analysis period, and the index categories are employed to describe their severity. Finally, the multivariate regression tree technique is applied to assess the relationship between hydroclimatic characteristics and the severity of agricultural and hydrological droughts. Our research indicates that multiple parameters influence the severity of agricultural and hydrological droughts in the Cesar River basin. The upper part of the river valley is very susceptible to agricultural and hydrological drought. Precipitation shortfalls and high potential evapotranspiration drive severe agricultural drought, whereas limited precipitation influences severe hydrological drought. In the middle part of the river, inadequate rainfall partitioning and an unbalanced water cycle that favours water loss through evapotranspiration and limits percolation cause severe agricultural and hydrological drought conditions. Finally, droughts are moderate in the basin's southern part (Zapatosa marsh and the Serranía del Perijá foothills). Moderate sensitivity to agricultural and hydrological droughts is related to the capacity of the subbasins to retain water, which lowers evapotranspiration losses and promotes percolation. Results show that the presented methodology, combining hydrological modelling and a machine learning tool, provides valuable information about the interplay between the hydroclimatic factors that influence drought severity in the Cesar River basin.",
        "affiliation_name": "Institute of Water Problems of the Russian Academy of Sciences",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Unravelling the enigma of machine learning model interpretability in enhancing disease prediction",
        "paper_author": "Tripathi R.K.P.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Machine learning (ML) models have made significant strides in disease prediction, providing new avenues for early detection and intervention. These models have demonstrated remarkable capabilities in analysing vast and complex datasets to identify patterns and trends that can aid in early diagnosis and treatment. However, opacity of these models often leaves healthcare practitioners and patients in the dark about the reasoning behind their predictions, raising concerns about trust, fairness, and practical adoption of AI-based disease prediction. This review delves into the critical topic of interpretability in ML models for disease prediction, its importance, techniques to achieve it, impact on clinical decisionmaking, challenges, and implications in healthcare. Urgent issues and moral dilemmas pertaining to model interpretability in healthcare, areas for further research to enhance interpretability of predictive models, and applications are also highlighted. Thus, the chapter provides insights into the applicability of AI-driven models to improve healthcare decision-making and patient outcomes.",
        "affiliation_name": "Galgotias University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Predicting depression from social media users by using lexicons and machine learning algorithms",
        "paper_author": "Selvaraj S.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Depression is one of the most common health issues among individuals. The rate of psychotic treatments is increasing day by day. Depression is created in many ways among the people, especially through work stress, financial burden, unemployment among the adults. Today, the emergence of social media into people's lives makes them expose their feelings and emotions on the social media platforms. The aim of this work is to predict the depressive features from social media users' comments by using machine learning techniques. Multinomial naive bayes, non-linear support vector machine, and artificial neural network methods are used for classifying the features and comparing it using performance evaluation metrics and get the best classifier. This system includes data pre-processing, feature extraction, data splitting, classification, and performance evaluation. The results show that the proposed system has gradually improved performance accuracy. According to the results, ANN gives 99.19%, the best accuracy compared to other machine learning classifiers.",
        "affiliation_name": "Mepco Schlenk Engineering College",
        "affiliation_city": "Sivakasi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Malware analysis and classification using machine learning models",
        "paper_author": "Swadeep S.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "In modern times, it has become common practice for major corporations to utilize computers for storing data. Unfortunately, the frequency of malware attacks has increased, which facilitates unauthorized individuals' access to private information. Analyzing malware has become a critical task in safeguarding information systems against malicious attacks. Therefore, machine learning techniques have become an effective tool for automating investigations using static and dynamic analysis, combining malware with similar behavior into separate families based on proximity. Deep learning techniques improve the accuracy of malware variant detection and classification by building neural networks with more potentially different layers. This research aims to address this issue by training machine learning models using various algorithms on a dataset obtained by performing static and dynamic analysis on both malicious and benign samples. The resulting models were then combined to produce superior results compared to those obtained from a single model, which can be seen in the results.",
        "affiliation_name": "Vellore Institute of Technology, Chennai",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine learning algorithms using scikit and tensorflow environments",
        "paper_author": "Maruthi P.B.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Machine learning is able to solve real-time problems. It has several algorithms such as classification, clustering, and more. To learn these essential algorithms, we require tools like Scikit and TensorFlow. Machine Learning Algorithms Using Scikit and TensorFlow Environments assists researchers in learning and implementing these critical algorithms. Covering key topics such as classification, artificial neural networks, prediction, random forest, and regression analysis, this premier reference source is ideal for industry professionals, computer scientists, researchers, academicians, scholars, practitioners, instructors, and students.",
        "affiliation_name": "Vellore Institute of Technology, Chennai",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "SRAM memory testing methods and analysis: An approach for traditional test algorithms to ML models",
        "paper_author": "Parvathi M.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "In the scenario of growing technologies towards single digit nanometer range, the existing algorithmic contemporary test methods have become inadequate in detecting all the faults within the static random access memory. To address the issues related to contemporary test methods, machine learning-based test analysis is proposed, which elevates the method of dataset preparation using various process parameters that are drawn from functional fault models (FFMs). The outcome of this proposed work is modeling of FFMs using ML regression, classification, and further prediction with accuracy analysis. The experiments resulted that logistic regression is best suited model that resulting with high accuracy in the range of 95% to 97%, compared to the linear regression model that results in accuracy levels in the range of 26.58% to 63%.",
        "affiliation_name": "BVRIT Hyderabad College of Engineering for Women",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Early detection of Alzheimer's using artificial intelligence for effective emotional support systems",
        "paper_author": "Sivasangari A.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The prominence of technological progress is evident only when its fruits reaching the society. Any disruptive technology has such a profound effect; artificial intelligence is not an exception. This chapter highlights one such technological impact for the benefit of mankind. Alzheimer's is a known neurological illness, sometimes leading to terminal stage of human life. The treatment becomes complicated when diagnosis takes place at a later stage of the disease. The prognosis and diagnosis, if supported by a technology such as artificial intelligence, will be made better by delaying the disease progression. In this chapter, machine learning algorithms such as random forest, cross validation method is used to analyze, train, and predict Alzheimer's disease and its progression. This in turn helps in improving the emotional support system to the patients. Several research groups are working on this domain, and here the insights provided are going to be more significant and useful for further investigations.",
        "affiliation_name": "Sathyabama Institute of Science and Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Using ensemble learning and random forest techniques to solve complex problems",
        "paper_author": "GladShiya V.B.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "2",
        "cover_date": "2023-12-18",
        "Abstract": "The branch of computer science and artificial intelligence known as machine learning is used to program machines to learn. Algorithms for machine learning are software programs or methods used to find hidden patterns in data, predict outcomes, and improve performance based on past performance. A technique used in machine learning called ensemble learning combines several models, such as classifiers or experts that have been carefully constructed to solve a particular computational intelligence problem. Ensemble refers to a collaborative effort to create a single impact. An ensemble can predict events more accurately and perform better in general than a single contributor. A random forest is a technique for ensemble learning in which many decision trees are combined to create the forest. This chapter covers the fundamentals of ensemble learning using random forest, implementation with realworld examples, and developing a model.",
        "affiliation_name": "Agurchand Manmull Jain College",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine learning algorithm with TensorFlow and SciKit for next generation systems",
        "paper_author": "Chopra A.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Machine learning plays a vital role in all major sectors like healthcare, banking, finance, and marketing. There is a need to understand the role and working of ML algorithms in a better way. Google also uses a learning algorithm to rank the web pages whenever we try to browse the internet to get the desired information. Understanding the platform and working of these algorithms is crucial for researchers. In this chapter, the authors have presented an overview of machine learning fundamentals and the working of these algorithms with suitable examples. They have also highlighted the importance of major machine learning libraries like TensorFlow and SciKit in developing and deploying vast applications. Finally, a case study of ML application is presented to better understand the concept. Future prospects of ML applications are also depicted in detail.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Classification models in machine learning techniques",
        "paper_author": "Majumder A.",
        "publication": "Machine Learning Algorithms Using Scikit and TensorFlow Environments",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Classification is the process of identifying, understanding, and grouping objects and ideas into specified categories. These pre-categorized training datasets are used by machine learning techniques to classify datasets into relevant and acceptable categories. Using the incoming training data, machine learning classifiers assess the chance or probability that the incoming data will fall into one of the established categories. One of categorization's most prominent applications is used by the largest email service providers of today: classifying emails as \"spam\" or \"non-spam. \" In essence, classification is a form of \"pattern recognition. \" Following the application of classification algorithms to the training data, the same pattern (similar number sequences, words, or attitudes, etc.) is found in future data sets. Classification falls within the category of supervised learning in the context of machine learning.",
        "affiliation_name": "National Institute of Technology Jamshedpur",
        "affiliation_city": "Jamshedpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Performance Analysis of the Distributed Support Vector Machine Algorithm Using Spark for Predicting Flight Delays",
        "paper_author": "Khotimah H.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "In big data analysis requires powerful machine learning frameworks, strategies, and environments to analyze data at scale. Therefore, Apache Spark is used as a cluster computing framework to process big data in parallel and can run on multiple clusters. In this study, the Support Vector Machine (SVM) algorithm is used as a classification method to predict whether a flight will experience a delayed arrival. This study also aims to analyze the performance of the distributed SVM algorithm using the Apache Spark framework in classifying delayed flight arrivals. Running time evaluation is important in proving how fast the data processing is done using Apache Spark. In addition, there is a test to prove the effect of using the SVM algorithm with a distributed system on the results of the classification accuracy of delayed flight arrivals. Distributed SVM performance testing is carried out using variations in data size and the number of worker nodes in the built cluster. From the test results, it was found that the most effective number of worker nodes used in the flight delay classification process was 4 worker nodes with the lowest running time results from the experiment of 4 variations in the number of worker nodes. In terms of accuracy, adding the number of worker nodes does not affect the accuracy of the program. The difference in the accuracy of results is caused by the random oversampling process on the data performed on each system test. Using the SVM algorithm with Spark is sufficient to provide good performance in the classification process with the highest accuracy result in the test being 93.98 %.",
        "affiliation_name": "University of Mataram",
        "affiliation_city": "Mataram",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Implementation of Machine Learning for Text Classification Using the Naive Bayes Algorithm in Academic Information Systems at Sebelas Maret University Indonesia",
        "paper_author": "Humaidi M.H.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "This study implements machine learning using the Naive Bayes algorithm to create a text classification in an engineering professional program information system. The methods used include text data collection, preprocessing, feature extraction, Naive Bayes model training, and evaluation using data testing. This study made a classification model to predict text categories with a test accuracy rate of 0.975 and a training accuracy of 0.967. This research contributes to the development of text classification in information systems and can be used as a basis for further study.",
        "affiliation_name": "Universitas Sebelas Maret",
        "affiliation_city": "Surakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Distributed Machine Learning using HDFS and Apache Spark for Big Data Challenges",
        "paper_author": "Indirman M.D.C.",
        "publication": "E3S Web of Conferences",
        "citied_by": "2",
        "cover_date": "2023-12-18",
        "Abstract": "Hadoop and Apache Spark have become popular frameworks for distributed big data processing. This research aims to configure Hadoop and Spark for conducting training and testing on big data using distributed machine learning methods with MLlib, including linear regression and multi-linear regression. Additionally, an external library, LSTM, is used for experimentation. The experiments utilize three desktop devices to represent a series of tests on single and multi-node networks. Three datasets, namely bitcoin (3,613,767 rows), gold-price (5,585 rows), and housing-price (23,613 rows), are employed as case studies. The distributed computation tests are conducted by allocating uniform core processors on all three devices and measuring execution times, as well as RMSE and MAPE values. The results of the single-node tests using MLlib (both linear and multi-linear regression) with variations of core utilization ranging from 2 to 16 cores, show that the overall dataset performs optimally using 12 cores, with an execution time of 532.328 seconds. However, in the LSTM method, core allocation variations do not yield significant results and require longer program execution times. On the other hand, in the multinode (2) tests, optimal performance is achieved using 8 cores, with an execution time of 924.711 seconds, while in the multi-node (3) tests, the ideal configuration is 6 cores with an execution time of 881.495 seconds. In conclusion, without the involvement of HDFS, distributed MLlib programs cannot be processed, and core allocation depends on the number of nodes used and the size of the dataset.",
        "affiliation_name": "University of Mataram",
        "affiliation_city": "Mataram",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Spatial rain probabilistic prediction performance using cost-sensitive learning algorithm",
        "paper_author": "Saputra A.H.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The use of machine learning in weather prediction is growing rapidly as an alternative to conventional numerical weather prediction. However, predictions using machine learning such as Long Short Term Memory (LSTM) based on neural networks have weaknesses in predicting extreme events with a high ratio of unbalanced data. This research examines the performance of using focal loss in LSTM to obtain a machine-learning model that is cost-sensitive. The model used the Global Forecasting System Data and the Global Satellite Measurement of Precipitation for the years 2017-2020. Testing the hyperparameter configuration was carried out using the hyperband method on the number of nodes and the number of iterations with 3 scenarios (2, 3, and 4 classes). The results showed an increased performance against noncost sensitive LSTM with an average increase of 25% accuracy and 11% F1-score on 2 classes scenario, 15% accuracy increase and 21% F1-score for scenario 3 classes, as well as an increase in accuracy of 15% and F1-score 26% for scenario 4 class. It also provides the idea of how cost-sensitive properties can help machine learning models detect classes with extreme ratios, based on an increase in average performance as the number of classification scenarios increases.",
        "affiliation_name": "Meteorology",
        "affiliation_city": "Kotabaru",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Enhancing Predictive Accuracy: Assessing the Effectiveness of SVM in Predicting Medical Student Performance",
        "paper_author": "Setyonugroho W.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The high cost of pursuing a medical education necessitates effectively monitoring and evaluating medical students' performance. This study aimed to develop and evaluate a prediction system for medical students’ national exam scores using the Support Vector Machine (SVM) algorithm. The dataset consisted of grades from first and second-year medical students at Muhammadiyah University of Yogyakarta, specifically from the 2014 and 2015 classes, to predict the final year exam score. The methodology involved data acquisition, data preprocessing, and classification and prediction of student performance. Remarkably, the SVM model achieved an accuracy rate of 95.48%. The findings highlight the substantial potential of SVM for accurately predicting medical student performance. The prediction system can enable educational institutions to proactively identify students needing additional support or intervention. This early intervention can help improve academic progress and enhance the overall quality of medical education. Future research efforts should focus on improving the prediction system's practicality and effectiveness by incorporating additional factors. This study successfully developed and evaluated a prediction system for medical student performance using the SVM algorithm. The high accuracy achieved by the SVM model emphasises its potential as a valuable tool for medical education institutions. By leveraging machine learning, educational institutions can provide targeted support to students, leading to improved learning outcomes and advancements in medical education.",
        "affiliation_name": "Politeknik Negeri Padang",
        "affiliation_city": "Padang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "An Analysis of Image Enhancement Effects on Convolutional Neural Network-based Pulmonary Tuberculosis Detection",
        "paper_author": "Susilo D.",
        "publication": "E3S Web of Conferences",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "Pulmonary Tuberculosis (TB) is a primary global infectious disease. Diagnosing TB patients involves medical examination and chest X-ray (CXR) imaging. This CXR image creates an opportunity to utilize machine learning to help physicians and radiologists diagnose TB suspects. Due to the inconsistency of image quality, image enhancement is one of the preprocessing steps to overcome the poor quality of the image. This study examines the effects of several image enhancement techniques, i.e., Histogram Equalization (HE), Contrast Limited Adaptive Histogram Equalization (CLAHE), and Fast Fourier Transform (FFT). These enhanced images are input for a Convolutional Neural Network (CNN). InceptionV3 is a transfer learning architecture with ImageNet as the pre-trained model. The image dataset consists of 3,500 normal and 3,500 tuberculosis CXR images. The best performance, in terms of accuracy and processing time, is achieved by the CLAHE enhancement technique, increasing accuracy by 4.57% compared to the original images as input and a processing time of 5.6 ms faster per testing image. A deeper analysis shows despite FFT achieving high performance, the processing time increases by 14.4 ms compared to the original image processing time. This study concluded that each image enhancement needs to consider the characteristics of the images.",
        "affiliation_name": "Universitas Gadjah Mada",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "A Machine Learning Approach to Improving Timing Consistency between Global Route and Detailed Route",
        "paper_author": "Chhabria V.A.",
        "publication": "ACM Transactions on Design Automation of Electronic Systems",
        "citied_by": "3",
        "cover_date": "2023-12-18",
        "Abstract": "Due to the unavailability of routing information in design stages prior to detailed routing (DR), the tasks of timing prediction and optimization pose major challenges. Inaccurate timing prediction wastes design effort, hurts circuit performance, and may lead to design failure. This work focuses on timing prediction after clock tree synthesis and placement legalization, which is the earliest opportunity to time and optimize a \"complete\"netlist. The article first documents that having \"oracle knowledge\"of the final post-DR parasitics enables post-global routing (GR) optimization to produce improved final timing outcomes. To bridge the gap between GR-based parasitic and timing estimation and post-DR results during post-GR optimization, machine learning (ML)-based models are proposed, including the use of features for macro blockages for accurate predictions for designs with macros. Based on a set of experimental evaluations, it is demonstrated that these models show higher accuracy than GR-based timing estimation. When used during post-GR optimization, the ML-based models show demonstrable improvements in post-DR circuit performance. The methodology is applied to two different tool flows - OpenROAD and a commercial tool flow - and results on an open-source 45nm bulk and a commercial 12nm FinFET enablement show improvements in post-DR timing slack metrics without increasing congestion. The models are demonstrated to be generalizable to designs generated under different clock period constraints and are robust to training data with small levels of noise.",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Unraveling the effect of single atom catalysts on the charging behavior of nonaqueous Mg CO2 batteries: A combined density functional theory and machine learning approach",
        "paper_author": "Pritom R.",
        "publication": "Journal of Materials Chemistry A",
        "citied_by": "4",
        "cover_date": "2023-12-18",
        "Abstract": "This study integrates density functional theory (DFT) and machine learning (ML) methodologies to investigate the charging performance and catalyst design principles of porphyrin-supported single atom catalysts (SACs) based on 3d and 4d transition metals (TMs) in the context of nonaqueous Mg CO2 batteries. Specifically, we utilize DFT calculations to elucidate the adsorption energies of the primary discharge product, MgCO3, on SACs supported on NxSy (where x = 4, 3, 2 and y = 0, 1, 2, respectively) moieties of porphyrin. Our analysis unveils the ability of these SACs to effectively bind with MgCO3, which correlates with enhancing the kinetics of its decomposition, a pivotal factor influencing the charging performance. The results demonstrate that the improved adsorption energies of early TMs are expected to reduce the decomposition barrier for MgCO3 during battery charging. Furthermore, we leverage a DFT-derived dataset to construct ML models using Gradient Boosting Regression (GBR) and Artificial Neural Network (ANN) algorithms. Employing K-fold cross-validation, both algorithms consistently exhibit remarkable accuracy in their predictions. To unravel the catalyst design principles, we also conduct feature importance analysis, using SHapley Additive exPlanations (SHAP), Permutation Importance, and Mean Decrease Impurity (MDI) techniques to identify the most significant features. This study reveals that the ionization potential of TMs is the most important descriptor for the selection of SACs for cathodes in Mg CO2 batteries. Overall, this combined DFT and ML investigation provides insights into both the charging performance of SACs in Mg CO2 batteries and the fundamental principles governing catalyst design.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Detroit",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Evolutionary computation and streaming analytics machine learning with IoT for urban intelligent systems",
        "paper_author": "Ganesh Babu R.",
        "publication": "Semantic Intelligent Computing and Applications",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "In the Internet of things (IoT) era, for a wide range of fields and applications, a vast number of detecting gadgets collect or potentially produce different tactile information after a while. These gadgets can cause large or fast/constant streams of information. Examining these information sources in order to find new data predict future bits of knowledge, and decide on control choices is a critical process that makes IoT a commendable worldview for organizations and a personal satisfaction that enhances innovation. In this chapter, we give a careful review on the use of a class of cutting-edge artificial intelligence (AI) systems to advance deep learning (DL), thus enhancing IoT space inspection and encouraging learning. We begin by articulating IoT information attributes and recognizing two essential IoT information medicines from an AI perspective: IoT massive evolutionary computation and streaming information analysis and IoT gushing information review are two expels of IoT. We also explore why DL is a good way to perfectly handle investigation in these kinds of data and applications. The capacity to use DL procedures for investigation of IoT information is then addressed, and its guarantees and difficulties are identified. On various DL systems and measurements, we pose a far-ranging base. We also research and detail major research projects that used DL in IoT space. Furthermore, elegant IoT gadgets that fused DL into their knowledge base are investigated. On the basis of IoT applications, the mist and cloud-based DL implementation approach is also overviewed. We finally shed light on some problems and possible reasons that need further research.",
        "affiliation_name": "Graphic Era Hill University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Applications of artificial intelligence for employees' health and safety: Present and future",
        "paper_author": "Gupta S.",
        "publication": "Semantic Intelligent Computing and Applications",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The rapid development in Industry 4.0 era has led to an exponential increase in machines of high potency which are essential for economic growth, thereby increasing the risk for employees. An unsafe and unhealthy work environment can impede the innovation and productivity of employees, which may result in damaging the reputation of the industries. Therefore, there is a need to give a serious thought to these unaddressed issues which may be useful in the safety of our employees. Machine learning (ML) has been pervasively applied across disparate disciplines, especially in industries, and has been found to be significantly efficacious in improving the performance. The capabilities of ML and artificial intelligence (AI) can be exploited to offset the shortcomings of traditional approaches to employees' safety. This chapter tries to address this issue. Recent advances in this domain are assessed that use ML and AI to address, resolve, and ameliorate the safety concerns of employees. Various applications using supervised learning, semisupervised learning, unsupervised learning, and reinforcement learning methodologies have been delineated. Further, detailed reasoning on why semisupervised learning methodology is preferred currently, primarily due to its high throughput, and the advantage of generating warnings with minimal requirement of historical data has been discussed. Complex deep learning models have become feasible, owing to the easy access to fast modern computers. Of the diverse implementations of neural networks used, this comes at the cost of blackbox models generated in deep learning techniques that might reduce the trust to effectuate such technologies. This treatise proposes explainable artificial intelligence (XAI) as a potential solution for this problem, which can be used to augment employees' trust in these black-box models by providing a lucid explanation of the model's working. In totality, this exposition maintains that these ML and deep learning techniques are effective in enhancing workplace health, safety, and environment, as their competence to automate reasoning can culminate in better-informed decisions and effective accident prevention.",
        "affiliation_name": "Dwarkadas Jivanlal Sanghvi College of Engineering",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "SUSTAINABILITY IN PROPERTY TAXATION: AN APPLICATION FOR REVENUE STABILITY AND FAIRNESS PERSPECTIVES, THE CITY OF BUFFALO, NY",
        "paper_author": "Ozmen E.",
        "publication": "International Journal of Strategic Property Management",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "The scholarly modeling of property tax has always posed a challenge, with two primary concerns to be addressed: first, maintaining sustainability in the collection, which is primarily a concern for local governments; and second, ensur-ing fair distribution, which is of greater concern for citizens. In today’s practices, assessment-based property tax increases unmatched expenses in bubble economies. There is a substitution problem in rapid falls, the tendency to not decrease the assessments gives way to black holes and opens the door to ghost cities. This paper proposes alternative approaches, aside from market/land value or last sold price, aimed at improving sustainability and fairness rates. The dataset examined is based on 93.7K records and 88 attributes for assessed value of properties within the City of Buffalo, the United States of America. Since the label (Total Value) is a numerical and continuous value, regression models are selected, where ensemble machine learning methods categorically work well with larger datasets, combined with weak learners, like decision trees. Stacked Ensemble led the least error for regression with 0.98 R2, followed by Gradient Boosting. Results show a 79% domi-nance of uncontrollable attributes, such as Land Value, Neighborhood, and Sale (last sold) Price, compared to controllable attributes, such as Total Living Area, Construction Grade, Second Story Area, and many others. This article suggests hav-ing a more balanced split between uncontrollable and controllable attributes would contribute to both sustainability and fair distribution.",
        "affiliation_name": "DeVry University",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Can a Machine Ace the Test? Assessing GPT-4.0's Precision in Plastic Surgery Board Examinations",
        "paper_author": "Al Qurashi A.A.",
        "publication": "Plastic and Reconstructive Surgery - Global Open",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Background: As artificial intelligence makes rapid inroads across various fields, its value in medical education is becoming increasingly evident. This study evaluates the performance of the GPT-4.0 large language model in responding to plastic surgery board examination questions and explores its potential as a learning tool. Methods: We used a selection of 50 questions from 19 different chapters of a widely-used plastic surgery reference. Responses generated by the GPT-4.0 model were assessed based on four parameters: accuracy, clarity, completeness, and conciseness. Correlation analyses were conducted to ascertain the relationship between these parameters and the overall performance of the model. Results: GPT-4.0 showed a strong performance with high mean scores for accuracy (2.88), clarity (3.00), completeness (2.88), and conciseness (2.92) on a three-point scale. Completeness of the model's responses was significantly correlated with accuracy (P < 0.0001), whereas no significant correlation was found between accuracy and clarity or conciseness. Performance variability across different chapters indicates potential limitations of the model in dealing with certain complex topics in plastic surgery. Conclusions: The GPT-4.0 model exhibits considerable potential as an auxiliary tool for preparation for plastic surgery board examinations. Despite a few identified limitations, the generally high scores on key parameters suggest the model's ability to provide responses that are accurate, clear, complete, and concise. Future research should focus on enhancing the performance of artificial intelligence models in complex medical topics, further improving their applicability in medical education.",
        "affiliation_name": "King Abdullah Medical City",
        "affiliation_city": "Makkah",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Clinical forecasting of acute myeloid leukemia using ex vivo drug-sensitivity profiling",
        "paper_author": "Andersen A.N.",
        "publication": "Cell Reports Methods",
        "citied_by": "2",
        "cover_date": "2023-12-18",
        "Abstract": "Current treatment selection for acute myeloid leukemia (AML) patients depends on risk stratification based on cytogenetic and genomic markers. However, the forecasting accuracy of treatment response remains modest, with most patients receiving intensive chemotherapy. Recently, ex vivo drug screening has gained traction in personalized treatment selection and as a tool for mapping patient groups based on relevant cancer dependencies. Here, we systematically evaluated the use of drug sensitivity profiling for predicting patient survival and clinical response to chemotherapy in a cohort of AML patients. We compared computational methodologies for scoring drug efficacy and characterized tools to counter noise and batch-related confounders pervasive in high-throughput drug testing. We show that ex vivo drug sensitivity profiling is a robust and versatile approach to patient prognostics that comprehensively maps functional signatures of treatment response and disease progression. In conclusion, ex vivo drug profiling can assess risk for individual AML patients and may guide clinical decision-making.",
        "affiliation_name": "Oslo Universitetssykehus",
        "affiliation_city": "Oslo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Quantitative comparison of the computational complexity of optical, digital and hybrid neural network architectures for image classification tasks",
        "paper_author": "Chen M.",
        "publication": "Optics Express",
        "citied_by": "3",
        "cover_date": "2023-12-18",
        "Abstract": "By implementing neuromorphic paradigms in processing visual information, machine learning became crucial in an ever-increasing number of applications of our everyday lives, ever more performing but also computationally demanding. While a pre-processing of the information passively in the optical domain, before optical-electronic conversion, can reduce the computational requirements for a machine learning task, a comprehensive analysis of computational requirements for hybrid optical-digital neural networks is thus far missing. In this work we critically compare and analyze the performance of different optical, digital and hybrid neural network architectures with respect to their classification accuracy and computational requirements for analog classification tasks of different complexity. We show that certain hybrid architectures exhibit a reduction of computational requirements of a factor >10 while maintaining their performance. This may inspire a new generation of co-designed optical-digital neural network architectures, aimed for applications that require low power consumption like remote sensing devices.",
        "affiliation_name": "University of Shanghai for Science and Technology",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Physiological Signals as Predictors of Mental Workload: Evaluating Single Classifier and Ensemble Learning Models",
        "paper_author": "Izzah N.",
        "publication": "Jurnal Optimasi Sistem Industri",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "With a growing emphasis on cognitive processing in occupational tasks and the prevalence of wearable sensing devices, understanding and managing mental workload has broad implications for safety, efficiency, and well-being. This study aims to develop machine learning (ML) models for predicting mental workload using Heart Rate Variability (HRV) as a representation of the Autonomic Nervous System (ANS) physiological signals. A laboratory experiment, involving 34 participants, was conducted to collect datasets. All participants were measured during baseline, two cognitive tests, and recovery, which were further separated into binary classes (rest vs workload). A comprehensive evaluation was conducted on several ML algorithms, including both single (Support Vector Machine – SVM, and Naïve Bayes) and ensemble learning (Gradient Boost and AdaBoost) classifiers and incorporating selected features and validation approaches. The findings indicate that most HRV features differ significantly during periods of mental workload compared to rest phases. The SVM classifier with knowledge domain selection and leave-one-out cross-validation technique is the best model (68.385). These findings highlight the potential to predict mental workload through interpretable features and individualized approaches even with a relatively simple model. The study contributes not only to the creation of a new dataset for specific populations (such as Indonesia) but also to the potential implications for maintaining human cognitive capabilities. It represents a further step toward the development of a mental workload recognition system, with the potential to improve decision-making where cognitive readiness is limited and human error is increased.",
        "affiliation_name": "Universiti Malaysia Pahang Al-Sultan Abdullah",
        "affiliation_city": "Pekan",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Approach for estimating the vertical distribution of the diffuse attenuation coefficient in the South China Sea",
        "paper_author": "Zhang X.",
        "publication": "Optics Express",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "The vertical distribution of the diffuse attenuation coefficient K(z, λ) is critical for studies in bio-optics, ocean color remote sensing, underwater photovoltaic power, etc. It is a key apparent optical property (AOP) and is sensitive to the volume scattering function β(ψ, z, λ). Here, using three machine learning algorithms (MLAs) (categorical boosting (CatBoost), light gradient boosting machine (LightGBM), and random forest (RF)), we developed a new approach for estimating the vertical distribution of Kd(z, 650), KLu(z, 650), and Ku(z, 650) and applied it to the South China Sea (SCS). In this approach, based on in situ β(ψ, z, 650), the absorption coefficient a(z, 650), the profile depths z, and Kd(z, 650), KLu(z, 650), and Ku(z, 650) calculated by Hydrolight 6.0 (HL6.0), three machine learning models (MLMs) without or with boundary conditions for estimating Kd(z, 650), KLu(z, 650), and Ku(z, 650) were established, evaluated, compared, and applied. It was found that (1) CatBoost models have superior performance with R2 ≥ 0.92, RMSE≤ 0.021 m−1, and MAPE≤ 4.3% and most significantly agree with HL6.0 simulations; (2) there is a more satisfactory consistency between HL6.0 simulations and MLMs estimations while incorporating the boundary conditions; (3) the estimations of Kd(z, 650), KLu(z, 650), and Ku(z, 650) derived from CatBoost models with and without boundary conditions have a good agreement with R2 ≥0.992, RMSE ≤0.007 m−1, and MAPE≤0.8%, respectively; (4) there is an overall decreasing trend with increasing depth and increasing offshore distance of Kd(z, 650), KLu(z, 650), and Ku(z, 650) in the SCS. The MLMs for estimating K(z, λ) could provide more accurate information for the study of underwater light field distribution, water quality assessment and the validation of remote sensing data products.",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Image-fusion-based object detection using a time-of-flight camera",
        "paper_author": "Yang D.",
        "publication": "Optics Express",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "In this work, we demonstrate an innovative object detection framework based on depth and active infrared intensity images fusion with a time-of-flight (ToF) camera. A slide window weight fusion (SWWF) method provides fuse image with two modalities to localize targets. Then, the depth and intensity information is extracted to construct a joint feature space. Next, we utilize four machine learning methods to achieve object recognition. To verify this method, experiments are performed on an in-house dataset containing 1066 images, which are categorized into six different surface materials. Consequently, the approach performs well on localization with a 0.778 intersection over union (IoU). The best classification results are obtained with K-Nearest Neighbor (KNN) with a 98.01% total accuracy. Furthermore, our demonstrated method is less affected by various illumination conditions.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Lafayette",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Liver volumetric and anatomic assessment in living donor liver transplantation: the role of modern imaging and artificial intelligence",
        "paper_author": "Machry M.",
        "publication": "World Journal of Transplantation",
        "citied_by": "6",
        "cover_date": "2023-12-18",
        "Abstract": "The shortage of deceased donor organs has prompted the development of alternative liver grafts for transplantation. Living-donor liver transplantation (LDLT) has emerged as a viable option, expanding the donor pool and enabling timely transplantation with favorable graft function and improved long-term outcomes. An accurate evaluation of the donor liver’s volumetry (LV) and anatomical study is crucial to ensure adequate future liver remnant, graft volume and precise liver resection. Thus, ensuring donor safety and an appropriate graft-to-recipient weight ratio. Manual LV (MLV) using computed tomography has traditionally been considered the gold standard for assessing liver volume. However, the method has been limited by cost, subjectivity, and variability. Automated LV techniques employing advanced segmentation algorithms offer improved reproducibility, reduced variability, and enhanced efficiency compared to manual measurements. However, the accuracy of automated LV requires further investigation. The study provides a comprehensive review of traditional and emerging LV methods, including semi-automated image processing, automated LV techniques, and machine learning-based approaches. Additionally, the study discusses the respective strengths and weaknesses of each of the aforementioned techniques. The use of artificial intelligence (AI) technologies, including machine learning and deep learning, is expected to become a routine part of surgical planning in the near future. The implementation of AI is expected to enable faster and more accurate image study interpretations, improve workflow efficiency, and enhance the safety, speed, and cost-effectiveness of the procedures. Accurate preoperative assessment of the liver plays a crucial role in ensuring safe donor selection and improved outcomes in LDLT. MLV has inherent limitations that have led to the adoption of semi-automated and automated software solutions. Moreover, AI has tremendous potential for LV and segmentation; however, its widespread use is hindered by cost and availability. Therefore, the integration of multiple specialties is necessary to embrace technology and explore its possibilities, ranging from patient counseling to intraoperative decision-making through automation and AI.",
        "affiliation_name": "Universidade Federal de Ciencias da Saúde de Porto Alegre",
        "affiliation_city": "Porto Alegre",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Anterior forebrain pathway in parrots is necessary for producing learned vocalizations with individual signatures",
        "paper_author": "Zhao Z.",
        "publication": "Current Biology",
        "citied_by": "3",
        "cover_date": "2023-12-18",
        "Abstract": "Parrots have enormous vocal imitation capacities and produce individually unique vocal signatures. Like songbirds, parrots have a nucleated neural song system with distinct anterior (AFP) and posterior forebrain pathways (PFP). To test if song systems of parrots and songbirds, which diverged over 50 million years ago, have a similar functional organization, we first established a neuroscience-compatible call-and-response behavioral paradigm to elicit learned contact calls in budgerigars (Melopsittacus undulatus). Using variational autoencoder-based machine learning methods, we show that contact calls within affiliated groups converge but that individuals maintain unique acoustic features, or vocal signatures, even after call convergence. Next, we transiently inactivated the outputs of AFP to test if learned vocalizations can be produced by the PFP alone. As in songbirds, AFP inactivation had an immediate effect on vocalizations, consistent with a premotor role. But in contrast to songbirds, where the isolated PFP is sufficient to produce stereotyped and acoustically normal vocalizations, isolation of the budgerigar PFP caused a degradation of call acoustic structure, stereotypy, and individual uniqueness. Thus, the contribution of AFP and the capacity of isolated PFP to produce learned vocalizations have diverged substantially between songbirds and parrots, likely driven by their distinct behavioral ecology and neural connectivity.",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reproducible and fully automated testing of nocifensive behavior in mice",
        "paper_author": "Dedek C.",
        "publication": "Cell Reports Methods",
        "citied_by": "4",
        "cover_date": "2023-12-18",
        "Abstract": "Pain in rodents is often inferred from their withdrawal from noxious stimulation. Threshold stimulus intensity or response latency is used to quantify pain sensitivity. This usually involves applying stimuli by hand and measuring responses by eye, which limits reproducibility and throughput. We describe a device that standardizes and automates pain testing by providing computer-controlled aiming, stimulation, and response measurement. Optogenetic and thermal stimuli are applied using blue and infrared light, respectively. Precise mechanical stimulation is also demonstrated. Reflectance of red light is used to measure paw withdrawal with millisecond precision. We show that consistent stimulus delivery is crucial for resolving stimulus-dependent variations in withdrawal and for testing with sustained stimuli. Moreover, substage video reveals “spontaneous” behaviors for consideration alongside withdrawal metrics to better assess the pain experience. The entire process was automated using machine learning. RAMalgo (reproducible automated multimodal algometry) improves the standardization, comprehensiveness, and throughput of preclinical pain testing.",
        "affiliation_name": "University of Toronto, Institute of Biomaterials and Biomedical Engineering",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "An automaton for preclinical pain testing",
        "paper_author": "Graham R.D.",
        "publication": "Cell Reports Methods",
        "citied_by": "0",
        "cover_date": "2023-12-18",
        "Abstract": "In this issue of Cell Reports Methods, Dedek et al. present RAMalgo—an AI-powered, automated platform for quantifying nociceptive behaviors in mice. With integrated video tracking and mechanical, thermal, and optogenetic stimulation, RAMalgo has the potential to increase standardization and throughput of pain behavior measurement in rodents.",
        "affiliation_name": "Washington University School of Medicine in St. Louis",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Enables Accurate Prediction of Quinone Formation during Drug Metabolism",
        "paper_author": "Sandhu H.",
        "publication": "Chemical Research in Toxicology",
        "citied_by": "4",
        "cover_date": "2023-12-18",
        "Abstract": "Metabolism helps in the elimination of drugs from the human body by making them more hydrophilic. Sometimes, drugs can be bioactivated to highly reactive metabolites or intermediates during metabolism. These reactive metabolites are often responsible for the toxicities associated with the drugs. Identification of reactive metabolites of drug candidates can be very helpful in the initial stages of drug discovery. Quinones are soft electrophiles that are generated as reactive intermediates during metabolism. Quinones make up more than 40% of the reactive metabolites. In this work, a reliable data set of 510 molecules was used to develop machine learning and deep learning-based predictive models to predict the formation of quinone-type metabolites. For representing molecules, two-dimensional (2D) descriptors, PubChem fingerprints, electro-topological state (E-state) fingerprints, and metabolic reactivity-based descriptors were used. Developed models were compared to the existing Xenosite web server using the untouched test set of 102 molecules. The best model achieved an accuracy of 86.27%, while the Xenosite server could achieve an accuracy of only 52.94% on the test set. Descriptor analysis revealed that the presence of greater numbers of polar moieties in a molecule can prevent the formation of quinone-type metabolites. In addition, the presence of a nitrogen atom in an aromatic ring and the presence of metabolophores V51, V52, and V53 (SMARTCyp descriptors) decrease the probability of quinone formation. Finally, a tool based on the best machine learning models was developed, which is accessible at http://14.139.57.41/quinonepred/.",
        "affiliation_name": "National Institute of Pharmaceutical Education and Research, Mohali",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Odor representations from the two nostrils are temporally segregated in human piriform cortex",
        "paper_author": "Dikeçligil G.N.",
        "publication": "Current Biology",
        "citied_by": "7",
        "cover_date": "2023-12-18",
        "Abstract": "The human olfactory system has two discrete channels of sensory input, arising from olfactory epithelia housed in the left and right nostrils. Here, we asked whether the primary olfactory cortex (piriform cortex [PC]) encodes odor information arising from the two nostrils as integrated or distinct stimuli. We recorded intracranial electroencephalogram (iEEG) signals directly from PC while human subjects participated in an odor identification task where odors were delivered to the left, right, or both nostrils. We analyzed the time course of odor identity coding using machine-learning approaches and found that uni-nostril odor inputs to the ipsilateral nostril are encoded ∼480-ms faster than odor inputs to the contralateral nostril on average. During naturalistic bi-nostril odor sampling, odor information emerged in two temporally segregated epochs, with the first epoch corresponding to the ipsilateral and the second epoch corresponding to the contralateral odor representations. These findings reveal that PC maintains distinct representations of odor input from each nostril through temporal segregation, highlighting an olfactory coding scheme at the cortical level that can parse odor information across nostrils within the course of a single inhalation.",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Block sparsity promoting algorithm for efficient construction of cluster expansion models for multicomponent alloys",
        "paper_author": "Thekkepat K.",
        "publication": "Journal of Physics Condensed Matter",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Multicomponent alloys are gaining significance as drivers of technological breakthroughs especially in structural and energy storage materials. The vast configuration space of these materials prohibit computational modeling using first-principles based methods alone. The cluster expansion (CE) method is the most widely used tool for modeling configurational disorder in alloys. CE relies on machine learning algorithms to train Hamiltonians and uses first-principles calculated data as training sets. In this paper we present a new compressive sensing-based algorithm for the efficient construction of CE Hamiltonians of multicomponent alloys. Our algorithm constructs highly sparse and physically reasonable models from a carefully selected small training set of alloy structures. Compared to conventional fitting algorithms, the algorithm achieves more than 50% reduction in the training set size. The resultant sparse models can sample the configuration space at least 3 × faster. We demonstrate this algorithm on 4 different alloy systems, namely Ag-Au, Ag-Au-Cu, Ag-Au-Cu-Pd and (Ge,Sn)(S,Se,Te).The sparse CE models for these alloys can rapidly reproduce known ground state orderings and order-disorder transitions. Our method can truly enable high-throughput multicomponent alloy thermodynamics by reducing the cost associated with model construction and configuration sampling.",
        "affiliation_name": "Indian Institute of Technology Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Thermal conductivity of van der Waals heterostructure of 2D GeS and SnS based on machine learning interatomic potential",
        "paper_author": "Li W.",
        "publication": "Journal of Physics Condensed Matter",
        "citied_by": "4",
        "cover_date": "2023-12-18",
        "Abstract": "van der Waals heterostructures have provided an unprecedented platform to tune many physical properties for two-dimensional materials. In this work, thermal transport properties of van der Waals heterostructures formed by vertical stacking of monolayers GeS and SnS have been investigated systematically based on machine learning interatomic potential. The effect of van der Waals interface on the lattice thermal transport of 2D SnS and GeS can be well clarified by introducing various stacking configurations. Our results indicate that the van der Waals interface can strongly suppress the thermal transport capacity for the considered heterostructures, and either the average thermal conductivity per layer or the 2D thermal sheet conductance for the considered heterostructures is lower than that of corresponding monolayers. The suppressed thermal conductivity with tunable in-plane anisotropy in SnS/GeS heterostructures can be ascribed to the enhanced interface anharmonic scattering, and thus exhibits obvious interface-dependent characteristics. Therefore, this work highlights that the van der Waals interface can be employed to effectively modulate thermal transport for the 2D puckered group-IV monochalcogenides, and the suppressed lattice thermal conductivity together with interface-dependent phonon transport properties in the SnS/GeS heterostructure imply the great potential for corresponding thermoelectrical applications.",
        "affiliation_name": "Shaanxi University of Science and Technology",
        "affiliation_city": "Xinyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Learning and knowledge transfer by humans and digital platforms: which tools best support the decision-making process?",
        "paper_author": "Russo G.",
        "publication": "Journal of Knowledge Management",
        "citied_by": "7",
        "cover_date": "2023-12-18",
        "Abstract": "Purpose: This study aims to investigate the impact of technologies on the knowledge transfer process. In particular, the authors aim to analyze the topic of knowledge brokers and the relationship between broker and digital tools in the knowledge transfer process in the sport context. The study developed, therefore, aims to investigate the creating of this environment for knowledge transfer and knowledge sharing between man and machine, looking to improve the planning of technical sports projects of the clubs. Design/methodology/approach: This paper presents a qualitative approach aimed at analyzing how platforms and the players’ agents can be useful tools in the knowledge transfer process. The research was conducted through a survey with a structured questionnaire via e-mail to 64 managers at the head of clubs playing in the Italian Series B basketball in the 2021–2022 championship. The total number of questions administered is 21. Findings: The results demonstrate how sports directors, for the construction of a technical sports project, in addition to learning off the pitch by interactions with media, fans, pressure management, leadership skills, positive attitude, tolerance, understanding of other opinions, background and cultures, see the athletes’ agents as the main stakeholder of the managers. The research resulted, by the clubs’ managers, in both formal learning and informal-type learning. Informal learning, by far the most frequently used and most important in the general learning process of executives, is identified in the use that executives make of information available on digital platforms and of the fiduciary relationships that management has with players’ agents. Originality/value: The results demonstrate the valuable opportunities for executives, coaches, managers and clubs to strategically manage learning and knowledge sharing. Improving and managing knowledge-sharing strategies would help increase knowledge, not only of the sports directors but also of the entire club, thus improving the absolute quality of the game within the Italian basketball divisions. The authors have developed an innovative framework regarding the construction of a “typed sports technical project”, and the authors have identified a series of crucial phases capable of determining the creation of a new roster of athletes.",
        "affiliation_name": "Dipartimento di Economia, Management e Diritto dell'Impresa",
        "affiliation_city": "Bari",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Visual Detection of Coumarin and Umbelliferone for Beverage Safety Based on Eu(III)-Functionalized HOF Hybrids: Further Constructing an SVM-Assisted Digital Anti-Counterfeiting Platform",
        "paper_author": "Zhu K.",
        "publication": "Advanced Optical Materials",
        "citied_by": "9",
        "cover_date": "2023-12-18",
        "Abstract": "The development of rapid, sensitive, and intuitive intelligent fluorescent materials (IFMs) for monitoring beverage safety is important for human health. In this study, an emerging IFM, a dual-emitting Eu3+-functionalized hydrogen-bonded organic framework (Eu@HOF, Eu@1), is fabricated through coordination post-synthetic modification. The ligand-to-metal charge transfer-induced energy transfer (LMCT-ET) from 1 to Eu3+ provides Eu@1 with palpable red fluorescence. Eu@1 as a sensor can specifically discriminate coumarin (Cou), a common spice used in beverages but a suspected carcinogen, with high sensitivity, high efficiency, and excellent anti-interference. Eu@1 can also quantitatively distinguish 7-hydroxycoumarin (umbelliferone, Ulf), a metabolite of Cou, in chromatic and ratiometric modes. In realistic milk and soy milk samples, the detection limits (DL) of Eu@1 for Cou are 0.0979 and 0.0511 mg L−1, respectively, whereas that of Ulf in practical serum samples is 0.0099 mg L−1. Furthermore, based on the polyethylene-vinyl acetate (PEVA) films, three digital anti-counterfeiting platforms with multiple encryption information are constructed, assisted by a support vector machine. This work proposes a facile pathway for preparing Eu@HOF fluorescent sensors to determine beverage safety and opens the possibility of designing an efficient and precise multifunctional digital anti-counterfeiting platform via machine learning.",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Semantic intelligent computing and applications",
        "paper_author": "Ghonge M.M.",
        "publication": "Semantic Intelligent Computing and Applications",
        "citied_by": "1",
        "cover_date": "2023-12-18",
        "Abstract": "Artificial intelligence advancements, machine intelligence innovations, and semantic web developments together make up semantic intelligence technologies. The edited book integrates artifi cial intelligence, machine learning, IoT, blockchain, and natural language processing with semantic web technologies. This book also aims to offer real-life solutions to the pressing issues currently being faced by semantic web technologies. • Provides a guideline manual for the theory and applications of semantic technologies. • Discusses applications to AI, Machine Learning, IoT, Blockchain. • Can serve as reference for practitioners as well as textbook for advanced students.",
        "affiliation_name": "Bapuji Institute of Engineering and Technology, Davangere",
        "affiliation_city": "Davangere",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Identification and validation of INHBE and P4HA1 as hub genes in non-alcoholic fatty liver disease",
        "paper_author": "Cao J.",
        "publication": "Biochemical and Biophysical Research Communications",
        "citied_by": "7",
        "cover_date": "2023-12-17",
        "Abstract": "Purpose: Non-alcoholic fatty liver disease (NAFLD) is currently the most prevalent type of liver disease and a worldwide disease threatening human health. This study aims to identify the novel diagnostic biomarkers of NAFLD by comprehensive bioinformatics and machine learning, and to validate our results in hepatocyte and animal models. Methods: We used Gene Expression Omnibus (GEO) databases on NAFLD patients for differential gene expression analyses. Intersections were taken with genes from the key modules of WGCNA and differentially expressed genes (DEGs). Machine learning algorithms like LASSO regression analysis, SVM-RFE, and RandomForest were used to screen hub genes. In addition, a nomogram model and calibration curves were built in order to forecast the probability of NAFLD occurrence. Then, the relationship between hub genes and immune cells was verified using Spearman analysis. Finally, we further verified the expression of key genes by constructing a steatosis hepatocyte model and animal model. Results: Key genes (INHBE and P4HA1) were identified by comprehensive bioinformatics analysis and machine learning. INHBE and P4HA1 were up-regulated and down-regulated in the steatosis hepatocyte model, respectively. Animal experiments also showed that INHBE was up-regulated in the liver of mice fed with high fat diet (HFD). Conclusion: INHBE and P4HA1 are the hub genes of NAFLD. Our findings may contribute to a greater understanding of the occurrence and development of NAFLD and provide potential biomarkers and possible therapeutic targets for future clinical diagnosis and treatment.",
        "affiliation_name": "Tongji Medical College of Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Wildland and Forest Fire Prediction in Thailand using Satellite Data",
        "paper_author": "Phankrawee W.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-16",
        "Abstract": "Fire, either manmade or natural causes, poses significant threats to ecosystems, infrastructure, and all lives. Early prediction and monitoring are critical for fire management and mitigation. However, a lack of workforce, and it is insufficient to rely only on conventional monitoring techniques, such as employing human staff to operate lookout towers for fires or waiting for someone to call for an emergency. In previous work, satellite data can be used for fire prediction in many countries. In this work, we exploited 10 years-hot spots data from NASA satellite and Thai meteorological data from 2012-2022 and applied machine learning techniques for fire prediction in Thailand. In this work, we used the Extratrees BAG L2 model (this model consists of ExtraTrees, Bootstrap Aggregating, and Regularization) for fire prediction and evaluated prediction results using Mean squared error(MSE), Root mean squared error(RMSE), Mean absolute error (MAE) and R square. We obtained the values of MSE, RMSE, MAE and R square are 0.0057, 0.075, 0.04355 and 0.6869, respectively.",
        "affiliation_name": "Sirindhorn International Institute of Technology, Thammasat University",
        "affiliation_city": "Pathum Thani",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Risk Assessment System of Muscle Injuries of Electric Welders based on Machine Learning.",
        "paper_author": "Ruengdech C.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "Safety is essential for workers' quality of life, which has become one of the main priorities for enterprises. Electric welders want safety precautions required during work in construction industries with safety risks, especially muscle injuries. This issue needs to be addressed by the safety officer to suggest a decrease in the risk. However, the lack of expertise and accuracy in risk assessment has produced muscle injuries. Thus, using machine learning techniques for primary prevention is cost-effective to mitigate risk assessment. This study proposes using artificial intelligence risk assessment of muscle injuries (AIRAMI) during welding tasks for electric welders. Image processing is an applied machine learning method to aid in the risk assessment of muscle injuries based on rapid entire body assessment (REBA). The five hundred electric welders' pose images were trained using OpenCV and Mediapipe. The assessment output is shown based on REBA score criteria, including five risk levels, and color icon alerts are displayed independently for each assessment. The findings show that AIRAMI can effectively and precisely evaluate the risk assessment of electric welders' muscle injuries.",
        "affiliation_name": "King Mongkut's University of Technology North Bangkok",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Integral Communication and Digital Identity",
        "paper_author": "Rafajac O.",
        "publication": "Integral Communication and Digital Identity",
        "citied_by": "1",
        "cover_date": "2023-12-16",
        "Abstract": "This book explains how taxonomy can be used to describe and connect social actors in an integral way. Integral communication refers to a specific way of open information exchange which uses all qualities and preferences of subjects in conversation and allows anonymous feedback exchange, which enhances trust, learning and development. The role of integral communication is to promote perceptiveness, collaboration, personal development, and organizational learning among all the actors involved. In this book, the authors propose a new original way of digital communication that uses tags and their metadata to describe qualities and preferences of a particular node in the network. Although most social networks, sharing platforms and e-government frameworks are already applying taxonomies and social tagging to define user identity, none of them is focused on tags exclusively, while within an integral communication framework they represent the basic element of user definition and networking. In addition, other social platforms rarely allow anonymous feedback exchange, and they are usually not focused on the personal development of their end-users. Aside from helping actors present their attributes and preferences, integral communication promotes teamwork, sustainability, trust, organisational learning, and personalized communication with AI machines. After reading this book, readers will learn how to harness the power of integral networking and understand why anonymous feedback is a critical element for learning and development.",
        "affiliation_name": "Veleučilište u Rijeci",
        "affiliation_city": "Rijeka",
        "affiliation_country": "Croatia"
    },
    {
        "paper_title": "The effect of Data Augmentation Using SMOTE: Diabetes Prediction by Machine Learning Techniques",
        "paper_author": "Al-Qerem A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "Diabetes mellitus, a severe and enduring condition characterized by impaired glucose metabolism, poses a substantial threat to public health. Its pervasive impact continues to escalate globally, with a rising incidence that challenges preventive measures. Despite earnest efforts, individuals struggle to evade the clutches of diabetes, necessitating innovative approaches for disease management. Traditional methodologies in diabetes health monitoring exhibit limitations, prompting the exploration of advanced techniques. This study employs machine learning (ML) methods to delve into diabetes, aiming to enhance diagnostic accuracy. The primary objective is to develop a method capable of precise diabetes diagnoses with a heightened level of precision. The investigation incorporates machine learning algorithms, specifically Random Forest (RF), K Nearest Neighbor (KNN), and Logistic Regression. The inclusion of these algorithms seeks to streamline data processing times.Notably, this study incorporates the Synthetic Minority Over-sampling Technique (SMOTE) as a data augmentation strategy. SMOTE addresses imbalances in the dataset, contributing to a more robust and representative sample. The research evaluates the effectiveness and accuracy of diabetes prediction using these algorithms both before and after SMOTE implementation. By considering the impact of SMOTE, the study aims to determine the optimal algorithm for assessing diabetes development. The comparative analysis sheds light on how SMOTE enhances the overall performance of machine learning models. This nuanced approach not only refines diabetes diagnostic protocols but also underscores the significance of addressing data imbalances in predictive modeling for enhanced precision in disease prediction.",
        "affiliation_name": "Shaqra University",
        "affiliation_city": "Shaqra",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Smart room for patient monitoring based on IoT technologies",
        "paper_author": "Zhukova N.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-16",
        "Abstract": "This article presents a method for building a hospital room with extended intelligent features based on Internet of Things (IoT) technologies. We begin by reviewing existing vision-based health care systems and identifying important and useful functions that they should have. We then present a method for building a smart room that allows increase the level of the intelligence of the existing hospital rooms due to extensive use of the up-To-date machine learning methods. The proposed solution assumes using readily available hardware devices to reduce the cost of smart room building. Compared to commercially available assistive technologies, the proposed smart room turn out to have high level of intelligence and to be very cost effective. The system's non-intrusive nature makes it easy to use it both in hospitals and at home for patient care.",
        "affiliation_name": "St. Petersburg Federal Research Center of the Russian Academy of Sciences",
        "affiliation_city": "Saint Petersburg",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Data Mining in Mobile Learning: Uncovering Insights for Enhanced Vocabulary Acquisition",
        "paper_author": "Wu M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "The integration of mobile learning and machine learning, driven by the proliferation of smart handheld devices and the vast amount of learning resources available on the internet, has revolutionized education. This study explores the use of mobile learning, specifically leveraging mobility and big data mining techniques, to improve college English vocabulary acquisition among university students. By addressing the challenges faced in mobile learning and applying innovative methodologies, we have developed a personalized recommendation system based on data mining algorithms. This system suggests English vocabulary words to students based on their past performance, harnessing the power of big data mining. Through a comprehensive evaluation, we have demonstrated the effectiveness of our approach in enhancing vocabulary acquisition and retention compared to traditional book-based learning methods. The findings of this research not only contribute to the advancement of mobile learning but also provide valuable insights for educators and policymakers on the effective utilization of mobility and big data mining for enhanced student learning outcomes.",
        "affiliation_name": "Shenyang Jianzhu University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Machine Learning Based Novel Approach of Predicting International Roughness Index(IRI) from Traffic Characteristics using Random Forest Regression",
        "paper_author": "Abir A.R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "International Roughness Index (IRI) stands as a well-established metric for assessing pavement roughness and overall condition. Predicting IRI is crucial for maintaining pavement infrastructure. In this study, we present a novel approach to predict IRI using Random Forest regression, focusing exclusively on traffic characteristics as predictive variables. Existing studies considered a wide range of factors, including pavement materials, climate, structural attributes, and various pavement distress indicators alongside traffic data where we developed our model using only traffic characteristics. We have used Long-Term Pavement Performance Program (LTPP) dataset for training our models. We have compared our Random forest model with three other models (XGBoost,SVM regression,Gradient Boosting). R squared value and Mean Squared Error (MSE) were taken as performance evaluation metrics. Random forest showed R squared value of 0.70623 and MSE of 8.22 × 10-6 where Gradient Boosting, XGBoost and SVM had R squared value of 0.5737, 0.497, and 0.3455 respectively.We also compared between two hyperparameter tuning methods(Random Search and Grid Search) used in our models and found Random search to perform better. We have also presented a comparative analysis of existing IRI prediction models with our model. Finally we present a SHAP(SHapley Additive exPlanations) analysis to interpret our model and find the contribution of each input feature on our model. We found Annual ESAL (Equivalent Single Axle Load) to be the most dominant factor to predict IRI from traffic characteristics.",
        "affiliation_name": "Bangladesh University of Engineering and Technology",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "CLEB: A Continual Learning Energy Bidding Framework for An Energy Market Bidding Application",
        "paper_author": "Nguyen T.D.T.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-16",
        "Abstract": "Energy trading in the day-Ahead and continuous energy market enables the maximization of profits for market participants, such as utility companies/suppliers and residential/industrial consumers. However, in practice, the AI-based decision-making process for accepting or rejecting bids/offers from customers/suppliers, commonly referred to as bidding decisions, often experiences performance degradation due to the fluctuation of renewable energy resources and the intermittent demand behavior of customers. This phenomenon is widely recognized as a data distribution shift in machine learning. One conventional approach involves training the model from scratch over an extended historical period, incurring significant computational and storage costs. To address this challenge more effectively, we propose a Continual Learning-based Energy Bidding framework (CLEB). This framework employs a relay-based continual learning method, utilizing a combination of a small portion of historical data and the most recent data with different distributions to enhance the accuracy of bidding decisions. The framework consists of predictive neural networks, specifically a Multi-Layer Perceptron (MLP), as well as data buffers for storing newly acquired data from a non-stationary data stream within an application. Subsequently, the evolving probability distribution of the data stream identified by the framework is utilized to retrain the model. Our evaluation in a public European energy trading dataset shows that the framework significantly improves accuracy performance of prediction model under the data distribution shift occurrences, allowing the model adaptively itself to deal with non-stationary data distributions in dynamic environments.",
        "affiliation_name": "Kyung Hee University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Towards the Development of a Recommender System for an OTC Drug Dispenser",
        "paper_author": "Dela Calzada W.J.P.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "In the age of healthcare digitization, the integration of cutting-edge technologies offers the potential to elevate medical services and enhance patient well-being. A novel solution in this regard is the AI-powered recommendation system for over-The-counter (OTC) drug dispensing, designed to bolster access to affordable and essential medications within neighborhood pharmacies. This drug dispenser employs advanced AI algorithms to provide precise, tailored medication recommendations and dispenses pre-packaged doses. Moreover, its continuous development and enhancement make it adaptable to the changing needs of its intended user base. Thoroughly assessed for its accuracy through intrinsic evaluations conducted by researchers, the system has demonstrated its efficacy in medication decisions. With the potential to enhance healthcare outcomes and reduce disparities in healthcare access, the AI-enabled OTC drug dispenser represents a new era of healthcare efficiency, personalization, and technological empowerment within local community pharmacies.",
        "affiliation_name": "University of the Immaculate Conception",
        "affiliation_city": "Davao",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "SmartRest: Empowering Elderly Care through Computer Vision-based Ambient Assisted Living (AAL), Communication, and Smart Medicine Dispenser",
        "paper_author": "Sarmiento J.P.R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "The physical and emotional strain of caring for elderly people can overwhelm family members and caregivers who need to attend to the needs of elderly people and other responsibilities in their daily lives. To address these concerns, the researchers created the following: First, a Mobile Remote Assistance that allows elderly individuals to convey their needs like thirst, hunger, socialization, other assistance, or emergency through buttons. Second, a Computer Vision-based Ambient Assisted Living that utilizes computer vision algorithms for real-Time monitoring of the living environment, designed to swiftly identify and alert caregivers and family members during fire and smoke incidents. Third, an automated Smart Medicine Dispenser that administers medicine based on a pre-established schedule and sends a notification when it's time to take their medication. The researchers conducted an evaluation using the ISO 25010:2011 software quality standard, focusing specifically on functional suitability and usability. The outcomes indicate a mean score of 4.44 for SmartRest's Functional Suitability, earning a classification of \"Satisfied.\"Usability registers a mean of 4.45, classified as \"Satisfied\"as well. Moreover, the computer vision model achieved an F1 score of 0.98. The evaluation results demonstrate positive results across all categories, affirming the efficient and intended operation of the system.",
        "affiliation_name": "Pamantasan ng Lungsod ng Maynila",
        "affiliation_city": "Manila",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "IoT Based Accident Prevention System using Machine Learning techniques",
        "paper_author": "Alnashwan R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "The likelihood of car accidents increases during extreme weather conditions, such as fog, winds, snow, rain, etc. While it may not be possible to prevent all such accidents, their incidence can be reduced by taking proper measures. Therefore, an intelligent accident-Avoidance system is necessary to predict the severity of accidents based on weather and road conditions. This research paper suggests three machine learning (ML) methods for an Internet of Things (IoT)-based accident severity prediction system. The methods are Random Forest, LightGBM, and XGBoost.The aim is to predict the severity of car accidents based on various weather features using a machine learning model. However, considering the previous work, we observed that the size of datasets is frequently minimal, and some of the research discusses the influence of the weather on the number of accidents. Therefore, we used the Countrywide Traffic Accident Dataset, which covers 2.8 million vehicle accidents in the United States from 2016 to 2021. In conclusion, our methodology appears to be efficient in predicting the severity of car accidents. Among the three methods, LightGBM achieved the highest prediction accuracy (72%), precision (70%), recall (70%), F1-scores (70%), and area curve (AUC) (0.86) of the receiver operating characteristic (ROC) curve.",
        "affiliation_name": "King Saud University",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "AICCC 2023 - 2023 6th Artificial Intelligence and Cloud Computing Conference",
        "paper_author": "NA",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "The proceedings contain 37 papers. The topics discuss include: weakly-supervised motion in-betweening learning via pose priors; conventional machine learning approach for waste classification; the effect of data augmentation using SMOTE: diabetes prediction by machine learning techniques; enhancing regression tree predictions with terminal-node anomaly detection; a machine learning based novel approach of predicting international roughness index(IRI) from traffic characteristics using random forest regression; CLEB: a continual learning energy bidding framework for an energy market bidding application; artificial intelligence aspect of transportation analysis using large scale systems; a comparative analysis of symbolic and deep learning based RDFS materialization; and sparse fully convolutional network for video-based point cloud compression color enhancement.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Conventional Machine Learning Approach for Waste Classification",
        "paper_author": "Jangsamsi K.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "Waste management is a complex and challenging process, especially waste classification to sort waste by categories. The paper aims to overcome these challenges by proposing a waste classification approach that uses various feature extraction algorithms along with a support vector machine (SVM). The purpose is to identify the most effective feature for building a classification model, even with a low number of samples and high intra-class variance. SVM was used for classification while Fourier descriptors (FDs), histogram of oriented gradients (HOG), and local binary pattern (LBP) were used for feature extraction. The dataset used in this paper was obtained from Kaggle.com and Google.com with different types of vision problems. The experimental results showed that classification with LBP feature extraction achieves the highest accuracy. This accuracy is higher than the experiments with other feature extractions.",
        "affiliation_name": "King Mongkut's University of Technology Thonburi",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Artificial Intelligence Aspect of Transportation Analysis Using Large Scale Systems",
        "paper_author": "Hu T.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "11",
        "cover_date": "2023-12-16",
        "Abstract": "Problem: The problem of the finalized exploration revolved around the inadequacy of current traffic forecasting models. Despite decades of examination in many fields, existing approaches, often relying on linear models and stationary time series assumptions, struggle to accurately predict traffic under chaotic events. The identified limitation has profound consequences, evident in the significant economic losses and time inefficiencies incurred due to traffic congestion, as exemplified by the $144 billion in losses and the 34% increase in travel time for drivers in Los Angeles County in 2013. The challenge lies in the inherently unpredictable nature of traffic events, ranging from regular rush hours causing sharp declines in traffic speed to unpredictable accidents leading to unforeseen delays. Consequently, there is a pressing need for a more effective and adaptive traffic forecasting model that can reliably operate under both normal and abnormal traffic conditions, addressing the shortcomings of traditional linear models and stationary time series assumptions. Purpose: The purpose of the completed investigation was to determine whether a traffic forecasting model that incorporates machine learning and deep learning technologies can yield effective traffic forecasts based on real-Time weather and traffic data. Method: The study involved the development of a traffic forecasting model as informed by existing literature. Data collection was done through simulating data similar to the traffic data from Los Angeles County that was utilized in Yu et al.'s research on deep learning and traffic prediction in extreme weather scenarios [1]. Data analysis was done through MAE and t-Test. Results: The findings demonstrated that the created traffic forecasting model outperformed the current methods in its ability to provide traffic forecasts with a better degree of accuracy. Conclusion: Regardless of the traffic volume, weather, or time of day, the developed traffic forecasting algorithm can give precise real-Time traffic predictions.",
        "affiliation_name": "Whiting School of Engineering",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "I Am an Earphone and I Can Hear My User's Face: Facial Landmark Tracking Using Smart Earphones",
        "paper_author": "Zhang S.",
        "publication": "ACM Transactions on Internet of Things",
        "citied_by": "7",
        "cover_date": "2023-12-16",
        "Abstract": "This article presents EARFace, a system that shows the feasibility of tracking facial landmarks for 3D facial reconstruction using in-ear acoustic sensors embedded within smart earphones. This enables a number of applications in the areas of facial expression tracking, user interfaces, AR/VR applications, affective computing, and accessibility, among others. Although conventional vision-based solutions break down under poor lighting and occlusions, and also suffer from privacy concerns, earphone platforms are robust to ambient conditions while being privacy-preserving. In contrast to prior work on earable platforms that perform outer-ear sensing for facial motion tracking, EARFace shows the feasibility of completely in-ear sensing with a natural earphone form factor, thus enhancing the comfort levels of wearing. The core intuition exploited by EARFace is that the shape of the ear canal changes due to the movement of facial muscles during facial motion. EARFace tracks the changes in shape of the ear canal by measuring ultrasonic channel frequency response of the inner ear, ultimately resulting in tracking of the facial motion. A transformer-based machine learning model is designed to exploit spectral and temporal relationships in the ultrasonic channel frequency response data to predict the facial landmarks of the user with an accuracy of 1.83 mm. Using these predicted landmarks, a 3D graphical model of the face that replicates the precise facial motion of the user is then reconstructed. Domain adaptation is further performed by adapting the weights of layers using a group-wise and differential learning rate. This decreases the training overhead in EARFace. The transformer-based machine learning model runs on smart phone devices with a processing latency of 13ms and an overall low power consumption profile. Finally, usability studies indicate higher levels of comforts of wearing EARFace's earphone platform in comparison with alternative form factors.",
        "affiliation_name": "University Park",
        "affiliation_city": "University Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Efficient IoT Traffic Inference: From Multi-view Classification to Progressive Monitoring",
        "paper_author": "Pashamokhtari A.",
        "publication": "ACM Transactions on Internet of Things",
        "citied_by": "0",
        "cover_date": "2023-12-16",
        "Abstract": "Machine learning-based techniques have proven to be effective in Internet-of-Things (IoT) network behavioral inference. Existing works developed data-driven models based on features from network packets and/or flows, but mainly in a static and ad-hoc manner, without adequately quantifying their gains versus costs. In this article, we develop a generic architecture that comprises two distinct inference modules in tandem, which begins with IoT network behavior classification followed by continuous monitoring. In contrast to prior relevant works, our generic architecture flexibly accounts for various traffic features, modeling algorithms, and inference strategies. We argue quantitative metrics are required to systematically compare and efficiently select various traffic features for IoT traffic inference. This article1 makes three contributions: (1) For IoT behavior classification, we identify four metrics, namely, cost, accuracy, availability, and frequency, that allow us to characterize and quantify the efficacy of seven sets of packet-based and flow-based traffic features, each resulting in a specialized model. By experimenting with traffic traces of 25 IoT devices collected from our testbed, we demonstrate that specialized-view models can be superior to a single combined-view model trained on a plurality of features by accuracy and cost. We also develop an optimization problem that selects the best set of specialized models for a multiview classification. (2) For monitoring the expected IoT behaviors, we develop a progressive system consisting of one-class clustering models (per IoT class) at three levels of granularity. We develop an outlier detection technique on top of the convex hull algorithm to form custom-shape boundaries for the one-class models. We show how progression helps with computing costs and the explainability of detecting anomalies. (3) We evaluate the efficacy of our optimally selected classifiers versus the superset of specialized classifiers by applying them to our IoT traffic traces. We demonstrate how the optimal set can reduce the processing cost by a factor of six with insignificant impacts on the classification accuracy. Also, we apply our monitoring models to a public IoT dataset of benign and attack traces and show they yield an average true-positive rate of 94% and a false-positive rate of 5%. Finally, we publicly release our data (training and testing instances of classification and monitoring tasks) and code for convex hull-based one-class models.",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Intelligent Diagnosis Model of Mechanical Fault for Power Transformer Based on SVM Algorithm",
        "paper_author": "Zang C.",
        "publication": "Gaoya Dianqi/High Voltage Apparatus",
        "citied_by": "7",
        "cover_date": "2023-12-16",
        "Abstract": "Vibration analysis method is a non⁃electric diagnostic method for mechanical fault of transformer. The method can diagnose such faults as winding deformation or core looseness inside the transformer by analyzing vibra⁃ tion characteristic of the surface of transformer oil tank. SVM，as a new machine learning method，can train and ob⁃ tain a classification model with strong generalization ability under the condition of small samples. Based on the vibra⁃ tion signal and SVM algorithm，an intelligent diagnosis model of transformer is constructed. The SVM training data set is constructed on the basis of collection of hundreds of groups of vibration signal data trial transformer and spec⁃ trum feature extraction.The one class υ⁃SVM fault diagnosis model is trained and good results are achieved. The effec⁃ tiveness of the model is verified，which can provide some references for the related researchers.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Investigating the Performance of CMIP6 Seasonal Precipitation Predictions and a Grid Based Model Heterogeneity Oriented Deep Learning Bias Correction Framework",
        "paper_author": "Huang B.",
        "publication": "Journal of Geophysical Research: Atmospheres",
        "citied_by": "4",
        "cover_date": "2023-12-16",
        "Abstract": "Climate change is expected to alter the magnitude and spatiotemporal patterns of hydro-climate variables such as precipitation, which has significant impacts on the ecosystem, human societies and water security. Global Climate Models are the major tools to simulate historical as well as future precipitation. However, due to imperfect model structures, parameters and boundary conditions, direct model outputs are subject to large uncertainty, which needs serious evaluation and bias correction before usage. In this study, seasonal precipitation predictions from 30 Coupled Model Inter-comparison Project Phase 6 (CMIP6) models and Climate Research Unit observations are used to evaluate historical precipitation climatology in global continents during 1901–2014. A grid based model heterogeneity oriented Convolutional Neural Network (CNN) is proposed to correct the ensemble mean precipitation bias ratio. Besides, regression based Linear Scaling (LS), distribution based Quantile Mapping (QM) and spatial correlation CNN bias correction approaches are employed for comparison. Results of model performance evaluation indicate that generally precipitation prediction is more reliable in JJA than DJF on the global scale. Most models tend to have larger bias ratio for extreme precipitation. In addition, current CMIP6 models still have certain issues in accurate simulation of precipitation in mountainous regions and the regions affected by complex climate systems. Moreover, the proposed grid based model heterogeneity oriented CNN has better performance in ensemble mean bias correction than LS, QM, and spatial correlation CNN, which could consider the relative model performance and capture the features similar to actual climate dynamics.",
        "affiliation_name": "Hohai University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Surface Turbulent Fluxes From the MOSAiC Campaign Predicted by Machine Learning",
        "paper_author": "Cummins D.P.",
        "publication": "Geophysical Research Letters",
        "citied_by": "4",
        "cover_date": "2023-12-16",
        "Abstract": "Reliable boundary-layer turbulence parametrizations for polar conditions are needed to reduce uncertainty in projections of Arctic sea ice melting rate and its potential global repercussions. Surface turbulent fluxes of sensible and latent heat are typically represented in weather/climate models using bulk formulae based on the Monin-Obukhov Similarity Theory, sometimes finely tuned to high stability conditions and the potential presence of sea ice. In this study, we test the performance of new, machine-learning (ML) flux parametrizations, using an advanced polar-specific bulk algorithm as a baseline. Neural networks, trained on observations from previous Arctic campaigns, are used to predict surface turbulent fluxes measured over sea ice as part of the recent MOSAiC expedition. The ML parametrizations outperform the bulk at the MOSAiC sites, with RMSE reductions of up to 70 percent. We provide a plug-in Fortran implementation of the neural networks for use in models.",
        "affiliation_name": "Université de Toulouse",
        "affiliation_city": "Toulouse",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Semi-empirical and machine learning-based prediction of site of metabolisms mediated by aldehyde oxidase",
        "paper_author": "Shiotake Y.",
        "publication": "Chemical Physics Letters",
        "citied_by": "1",
        "cover_date": "2023-12-16",
        "Abstract": "Prediction of drug clearance by aldehyde oxidase (AO) catalyzed metabolism has been of great interest in drug discovery. We report a fast, accurate, and fully-automated tool that combines semi-empirical quantum mechanical (SQM) calculations and machine-learning (ML) technique to predict AO-mediated site of metabolism (SOM). We infer that calculated probability scores together with those based on approximate C(sp2)−H bond dissociation energies accomplish accurate and immediate prediction of the number and rank ordering of SOMs. Tests on a series of 150 AO substrates demonstrate that our computational strategy can be applicable to high-throughput screening of metabolically stable compounds.",
        "affiliation_name": "Hiroshima City University",
        "affiliation_city": "Hiroshima",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Committed Ice Loss in the European Alps Until 2050 Using a Deep-Learning-Aided 3D Ice-Flow Model With Data Assimilation",
        "paper_author": "Cook S.J.",
        "publication": "Geophysical Research Letters",
        "citied_by": "5",
        "cover_date": "2023-12-16",
        "Abstract": "Modeling the short-term (<50 years) evolution of glaciers is difficult because of issues related to model initialization and data assimilation. However, this timescale is critical, particularly for water resources, natural hazards, and ecology. Using a unique record of satellite remote-sensing data, combined with a novel optimisation and surface-forcing-calculation method within the framework of the deep-learning-based Instructed Glacier Model, we are able to ameliorate initialization issues. We thus model the committed evolution of all glaciers in the European Alps up to 2050 using present-day climate conditions, assuming no future climate change. We find that the resulting committed ice loss exceeds a third of the present-day ice volume by 2050, with multi-kilometer frontal retreats for even the largest glaciers. Our results show the importance of modeling ice dynamics to accurately retrieve the ice-thickness distribution and to predict future mass changes. Thanks to high-performance GPU processing, we also demonstrate our method's global potential.",
        "affiliation_name": "Université Grenoble Alpes",
        "affiliation_city": "Saint Martin d'Heres",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Optimizing Seasonal-To-Decadal Analog Forecasts With a Learned Spatially-Weighted Mask",
        "paper_author": "Rader J.K.",
        "publication": "Geophysical Research Letters",
        "citied_by": "2",
        "cover_date": "2023-12-16",
        "Abstract": "Seasonal-to-decadal climate prediction is crucial for decision-making in a number of industries, but forecasts on these timescales have limited skill. Here, we develop a data-driven method for selecting optimal analogs for seasonal-to-decadal analog forecasting. Using an interpretable neural network, we learn a spatially-weighted mask that quantifies how important each grid point is for determining whether two climate states will evolve similarly. We show that analogs selected using this weighted mask provide more skillful forecasts than analogs that are selected using traditional spatially-uniform methods. This method is tested on two prediction problems using the Max Planck Institute for Meteorology Grand Ensemble: multi-year prediction of North Atlantic sea surface temperatures, and seasonal prediction of El Niño Southern Oscillation. This work demonstrates a methodical approach to selecting analogs that may be useful for improving seasonal-to-decadal forecasts and understanding their sources of skill.",
        "affiliation_name": "Walter Scott, Jr. College of Engineering",
        "affiliation_city": "Fort Collins",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Information Deprivation and Democratic Engagement",
        "paper_author": "Yee A.K.",
        "publication": "Philosophy of Science",
        "citied_by": "4",
        "cover_date": "2023-12-16",
        "Abstract": "There remains no consensus among social scientists as to how to measure and understand forms of information deprivation such as misinformation. Machine learning and statistical analyses of information deprivation typically contain problematic operationalizations which are too often biased towards epistemic elites' conceptions that can undermine their empirical adequacy. A mature science of information deprivation should include considerable citizen involvement that is sensitive to the value-ladenness of information quality, and doing so may improve the predictive and explanatory power of extant models.",
        "affiliation_name": "University of Toronto, Institute for the History and Philosophy of Science and Technology",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Microbiome and metabolome in home-made fermented soybean foods of India revealed by metagenome-assembled genomes and metabolomics",
        "paper_author": "Kharnaior P.",
        "publication": "International Journal of Food Microbiology",
        "citied_by": "9",
        "cover_date": "2023-12-16",
        "Abstract": "Grep-chhurpi, peha, peron namsing and peruñyaan are lesser-known home-made fermented soybean foods prepared by the native people of Arunachal Pradesh in India. Present work aims to study the microbiome, their functional annotations, metabolites and recovery of metagenome-assembled genomes (MAGs) in these four fermented soybean foods. Metagenomes revealed the dominance of bacteria (97.80 %) with minor traces of viruses, eukaryotes and archaea. Bacillota is the most abundant phylum with Bacillus subtilis as the abundant species. Metagenome also revealed the abundance of lactic acid bacteria such as Enterococcus casseliflavus, Enterococcus faecium, Mammaliicoccus sciuri and Staphylococcus saprophyticus in all samples. B. subtilis was the major species found in all products. Predictive metabolic pathways showed the abundance of genes associated with metabolisms. Metabolomics analysis revealed both targeted and untargeted metabolites, which suggested their role in flavour development and therapeutic properties. High-quality MAGs, identified as B. subtilis, Enterococcus faecalis, Pediococcus acidilactici and B. velezensis, showed the presence of several biomarkers corresponding to various bio-functional properties. Gene clusters of secondary metabolites (antimicrobial peptides) and CRISPR-Cas systems were detected in all MAGs. This present work also provides key elements related to the cultivability of identified species of MAGs for future use as starter cultures in fermented soybean food product development. Additionally, comparison of microbiome and metabolites of grep-chhurpi, peron namsing and peruñyaan with that of other fermented soybean foods of Asia revealed a distinct difference.",
        "affiliation_name": "Sikkim University",
        "affiliation_city": "Gangtok",
        "affiliation_country": "India"
    },
    {
        "paper_title": "ChatGPT: From technological innovation to paradigm revolution",
        "paper_author": "Zhang H.",
        "publication": "Studies in Science of Science",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Does ChatGPT signal an \" intelligent revolution\" ? It is urgent to make a systematic analysis. In this paper, starting from the evaluation of the innovation effects of ChatGPT, the comparative analysis found that it belongs to progressive innovation and disruptive innovation in the series of products of OpenAI, Codex and InstructGPT for instance; ChatGPT is superior to Codex and InstructGPT in following human values, avoiding answers outside the scope of knowledge, dialogue ability, and in - task dialogue history modeling. The aforementioned conversational capability - related performance improvements come at the expense of some performance. n terms of code understanding and code generation, it is weaker than Codex; In terms of context learning ability, it is weaker than InstructGPT. Compared with similar competitive products, OPT of Meta, Sparrow of DeepMind, RL4LMs of Ai2, FLAN of Google, and so on, ChatGPT is indeed a breakthrough innovation and subversive technological innovation. Within the Generative Pre - trained Model technological system of OpenAI, ChatGPT has formed a trans - boundary integrated disruptive technology evolution trajectory. In the entire AI ecosystem including multimodal big models, it can be regarded as a performance transition type of disruptive technology. In contrast to a set of AI big models developed by the Chinese R&D startups, institutions or corporations, ChatGPT has become an important part of the \" bottleneck\" technology system to China, including various sub - fields of artificial intelligence. With ChatGPT, USA has formed a certain technical \" moat\" in the subdivision field and the overall technical system, and there are inter - generational competitive advantages for Chinese large language models. It is found that ChatGPT, as a \" production tool\", forms a paradigm revolution in the supply of productivity tools in the field of artificial intelligence. As the disruptive technological innovation and one part of the basic technical cores of ChatGPT, Codex is manifested as a breakthrough in \" production tools\" . The big model for coding generation, Codex essentially realizes two levels of innovation: functional product innovation and instrumental paradigm revolution. On the functional level, Codex and its subsequent series of large models gain the ability to understand code and complex reasoning, which in turn makes them more powerful than competing large models in understanding the practical effects of human language. On the productional level, Codex formed a paradigm revolution in the supply chain of code production tools in the field of artificial intelligence. The man - machine dialogue mechanism of ChatGPT, in fact, provides a new technical solution for the ethical governance of artificial intelligence. ChatGPT has Continue the tradition of human - computer interaction, which always been an important way of artificial intelligence ethical governance, in that chatbot has become an important technical solution of artificial intelligence ethical governance, and can unify the core elements of technology ethical governance such as technology subject, technology object, technology itself, technology application process, and technology scene on the dialogue platform. So, at the same time, ChatGPT also realizes the paradigm change of AI ethical governance. The organizational structural elements generated for ChatGPT can be traced back to the organizational mission of OpenAI, the flat project - oriented organization, the financing mechanism innovation with limited returns, and the efficient coupling of open source and crowdsourcing R&D organizational solution in the process of AI ModelOps. These findings lay a solid theorical and experiential foundation for further research on political, economic, and social impacts of the big models like ChatGPT and related technological governance.",
        "affiliation_name": "Shanghai Artificial Intelligence Laboratory",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Detection of COVID-19 infection from CT images using the medical photogrammetry technique",
        "paper_author": "Çatal Reis H.",
        "publication": "Mersin Photogrammetry Journal",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Medical data such as computed tomography (CT), magnetic resonance imaging (MRI), and Ultrasound images are used in medical photogrammetry. CT images have been used frequently in recent years for the diagnosis of COVID-19 disease, which has contagious and fatal symptoms. CT is an effective method for early detection of lung anomalies due to COVID-19 infection. Machine learning (ML) techniques can be used to detect and diagnose medical diseases. In particular, classification methods are applied for disease diagnosis and diagnosis. This study proposes traditional machine learning algorithms Random Forest, Logistic Regression, K-Nearest Neighbor and Naive Bayes, and an ensemble learning model to detect COVID-19 anomalies using CT images. According to the experimental findings, the proposed ensemble learning model produced an accuracy of 96.71%. This study can help identify the fastest and most accurate algorithm that predicts CT images with Covid-19 during the epidemic process. In addition, machine learning-based approaches can support healthcare professionals and radiologists in the diagnostic phase.",
        "affiliation_name": "Gümüşhane Üniversitesi",
        "affiliation_city": "Gumushane",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "From ChatGPT to the human - machine collective knowledge construction",
        "paper_author": "Zhang Y.",
        "publication": "Studies in Science of Science",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Large language models like ChatGPT are expected to bring about a new round of knowledge revolution. ChatGPT has powerful language comprehension and learning abilities that enable it to function as a knowledge base. The open use of ChatGPT provides people with more equal opportunities to access knowledge and can help enrich people’ s understanding of knowledge, resolve conflicts caused by differences in knowledge, and provide new ways to promote collaboration among groups. To achieve knowledge co - construction, humans and machine should collaborate. Companies should better shoulder the social responsibility for knowledge collaboration and establish trust relationships among diverse entities to promote human - machine collaboration. Multiple negotiation mechanisms should also be established to promote the active role of large language models in knowledge transformation and make knowledge production more innovative.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Image recognition of non-metallic inclusions based on deep learning",
        "paper_author": "Liang Y.",
        "publication": "Kang T'ieh/Iron and Steel",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Due to the reaction between molten steel and slag, refractory, atmosphere, the non-metallic inclusions (NMIs) were generally formed during the steelmaking process. The NMIs may damage the continuity and increase the non-uniformity of the steel matrix, and then decrease the ductility, toughness, and fatigue resistance. The qualitative detection of NMIs was generally through SEM and EDS. However, the method was very time-consuming and had subjective and random. Rapid detection and identification of NMIs were very important to improve the steelmaking process. In recent years, with the increasing maturity of computer vision technology, RCNN target detection algorithms have evolved and improved for many generations, and the Mask-RCNN target detection algorithm was formed. Mask-RCNN can not only accurately realize the location of non-metallic inclusion, but also realize the mask segmentation and recognition classification. The Mask-RCNN can be effectively applied to inclusion segmentation and recognition. Based on the Mask-RCNN target detection algorithm, a large number of SEM images for AlN、Al2O3、MnS, and AlN-MnS NMIs in low-density steel were trained, and after 10 000 iterations of training, the accurate location and mask segmentation of the mentioned four kinds of NMI were accurately identified. The model was effective and accurate for inclusion detection and recognition. The recognition accuracy of MnS and AlN-MnS inclusions was 100%, the value of AlN inclusion was 95.91%, and the value of Al2O3 inclusion was only 83.33%.",
        "affiliation_name": "China Iron and Steel Research Institute Group",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application value of joint friction sounds in diagnosing meniscus injury of the knee based on machine learning models",
        "paper_author": "Hu B.",
        "publication": "Chinese Journal of Trauma",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Objective To investigate the application value of joint friction sounds in diagnosing meniscus injury of the knee based on machine learning models. Methods A case-control study was conducted to analyze the clinical data of 17 patients with meniscus injury of the knee (meniscus injury group) admitted to Sir Run Run Shaw Hospital Affiliated to Nanjing Medical University from August 2020 to October 2022, as well as 75 recruited healthy subjects without knee joint diseases (healthy group). The knee joint friction sounds of the subjects were collected in a relatively quiet environment (peak value below 40 dB). The sounds collected in a flexion-extension-flexion mode of exercise were split and divided randomly with a ratio of 4∶1 into the training set (125 segments from the meniscal injury group and 187 segments from the healthy group) and the test set (33 segments from the meniscal injury group and 47 segments from the healthy group). The sounds obtained in a sit-stand-sit mode of exercise were split and divided randomly with a ratio of 4∶1 into the training set (81 segments from the meniscal injury group and 164 segments from the healthy group) and the test set (20 segments from the meniscal injury group and 40 segments from the healthy group). Four machine learning models were built, including support vector machine with linear kernels, radial basis function support vector machine, random forest, and extremely randomized trees. The learning training of the model was performed on the training set, and its model performance was verified with the test set. The time required in a single collection of joint friction sound from the subjects and the interpretation of data analysis was recorded. Knee function of the subjects were scored according to the Lysholm Score before and at 1 day after the test. The accuracy rates of diagnosis of meniscus injury with friction sounds under the two modes of exercise were compared based on the test results to yield an optimal one. The effectiveness of the four models was compared to find the best machine learning model fitting the data frame of this study according to the test results such as accuracy, sensitivity, specificity, F1 score, and area under the receiver operating characteristic curve (AUC) obtained with the optimal mode of exercise. The diagnostic accuracy, misdiagnosis rate and missed diagnosis rate of joint friction sound for meniscal injury under the optimal machine learning model with the optimal mode of exercise were observed. Results The time required in a single collection of joint friction sound ranged from 5 to 10 minutes [(7.1±1.3)minutes], when the time required for interpretation of data analysis was approximately 1 minute. The Lysholm Score before and after the test was (75.6±4.0)points and (77.7±3.7)points respectively in the meniscal injury group (P>0.05), and (99.6±0.9)points and (99.5±1.0)points respectively in the healthy group (P>0.05). The diagnosing accuracy rates for flexion-extension-flexion of exercise and sit-stand-sit modes of exercise were 0.775 and 0.817 under the support vector machine model with linear kernels; 0.813 and 0.900 under the radial basis function support vector machine model; 0.800 and 0.867 under the random forest model; 0.800 and 0.900 under the extremely randomized tree model. The accuracy rates for sit-stand-sit mode of exercise were all higher than those for flexion-extension-flexion mode of exercise. In the sit-stand-sit mode of exercise, the extremely randomized tree model had an accuracy rate of 0.900, sensitivity of 0.900, specificity of 0.950, F1 score of 0.900, and AUC of 0.942, which were higher than those under the remaining 3 models, showing better machine learning efficacy. Under the extremely randomized tree model in the sit-stand-sit mode of exercise, 22 (18 true positive and 4 false positive) were diagnosed as meniscal injury and 38 (36 true negative and 2 false negative) as healthy out of 60 segments in the test set (20 from the meniscal injury group and 40 from the healthy group). The diagnostic accuracy of joint friction sounds in diagnosing meniscus injury of the knee was 0.900, with the misdiagnosis rate of 0.100 and the missed diagnosis rate of 0.100. Conclusion Diagnosis of meniscus injury of the knee with joint friction sounds can shorten time and enhance safety during the examination process. The diagnostic model using machine learning-based artificial intelligence is faster and more stable, which can be used as a diagnostic marker for such injury.",
        "affiliation_name": "Suqian University",
        "affiliation_city": "Suqian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of artificial intelligence in brachytherapy for cervical cancer",
        "paper_author": "Zhang W.",
        "publication": "Chinese Journal of Radiation Oncology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Brachytherapy (BT) provides the opportunity to deliver highly potent radiation doses to the tumor, while more effectively sparing the surrounding organs at risk (OAR) due to the proximity of radiation sources to the tumor target and rapid fall-off of the source dose profile. As an important part of radiotherapy for cervical cancer, BT plays an irreplaceable role. The BT process is complex and can be divided into a series of steps. Long time waiting for patients in the state of implantation of the applicator may cause changes in the position of the applicator relative to the tumor and the movement of the OAR. In recent years, artificial intelligence (AI) has made great progress in the medical field. Machine learning and neural network have been widely applied in all aspects of BT, such as implantation of the applicator, image acquisition, segmentation of target area and OAR, reconstruction of the applicator, plan optimization, and treatment delivery, etc. In addition, BT significantly reduces the overall time, improves the homogeneity of operation, and enhances the accuracy of treatment. In this article, the application, development prospects, and challenges of AI in the BT of cervical cancer in recent years were reviewed, aiming to provide novel ideas for the application of AI in BT.",
        "affiliation_name": "Peking Union Medical College Hospital",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "In silico immunoinformatics based prediction and designing of multi-epitope construct against human rhinovirus C",
        "paper_author": "Sur S.",
        "publication": "Acta Biologica Szegediensis",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Human rhinovirus C (HRV-C) is an RNA virus infecting human respiratory tract. It is associated with complexities like asthma, chronic obstructive pulmonary disease, and respiratory damage. HRV-C has many serotypes. Till date there is no vaccine. Despite some limitations, corticosteroids, bronchodilators, and common cold medicines are used to treat HRV-C infections. Here, we have used immunoinformatics approach to predict suitable cytotoxic T-cell, helper T-cell and linear B-cell epitopes from the most antigenic protein. VP2 protein of Rhinovirus C53 strain USA/CO/2014-20993 was found to be most antigenic. The multi-epitope construct was designed using the best CTL, HTL and linear B-cell epitopes and attaching them with adjuvant and linkers. Interferon-gamma inducing epitopes and conformational B-cell epitopes were also pre-dicted from the construct. Physicochemical and structural properties of the construct were satisfactory. Binding pockets were identified that could be the targets for designing effective inhibitors. Molecular docking revealed strong binding affinity of the construct with human Toll-like receptors 2 and 4. Normal mode analysis divulged stability of the docked complex. Codon optimization, in silico cloning and immune simulation analysis demonstrated suitability of the construct. These findings are likely to aid in vitro studies for developing vaccine against HRV-C.",
        "affiliation_name": "Ramananda College",
        "affiliation_city": "Bishnupur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Security requirements formalization with RQCODE",
        "paper_author": "Sadovykh A.",
        "publication": "CyberSecurity in a DevOps Environment: From Requirements to Monitoring",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Security requirements vary in nature and form. These requirements may come from compliance checklists, implementation guidelines, corporate standards, and reports from organizations such as NIST, MITRE, and OWASP. Stakeholders may express additional requirements, depending on the context, to address threats and vulnerabilities as quickly as possible. Requirements are usually expressed in natural language, sometimes accompanied by tests, fixes, or descriptions of attack vectors. Analyzing, managing, verifying, validating, and tracing the requirements are therefore challenging as it relies heavily on human activity. Formalizing requirements for automated analysis and reuse can help to reduce human error-prone activities. Seamless Object-Oriented Requirement (SOOR) promotes a paradigm of multi-requirement views. In this paradigm, requirements are classes described in an object-oriented programming (OOP) language that combines representations in natural language with those in formal languages, such as LTL or Eiffel. The embedded formal language representations can provide means for validating requirements. In addition, the major advantage is that OOP supports seamless reuse of requirements classes and extensions through inheritance or associations. RQCODE is a novel approach based firstly on the implementation of SOOR in Java, and secondly on the applicability of SOOR to security requirements. This is done while providing a lightweight formalization through the associated tests that validate and strengthen system security according to the Security Technical Implementation Guide (STIG). We argue that this approach, also known as RQCODE, offers several advantages for formalizing, reusing, analyzing, and validating security requirements by automated means. In this chapter, we discuss the challenges of requirements specification in the cybersecurity domain and present our RQCODE approach.",
        "affiliation_name": "Institut de Recherche en Informatique de Toulouse",
        "affiliation_city": "Toulouse",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Natural language processing with machine learning for security requirements analysis: practical approaches",
        "paper_author": "Sadovykh A.",
        "publication": "CyberSecurity in a DevOps Environment: From Requirements to Monitoring",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Analyzing security requirements is a tedious task. Quite often they are spread around requirements specifications or specified in a very generic form. The experts have to make sure to extract all the security requirements and properly detail by applying the best practices from appropriate standards such as OWASP ASVS, STIG, or IEC62443. The requirements are specified in various forms, most commonly as statements in natural language. Natural language processing (NLP) has been applied for many years in requirements engineering (RE) for many analysis tasks. However, until recently, the performance on NLP methods on the RE tasks has been questionable. In this chapter, we outline the state of the art in the NLP methods in RE and in particular analysis of security requirements as well as provide practical recipes application of modern transfer learning architectures to several important RE tasks illustrated with an example.",
        "affiliation_name": "SOFTEAM",
        "affiliation_city": "Ivry-sur-Seine",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Hard real-time computing systems: Predictable scheduling algorithms and applications",
        "paper_author": "Buttazzo G.",
        "publication": "Hard Real-Time Computing Systems: Predictable Scheduling Algorithms and Applications",
        "citied_by": "548",
        "cover_date": "2023-12-15",
        "Abstract": "This book is a basic treatise on real-time computing, with particular emphasis on predictable scheduling algorithms. The main objectives of the book are to introduce the basic concepts of real-time computing, illustrate the most significant results in the field, and provide the basic methodologies for designing predictable computing systems useful in supporting critical control applications. Hard Real-Time Computing Systems is written for instructional use and is organized to enable readers without a strong knowledge of the subject matter to quickly grasp the material. Technical concepts are clearly defined at the beginning of each chapter, and algorithm descriptions are corroborated through concrete examples, illustrations, and tables. This new, fourth edition includes new sections to explain the variable-rate task model, how to improve predictability and safety in cyber-physical real-time systems that exploit machine learning algorithms, additional coverage on Response Time Analysis, and a new chapter on implementing periodic real-time tasks under Linux.",
        "affiliation_name": "Sant'Anna Scuola Universitaria Superiore Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "A Data-Driven Analytical Framework for ESG-based Stock Investment Analytics using Machine Learning and Natural Language Processing",
        "paper_author": "Cao E.E.C.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "This research explores the intricate relationship between sentiment analysis, stock market dynamics, and Environmental, Social, and Governance (ESG) based investment analytics, harnessing sentiment as a predictive tool for stock price movements. Leveraging Twitter data, Natural Language Processing (NLP), TextBlob, and the scikit-learn RandomForestRegressor, in combination with machine learning algorithms, the study evaluates public sentiment’s impact on stock prices, offering valuable insights to investors and risk managers. Moreover, the findings elucidate the potential to enhance ESG-based investment analytics by incorporating sentiment-derived insights into investment decision-making processes, which is particularly pertinent given the increasing market focus on sustainable investing. Experimental results unveil the potential of sentiment analysis in forecasting stock price changes and augmenting ESG investment strategies, underlining its utility as both a forecasting instrument and a risk management mechanism. However, the research also identifies challenges, including limitations of the Twitter API and the need for data refinement. Strategies to address these challenges are discussed, emphasizing the importance of diversifying data sources and enhancing data quality. This study advances our understanding of sentiment analysis in financial markets and its applicability to ESG-based investment analytics, offering data-driven guidance to navigate the complexities of the stock market landscape. Ultimately, it highlights the promising prospect of integrating social media sentiment analysis with machine learning for more informed stock market predictions, risk management, and sustainable investment strategy formulation.",
        "affiliation_name": "California State Polytechnic University, Pomona",
        "affiliation_city": "Pomona",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "On the Use and Reuse of Graphs for Network Security with Real-Time Edge Learning",
        "paper_author": "Jerge M.M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "We present a novel approach in network security using unsupervised online machine learning method at the edge, through graph learning. The proposed system takes advantage of an online learning paradigm, by collecting real network data to build a ground truth of a network’s topology, using shallow graph neural networks (GNNs). Our proposed solution includes an edge-based infrastructure, through K3s and Kafka, which could then scale to match the needs of larger networks. We then perform simple cyber-attacks and show how visual analysis can identify malicious behaviors, without any prior labeled data. Our results against simple attacks show promise that improved graph analytics should capture even more complex attack vectors. We then conclude with some suggestions for improved edge deployment, against larger and more complex networks.",
        "affiliation_name": "University of Cincinnati",
        "affiliation_city": "Cincinnati",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Serverless-DFS: Serverless Federated Learning with Dynamic Forest Strategy",
        "paper_author": "Deng B.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Training large-scale machine learning models typically requires support from High-performance Computers (HPCs) or cloud servers. One strategy to reduce the computational burden and alleviate the communication bottleneck of servers or HPCs is to move a subset of training computation to the edge or end-user devices. Federated learning is a distributed training approach that aims to protect the privacy of end-user data. However, most federated learning systems utilize centralized server architecture, which slows down the model training and limits the system’s scalability. Many machine learning trainings require high performance while maintaining end-user data security. The state-of-the-art serverless approaches have performance limitations and can be further improved. This paper proposes Serverless-DFS, a serverless federated learning with a dynamic forest strategy, to improve the performance and scalability of federated learning while keeping its privacy protection capability. From the experimental results, our Serverless-DFS approach is observed to have a 63.9X speedup compared to the default server-client method in a large-scale system with 256 clients.",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "DoH Tunneling Traffic Detection Based on Single Packet Features Analysis",
        "paper_author": "Pich R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "DNS over HTTPS (DoH) Tunneling is a technique used to encapsulate the information or programs of other protocols into the DNS protocol with the encrypted form for communication. On the strength of DNS as the core component in internet communication, DoH straightens data privacy with less restriction and qualification of tunneling techniques, the attackers take advantage of exploring DoH Tunneling traffic to initial and deploy their activities, such as command and control communication and data exfiltration. Keeping their assets safe is becoming a critical issue for every organization. Based on our knowledge and investigation, currently, there are only flow-level feature analysis solutions that have been made, and they don’t have any methods using single packet information to detect the DoH Tunneling traffic. it can’t be used passive data analysis methods such as the active detection system’s flow-level detection system. Therefore, in this paper, the first packet-level feature analysis solution to detect DoH Tunneling traffic by using only five selected features from the packet and a study of the number of packets inside flow learning for this traffic detection is proposed. As a result, Random Forest can perform well, with a high accuracy of up to 99.93% among other algorithms.",
        "affiliation_name": "Université de Namur",
        "affiliation_city": "Namur",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Apply Machine-Learning Model for Clustering Rowing Players",
        "paper_author": "Wilaikaew P.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Rowing, as a sport composed of single player or multiple players, performs body movements under certain rhythm with slight variation. The analysis of rhythm alternation or match is important on rowing research and merit our study. Therefore, this study analyzes the rowing movements by the following three procedures, rowing cycle segmentation, feature extraction, rowing cycle clustering. The rowing cycle segmentation procedure segments each player’s video to videos of single cycle under the analysis of MediaPipe detected joint points. The feature extraction procedure calculates features from each rowing cycle by selecting amplitudes, angles, angular speeds of 4 selected joint points. At last, the rowing cycle clustering procedure analyzes all one-cycled videos using above features by different clustering and scoring methods. Three clustering methods, including K-means, Birch, and Gaussian-mixture, are experimented in this study for finding the most efficient one. A hybrid measurement from the Silhouette score, the Calinski-Harabasz index, and the Davies-Bouldin index, is proposed for finding the optimal clusters number. Experimental results of 15 players’ videos show that applying K-means clustering algorithm with the proposed hybrid measurement performs better for finding the rowing group.",
        "affiliation_name": "Kasetsart University Sriracha Campus",
        "affiliation_city": "Si Racha",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "NLPIR 2023 - 2023 7th International Conference on Natural Language Processing and Information Retrieval",
        "paper_author": "NA",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The proceedings contain 49 papers. The topics discussed include: cross-lingual text clustering in a large system; explainable machine learning models for Swahili news classification; impact of emojis in emotion analysis on code-mixed text; extracting structured information from the textual description of geometry word problems; exploring hierarchical multi-label text classification models using attention-based approaches for Vietnamese language; leveraging salience analysis and sparse attention for long document summarization; domain specific transformers-based prioritization of re-admission for patients in healthcare; exploring the impact of lexicon-based knowledge transfer for hate speech detection in Indonesia code-mixed languages; action-item-driven summarization of long meeting transcripts; and a brain function connection method for tone processing of deaf children based on one-dimensional convolutional network.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "On Cognitive Level Classification of Assessment-items Using Pre-Trained BERT-based Model",
        "paper_author": "Dipto A.S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Outcome based education (OBE) is gaining popularity nowadays due to its effectiveness in preparing learners for their future roles as active participants. Bloom's taxonomy is a well-known educational model as it helps implement the OBE. It offers teachers a tool to encourage progressive thinking and intellectual development in students. Bloom's Taxonomy helps categorize cognitive skills and learning objectives, while the cognitive level classification of assessment items determines the complexity needed to complete the assessment. By using both the cognitive level classification and Bloom's Taxonomy, educators can create assessments that accurately measure students' abilities and target specific learning outcomes. This paper proposes a model that can accurately categorize assessment items according to their cognitive complexity. The paper utilizes the cognitive domains of Bloom's Taxonomy and focuses specifically on the first four levels: remembering, understanding, applying, and analysing. Some previous attempts have been made in this field but, to our best knowledge, this is the first time the Bidirectional architecture of Deep Learning (DL) algorithms and BERT-based Transformer model have been used. By comparing several machine learning (ML) algorithms, DL algorithms with Bidirectional layers and pre-Trained BERT-based Transformer model, it has been found that the BERT model scores the highest among all the other ML and DL algorithms. The performance is evaluated based on accuracy, precision, recall, and F1-score. The BERT-based Transformer model has an accuracy of 89%, where some of the other algorithms performed considerably well (BiLSTM: 84%, LSTM: 83%, BiGRU: 83%, RF: 83%). Also, compared to the state-of-The-Art model, the transformer model scored higher. This suggests that the model can be used to deploy as the classification model. The developed model will help educators with the exact assessment items to implement OBE. Overall, this research contributes to the field of NLP and educational assessment by demonstrating the potential of ML and DL approaches in accurately classifying assessment items.",
        "affiliation_name": "East West University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Named entity recognition for setswana language: A conditional random fields (CRF) approach",
        "paper_author": "Okgetheng B.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Named Entity Recognition (NER) is a fundamental task in Natural Language Processing (NLP) focused on identifying entities like individuals, organizations, and locations within text. Locating these entities can present initial challenges, and subsequent classification can be equally daunting. This complexity is exemplified in Setswana, where shared naming between locations and personal names adds an extra layer of intricacy. This study introduces a Setswana NER approach, featuring a Setswana Regex Annotator (SERxA) for preliminary entity classification, followed by BRAT tool annotation. Employing the Conditional Random Fields (CRF) algorithm, we establish a supervised statistical machine learning NER model for Setswana. Evaluation using standard metrics on a held-out test set attains impressive F1-scores of 0.94 for person entities and 0.79 for location entities. Our findings underscore the viability of NER in Setswana and emphasize the necessity of nurturing NLP resources for less-resourced languages.",
        "affiliation_name": "University of Botswana",
        "affiliation_city": "Gaborone",
        "affiliation_country": "Botswana"
    },
    {
        "paper_title": "Exploring the Impact of Lexicon-based Knowledge Transfer for Hate Speech Detection in Indonesia Code-Mixed Languages",
        "paper_author": "Pamungkas E.W.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In this study, our objective is to examine the influence of external knowledge from a lexicon on knowledge transfer for mitigating the language shift issue in the detection of hate speech in code-mixed languages. To accomplish this, we constructed a lexicon based on findings from previous studies. Subsequently, we implemented several machine learning models with various scenarios to assess the impact of the lexicon. The experimental results demonstrate that incorporating lexicon features leads to improved performance in detecting hate speech within code-mixed languages. Particularly, utilizing a lexicon that encompasses both implicit and explicit lexicons yields the most favorable outcomes in this investigation. This research provides valuable insights into understanding the detection of hate speech in code-mixed Indonesian languages and contributes to the advancement of more robust systems aimed at fostering a safer and more inclusive online environment. By leveraging the lexicon and exploring the interplay between implicit and explicit elements in hate speech, this study enhances our understanding of addressing hate speech challenges in Indonesia code-mixed languages and paves the way for developing more effective detection mechanisms.",
        "affiliation_name": "Universitas Muhammadiyah Surakarta",
        "affiliation_city": "Surakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Fine-Tuning BERT on Twitter and Reddit Data in Luganda and English",
        "paper_author": "Kimera R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Deep learning techniques, driven by the Transformer architecture and models like BERT, find broad utility. While sentiment analysis in high-resource languages is well-established, it's largely unexplored in low-resource ones. Our focus is on Luganda, a prevalent Ugandan language, spoken by over 21 million people. We utilized three datasets, from social media, to train machine learning models as baseline models and used BERT for deep learning. Our findings enhance sentiment analysis in both Luganda and English. Our approach for data extraction aids domain-specific dataset construction. This research advances NLP and aligns with global deep-learning initiatives.",
        "affiliation_name": "Handong Global University",
        "affiliation_city": "Pohang",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A Study of Dialog Summarization Across Datasets and Domains",
        "paper_author": "Ranganathan A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "This study of dialog summarization covers multi-domain, multimodal and multilingual datasets, and the potential challenges in the different domains. The scope and progress of this rapidly evolving topic rely on the availability of datasets and emerging domains. Such a study can facilitate the cross-application of datasets to different domains to refine models and also aid scenarios where there is a lack of data in privacy-sensitive settings. Further, our work can enable the cross-fertilization of ideas across domains and in different contexts. Our study encompasses current and emerging domains, a comprehensive compilation of datasets, and avenues for further research.",
        "affiliation_name": "Indian Institute of Technology Madras",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Exploring Naive Approaches to Tell Apart LLMs Productions from Human-written Text",
        "paper_author": "Giudice O.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Powerful Large Language Models (large LMs or LLMs) such as BERT and GPT are making the task of detecting machine-generated text more and more prominent and crucial to minimize threats posed by text generation models misuse. Nonetheless, only a limited number of efforts exist so far, which can be classified into simple classifiers, zero-shot approaches, and fine-Tuned LMs. These approaches usually rely on LMs whose discrimination accuracy decreases as the size difference in favor of the generator model increases (hence, a detector should always employ a LM with at least the same number of parameters of the source LM). Also, most of these approaches do not explicitly investigate whether the sentence syntactic structure can provide additional information that helps to build better detectors. All these considerations make the generalizing ability of detection methods into question. While generation techniques become more and more capable of producing human-like text, are the detection techniques capable of keeping up if not properly trained? In this paper, we evaluate the most effective (and reproducible) detection method available in the state of the art in order to figure out the limits in its robustness. We complement this analysis by discussing results obtained using a novel naive approach that demonstrably achieves comparable results in terms of robustness with respect to much more advanced and sophisticated state-of-The-Art methods. Code with details on experiments are available at: https://github.com/bancaditalia/gen-Text-detect.",
        "affiliation_name": "Banca d'Italia",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Explainable Machine Learning Models for Swahili News Classification",
        "paper_author": "Murindanyi S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Although Swahili is considered a well-resourced language, challenges persist in utilizing it for Natural Language Processing (NLP) tasks, primarily due to the limited data availability required for these systems. For instance, obtaining sufficient Swahili news data for classification remains a significant obstacle. This paper addresses the problem of accurate Swahili news classification by leveraging classical machine learning (ML) models and deep neural networks (DNN). Our proposed method involves data acquisition, Exploratory Data Analysis (EDA), and employing modelling techniques using classical ML models, such as Support Vector Machine (SVM), Logistic Regression, Multinomial Naive Bayes, Random Forest, Gradient Boosting, Hard Voting, and Bagging, as well as DNN models including Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Bidirectional LSTM (Bi-LSTM), and CNN-Bi-LSTM + Attention. The models were evaluated using Area Under the Curve (AUC) metrics and accuracy. Our results demonstrate commendable performance for classical ML classifiers and DNN models, with accuracies above 75%. Notably, the CNN-Bi-LSTM + Attention model achieved an impressive AUC score of 97%. Additionally, explainability using LIME (Local Interpretable Model-agnostic Explanations) provided valuable insights into model decisions. This research contributes to Swahili natural language processing and lays the foundation for further explorations into transformer-based models for improved classification.",
        "affiliation_name": "Makerere University",
        "affiliation_city": "Kampala",
        "affiliation_country": "Uganda"
    },
    {
        "paper_title": "Empowering Precision in Financial News: A Revolution in Editorial Classification through Cutting-Edge Natural Language Processing",
        "paper_author": "Khunti S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Amidst the continuous stream of diverse data on the Bloomberg terminal, distinguishing editorial news articles from regular articles is critical to aid its users in tailoring their news experience and further analyzing the impact of news on global financial markets. In this paper, we propose various Artificial Intelligence and Neural Networks models regarding developing an editorial classifier that generalizes well across various news sources. The training set comprises articles published by news sources from the US. We compare the performance of these models using the Aggregate F1-measure and Binary Classification Performance Metric as evaluation metrics to account for the presence of class imbalance in our data. Further, we gauged our models by comparing their performance on a Zero-Shot dataset which comprised 1805 news articles published by Metro Winnipeg, a Canadian news source.",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Coral Reef Benthic Material Information Extraction Method Based on Improved U-Net",
        "paper_author": "Fu Y.",
        "publication": "Jisuanji Gongcheng/Computer Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The extraction of coral reef benthic material information is of great significance in coral reef remote sensing monitoring. Traditional information extraction methods for benthic organisms on coral reefs, such as Support Vector Machine(SVM) and the maximum likelihood method, have several drawbacks, including poor accuracy, low level of automation, and high time cost. At present, methods based on deep learning are being widely used in image segmentation, and satisfactory results have been obtained. Therefore, a segmentation network model based on improved U-Net and deep learning technology is designed to extract benthic material information from coral reefs. To improve segmentation details, a multi-input mode is set for each level of the encoder. The residual structure of ResNet34 is used as the encoder of the network to extract more abundant features. A new feature extraction block is designed by combining decomposition convolution, attention mechanism, and channel shuffle operation, to replace the common convolution layer in the encoder, bottom layer, and decoder; Concurrently, the attention mechanism is used to improve the far hop connection of the U-Net model, adjust the weight, and improve segmentation accuracy. Based on the GF-2 multispectral remote sensing image of Sanya, the extracted ground objects are classified as healthy coral reef, albino coral reef, algal mixture, sand, spray, deep sea area, and land. The dataset is established through visual interpretation and revision of an object-oriented method combined with Google Earth image. The experimental results show that mean Intersection over Union(mIoU)and average F1 score of the model in this study reached 67.17% and 78.7%, respectively. Compared with commonly used segmentation models, the proposed model performs better in visual effect and evaluation indicators. The ablation experimental results prove the effectiveness of the improved module.",
        "affiliation_name": "Aerospace Information Research Institute",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research on Manycore On-chip Storage Hierarchy for Exascale Supercomputer Systems",
        "paper_author": "Fang Y.",
        "publication": "Jisuanji Gongcheng/Computer Engineering",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Manycore has become the mainstream processor architecture for building HPC supercomputer systems, providing powerful computing power for High Performance Computing(HPC) exascale supercomputers. With the increasing number of cores integrated on manycore processor chips, the competition for large-scale cores for memory resources has become more intense. Manycore on-chip memory hierarchy is an important structure that alleviates the \"memory wall\" problem, aids HPC applications better play the computing advantages of manycore processors, and improves the performance of practical applications. The design has a significant impact on the performance, power consumption, and area of an on-chip system. The design of a many-call on-chip memory hierarchy has a significant impact on the performance, power consumption, and area of manycore systems. It is an important part of the structural design of manycore systems and is a research interest in the industry. Owing to the differences in the development history of manycore chips, the design technology of on-chip microarchitecture, and the different requirements of the application fields, the current HPC mainstream manycore on-chip storage hierarchy is different; however, from the perspective of horizontal comparison and the vertical development trend of each processor, as well as from the changes in application requirements brought by the continuous integration and development of HPC, data science, and machine learning, the hybrid structure of the SPM+Cache would most likely become the mainstream choice for the on-chip storage hierarchy designs of manycore processors in HPC exascale supercomputer systems in the future. For exascale computing software and algorithms, the designs and optimization based on the characteristics of the manycore memory hierarchy can aid HPC applications benefit from the computing advantages of manycore processors, thus effectively improving the performance of practical applications. Therefore, software, algorithm design, and optimization technology for the characteristics of the manycore on-chip storage hierarchy is also a research interest in the industry. This study first partitioned the on-chip memory hierarchy into multilevel Cache, SPM, and SPM+Cache hybrid structures according to different organizations, and then summarized and analyzed the advantages and disadvantages of these structures. This study analyzed the current status and development trend of the memory hierarchy designs of the chips of mainstream exascale supercomputer systems, such as the international mainstream GPU, homogeneous manycore, and domestic manycore. In summary, the research status of software and hardware technologies is related to the design and optimization of the memory hierarchy from the manycore of the manycore LLC management and cache consistency protocol, SPM management and data movement optimization, and the global perspective optimization of the SPM+cache hybrid architecture. Thus, this study looks forward to the future research direction of on-chip memory hierarchy based on different perspectives, such as hardware, software, and algorithm designs.",
        "affiliation_name": "National Research Center of Parallel Computer Engineering and Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An Efficient Model for Non-Distal Presentation Attack Detection",
        "paper_author": "Chandra T.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The increasing prominence of fingerprint recognition as a biometric identifier has made it more vulnerable to presentation attacks, specifically non-distal attacks that exploit ridge and minutiae patterns found in non-distal phalanges. In this study, we present presentation attacks through non-distal/toe prints and a state-of-the-art lightweight inverted residual network that excels at differentiating between distal and non-distal prints, providing unrivaled performance in terms of accuracy, inference time, and false negative rate (FNR). Our proposed model surpasses other statistical machine learning methods, such as variable-margin SVM, and lightweight models like MobileNet v2, MobileNet v3, and ResNet18. We meticulously evaluate our model using a diverse array of datasets, including the NIST dataset, an in-house collected dataset, a toe dataset, a synthetic dataset generated by VeriFinger software, and a six-class dataset. To assess performance when only minutiae points are available, we develop an algorithm that converts fingerprints to minutiae points and subsequently reconstructs fingerprints. Furthermore, we examine the ridge density of distal and non-distal prints across datasets, emphasizing their similarities and underscoring the need for advanced detection techniques. To the best of our knowledge, this study represents the first endeavor to propose a solution for presentation attack detection in non-distal phalanges. Our research demonstrate various challenges of presentation attacks, the effectiveness of our approach, which holds the potential to significantly influence the domain of fingerprint recognition and security. By sharing our dataset, model, and experimental details with the research community, we aim to foster further advancements in this crucial area. Upon publication, we will make our dataset and experimental details available alongside the paper.",
        "affiliation_name": "International Institute of Information Technology, Hyderabad",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "An Efficient Motor Imagery Classification Framework using Sparse Brain Connectivity and Class-consistent Dictionary Learning from Electroencephalogram Signals",
        "paper_author": "Pain S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Identifying patterns in high-dimensional and noisy neuro-imaging data such as Electroencephalogram (EEG) has always been challenging. This fact hampers the performance of the real-time Brain-Computer Interfaces (BCI) controlled by EEG recordings of brain signals, such as imagined motor activity (MI-EEG). Traditionally, the MI-EEG signals are classified by mainly two approaches, firstly, using the Common Spatial Patterns (CSPs) extracted from MI-EEG as features for Machine Learning (ML) classifiers, and secondly, using various Deep Learning (DL)-based approaches. But these methods are computationally heavy and ignore the dynamic topological interactions between the brain regions. Recently, due to high performance and low testing time, sparse representation-based classifiers have been utilized for MI-EEG classifications with higher real-life applicability. But these methods consider a fixed training dictionary consisting of inherently noisy training features. This study proposes an efficient MI-EEG classification framework utilizing a sparse representation of brain connectivity features and a dictionary learned from the training features. Here, the dynamic synchrony of co-activating brain regions is captured by suitable connectivity measures, which are further used as features. Further, sparse representations of the connectivity features are obtained through sparsity and dictionary learning. As this dictionary learning method preserves the class information during dictionary updation, this method is best suited for classification tasks. The dictionary learning method simultaneously learns a reduced dictionary and a linear classifier further used for classification. The proposed framework is validated using a publicly available MI dataset, and corresponding classification performances are observed. The proposed framework outperforms the other sparsity-based classifiers in mixed-, intra-, and cross-subject performances, making it suitable for real-life BCI applications.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Conference Proceedings - 2023 International Conference on Mathematics, Intelligent Computing and Machine Learning, MICML 2023",
        "paper_author": "NA",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The proceedings contain 16 papers. The topics discussed include: finite sample breakdown point of the minimum volume ellipsoid estimator in extended general position of sample; decryption speed up of RSA by pre-calculation; selecting hyperparameters of nonlinear support vector machine using Bayesian inference; safety assessment method for power operation environment based on multi-source data fusion; using ensemble models to detect deepfake images of human faces; cross-platform network public opinion topic modeling; implementation of an alarm system to protect a submersible pump of a company in Cusco, 2023; improved YoloV5 model target detection algorithm based on temporal neural networks; an illumination invariant convolution module for zero-shot object detection in the night; and an improved sparrow search algorithm for solving hybrid flow shop scheduling problems with lot streaming.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "An Improved Sparrow Search Algorithm for Solving Hybrid Flow Shop Scheduling Problems with Lot Streaming",
        "paper_author": "Zheng J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In addressing the lot streaming hybrid flow shop problem with equipment adjustment times, a scheduling model is devised with the multi-objective of minimizing completion time and energy consumption. To tackle this intricate problem, we propose an improved multi-objective Sparrow Search Algorithm (ISSA). The algorithm initiates the population through a three-stage variable-length real-number coding and Logistic-Tent chaotic mapping, enhancing the quality of initial solutions. Subsequently, a multifaceted enhancement is introduced during the Sparrow’s search phase to elevate population diversity. In the Sparrow’s explorer phase, an adaptive inertia weight is introduced. In the Sparrow’s follower phase, a subset of the population engages in both sine and cosine searches, while another subset adopts a spiral search strategy to follow the exploratory Sparrows. This paper applies six optimization algorithms and designs a set of test instances to compare the performance of each algorithm. Comparative experiments validate the ability of ISSA to escape local optima and converge quickly.",
        "affiliation_name": "Beijing Information Science &amp; Technology University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Student Behavior Detection in the classroom based on Human-Object Interaction model",
        "paper_author": "Rathod D.G.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Student behavior in the classroom is an important topic in educational analysis, and it is important to better understand and measure these behaviors. The smart classroom of the future will enhance the learning experience and support seamless communication between students and teachers through real-time learning and machine learning. The use of Object detection algorithm to recognize student behavior in the classroom can improve the speed of work, accuracy of analysis and application scale, and there are some studies that will promote the development of education with science and technology. At the same time, with the development of recognition algorithms, the use of neural networks in object detection has become a trend.",
        "affiliation_name": "Charotar University of Science &amp; Technology",
        "affiliation_city": "Changa",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023",
        "paper_author": "Paul S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The Software Engineering Information Retrieval (IRSE) track aims to devise solutions for the automated evaluation of code comments within a machine learning framework, with labels generated by both humans and large language models. Within this track, there is a binary classification task: discerning comments as either useful or not useful. The dataset includes 9,048 pairs of code comments and surrounding code snippets drawn from open-source C-based projects on GitHub and an additional dataset generated by teams employing large language models. In total, 17 teams representing various universities and software companies have contributed 56 experiments. These experiments were assessed through quantitative metrics, primarily the F1-Score, and qualitative evaluations based on the features developed, the supervised learning models employed, and their respective hyperparameters. It is worth noting that labels generated by large language models introduce bias into the prediction model but lead to less over-fitted results.",
        "affiliation_name": "Dhirubhai Ambani Institute of Information and Communication Technology",
        "affiliation_city": "Gandhinagar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Explainability of Text Processing and Retrieval Methods",
        "paper_author": "Anand A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "This tutorial presents explainability of text processing and retrieval methods, an emerging area focused on fostering responsible and trustworthy deployment of machine learning systems in the context of information retrieval. As the field has rapidly evolved in the past 4-5 years, numerous approaches have been proposed that focus on different access modes, stakeholders, and model development stages. This tutorial aims to introduce IR-centric notions, classification, and evaluation styles in explainable information retrieval (ExIR) while focusing on IR-specific tasks such as ranking, text classification, and learning-to-rank systems. We will delve into method families and their adaptations to IR, extensively covering post-hoc methods, axiomatic and probing approaches, and recent advances in interpretability-by-design approaches. We will also discuss ExIR applications for different stakeholders, such as researchers, practitioners, and end-users, in contexts like web search, patent and legal search, and high-stakes decision-making tasks. To facilitate practical understanding, we will provide a hands-on session on applying text processing and ExIR methods, reducing the entry barrier for students, researchers, and practitioners alike. Earlier version of this tutorial has been presented in SIGIR 2023.",
        "affiliation_name": "Indian Statistical Institute, Kolkata",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The Perception of the Syrian Asylum Seekers in Turkey: Sentiment Analysis with Twitter Data",
        "paper_author": "Parlak İ.",
        "publication": "Galactica Media: Journal of Media Studies",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "This study examines the perception of Syrian refugees who have migrated to Turkey within the Turkish public. For this purpose, the reasons for Syrian refugees’ migration to Turkey, their population in Turkey, their distribution in Turkey, their education status and enrollment rates, their working lives, their impact on the economy, the aid provided to them, their impact on public services and security in Turkey were investigated. Subsequently, sentiment analyses were conducted based on machine learning approaches on Twitter to measure the perception of the Turkish public regarding Syrian refugees. Perception was examined in three different dimensions: general perception, the nature of perception, and the reasons behind perception. In this context, tweets related to Syrian refugees posted throughout the year 2021 were collected, pre-processed, and transformed into a format suitable for data mining algorithms. Some of the tweets were manually classified according to the machine learning technique, and the remaining tweets were automatically classified by algorithms determined, taking into account the manually made classifications. As a result, it was determined that the general perception of the Turkish public regarding Syrian refugees on Twitter is largely negative and characterized by ‘discontent’. The main reasons behind this perception were found to be the perceived harm caused by Syrian refugees, their high numbers, and perceptions that they are better off than the locals, primarily due to their refugee and residency rights.",
        "affiliation_name": "Ondokuz Mayis Üniversitesi",
        "affiliation_city": "Samsun",
        "affiliation_country": "Türkiye"
    },
    {
        "paper_title": "Machine learning for fall prediction and monitor of older adults:a systematic review",
        "paper_author": "Luo Y.",
        "publication": "Chinese Journal of Nursing Education",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Objective To systematically review the fall prediction and monitor value of machine learning (ML) for older adults. Methods Databases including CNKI,SinoMed, VIP,Wanfang Data, Web of Science, PubMed, Embase and CINAHL were searched to retrieve all studies that focused on ML in predicting fall of older adults. The searching time was set from the date of database's establishment to July 2022. After that,two reviewers independently screened literature, extracted data and assessed the risk of bias of included studies by the standard of QUADAS-2. Results A total of 15 studies were included. In most studies, neural network and random forest models were mainly being used. In addition, though a few studies focused on specific populations, such as older women with osteoporosis and older patients in acute care,the majority of studies included older adults. Based on the quality evaluation, the included studies were highly applicable and had a low risk of bias. Conclusion ML has high predictive value and application value in fall identification and fall risk prediction for older adults. Meanwhile, there are still some problems. In the future, big data analysis should still base on clinical experience, as well as pay attention to specific populations, in order to develop a deeper combination and development of artificial intelligence and nursing.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Multimodal characterization of halide perovskites: From the macro to the atomic scale",
        "paper_author": "Doherty T.A.S.",
        "publication": "Halide Perovskite Semiconductors: Structures, Characterization, Properties, and Phenomena",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Halide perovskite semiconductors are enabling a wide variety of high-performing optoelectronic devices, including photovoltaics, light-emitting diodes, photodetectors and radiation detectors. However, these materials exhibit heterogeneity in their chemical, structural, morphological, and optoelectronic properties on a range of length scales that ultimately limits functionality. In order to push the technology toward commercialization, a global understanding of the relationship between these properties, and how they evolve under continuous operation to contribute to instabilities and performance losses, is required. This chapter will cover efforts to elucidate interproperty relationships through powerful multimodal and correlative microscopic techniques. A variety of ex-situ and in-situ measurements have led to the key conclusion that the length scales that are extremely important-yet least understood-are on the grain-to-grain, subgrain, and atomic scales. The disorder of these materials on such length scales and their soft ionic nature make characterization challenging, particularly at high resolution, but exploiting the latest experimental probes in laboratories and large-scale facilities, such as synchrotrons, will push the boundaries of our knowledge and allow rational approaches to improve performance and stability. Future work will employ machine learning and data science to process large-scale hyperspectral data sets and drive operando measurements on the manufacturing line. These approaches will be coupled with industry-standard testing, which will in turn refine high-throughput processing and device configurations. These approaches, which push the envelope on experimental capabilities, will be adaptable to many other disordered materials families.",
        "affiliation_name": "Department of Physics",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Parametric Information Geometry with the Package Geomstats",
        "paper_author": "Le Brigant A.",
        "publication": "ACM Transactions on Mathematical Software",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "We introduce the information geometry module of the Python package Geomstats. The module first implements Fisher-Rao Riemannian manifolds of widely used parametric families of probability distributions, such as normal, gamma, beta, Dirichlet distributions, and more. The module further gives the Fisher-Rao Riemannian geometry of any parametric family of distributions of interest, given a parameterized probability density function as input. The implemented Riemannian geometry tools allow users to compare, average, interpolate between distributions inside a given family. Importantly, such capabilities open the door to statistics and machine learning on probability distributions. We present the object-oriented implementation of the module along with illustrative examples and show how it can be used to perform learning on manifolds of parametric probability distributions.",
        "affiliation_name": "Université Paris-Saclay",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France"
    },
    {
        "paper_title": "KiT-RT: An Extendable Framework for Radiative Transfer and Therapy",
        "paper_author": "Kusch J.",
        "publication": "ACM Transactions on Mathematical Software",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In this article, we present Kinetic Transport Solver for Radiation Therapy (KiT-RT), an open source C++-based framework for solving kinetic equations in therapy applications available at https://github.com/CSMMLab/KiT-RT. This software framework aims to provide a collection of classical deterministic solvers for unstructured meshes that allow for easy extendability. Therefore, KiT-RT is a convenient base to test new numerical methods in various applications and compare them against conventional solvers. The implementation includes spherical harmonics, minimal entropy, neural minimal entropy, and discrete ordinates methods. Solution characteristics and efficiency are presented through several test cases ranging from radiation transport to electron radiation therapy. Due to the variety of included numerical methods and easy extendability, the presented open source code is attractive for both developers, who want a basis to build their numerical solvers, and users or application engineers, who want to gain experimental insights without directly interfering with the codebase.",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Weighted Two-Hidden-Layer Extreme Learning Machine Method with Improved Gray Wolf Optimization for Complex Data Classification",
        "paper_author": "Qin X.",
        "publication": "International Journal of Pattern Recognition and Artificial Intelligence",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Extreme Learning Machine (ELM) is widely popular for its advantages such as fast training speed and good generalization performance. However, the randomness of hidden layer parameters in ELM leads to unstable prediction performance of the model. We propose a novel two-hidden-layer extreme learning machine (TELM) for complex data classification. Firstly, the idea of weighting is introduced into TELM, and a weighted two-hidden-layer extreme learning machine (WTELM) model is proposed to improve the classification accuracy of the model. Secondly, the convergence factor and position update formula in gray wolf optimization algorithm (GWO) are adjusted to enhance the optimization algorithm's ability to search for optimal parameters. Finally, an improved gray wolf optimization (IGWO) is utilized to search for the optimal parameters of the WTELM model. The impact of different intelligent optimization algorithms on the model's classification results is compared. The experimental results demonstrate that the classification accuracy of the WTELM model has been improved by about 11-18% compared to traditional ELM models. Moreover, compared to the WTELM model, the classification accuracy of the IGWO-WTELM model has improved by about 1-19%. This indicates that the method proposed in this paper is significantly superior to traditional ELM methods and their variants, improving the stability, training speed and classification accuracy of the model.",
        "affiliation_name": "Changchun University of Technology",
        "affiliation_city": "Changchun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Carpet Back Sizing Quality Assessment by Measuring the Amount of Resin Using Image Processing and Machine Learning Approaches",
        "paper_author": "Momeni Heravi M.E.",
        "publication": "Tekstilec",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The mechanical properties of the carpet, such as dimensional stability, bending stiffness, handle and creep-ing on the surface during use, have a direct relationship with the amount of resin applied to the back of the carpet in the sizing process. In today’s factories, the optimal amount of resin and the mechanical quality of the carpet are controlled by the operator touching the carpet on the machine carpet finishing line or man-ually while rolling the carpet. Proposed in this paper is an automatic method based on the evaluation of the bending stiffness of the sized carpet that uses digital image processing and machine learning to measure the optimal amount of size concentration and control this index. For this purpose, during the final stage of carpet production, the carpet is folded in the middle, and two edges of the carpet are placed on top of each other. A side view image is then taken of the carpet. Using edge detection methods, the edges of the carpet are identified, and different features, such as the average, maximum and minimum statistics for the curve and contour angles, are then extracted. Different conventional machine learning approaches, such as KNN, CART and SVM, are applied. To evaluate the proposed method, a dataset containing 220 different images is used in a 10-fold cross-validation scheme. Different performance measures resulting from the evaluations demon-strate the effectiveness and applicability of the method.",
        "affiliation_name": "Islamic Azad University, Mashhad Branch",
        "affiliation_city": "Mashhad",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Application and prospect of machine learning in orthopaedic trauma",
        "paper_author": "Tian C.",
        "publication": "Zhongguo xiu fu chong jian wai ke za zhi = Zhongguo xiufu chongjian waike zazhi = Chinese journal of reparative and reconstructive surgery",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "目的: 综述机器学习在创伤骨科领域的应用进展并展望其在临床中的应用前景。. 方法: 广泛查阅国内外相关文献，阐述机器学习算法研究现状，总结其在创伤骨科领域的研究进展。. 结果: 随着计算机数据处理能力的飞速发展、医工交叉的逐步深入，人工智能在医学领域应用渐广。目前，机器学习在创伤骨科领域得到了广泛应用，在骨折影像识别与诊断分层、创伤骨科临床决策及评估、围术期与预后风险预测等方面，有着较强的性能和准确性。然而，机器学习的发展及临床应用仍存在着数据库样本不足、模型解释性差以及普适性和个体化差异的问题。. 结论: 随着临床样本量的增加以及算法性能的提升，机器学习在创伤骨科辅助诊断、指导决策、制定个性化医疗方案以及合理配置临床资源方面具有广阔应用前景。.",
        "affiliation_name": "Zhongda Hospital Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Embedded Mechanical Engineering Controller Design Using LSTM Technology",
        "paper_author": "Shi L.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Embedded controllers are very competitive in the market and can be seen worldwide in a wide range of applications from office automation equipment, consumer electronics, telecommunication, smart instrumentation to automotive electronics, financial electronics, industrial control and other different fields. The embedded construction machinery controller designed in this paper is mainly used in automotive electronics and construction machinery, and the design process mainly defines the functions of the controller according to the structural system of construction machinery and the functional module requirements of the control. In this paper, a fault time series prediction method based on long short-term memory (LSTM) recurrent neural network is proposed from the data, including network structure design, network training and prediction process implementation algorithm, etc. Further, with the goal of minimizing the prediction error, a multi-layer grid search-based LSTM prediction model parameter preference algorithm is proposed, and through experiments with a variety of typical time series prediction models The proposed LSTM prediction model and its parameter selection algorithm are verified to be highly applicable and accurate in the implementation of the embedded controller.",
        "affiliation_name": "Shanghai Key Laboratory of Ship Engineering",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Educational Missions and Tactics in the EU Artificial Intelligence Strategy in the Era of Digital Transformation: A Policy Analysis Based on EU Documents Published During 2018-2022",
        "paper_author": "Xiong Y.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In the era of digital transformation, AI, cloud computing, big data, blockchain, and other intelligent technologies have increasingly profound impacts on work, study, life, and especially education. The Publishing of The Age of Artificial Intelligence: Towards a European Strategy for Human-Centric Machines marked the official launch of the EU Artificial Intelligence Strategy. By analyzing policy documents published during 2018 and 2022 for the EU Artificial Intelligence Strategy, it is found that the strategy has set three strategic goals, namely achieving an 'Ecosystem of Excellence', building an 'Ecosystem of Trust', and establishing an 'Ecosystem of Digital Education'. To ensure its implementation, the European Commission has published a series of policy documents successively. As the main driver of the AI strategy, education plays an important role in the development of AI, and the EU has adopted various education tactics in the series of documents. Given the particularity of the EU as a regional cooperation organization, this strategy values philosophy, norms, and cooperation. It also provides a good reference for AI development and digital transformation of society in other countries and brings new opportunities for international cooperation in the field of AI.",
        "affiliation_name": "Wenzhou University",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of Deep Belief Network for Sustainable Development via Deep Learning to Export Credit Risk Assessment Under the Belt and Road Strategy",
        "paper_author": "Li Z.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The purpose of the study is to reduce the export credit risk of enterprises, and the export credit risk assessment of enterprises under the belt and road strategy based on deep learning is discussed. First, the research background and deep belief networks are introduced. Second, the contrast divergence algorithm based on the deep belief model is improved on the restricted Boltzmann machine. Finally, the deep belief network of classification and partition is constructed and simulated. The results show that the test accuracy of the classification and partition of the restricted Boltzmann machine (CPRBM) constructed is higher than that of the restricted Boltzmann machine (RBM). When the accuracy of the algorithm is verified under the condition of unbalanced two classification samples in a relatively small amount of datasets, the accuracy of the CPRBM algorithm is 93.71%, and the accuracy of the RBM algorithm is 89.86%. In the optimization stage of the deep belief networks, the convergence rate of the CPRBM is slower than that of the RBM. Since the optimized system increases the penalty term in the first training stage of the deep belief networks, the penalty term is canceled in the second stage of optimization. At three time points, the algorithm accuracy of the CPRBM is higher than that of the RBM. The simulation results are consistent with the previous experimental results. Although the accuracy is not high at the third time point, the CPRBM algorithm still has some advantages. Compared with the accuracy of the support vector machine (SVM) and the deep extreme learning machine (DELM), the CPRBM algorithm based on deep belief networks has the highest accuracy at any time point. The CPRBM algorithm constructed has obvious advantages compared with common models, and the overall performance of the algorithm is better. The conclusions provide the support for the sustainable development of the economy under the Belt and Road strategy.",
        "affiliation_name": "Shanghai Lida University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Classification of Gestational Diabetes Using Machine Learning Techniques",
        "paper_author": "Comlan M.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In this work, we characterized the association of diabetes with pregnancy and developed a classification system for gestational diabetes based on machine learning models. Using statistical data, we can predict whether or not a patient has gestational diabetes based on certain attributes: age, number of pregnancies, insulin levels, etc. This allows the patient to seek medical attention quickly to reduce the risk of complications from this disease on her health. To achieve this goal, we proposed a method of data classification using supervised learning techniques: KNN, decision tree, and Random Forest. First, we will use Machine Learning tools (Google Colab) to create and train our algorithm, then evaluate its effectiveness and accuracy. In the second phase, we will use our model to predict cases of diabetes.",
        "affiliation_name": "University of Abomey-Calavi",
        "affiliation_city": "Cotonou",
        "affiliation_country": "Benin"
    },
    {
        "paper_title": "Identification of Single Nucleotide Genetic Polymorphism Sites Using Machine Learning Methods",
        "paper_author": "Yatskou M.M.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The paper presents an algorithm for simulation modelling of nucleotide variations in the genomic DNA molecule. To identify single nucleotide genetic polymorphisms, it is proposed to use machine learning methods trained on simulated data. A comparative analysis of the most effective classical and machine learning algorithms for identifying single nucleotide polymorphisms was performed on simulated data. The most optimal method for identifying single nucleotide genetic polymorphisms in DNA molecules at various experimental noise levels is the machine learning algorithm CART.",
        "affiliation_name": "Belarusian State University",
        "affiliation_city": "Minsk",
        "affiliation_country": "Belarus"
    },
    {
        "paper_title": "Experimental Results Regarding Multiple Machine Learning via Quaternions",
        "paper_author": "Zhu T.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "This paper presents an experimental study on the application of quaternions in several machine learning algorithms. Quaternion is a mathematical representation of rotation in three-dimensional space, which can be used to represent complex data transformations. In this study, we explore the use of quaternions to represent and classify rotation data, using randomly generated quaternion data and corresponding labels, converting quaternions to rotation matrices, and using them as input features. Based on quaternions and multiple machine learning algorithms, it has shown higher accuracy and significantly improved performance in prediction tasks. Overall, this study provides an empirical basis for exploiting quaternions for machine learning tasks.",
        "affiliation_name": "Wenzhou-Kean University",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Novel Hybrid Model for Forecasting China Carbon Price Using CEEMDAN and Extreme Learning Machine Optimized by Whale Algorithm",
        "paper_author": "Ni L.",
        "publication": "Advances in Transdisciplinary Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The carbon market can provide economic incentives for manufacturing industry to reduce carbon emissions. This paper follows the idea of 'primary decomposition- noise reduction-secondary decomposition- forecasting and integration', the contribution is constructing a hybrid carbon price forecasting model using Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) and Extreme Learning Machine (ELM) optimized by the Whale Optimization Algorithm (WOA). The results conclude that, the CEEMDAN-type secondary decomposition hybrid models have high forecasting accuracy, the WOAELM-type models can effectively reduce the forecasting errors. Noteworthy, the forecasting errors RMSE, MAE and MAPE of the proposed CEEMDAN-SE-CEEMD-WOAELM model are 2.587, 2.04 and 0.108 respectively, that is the lowest in all the comparative models. The forecasting accuracy and reliability of the proposed model have been convinced. Those findings can provide valuable reference for manufacturing industry to reduce pollutant emissions and take low-carbon investment.",
        "affiliation_name": "Universiti Malaysia Sarawak",
        "affiliation_city": "Kota Samarahan",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Machine learning estimation of the resident population",
        "paper_author": "Calian V.",
        "publication": "Statistical Journal of the IAOS",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "In this paper, we formulate the problem of estimating the resident population, i.e. correcting for over-counts in administrative register data, as a binary classification problem. We propose a solution based on machine learning algorithms. The selection and the optimisation of the best algorithm is shown to depend on the goal of prediction. We illustrate this method for two important cases of official statistics, Census resident population and survey design with minimum non-response. The performance of the algorithms, the uncertainty of estimates and of the evaluation metrics are described in detail and implemented in shared, open source code. We exemplify with the results obtained by applying this method to Icelandic register and survey data.",
        "affiliation_name": "Statistics Iceland",
        "affiliation_city": "Reykjavik",
        "affiliation_country": "Iceland"
    },
    {
        "paper_title": "Classifying respondent comments from the 2021 Canadian Census of Population using machine learning methods",
        "paper_author": "Yoon J.",
        "publication": "Statistical Journal of the IAOS",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "To improve the analysis of respondent comments from the Canadian Census of Population, data scientists at Statistics Canada compared and evaluated traditional machine learning, deep learning and transformer-based techniques. Cross-lingual Language Model-Robustly Optimized Bidirectional Encoder Representations from Transformers (XLM-R), a cross-lingual language model, fine-tuned on census respondent comments yield the best result of 89.91% F1 score overall despite language and class imbalances. Following the evaluation, the fine-tuned model was implemented successfully to objectively categorize comments from the 2021 Census of Population, with high accuracy. As a result, feedback from respondents was directed to the appropriate subject matter analysts, for them to analyze post-collection.",
        "affiliation_name": "Statistics Canada",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine learning and data augmentation in the proxy means test for poverty targeting",
        "paper_author": "Wobcke W.",
        "publication": "Statistical Journal of the IAOS",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Recent years have seen increased interest in the use of alternative data sources in the definition and production of official statistics and indicators for the UN Sustainable Development Goals. In this paper, we consider the application of data science to the production of official statistics, illustrating our perspective through the use of poverty targeting as an application. We show that machine learning can play a central role in the generation of official statistics, combining a variety of types of data (survey, administrative and alternative). We focus on the problem of poverty targeting using the Proxy Means Test in Indonesia, comparing a number of existing statistical and machine learning methods, then introducing new approaches in the spirit of small area estimation that utilize area-level features and data augmentation at the subdistrict level to develop more refined models at the district level, evaluating the methods on three districts in Indonesia on the problem of estimating 2020 per capita household expenditure using data from 2016-2019. The best performing method, XGBoost, is able to reduce inclusion/exclusion errors on the problem of identifying the poorest 40% of the population in comparison to the commonly used Ridge Regression method by between 4.5% and 13.9% in the districts studied.",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Using And Optimizing The Recycled Aggregates In Concrete: A Review",
        "paper_author": "Mohammed Y.H.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Reusing aggregate from building and demolition waste can help protect the ordinary natural aggregate supply, reduce landfill demand, and drive toward a more sustainable environment. This paper examines the recycled history of recycled aggregate and recycled aggregate. A general review of how recycled aggregates were used by previous researchers in recent years and their findings are reviewed in this review paper. In addition, methods for enhancing the mechanical characteristics of recycled aggregate and long-term efficiency such as improving the properties without modifying the recycled aggregate (namely, different concrete mixing designs and the addition of reinforcing fibers) were reviewed. The machine learning model for predicting compressive strength in addition to compressive stress modulus and graphs for recycled aggregate concrete are reviewed, as well as their limitations are discussed. It discusses the research perspectives of recycled aggregate, namely the development of “green” processing methods for recycled aggregate and additional guidance on building a database to predict the strength of recycled aggregate.",
        "affiliation_name": "Northern Technical University",
        "affiliation_city": "Mosul",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Comparative Analysis of LDA, LSA and NMF Topic Modelling for Web Data",
        "paper_author": "Shastry P.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Whenever the user enters any website, the URL, timestamp, client IP-address and other information are stored in the web log file. This information can be further analysed, and useful information can be extracted. Processing the entire web log document files is a difficult process which hinders the performance. For example, if there are 2000 documents and each of these documents have 500 words in them then to process the entire set of documents requires 500*2000 = 1000000 threads. So, to avoid this if we divide the document into documents having topics for example, number of topics=3, then processing it requires just 3*500 words = 1500 threads. Hence, this work proposes a comparative analysis which employs Topic Modelling Methods like LDA, LSA, NMF to extract the hidden features from the web log data.",
        "affiliation_name": "PES University",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Development of Standalone Iris Recognition System Using Deep Neural Networks",
        "paper_author": "Mohammad M.B.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Biometrics is predominantly used for identification and access control. The central concept of biometric authentication is that each individual can be reliably authenticated based on the inherent cognitive and physiological characteristics. Iris recognition can be used over long distances, with some methods requiring only a single glance from the user. To recognize the iris, five steps are required: image capture, localization, segmentation, normalization, and finally feature extraction. Image size, image quality, image background, color of eyes, and light reflections all have a significant impact on feature extraction and classification while capturing images. To compensate for the effects of noisy, low-lit, and low-contrast iris images in Iris classification, Image pre-processing is employed which is inherently slow, non-adaptive, and problem-specific. Machine learning and deep learning techniques provide a solution to the problem by increasing operation speed as well as handling noisy data. Deep learning processes are typically used for classification and recognition tasks. Resnet-50, Shuffle Net, Efficient Net-B0, Mobile Net-V2, Inception Net V3, and GoogleNet were trained using two widely used datasets, namely IIT Delhi Iris Dataset and the Multi Media University (MMU) Iris Dataset. Different pre-trained models were tested using a transfer learning approach, and it was discovered that the Resnet-50 architecture provides a superior accuracy of 99.33 percent for the IITD Iris dataset and 96.27 percent for the MMU Iris dataset, respectively. The best model has been deployed on standard Raspberry PI hardware, allowing the system to function as a standalone model.",
        "affiliation_name": "Andhra Loyola Institute of Engineering and Technology",
        "affiliation_city": "Vijayawada",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Empirical Analysis of Machine Learning Models for Detecting Credit Card Fraud",
        "paper_author": "Jagadishwari V.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Credit cards, which are still a common mode of payment, are accepted both online and offline and enable cashless transactions. It’s a quick, convenient, and widely used method of making payments and other transactions. As a result of these advancements, credit card fraud is on the rise. Billions of dollars have been lost as a result of these deceptions. These acts are carried out so gracefully that they appear to be real transactions. As a result, straightforward design approaches and other less complex techniques will be viewed as useless. All banks must now have a well-organized fraud detection strategy in order to avoid confusion and restore order. In this work, we used machine learning algorithms to detect fake transactions. Approaches have been found to decrease the number of false alerts while also boosting the number of frauds uncovered. To detect and prevent fraud, slightly altered versions of these algorithms can be deployed to bank credit card scam detection methods. Four machine learning models have been built and tested, Gradient Boost and Random forest algorithms have been found to perform better.",
        "affiliation_name": "Dayananda Sagar College of Engineering",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Overload Prediction in Transmission System Using Machine Learning Algorithm",
        "paper_author": "Femila Josephin J.D.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Security is one of the key issues that power system operators have. Transmission networks are frequently pushed near to or even over their limits in order to handle increased electric power consumption and trades as a result of an increase in unforeseen power exchanges. Some lines put on specific pathways may become overloaded if exchanges are not regulated. Congestion is the term used to describe this phenomena. The system's congestion cannot be allowed to last much longer since it could lead to a substantial rise in electricity rates and jeopardise the efficiency and security of the system. Congestion is managed in an effort to prevent it. In this planned project, facts devices will be installed. The results were acquired using a prototype 6-bus system in the Power World simulator. The results were acquired utilising a model 6-bus system. The Power World results are then sent to MATLAB, which runs a machine learning algorithm.",
        "affiliation_name": "Thiagarajar College of Engineering",
        "affiliation_city": "Madurai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Review on Digital Soil Mapping Models from a Statistical Perspective",
        "paper_author": "Asare S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In order to estimate soil quality, yield of underlying crops, structural strength & stability of buildings & other structures, identify strategies to enhance quality, etc., digital soil mapping (DSM) is a procedure that transforms soil-related data into maps. Researchers have presented a broad range of models to carry out this activity, and each of these models differs in terms of its deployment-specific future research objectives, application-specific subtleties, functional benefits, and context-specific restrictions. Researchers find it challenging to pinpoint the best mapping models for their context-aware use cases as a result of these variances. This raises system cost and time to market for DSM applications by requiring researchers to evaluate several models before using them in deployments. The difficulty of choosing the right model for a given use case is further increased by the fact that various models differ in terms of both qualitative and quantitative metrics, such as mapping accuracy, latency required for mapping, computational complexity, precision of mapping, cost of mapping, etc. This paper analyses numerous newly suggested DSM strategies and compares them in terms of various application-specific & deployment-specific aspects to address these concerns and aid readers in identifying the best performing models. Based on the debate, it was concluded that MLMs, such as Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNNs), Q-Learning, and Reinforcement Learning, outperform other models, making them very beneficial for real-time DSM applications. Additionally, this article analyses several models according to performance metrics, which helps identify the DSM Models that perform the best and suggests techniques that may be used to further improve their performance. This paper suggests a unique DSM Rank Metric (DRM), which combines many assessment factors to identify models capable of establishing an equilibrium between various performance indicators, to aid in the selection of models. Researchers will be able to find DSM Models that are well optimized in terms of main performance metrics and can function effectively under various application situations by referring to DRM values & scenarios.",
        "affiliation_name": "GITAM University",
        "affiliation_city": "Visakhapatnam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Experimental Analysis of Different Machine Learning Models for Sentiment Analysis",
        "paper_author": "Talukdar M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "As a human being it is obvious for us to get influenced by other people opinions in our day to day life. People today are free to give their views related to any particular topics as the explosion of the World Wide Web is being increasing in every moment. Thus, in this process lots of information is produced which really need to be processed so that sentiments from those information can be extracted to help others in different fields like business, product analysis etc. Sentiment analysis is the mechanism through which we can perform this task. Here, we have taken accuracy as evaluation matrix to perform document level sentiment analysis on movie review datasets using Naïve Bayes, SVM, Logistic Regression- machine learning algorithms and deep learning methods like CNN and RNN. We found that among those RNN provides batter accuracy than all other mechanisms.",
        "affiliation_name": "Gauhati University",
        "affiliation_city": "Guwahati",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Hybrid Proactive Approach to Prediction of Credit Card Fraudulent Activities Detection",
        "paper_author": "Prabha N.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Financial crime's negative prediction is important research and it is needed for financial institutions. Previous research using single and hybrid algorithms has been used to detect credit card fraud. Because no further research into different hybrid algorithms for a given dataset was done, these approaches have significant limits. This study creates and tests hybrid machine learning models for detecting fraudulent behaviour using a real-world dataset. The different states of the survey described different machine learning related algorithms that are used to detect fraud and also hybrid algorithm mechanisms are also used to produce better performance in terms of accuracy and related activities. The prediction is made based on the proactive and reactive types. Most of the previous types of work are performed based on the reactive type. This work proposed a proactive type prediction using different dynamic activities such as types of traction, time, location, customer amount, transaction ranges, etc. In this work, a proactive approach to prediction of fraudulent activity detection using ensemble learning and deep learning techniques is proposed. The eXtreme Gradient boosting ensemble method is used for proactive feature selection and CNN deep learning methods are used for analysis of fraud activities. For implementation, a real-time dataset from a commercial bank with 284, 807 features is used. The accuracy, sensitivity, and specificity metrics are used to measure the performance of proposed work.",
        "affiliation_name": "Thiruvalluvar University",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Tumor Image Segmentation using Artificial Neural Networks",
        "paper_author": "Gangadhara Reddy P.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Magnetic Resonance Imaging (MRI) brain segmentation scans were beneficial for diagnosing, treatment and evaluation of affected tumors or specific diseases. Until now, medical professionals accomplished manual segmentation, which is widely utilized in hospitals and diagnostic centers. Manual Segmentation is an authentic conventional method, which is accurate and consumes more time, expensive, finally might be not reliable. Several routine and semi-routine practices for segmentation of magneto resonance images are available in the previous works, nonetheless the obtained accurate values are not comparable with various manual segmentation methods. The proposed method in this work employs a Supervised Artificial Neural Network (ANN) algorithm. The specifications considered in this paper are PSNR, Mean square and Normalized absolute errors, Maximum and Average differences, Normalized Cross-Correlation and structural content. The proposed ANN method attained competitive results with several segmentation methods trained with Artificial Neural Network.",
        "affiliation_name": "Sri Venkateswara University College Of Engineering",
        "affiliation_city": "Tirupati",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Performance Enhancement of Human Activity Recognition and Fall Related System using Multi-modal Broad Learning System (mBLS)",
        "paper_author": "Shahiduzzaman K.M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Elder citizens face sudden fall which can cause injuries of both fatal and non-fatal type. These sudden falls are sometime more dangerous than diseases heart attract, blood sugar, blood pressure because these can be untreated for a long period of time which can lead to death. An elder citizen who faces an sudden fall, make his or her social life limited. This is why a smart and effective anti-fallen system needed to be developed to support elderly health care, especially to those who lives independently, which can detect and predict a sudden fall through proper human activity recognition. In this paper, we have introduced an end-edge-cloud based wearable smarachFALL (smart activity recognition architecture for fall detection and prediction) architecture for elderly care. We have designed simulation setups to answer the question of why we need such system and the effectiveness. These experimental results also shows the advantage of using tightly couple multiple information for recognizing human activity. We are able to achieve a low false alarm rate (FAR) with an improved accuracy. These work serves as the starting point for future related research activities.",
        "affiliation_name": "Khulna University of Engineering and Technology",
        "affiliation_city": "Khulna",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Comparing the Performance of Machine Learning Algorithms for the Prediction of Breast Cancer Recurrence",
        "paper_author": "Nathiya S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "The most widespread cancer in females around the world, breast cancer is accountable for more than 25% of all cases in females (approximately 23 percent). Considering breast cancer is the deadliest disease and death increases with late-stage diagnosis, early identification is highly recommended to lower mortality. The medical industry's innovation and technological development have played a prominent part, and the majority of women with breast cancer have made a full recovery for the first time. The current challenge is sensing a recurrence of breast cancer at a preliminary phase after recovering from the first occurrence. In medical diagnosis, there are several approaches available for breast cancer recurrence prediction, with mammography being the most common and widely used method. However, these methods have some shortcomings, such as the fact that they necessitate additional diagnosis, which takes time, and they are not always accurate. Additional strategies for predicting breast cancer recurrence are required to improve life expectancies. Today's world, Data Mining plays an important role in medical diagnostics, producing astounding results that help a patient survive. Using two dissimilar machine learning techniques from data mining, the Support Vector Machine algorithm and other one is the Artificial Neural Network algorithm, this learning method uses the Breast Cancer Wisconsin (Prognostic) Dataset to forecast breast cancer recurrence in the initial stages. Using metrics like Accuracy, Precision, and Recall, the algorithms' ability in foretelling breast cancer recurrence is contrasted. At the data-preparation phase, the dataset's missing attribute values are filled in using the K-Nearest Neighbor method.",
        "affiliation_name": "Dr.SNS Rajalakshmi College of Arts and Science",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Data-Driven Prognosis of Long COVID in Patients Using Machine Learning",
        "paper_author": "Parvathy S.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Long-COVID is a health condition in which individuals experience persisting, returning or new symptoms longer than 4 weeks after they have recovered from COVID-19 and this condition can even last for months. It can cause multi-organ failure and in some cases, it can even lead to death. The effects and symptoms of Long COVID can vary from person to person. Even though it's rising globally, there is a limited understanding about its prediction, risk factors and whether its prognosis can be predicted in the initial first week of acute COVID-19. Artificial Intelligence (AI) and Machine Learning (ML) have aided the medical industry in a variety of ways including the diagnosis, prediction, and prognosis of many diseases. This paper introduces a novel method to determine Long COVID in the early or first week of acute COVID-19 by considering the basic demographics, and symptoms during COVID-19, along with the clinical lab results of the patients hospitalized. In comparison with different ML models such as Logistic Regression, Support Vector Machine (SVM), XGBoost and Artificial Neural Network (ANN) to predict and classify the patients as Long COVID or Short COVID during the first week of COVID-19, ANN has outperformed the other models with an accuracy of 81% when considering the symptoms of COVID-19 and a 79% for the clinical test data. The predictive factors and the significant clinical tests for the Long COVID are also determined by using different methods like Chi-square Test and Pearson Correlation.",
        "affiliation_name": "Amrita University, Amritapuri Campus",
        "affiliation_city": "Kollam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "An approach for Prediction of Weather by Using Feed-Forward Neural Networks",
        "paper_author": "Gupta V.M.N.S.S.V.K.R.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Predicting the weather is tough, and rainfall forecasting is even more difficult. Rainfall prediction is crucial in the agriculture industry. It is important to estimate rainfall accurately in order to avoid heavy rain and to provide information about natural disaster alerts. Machine learning models have been seen to perform well in the prediction of weather, so those models are used to provide precise and accurate forecast results. In this article, the feed-forward neural networks are used to predict rainfall. The suggested article achieves 92 percent accuracy when applied to UGC dataset.",
        "affiliation_name": "S.R.K.R.Engineering College",
        "affiliation_city": "Bhimavaram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A random forest approach to quality-checking automatic snow-depth sensor measurements",
        "paper_author": "Blandini G.",
        "publication": "Cryosphere",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "State-of-the-art snow sensing technologies currently provide an unprecedented amount of data from both remote sensing and ground sensors, but their assimilation into dynamic models is bounded to data quality, which is often low – especially in mountain, high-elevation, and unattended regions where snow is the predominant land-cover feature. To maximize the value of snow-depth measurements, we developed a random forest classifier to automatize the quality assurance and quality control (QA/QC) procedure of near-surface snow-depth measurements collected through ultrasonic sensors, with particular reference to the differentiation of snow cover from grass or bare-ground data and to the detection of random errors (e.g., spikes). The model was trained and validated using a split-sample approach of an already manually classified dataset of 18 years of data from 43 sensors in Aosta Valley (northwestern Italian Alps) and then further validated using 3 years of data from 27 stations across the rest of Italy (with no further training or tuning). The F1 score was used as scoring metric, it being the most suited to describe the performances of a model in the case of a multiclass imbalanced classification problem. The model proved to be both robust and reliable in the classification of snow cover vs. grass/bare ground in Aosta Valley (F1 values above 90 %) yet less reliable in rare random-error detection, mostly due to the dataset imbalance (samples distribution: 46.46 % snow, 49.21 % grass/bare ground, 4.34 % error). No clear correlation with snow-season climatology was found in the training dataset, which further suggests the robustness of our approach. The application across the rest of Italy yielded F1 scores on the order of 90 % for snow and grass/bare ground, thus confirming results from the testing region and corroborating model robustness and reliability, with again a less skillful classification of random errors (values below 5 %). This machine learning algorithm of data quality assessment will provide more reliable snow data, enhancing their use in snow models.",
        "affiliation_name": "Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi",
        "affiliation_city": "Genoa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Hydrogen atom scattering at the Al<inf>2</inf>O<inf>3</inf>(0001) surface: a combined experimental and theoretical study",
        "paper_author": "Liebetrau M.",
        "publication": "Physical Chemistry Chemical Physics",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Investigating atom-surface interactions is the key to an in-depth understanding of chemical processes at interfaces, which are of central importance in many fields - from heterogeneous catalysis to corrosion. In this work, we present a joint experimental and theoretical effort to gain insights into the atomistic details of hydrogen atom scattering at the α-Al2O3(0001) surface. Surprisingly, this system has been hardly studied to date, although hydrogen atoms as well as α-Al2O3 are omnipresent in catalysis as reactive species and support oxide, respectively. We address this system by performing hydrogen atom beam scattering experiments and molecular dynamics (MD) simulations based on a high-dimensional machine learning potential trained to density functional theory data. Using this combination of methods we are able to probe the properties of the multidimensional potential energy surface governing the scattering process. Specifically, we compare the angular distribution and the kinetic energy loss of the scattered atoms obtained in experiment with a large number of MD trajectories, which, moreover, allow to identify the underlying impact sites at the surface.",
        "affiliation_name": "Georg-August-Universität Göttingen",
        "affiliation_city": "Gottingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Inverse Estimation of Volumetric Heat Generation Rate from a Protruding Heat Source Under Natural Convection",
        "paper_author": "Rakes S.G.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "This paper presents the results of the heat source strength in a vertical plate driven by natural convection using a machine learning-based inverse technique. The geometry used in the present study takes after the cooling of electronic systems, where the vertical plate and heat source symbolizes the printed circuit board (PCB) and an electronic chip, respectively. The inverse problem in the present study is solved using measured (proxy) temperatures at the PCB wall substrate and the data-centric machine learning method. The database required for building the inverse model is obtained by running the commercial CFD code for buoyancy-driven heat source geometry placed on a vertical plate. A non-iterative inverse model is trained with an input-output (temperature mapped on the aft side of PCB - heat source strength) dataset using three layers neural network. Robustness of the network is reported. The measured temperatures with noise are seeded into the model, and the heat source intensity is estimated. The effect of the Raleigh number is elucidated. The inverse model is validated by drawing the scatter plot between measured and simulated (obtained from retrieved heat source values) temperature, that is, within ± 5%.",
        "affiliation_name": "Amrita Vishwa Vidyapeetham University, Bangalore",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Life Cycle Assessment (LCA) Score Prediction of Laminated Foil Packaging by the implementation of Deep Learning",
        "paper_author": "Fatriansyah J.F.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The increasing need for multilayer packaging is the biggest contributor to the problem of plastic waste in the food and beverage sector. One of the types of multilayer packaging that is most often used as packaging is laminated foil. The low value of laminated foil in the recycling industry due to its high complexity makes a thorough evaluation of the use of laminated foil with the Life Cycle Assessment method necessary. The use of machine learning can be a user-friendly solution for calculating LCA scores. This series of research consists of a literature study, product data collection, dataset creation, and LCA standard formulation, and ends with algorithm development from a deep learning-based machine learning program. The literature study process produces important information which is then used for the process of collecting packaging data at retail places as well as making datasets involving Microsoft Excel and OpenLCA software. The building of machine learning programs then be done and becomes an important discussion in this research. To produce an optimal program, there are various parameters are tested. These parameters are test size, random state, number of layers and dense, learning rate, batch size, and epochs. This study resulted in a program with an accuracy of 97.09% which can be used to predict the LCA score of Laminated Foil packaging.",
        "affiliation_name": "Universitas Indonesia",
        "affiliation_city": "Depok",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Detection and Categorization of Patients Having Alzheimer’s Disease: Machine Learning Algorithms",
        "paper_author": "Deshpande D.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Alzheimer's illness is a condition that gradually impairs memory and other important brain functions. The reason for this is because the connections between brain cells and the cells themselves deteriorate and die, producing memory loss. There is no cure in the world for this disease, but medication and some other strategies, activities, games, etc. may help in improving the symptoms. This research Alzem-cure will help in detecting, predicting, and analyzing the AD. Logistic Regression is implemented in order to achieve the aforementioned tasks. A front-end where patients can submit their attributes’ regarding Alzheimer’s is made which will result in predicting whether the patient is demented or non-demented. Furthermore, in the front-end various activities, games and tasks are mentioned which significantly results in improving the symptoms of the patient and keep them calm and positive all day long.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine Learning Model to Predict Microbe Growth in Neutropenic Patients with Hematological Malignancy",
        "paper_author": "Irfana N.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Risk of internal infection in neutropenic patients with hematological malignancy is associated with neutropenic sepsis. Empirical use of broad-spectrum antibiotics prior to culture result may cause antibiotic resistance in the future. Prediction of microbial growth prior to culture results using various machine learning algorithms can reduce the risk of antibiotic resistance in patients to a large extent. In this paper, we proposed various machine learning models to predict microbial growth using the focus of infection in patients as input features.In comparison with various ML models such as Logistic Regression, Support Vector Machine (SVM), XG-Boost, Decision tree and Artificial Neural Network (ANN) to predict microbial growth in neutropenic patients with hematological malignancy XG-Boost algorithm exhibit better accuracy compared to other algorithm. Evaluation of various algorithm was carried out using evaluation matrix.",
        "affiliation_name": "Amrita University, Amritapuri Campus",
        "affiliation_city": "Kollam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "AI/ML for Next Generation Wireless Networks",
        "paper_author": "Mahesh H.B.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The next generation wireless networks 5G and beyond 5G are heterogeneous networks. They are effectively formed and highly active and complex design networks to transportabundant data at an effective way with concentrated speed and offering extremely low dormancy. 5G networks have the capability of supporting more number of subscribers with high reliability. These wireless networks have significant issues related to design, deployment, data storage, operation, administration and management. These networks demands automotive design with less human intervention. These are highly intelligent networks interms of reasoning, decision making. The resource allocation, usage and network deployment are mainly impact the performance of the next generation wireless networks. Wireless networks 5G or 6G may be standalone structure or they built upon the existing infrasture. The next generation wireless applications includes Smart Home, shrewd cities, transport and logistics,autonomous driving, drone operation, security and surveillance, satellite internet, smart farming, fleet management, healthcare, and mission-critical applications. The above mentioned applications highly demands less power requirement, high response time, less cost, minimizing interference and redundancy to maximize coverage and capacity. To meet the above mentioned issues artificial intelligence and machine learning techniques are employed. The integration of AI/ML technology with wireless celluar network is described in this article. Mainly, this work examine/review the machine learning (ML) approaches that can be used with 6G wireless networks. This article explains the incorporation of different Machine learning algorithms, network optimization using AI principles, AI opportunities for wireless networks, Q-Learning algorithm and its working in improving the performance, use of block-chain technology with wireless network and cognitive radio for dynamic spectral allocationetc.,Federated Learning for data sharing in mobile devices, Kernel Hilbert space for Data rate improvement in 6G. At the end of this article, the CIR prediction with analytical recursive least-squares (RLS) algorithm, machine learning (Linear regression)is depicted and compared. The delay versus number of MCD’s is analyzed with Q-Learning, deep Q-learning and round robin algorithms.",
        "affiliation_name": "JSS Academy of Technical Education, Bengaluru",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Enhancing Accuracy of Machine Learning Model in Digital Soil Mapping",
        "paper_author": "Chinchmalatpure S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The goal of this research work is to establish quantitative techniques for predicting the pH value of the soil and thus finding for what purpose the land will be useful. What all parameters can be used to find the pH value of the soil is the most important thing. Several aspects influence this, including temperature, latitude, longitude, climate, etc. Taking all these factors into consideration, a comparative analysis between different regression models including Multiple Linear Regression (MLR), Random Forest for regression, Decision Trees for regression, XGBoost for regression and Support Vector Regression (SVR) is presented. The dataset considered for this study comprises a total 79 features including country, region, temperature, precipitation, climate, latitude, longitude, ph value, etc. Data Cleaning is performed and the significant columns are chosen which have an effect on ph value. After evaluating the performance of the respective regression algorithms, it could be seen that the XGboost and random forest provide almost the same R squared value with XGboost slightly higher. XGboost provides the highest R-squared value i.e. 0.8493, followed by random forest with 0.8483, SVM with 0.723, decision trees with 0.698 and MLR with 0.261 as the corresponding R-squared values.",
        "affiliation_name": "Vishwakarma Institute of Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Utilizing time series for forecasting the development trend of coronavirus: A validation process",
        "paper_author": "Zhang X.",
        "publication": "Journal of Computational Methods in Sciences and Engineering",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "A time series prediction model was developed to predict the number of confirmed cases from October 2022 to November 2022 based on the number of confirmed cases of New Coronary Pneumonia from January 20, 2021 to September 20, 2022. We will analyze the number of confirmed cases in the Philippines from January 1, 2020 to September 20, 2022 to build a prediction model and make predictions. Among the works of other scholars, it can be shown that time series is an excellent forecasting model, particularly around dates. The study in this work begins with the original data for inference, and each phase of inference is based on objective criteria, such as smooth data analysis utilising ADF detection and ACF graph analysis, and so on. When comparing the performance of algorithms with functions for time series models, hundreds of algorithms are evaluated one by one on the basis of the same data source in order to find the best method. Following the acquisition of the methods, ADF detection and ACF graph analysis are undertaken to validate them, resulting in a closed-loop research. Although the dataset in this study was generated from publicly available data from the Philippines (our data world for coronaviruses), the ARIMA model used to predict data beyond September 20, 2022 exhibited unusually high accuracy. This model was used to compare the performance of several algorithms, each evaluated using the same training data. Finally, the best R2 for the ARIMA model was 92.56% or higher, and iterative optimization of the function produced a predictive model with an R2 of 97.6%. This reveals the potential trajectory of coronaviruses in the Philippines. Finally, the model with the greatest performance is chosen as the prediction model. In actual implementations, several subjective and objective elements, such as the government's epidemic defence measures, the worldwide pandemic condition, and whether the data source distributes the data in a timely way, might restrict the prediction's accuracy. Such prediction findings can be used as a foundation for data releases by health agencies.",
        "affiliation_name": "Angeles University Foundation",
        "affiliation_city": "Angeles City",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "Comparative Study of Different Machine Learning Models for Detecting Spam Tweet",
        "paper_author": "Sanjana G.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In recent times, the increase in use of electronic gadgets and evolving technologies have paved way to gather and share information across the globe through a well-built framework, social networking platforms. Twitter has grown to become one of the key platforms for communication and news circulation. Millions of users today rely on the content available on social media to make decisions, hence detecting and deleting spam details is critical. This paper focuses on conducting a systematic study on different approaches of detecting spam tweets by making use of the tweet content. This work brings a comparative study between ways of detecting spam tweets by making use of different features of tweet like URLs and mentions and analyzing the tweet subject on a publicly available dataset,” social honeypot dataset”. To detect a spam tweet using different features present in spam, Machine Learning algorithms like – SVM, Naïve Bayes, Random Forest algorithms are used. To detect a spam tweet by analyzing the content of tweet Machine learning algorithms- SVM, Naïve Bayes, Random Forest, Light GBM, BERT model is used. By this study we could conclude that content analysis using NLP techniques gave better accuracy on the dataset.",
        "affiliation_name": "PES University",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Prediction of Diabetes Using Optimized RBFNN Algorithm",
        "paper_author": "Sivaraman M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Diabetic is the primary disease growing the ratios for most of the peoples and it causes kidney failure, amputations, loss of sight, lower limb amputation, stroke, and heart problems. It would be caused by many reasons, such as a lack of daily exercise, lifestyle, poor healthy food habits, overweight, genetic, and so on. Human body convert foodstuff into glucose. Diabetes is a set of disease classified by a raised glucose level in the blood. Diabetes Peoples, the pancreas is not supported to released insulin. The aim of this research work to identify diabetic patients in medical fields using software. Secondary diabetes data samples downloaded from the online and applied for the analysis of the proposed work. In this experimental, Radial-Basis Function Neural Network Algorithm (RBFNN), Logistic Regression (LR) and Optimized RBFNN algorithm are implemented. Optimized RBFNN model gives the best level of accuracy compared to the other models.",
        "affiliation_name": "Dr.SNS Rajalakshmi College of Arts and Science",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Early Detection of Cardiovascular Events Using Minimal ECG Leads",
        "paper_author": "Aathira M.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Electrical activity of the heart is represented in a non-intrusive method through electrocardiogram or ECG. A 12 Lead ECG is commonly used among medical practitioners for detecting cardiac abnormalities and other issues. Most of the cardiac abnormalities are signs of chronic cardiac diseases. Hence they need to be diagnosed at the earliest. Automated classification of diseases from an ECG helps in quick diagnosis than a doctor’s diagnosis.12 lead ECG is the main diagnosing system but there is a need for a minimal lead ECG screening system. We developed an algorithm which can automatically group cardiac abnormalities from the specific lead; lead II. Here we are using the dataset from CPSC 2018 which contains 2000 samples. Here all the entries were of 12 lead ECG data from which lead II ECG data was extracted. Various machine learning models including SVM, XG-Boost, Decision tree, ANN and CNN were evaluated to find the best machine learning model to predict cardiovascular diseases. Evaluating different machine learning algorithm, SVM shows more accuracy and CNN shows less accuracy when compared to others in the prediction of CVDS. The mismatch in training and testing accuracy in the models is due to overfitting of dataset. However model can be improved by adding more clinical data and large number of data set in future. The best machine learning model can be used with the wearable devices to predict the cardiovascular diseases from the ECG signal before a doctor could.",
        "affiliation_name": "Amrita University, Amritapuri Campus",
        "affiliation_city": "Kollam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "3rd International Conference on Advances in Physical Sciences and Materials, ICAPSM 2022",
        "paper_author": "NA",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The proceedings contain 214 papers. The topics discussed include: structural and electrical properties of nickel-zinc ferrite/barium titanate composites; data-driven prognosis of long COVID in patients using machine learning; an efficient content based image retrieval and classification based on hybrid texture feature extraction; stability analysis of diseased predator-prey model with Holling type II functional response; phase transformation analysis of iron oxide nanomaterials via calcination temperature; new exact traveling wave solutions to the Zakharov-Kuznetsov-Benjamin-Bona-Mahony Equation; enhancing heat dissipation in light emitting diodes (LED) using genetic algorithm; performance of mini-channel heat sinks used in battery thermal management; and effective use of digital learning technologies in the educational process.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A Novel Method for Solar Water Pumping System Using Machine Learning Techniques",
        "paper_author": "Sumathi S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "This research article presents with the application of a Cuk converter and Single Ended Primary Inductor Converter (SEPIC) for solar water pumping with Maximum Power Point Tracking (MPPT). A centrifugal pump linked to its shaft is driven by a permanent magnet brushless DC (BLDC) motor. The Incremental Conductance Maximum Power Point Tracking (INC-MPPT) technique is used to manage the converter and soft start the BLDC motor with zero ripple current. A hybridized MPPT technique based on Gravitational Search Algorithm (GSA) and Particle Swarm Optimization (PSO) is presented. This new converter lowers supply current ripple to a minimum and maximum the amount of Photovoltaic power collected from a solar component by merging the input and output magnetic cores of an inductance. The proposed method is more efficient since the motor speed remains constant even when the load is full. The dynamic and steady-state performance of a BLDC motor coupled to a centrifugal water pump fed by the SPV array-SEPIC is assessed, and its applicability is confirmed using simulated results in the MATLAB/ Simulink environment. The experimental outcomes for a 5.0 kW prototype system are discussed for a PV power conditioning system. The CUK-SEPIC achieves high settling time of 0.9 for a 5.0 kW output power, improving power efficiency. The performance of proposed system is compared with different techniques.",
        "affiliation_name": "Mahendra Engineering College",
        "affiliation_city": "Mallasamudram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Lagrangian Analysis of Tropical Cyclone Intensification Simulated by General Circulation Models Compared with Observations",
        "paper_author": "Song C.",
        "publication": "Journal of Climate",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "To understand the intensification process of tropical cyclones (TCs), we analyzed the relationship between the TC intensification rate (I) and environmental variables along TC tracks during the time from TC genesis (tG) to maximum TC strength (tX), hereinafter tGX ≡ tX - tG, using a state-of-the-art general circulation model (GCM), observed TC tracks, and ERA5 data. During tGX, strong TCs with high I (sTCs) consume more convective available potential energy (CAPE) than weak TCs with low I (wTCs) and bring more CAPE from the equator to sustain sTCs. Compared to wTCs, sTCs prefer an unstable atmosphere with higher sea surface temperature (SST), stronger grid-mean upward flow at 500 hPa (ω500), more moisture convergence (MC), and weaker wind shear (Vs). Our GCM simulation shows that MC and CAPE have a single regression slope with I applicable both within and across climate regimes. Using machine learning, we found that the best combination of environmental variables (V6) for predicting I consists of ω500, MC, SST, midtropospheric stability (MTS), Vs, and latitude (| f |). Machine learning with V6 reproduces well the spatial distribution and interclimate changes of I: TCs are intensified in regions of stronger upward ω500, more MC, warmer SST, weaker MTS, smaller Vs, and larger | f |; TCs in a warmer climate have higher I than TCs in a colder climate due to more MC, warmer SST, but stronger MTS. These results are consistent with the conceptual understanding that TCs are intensified by the release of latent heat.",
        "affiliation_name": "Seoul National University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "DETECTION OF FACIAL MICRO-EXPRESSIONS USING CNN",
        "paper_author": "Sánchez García F.T.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Brief, involuntary micro-facial expressions represent a window into a person's hidden or repressed emotions. The ability to analyze and detect them can have a significant impact in various fields that require an understanding of human behavior. However, the process of detecting micro-expressions poses significant challenges, such as the implementation of the detection method or the generation of extensive and quality data. This article develops a Machine Learning model with a convolutional neural network; It is compared with other existing models of micro expressions in the prediction of one of 7 human emotions, to recognize micro expressions and predict one of 7 emotions.",
        "affiliation_name": "Instituto Politécnico Nacional",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "DESIGN OF CONTEMPORARY MULTIVARIATE DATASET TO ASSESS THE QUALITY OF OBJECT, FACE AND PROXIMITY DETECTION IN ASSISTING THE VISUALLY IMPAIRED PEOPLE",
        "paper_author": "Sajini S.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "In recent years, advancements in Computer Vision have significantly impacted the development of assistive technologies for visually impaired individuals. The Major Objective of this research builds on the creation of a contemporary multivariate dataset designed to evaluate the quality of object, face, and proximity detection systems tailored to assist visually impaired individuals. The dataset incorporates diverse real-world scenarios, encompassing various environmental conditions and complexities commonly encountered by the visually impaired. It includes annotated images and accompanying ground truth data to facilitate the training and assessment of machine learning models for accurate object and face detection, as well as proximity estimation. The research work was based on the model designed using IoT enabled device and tested with 100 samples of visually impaired people. By leveraging this dataset, researchers and developers can enhance the performance of assistive technologies, ultimately improving the lives and independence of visually impaired individuals. The proposed dataset serves as a valuable resource for advancing the field of Computer Vision in the domain of accessibility and inclusive technology.",
        "affiliation_name": "Annamalai University",
        "affiliation_city": "Chidambaram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "AN IMPROVED MALWARE VARIANT DETECTION MODEL BASED ON HOMOGENEOUS STATIC HYBRID FEATURES AND A DATA AUGMENTATION TECHNIQUE",
        "paper_author": "Cletus A.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The use of Machine learning has become the de-facto standard for malware defense due to the limitations of signature-based, heuristic-based and other cloud-based techniques. However, poor malware features, class imbalance problems and malware obfuscation remain challenges facing malware researchers. To ensure efficient and resilient detection in the face of these challenges requires novel models that adopt innovative techniques to improve malware detection. The paper proposed an improved novel malware variant detection model based on Homogeneous Multi-Static Hybrid features (HMSHF), obfuscated malware dataset and Synthetic Minority Oversampling Technique (SMOTE). A malware dataset comprising 11678 malware files from virusTotal.com and 3963 benign files obtained from windows environment was used for the study. We extracted ‘fine-grained’ strings, APIs, and opcode features from static disassembly of the malware dataset. We trained and tested a Random Forest (RF), Support Vector Machine (SVM), GradientBoost (GB), and eXtremGradientBoost (XGB) ensemble algorithms before and after obfuscating the malware dataset. We hybridized the features into HMSHF for training and testing the ensembles before and after the malware was obfuscated. We evaluated the performance of the models using individual features and the hybrid features before and after obfuscations. To overcome the class imbalance problem, we applied the SMOTE technique on the training set with the HMSHF. The proposed hybrid features showed effectiveness and efficiency in classifying malware with 99.87% accuracy without data augmentation and 98.8% accuracy with SMOTE data augmentation. Consequently, the paper concluded that, the proposed technique improved malware detection and demonstrated resilience against obfuscation compared with the state of the art. Thus, the approach can be adopted for the detection of known, unknown and zero-day malware. Notwithstanding the improved performance, this work is not without limitations; the use of feature selection instead of feature extraction, and use of ensembles instead of other Deep learning techniques and SMOTE instead of other data augmentation methods. Thus, future works will adopt the approach and use Principal Component Analysis (PCA) dimensionality reduction techniques; employ deep learning techniques and apply other data augmentation techniques to observe the performance.",
        "affiliation_name": "University of Energy and Natural Resources",
        "affiliation_city": "Sunyani",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "The Impact of Information Technology on Fake News",
        "paper_author": "Karnyoto A.S.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Fake news is false or misleading information presented as news. False stories tend to spread farther, faster, and more broadly than true stories. Some individuals and organizations intentionally applied misleading information for certain benefits. The internet goes quickly, mobile devices became popular, and social media users grow more significant in number, make no boundaries world and connect every user. As a result, information circulates in immense numbers makes to handle fake news manually is impossible. Fake news also affects human psychology. Hoax related to how to cure COVID-19 and the lack of toilet paper has led to casualties and riots. Fake news potentially differs in writing technique compare to real information. In this paper, we discussed a few studies related to fake news detection. Their algorithm can capture writing style in content viz lexicon, syntax, semantic, and discourse. Also, those studies implemented user-based, content-based, and social context-based. It used machine learning, deep learning, and reinforcement learning. Furthermore, education plays a vital role in making people understand the impact of fake news. Itis necessary to do a campaign for all internet users. The national government necessity collaborates with society implement the particular rule for better internet environment.",
        "affiliation_name": "Universitas Kristen Indonesia",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "AN IMPROVED REAL-TIME HANDGUN DETECTION SYSTEM USING YOLO V5 ON A NOVEL DATASET",
        "paper_author": "Rahil I.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In the face of widespread gun violence, it has become imperative to enhance the capabilities of public surveillance cameras by integrating intelligent automatic handgun detection systems. This study presents a comprehensive approach to automate the real-time identification of pistols in video security footage using the advanced YOLO-V5 algorithm. A carefully curated dataset of varied pistol images was employed to optimize the model's performance across diverse scenarios and minimize dependence on human security personnel. Recognizing the crucial implications of firearm detection in images for public safety and law enforcement, this study employed advanced techniques such as data augmentation, transfer learning, and test time augmentation to enhance the model's performance. Iterative fine-tuning of hyperparameters was conducted to attain the desired level of accuracy. The results demonstrate that the YOLO-V5 model exhibits high precision and recall in detecting handguns, even in complex and challenging environments. This study represents a significant advancement in the development of effective gun detection systems, serving as a catalyst for further research in this exciting field. By automating the identification of firearms in real-time video surveillance, this approach addresses a critical need for enhanced public safety measures and offers valuable insights into the potential of intelligent surveillance technologies.",
        "affiliation_name": "Université Cadi Ayyad",
        "affiliation_city": "Marakech",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "THE INTERNET OF VEHICLES (IOV) TECHNOLOGY: CHALLENGES AND SOLUTIONS",
        "paper_author": "Alkarim A.S.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "The Internet of Things (IoT) revolution has paved the way for the emergence of Internet of Vehicles (IoV) technology, enabling seamless communication and data exchange among vehicles, infrastructure, and pedestrians. This paper delves into the IoV landscape, examining its challenges, solutions, and the role of artificial intelligence (AI) methods in addressing critical issues. The paper begins by elucidating the foundational concepts of IoV, emphasizing its potential to revolutionize transportation systems through communication protocols, Vehicle-to-Everything (V2X) technology, cybersecurity, data management, edge computing, and artificial intelligence (AI). However, realizing these benefits involves numerous challenges, including managing massive amounts of data, addressing data privacy and security concerns, mitigating network congestion, ensuring reliability, and achieving scalability. This paper comprehensively analyses IoV technology, explores the associated challenges, and presents innovative solutions enabled by artificial intelligence. By harnessing the potential of AI methods, the IoV ecosystem can evolve into a safer, more efficient, and sustainable transportation paradigm, revolutionizing how we navigate and interact with urban environments.",
        "affiliation_name": "Faculty of Science",
        "affiliation_city": "Cairo",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "DEMENTIA RISK ASSESSMENT USING MACHINE LEARNING AND PART-OF-SPEECH TAGS",
        "paper_author": "Zadgaonkar A.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Dementia, a set of cognitive decline syndromes distinct from typical age-related degeneration, poses a significant public health challenge. The key to dementia detection lies in analyzing sentence structure and conversational style, particularly in speech. This study focuses on creating and evaluating a machine learning model for non-invasive early dementia detection through speech parameter analysis in everyday conversation. Leveraging the DementiaBank dataset, comprising over 500 voice transcripts from individuals aged 60 and older, the study employs 63 tagged Part-of-Speech (PoS) parameters extracted from chat transcripts. Data from 244 control subjects and 306 dementia patients are used. Machine learning methods, including Random Forest, Deep Neural Network, and Support Vector Machine, achieve respective accuracy rates of 83%, 92%, and 84%. These results underscore the effectiveness of informatics-based machine learning in non-invasive dementia detection using PoS tags. Additionally, the study provides insights into the relative importance of each PoS tag in dementia detection. This research contributes to the growing informatics field of dementia detection and supports the development of less intrusive diagnostic tools.",
        "affiliation_name": "Indian Institute of Information Technology, Nagpur",
        "affiliation_city": "Nagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "COMPARATIVE ANALYSIS OF PREDICTIVE MODELS FOR WORKLOAD SCALING IN IAAS CLOUDS: A STUDY ON MODEL EFFECTIVENESS AND ADAPTABILITY",
        "paper_author": "Pothu S.N.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "The demand for dependable workload prediction models has surged in the ever-evolving domain of cloud computing, especially across renowned platforms such as AWS, Google Cloud, and Azure. These models are instrumental in enabling efficient resource allocation and enhancing overall performance. This comparative research focuses on various predictive models pivotal for reactive and proactive scaling in Infrastructure as a Service (IaaS) clouds. Initially, the study evaluates time series and machine learning models. These models have shown prowess in accurately forecasting workloads on real-time cloud datasets, leading to notable savings in resource allocation. However, their effectiveness can be challenged during abrupt changes in workload, underscoring the need for more dynamic modeling approaches. The research then delves deeper into Markov models and their simulations on real-time cloud datasets. These models, rooted in state transitions and probabilistic events, have been a cornerstone in predicting resource demands and optimizing workload distribution in cloud environments. Simulations based on Markov models provide valuable insights into potential future states, making them an invaluable tool for proactive resource management. Nevertheless, the intricacies involved in these simulations, especially when handling large-scale real-time datasets, can sometimes act as a double-edged sword, leading to computational challenges and necessitating further optimization. The study also touches upon reinforcement learning models, which have been significant in resource management and performance enhancement. However, these models come with their challenges, where the complexity of their learning algorithms might sometimes hinder optimal performance. This observation paves the way for a recommendation to refine and streamline the learning processes to bolster their efficiency. The research concludes with an examination of evidence-based design and simulation models. While adept at assessing specialized aspects, such as visual comfort in modern office designs, their performance can be compromised by the complexities associated with their simulation methods. The specific use case and inherent requirements influence the ideal predictive model. While particular models excel in more stable settings, others are tailored for unpredictable environments. The future beckons a focus on refining these models, ensuring they are well-equipped to handle abrupt changes and the multifaceted nature of cloud settings, thereby maximizing the potential of cloud computing services.",
        "affiliation_name": "Sir C.R.Reddy College of Engineering",
        "affiliation_city": "Eluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "REVOLUTIONIZING COMPUTER VISION: ENHANCED FOOD IMAGE CLASSIFICATION WITH SWIN TRANSFORMER AND SVM CLASSIFIER",
        "paper_author": "Elpina ",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "This paper presents a novel approach for food image classification using a combination of the Swin Transformer model and a support vector machine (SVM) classifier. The proposed method surpasses the performance of the original Swin Transformer model trained on ImageNet, achieving an impressive accuracy of 91.05% on the testing dataset. Comparative evaluation shows that the SVM classifier enhances the classification capabilities of the Swin Transformer, outperforming the baseline approach. The results highlight the efficacy of the Swin Transformer as a feature extraction model for food image classification tasks. The integration of deep learning with traditional machine learning techniques, as demonstrated by the SVM classifier, shows promise for improving classification accuracy in various applications such as food recognition systems and dietary analysis tools. Future work includes further optimization of the proposed method, exploring domain adaptation and transfer learning techniques, and investigating advanced fusion methods to achieve even higher classification accuracy and improved generalization across diverse food domains.",
        "affiliation_name": "Bina Nusantara University",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Remittance dependence, support for taxation and quality of public services in Africa",
        "paper_author": "Konte M.",
        "publication": "Journal of Institutional Economics",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "We explore the heterogeneous effect of migrant remittances on citizens' support for taxation using a sample comprising 45,000 individuals from the Afrobarometer survey round 7 [2016-2018] across 34 African countries. To correct for unobserved heterogeneity, we endogenously identify latent classes/subtypes of individuals that share similar patterns on how their support for taxation is affected by their unobserved and observed characteristics, including remittance dependency. We apply the finite multilevel mixture of regressions approach, a supervised machine learning method to detect hidden classes in the data without imposing a priori assumptions on class membership. Our data are best generated by an econometric model with two classes/subtypes of individuals. In class 1 where more than two-thirds of the citizens belong, we do not find any significant evidence that remittance dependence affects support for taxation. However, in class 2 where the remaining one-third of the citizens belong, we find a significant negative effect of remittance dependence on support for taxation. Furthermore, we find that citizens who have a positive appraisal of the quality of the public service delivery have a lower probability of belonging to the class in which depending on remittance reduces support for taxation. The findings emphasize the need for efficient public services provisioning to counteract the adverse effect of remittances on tax morale.",
        "affiliation_name": "Universiteit Maastricht",
        "affiliation_city": "Maastricht",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Revealing microcanonical phases and phase transitions of strongly correlated systems via time-averaged classical shadows",
        "paper_author": "Gyawali G.",
        "publication": "Physical Review B",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Quantum computers and simulators promise to enable the study of strongly correlated quantum systems. Yet, surprisingly, it is hard for them to compute ground states. They can, however, efficiently compute the dynamics of closed quantum systems. We propose a method to study the quantum thermodynamics of strongly correlated electrons from quantum dynamics. We define time-averaged classical shadows (TACS) and prove it is a classical shadow(CS) of the von Neumann ensemble, the time-averaged density matrix. We then show that the diffusion maps, an unsupervised machine learning algorithm, can efficiently learn the phase diagram and phase transition of the one-dimensional transverse field Ising model both for ground states using CS and state trajectories using TACS. It does so from state trajectories by learning features that appear to be susceptibility and entropy from a total of 90 000 shots taken along a path in the microcanonical phase diagram. Our results suggest a low number of shots from quantum simulators can produce quantum thermodynamic data with a quantum advantage.",
        "affiliation_name": "Southern Illinois University Carbondale",
        "affiliation_city": "Carbondale",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modulation of interface modes for resonance-induced enhancement of the interfacial thermal conductance in pillar-based Si/Ge nanowires",
        "paper_author": "Liu Y.",
        "publication": "Physical Review B",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "The interfacial thermal conductance (ITC) plays a crucial role in nanoscale heat transfer, and its enhancement is of great interest for various applications. In this study, we explore the influence of resonance on the interfacial modes in pillar-based Si/Ge nanowires through nonequilibrium molecular dynamics simulations, employing both empirical and machine-learning potentials. Our results reveal a significant enhancement in the ITC by introducing pillars in the nanowire structure. The resonance-induced enhancement of the matching degree of the phonon density of states together with the calculation results of the phonon transmission coefficient indicate a significant improvement in both elastic and inelastic phonon transport at the interface. Moreover, we demonstrate the effective utilization of resonance to modulate the interfacial modes in pillar-based Si/Ge nanowires, resulting in improved phonon transport efficiency. This modulation is achieved by strategically repositioning the Si and Ge walls near the interface, leading to the development of the ATI-wall structure. Remarkably, the ATI-wall structure exhibits an unprecedented increase in the ITC compared to the original pillar-based design. To provide additional support for our conclusion, we conduct supplementary simulations using graphics processing unit molecular dynamics in conjunction with the neuroevolution potential to calculate the ITC. Our findings highlight the significance of interfacial mode modulation in enhancing the heat transfer in nanoscale systems and provide valuable insights for the design and optimization of thermal management devices and materials.",
        "affiliation_name": "Yunnan University",
        "affiliation_city": "Kunming",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Raman spectroscopy of brain and skin tissue in a minipig model of Huntington's disease",
        "paper_author": "Tipatet K.",
        "publication": "Analytical Methods",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "We applied Raman spectroscopy to brain and skin tissues from a minipig model of Huntington's disease. Differences were observed between measured spectra of tissues with and without Huntington's disease, for both brain tissue and skin tissue. There are linked to changes in the chemical composition between tissue types. Using machine learning we correctly classified 96% of test spectra as diseased or wild type, indicating that the test would have a similar accuracy when used as a diagnostic tool for the disease. This suggests the technique has great potential in the rapid and accurate diagnosis of Huntington's and other neurodegenerative diseases in a clinical setting.",
        "affiliation_name": "Academy of Sciences of the Czech Republic",
        "affiliation_city": "Prague",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Machine Learning Assisted Fast Demodulation of Large Dynamic Range Dual-Parameter Optical Fiber Sensors",
        "paper_author": "Zhao Y.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "The mutual constraint between sensitivity and measurement range has always been a problem that restricts the development and application of optical fiber interference sensors. We propose a new high-sensitivity tapered dual-parameter optical fiber sensor packaged with polydimethylsiloxane (PDMS) in this article. The use of the multilayer perceptron (MLP) network for demodulation of spectrum without preprocessing improves the constraint relationship between the measurement range and sensitivity of the interferometric sensor, ensuring high sensitivity while expanding the dynamic range. By introducing principal component analysis (PCA) to reduce the dimensionality of the original data, the computational efficiency is improved, and the practicality of the model is improved. As far as we know, this is the first time that PCA and MLP have been used simultaneously to demodulate the spectrum. The detection system has advantages, such as low cost, high sensitivity, easily prepared, fully packaged, and remote real-Time monitoring ability. This demodulation method can also be easily extended to demodulation of other multiparameter sensors.",
        "affiliation_name": "The State Key Laboratory of Synthetical Automation for Process Industries",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Electrifying insights into cardiac arrhythmias: From molecular mechanisms to therapeutic translations",
        "paper_author": "Trew M.L.",
        "publication": "Interface Focus",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Disruptions to normal bioelectric rate and rhythm profiles in the heart are cardiac arrhythmias. Their impacts range from minor discomforting symptoms to acute or chronic life-threatening events, with atrial fibrillation increasing the risk of stroke and heart failure, and ventricular arrhythmia associated with sudden cardiac death. To improve mechanistic understandings and advance potential approaches to treatment of arrhythmias, this Interface Focus themed issue on cardiac electrophysiology is a collection of recent studies. They investigate some of the molecular and cellular mechanisms or tissue substrates instigating and maintaining arrhythmia, and discover relevant imaging and signalling biomarkers that assess arrhythmic risks. The studies use imaging, computer simulations, machine learning and both human and animal models in their investigations exploring basic science and strategies for early recognition and improved treatment strategies.",
        "affiliation_name": "Auckland Bioengineering Institute",
        "affiliation_city": "Auckland",
        "affiliation_country": "New Zealand"
    },
    {
        "paper_title": "MODIFIED RANDOM FOREST REGRESSION MODEL FOR PREDICTING WHOLESALE RICE PRICES",
        "paper_author": "Dewi C.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Both in terms of diet and economy, Indonesian people attach great importance to rice as a staple food. In addition, it is very important to monitor rice price fluctuations every month so that overall rice prices remain stable and do not burden the community. Tracking rice price fluctuations helps rice producers, traders, and businesses make informed decisions about when to buy, sell, or store rice. This can optimize their supply chain management and maximize profits. Researchers and analysts can use rice price data to study market trends, identify patterns, and develop predictive models for future price movements. This research purpose to determine the most optimal forecasting model by using the Average Rice Price dataset at the Indonesian Wholesale Trade Level from January 2010 to December 2022. The dataset is obtained from the Central Statistics Agency of Indonesia. Moreover, the best model proposed in this research uses the Random Forest method with hyperparameter tuning using the n estimator parameter of 500. Our proposed method can reduce the MAPE value from 0.0093573 to 0.0089389 and increase the R2 Score value from 0.9916805 to 0.9921578. Moreover, we analyze the performance of our proposed methodology with several other datasets sourced from UCI (University of California Irvine). The experimental outcomes indicate that the suggested model displays superior performance when compared to alternative methods, with a tendency of decreasing MAPE values and increasing R2 values in each experiment for all datasets.",
        "affiliation_name": "Satya Wacana Christian University",
        "affiliation_city": "Salatiga",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "STOCK MARKET PREDICITION USING STATISTICAL &amp; DEEP LEARNING TECHNIQUES",
        "paper_author": "Alqahtani M.G.",
        "publication": "Journal of Theoretical and Applied Information Technology",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Predicting stock marketing prices has persistently a challenge due to the complexity of the stock data. Accurately predicting a stock's short-term price can increase the rate of investment and business opportunities in the stock market. This study aims to predict the closing prices of six major sectors in the Saudi stock market: Banking, Basic Materials, Real Estate Management and Development, Insurance, Energy, and Telecommunication. The dataset was historical records of the six sectors for seven years, along with two economic indicators: oil prices and inflation rates. Six models were employed for prediction: Auto-Regressive Integrated Moving Average (ARIMA), Support Vector Regression (SVR), Random Forests, Long Short-Term Memory (LSTM), Bidirectional Long Short-Term Memory (Bi-LSTM), and gated recurrent units (GRU). The models were evaluated using four regression metrics: mean squared error (MSE), mean absolute error (MAE), the mean absolute percentage error (MAPE), and the root mean squared error (RMSE). The findings revealed that GRU and Random Forests exhibit superior performance across multiple sectors, while SVR and Bi-LSTM demonstrated promising results. However, ARIMA consistently performed poorly across all sectors. The study provided valuable insights into the effectiveness of different models in predicting stock prices in the Saudi stock market. These findings could aid investors, analysts, and decision-makers in making informed investment decisions.",
        "affiliation_name": "Princess Nourah Bint Abdulrahman University",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "WGCNA combined with machine learning to find potential biomarkers of liver cancer",
        "paper_author": "Lv J.H.",
        "publication": "Medicine (United States)",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "The incidence of hepatocellular carcinoma (HCC) has been increasing in recent years. With the development of various detection technologies, machine learning is an effective method to screen disease characteristic genes. In this study, weighted gene co-expression network analysis (WGCNA) and machine learning are combined to find potential biomarkers of liver cancer, which provides a new idea for future prediction, prevention, and personalized treatment. In this study, the \"limma\"software package was used. P < .05 and log2 |fold-change| > 1 is the standard screening differential genes, and then the module genes obtained by WGCNA analysis are crossed to obtain the key module genes. Gene Ontology and Kyoto Gene and Genome Encyclopedia analysis was performed on key module genes, and 3 machine learning methods including lasso, support vector machine-recursive feature elimination, and RandomForest were used to screen feature genes. Finally, the validation set was used to verify the feature genes, the GeneMANIA (http://www.genemania.org) database was used to perform protein-protein interaction networks analysis on the feature genes, and the SPIED3 database was used to find potential small molecule drugs. In this study, 187 genes associated with HCC were screened by using the \"limma\"software package and WGCNA. After that, 6 feature genes (AADAT, APOF, GPC3, LPA, MASP1, and NAT2) were selected by RandomForest, Absolute Shrinkage and Selection Operator, and support vector machine-recursive feature elimination machine learning algorithms. These genes are also significantly different on the external dataset and follow the same trend as the training set. Finally, our findings may provide new insights into targets for diagnosis, prevention, and treatment of HCC. AADAT, APOF, GPC3, LPA, MASP1, and NAT2 may be potential genes for the prediction, prevention, and treatment of liver cancer in the future.",
        "affiliation_name": "Heilongjiang University of Chinese Medicine",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Brain asymmetry is globally different in males and females: exploring cortical volume, area, thickness, and mean curvature",
        "paper_author": "Dumitru M.L.",
        "publication": "Cerebral Cortex",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Brain asymmetry is a cornerstone in the development of higher-level cognition, but it is unclear whether and how it differs in males and females. Asymmetry has been investigated using the laterality index, which compares homologous regions as pairwise weighted differences between the left and the right hemisphere. However, if asymmetry differences between males and females are global instead of pairwise, involving proportions between multiple brain areas, novel methodological tools are needed to evaluate them. Here, we used the Amsterdam Open MRI collection to investigate sexual dimorphism in brain asymmetry by comparing laterality index with the distance index, which is a global measure of differences within and across hemispheres, and with the subtraction index, which compares pairwise raw values in the left and right hemisphere. Machine learning models, robustness tests, and group analyses of cortical volume, area, thickness, and mean curvature revealed that, of the three indices, distance index was the most successful biomarker of sexual dimorphism. These findings suggest that left–right asymmetry in males and females involves global coherence rather than pairwise contrasts. Further studies are needed to investigate the biological basis of local and global asymmetry based on growth patterns under genetic, hormonal, and environmental factors.",
        "affiliation_name": "Universitetet i Bergen",
        "affiliation_city": "Bergen",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Research Accomplishments in Pulmonary, Critical Care, and Sleep: A Retrospective Review",
        "paper_author": "Kiley J.P.",
        "publication": "American Journal of Respiratory and Critical Care Medicine",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "NA",
        "affiliation_name": "NHLBI Division of Lung Diseases",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Prediction of misfolded proteins spreading in Alzheimer’s disease using machine learning and spreading models",
        "paper_author": "Gherardini L.",
        "publication": "Cerebral Cortex",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The pervasive impact of Alzheimer’s disease on aging society represents one of the main challenges at this time. Current investigations highlight 2 specific misfolded proteins in its development: Amyloid-β and tau. Previous studies focused on spreading for misfolded proteins exploited simulations, which required several parameters to be empirically estimated. Here, we provide an alternative view based on 2 machine learning approaches which we compare with known simulation models. The first approach applies an autoregressive model constrained by structural connectivity, while the second is based on graph convolutional networks. The aim is to predict concentrations of Amyloid-β 2 yr after a provided baseline. We also evaluate its real-world effectiveness and suitability by providing a web service for physicians and researchers. In experiments, the autoregressive model generally outperformed state-of-the-art models resulting in lower prediction errors. While it is important to note that a comprehensive prognostic plan cannot solely rely on amyloid beta concentrations, their prediction, achieved by the discussed approaches, can be valuable for planning therapies and other cures, especially when dealing with asymptomatic patients for whom novel therapies could prove effective.",
        "affiliation_name": "Scuola di Medicina e Chirurgia",
        "affiliation_city": "Padua",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "A novel IDS system based on Hedge algebras to detect DDOS attacks in IoT systems",
        "paper_author": "Minh H.T.",
        "publication": "Vietnam Journal of Science and Technology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "In recent years, we have experienced rapid and beneficial development of IoT solutions throughout all aspects of life. In addition to the apparent advantages, the increased number and variety of devices have resulted in more security issues. The DDoS attack, which originates from a broad range of sources and is a significant challenge for IoT systems, is one of the most prevalent but devastating attacks. Because IoT devices are typically simple and have few computing resources, it puts them at risk of being infected and attacked. IDS intrusion detection systems are considered superior protection against DDoS attacks. Therefore, the IDS system attracts many researchers and implements intelligent techniques such as machine learning and fuzzy logic to detect these DDoS attacks quickly and precisely. Along with the approach of intelligent computation, this study presents a novel technique for detecting DDoS attacks based on hedge algebra, which has never been implemented on IDS systems. We use the PSO swarm optimization algorithm to optimize the proposed model's parameters for performance optimization. Our experiment carried out on the IoT-23 dataset shows that the proposed model's accuracy and performance for DDoS attack detection are better than those proposed by other previous research.",
        "affiliation_name": "Thang Long University",
        "affiliation_city": "Hanoi",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Catalyst Energy Prediction with CatBERTa: Unveiling Feature Exploration Strategies through Large Language Models",
        "paper_author": "Ock J.",
        "publication": "ACS Catalysis",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "Efficient catalyst screening necessitates predictive models for adsorption energy, which is a key descriptor of reactivity. Prevailing methods, notably graph neural networks (GNNs), demand precise atomic coordinates for constructing graph representations, while the integration of observable attributes remains challenging. This research introduces CatBERTa, an energy prediction Transformer model that uses textual inputs. Built on a Transformer encoder pretrained for language modeling purposes, CatBERTa processes human-interpretable text, incorporating target features. Attention score analysis reveals CatBERTa’s focus on tokens related to adsorbates, bulk composition, and their interacting atoms. Moreover, interacting atoms emerge as effective descriptors for adsorption configurations, while factors such as the bond length and atomic properties of these atoms offer limited predictive contributions. In predicting the adsorption energy from textual representations of initial structures, CatBERTa exhibits a precision comparable to that of conventional GNNs. Notably, in subsets recognized for their high accuracy with GNNs, CatBERTa consistently achieves a mean absolute error of 0.35 eV. Furthermore, the subtraction of the CatBERTa-predicted energies effectively cancels out their systematic errors by as much as 19.3% for chemically similar systems, surpassing the error reduction observed in GNNs. This outcome highlights its potential to enhance the accuracy of the energy difference predictions. This research establishes a fundamental framework for text-based catalyst property prediction without relying on graph representations while also unveiling intricate feature-property relationships.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Phase transitions of LaMnO3 and SrRuO3 from DFT+U based machine learning force fields simulations",
        "paper_author": "Jansen T.",
        "publication": "Physical Review B",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Perovskite oxides are known to exhibit many magnetic, electronic, and structural phases as function of doping and temperature. These materials are theoretically frequently investigated by the DFT+U method, typically in their ground state structure at T=0. We show that by combining machine learning force fields (MLFFs) and DFT+U based molecular dynamics, it becomes possible to investigate the crystal structure of complex oxides as function of temperature and U. Here, we apply this method to the magnetic transition metal compounds LaMnO3 and SrRuO3. We show that the structural phase transition from orthorhombic to cubic in LaMnO3, which is accompanied by the suppression of a Jahn-Teller distortion, can be simulated with an appropriate choice of U. For SrRuO3, we show that the sequence of orthorhombic to tetragonal to cubic crystal phase transitions can be described with great accuracy. We propose that the U values that correctly capture the temperature-dependent structures of these complex oxides can be identified by comparison of the MLFF simulated and experimentally determined structures.",
        "affiliation_name": "MESA+ Instituut",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Venice lagoon chlorophyll-a evaluation under climate change conditions: A hybrid water quality machine learning and biogeochemical-based framework",
        "paper_author": "Zennaro F.",
        "publication": "Ecological Indicators",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Climate change presents a significant challenge to lagoon ecosystems, which are highly valued coastal environments known for their provision of unique ecosystem services. As important as fragile, lagoons are vulnerable to both natural processes and anthropogenic activities, and this vulnerability is exacerbated by the impacts of climate change, which are likely to result in severe ecological consequences. The complexity of water quality (WQ) processes, characterized by compounding and interconnected pressures, highlights the importance of adequate sophisticated methods to estimate future ecological impacts on lagoon environments. In this setting, a hybrid framework is introduced where Machine Learning (ML) and biogeochemical (BGC) models are integrated in a sequential modelling approach. This integration exploits the unique strengths offered by both models. The ML model allows capturing and learning linear and nonlinear correlations from historical data; the BGC interprets and simulates complex environmental systems subject to compounded pressures, building on identified causal relationships. Multi-Layer Perceptron (MLP) and Random Forest (RF) ML algorithms are trained, validated and tested within the Venice lagoon case study to assimilate historical WQ data (i.e., water temperature, salinity, and dissolved oxygen) and spatio-temporal information (i.e., monitoring station location and month), and to predict changes in chlorophyll-a (Chl-a) conditions. Then, projections from the BGC model SHYFEM-BFM for 2019, 2050, and 2100 timeframes under RCP 8.5 are integrated into the ML model (composing the hybrid ML-BGC model) to evaluate Chl-a variations under future biogeochemical conditions forced by climate change projections. Moreover, the SHYFEM-BFM standalone Chl-a projections are also used to compare the hybrid and the BGC scenarios. Annual and seasonal Chl-a predictions are developed by classes based on two classification modes (median and quartiles) established on the descriptive statistics computed on historical data. Results from the case study showed as the RF successfully classifies Chl-a with an overall model accuracy of about 80% for the median and 61% for the quartiles modes. Concerning future climate change scenarios, results revealed a decreasing trend for the lowest Chl-a values (below the first quartile, i.e. 0.85 µg/l) moving to the far future (2100), with an opposite rising trend for the highest Chl-a values (above the fourth quartile, i.e. 2.78 µg/l). On the seasonal level, summer remains the season with the highest Chl-a values in all scenarios, although in 2100 a strong increase in higher Chl-a values is also expected during the springtime one. The proposed hybrid framework represents a valuable approach to strengthen both multivariate Chl-a modelling and scenarios analysis, by placing artificial intelligence-based models alongside biogeochemical models.",
        "affiliation_name": "Fondazione Centro Euro-Mediterraneo sui Cambiamenti Climatici",
        "affiliation_city": "Lecce",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Unlocking the metaverse: A strategic guide for the future of the built environment",
        "paper_author": "Doherty P.",
        "publication": "Unlocking the Metaverse: A Strategic Guide for the Future of the Built Environment",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Unlocking the Metaverse Highly comprehensive resource providing insight into how the \"Metaverse,\" and digital worlds in general, can be leveraged for business success Unlocking the Metaverse focuses on the strategic implementation of processes and the execution of Metaverse strategies, technologies, and innovations and provides readers with real world tools and strategies to succeed with market demands. The text provides a clear and concise description of what the Metaverse is and what its value means to readers and their companies. A continuous interaction with readers inside the book's virtual world in the Metaverse provides both structured and unstructured interactions with the highly qualified author and his guests in periodic and ongoing public events, serving as a repository of continuous learning and a sandbox for continuous innovations to be explored, analyzed, and reported. Unlocking the Metaverse covers sample topics such as: • Construction documents and drawings, covering building information modeling (BIM), digital twins, virtual worlds, the metaverse, and level of experience/engagement measures • Specifications changing role, covering specification manuals, lifecycle, 3D geolocation specs, and 3D search • Smart contracts and tokenomics, DLT/blockchain, smart contracts, NFTs/FTs (digital building/digital asset), fractionalized ownership and digital real estate, and CBDCs, stablecoins, and crypto • Future outlooks, covering machine learning and artificial intelligence (AI) as a whole, and its probable applications in gaming and robotics Providing authoritative coverage of an important and fast-evolving industry, Unlocking the Metaverse is an essential resource for architects, engineers, and contractors, facility managers and operators, and property owners who want to stay on the cutting edge of new forms of technology and leverage them to increase business success.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Organopalladium Catalysis as a Proving Ground for Data-Rich Approaches to Reaction Development and Quantitative Predictions",
        "paper_author": "Lu J.",
        "publication": "ACS Catalysis",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "With the advent of high-throughput methods for both computation and experimentation, data-rich approaches to discovering and understanding chemical reactions are becoming ever more central to catalysis research. Organopalladium catalysis is at the forefront of these new approaches, providing a rich proving ground for method development and validation. This critical Perspective discusses a number of recent case studies from academic and industrial laboratories that illustrate how to generate, analyze, and correlate large data sets for quantitative predictions of reactivity and selectivity. Both the power and potential pitfalls of these approaches are discussed, as are the opportunities for both practical predictions and fundamental mechanistic insights.",
        "affiliation_name": "University of Victoria",
        "affiliation_city": "Victoria",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine Learning-Supported Enzyme Engineering toward Improved CO<inf>2</inf>-Fixation of Glycolyl-CoA Carboxylase",
        "paper_author": "Marchal D.G.",
        "publication": "ACS Synthetic Biology",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Glycolyl-CoA carboxylase (GCC) is a new-to-nature enzyme that catalyzes the key reaction in the tartronyl-CoA (TaCo) pathway, a synthetic photorespiration bypass that was recently designed to improve photosynthetic CO2 fixation. GCC was created from propionyl-CoA carboxylase (PCC) through five mutations. However, despite reaching activities of naturally evolved biotin-dependent carboxylases, the quintuple substitution variant GCC M5 still lags behind 4-fold in catalytic efficiency compared to its template PCC and suffers from futile ATP hydrolysis during CO2 fixation. To further improve upon GCC M5, we developed a machine learning-supported workflow that reduces screening efforts for identifying improved enzymes. Using this workflow, we present two novel GCC variants with 2-fold increased carboxylation rate and 60% reduced energy demand, respectively, which are able to address kinetic and thermodynamic limitations of the TaCo pathway. Our work highlights the potential of combining machine learning and directed evolution strategies to reduce screening efforts in enzyme engineering.",
        "affiliation_name": "Max Planck Institute of Biophysics",
        "affiliation_city": "Frankfurt am Main",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Investigating Atmospheric Responses to and Mechanisms Governing North Atlantic Sea Surface Temperatures over 10-Year Periods",
        "paper_author": "Gu Q.",
        "publication": "Journal of Climate",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "North Atlantic sea surface temperature (SST) variability plays a critical role in modulating the climate system. However, characterizing patterns of North Atlantic SST variability and diagnosing the associated mechanisms is challenging because they involve coupled atmosphere–ocean interactions with complex spatiotemporal relationships. Here we address these challenges by applying a time-evolving self-organizing map approach to a long preindustrial coupled control simulation and identify a variety of 10-yr spatiotemporal evolutions of winter SST anomalies, including but not limited to those associated with the North Atlantic Oscillation–Atlantic multidecadal variability (NAO–AMV)-like interactions. To assess mechanisms and atmospheric responses associated with various SST spatiotemporal evolutions, composites of atmospheric and oceanic variables associated with these evolutions are investigated. Results show that transient-eddy activities and atmospheric circulation responses exist in almost all the evolutions that are closely correlated to the details of the SST pattern. In terms of the mechanisms responsible for generating various SST evolutions, composites of ocean heat budget terms demonstrate that contributions to upper-ocean temperature tendency from resolved ocean advection and surface heat fluxes rarely oppose each other over 10-yr periods in the subpolar North Atlantic. We further explore the potential for predictability for some of these 10-yr SST evolutions that start with similar states but end with different states. However, we find that these are associated with abrupt changes in atmospheric variability and are unlikely to be predictable. In summary, this study broadly investigates the atmospheric responses to and the mechanisms governing the North Atlantic SST evolutions over 10-yr periods.",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Transcriptional correlates of frequency-dependent brain functional activity associated with symptom severity in degenerative cervical myelopathy",
        "paper_author": "Guo X.",
        "publication": "NeuroImage",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Background: Neuroimaging techniques provide insights into the brain abnormalities secondary to degenerative cervical myelopathy (DCM) and their association with neurological deficits. However, the neural correlates underlying the discrepancy between symptom severity and the degree of spinal cord compression, as well as the transcriptional correlates of these cortical abnormalities, remain unknown in DCM patients. Methods: In this cross-sectional study, which collected resting-state functional MRI (rs-fMRI) images and the Japanese Orthopedic Association (JOA) score, enrolled 104 participants (54 patients and 50 healthy controls). The frequency-dependent amplitude of low-frequency fluctuation (ALFF) was obtained for all participants. We investigated the ALFF differences between mild-symptom DCM patients and severe-symptom DCM patients while carefully matching the degree of compression between these two groups via both univariate comparison and searchlight classification for three frequency bands (e.g., Slow-4, Slow-5, and Full-band). Additionally, we identified genes associated with symptom severity in DCM patients by linking the spatial patterns of gene expression of Allen Human Brain Atlas and brain functional differences between mild symptom and severe symptom groups. Results: (1) We found that the frequency-specific brain activities within the sensorimotor network (SMN), visual network (VN), and default mode network (DMN) were associated with the varying degrees of functional impairment in DCM patients; (2) the frequency-specific brain activity within the SMN correlated with the functional recovery in patients with DCM; (3) a spatial correlation between the brain-wide expression of genes involved in neuronal migration and the brain functional activities associated with symptom severity was identified in DCM patients. Conclusion: In conclusion, our study bridges gaps between genes, cell classes, biological processes, and brain functional correlates of DCM. While our findings are correlational in nature, they suggest that the neural activities of sensorimotor cortices in DCM are associated with the severity of symptoms and might be associated with neuronal migration within the brain.",
        "affiliation_name": "Cangzhou Central Hospital",
        "affiliation_city": "Cangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Associations between weekly gestational exposure of fine particulate matter, ozone, and nitrogen dioxide and preterm birth in a North Carolina Birth Cohort, 2003-2015",
        "paper_author": "Krajewski A.K.",
        "publication": "Environmental Epidemiology",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Background: Preterm birth (PTB; <37 weeks completed gestation) is associated with exposure to air pollution, though variability in association magnitude and direction across exposure windows exists. We evaluated associations between weekly gestational exposure to fine particulate matter (PM2.5), nitrogen dioxide (NO2), and ozone (O3) with PTB in a North Carolina Birth Cohort from 2003 to 2015 (N = 1,367,517). Methods: Daily average PM2.5and daily 8-hour maximum NO2concentration estimates were obtained from a hybrid ensemble model with a spatial resolution of 1 km2. Daily 8-hour maximum census tract-level concentration estimates for O3were obtained from the EPA's Fused Air Quality Surface Using Downscaling model. Air pollutant concentrations were linked by census tract to residential address at delivery and averaged across each week of pregnancy. Modified Poisson regression models with robust errors were used to estimate risk differences (RD [95% confidence intervals (CI)]) for an interquartile range increase in pollutants per 10,000 births, adjusted for potential confounders. Results: Associations were similar in magnitude across weeks. We observed positive associations for PM2.5and O3exposures, but generally null associations with NO2. RDs ranged from 15 (95% CI = 11, 18) to 32 (27, 37) per 10,000 births for PM2.5; from -7 (-14, -1) to 0 (-5, 4) for NO2; and from 4 (1, 7) to 13 (10, 16) for O3. Conclusion: Our results show that increased PM2.5exposure is associated with an increased risk of PTB across gestational weeks, and these associations persist in multipollutant models with NO2and/or O3.",
        "affiliation_name": "United States Environmental Protection Agency",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Fluid–structure interaction with a Finite Element–Immersed Boundary approach for compressible flows",
        "paper_author": "Morales F.A.P.",
        "publication": "Ocean Engineering",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "This paper presents the mathematical modeling and numerical simulations of fluid–structure interaction (FSI) problems. The fluid domain is discretized using a Cartesian block-structured mesh and solved using the Finite Volume Method (FVM), using the LES methodology with Smagorinsky turbulent closure model. The fluid flow in the system is considered compressible, with properties that vary. The Immersed Boundary Method (IBM) is used to model the solid–fluid interface, and the structure deformation was solved using the Finite Element Method (FEM). The Multi-direct Forcing Scheme is used to calculate the fluid-dynamics forces through the IBM. After calculating the fluid forces exerted on the solid, the forces are interpolated and transferred to the FEM model, providing the deformation of the structure at each time step. The structural domain was discretized with Hexahedral eight-noded element with extra shape functions. The simulations were carried out using MFSIm (in-house code), a multiphysics simulation framework developed by the Fluid Mechanics Laboratory of the Federal University of Uberlândia with financial support from Petrobras. This paper demonstrates the practical application of FSI analysis in an industrial context, specifically focusing on a pipeline system within a Fluid Catalytic Cracking Unit (FCCU) used in the oil and gas industry. The analysis involves the use of butterfly valves positioned at different angles of opening. The results are treated statistically, and a surface response is generated. Machine learning is employed to predict the surface response, showing the valve configurations that yield the maximum and minimum displacement magnitudes of the evaluated structural probes.",
        "affiliation_name": "Universidade Federal de Uberlândia",
        "affiliation_city": "Uberlandia",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "DoS attack detection using online learning techniques in wireless sensor networks",
        "paper_author": "Lai T.T.",
        "publication": "Alexandria Engineering Journal",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Wireless sensor network (WSN) models pose substantial security vulnerabilities since most WSNs are deployed in unattended hostile environments. This research focuses on denial-of-service (DoS) attack detection, a crucial problem in WSN security. Previous research has mostly focused on offline machine learning algorithms, which require long-term data collection and cannot continually adapt to new data. Online learning is thus more suitable for detecting DoS attacks in WSN due to the benefit of continuous improvement with fresh data. Nevertheless, existing online DoS attack detection algorithms do not take internal and external data interference into consideration. Thus, noisy data might have a negative effect on the performance of the model. Moreover, the data includes features that are redundant or unnecessary for the classification. Hence, the selection of proper features not only decreases computational time but also improves the performance of the model. This study proposes an online-learning-based approach for detecting DoS attacks in WSN. Specifically, a feature selection method is proposed to identify the most appropriate attributes for the training process. Furthermore, a noise-tolerant online passive-aggressive multi-class classifier is also developed. The performance of our proposed method is investigated in terms of accuracy, precision, recall, and F1-score, and it proves to be competitive.",
        "affiliation_name": "Soongsil University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Spatial subsetting enables integrative modeling of oral squamous cell carcinoma multiplex imaging data",
        "paper_author": "Einhaus J.",
        "publication": "iScience",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Oral squamous cell carcinoma (OSCC), a prevalent and aggressive neoplasm, poses a significant challenge due to poor prognosis and limited prognostic biomarkers. Leveraging highly multiplexed imaging mass cytometry, we investigated the tumor immune microenvironment (TIME) in OSCC biopsies, characterizing immune cell distribution and signaling activity at the tumor-invasive front. Our spatial subsetting approach standardized cellular populations by tissue zone, improving feature reproducibility and revealing TIME patterns accompanying loss-of-differentiation. Employing a machine-learning pipeline combining reliable feature selection with multivariable modeling, we achieved accurate histological grade classification (AUC = 0.88). Three model features correlated with clinical outcomes in an independent cohort: granulocyte MAPKAPK2 signaling at the tumor front, stromal CD4+ memory T cell size, and the distance of fibroblasts from the tumor border. This study establishes a robust modeling framework for distilling complex imaging data, uncovering sentinel characteristics of the OSCC TIME to facilitate prognostic biomarkers discovery for recurrence risk stratification and immunomodulatory therapy development.",
        "affiliation_name": "Stanford University School of Medicine",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Machine Learning-Based Online Human Motion Recognition System With Multiple Classifier for Exoskeleton",
        "paper_author": "Yan L.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Motion recognition and classification are crucial for exoskeleton applications in rehabilitation, activities of daily living (ADL), and entertainment. Accurate activity analysis is essential to improve human-machine coupling. However, conventional single-task detection systems, which focus on specific requirements, such as finite gait events, mode transitions (such as standing-to-sitting), or locomotion speed, are inadequate and cannot handle the complex and varied walking environments encountered during ADL. This article proposes a real-time, multiclassifier system that incorporates three artificial neural network (ANN) models to simultaneously recognize five gait events, nine activities, and walking speeds ranging from 0 to 8 km/h. Three machine-learning (ML) algorithms were fused and utilized to minimize reliance on manual thresholding methods. The activity detection, speed recognition, and gait detection were performed using a 1-dimension convolutional neural network (1-D-CNN), regression ANN (RANN), and multilayer perceptron (MLP), respectively. The experiment was conducted with five subjects wearing a developing cable-driven exoskeleton. The results demonstrate that the proposed portable motion recognition system accurately detected various movements, including gait events with 99.6% accuracy and a time error of 33 ms, a recognize speed with a mean square error (MSE) of 0.12, and an activity detection with 96.8% accuracy.",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Spectral Graph Wavelet Transform-Based Feature Representation for Automated Classification of Emotions From EEG Signal",
        "paper_author": "Krishna R.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "Electroencephalogram (EEG) monitors the brain’s electrical activity and carries useful information regarding the subject’s emotional states. Due to the nonstationary and being complex in nature, proper signal-processing techniques are necessary to get meaningful interpretations. The EEG signal has been represented using a graph by incorporating the temporal dependency. In this article, a novel feature based on spectral graph wavelet transform (SGWT) for representing EEG signals has been proposed by considering the interdependency among different samples of EEG signals. SGWT is effective in finding multiscale information at the local level as well as the global level. These multiscale representations allow for the extraction of information about the EEG signal at different scales. The SGWT coefficients are used to develop machine-learning classifiers for emotion identification. Principal component analysis (PCA) is also used for feature reduction. The proposed framework is evaluated based on a publicly available SEED dataset with the help of extensive experiments. The k-nearest neighbor (KNN) classifier provides 97.3% accuracy with a standard deviation of 1.2%. The SGWT-based representation has achieved 12.7% higher accuracy compared to the raw EEG signal, which shows the usefulness of the proposed approach. Our model for emotion recognition attains superior classification performance compared to state-of-the-art methods. Finally, the investigation of interdependency among the samples of EEG signals reveals that the SGWT-based representation of EEG signals is a useful tool for analyzing EEG signals.",
        "affiliation_name": "Indian Institute of Technology Indore",
        "affiliation_city": "Indore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Artificial intelligence-based optimized models for predicting the slump and compressive strength of sustainable alkali-derived concrete",
        "paper_author": "Zou B.",
        "publication": "Construction and Building Materials",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "Alkali-activated materials (AAMs) are a potential class of construction materials that are well-known for their versatility and capacity for long-term sustainability. As a result of its ability to lessen the negative effects that the building industry has on the environment, AAMs have become increasingly popular in recent years. However, it can be difficult and time-consuming to figure out what proportions of alkali-activated concrete (AAC) would work best for a given project. Compressive strength (CS) and slump, both of which are important properties of AAC's viability in construction, were predicted using machine learning (ML) techniques, such as multi-expression programming (MEP) and gene expression programming (GEP) in this study. The mathematical formulations of AAC for both slump and CS for the AAC were effectively derived with the application of these ML approaches. According to the study's findings, MEP models performed better than GEP models in making accurate predictions, with MEP achieving R2 values of 0.92 and 0.93 for slump and CS in AAC, respectively, whereas GEP provided R2 values of 0.86 and 0.89. The hyper-parameters of the AI models were fine-tuned, and the models were verified with statistical measurements and Taylor diagrams. It's possible that using the findings from sensitivity analysis to estimate the relative importance of factors impacting the slump and CS of AAC might be helpful. The artificial intelligence-based models that were built showed a strong connection with the desired outcomes, suggesting that they might be used to estimate the slump and CS of AAC for different values of the input components.",
        "affiliation_name": "China University of Mining &amp; Technology, Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Flood susceptibility mapping to improve models of species distributions",
        "paper_author": "Ebrahimi E.",
        "publication": "Ecological Indicators",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "As significant ecosystem disturbances flooding events are expected to increase in both frequency and severity due to climate change, underscoring the critical need to understand their impact on biodiversity. In this study, we employ advanced remote sensing and machine learning methodologies to investigate the effects of flooding on biodiversity, from individual species to broader ecological communities. Specifically, we utilized Sentinel-1 synthetic aperture radar (SAR) images and an ensemble of machine-learning algorithms to derive a flood susceptibility indicator. Our primary objective is to investigate the potential benefits of incorporating flood susceptibility, as a proxy for flood risk, into species distribution models (SDMs). By doing so, we aim to improve the performance of SDMs and gain deeper insights into the consequences of floods to biodiversity. Within the biodiverse landscape of the Zagros Mountains, a crucial Irano-Anatolian biodiversity hotspots, we examined the sensitivity of mammals, amphibians, and reptiles’ distributions to flooding. Our analysis compared the performance of models that combined flood susceptibility with climate variables against models relying solely on climate variables. The results indicate that the inclusion of flood susceptibility significantly improves the capacity of models to explain and map species distributions for 67% of the species in our study region. Notably, amphibians and mammals are more profoundly affected by flooding compared to reptiles. The study highlights the importance of incorporating flood susceptibility as a predictor variable in species distribution models to improve the baseline characterization of potential species distributions. The importance of this variable will obviously depend on the regional context and the species studied but its relevance is likely to increase with climate change. In summary, our research demonstrates the integration of remote sensing and machine learning as a potent approach to advance biodiversity data science, monitoring, and conservation in the face of climate-induced flooding.",
        "affiliation_name": "Shahid Beheshti University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Predicting and extracting thermal behavior rules of hydronic thermal barrier with interpretable ensemble learning in the heating season",
        "paper_author": "Guo J.",
        "publication": "Energy and Buildings",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Hydronic thermal barrier (HTB) creates dynamic thermal resistance in buildings, enabling buildings to adapt to outdoor weather fluctuations and regulate indoor environments. However, the lack of a comprehensive model to predict thermal behavior and explain the underlying rules is a significant limitation to its real-life situations. Additionally, the high computational cost of traditional numerical modelling also poses a challenge. To address these issues, this study proposed a framework for predicting HTB thermal behavior and extracting rules. A benchmark model was first introduced that incorporates coupled physical fields and accounts for multi-source uncertainties, reducing rule failures resulting from system changes. A data-driven prediction model was then developed, using machine learning and the finite element method, to clarify thermal behavior during the heating season in cold and severely cold regions of China. To enhance model generalization and applicability, three typical feature selection methods were employed. A comprehensive trial involving five ensemble learning models was conducted. Recursive Feature Elimination (RFE) selected the most representative features for prediction models. For heat storage efficiency, RFE combined with Light Gradient Boosting Machine achieved the best prediction performance with an R2 of 0.877, while the optimal prediction model for exergy efficiency was developed by combining RFE with Categorical Boosting with an R2 of 0.782. Finally, the profound HTB thermal behavior rules were extracted by the Shapley Additive exPlanation framework from both global and individual perspectives. Taken together, these findings can serve as a reference for the practical design and operation management of HTB.",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Syracuse",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modeling and optimization of oil adsorption capacity on functionalized magnetic nanoparticles using machine learning approach",
        "paper_author": "Hamedi H.",
        "publication": "Journal of Molecular Liquids",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Using magnetic nanoparticles (MNPs) has emerged as a promising solution to capture oil from emulsified oily wastewater due to their high oil adsorption capacity, low toxicity, and reusability. Various factors affect the oil adsorption process using MNPs; thus, optimization of the process is required to achieve higher oil adsorption capacity. Smart models based on artificial intelligence (AI) are becoming popular as advanced computational tools to assess the non-linear relationships of variables in complex processes. In this study, least squares support vector machines (LSSVM) hybridized with the coupled simulated annealing (CSA) algorithm, adaptive network-based fuzzy inference system (ANFIS), and optimization techniques such as gene expression programming (GEP) are used to predict the oil adsorption capacity as a target variable. Oil concentration, mixing time, and MNP dosage as effective parameters are selected as input variables. After conducting experiments, 149 data points are obtained, 80 % of which is used in the training process and the remaining 20 % for the testing step. The performances of the developed models are evaluated using statistical parameters, including the coefficient of determination (R2), mean percentage error (MPE), and mean absolute percentage error (MAPE). According to the results, ANFIS and LSSVM-CSA models have a better performance than the GEP model in estimating the oil adsorption capacity with higher values of R2 (>0.99) and smaller relative errors (close to zero) for all training, testing, and total datasets. Detailed model evaluation and error analysis indicate that the LSSVM-CSA model predicts slightly better than ANFIS with the highest R2 of 0.9921 and a very small MAPE = 3.7597 % over the total dataset. Although the developed GEP model shows an acceptable prediction with R2 > 0.95, the higher distribution of relative errors of the developed model results in a larger MAPE. Moreover, the GEP model computational time is considerably greater than that of the other models. The relative importance analysis using Pearson's and Spearman's correlation coefficients indicates that the oil concentration and MNP dosage are the most influential variables that affect the oil adsorption capacity.",
        "affiliation_name": "Memorial University of Newfoundland",
        "affiliation_city": "St John's",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Development of a whole-slide-level segmentation-based dMMR/pMMR deep learning detector for colorectal cancer",
        "paper_author": "Tong Z.",
        "publication": "iScience",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "To investigate whole-slide-level prediction in the field of artificial intelligence identification of dMMR/pMMR from hematoxylin and eosin (H&E) in colorectal cancer (CRC), we established a segmentation-based dMMR/pMMR deep learning detector (SPEED). Our model was approximately 1,700 times faster than that of the classification-based model. For the internal validation cohort, our model yielded an overall AUC of 0.989. For the external validation cohort, the model exhibited a high performance, with an AUC of 0.865. The human‒machine strategy further improved the model performance for external validation by an AUC up to 0.988. Our whole-slide-level prediction model provided an approach for dMMR/pMMR detection from H&E whole slide images with excellent predictive performance and less computer processing time in patients with CRC.",
        "affiliation_name": "The Second Affiliated Hospital Zhejiang University School of Medicine",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Data driven performance prediction of titanium-based matrix composites",
        "paper_author": "Wu X.",
        "publication": "Alexandria Engineering Journal",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Titanium matrix composites (TMCs) offer superior specific mechanical properties compared to monolithic alloys. However, the complex interdependent effects of composition and processing on the resulting microstructure and properties make experimental determination of optimal TMC formulations challenging. This work explored a materials informatics approach integrating machine learning (ML) modeling with targeted fabrication and characterization for accelerated data-driven design of TMCs. A dataset of 368 data points on composition, processing method and mechanical properties of various TMCs was compiled from literature. Five ML regression algorithms were implemented to predict density, hardness and strength from composition-processing features. Among the models, random forest achieved highest accuracy with R2 scores above 0.93 and low errors. Fabrication of Ti-6Al-4 V/SiC using ML-guided parameters showed excellent agreement between predicted and experimentally measured properties. The ML models outperformed conventional empirical predictions by learning complex structure-property linkages from data. This integrated computational-experimental framework can guide rapid identification of property-optimized TMC formulations by reducing trial-and-error. Further work should focus on physics-based feature engineering and active learning. The data-driven approach demonstrated here shows promise for accelerating development of high-performance TMCs.",
        "affiliation_name": "Guangzhou College of Commerce",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Information integration during bioelectric regulation of morphogenesis of the embryonic frog brain",
        "paper_author": "Manicka S.",
        "publication": "iScience",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Spatiotemporal patterns of cellular resting potential regulate several aspects of development. One key aspect of the bioelectric code is that transcriptional and morphogenetic states are determined not by local, single-cell, voltage levels but by specific distributions of voltage across cell sheets. We constructed and analyzed a minimal dynamical model of collective gene expression in cells based on inputs of multicellular voltage patterns. Causal integration analysis revealed a higher-order mechanism by which information about the voltage pattern was spatiotemporally integrated into gene activity, as well as a division of labor among and between the bioelectric and genetic components. We tested and confirmed predictions of this model in a system in which bioelectric control of morphogenesis regulates gene expression and organogenesis: the embryonic brain of the frog Xenopus laevis. This study demonstrates that machine learning and computational integration approaches can advance our understanding of the information-processing underlying morphogenetic decision-making, with a potential for other applications in developmental biology and regenerative medicine.",
        "affiliation_name": "Tufts University",
        "affiliation_city": "Medford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Combining spectroscopy and machine learning for rapid identification of plastic waste: Recent developments and future prospects",
        "paper_author": "Yang J.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "Recycling and utilization of plastic waste are receiving more and more attention, and the combination of spectroscopic techniques and machine learning is expected to solve the problem of efficiently identifying and classifying plastic waste at the front end of high-value recycling. Currently, the spectroscopic techniques used for plastic waste classification include near-infrared (NIR) spectroscopy, mid-infrared (MIR) spectroscopy, Raman spectroscopy, laser-induced breakdown spectroscopy (LIBS), X-ray fluorescence (XRF) spectroscopy, terahertz (THz) spectroscopy, etc., and the machine methods combined with them include traditional machine methods and deep learning methods. This paper mainly summarizes the research progress in the application of spectroscopic techniques combined with machine learning in the rapid identification of plastic waste in the past five years, focusing on the innovative research of machine learning methods in plastic identification, the relative advantages and disadvantages of various spectroscopic techniques, and the influencing factors of spectroscopic techniques in plastic identification. In addition, this paper describes the application of spectroscopic instrumentation in the plastic waste recycling industry. In the end, the paper presents an outlook on the future trajectory and potential of this field and proposes recommendations for its advancement in three key dimensions: spectroscopy, machine learning algorithms, and practical engineering applications.",
        "affiliation_name": "Research Institute of Petroleum Processing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting stroke and myocardial infarction risk in Takayasu arteritis with automated machine learning models",
        "paper_author": "Lu Y.T.",
        "publication": "iScience",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Few models exist for predicting severe ischemic complications (SIC) in patients with Takayasu arteritis (TA). We conducted a retrospective analysis of 703 patients with TA from January 2010 to December 2019 to establish an SIC prediction model for TA. SIC was defined as ischemic stroke and myocardial infarction. SIC was present in 97 of 703 (13.8%) patients with TA. Common iliac artery, coronary artery, internal carotid artery, subclavian artery, vertebral artery, renal artery involvement, chest pain, hyperlipidemia, absent pulse, higher BMI, vascular occlusion, asymmetric blood pressure in both upper limbs, visual disturbance, and older age were selected as predictive risk factors. Considering both discrimination and calibration performance, the Weighted Subspace Random Forest model was the most optimal model, boasting an area under the curve of 0.773 (95% confidence interval [0.652, 0.894]) in the validation cohort. Effective models for predicting SIC in TA may help clinicians identify high-risk patients and make targeted interventions.",
        "affiliation_name": "Fuwai Hospital, Chinese Academy of Medical Sciences &amp; Peking Union Medical College",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Development of a Machine Learning Framework Based on Occupant-Related Parameters to Predict Residential Electricity Consumption in the Hot and Humid Climate",
        "paper_author": "Qavidel Fard Z.",
        "publication": "Energy and Buildings",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Occupant-related variables constitute one of the most significant groups of factors influencing residential building energy consumption. However, prediction methods often oversimplify these parameters, leading to substantial discrepancies between predicted and actual consumption. To address this issue, the present study aims to develop a machine learning framework for predicting electricity consumption in residential buildings based on occupant-related factors. The study incorporates twenty-six inputs, including occupant characteristics such as demographics, occupancy, behavior, and behavioral efficiency, two time-related factors, and three extra parameters related to equipment (refrigerator age, hot water source, and type of electricity meter) for training and testing the Random Forest (RF) algorithm in both regression and classification forms. The results indicate that the trained RF regressor exhibits well performance (R2Train = 0.989, R2Test = 0.916, MAETrain = 0.81, MAETest = 2.21, RMSETrain = 1.27, and RMSETest = 3.45). Furthermore, feature importance analysis reveals that the most significant parameter is the time of year, representing weather conditions, followed by the number of occupants, neighborhood, indoor set-point range, mean age of occupants, window opening, and cooling system mode. Even after removing the least impactful factors, the model maintains strong performance with the 16 most important variables (R2Train = 0.986, R2Test = 0.910, MAETrain = 0.83, MAETest = 2.25, RMSETrain = 1.31, and RMSETest = 3.49). Additionally, the RF classifier is designed for problems with 2, 4, 6, and 8 classes based on energy consumption ranges. The results of this model demonstrate that the 2-class model achieves the highest performance (AccuracyTest = 0.963, MAETest = 0.04, and RMSETest = 0.19). However, it lacks detailed categorization of homes based on electricity consumption. On the other hand, the 4-class and 6-class models strike a good balance between prediction performance and the level of detail. In conclusion, the proposed method can accurately predict residential electricity consumption and can serve as a valuable reference for researchers and utility managers when formulating energy reduction policies and comparing the effectiveness of different strategies.",
        "affiliation_name": "Shahid Beheshti University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Advancing COP26 climate goals: Leveraging energy innovation, governance readiness, and socio-economic factors for enhanced climate resilience and sustainability",
        "paper_author": "Sarkodie S.A.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Climate change adaptation and mitigation remain critical to achieving sustainable development while reducing climate vulnerability, particularly among climate-exposed and sensitive regions. Yet, achieving a balance between climate-resilience pathways, high economic productivity, high human development, and energy efficiency appears complex, leading to potential trade-offs. Here, we examine the overarching effect of the diversified energy portfolio, socio-economic drivers, and governance adaptation readiness on Climate change vulnerability across 212 economies. Contrary to the poor conventional panel techniques reported in the existing literature, we employ novel machine learning and dynamic panel estimation techniques that control for chaos, nonlinearity, mutual coupling, and heterogeneity in dynamic systems. The convergent cross-mapping causality technique reveals mutual coupling effects between energy portfolio, governance readiness, socio-economic drivers, and climate change vulnerability. The rapidly increasing population and increasing demand for resources under the business-as-usual society and economic structure that normalizes unsustainable development pathways due to weak governance structures create ineffective climate-resilient policies that lead to unabated emissions with consequences on climate change. The effect of social and governance readiness leads the transformation process to attain sustainable development. Thus, high social and governance readiness spurs climate resilience through climate change adaptation and mitigation to achieve sustainable development. Alternative (renewables) and nuclear energy have displacement effects on fossil fuels, yet, the magnitude of displacement is not large enough to replace future fossil fuel consumption. Conversely, a low-carbon future is still attainable by replacing the fossil energy portfolio with more natural gas and carbon-abatement technologies. Our study demonstrates that energy innovations are useful climate-resilience pathways that lessen climate change vulnerability.",
        "affiliation_name": "Nord Universitet",
        "affiliation_city": "Bodo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Machine-learning-assisted wearable PVA/Acrylic fluorescent layer-based triboelectric sensor for motion, gait and individual recognition",
        "paper_author": "Zhang D.",
        "publication": "Chemical Engineering Journal",
        "citied_by": "13",
        "cover_date": "2023-12-15",
        "Abstract": "Flexible sensors with precise perception ability play an important role in environmental sensing. The organic fusion between the sensitive structure and sensitive material presents some challenges for the overall design and integration of the sensor, including designing multiple sensitive branch structures, simplifying system design, and sensing multiple stress modes. Here, based on a same-plane interdigital electrode design, we developed a triboelectric sensor and its array (TSA) that mimics the synaptic structure of a neural cell. The interdigital electrode structure can effectively simulate the synaptic structure of neural cells and achieve effective perception of multi-directional stress. The enhancement of the triboelectric effect is achieved through layer-by-layer self-assembly technology between PVA film and acrylic fluorescent layer. The interface effect between PVA film and acrylic fluorescent layer can effectively enhance the electrostatic effect. Further analysis with deep learning CNN can extract higher-level motion features. A single sensor can be used to identify which part of the body is producing the movement (98.89%). A TSA with different numbers of sensors can achieve high-precision recognition of gesture numbers (99.25%), foot shape, gait (99.23%), and individuals (99.75%). The sensor can be flexibly manufactured and integrated according to specific application scenarios. The long-term goal is to effectively help limb-injured patients with rehabilitation therapy and build intelligent home environment.",
        "affiliation_name": "China University of Petroleum (East China)",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "First-generation themed article collections",
        "paper_author": "Bajorath J.",
        "publication": "Artificial Intelligence in the Life Sciences",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Meteorological drought assessment in northern Bangladesh: A machine learning-based approach considering remote sensing indices",
        "paper_author": "Sadiq M.A.",
        "publication": "Ecological Indicators",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "Meteorological drought, driven by inadequate precipitation, has significant repercussions for water resources, agriculture, and human well-being. This study conducted an extensive assessment of meteorological drought in northern Bangladesh, employing remote sensing indices and machine learning techniques. The main aim was to evaluate meteorological drought occurrences in northern Bangladesh from 2010 to 2019, utilizing seven drought parameters and a machine learning model. Utilizing a Random Forest (RF) model, this study employed the Standardized Precipitation Index (SPI) as the dependent variable and seven remote sensing indices as independent variables. Through this methodology, the study assessed the significance of these indices generated by the model and integrated them, culminating in the creation of a meteorological drought distribution map spanning 2010 to 2019. This approach offers novel insights by probing the interplay and collective impacts of these indices, shedding light on previously unexplored aspects of regional drought patterns of northern Bangladesh. The major findings showed that precipitation strongly influenced both short-term and long-term meteorological drought episodes. Moreover, land surface-related indices, such as Evapotranspiration (ET) and Normalized Difference Water Index (NDWI), exhibited a more pronounced impact on short-term drought occurrences, while vegetation-related indices like Normalized Multi-band Drought Index (NMDI) and Normalized Difference Vegetation Index (NDVI) demonstrated greater influence over long-term drought events. During this timeframe, the Rajshahi division experienced frequent extreme and severe drought events. Moderate droughts and abnormally dry conditions were widespread. The Barind tract area consistently faced moderate to extreme droughts, with exceptions in 2011, 2014, and 2019. On average, over 5% of the region had extreme droughts, while more than 12% experienced severe droughts during this decade. Long-term drought indicators (SPI 6 and SPI 9) consistently showed higher frequencies of extreme and severe droughts compared to short-term indicators (SPI 1 and SPI 3), emphasizing the influence of prolonged rainfall deficits on extreme droughts and the relevance of longer time frames for severe drought dynamics. The RF model demonstrated strong performance with accuracy ranging from 81% to 95%. Low prediction errors (RMSE 6% to 31%) and high out-of-bag (OOB) accuracy ranging from 76% to 98% highlighted its accuracy. The F1 score consistently exceeded 76%, indicating high precision and recall. Cross-validation values ranged from 78% to 94%, affirming reliable generalization to new data. Incorporating the main findings, this study contributes valuable insights for the formulation of targeted drought mitigation strategies in northern Bangladesh. It is imperative to note that the scope of this study is confined to the northern region of Bangladesh, and generalizing these findings to other regions should be exercised with caution. Nevertheless, the research methodology and approach can serve as a model for future studies in related fields, advancing knowledge of how to assess droughts using remote sensing and machine learning methods.",
        "affiliation_name": "Khulna University of Engineering and Technology",
        "affiliation_city": "Khulna",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Forecasting unconfined compressive strength of calcium sulfoaluminate cement mixtures using ensemble machine learning techniques integrated with shapely-additive explanations",
        "paper_author": "Balasooriya Arachchilage C.",
        "publication": "Construction and Building Materials",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "Calcium sulfoaluminate (CSA) cement mixture design is challenging due to the influence of multiple features on its unconfined compressive strength (UCS). Consequently, the relationships between input features and the UCS exhibit non-linear behavior, making it difficult to understand using experimental methods alone. Therefore, for the first time, this study constructed non-linear ensemble machine learning (ML) models on a dataset compiled from experimental literature to accurately predict the UCS of CSA cement mixtures. After applying feature selection techniques, four different ensemble models were built on the modified datasets to predict the UCS. The extreme gradient boosting model built on the dataset modified by the least absolute shrinkage and selection operator method achieved the best prediction accuracy (coefficient of determination; R2 = 0.95) on testing data. Finally, the SHapely Additive exPlanations analysis could interpret the selected ML model both quantitatively and qualitatively, by explaining the independent relationships between each input feature and UCS.",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A new binary object-oriented programming optimization algorithm for solving high-dimensional feature selection problem",
        "paper_author": "Khalid A.M.",
        "publication": "Alexandria Engineering Journal",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Feature selection (FS) is a crucial task in machine learning applications, which aims to select the most appropriate feature subset while maintaining high classification accuracy with the minimum number of selected features. Despite the widespread usage of metaheuristics as wrapper-based FS techniques, they show reduced effectiveness and increased computational cost when applied to high-dimensional datasets. This paper presents a novel Binary Object-Oriented Programming Optimization Algorithm (BOOPOA) for FS of high dimensional datasets, where the Object-Oriented Programming Optimization Algorithm (OOPOA) is a novel optimization technique inspired by the inheritance concept of Object-Oriented programming (OOP) languages. The effectiveness of this method in solving high dimensional FS problems is validated by using 26 datasets, most of which are of high dimension (large number of features). Seven existing FS algorithms are compared with the proposed OOPOA using various metrics, including best fitness, average fitness (AVG), selection size, and computational time. The results prove the superiority of the proposed algorithm over the other FS algorithms, having an average performance of %92.5, 0.078, 0.084, %38.9, and 8.6 min for classification accuracy, best fitness, average fitness, size reduction ratio, and computational time. The outcomes demonstrate the proposed FS approach's superiority over currently used methods.",
        "affiliation_name": "Faculty of Computers and Information",
        "affiliation_city": "Zagazig",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Sonoelectrochemical system mechanisms, design, and machine learning for predicting degradation kinetic constants of pharmaceutical pollutants",
        "paper_author": "Zhou Y.",
        "publication": "Chemical Engineering Journal",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "This study explores the mechanism, design, and application of machine learning in the sonoelectrochemical (US-EC) systems and select ibuprofen (IBP) as the target pollutant. Mechanism investigation shows that [rad]OH and S O4·- are the primary chemical oxidation species through scavenger experiments. Based on the heterogeneous nucleation mechanism, the electrodes in the ultrasound (US) system play the role of electrode-sonocataliytic and can promote the degradation kinetic constant of pharmaceutical pollutants. The effects of design parameters, including US frequency, voltage, electrolyte, electrode area, gap, and position on IBP degradation were investigated. The results demonstrated that under optimized parameters: US frequency of 35 kHz, voltage of 5 V, 0.1 M Na2SO4 electrolyte, 1.5 cm gap, and placement at P8, the US-EC system achieved a kinetic constant of 0.016 min−1. Chemiluminescence was used to visualize the spatial distribution of the oxidant, and provided theoretical support for mechanism and design parameter optimization. The eXtreme Gradient Boosting model was used to predict the kinetic constant of pharmaceutical contaminants including IBP, indicating excellent model performance with results of R2 and RMSE reaching 0.98 and 0.0005, respectively. SHapley Additive exPlanations was employed to assess the impact of design parameters on pharmaceutical pollutants degradation. The results showed that US frequency, US power, and the distance 'r' from the US transmitter to the anode have the most significant impact on the prediction performance of the model. Two sets of new experiments were verified using this model, and the prediction accuracy reached 76% and 82% respectively, demonstrating that machine learning can effectively predict the kinetic constants of pharmaceutical contaminants under complex factors affecting the US-EC system, assisting researchers in swiftly evaluating the system's pollutant treatment performance and simplifying the experimental workload.",
        "affiliation_name": "Korea University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A machine learning and directed network optimization approach to uncover TP53 regulatory patterns",
        "paper_author": "Triantafyllidis C.P.",
        "publication": "iScience",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "TP53, the Guardian of the Genome, is the most frequently mutated gene in human cancers and the functional characterization of its regulation is fundamental. To address this we employ two strategies: machine learning to predict the mutation status of TP53 from transcriptomic data, and directed regulatory networks to reconstruct the effect of mutations on the transcipt levels of TP53 targets. Using data from established databases (Cancer Cell Line Encyclopedia, The Cancer Genome Atlas), machine learning could predict the mutation status, but not resolve different mutations. On the contrary, directed network optimization allowed to infer the TP53 regulatory profile across: (1) mutations, (2) irradiation in lung cancer, and (3) hypoxia in breast cancer, and we could observe differential regulatory profiles dictated by (1) mutation type, (2) deleterious consequences of the mutation, (3) known hotspots, (4) protein changes, (5) stress condition (irradiation/hypoxia). This is an important first step toward using regulatory networks for the characterization of the functional consequences of mutations, and could be extended to other perturbations, with implications for drug design and precision medicine.",
        "affiliation_name": "Università Bocconi",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Smart SO<inf>2</inf> Sensor Based on Cs<inf>3</inf>Cu<inf>2</inf>I<inf>5</inf>@Fe<inf>2</inf>O<inf>3</inf> Nanocrystals for Eliminating Humidity Interference",
        "paper_author": "Zhuang Y.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Sulfur dioxide is a colorless gas with strong pungent odor, and prolonged inhalation can damage the respiratory system and heart. Precise measurement of sulfur dioxide is very important for the human health. While the current sulfur dioxide sensor works at a high temperature and is easily interfered by humidity. Therefore, in this work, we used a solution method to coat perovskite nanocrystals Cs3Cu2I5 with metal oxides Fe2O3 and obtained the room-temperature sulfur dioxide gas-sensitive materials Cs3Cu2I5@Fe2O3 nanocrystals. Meanwhile, combined with machine learning, the sensor has the ability of self-calibrating under different humidity environment, realizing the high precision and anti-interference measurement of sulfur dioxide. In addition, in this structure, the coating Fe2O3 not only helps to improve water stability but also transfers the interaction of sulfur dioxide to the inner Cs3Cu2I5 and lowers the gas-sensitive temperature to room temperature. The response/recovery time of the sulfur dioxide sensor based on Cs3Cu2I5@Fe2O3 is 31/816 s, and the sensitivity is 0.19 at 10 ppm. Then, intelligent classification algorithm was used for recognition, and the accurate recognition rate was up to 95.0%. Furthermore, density functional theory (DFT) was implemented to reveal the gas-sensitive mechanism that sulfur dioxide was adsorbed by Cs3Cu2I5@Fe2O3 nanocrystals, the good response was attributed to the band structure changes significantly, and the hybridization of electron orbitals was appeared between gas and nanocrystals. We believe that the sensor will have potential in sulfur dioxide, and the idea of using machine learning to intelligent eliminate humidity interference can also be extended to other gas sensor.",
        "affiliation_name": "China University of Mining and Technology",
        "affiliation_city": "Xuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Multiweight Adversarial Open-Set Domain Adaptation Network for Machinery Fault Diagnosis With Unknown Faults",
        "paper_author": "Wang R.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Domain adaptation (DA) methods have proven successful in addressing the domain-shift challenge in rotating machinery fault diagnosis, and the basic tasks that the fault categories of source and target domains are identical have been well achieved. However, machine failures in the industry often unpredictably happen, which gives rise to a more challenging task called cross-domain open-set fault diagnosis (COFD). To tackle this task, a novel multiweight adversarial open-set DA network is proposed in this article. The proposed network uses the adversarial learning strategy to eliminate the marginal distribution discrepancy between source samples and shared-class target samples, thus ensuring that the generalization features across domains are learned. A weighted learning module combining the class-level with domain-level discriminative information is constructed to evaluate the similarity between target samples and the source classes, which adaptively assign larger weights for target shared classes and smaller weights for target private classes. An outlier classifier is established to perform pseudolabel learning on target samples, making the decision boundary between shared and outlier classes robust. Experiments on two cases with several open-set diagnostic tasks demonstrate that the proposed method is a potential tool for detecting new faults in mechanical devices.",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Human Lower Limb Motion Intention Recognition for Exoskeletons: A Review",
        "paper_author": "Li L.L.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "Human motion intention (HMI) has increasingly gained concerns in lower limb exoskeletons (LLEs). HMI recognition (HMIR) is the precondition for realizing active compliance control in LLEs. Accurate and efficient recognition of the HMI will benefit the LLEs achieving natural and effective human-robot interaction (HRI) and improving the wearing comfort level. A systematic review of HMIR is of great significance in developing LLEs. However, there is no literature comprehensively describing the development roadmap of the human lower limb motion intention recognition (HLLMIR) in the LLEs so far. In order to have a comprehensive understanding of the HLLMIR and explore the current research status and development trend of LLEs, this article provides a systematic review of the HLLMIR research for LLEs. First, the HMI mechanism and understanding are fully illustrated, and the HMIR tasks pertaining to lower limb motions (LLMs) are elaborated on. Next, the intention-related sensing signals with different sources are dissected in detail, including bioelectric signals of electroencephalography (EEG) and electromyogram (EMG), biomechanical signals, and multisource signals fusion. The HMIR methods for the LLEs are thoroughly addressed and analyzed, the methods are categorized as model-based, such as the musculoskeletal model and the model-free method involving heuristic rule-based, conventional machine learning (ML)-based, and deep learning (DL)-based. Finally, an overall discussion on the recognition tasks, sensing signals, recognition methods, and performance assessments is given, and thus, the research challenges of the HLLMIR are summarized and prospected.",
        "affiliation_name": "Shenzhen University",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "IRT-SD-SLE: An Improved Real-Time Step Detection and Step Length Estimation Using Smartphone Accelerometer",
        "paper_author": "Sadhukhan P.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Smartphone sensor-based pedestrian dead reckoning (PDR) systems provide a viable solution to the problem of localization in an infrastructure-less area. Step detection (SD) and step length estimation (SLE), being two fundamental operations of the PDR-based localization technique, have drawn many researchers' attention in the recent time. Most of the existing SD and SLE methods proposed over the years, however, provide either server-or cloud-based solution that consume additional network bandwidth and suffer from increased transmission delay. Moreover, nonavailability of the inertial sensors like gyroscope, magnetometers, etc., at every smartphone makes majority of the existing SLE methods less applicable to such devices. To address the above-said issues, in this article, we focus on devising an improved SLE method that would detect the pedestrian's steps and subsequently estimate the step length in real-time by processing the accelerometer data at the device itself. Our proposed method transforms the measured acceleration values along the Earth coordinate system (ECS) and also applies sliding window meaning (SWM) to mitigate the negative effects of the smartphone's orientation and gravitational bias on the accuracy of SD and SLE. The performances of our proposed method are evaluated in terms of accuracy for ten different users by taking the device in two different postures (handheld and trouser pocket) under two different walking modes (normal and fast) to demonstrate its efficacy. Moreover, our proposed method obtains more than 80% average accuracy for SD and also obtains more than 75% accuracy (median) for SLE for all participants under four different scenarios considered here.",
        "affiliation_name": "Xi'an Jiaotong-Liverpool University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Path Loss Estimation and Jamming Detection in Hybrid RF-VLC Vehicular Networks: A Machine-Learning Framework",
        "paper_author": "Ullah A.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Emerging vehicle-to-everything (V2X) networks employ machine-learning (ML) techniques to provide adaptive, reliable, secure, and low-latency communication. Previously proposed fitting-based path loss and rule-based jamming detection schemes in vehicular networks lack accuracy due to the highly mobile and complex vehicular environment. Standalone ML models are utilized for different regression and classification problems in vehicular networks; however, these models still provide limited accuracy in the case of limited datasets. This article proposes a hybrid learning framework for jamming detection and path loss predictions based on the successive usage of multiple deep neural network (DNN) blocks, in which each block extends the feature set of the succeeding block for efficient and fast learning. The proposed hybrid DNN model for jamming detection comprises three DNN blocks, that is, a multilayer perceptron (MLP) block and two sequential learning blocks with bidirectional LSTM and gated recurrent unit (GRU) layers. Similarly, for path estimation, the proposed hybrid model includes one MLP block followed by two bagged tree-based learning blocks. The proposed models for jamming and path loss prediction are trained and tested on a real-world dataset. In the IEEE 802.11p link, the proposed hybrid model has been demonstrated to classify injected jamming signals with a significantly improved accuracy of 90.4% compared to existing benchmarks, including the random forest (RaFo) classifier and the deep convolutional neural network (DCNN). Similarly, the proposed hybrid DNN model for path loss estimation outperforms existing RaFo and fitting-based models, with a mean absolute error (MAE) reduction of 4.5 and 0.9 dB in the case of vehicular visible light communication (V-VLC) and IEEE 802.11p links, respectively.",
        "affiliation_name": "Chosun University",
        "affiliation_city": "Gwangju",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Estimation of Three-Dimensional Ground Reaction Forces During Walking and Turning Using Insole Pressure Sensors Based on Gait Pattern Recognition",
        "paper_author": "Eguchi R.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Three-dimensional ground reaction forces (3D GRFs) in various gait patterns (e.g., walking and turning) provide essential information for clinical assessment. Previous scholars proposed to estimate GRFs from insoles with few pressure sensors using machine learning techniques. However, estimating GRFs during turning using a model learned from walking proved difficult because relationships between plantar pressure and GRFs vary according to the gait pattern. In this study, GRFs were estimated based on gait pattern recognition. GRF estimation models were learned from various gait patterns in advance. These models represented relationships between the insole measurements and GRFs using a Gaussian process regression (GPR). The GRFs were estimated from the insole measurements using a maximum likelihood (ML) model recognized as the current gait pattern. The ML model had the largest time frames, in which its standard deviation (SD) of the probabilistically estimated vertical GRF was the smallest among all the models (i.e., its training data were closest to the inputs), in the initial and terminal stance phases (subphases). In addition, the time frames of the contralateral leg were considered to enhance the recognition accuracy based on interlimb coordination. Experiment results showed that the proposed system, which used a common model learned from all the gait patterns for the vertical GRF and the ML model in the subphases of both legs for the horizontal GRFs, estimated 3D GRFs during walking and turning with different curvatures and directions with higher accuracy. The system can be widely applied for clinical walking tests and monitoring in daily life.",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Classification of Activities of Daily Living for Older Adults Using Machine Learning and Fixed Time Windowing Technique",
        "paper_author": "Nieto-Vallejo A.E.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The classification of activities of daily living (ADLs) in the home of older adults makes it possible to identify risk situations and changes in behavior that may be associated with some type of problem. This information allows caregivers and health professionals to take action when these types of situations are detected. Although many machine learning classification techniques have been proposed, the effectiveness of the solution in a real-world context remains unclear in most cases due to the large number of sensors required, the type of sensors used which may pose privacy issues, and the assumption of considering only segmented sensor events for each activity before training the models. This article presents an evaluation of different machine learning techniques using fixed time windows to extract spatiotemporal features and classify ten human activities in a real smart home with unobtrusive sensors using the Aruba CASAS dataset. The three classification techniques that achieved better performance were random forest, XGBoost, and support vector machine (SVM), achieving an accuracy of 97% with our best model, outperforming other approaches from the literature that were using the same dataset under similar conditions. The proposed classification techniques were also evaluated under a more realistic scenario by reducing the amount of hardware required and using an additional class labeled 'Other' to consider all raw sensor events, including those that do not belong to any specific activity, achieving an accuracy of 89%, outperforming other approaches from the literature using the same dataset under similar conditions.",
        "affiliation_name": "Pontificia Universidad Javeriana",
        "affiliation_city": "Bogota",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "Induction Motor Failure Identification Based on Multiscale Acoustic Entropy Feature Selection and Hierarchical Adaptive Neuro-Fuzzy Inference System With Localized Recurrent Input",
        "paper_author": "Xue S.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "As induction motor is one of the most preponderant driving equipment in modern industrial systems, timely detection and maintenance of motor failures can efficaciously circumvent economic losses and catastrophic accidents. Though vast majority of machinery fault diagnosis approaches are based on vibration analysis, there may be circumstances that it is impossible to install vibratory sensors in some sophisticated equipment or harsh environments. In view of this, a fault diagnosis method for induction motor based on multiscale acoustic entropy feature selection and hierarchical adaptive neuro-fuzzy inference system (HANFIS) with localized recurrent input is presented in this article. First, multiscale entropy features, which can reflect the health state of the running motor, are extracted from the collected acoustic signals. Subsequently, to avoid the dimensionality disaster problem and remove irrelevant features, the Relief-F algorithm is used for feature selection. Next, based on the fuzzy formalisms, a newly designed HANFIS is utilized for motor fault identification, where the localized recurrent input mechanism allows for injecting important features again into the model to prevent it from forgetting significant discriminative information, to further promote the overall diagnostic accuracy. Finally, experiments on two acoustic datasets of induction motor and comparisons with existing approaches sufficiently verify the effectiveness and superiority of the proposed method.",
        "affiliation_name": "Zhejiang Lab",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An efficient adaptive-mutated Coati optimization algorithm for feature selection and global optimization",
        "paper_author": "Hashim F.A.",
        "publication": "Alexandria Engineering Journal",
        "citied_by": "27",
        "cover_date": "2023-12-15",
        "Abstract": "The feature selection (FS) problem has occupied a great interest of scientists lately since the highly dimensional datasets might have many redundant and irrelevant features. FS aims to eliminate such features and select the most important ones that affect classification performance. Metaheuristic algorithms are the best choice to solve this combinatorial problem. Recent researchers invented and adapted new algorithms, hybridized many algorithms, or enhanced existing ones by adding some operators to solve the FS problem. In our paper, we added some operators to the Coati optimization algorithm (CoatiOA). The first operator is the adaptive s-best mutation operator to enhance the balance between exploration and exploitation. The second operator is the directional mutation rule that opens the way to discover the search space thoroughly. The final enhancement is controlling the search direction toward the global best. We tested the proposed mCoatiOA algorithm in solving) in solving challenging problems from the CEC'20 test suite. mCoatiOA performance was compared with Dandelion Optimizer (DO), African vultures optimization algorithm (AVOA), Artificial gorilla troops optimizer (GTO), whale optimization algorithm (WOA), Fick's Law Algorithm (FLA), Particle swarm optimization (PSO), Harris hawks optimization (HHO), and Tunicate swarm algorithm (TSA). According to the average fitness, it can be observed that the proposed method, mCoatiOA, performs better than the other optimization algorithms on 8 test functions. It has lower average standard deviation values compared to the competitive algorithms. Wilcoxon test showed that the results obtained by mCoatiOA are significantly different from those of the other rival algorithms. mCoatiOA has been tested as a feature selection algorithm. Fifteen benchmark datasets of various types were collected from the UCI machine-learning repository. Different evaluation criteria are used to determine the effectiveness of the proposed method. The proposed mCoatiOA achieved better results in comparison with other published methods. It achieved the mean best results on 75% of the datasets.",
        "affiliation_name": "Faculty of Computers and Information",
        "affiliation_city": "Minya",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Wireless sEMG Sensor for Neck Muscle Activity Measurement and Posture Classification Using Machine Learning",
        "paper_author": "Dandumahanti B.P.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "The nature of prolonged work and lifestyle has affected upper extremities, leading to neck musculoskeletal disorders (MSDs). The existing wired surface electromyography (sEMG) techniques limit the dynamic muscle activity measurement. In the current study, a wireless, lightweight, cost-effective, and fast data-Transmitting sEMG module is developed and assisted with pattern classification techniques to identify neck postural risks. The developed system transmits EMG signals with a sampling rate of 1024 Hz and a signal-To-noise ratio (SNR) of 50-60 dB. When calibrated with a standard EMG system, error analysis indicates a maximum percentage of error (PoE) of 1.767% for the developed system. An experimental trial was performed on 30 subjects by measuring muscle activity on two neck muscles: sternocleidomastoid (SCM) and upper trapezius descendens (TRP). A 3-min experimental trial resulted in an increase of muscle activity by 1.64% maximum voluntary contraction (MVC) at SCM and 3.87% MVC at TRP muscle. Indicating TRP muscle shows more muscle activity than the SCM muscle during flexion. Three machine learning classification algorithms were used to distinguish neutral and flexed neck postures; the support vector machine (SVM) gives higher classification accuracy of 96% than other classification algorithms. The proposed system can be used to identify the fatigued muscles, which alerts the user to adjust the posture during prolonged flexed tasks.",
        "affiliation_name": "SRM Institute of Science and Technology",
        "affiliation_city": "Kattankulathur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Intelligent IoT Anklets for Monitoring the Assessment of Parkinson's Diseases",
        "paper_author": "Zhao Y.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Parkinson's disease (PD) is one of the fastest-growing neurological diseases in the world, characterized by impaired speech and walking abilities in patients. Currently, doctors usually assess the severity of PD based on these indicators. However, these methods have problems such as vague diagnostic criteria, low quantification, and poor accuracy. Therefore, how quantifying and assessing PD and its severity level by accurately and timely measuring the gait characteristics of patients is a great challenge. This article aims to develop a portable wearable smart anklet that can identify and grade PD patients by quantitatively measuring their gait characteristics. The method of this article mainly includes three aspects: first, an Internet of Things anklet ( 19× 26×6 mm) is designed and manufactured to measure the three-axis acceleration and three-axis angular velocity at the patient's ankle; second, the gait data of 40 PD patients (ten-grade one patient, 16-grade two patients, and 14-grade three patients) are collected and 150 gait features are extracted; finally, feature engineering and optimized K-nearest neighbor (KNN) multifeature classification algorithm are used to detect and accurately classify the abnormal gait patterns of PD patients. The results of this article show that the method can effectively quantify the degree of illness of the patient's gait in nine parameters and achieve a classification accuracy of 96.5%, significantly better than other existing methods based on gait measurement. This novel, convenient, and efficient PD diagnosis auxiliary tool will provide strong support for the formulation of personalized treatment plans for PD patients.",
        "affiliation_name": "School of Control Engineering, Northeastern University",
        "affiliation_city": "Qinhuangdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Learning algorithms estimate pose and detect motor anomalies in flies exposed to minimal doses of a toxicant",
        "paper_author": "Manduca G.",
        "publication": "iScience",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Pesticide exposure, even at low doses, can have detrimental effects on ecosystems. This study aimed at validating the use of machine learning for recognizing motor anomalies, produced by minimal insecticide exposure on a model insect species. The Mediterranean fruit fly, Ceratitis capitata (Diptera: Tephritidae), was exposed to food contaminated with low concentrations of Carlina acaulis essential oil (EO). A deep learning approach enabled fly pose estimation on video recordings in a custom-built arena. Five machine learning algorithms were trained on handcrafted features, extracted from the predicted pose, to distinguish treated individuals. Random Forest and K-Nearest Neighbor algorithms best performed, with an area under the receiver operating characteristic (ROC) curve of 0.75 and 0.73, respectively. Both algorithms achieved an accuracy of 0.71. Results show the machine learning potential for detecting sublethal effects arising from insecticide exposure on fly motor behavior, which could also affect other organisms and environmental health.",
        "affiliation_name": "Università di Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "An overview of clinical machine learning applications in neurology",
        "paper_author": "Smith C.M.",
        "publication": "Journal of the Neurological Sciences",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning techniques for clinical applications are evolving, and the potential impact this will have on clinical neurology is important to recognize. By providing a broad overview on this growing paradigm of clinical tools, this article aims to help healthcare professionals in neurology prepare to navigate both the opportunities and challenges brought on through continued advancements in machine learning. This narrative review first elaborates on how machine learning models are organized and implemented. Machine learning tools are then classified by clinical application, with examples of uses within neurology described in more detail. Finally, this article addresses limitations and considerations regarding clinical machine learning applications in neurology.",
        "affiliation_name": "Cleveland Clinic Foundation",
        "affiliation_city": "Cleveland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Identification of epileptic networks with graph convolutional network incorporating oscillatory activities and evoked synaptic responses",
        "paper_author": "Dou Y.",
        "publication": "NeuroImage",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Stereoelectroencephalography (SEEG) offers unique neural data from in-depth brain structures with fine temporal resolutions to better investigate the origin of epileptic brain activities. Although oscillatory patterns from different frequency bands and functional connectivity computed from the SEEG datasets are employed to study the epileptic zones, direct electrical stimulation-evoked electrophysiological recordings of synaptic responses, namely cortical-cortical evoked potentials (CCEPs), from the same SEEG electrodes are not explored for the localization of epileptic zones. Here we proposed a two-stream model with unsupervised learning and graph convolutional network tailored to the SEEG and CCEP datasets in individual patients to perform localization of epileptic zones. We compared our localization results with the clinically marked electrode sites determined for surgical resections. Our model had good classification capability when compared to other state-of-the-art methods. Furthermore, based on our prediction results we performed group-level brain-area mapping analysis for temporal, frontal and parietal epilepsy patients and found that epileptic and non-epileptic brain networks were distinct in patients with different types of focal epilepsy. Our unsupervised data-driven model provides personalized localization analysis for the epileptic zones. The epileptic and non-epileptic brain areas disclosed by the prediction model provide novel insights into the network-level pathological characteristics of epilepsy.",
        "affiliation_name": "Shenzhen University General Hospital",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Machine Learning Approach to Predict Weight Change in ART-Experienced People Living with HIV",
        "paper_author": "Motta F.",
        "publication": "Journal of Acquired Immune Deficiency Syndromes",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Introduction:The objective of the study was to develop machine learning (ML) models that predict the percentage weight change in each interval of time in antiretroviral therapy-experienced people living with HIV.Methods:This was an observational study that comprised consecutive people living with HIV attending Modena HIV Metabolic Clinic with at least 2 visits. Data were partitioned in an 80/20 training/test set to generate 10 progressively parsimonious predictive ML models. Weight gain was defined as any weight change >5%, at the next visit. SHapley Additive exPlanations values were used to quantify the positive or negative impact of any single variable included in each model on the predicted weight changes.Results:A total of 3,321 patients generated 18,322 observations. At the last observation, the median age was 50 years and 69% patients were male. Model 1 (the only 1 including body composition assessed with dual-energy x-ray absorptiometry) had an accuracy greater than 90%. This model could predict weight at the next visit with an error of <5%.Conclusions:ML models with the inclusion of body composition and metabolic and endocrinological variables had an excellent performance. The parsimonious models available in standard clinical evaluation are insufficient to obtain reliable prediction, but are good enough to predict who will not experience weight gain.",
        "affiliation_name": "Azienda Ospedaliero - Universitaria di Modena",
        "affiliation_city": "Modena",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Vocal Cord Vibration Signal Recognition Model Based on Feature Engineering Preprocessing",
        "paper_author": "Zhang Q.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "The vocal cord vibration signal carries as much rich phonetic information as the speech signal. However, conventional automatic speech recognition (ASR) technology cannot effectively deal with vocal cord vibration signal. In this article, a wearable throat speech detection sensor (TSDS) based on graphene sheets is designed. Subsequently, a large number of Chinese and English words are collected, and a dataset of vocal cord vibration for recognition tasks is established. Applying the knowledge of transfer learning, we use XGBoost applied to bearing fault detection as a source model, combined with feature engineering technology principal component analysis (PCA), and propose an extreme gradient boosting model fused with PCA for efficient identification of vocal fold vibration signals. The model reduces the data dimension, saves the operation time, and can automatically extract the characteristic parameters with a large contribution to the vocal cord vibration signal at the same time.",
        "affiliation_name": "Yanshan University",
        "affiliation_city": "Qinhuangdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Quantifying architectural color Quality: A Machine learning integrated framework driven by quantitative color metrics",
        "paper_author": "Zhang C.",
        "publication": "Ecological Indicators",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "The assessment and prediction of architectural color quality play a pivotal role in urban spatial environments, influencing the aesthetic and psychological dimensions of urban space. Despite the criticality, there exists a lacuna in efficient methodologies capable of quantitatively evaluating architectural color quality. This study endeavors to bridge this gap by introducing a novel framework employing a machine learning approach in conjunction with operationalizable color feature templates for predicting architectural color quality. Four machine learning models - XGBoost, ANN, SVM, and LGBM - are utilized to assess the color quality based on selected color feature indices. Moreover, this research employs SHAP values to elucidate the contribution of various color features towards model prediction. The findings reveal that among the tested models, XGBoost outshines in terms of prediction accuracy. Significant color features including building height, lightness and saturation of primary colors, and red values in both primary and secondary colors were found to exert substantial influence on the model's predictive capacity. This pioneering approach provides a scalable and quantifiable means to evaluate and predict architectural color quality, which has the potential to significantly contribute to urban color planning and evaluation, thereby propelling forward the domain of architectural color research.",
        "affiliation_name": "University of Leeds",
        "affiliation_city": "Leeds",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Presentation of machine learning methods and multi-objective optimization of fracture indices for asphalt rubber mixtures containing wax-based warm mix additives modified by nano calcium carbonate",
        "paper_author": "Hosseinian S.M.",
        "publication": "Construction and Building Materials",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Warm mix asphalt (WMA) additives have been proposed to overcome the high viscosity problem of crumb rubber modified asphalt (CRMA) binders. Various additives have been used to improve the low-temperature cracking performance of asphalt mixtures, but no study has been conducted to present the optimum additive content in CRMA binders in different loading modes. Therefore, this research aims to present the optimum content of nano calcium carbonate (NCC) to improve the fracture toughness and energy of asphalt rubber mixtures containing WMA additives (slack wax (SW) and polypropylene wax (PPW)). The semi-circular bend (SCB) fracture test was applied under pure mode I, mixed mode I-II, mixed mode II-I and pure mode II loadings at subzero temperature. Machine learning methods, including multivariate regression (MVR) and artificial neural network (ANN) models of group method of data handling (GMDH) and multilayer perceptron (MLP), were used to provide the prediction models of effective stress intensity factor (Keff) and fracture energy (Gf). Finally, the multi-objective optimization of Keff and Gf was performed to obtain optimum NCC content. The results indicated that in MVR model, the outputs had a small correlation with laboratory values, so that R value of MVR was 0.8406 and 0.8011 for Keff and Gf, respectively. Also, it was revealed in MVR that NCC had the highest impact on Keff and Gf significantly. GMDH model results showed that the relationships between predicted and laboratory values of Keff and Gf are appropriately described with R value of 0.9546 and 0.9229 for Keff and Gf models, respectively. In MLP model, different layer structures of the feed-forward neural network were developed to obtain the most accurate structure. It was indicated that MLP with 4–22–1 and 3–19–1 structures had a higher accuracy for Keff and Gf prediction models with R value of 0.9951 and 0.9978, respectively. Finally, by the use of the best model relationships, the results of the multi-objective optimization indicated that 4.91% and 6.37% NCC were the design optimum contents resulting in a maximum of Keff and Gf simultaneously for SW and PPW-modified CRMA mixtures. Moreover, the optimum NCC contents in loading modes of mode mixity Me of 1, 0.8, 0.4 and 0 were 3.62%, 5.12%, 4.08% and 3.42% for SW-modified CRMA mixtures and 4.35%, 6.51%, 7.19% and 2.84% for PPW-modified CRMA mixtures, respectively.",
        "affiliation_name": "Imam Khomeini International University",
        "affiliation_city": "Qazvin",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Flash-based content addressable memory with L2 distance for memory-augmented neural network",
        "paper_author": "Yang H.",
        "publication": "iScience",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Memory-augmented neural network (MANN) has received increasing attention as a promising approach to achieve lifelong on-device learning, of which implementation of the explicit memory is vital. Content addressable memory (CAM) has been designed to accelerate the explicit memory by harnessing the in-memory-computing capability. In this work, a CAM cell with quadratic code is proposed, and a 1Mb Flash-based multi-bit CAM chip capable of computing Euclidean (L2) distance is fabricated. Compared with ternary CAM, the latency and energy are significantly reduced by 5.3- and 46.6-fold, respectively, for the MANN on Omniglot dataset. Besides, the recognition accuracy has slight degradation (<1%) even after baking for 105 s at 200°C, demonstrating the robustness to environmental disturbance. Performance evaluation indicates a reduction of 471-fold in latency and 1267-fold in energy compared with GPU for search operation. The proposed robust and energy-efficient CAM provides a promising solution to implement lifelong on-device machine intelligence.",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Optimizing environmental sustainability in pharmaceutical 3D printing through machine learning",
        "paper_author": "Li H.",
        "publication": "International Journal of Pharmaceutics",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "3D Printing (3DP) of pharmaceuticals could drastically transform the manufacturing of medicines and facilitate the widespread availability of personalised healthcare. However, with increasing awareness of the environmental damage of manufacturing, 3DP must be eco-friendly, especially when it comes to carbon emissions. This study investigated the environmental effects of pharmaceutical 3DP. Using Design of Experiments (DoE) and Machine Learning (ML), we looked at energy use in pharmaceutical Fused Deposition Modeling (FDM). From 136 experimental runs across four common dosage forms, we identified several key parameters that contributed to energy consumption, and consequently CO2 emission. These parameters, identified by both DoE and ML, were the number of objects printed, build plate temperature, nozzle temperature, and layer height. Our analysis revealed that minimizing trial-and-error by being more efficient in R&D and reducing the build plate temperature can significantly decrease CO2 emissions. Furthermore, we demonstrated that only the ML pipeline could accurately predict CO2 emissions, suggesting ML could be a powerful tool in the development of more sustainable manufacturing processes. The models were validated experimentally on new dosage forms of varying geometric complexities and were found to maintain high accuracy across all three dosage forms. The study underscores the potential of merging sustainability and digitalization in the pharmaceutical sector, aligning with the principles of Industry 5.0. It highlights the comparable learning traits between DoE and ML, indicating a promising pathway for wider adoption of ML in pharmaceutical manufacturing. Through focused efforts to reduce wasteful practices and optimize printing parameters, we can pave the way for a more environmentally sustainable future in pharmaceutical 3DP.",
        "affiliation_name": "Prince Sattam Bin Abdulaziz University",
        "affiliation_city": "Al Kharj",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "A personalized regression model for predicting thermal sensation based on local skin temperature in moderate summer conditions",
        "paper_author": "Qi Y.",
        "publication": "Energy and Buildings",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Personalized thermal sensation models play a crucial role in ensuring occupant's thermal comfort satisfaction and improving building energy efficiency. However, an adaptive and accurate personalized model that can be easily implemented in real life is still challenging. This paper investigates the influencing factors of thermal sensation vote (TSV) and proposes a personalized regression model that only uses a single local skin temperature as the key indicator. A survey is conducted with forty subjects aging from 20 to 59 years old. The relationship among ambient temperature, skin temperatures, and subjective TSV is analyzed. The forehead temperature is recommended as the key indicator for prediction because it exhibits a strong correlation with ambient temperature and TSV, and it is easy to capture. Furthermore, the impact of individual characteristics on TSV is investigated. The proposed model effectively captures and compensates for individual differences by incorporating subjects' set point skin temperature and body fat percentage (BF%). The proposed model can be readily applied in real-life scenarios due to its minimal requirement for occupant's feedback and its higher accuracy compared to other models. Specifically, it exhibits a significantly lower Root Mean Square Error (RMSE) of 15.8 %, 9.4 %, and 65.2 % compared to the Support Vector Regression (SVR) model Zhang's model and Zhou's model. Moreover, the proposed model showcases the lowest mean absolute error among the compared models. This approach of developing a personalized regression model based on local body temperature holds promise for future international ergonomic standard development.",
        "affiliation_name": "China National Institute of Standardization",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep learning untangles the resistance mechanism of p53 reactivator in lung cancer cells",
        "paper_author": "Lee S.M.",
        "publication": "iScience",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Tumor suppressor p53 plays a pivotal role in suppressing cancer, so various drugs has been suggested to upregulate its function. However, drug resistance is still the biggest hurdle to be overcome. To address this, we developed a deep learning model called AnoDAN (anomalous gene detection using generative adversarial networks and graph neural networks for overcoming drug resistance) that unravels the hidden resistance mechanisms and identifies a combinatorial target to overcome the resistance. Our findings reveal that the TGF-β signaling pathway, alongside the p53 signaling pathway, mediates the resistance, with THBS1 serving as a core regulatory target in both pathways. Experimental validation in lung cancer cells confirms the effects of THBS1 on responsiveness to a p53 reactivator. We further discovered the positive feedback loop between THBS1 and the TGF-β pathway as the main source of resistance. This study enhances our understanding of p53 regulation and offers insights into overcoming drug resistance.",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Structural indicator synergy for mitigating extreme urban heat island effects in industrial city: Simulation and verification based on machine learning",
        "paper_author": "Liu S.",
        "publication": "Ecological Indicators",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Industrial areas emit large amounts of extremely high temperatures and aggravate the extreme urban heat island (E-UHI) effect, which has become a non-negligible environmental issue worldwide. Due to the lack of in-depth understanding of the relationship between E-UHI and surface structural synergy, few studies explored the causes and mitigation measures of E-UHI. Therefore, this study accordingly defined the E-UHI effect at a finer scale based on the thermal characteristics and human thermal perceptions, and a multi-indicator’ method based on machine learning was proposed to quantify internal causes and collaborative mitigation measures. The results revealed that the average E-UHI scale shows a quadratic growth in Wu'an. Artificial heat from production space (PS) is the main cause of E-UHI formation. The synergy between green space (GS), PS and shape of industrial land determines the development of E-UHI. Although both the decrease of PS and the increase of GS are ways to mitigate high land surface temperature, when PS is higher than 50%, the cooling effect of GS is not obvious. When GS is less than 2.5%, the adjustment of PS is invalid for improving the thermal environment. For mitigating E-UHI, a factory with high PS needs to increase its shape index. The synergy between the structural indicators is a novel model to solve the shortcoming of adjusting a single factor in mitigating complex E-UHI. The results provide theoretical guidance for mitigating E-UHIs.",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Fire resistance of reinforced concrete beams: State of the art, analysis and prediction",
        "paper_author": "Wang Y.",
        "publication": "Construction and Building Materials",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Reinforced concrete (RC) beams are widely applied in building structures, and fire resistance performance becomes a focus of fire research with the high frequency of building fires. This paper aims to summarize the fire resistance performance of 216 specimens in 80 references and propose a fire resistance prediction equation. Firstly, the factors of fire resistance are considered in these specimens such as load ratio, concrete cover thickness and longitudinal reinforcement ratio. The influence rules of these factors are summarized. And the theoretical analysis, finite element simulation and fire resistance prediction equation of RC beams are also summarized. It is found that the parameters such as load ratio and concrete cover thickness have a great impact on fire resistance, while the parameters such as stirrup spacing have a minor impact on fire resistance. Secondly, the Pearson correlation analysis of 10 parameters is conducted in 216 specimens and 6 parameters with a correlation degree greater than 0.1 are identified as important parameters. The database is established by 4 Machine Learning (ML) algorithms. It is found that the database established by the Random Forest (RF) algorithm has high performance. Finally, the fire resistance prediction equation of RC beam is obtained by the database and nonlinear regression analysis. The prediction equation is compared with existing equations, and it is found that the proposed equation with R2 of 0.935 has high precision in predicting fire resistance. The proposed equation can be adopted to guide the fire resistance design of RC beams.",
        "affiliation_name": "Shandong Xiehe University",
        "affiliation_city": "Jinan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A novel semi-supervised fault diagnosis method for chillers based on neighbor-optimized graph convolutional network",
        "paper_author": "Deng Q.",
        "publication": "Energy and Buildings",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "The fault diagnosis of chillers is of great significance in reducing building energy consumption and extending the operational lifespan of refrigeration equipment. Several popular machine learning-based fault diagnosis methods rely heavily on many labeled samples. However, such samples are difficult to obtain in practice due to sparse fault data and high labeling costs. This limits the application of ML-based fault diagnosis methods based on supervised learning. To reduce the dependence on labeled samples, this paper proposes a novel chiller fault diagnosis method based on neighbor-optimized graph convolutional network. The method improves the utilization efficiency of unlabeled samples by mining the spatio-temporal relationship between a large number of unlabeled samples and a limited number of labeled samples. And it dynamically adjusts the graph's structure by optimizing the number of adjacent samples in the correlation graph to obtain better diagnostic results. Its effectiveness is validated on the authoritative dataset ASHRAE RP-1043 and a more challenging dataset of real-world chillers in a building. Experimental results show that the proposed method can achieve better diagnostic performance than the state-of-the-art methods.",
        "affiliation_name": "University of Science and Technology Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "On the theory of deep learning: A theoretical physics perspective (Part I)",
        "paper_author": "Chinea Manrique de Lara A.",
        "publication": "Physica A: Statistical Mechanics and its Applications",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Deep learning machines are computational models composed of multiple processing layers of adaptive weights to learn representations of data with multiple levels of abstraction. Their structures mainly reflect the intuitive plausibility of decomposing a problem into multiple levels of computation and representation since it is believed that higher layers of representation allow a system to learn complex functions. Surprisingly, after decades of research, from learning and design perspectives these models are still deployed in a heuristic manner. In this paper, deep learning machines are modeled as disordered physical systems where its macroscopic behavior is determined in terms of the interactions defined between the basic information-processing constituent of these models, namely, the artificial neuron. They are viewed as the equilibrium states of a theoretical body that is subject to the law of increase of the entropy. The study of the changes in energy of the body when passing from one equilibrium state to another is used to understand the structure and role of the phase space of the system, and the resulting degree of disorder. It is shown that the topology of these models is strongly linked to their resulting level of disorder. Furthermore, the proposed theoretical characterization permit to assess the thermodynamic efficiency with which information can be processed by these models, and to provide a practical methodology to quantitatively estimate and compare their expected learning and generalization capabilities. These theoretical results provides new insights to the theory of deep learning and their implications are shown to be consistent through a set of benchmarks designed to experimentally assess their validity.",
        "affiliation_name": "Universidad Nacional de Educacion a Distancia",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Pharmaceutical nanonization by green supercritical processing: Investigation of Exemestane anti-estrogenic medicine solubility using machine learning",
        "paper_author": "Faris Alotaibi H.",
        "publication": "Journal of Molecular Liquids",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Oral administration is known as the most prevalently-employed approach of drug delivery because of possessing different benefits like simplicity of use, affordability and negligible sterility restrictions. Despite the noteworthy interests of scientists to manufacture oral therapeutic medicines, poor solubility/bioavailability of orally-administered drugs remains a big challenge in recent years. Therefore, various scientists are trying to develop novel techniques to enhance the solubility of orally-administered therapeutic agents. One of the promising ways, which has recently attracted the global attentions is the use of supercritical fluids (SCFs). This technique could overcome the unfavorable/detrimental influences of organic solvents on the environment due to its environmentally-benign characteristics, non-inflammability and low toxicity. In this research, the solubility of Exemestane (EXE) drug is modeled based on two parameters of temperature and pressure. In order to handle the modeling process, the AdaBoost method with three core models of linear regression (LR), K-Nearest Neighbor (KNN) and Gaussian Process (GPR) are considered, which are tuned by AEO method in terms of their hyper-parameters. Based on the evaluations carried out in this research, ADA GPR, ADA KNN, and ADA LR models showed 0.996, 0.991, and 0.925 values in terms of R-square score. Also, in terms of the error rate, the three models ADA GPR, ADA KNN, and ADA LR have an RMSE error equal to 1.3459, 1.8967, and 5.8875, respectively. Based on these facts and some other analyses, the Gaussian process model optimized and boosted with AdaBoost can be accepted as the most accurate model of this research.",
        "affiliation_name": "Princess Nourah Bint Abdulrahman University",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Numerical optimization of drug solubility inside the supercritical carbon dioxide system using different machine learning models",
        "paper_author": "Almehizia A.A.",
        "publication": "Journal of Molecular Liquids",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "This research comprehensively investigates the solubility characteristics of five distinct drugs including: Nystatin, Niflumic acid, Tolfenamic acid, Glibenclamide, and Rivaroxaban, across a range of pressure (P) and temperature (T) conditions. The solubility is computed in supercritical carbon dioxide as the solvent. It was aimed to build a holistic view of solubility estimation using machine learning technique. To predict drug solubility accurately, three regression models— K-Nearest Neighbors (KNN), Multilayer Perceptron (MLP), and Polynomial Regression (PR)—were employed, with hyperparameter optimization conducted using the Harmony Search (HS) algorithm. Performance evaluation metrics, including R-squared (R2) scores, Root Mean Square Error (RMSE), and Maximum Error, were employed to assess model effectiveness. Notably, HS-PR emerged as the top-performing model, achieving an impressive score of 0.96449 in terms of R2 metric, highlighting its proficiency in modeling drug solubility under varying conditions.",
        "affiliation_name": "King Khalid University",
        "affiliation_city": "Abha",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Handling complete short-term data logging failure in smart buildings: Machine learning based forecasting pipelines with sliding-window training scheme",
        "paper_author": "Papadopoulos D.N.",
        "publication": "Energy and Buildings",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "This paper implements a machine learning(ML)-based procedure for constructing the missing sensor(s) data in a net zero energy building in case of complete failure in data recording (for up to one hour). In the first scenario, missing temperature data is re-created using the sensor's ex-ante data, the HVAC system's status flag, and the ambient conditions. In the second scenario, the temperature data (until failure occurred) from two close-by spaces are also utilized as inputs. For each scenario, ML-based pipelines' performance is first assessed by considering different prediction horizons using a benchmark algorithm. Next, each pipeline's most promising features and the most suitable algorithm are identified. Using the obtained optimal pipeline, a sliding window-based training scheme is implemented, and the size of the training window is optimized. It is shown that feature selection, algorithm optimization procedures, and the sliding window-based training scheme notably improve the forecasting performance. The proposed methodology can be deployed as a tool in intervals with total data logging failure, providing data to ML-based controllers in smart buildings and avoiding disruptions in the building management system.",
        "affiliation_name": "Concordia University",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine learning aided pharmaceutical engineering: Model development and validation for estimation of drug solubility in green solvent",
        "paper_author": "Meng D.",
        "publication": "Journal of Molecular Liquids",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "This research paper explores the prediction of solubility of Nystatin in SC-CO2 and corresponding density using regression models and Glowworm Swarm Optimization (GSO). The dataset consists of temperature, pressure, solvent density, and solubility of Nystatin drug, with three regression models applied: Multi-Layer Perceptron (MLP), K-Nearest Neighbors (KNN), and Kernel Ridge Regression (KRR). GSO is employed for hyper-parameter tuning of models. For solubility predictions, GSO-KNN demonstrates exceptional performance with an R2 score of 0.99201 and MSE of 4.1500E-04. GSO-MLP also excels with an R2 score of 0.99956 and an MSE of 2.4690E-05. Regarding density predictions, GSO-KRR achieves an R2 score of 0.93993, while GSO-KNN exhibits an R2 score of 0.98804 and GSO-MLP attains an R2 score of 0.98868. Although GSO-KRR lags behind, all models demonstrate substantial predictive accuracy. This study highlights the utility of regression models in predicting solubility and density in SC-CO2, showcasing the superiority of GSO-MLP and GSO-KNN for solubility and density predictions and the competence of all models for density predictions. The findings provide valuable insights for applications in pharmaceutical and materials science research.",
        "affiliation_name": "Ltd.",
        "affiliation_city": "Changchun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A machine learning approach for assessing the compressive strength of cementitious composites reinforced by graphene derivatives",
        "paper_author": "Montazerian A.",
        "publication": "Construction and Building Materials",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "The potential reinforcement effect of graphene derivatives (GDs) on cementitious composites (CCs) has attracted significant attention. Previous studies, however, have produced varied results regarding the impact of GDs on CCs. This can be attributed to differences in the properties of GDs and the fabrication details of CCs reinforced by GDs. Experiments to explore these factors are both time-consuming and cost-ineffective. Additionally, no predictive model currently exists for assessing the influence of GDs on the compressive strength of CCs. In terms of Machine Learning (ML), most existing models focus on continuous parameters, including mixture design properties of CCs and reinforcing filler content, but ignore discontinuous parameters such as dispersion technique of GDs in CCs, curing type, and type of GDs. Compiling a unique dataset, this study tailors ML models to comprehensively explore the effect of GDs inclusion on the compressive strength of CCs, considering continuous and discontinuous parameters, including GD properties, fabrication details, and mixture design properties. The most used dispersion techniques and types of GDs were divided into different categories in this study. Moreover, the dataset included cement strength grade and fineness modules to distinguish between the effect of cement types' variety and GDs. Finally, the backwards elimination technique confirmed the necessity of such a customized dataset for trustworthy predictions. Artificial neural networks (ANN), decision trees, and support vector regressors could successfully investigate the impact of GDs' inclusion on the compressive strength of CCs, with ANN demonstrating superior prediction performance. Among the GDs properties, sensitivity analysis revealed that lateral size had the highest effect. Among the fabrication conditions, the dispersion technique had the greatest effect. Considering all investigated parameters, the water-to-cement ratio was considered the most influential, followed by lateral size and curing time. A low w/c significantly reduces the strength growth rate due to poor dispersion of GDs.",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Study on predicting the radiant heat flow rate of floor surface of radiant floor heating",
        "paper_author": "Lu L.",
        "publication": "Energy and Buildings",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Radiant heat flow rate of radiant surface is crucial for radiant floor heating design and terminal selection. We found that the present empirical formula to predict radiant heat flow rate of radiant surface has limits under varied room size and surface emissivity circumstances. Wall insulation conditions also have substantial influences on the operating efficiency of floor radiant heating. Adopting machine learning algorithms and backward selection method, a two-layer Neural Network model was demonstrated to have good accuracy and requisite relevant features for new empirical formula was identified. The new formula containing the information of room depth, weighted radiant surface area, insulation conditions, indoor air temperature and radiant surface temperature as independent variables exhibits great accuracy with R-squared of 0.97 and RMSE of 2.74. The substitution of AUST with indoor air temperature can increase the prediction accuracy. Analysis reveals structural pattern and indicates interaction between wall insulation and non-radiative surface with low emissivity. We propose the use of non-radiant surfaces with low emissivity as a passive energy-saving technique for radiant floor heating. And the updated empirical formula can increase its application scenarios, and aid promote application of FRH and new passive technique.",
        "affiliation_name": "Key Laboratory of the Three Gorges Reservoir Region's Eco-Environment, Ministry of Education",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Characterizing environmental pollution with civil complaints and social media data: A case of the Greater Taipei Area",
        "paper_author": "Guo M.",
        "publication": "Journal of Environmental Management",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Environmental pollution is a major cause of nuisance and ill health among urban residents. Complaints are traditionally self-reported through phone-based systems. Social media provide novel channels to detect pollution-related incidents; however, their reliability has not been sufficiently evaluated. This study aimed to compare pollution incidents expressed on Twitter with those extracted from phone-based systems and to identify the built environment and socioeconomic attributes that can predict the likelihood of pollution incidents. A total of 639,746 tweets were retrieved from the Greater Taipei Area in 2017 and 110,716 self-reported pollution incidents were extracted from the Public Nuisance Petition system during the same period. The results suggest that complaints collected from phone-based systems and Twitter were found to have correlated with each other spatially, albeit they differ in temporal profiles and by the proportion of pollution categories. Catering businesses and the entertainment activities they attract appear to be the main sources of pollution complaints and can be precisely captured by geotagged tweets. This can serve as a strong predictor for pollution incidents, more than traditional indicators such as population density or industrial activities, as suggested by earlier studies. Social media analytics, with their ability to monitor and analyze online discussions in a timely manner, can be a valuable supplement to existing phone-based pollution monitoring procedures. The methodologies developed in this study have the potential to support the proactive management of urban environmental pollution, in which resources can be prioritized in key areas to further enhance the quality of urban services.",
        "affiliation_name": "The University of Hong Kong, Shenzhen Institute of Research and Innovation",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A new model predictive control approach integrating physical and data-driven modelling for improved energy performance of district heating substations",
        "paper_author": "Zhang Z.",
        "publication": "Energy and Buildings",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "District heating (DH) substations play a crucial role in ensuring the efficient and effective distribution of thermal energy necessary to provide space heating for buildings. However, optimizing their operation for energy savings while still ensuring indoor comfort poses significant challenges due to the complex dynamics of building demand and the inertia of building envelopes. To address these challenges, this study introduces a novel model predictive control (MPC) approach that combines a reduced-order physical model with a machine learning-based data-driven model to jointly optimize the operation parameters of a DH substation. In this approach, a reduced-order physical model is first used to capture essential operational principles and energy behaviors of the DH substations and generate candidate solutions for the control of the DH substations. Then, a data-driven model is constructed by integrating a Long Short-Term Memory model and a Back-propagation Neural Network, leveraging historical operational data of the DH substation concerned. The data-driven model is further formulated into a data-driven MPC framework to identify optimal control solutions from all candidates provided by the physical model. To evaluate the proposed approach, a data-driven surrogate model is developed using real operational data. Comparative analysis against the original fuzzy rule-based control strategy and a pure data-driven strategy demonstrates a substantial reduction in heat consumption of 4.77% and 19.47%, respectively. Moreover, compared with using a reduced-order physical model alone, this approach achieves additional benefits in reducing the energy consumption of the DH substation and minimizing indoor temperature fluctuations within the end-users.",
        "affiliation_name": "Shandong Jianzhu University",
        "affiliation_city": "Jinan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A systematic review of research on personal thermal comfort using infrared technology",
        "paper_author": "Wu Y.",
        "publication": "Energy and Buildings",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "Personal thermal comfort studies are crucial for balancing both human comfort and building energy savings. Thus, personal comfort models (PCMs) are expected to play a pivotal role in the development of smart buildings. Infrared technology has received significant attention from researchers because of its non-intrusive nature for collecting personal data. This systematic review examined 36 personal thermal comfort studies that employed infrared technology over the past decade. The review analyzed the (1) infrared devices, (2) experimental designs, (3) subjects, and (4) analysis methods and results. The review found that most studies were experimental and focused on exploring feasibility at a theoretical level, while the number of practical application studies was limited. The accuracy of infrared devices was identified as a primary concern for researchers, and some studies proposed methods to mitigate measurement errors. Most studies included young subjects and examined single clothing insulation and metabolic rates, limiting the generalizability of the corresponding PCMs, which were mainly constructed using machine learning. To facilitate data sharing and comparison of results and to overcome the limitations in terms of applicable populations and application scenarios, the review suggests that standardized data collection and processing should be used in future studies. Furthermore, the paper proposes the integration of PCMs and personal comfort systems, which are two hotspots in personal thermal comfort research, to achieve cooperative applications. Finally, the study discusses the future applications of infrared technology in scenarios such as vehicle cabins, sleep areas, and outdoor environments, considering their unique characteristics.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Utilizing MATLAB machine learning models to categorize transient events in a nuclear power plant using generic pressurized water reactor simulator",
        "paper_author": "Zubair M.",
        "publication": "Nuclear Engineering and Design",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Enhancing safety and dependability within nuclear power facilities holds paramount importance in safeguarding both individuals and the environment. The adoption of machine learning for diagnosing faults in these plants is steadily gaining interest, driven by its capacity to detect faults, alleviate human errors in high-pressure scenarios, and ensure the secure and consistent operation of these facilities swiftly and accurately. This paper examines the use of machine learning models for fault diagnostics, specifically, the identification of transient events in a nuclear power plant to reduce human errors. The data was collected from WSC's Generic Pressurized Water Reactor (GPWR) simulator and processed using MATLAB. The simulator encompasses models for both the primary and secondary systems of the nuclear power plant (NPP). Additionally, it incorporates models for the control systems and instrumentation responsible for monitoring and regulating the reactor, serving as integral components for data extraction and transient modeling. A total of 9 different transient events were simulated with 12 different initial conditions to create a dataset with 72,000 observations. Nine types of classification models (33 total preset models) were trained and validated using the classification learners application. Among them, the Neural Network Classifiers (NNC) displayed the highest average accuracy of 90%. The Fine Tree, Ensemble Bagged Trees, and Medium Neural Network models were the best-performing individual models with validation accuracies above 90% and a maximum training time of 8 min. These models were further analyzed using accuracy, confusion matrix, precision, recall, and F1 score. To optimize these models, techniques such as different validation schemes and feature selection were utilized to further reduce their training time and improve their prediction accuracy. The optimized models boasted comparable accuracies with a maximum training time of under 1.5 min. The results of this study exhibited favorable comparisons with other machine-learning endeavors in the field of reactor transient detection and diagnostics. Notably, the study maintained low execution and computation times while preserving high levels of accuracy. This study offers insightful information on how AI and machine learning can be used to improve nuclear power plant diagnostics, enhance safety, and provide support to the operator.",
        "affiliation_name": "University of Sharjah",
        "affiliation_city": "Sharjah",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "OCPMDM 2.0: An intelligent solution for materials data mining",
        "paper_author": "Chang D.",
        "publication": "Chemometrics and Intelligent Laboratory Systems",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning methods have played a significant role in materials design. With the rapid development of the Materials Genome Initiative (MGI) and data science, material researchers are confronted with the requirements to conduct sophisticated data analytics in modeling the property of materials. To make it more convenient for material researchers to design new materials using machine learning methods, an intelligent web platform called the second version of online computation platform for material data mining (OCPMDM 2.0) has been updated from the previous computation platform in our lab. Besides the various data mining algorithms developed in OCPMDM 1.0, the new platform tries to provide an intelligent solution for materials datamining, including descriptors filling, virtual screening of candidate materials, connection with materials databases and model sharing. It is convenient for materials researchers to obtain the machine learning model and the result of applying model by only submitting materials data on OCPMDM 2.0. To demonstrate the applications of the platform, two data sets of different kinds of materials were automatically processed to obtain the best models in the platform. The models are applied to screen out candidates with better properties than those in the training dataset. Material data mining process can be implemented via the platform, which provides convenient ways for material researchers in materials design and optimization. The URL of the platform is http://materials-data-mining.com/ocpmdm/.",
        "affiliation_name": "Shanghai University College of Sciences",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Wireless water consumption sensing system for building energy efficiency: A visual-based approach with self-powered operation",
        "paper_author": "Liang R.",
        "publication": "Energy and Buildings",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "The use of smart wireless remote water meters has become popular due to their efficiency in avoiding manual labor and automate meter reading. The current implementation of these measurement instruments often requires expensive external power sources and separate data aggregators, posing challenges for circuit safety and the goal of reducing carbon emissions in aging communities. In response, a novel wireless system has been developed to accurately measure water consumption in buildings. This system incorporates advanced machine learning techniques and utilizes the potential of water-based energy in a seamless manner. This novel methodology utilizes optical sensors to acquire visual data of water gauges and exploits machine learning techniques, specifically the AVSM model also called Advanced Visual Sensing Model (AVSM). This methodology employs a rigorous approach to achieve accurate metric determinations, thereby eliminating the necessity for additional hardware or excessive power configurations. Moreover, an integrated micro water generator has been seamlessly implemented, demonstrating the capability to effectively transfer energy to a lithium battery for the purpose of storage. This implementation guarantees consistent functionality and a significant decrease in reliance on external power supplies. The data augmentation procedure involves the stochastic manipulation of image luminance, resulting in encouraging results when used in conjunction with the AVSM model. Significantly, the dimensions of the model have been significantly decreased, while maintaining a commendable mean average precision (mAP). By leveraging this method and visual-based features, the system can contribute to overall building energy efficiency and reduce the burdens of manual meter reading while supporting CO2 emissions reduction as a feasible and cost-effective solution for building management, promoting sustainability, and advancing energy-efficient practices in old communities. This new wireless system for measuring water usage provides a practical and affordable way to enhance energy efficiency in buildings, lessen the workload of manual meter reading, and help meet carbon emissions reduction goals. As well as optimizing resource and energy use, this method also aligns with eco-friendly solutions to combat global warming and climate change.",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Application of machine learning algorithms and feature selection methods for better prediction of sludge production in a real advanced biological wastewater treatment plant",
        "paper_author": "Ekinci E.",
        "publication": "Journal of Environmental Management",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "Although the management of sewage sludge is an important and challenging task of wastewater treatment, there is a scarcity of studies on the prediction of waste sludge. To overcome this deficiency, the present work aims to develop an appropriate model providing accurate and fast prediction of sewage sludge. With this aim, different machine learning (ML) algorithms were tested by data obtained from a real advanced biological wastewater treatment plant located in Kocaeli, Turkey. In modelling studies, a data set from January 2022 to December 2022 composed of 208 daily measurements was considered. The flow rate of the plant (Q), polyelectrolyte dosage (PD) and removed amounts of total suspended solids (TSS), chemical oxygen demand (COD), biological oxygen demand (BOD), total phosphorous (TP), total nitrogen (TN) were assigned as input parameters to predict sludge production (SP). The precision of the models was evaluated in terms of Mean Square Error (MSE), Mean Absolute Percentage Error (MAPE), Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and correlation coefficient (R2). Among the various tested models Kernel Ridge Regression provided the best accuracy with R2 value of 0.94 and MAE value of 3.25. Mutual information-based feature selection (MIFS) and correlation-based feature selection (CFS) algorithms were also used in the study in order to enhance the model performance. Thus, higher prediction accuracies were achieved using the selected subset of features. Furthermore, importance contribution of features were calculated and visualized by SHapley Additive exPlanations (SHAP) technique. The overall results of the work indicate the feasibility of ML models for describing the dynamic and complex nature of SP. The process operators may benefit from this modelling approach since it enables accurate and fast estimation of sewage sludge by using fewer and easily measurable parameters.",
        "affiliation_name": "Sakarya University of Applied Sciences",
        "affiliation_city": "Serdivan",
        "affiliation_country": "Türkiye"
    },
    {
        "paper_title": "Towards global long-term water transparency products from the Landsat archive",
        "paper_author": "Maciel D.A.",
        "publication": "Remote Sensing of Environment",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "Secchi Disk Depth (Zsd) is one of the most fundamental and widely used water-quality indicators quantifiable via optical remote sensing. Despite decades of research, development, and demonstrations, currently, there is no operational model that enables the retrieval of Zsd from the rich archive of Landsat, the long-standing civilian Earth-observation program (1972 – present). Devising a robust Zsd model requires a comprehensive in situ dataset for testing and validation, enabling consistent mapping across optically varying global aquatic ecosystems. This study utilizes Mixture Density Networks (MDNs) trained with a large in situ dataset (N = 5689) from 300+ water bodies to formulate and implement a global Zsd algorithm for Landsat sensors, including the Thematic Mapper (TM), Enhanced Thematic Mapper Plus (ETM+), and Operational Land Imager (OLI) aboard Landsat-5, -7, -8, and -9, respectively. Through an extensive Monte Carlo cross-validation with in situ data, we showed that MDNs improved Zsd retrieval when compared to other commonly used machine-learning (ML) models and recently developed semi-analytical algorithms, achieving a median symmetric accuracy (ε) of ∼29% and median bias (β) of ∼3%). A fully trained MDN model was then applied to atmospherically corrected Landsat data (i.e., remote sensing reflectance; Rrs) to both further validate our MDN-estimated Zsd products using an independent global satellite-to-in situ matchup dataset (N = 3534) and to demonstrate their utility in time-series analyses (1984 – present) via selected lakes and coastal estuaries. The quality of Rrs products rigorously assessed for the Landsat sensors indicated sensor-/band-dependent ε ranging from 8% to 37%. For our Zsd products, we found ε ∼ 39% and β ∼ 8% for the Landsat-8/OLI matchups. We observed higher errors and biases for TM and ETM+, which are explained by uncertainties in Rrs products induced by uncertainties in atmospheric correction and instrument calibration. Once these sources of uncertainty are, to the extent possible, characterized and accounted for, our developed model can then be employed to evaluate long-term trends in water transparency across unprecedented spatiotemporal scales, particularly in poorly studied regions of the world in a consistent manner.",
        "affiliation_name": "University of Maryland, Baltimore County (UMBC)",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mapping integrated crop-livestock systems in Brazil with planetscope time series and deep learning",
        "paper_author": "Bueno I.T.",
        "publication": "Remote Sensing of Environment",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Accurate mapping of crops with high spatiotemporal resolution plays a critical role in achieving the Sustainable Development Goals (SDGs), especially in the context of integrated crop-livestock systems (ICLS). Stakeholders can make informed decisions and implement targeted strategies to achieve multiple SDGs related to agriculture, rural development, and sustainable livelihoods by understanding the spatial dynamics of these systems. Accurate information on the extent of ICLS derived from multitemporal remote sensing and emerging map techniques such as deep learning can help in the implementation of sustainable agricultural practices. However, far too little attention has been paid to ICLS map accuracy because it may not be at the forefront of research agendas compared to those of other agricultural practices. This paper aims to map ICLS using high spatiotemporal resolution imagery and deep learning neural network classifiers at two different sites located in Brazil. The pipeline involves four interpretation approaches based on the ICLS class: evaluating deep neural network classifiers with different image composition intervals, explaining commission and omission errors, evaluating the temporal transferability of the method, and evaluating the influence of variables. The study area consists of two locations in São Paulo (study site 1, SS1) and Mato Grosso state (study site 2, SS2), Brazil. We derived nine spectral variables from PlanetScope (PS) images and four metrics through object-based image analysis (OBIA) using two time intervals, 10 and 15 days, to generate the image compositions. These input variables were used in three deep neural network classifiers: convolutional neural network in one dimension (Conv1D), long short-term memory (LSTM), and LSTM with a fully convolutional network (LSTM-FCN). Our results showed that mapping dynamic land use such as ICLS is possible by using high-spatiotemporal-resolution imagery and deep neural network classifiers. The 15-day LSTM-FCN classifier returned the highest map accuracies for both sites, with the following class-level accuracies: producer accuracy (PA) = 97.0% and user accuracy (UA) = 97.0% for SS1 and PA = 82.0% and UA = 96.5% for SS2. Meanwhile, we found map uncertainties arising from the diverse crop calendars and spectro-temporal similarities between ICLS and other land use. The best approaches revealed that temporal generalization was suitable for mapping ICLS, but some classifiers could not generalize due to the inherent characteristics of the class. Most variables were considered efficient for predicting ICLS, although spectral indices revealed better functional relationships, while the PS bands had a lower influence on the predictions. The accuracies achieved with the proposed method represent promising opportunities for the sufficiently accurate mapping of ICLS and other complex crop activities.",
        "affiliation_name": "Universidade Estadual de Campinas",
        "affiliation_city": "Campinas",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Comparison of machine learning approaches for the classification of elution profiles",
        "paper_author": "Baccolo G.",
        "publication": "Chemometrics and Intelligent Laboratory Systems",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Hyphenated chromatography is among the most popular analytical techniques in omics related research. While great advancements have been achieved on the experimental side, the same is not true for the extraction of the relevant information from chromatographic data. Extensive signal preprocessing is required to remove the signal of the baseline, resolve the time shifts of peaks from sample to sample and to properly estimate the spectra and concentrations of co-eluting compounds. Among several available strategies, curve resolution approaches, such as PARAFAC2, ease the deconvolution and the quantification of chemicals. However, not all resolved profiles are relevant. For example, some take into account the baseline, others the chemical compounds. Thus, it is necessary to distinguish the profiles describing relevant chemistry. With the aim to assist researchers in this selection phase, we have tried three different classification algorithms (convolutional and recurrent neural networks, k-nearest neighbours) for the automatic identification of GC-MS elution profiles resolved by PARAFAC2. To this end, we have manually labelled more than 170,000 elution profiles in the following four classes: ‘Peak’, ‘Cutoff peak’,’ Baseline’ and ‘Others’ in order to train, validate and test the classification models. The results highlight two main points: i) neural networks seem to be the best solution for this specific classification task confirmed by the overall quality of the classification, ii) the quality of the input data is crucial to maximize the modelling performances.",
        "affiliation_name": "Københavns Universitet",
        "affiliation_city": "Copenhagen",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Machine learning based classification of lake ice and open water from Sentinel-3 SAR altimetry waveforms",
        "paper_author": "Mugunthan J.S.",
        "publication": "Remote Sensing of Environment",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "The aim of the study was to evaluate, for the first time, the capability of different machine learning (ML) algorithms in classifying along-track lake surface conditions (open water and ice types) across ice seasons (freeze-up, ice growth and break-up periods) from Sentinel-3 A/B synthetic aperture radar altimeter (SRAL) data. To achieve this goal, over 107,500 radar waveforms extracted from 11 large lakes across the Northern Hemisphere and three ice seasons (2018–2021) were manually labelled using complementary satellite data (Sentinel-1 imaging Synthetic Aperture Radar (SAR), Sentinel-2 Multispectral Instrument (MSI) Level 1C, and MODIS Aqua/Terra data) for the training and testing of the ML algorithms in discriminating between open water, young (thin) ice, growing ice and melting ice. The four ML algorithms tested include Random Forest (RF), Gradient Boosting Trees (GBT), K Nearest Neighbor (KNN) and Support Vector Machine (SVM). To characterize the waveforms, seven waveform parameters were derived: Leading Edge Width (LEW), Offset Center of Gravity (OCOG) Width, Pulse Peakiness (PP), backscatter coefficient (Sigma0), late tail to peak power (LTPP), early tail to peak power (ETPP) and the maximum value of the echo power (Max). Accuracies >95% were achieved across all classifiers using a 4-parameter combination (Sigma0, PP, OCOG Width, and LEW). Among all waveform parameters, Sigma0, OCOG width and PP were found to be the most important parameters for discriminating between lake ice types and open water. Despite showing comparable classification performances in the overall classification, RF and KNN are found to be a better fit for global lake ice mapping as both are less sensitive to their internal hyperparameters. Additionally, consistent results (>93.7% accuracy in all classifiers) achieved on the accuracy assessment carried out for each lake (out-of-sample testing) revealed the strength of the classifiers for spatial transferability. Implementation of RF and KNN could be valuable in a pre-or post-processing step for identifying lake surface conditions under which the retrieval of water level and ice thickness may be limited or not possible and, therefore, inform algorithms currently used for the generation of operational or research products. While the research focused on 11 of the largest lakes of the Northern Hemisphere, the classification approach presented herein has potential for application on smaller lakes too since data in SAR mode (∼300 m along-track resolution) are used.",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Protocol for the design and accelerated optimization of a waste-to-energy system using AI tools",
        "paper_author": "Zhou J.",
        "publication": "STAR Protocols",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Amid a surge in waste volume, the need to achieve sustainable waste treatment has become increasingly important. Here, we present a protocol for the design and accelerated optimization of a waste-to-energy system using artificial intelligence tools. We describe steps for waste treatment process advancement as demonstrated by the medical waste-to-methanol conversion and implementing data-driven process optimization. We then detail procedures for streamlining tasks by establishing connectivity between systems such as Aspen Plus and MATLAB. For complete details on the use and execution of this protocol, please refer to Shi et al. (2022)1 and Fang et al. (2022).2",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning approach to railway ballast degradation prognosis considering crumb rubber modification and parent rock strength",
        "paper_author": "Koohmishi M.",
        "publication": "Construction and Building Materials",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Parent rock strength and crumb rubber modification are two critical mechanical parameters that significantly decide the ballast layer degradation subjected to train dynamic loading. Using machine learning to predict ballast degradation considering these two parameters is helpful for deciding ballasted track maintenance cycle. In the current study, the ballast degradation process data (variables: parent rock types, loading types, ballast gradations and compositions of crumb rubber-ballast mixture) were used to train machine learning models. The drop-weight impact loading tests were performed to simulate different train dynamic loadings. Two well-established machine learning models, i.e., random forest (RF) and support vector regression (SVR) were trained and verified, to more effectively assess the importance of these variables. The results from the validated machine learning models confirm that the parent rock type is the most influential parameter, followed by the loading type (applied stress level), to control and predict the degradation of the ballast-CR mixture. The experimental assessment reveals that although the incorporation of CR suppresses degradation across all characterized rock types, the improvement in performance of the ballast-CR specimen against degradation is more noticeable for high-strength parent rock subjected to a considerable stress level. Meanwhile, this positive influence is also observed for ballast of weaker strength when the applied stress level is low.",
        "affiliation_name": "Faculteit Civiele Techniek en Geowetenschappen, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Spatio-temporal fusion of meteorological factors for multi-site PM2.5 prediction: A deep learning and time-variant graph approach",
        "paper_author": "Wang H.",
        "publication": "Environmental Research",
        "citied_by": "18",
        "cover_date": "2023-12-15",
        "Abstract": "In the field of environmental science, traditional methods for predicting PM2.5 concentrations primarily focus on singular temporal or spatial dimensions. This approach presents certain limitations when it comes to deeply mining the joint influence of multiple monitoring sites and their inherent connections with meteorological factors. To address this issue, we introduce an innovative deep-learning-based multi-graph model using Beijing as the study case. This model consists of two key modules: firstly, the 'Meteorological Factor Spatio-Temporal Feature Extraction Module'. This module deeply integrates spatio-temporal features of hourly meteorological data by employing Graph Convolutional Networks (GCN) and Long Short-Term Memory (LSTM) for spatial and temporal encoding respectively. Subsequently, through an attention mechanism, it retrieves a feature tensor associated with air pollutants. Secondly, these features are amalgamated with PM2.5 concentration values, allowing the 'PM2.5 Concentration Prediction Module' to predict with enhanced accuracy the joint influence across multiple monitoring sites. Our model exhibits significant advantages over traditional methods in processing the joint impact of multiple sites and their associated meteorological factors. By providing new perspectives and tools for the in-depth understanding of urban air pollutant distribution and optimization of air quality management, this model propels us towards a more comprehensive approach in tackling air pollution issues.",
        "affiliation_name": "Aerospace Information Research Institute",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reservoir tortuosity prediction: Coupling stochastic generation of porous media and machine learning",
        "paper_author": "Zou X.",
        "publication": "Energy",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Accurate reservoir tortuosity prediction is the foundation of the high-quality evaluation of reservoir petrophysical properties. However, conventional empirical equations as a form of experimental data fitting lacks universality because the data are usually from a single horizon or block. We developed a model combining the stochastic generation of porous media with machine learning (ML) to predict reservoir tortuosity based on pore structure parameters. Real core scanning images from public databases were employed in stochastic generation as reference, which is an economic and accurate method of meeting the dataset quality and scale requirements of ML. The particle swarm optimization algorithm, an efficient method of obtaining the best hyperparameter combination, was introduced for the hyperparameter tuning of six commonly used ML algorithms to determine the optional model for tortuosity prediction. Our trained ML models demonstrated superior tortuosity prediction accuracy over deterministic linear and exponential empirical equations with porosity as the only variable, which effectively demonstrates the potential of tortuosity prediction using pore structure parameters. The proposed ML model enables precise tortuosity predictions based on a few measurable pore structural features, which can be obtained from well logging data and CT scanning; thus, it can be widely used in petroleum and logging fields.",
        "affiliation_name": "China Academy of Launch Vehicle Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Operation optimization of multi-boiler district heating systems using artificial intelligence-based model predictive control: Field demonstrations",
        "paper_author": "Saloux E.",
        "publication": "Energy",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "District energy systems through fourth and fifth generations have shown great promises to help integrate renewable energy sources at large scale and to decarbonize the built environment. However, older generations using boilers represent a large proportion of systems currently in operation, and significantly contribute to greenhouse gas (GHG) emissions. Moreover, operational data has become increasingly available for these older generation systems and represents a suitable opportunity for Artificial Intelligence (AI)-based modelling and advanced controls. In this context, model predictive control (MPC) has appeared as a powerful control solution; however, field implementation remains relatively scarce. This paper aims to develop an AI-based MPC strategy for multi-boiler district heating systems. It relies on heating load forecasting machine learning models and data-driven boiler performance curves to optimize boiler thermal outputs. This strategy was implemented in two Canadian demonstration sites and showed GHG emissions reductions of 1.3 % and 2.8 %. Although relatively modest, statistical analysis confirmed the realization of these savings. In absolute terms, the strategy helped avoid 45 t and 77 t CO2eq emissions and save $10,268 and $19,975 CAD during the testing period of 2–3 months. The model and strategy developed in this work could be easily scalable to similar district heating systems.",
        "affiliation_name": "École de Technologie Supérieure",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Advancing Clinical Psychiatry: Integration of Clinical and Omics Data Using Machine Learning",
        "paper_author": "Qi B.",
        "publication": "Biological Psychiatry",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "NA",
        "affiliation_name": "School of Medicine",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Wearable and self-powered triboelectric sensors based on NaCl/PVA hydrogel for driver multidimensional information monitoring",
        "paper_author": "Luo F.",
        "publication": "Nano Energy",
        "citied_by": "22",
        "cover_date": "2023-12-15",
        "Abstract": "Dangerous behaviors during driving such as fatigue or making phone calls may seem common in daily life. However, these behaviors are the actual “culprit” of many traffic accidents and pose a serious threat to traffic safety. Therefore, it is necessary to effectively detect dangerous driving behaviors by scientific and technological means. The present detection methods still face many bottlenecks, including individual differences, complex lighting changes, battery power supply, poor wearability, et al. Here, we designed a green and stretchable triboelectric sensor (TES) to monitor dangerous driving behaviors. The performance of the sensor was improved by about 9.99 and 3.58 times through doping sodium chloride solution in PVA hydrogel and introducing a curved contact surface between the electrode and friction layer, respectively. The proposed sensor has a high sensitivity of 1.95 V/kPa in the linear range of 0–11.28 kPa. By employing different machine learning models, we developed an intelligent neck ring based on the proposed sensor array to recognize different neck movements, which has achieved the highest accuracy of 96.10%. Finally, the intelligent neck ring was used to construct a sensing system for driver status monitoring. By collecting detailed driver information, the system can detect dangerous driving behaviors, monitor drivers’ health conditions, and provide appropriate reminders to improve driving safety and prevent the spread of viruses.",
        "affiliation_name": "Southwest University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A wearable device based on the ionic liquid decorated sponge-like ultraviolet-curable resin for recognizing human mental health conditions",
        "paper_author": "Yin F.",
        "publication": "Nano Energy",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Developing a wearable device that can reliably and continuously detect human pulse signals and assess heart rate variability (HRV) parameters is essential for discriminating healthy subjects from patients with cardiovascular diseases and mental health disorders. Here, by combining a template-assisted ultraviolet-curing method with a subsequent ionic liquid modification, we propose a sponge-like dielectric layer and adopt it to construct a wearable device for decoding human mental health conditions. Benefiting from the coexisting sponge-like structures and an ionic liquid, the proposed wearable device presents a robust capacitance response, and could continuously monitor human pulse signals as well as analyze inter-beat intervals (IBIs) and HRV parameters of volunteers under different emotional states. Lastly, IBIs distributions and heart rates extracted from the pulse signals of the volunteers with different emotional conditions are employed as input features to train a machine-learning model, which is performed to further demonstrate the possibility of recognizing human emotions via pulse signal analysis. In conclusion, by incorporating the proposed wearable device with a machine-learning model, it is expected to achieve the emotional recognition of the volunteers with a piece of the pulse signal, showing promising potential in future human-machine interaction personalized with medical services, communications, and entertainment.",
        "affiliation_name": "University of Jinan",
        "affiliation_city": "Jinan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Bubble transport during SGTR accident in lead-cooled fast reactor: A machine learning",
        "paper_author": "Dong K.",
        "publication": "Nuclear Engineering and Design",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Steam generator tube rupture (SGTR) is one of the safety issues for pool-type lead-cooled fast reactors (LFR). Accurately quantifying and predicting the bubble transport result is essential for evaluating the accident. This paper addresses tracking the bubble motion using an Eulerian-Lagrangian method in CFD based on the Europe Lead cooling System (ELSY) primary system model at 1/8 centrosymmetric structure. The steady and transient bubble distributions in the system under different leakage heights are obtained. Furthermore, the simulation results are predicted by machine learning, where Gaussian Process Regression (GPR) is employed for both steady conditions and transient conditions. The data-driven GPR model is established for the bubble transport prediction, which can capture complex non-linear relationships between input variables (i.e. bubble diameter, SG leakage height, final position, system contaminate) and output (reached bubble percentage) responses directly from data. For steady conditions, the prediction results by the kernel function of Automatic Relevance Determination (ARD) Rational Quadratic show the best accuracy in predicting the percentages of bubbles reaching the core, top of the steam generator, and staying in the system, with a total Root Mean Square Error (RMSE) of 3.22%. Four typical transient cases of bubble accumulation in the core are selected for prediction. All the cases are well predicted by the kernel function of ARD Matern 3/2 with low mean averaged error.",
        "affiliation_name": "China General Nuclear Power Corporation",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Modeling of asphaltic sludge formation during acidizing process of oil well reservoir using machine learning methods",
        "paper_author": "Shakouri S.",
        "publication": "Energy",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Considering the global need for fossil fuels and its limited resources, maximum production from oil reservoirs is important. Acid treatment is a common method to stimulate oil reservoirs, but acid and oil interaction may form undesirable asphaltic sludge, and the prediction of this phenomenon by using machine learning models can be useful for field application. In this study, multi-layer perceptron (MLP), extreme gradient boosting (XGBoost), random forest (RF), and categorical boosting (CatBoost) as four machine learning models were employed to estimate the weight of asphaltic sludge formed. To this end, a data set containing 199 experimental data for seven different oil samples including a wide range of SARA fractions was used. The input parameters of the models included oil properties, acid properties, and the content of protective additives. The statistical analysis indicated that the MLP model has the highest accuracy with the coefficient of determination (R2) of 0.9517. In addition, the impact analysis of the input variables showed that the ferric ion concentration has the highest impact on asphaltic sludge formation with a relevance factor of 0.2755. Finally, using the leverage method, only 4 outlier data points were identified, which proved the validity of the model.",
        "affiliation_name": "Shiraz University",
        "affiliation_city": "Shiraz",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Bayesian-optimized random forest prediction of key properties of micro-/nanofibrillated cellulose from different woody and non-woody feedstocks",
        "paper_author": "Signori-Iamin G.",
        "publication": "Industrial Crops and Products",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The scale-up of nanocellulose production, a still challenging task, could benefit greatly from machine learning. In this paper, random forest regressors were applied to predict two important parameters for nanocellulose processing: nanofibrillation yield and aspect ratio. The dataset comprised diverse pulp sources, ranging from non-woody and woody feedstock, and two different types of pulp pre-treatments, namely mechanical refining and enzymatic hydrolysis. The obtained models were evaluated in terms of number of features and optimized with regard to some important hyperparameters, using the Bayesian optimization function from the SkOpt library. Considering the heterogeneity of the data, the prediction of both aspect ratio and yield of nanofibrillation was deemed satisfactory. For the former, R² scores of 0.986, 0.902 and 0.932 were obtained for the training, validation and testing subsets, respectively. Regarding the latter, R² scores of 0.994, 0.947 and 0.877 were achieved for the same types of subsets. Other important remarks are that enzyme dosage was the most important feature for predicting aspect ratio, while it did not play an important role for yield modelling. For this output, the transmittance at 600 nm accounted for almost 90% of the total feature importance.",
        "affiliation_name": "Universidade Federal do Parana",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "A Free and open-source microgrid optimization tool: SAMA the solar alone Multi-Objective Advisor",
        "paper_author": "Ali Sadat S.",
        "publication": "Energy Conversion and Management",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Although there are many software tools for simulations of hybrid energy systems, Homer Pro and Homer Grid are the only tools offering optimal sizing of hybrid energy systems. Originally developed as open-source software, they have been closed, which limits user-developers abilities to adapt and improve the software. In addition, all current proprietary offering suffer from the following limitations: i) high costs that limit accessibility to low-resource labs and individuals, ii) incapable of conducting multi-objective optimization, iii) constrained on any new innovations in hybrid energy system design and operation, iv) difficulties for users to specifically define prices and costs in inputs, v) inability to model different electric utility billing structures, vi) complex pricing methodology, and vii) the absence of machine learning-based predictive modeling. To overcome these limitations, this paper introduces and validates SAMA (Solar Alone Multi-objective Advisor), an open-source microgrid optimization software program designed to optimize hybrid energy system sizes economically using metaheuristic algorithms based on specific load profiles and meteorological data. Through rigorous validation exercises, SAMA's outcomes are compared against those generated by the Homer Pro software across distinct climatic conditions and geographical locations (i.e., Sacramento, California in the marine west coast and New Bern in humid continental climate zones of U.S., respectively). The results demonstrate congruence between SAMA and Homer Pro. SAMA can be used for a diverse array of applications from renewable energy systems to off-grid and grid-tied configurations, and from policy formulation to feasibility assessment. Unique features of SAMA include multi-objective optimizer, levelized emission optimization, different pre-defined utility billing structures, and a top-down pricing methodology. These features further enhance SAMA's adaptability, allowing users to tailor the software to their specific needs and system configurations. Finally, the paper anticipates future advancements that could refine component modeling, accelerate optimization processes, and incorporate advanced data analysis techniques such as machine learning to predict energy demand and production patterns.",
        "affiliation_name": "Ivey Business School",
        "affiliation_city": "London",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "State of health estimation for lithium-ion batteries based on two-stage features extraction and gradient boosting decision tree",
        "paper_author": "Pan R.",
        "publication": "Energy",
        "citied_by": "18",
        "cover_date": "2023-12-15",
        "Abstract": "To ensure the stable, reliable, and safe operation of lithium-ion batteries, the state of health (SOH) serves as a crucial basis for battery safety monitoring and operational maintenance. However, the complex working environment of batteries leads to the presence of a significant amount of noise data, abnormal data, and data discontinuities, posing challenges for battery feature extraction and SOH estimation. To address this issue, this paper proposes a two-stage transformation-based feature extraction method combined with the gradient boosting decision tree (GBDT) algorithm. The two-stage transformation feature extraction method utilizes singular spectrum analysis (SSA) and fast Fourier transform (FFT) to extract time-domain and frequency-domain health features from the battery data, respectively. The GBDT ensemble learning algorithm is employed to estimate the SOH of lithium-ion batteries, leveraging the capability to effectively uncover and learn relevant features by combining multiple weak learners into a strong model. Furthermore, correlation analysis and ablation experiments are conducted to validate the effectiveness of the two-stage feature extraction method. Additionally, four sets of comparative experiments are designed to demonstrate the superior performance of the GBDT method compared to four other machine learning methods. The experimental results show that the mean absolute error (MAE) and root mean square error (RMSE) of SOH estimation using the proposed method do not exceed 3 % on the NASA and CALCE datasets.",
        "affiliation_name": "Xiangtan University",
        "affiliation_city": "Xiangtan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A machine learning based predictive maintenance algorithm for ship generator engines using engine simulations and collected ship data",
        "paper_author": "Park J.",
        "publication": "Energy",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Ships are usually operated for more than 20 years, incurring large maintenance costs. Therefore, they require efficient and preemptive maintenance technology. Current research has focused on machine learning for predictive maintenance (PdM) of ships, but PdM data collection is limited because ship undergoes preventive maintenance and access to detailed data is restricted. Therefore, abnormal signs of ship equipment are not easily detected. To enable applications of machine-learning PdM to ship generator engines, this study collected and analyzed the data from operating ships. The abnormal data of the engine needed for machine learning were collected through engine simulations. In addition, generator engine condition criterion value (GCCV) was defined to determine anomalous symptoms based on the exhaust gas temperature by analyzing maintenance items. Next, a factor that corrects the GCCV under specific engine-operating conditions was derived using a regression analysis for establishing revision GCCV (RGCCV). The Mean Absolute Error (MAE) of RGCCV, which is calculated as a correction-factor, showed reliable results of 3.331–4.054 in all cylinders. After configuring and verifying the RGCCV-based engine-anomaly detection algorithm, anomalies during operation could be detected under normal conditions of the engine.",
        "affiliation_name": "Mokpo National Maritime University",
        "affiliation_city": "Mokpo",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A user-driven machine learning approach for RNA-based sample discrimination and hierarchical classification",
        "paper_author": "Imtiaz T.",
        "publication": "STAR Protocols",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "RNA-based sample discrimination and classification can be used to provide biological insights and/or distinguish between clinical groups. However, finding informative differences between sample groups can be challenging due to the multidimensional and noisy nature of sequencing data. Here, we apply a machine learning approach for hierarchical discrimination and classification of samples with high-dimensional miRNA expression data. Our protocol comprises data preprocessing, unsupervised learning, feature selection, and machine-learning-based hierarchical classification, alongside open-source MATLAB code.",
        "affiliation_name": "Queen's University, School of Medicine",
        "affiliation_city": "Kingston",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A novel crude oil futures trading strategy based on volume-price time-frequency decomposition with ensemble deep reinforcement learning",
        "paper_author": "Du X.",
        "publication": "Energy",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "With the deepening financialization of crude oil, an increasing number of investors are becoming involved in trading crude oil futures. However, various factors influence crude oil futures price fluctuations, presenting complex characteristics. For this reason, a trading strategy plays a crucial role in investment. In this paper, we construct an ensemble trading strategy by combining time-frequency feature extraction of crude oil volume-price series with deep reinforcement learning. We decompose the original oil volume-price series by using the optimized variational mode decomposition. Additionally, taking into account the long memory characteristics of the crude oil time series, we employ the Sharpe ratio to filter the appropriate agents corresponding to market volatility. Moreover, the best features of the three agents are effectively combined and used in the next phase of trading, thus robustly adapting to different market volatility situations. Finally, we tested our strategy using Brent crude oil futures. Compared with other benchmark models, the proposed OVMD(V–P)-DRL-Ensemble strategy is suitable for the highly volatile crude oil market and performs well in terms of the corresponding performance evaluation metrics, showing excellent return performance and stability.",
        "affiliation_name": "Fuzhou University",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Multi-fidelity graph neural network for flow field data fusion of turbomachinery",
        "paper_author": "Li J.",
        "publication": "Energy",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "Efficient and accurate prediction of the flow field in turbomachinery is vital for tasks such as optimization and off-design modeling. Deep learning methods offer inspiring tools for flow field prediction when there is sufficient high-fidelity data for training. However, high-fidelity flow fields may be insufficient in practice due to the high computational/experimental cost. In this work, the capabilities of deep learning methods for fusing multi-fidelity flow field data are further explored. A multi-fidelity graph neural network (MFGNN) is proposed. The proposed framework contains two networks for approximating the low-fidelity flow fields and the correlations between the low-fidelity and high-fidelity flow fields, respectively. The data fusion method is validated by the off-design flow field prediction of a turbine. With limited high-fidelity data, MFGNN can accurately predict flow fields and is superior to the graph neural network that only uses high-fidelity data. The effects of low-fidelity dataset size and the extrapolation performance are also explored. With appropriate prior guidance by low-fidelity data, MFGNN can predict unknown flow fields within and beyond the range of high-fidelity training datasets. The proposed deep learning method shows the advantages of high precision and generalizability in addressing the physical field prediction problem.",
        "affiliation_name": "Baidu, Inc.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Mechanical properties prediction of blast furnace slag and fly ash-based alkali-activated concrete by machine learning methods",
        "paper_author": "SUN B.",
        "publication": "Construction and Building Materials",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "In this paper, 871 data were collected from literature and trained by the 4 representative machine learning methods, in order to build a robust compressive strength predictive model for slag and fly ash based alkali activated concretes. The optimum models of each machine learning method were verified by 4 validation metrics and further compared with an empirical formula and experimental results. Besides, a literature study was carried out to investigate the connection between compressive strength and other mechanical characteristics. As a result, the gradient boosting regression trees model and several predictive formulas were eventually proposed for the prediction of the mechanical behavior including compressive strength, elastic modulus, splitting tensile strength, flexural strength, and Poisson's ratio of BFS/FA-AACs. The importance index of each parameter on the strength of BFS/FA-AACs was elaborated as well.",
        "affiliation_name": "Faculteit Civiele Techniek en Geowetenschappen, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Patterns and drivers of carbon stock change in ecological restoration regions: A case study of upper Yangtze River Basin, China",
        "paper_author": "Quan Y.",
        "publication": "Journal of Environmental Management",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Balancing ecology and human development has been a long and wide concern. The upper Yangtze River Basin (UYRB) of China has implemented large important ecological restoration projects since the last century. These restoration practices have changed land use patterns within the UYRB, consequently impacting the local carbon cycle. The most noteworthy project is the Grain for Green Program, which returns cropland to natural vegetation (forest and grassland). Yet the effects of restoration on land use change, carbon sequestration, and associated food production remain unclear. This study utilized remote sensing data and conversion coefficients to analyze the ecological-policy-induced land use changes of the UYRB from 2000 to 2020 and their impacts on terrestrial carbon sequestration. Linear regression, machine learning, and structural equation modeling (SEM) were utilized to evaluate the correlations between environmental and socio-economic factors and the distribution of carbon stocks. The results indicated positive effects of ecological activities on the UYRB, despite decreases in cropland. Over the past 20 years, the UYRB had sequestered carbon by a total amount of 1796 ± 926 Mt C. The spatial distribution of sequestered carbon demonstrated a strong correlation with slopes, followed by temperatures. The SEM results indicated that agricultural production and carbon sequestration were enhanced synergically under land use changes. This further demonstrated the effectiveness of these land policies in achieving a balance between crop productivity and ecology protection. We emphasized the importance of vegetation restoration in achieving carbon neutrality and the necessity to continue these projects. We suggested a more reasonable land management for the future UYRB based on the characteristics of each geographical subregion. This work serves as an example of effective land management to other locations worldwide perusing the harmony of ecological restoration and human development.",
        "affiliation_name": "Southwest University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Hybrid random forest-based models for predicting shear strength of structural surfaces based on surface morphology parameters and metaheuristic algorithms",
        "paper_author": "Zhou J.",
        "publication": "Construction and Building Materials",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "The prediction of shear strength between soil-structure interactions is of great significance to the stability of geotechnical engineering. In this study, 480 morphological data with seven morphological parameters (deviation of the root mean square value of the profile (Pq), skewness of the height distribution in the profile (Psk), kurtosis of the height distribution of the profiles (Pku), average width of outline elements (PSm), root mean square slope of the profile (Pdq), material ratio of the profile(Pmr), number of peaks (Ppc)) were selected to generate a comprehensive database for predicting the peak interface efficiency (IEp) considering three different soil particle sizes (0.35 mm, 0.53 mm, and 0.80 mm). Three random forest (RF) models optimized using dragonfly algorithm (DA-RF), sparrow search algorithm optimized random forest (SSA-RF), and whale optimization algorithm (WOA-RF) were generated to predict IEp. and compared the predictive performance with extreme learning machine (ELM), support vector regression with radial basis function kernel (SVR-RBF) and initial RF models. The mean absolute error (MAE), the mean absolute percentage error (MAPE), the root mean square error (RMSE), and the coefficient of determination (R2) were used to evaluate the performance of all models. The results showed that the WOA-RF model has achieved the best performance by resulting in MAE of (0.0145, 0.0181, 0.0179 and 0.0210, 0.0273, 0.0216), MAPE of (1.9866, 2.6417, 2.5310 and 2.8924, 4.0294, 3.0816), and RMSE of (0 0178, 0.0237,0.0224 and 0.0252, 0.0362, 0.0276), R2 (0.9473, 0.9262, 0.9352 and 0.9404, 0.8433, 0.9313) in the training and testing phases. The results of significance analysis indicated that Pdq and Pq have more importance than other parameters for predicting IEp.",
        "affiliation_name": "Université Grenoble Alpes",
        "affiliation_city": "Saint Martin d'Heres",
        "affiliation_country": "France"
    },
    {
        "paper_title": "An intelligent design method for new binder material activated by solid wastes by integrating attention-based tree model and heuristic optimization algorithm",
        "paper_author": "Zhang M.",
        "publication": "Construction and Building Materials",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "To promote the utilization of industrial solid waste, a new green binder system namely SCGF for sustainable concrete is developed, in which slag-fly ash is activated by soda residue-carbide slag. However, the mix design of the SCGF is challenging due to heavy workload and the lack of theoretical basis. The relationship between mix proportion and mechanical properties of SCGF needs to be accurately expressed. In this paper, an intelligent design method of SCGF is proposed by coupling the attention mechanism, machine learning and multi-objective heuristic optimization algorithm. After training with experimental data, the prediction performance of attention-based tree model is evaluated. Multiple Pareto optimal solutions can be obtained by the proposed intelligent mix proportion design method. The results show that attention-based tree models perform higher accuracy (accuracy > 95 %) and better measures than that of classical tree models. Compared the strength and cost of SCGF to cement mortar, the mix proportion designed in this study has obvious advantages in environmental protection and economy (>50 % cost saving). Therefore, the proposed method can provide a theoretical basis for the recycling and utilization of industrial solid wastes.",
        "affiliation_name": "Tianjin University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Observation-informed modeling of artificial neural networks to predict flow and bleeding of cement-based materials",
        "paper_author": "Kang I.K.",
        "publication": "Construction and Building Materials",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Workability of concrete, an essential aspect in construction, determines the efficiency of pumping and placement processes, as well as the strength and durability properties after hardening. The slump test is the most widely used method for evaluating workability, and technicians roughly estimate the workability using their human senses. It may be challenging to unexperienced technicians and vulnerable to mistakes. This study aims to substitute human sensory and slump tests with artificial intelligence. An artificial neural network was adopted to predict both the fluidity and bleeding of the mortars. The observation-informed modeling acquires input of the measurement, the viscosity curve in this study, for the prediction. The resultant network yields a high accuracy for predicting the channel flow and bleeding rate of the mortar samples. This approach can improve the quality and efficiency of construction processes by reducing errors caused by human-sensory based decision.",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A numerical comparison of simplified Galerkin and machine learning reduced order models for vaginal deformations",
        "paper_author": "Snyder W.",
        "publication": "Computers and Mathematics with Applications",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "High-fidelity computer simulations of childbirth remain prohibitively expensive and time consuming, making them impractical for guiding decision-making during obstetric emergencies. Cheap computer simulations that preserve the accuracy of high-fidelity models can be developed using surrogate modeling. Two common approaches to surrogate modeling are physics-based reduced order modeling (ROM) and machine learning (ML), with the latter gaining popularity as the scientific computing community seeks to leverage advances from other, mostly non-physics-based, computational strategies. Although ROM and ML have been compared for various problems, to our knowledge, such a comparison for simulations of vaginal deformations is currently missing. This study provides a baseline numerical comparison between methods from these two fundamentally different approaches. Since there are many methods falling into each modeling approach, to provide a fair and natural comparison, we select a basic model from each category, with each allowing (i) a straightforward implementation in commercial software packages, and (ii) use by practitioners with limited experience in the field. As a benchmark for the numerical comparison of the ROM and ML approaches, we use the finite element (FE) modeling of the ex vivo deformations of rat vaginal tissue subjected to inflation testing to study the effect of a pre-imposed tear. From the ROM strategies, we consider a simplified Galerkin ROM (G-ROM) that is based on the linearization of the underlying nonlinear equations. From the ML strategies, we select a feed-forward neural network to create mappings from constitutive model parameters and luminal pressure values to either the FE displacement history (in which case we denote the resulting model ML) or the proper orthogonal decomposition (POD) coefficients of the displacement history (in which case we denote the resulting model POD-ML). The numerical investigation of G-ROM, ML, and POD-ML takes place in the reconstructive regime. The numerical results show that the G-ROM outperforms the ML model in terms of offline central processing unit (CPU) time for model training, online CPU time required to generate approximations, and relative error with respect to the FE models. The G-ROM achieves superior error performance to the best ML model with 11 POD basis functions. With higher-dimensional POD bases, the G-ROM achieves a relative error 3 orders of magnitude lower than that of the best ML model with an online CPU time still on the same order of magnitude as the best ML model. The POD-ML model improves on the speed performance of the ML, having online CPU times comparable to those of the G-ROM given the same size of POD bases. However, the POD-ML model does not improve on the error performance of the ML and is still outperformed by the G-ROM for POD bases of size greater than 11. This baseline numerical investigation serves as a starting point for future computer simulations that consider state-of-the-art G-ROM and ML strategies, and the in vivo geometry, boundary conditions, and material properties of the human vagina, as well as their changes during labor.",
        "affiliation_name": "Virginia Tech College of Engineering",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Interpretability and causal discovery of the machine learning models to predict the production of CBM wells after hydraulic fracturing",
        "paper_author": "Min C.",
        "publication": "Energy",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning approaches are widely studied in the production prediction of CBM wells after hydraulic fracturing, but rarely used in practice due to the low generalization ability and the lack of interpretability. A novel methodology is proposed to discover the latent causality existed in the observed data of CBM wells, which is aimed at finding an indirect way to interpret the machine learning models. Based on the theory of causal discovery, a causal graph is derived with explicit variables, including the input, output and treatment variables. The proposed method can capture the underlying nonlinear relationship between the factors and the output, which remedies the limitation of the traditional machine learning routines based on the correlation analysis of factors. The experiment on the data of a CBM reservoir shows that the detected causal relationship between the production and the geological/engineering factors, is coincident with the actual physical mechanism. Meanwhile, compared with the traditional methods, the interpretable machine learning models have better performance in predicting production capability, averaging 5%–31% improvement in accuracy. An application is presented to optimize the fracturing scheme and validated by numerical simulation, which shows the ineterpretable method can improve the stimulated production in a high extent.",
        "affiliation_name": "Southwest Petroleum University China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Electrochemical self-powered strain sensor for static and dynamic strain detections",
        "paper_author": "Huang Q.",
        "publication": "Nano Energy",
        "citied_by": "41",
        "cover_date": "2023-12-15",
        "Abstract": "The self-powered strain sensors based on piezoelectric and triboelectric principles have been widely reported in flexible electronics, but they cannot achieve static strain detection. Inspired by electrochemical reactions, we propose and construct an electrochemical self-powered strain sensor for static and dynamic strain detections. Specifically, the sensor is composed of Cu/Al electrodes, elastic core-spun yarn coated with LiCl-carbon nanotubes (CNTs), and latex tube encapsulation. Among them, Cu and Al electrodes are used for electrochemical reactions; Elastic core-spun yarn endows the sensor with excellent tensile performance; LiCl provides conductive ions in electrochemical reactions; CNTs with good conductivity not only reduce the resistance between Cu and Al electrodes, but also facilitate good resistance strain effect; Latex tube encapsulation inhibits the evaporation of water molecules in the electrolyte. The strain sensing performance of the sensor is evaluated based on the current response. The results show that the sensor has wide strain detection range (2–100 %) and good repeatability (1000 times). By analyzing the strain voltage and current responses, as well as the morphology characterization of the sensor, the strain response mechanism of the sensor has been clarified, which is controlled by electrochemical reactions and resistance strain effect. The static strain monitoring function of the sensor is verified by monitoring finger bending. Combined with machine learning, the sensor can be used for respiratory behavior recognition. This work fundamentally contributes to developing self-powered strain sensor with static and dynamic strain detections.",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Topological Charge Identification of Vortex Beams Through Optical Correlation",
        "paper_author": "Kumar R.",
        "publication": "IEEE Photonics Technology Letters",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Recently optical beams containing orbital angular momentum have gained considerable attention due to their wide range of uses. In all the applications, accurate determination of the magnitude and sign of the topological charge (TC) is very important. Different techniques for determining the vortex beam's TC have been reported such as interferometric, diffractive, and machine learning based methods. In this letter, we demonstrate a novel technique to identify the TC of a vortex beam using the optical correlation method where a maximum average correlation height filter has been used. Unlike conventional methods, the proposed method enables instant identification of TC without manually counting the number of fringes and requires lesser datasets with simple architecture as compared to the machine learning-based method. The proposed idea is verified through both numerical simulation and experimental results with the help of fork-shaped interferometry.",
        "affiliation_name": "Indian Institute of Technology Patna",
        "affiliation_city": "Patna",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A novel hybrid deep learning model for multi-step wind speed forecasting considering pairwise dependencies among multiple atmospheric variables",
        "paper_author": "Jiang W.",
        "publication": "Energy",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "The reliable wind speed forecasting is critical for wind farms as it enables them to improve cost-effectiveness and optimize energy efficiency. In this study, a novel hybrid deep learning model is proposed for multi-step wind speed forecasting, which simultaneously captures pairwise dependencies and temporal features of multiple atmosphere variables. Initially, to extract intrinsic mode functions (IMFs) of nonstationary atmospheric variables, the Variational Mode Decomposition (VMD) is used. The decomposed atmospheric variables are then grouped according to similarity of mode and the pairwise dependencies are captured using the Graph Neural Network (GNN). Subsequently, the Temporal Convolutional Network (TCN) is applied for wind speed forecasting. The proposed model notably outperforms existing models with a Mean Absolute Error (MAE) of less than 0.1 m/s in one-hour ahead forecasting (1-h). Additionally, it improves wind speed forecasting accuracy by 79.22% at 1-h, 79.13% at 2-h, 80.00% at 3-h, 78.70% at 6-h, and 58.41% at 12-h, respectively, compared to the frequently used LSTM technique for wind speed forecasting. The outcomes of this study indicate that this novel approach to wind speed forecasting holds substantial potential for real-world wind farm operational contexts.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning for Predicting Postoperative Atrial Fibrillation After Cardiac Surgery: A Scoping Review of Current Literature",
        "paper_author": "El-Sherbini A.H.",
        "publication": "American Journal of Cardiology",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Postoperative atrial fibrillation (POAF) occurs in up to 20% to 55% of patients who underwent cardiac surgery. Machine learning (ML) has been increasingly employed in monitoring, screening, and identifying different cardiovascular clinical conditions. It was proposed that ML may be a useful tool for predicting POAF after cardiac surgery. An electronic database search was conducted on Medline, EMBASE, Cochrane, Google Scholar, and ClinicalTrials.gov to identify primary studies that investigated the role of ML in predicting POAF after cardiac surgery. A total of 5,955 citations were subjected to title and abstract screening, and ultimately 5 studies were included. The reported incidence of POAF ranged from 21.5% to 37.1%. The studied ML models included: deep learning, decision trees, logistic regression, support vector machines, gradient boosting decision tree, gradient-boosted machine, K-nearest neighbors, neural network, and random forest models. The sensitivity of the reported ML models ranged from 0.22 to 0.91, the specificity from 0.64 to 0.84, and the area under the receiver operating characteristic curve from 0.67 to 0.94. Age, gender, left atrial diameter, glomerular filtration rate, and duration of mechanical ventilation were significant clinical risk factors for POAF. Limited evidence suggest that machine learning models may play a role in predicting atrial fibrillation after cardiac surgery because of their ability to detect different patterns of correlations and the incorporation of several demographic and clinical variables. However, the heterogeneity of the included studies and the lack of external validation are the most important limitations against the routine incorporation of these models in routine practice. Artificial intelligence, cardiac surgery, decision tree, deep learning, gradient-boosted machine, gradient boosting decision tree, k-nearest neighbors, logistic regression, machine learning, neural network, postoperative atrial fibrillation, postoperative complications, random forest, risk scores, scoping review, support vector machine.",
        "affiliation_name": "Faculty of Health Sciences",
        "affiliation_city": "Kingston",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Protocol to implement a computational pipeline for biomedical discovery based on a biomedical knowledge graph",
        "paper_author": "Su C.",
        "publication": "STAR Protocols",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Biomedical knowledge graphs (BKGs) provide a new paradigm for managing abundant biomedical knowledge efficiently. Today's artificial intelligence techniques enable mining BKGs to discover new knowledge. Here, we present a protocol for implementing a computational pipeline for biomedical knowledge discovery (BKD) based on a BKG. We describe steps of the pipeline including data processing, implementing BKD based on knowledge graph embeddings, and prediction result interpretation. We detail how our pipeline can be used for drug repurposing hypothesis generation for Parkinson's disease. For complete details on the use and execution of this protocol, please refer to Su et al.1",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Uncertainty quantification in machine learning for engineering design and health prognostics: A tutorial",
        "paper_author": "Nemani V.",
        "publication": "Mechanical Systems and Signal Processing",
        "citied_by": "49",
        "cover_date": "2023-12-15",
        "Abstract": "On top of machine learning (ML) models, uncertainty quantification (UQ) functions as an essential layer of safety assurance that could lead to more principled decision making by enabling sound risk assessment and management. The safety and reliability improvement of ML models empowered by UQ has the potential to significantly facilitate the broad adoption of ML solutions in high-stakes decision settings, such as healthcare, manufacturing, and aviation, to name a few. In this tutorial, we aim to provide a holistic lens on emerging UQ methods for ML models with a particular focus on neural networks and the applications of these UQ methods in tackling engineering design as well as prognostics and health management problems. Towards this goal, we start with a comprehensive classification of uncertainty types, sources, and causes pertaining to UQ of ML models. Next, we provide a tutorial-style description of several state-of-the-art UQ methods: Gaussian process regression, Bayesian neural network, neural network ensemble, and deterministic UQ methods focusing on spectral-normalized neural Gaussian process. Established upon the mathematical formulations, we subsequently examine the soundness of these UQ methods quantitatively and qualitatively (by a toy regression example) to examine their strengths and shortcomings from different dimensions. Then, we review quantitative metrics commonly used to assess the quality of predictive uncertainty in classification and regression problems. Afterward, we discuss the increasingly important role of UQ of ML models in solving challenging problems in engineering design and health prognostics. Two case studies with source codes available on GitHub are used to demonstrate these UQ methods and compare their performance in the life prediction of lithium-ion batteries at the early stage (case study 1) and the remaining useful life prediction of turbofan engines (case study 2).",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Dearborn",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An interpretable machine learning model for predicting bond strength of CFRP-steel epoxy-bonded interface",
        "paper_author": "Ke L.",
        "publication": "Composite Structures",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "This study develops an interpretable machine learning model for predicting the bond strength of CFRP-steel epoxy bonding interfaces and reveals key bond parameters. A total of 302 sets of experimental data were collected from the existing literature, including 16 influencing factors (i.e. the “features”) for the bond strength of the CFRP-steel bonded interface. Firstly, the sequential backward selection algorithms based on random forest (RF), maximum information coefficient (MIC), and distance coefficient (DC) were assessed. Then, Catboost and RF-based models were optimized and evaluated to determine the best prediction model. Finally, Shapley Additive Explanation (SHAP) was used to interpret the Catboost-based model. The results showed that the average Coefficient of Determination (R2) of the prediction for the test set by the Catboost and RF-based models was 95.5 % and 91.5 %, respectively, indicating the Catboost-based model has a higher prediction accuracy. The SHAP analysis indicates that the bond length, bond width, and the elastic modulus of the adhesive are the critical bonding parameters governing the bond strength of CFRP-steel epoxy-bonded interfaces. The Pareto diagram shows that the effective bond length is about 120 mm. This study provides valuable guidance for the design of bond performance and process optimization of CFRP-steel epoxy bonding interfaces.",
        "affiliation_name": "Dongguan University of Technology",
        "affiliation_city": "Dongguan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of deep learning modelling of the optimal operation conditions of auxiliary equipment of combined cycle gas turbine power station",
        "paper_author": "Chen Y.",
        "publication": "Energy",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Reasonable condition adjustment of the auxiliary machinery can optimize the operation performance of the Combined Cycle Gas Turbine (CCGT) power station. In this paper an optimization method for the operation control of the auxiliary equipment based on deep learning is proposed and applied to an F-class gas turbine generation unit. A database of the optimal operating conditions is established to achieve the best economic benefit based on the analysis of two years of historical operation data. The control optimization models are built using the machine learning algorithms including the Multi-Layer Perceptron (MLP), Supporting Vector Machine (SVM), Gaussian process regression and linear regression methods and their accuracy has been compared. The input parameters of these models consist of the load rate, the heating output and the ambient temperature, with the output parameters including the electrical currents for the mechanical draft cooling tower, the high pressure feed pump, the medium pressure feed pump and the condensate pump. The MLP model is designed with different network hidden layer structures and provides the highest calculation accuracy with the least average error of 1.82 %. Different training data sizes are compared and the optimal control trajectory is analyzed. The result can provide useful references for the optimization of auxiliary equipment operations.",
        "affiliation_name": "Zhejiang Province Baimahu Laboratory Co. Ltd",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Forecasting hourly PM<inf>2.5</inf> concentration with an optimized LSTM model",
        "paper_author": "Tran H.D.",
        "publication": "Atmospheric Environment",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning has become a powerful tool in air quality assessment which can provide timely and predictable information, alert the public, and take timely measures to prevent deteriorating air quality. The study proposed a deep learning-based long-short term memory (LSTM) model to predict hourly PM2.5 in one of the most polluted areas in Taiwan. A series of sensitivity assessments with model settings was conducted to optimize the performance of the LSTM model. Regarding the model input parameters, aerosol optical depth, pressure, and PM2.5 concentrations from the three nearby stations were used and later showed significant improvement in the forecast results. As a result of the 1–24 h forecast in 2021, the root-mean-square error (RMSE) shows a range from 6.3 to 13.1 μg m−3, and the Pearson correlation coefficient (r) varies from 0.92 to 0.59, as compared with the observed PM2.5. The model's predictability decreases as time increases—a strong correlation (r higher than 0.7) within a 9-h PM2.5 forecast. The seasonal variation showed that the highest RMSE, about 16.2 μg m−3, was observed during the winter, which is the high-polluted season in the area. Additionally, the spatial representation of the model was examined. The model can perform an efficient and satisfied forecast in the radius of 15 km from the training station. We further compared several deep learning-based algorithms in forecasting PM2.5, and our model performs better prediction results. The deep learning–based model investigated in this study can be implemented for routine air quality monitoring in urban areas and air-quality alarms associated with public health.",
        "affiliation_name": "Environmental Protection Administration, Taiwan",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "A flexible and efficient knowledge-guided machine learning data assimilation (KGML-DA) framework for agroecosystem prediction in the US Midwest",
        "paper_author": "Yang Q.",
        "publication": "Remote Sensing of Environment",
        "citied_by": "13",
        "cover_date": "2023-12-15",
        "Abstract": "Process-based models are widely used to predict the agroecosystem dynamics, but such modeled results often contain considerable uncertainty due to the imperfect model structure, biased model parameters, and inaccurate or inaccessible model inputs. Data assimilation (DA) techniques are widely adopted to reduce prediction uncertainty by calibrating model parameters or dynamically updating the model state variables using observations. However, high computational cost, difficulties in mitigating model structural error, and low flexibility in framework development hinder its applications in large-scale agroecosystem predictions. In this study, we addressed these challenges by proposing a novel DA framework that integrates a Knowledge-Guided Machine Learning (KGML)-based surrogate with tensorized ensemble Kalman filter (EnKF) and parallelized particle swarm optimization (PSO) to effectively assimilate historical and in-season multi-source remote sensing data. Specifically, we incorporate knowledge from a process-based model, ecosys, into a Gated Recurrent Unit (GRU)-based hierarchical neural network. The hierarchical architecture of KGML-DA mimics key processes of ecosys and builds a causal relationship between target variables. Using carbon budget quantification in the US Corn-Belt as a context, we evaluated KGML-DA's performance in predicting key processes of the carbon cycle at three agricultural sites (US-Ne1, US-Ne2, US-Ne3), along with county-level (627 counties) and 30-m pixel-level (Champaign County, IL) grain yield. The site experiments show that updating the upstream variable, e.g., gross primary production (GPP), improved the prediction of downstream variables such as ecosystem respiration, net ecosystem exchange, biomass, and leaf area index (LAI), with RMSE reductions ranging from 9.2% to 30.5% for corn and 4.8% to 24.6% for soybean. Uncertainty in downstream variables was automatically constrained after correcting the upstream variables, demonstrating the effectiveness of the causality linkages in the hierarchical surrogate. We found joint use of in-season GPP and evapotranspiration (ET) products along with historical GPP and surveyed yields achieved the best prediction for county-level yields, while assimilating in-season LAI observations benefitted the prediction in extreme years. Uncertainty and error analysis of regional yield estimation demonstrated that KGML-DA could reduce prediction error by 26.5% for corn and 36.2% for soybean. Remarkably, the GPU-based tensor operation design makes this DA framework more than 7000 times faster than the PB model with a High-Performance Computing system, indicating the high potential of the proposed framework for in-season, high-resolution agroecosystem predictions.",
        "affiliation_name": "College of Science and Engineering",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Numerical Study on Retrofitting of Hot Rolled Steel Beams with Cold-formed Steel Encased Channels-Design Concept using Machine Learning Method",
        "paper_author": "Chobe G.",
        "publication": "Engineering Structures",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "The paper presents a numerical investigation on the retrofitting of Hot-Rolled Steel (HRS) beams using Cold-Formed Steel (CFS) encasing channels. The open cross-section HRS channel is transformed into a closed cross-section by encasing the CFS channel. This transformation increases the torsional rigidity of the structural member and helps in reducing the vulnerability of Lateral-Torsional Buckling (LTB). Parametric studies were carried out using numerical analysis. The existing experimental results were used for validation of the numerical model. A total of 600 numerical simulations including design parameters such as thickness of the CFS channel, intermediate spacing between the spot welds (connecting HRS and CFS channels), slenderness ratio, and the cross-sectional dimensions of the HRS beam were considered. The analyses indicated that the effectiveness of the retrofitting increases with an increase in the slenderness ratio of the HRS channel. Machine Learning (ML) method called Symbolic Regression (SR) was used to formulate an equation predicting the increment in the moment capacity as a function of parameters investigated. Finally, a simple design concept is suggested to determine the required CFS channel thickness and intermediate spot weld spacing to achieve the required increment in the moment capacity after retrofitting.",
        "affiliation_name": "Indian Institute of Technology Hyderabad",
        "affiliation_city": "Sangareddy",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A critical review of the recent trends in source tracing of microplastics in the environment",
        "paper_author": "Mohan K.",
        "publication": "Environmental Research",
        "citied_by": "19",
        "cover_date": "2023-12-15",
        "Abstract": "Microplastics are found across the globe because of their size and ability to transport across environments. The effects of microplastics on the micro- and macro-organisms have brought out concern over the potential risk to human health and the need to regulate their distribution at the source. Control of microplastic pollution requires region-specific management and mitigation strategies which can be developed with the information on sources and their contributions. This review provides an overview of the sources, fate, and distribution of microplastics along with techniques to source-trace microplastics. Source-tracing approaches provide both qualitative and quantitive information. Since better outcomes have been produced by the integration of techniques like backward trajectory analysis with cluster analysis, the significance of integrated and multi-dimensional approaches has been emphasized. The scope of the plastisphere, heavy metal, and biofilm microbial community in tracing the sources of microplastics are also highlighted. The present review allows the researchers and policymakers to understand the recent trends in the source-tracing of microplastics which will help them to develop techniques and comprehensive action plans to limit the microplastic discharge at sources.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Solar power generation forecasting by a new hybrid cascaded extreme learning method with maximum relevance interaction gain feature selection",
        "paper_author": "Memarzadeh G.",
        "publication": "Energy Conversion and Management",
        "citied_by": "15",
        "cover_date": "2023-12-15",
        "Abstract": "Today, renewable energies have a key role in sustainable and clean power generation. On the other hand, solar energy is available in most regions in developing economies. Therefore, photovoltaic power forecasting is crucial for low-carbon power operation, planning, and trading. In this paper, the proposed hybrid cascaded forecasters network model combines LSTM, NARX, ELM, MRIG feature selection, and WT techniques, enabling accurate Solar Power Generation Forecasting (SPGF) for the next 24 h. By integrating these diverse models, the hybrid approach capitalizes on the strengths of each model and compensates for their weaknesses. This synergy significantly enhances the efficiency and accuracy of the forecasting method, leading to improved SPGF performance. The results of day-ahead SPGF for this case study demonstrate the hybrid model's impressive accuracy. For instance, the average prediction error for SPGF of the Mahan PV power plant resulted in a MAPE of 4.7213%, MAE of 0.0100 MW, and RMSE of 0.0198 MW.",
        "affiliation_name": "Graduate University of Advanced Technology",
        "affiliation_city": "Kerman",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Ecological regulation network of quality in American Ginseng: Insights from macroscopic-mesoscopic-microscopic perspectives",
        "paper_author": "Zhang X.",
        "publication": "Industrial Crops and Products",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The environment profoundly influences the growth, development and constituents of plants. Nonetheless, a lack of comprehensive studies at various scales hinders our understanding of how environmental factors impact the quality of American ginseng. This study employed an integrated approach, considering macroscopic-mesoscopic-microscopic perspective, to reveal the ecological variables impacting the quality of American ginseng. From the macroscopic perspective, the MaxEnt model revealed that American ginseng is suitable for growth in temperate regions. The temperature seasonality and warmest quarter emerged as crucial bioclimatic factors that influence the distribution of American ginseng. Taking the mesoscopic perspective, the ginsenosides were significantly positively correlated with available phosphorus (AP) and soil water content (SWC), and significantly negatively correlated with ammonium nitrogen (NN), available potassium (AK), and microbial biomass carbon (MBC). From the microscopic perspective, a total of 16 microorganisms, including 14 bacteria and 2 fungi, were identified to have a significant impact on the synthesis of ginsenosides through 16 S and internally transcribed spacer (ITS) rRNA amplicon sequencing combine with machine learning. Notably, this is the first time to construct an ecological network for regulating the quality of American ginseng and identify the key ecological factors, which can serve as valuable references for targeted breeding and domestication of American ginseng. These findings not only established a theoretical foundation for the future investigation of biological fertilizers, but simultaneously provided crucial insights for cultivating high-quality medicinal plants.",
        "affiliation_name": "Institute of Medicinal Plant Development, Chinese Academy of Medical Sciences &amp; Peking Union Medical College",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Homogenization of daily temperatures using covariates and statistical learning—The case of parallel measurements",
        "paper_author": "de Valk C.",
        "publication": "International Journal of Climatology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "A data driven method based on generalized additive modelling (GAM) has been developed for homogenizing daily minimum and maximum temperature (TN, TX) series using parallel measurements and covariates. The method is applied to two coastal and two inland stations in the Netherlands. Between 1950 and 1972, these stations were relocated from cities to airports, accompanied by parallel measurement of at least 5 years at the old and new sites. Separating these parallel measurements in training and test data, the method compares numerous models involving covariates like the wind vector, cloudiness, specific humidity and sea surface temperature, and selects a model for each station. The resulting models offer an improvement compared to models based on temperature and season only: seasonal dependence is largely replaced by dependence on physical quantities. However, quantitatively, the impact is not large in the cases studied. One of the reasons might be that some covariates have only been measured at specific times not coinciding with the occurrences of the temperature minima or maxima. Additional benefits of the method are robustness and estimation of the sampling error variance of the daily homogenized daily temperature values.",
        "affiliation_name": "Royal Netherlands Meteorological Institute",
        "affiliation_city": "De Bilt",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "A segmented evaluation model for building energy performance considering seasonal dynamic fluctuations",
        "paper_author": "Zhang D.",
        "publication": "Energy Conversion and Management",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Carbon emissions of existing buildings in China have accounted for over 1/4 of the national total, and energy management in the building sector is influenced by energy performance evaluation, such as evaluation methods and indicators, accurate evaluation of building energy performance is crucial for achieving energy conservation and emission reduction. This study adopts medium (monthly)-long-term (multiyear) actual data, combines energy consumption characteristics and weather parameters, selects target variables with appropriate time granularity, segments the time series, strengthens the similarity of building characteristics within the segments and the practicability of adapting to climate change. Then XGBoost based on genetic algorithm optimization is used to construct an energy consumption prediction model within each segment, forming a comprehensive building performance evaluation method with multiple segments, two dimensions and multiple indicators. The results show that the segmented model has higher accuracy, fewer discrete points, more representative and targeted important features, and the R2 is up to 0.85. The model can provide a basis for managers to set energy consumption quotas, identify low-performance buildings, and improve energy efficiency.",
        "affiliation_name": "Chongqing University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "IDSN: A one-stage interpretable and differentiable STFT domain adaptation network for traction motor of high-speed trains cross-machine diagnosis",
        "paper_author": "He C.",
        "publication": "Mechanical Systems and Signal Processing",
        "citied_by": "30",
        "cover_date": "2023-12-15",
        "Abstract": "A surge of transfer fault diagnosis techniques has been proposed to guarantee the safe operation of traction motor systems. However, existing efforts highly depend on the availability of fault data in source domain, which is rare in practice due to the regular maintenance. Fortunately, self-customized testbeds provide an opportunity to easily obtain fault data, assuming that the simulated data can be utilized to monitor the real-world traction motor systems via the cross-machine diagnosis method. Besides, current deep learning-based cross-machine fault diagnosis methods suffer from the poor physical interpretability and the troublesome hype-parameter selection. To tackle aforementioned issues, a one-stage Interpretable and Differentiable STFT cross-machine dual-driven adaptation Network (IDSN) is proposed. In IDSN, a new paradigm termed interpretable differentiable STFT layer is devised, where a derivable coefficient is introduced to adjust pivotal parameters of STFT such as window length by the gradient descent. Prominently, it is a plug-and-play module, which can be embedded into the arbitrary typical network without conflict. Besides, a novel adaptive trade-off coefficient is developed to tackle the weight matching of the domain discrepancy metric. Finally, to ensure the reliability and effectiveness of cross-machine diagnosis, a concise yet valid smoothed joint maximum mean discrepancy is proposed, which simultaneously promotes intra-class compactness and inter-class separability. The results of experiments confirm that the proposed IDSN outperforms the state of the art.",
        "affiliation_name": "Collaborative Innovation Center of Railway Traffic Safety",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Femurs segmentation by machine learning from CT scans combined with autonomous finite elements in orthopedic and endocrinology applications",
        "paper_author": "Yosibash Z.",
        "publication": "Computers and Mathematics with Applications",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Efficient, accurate and reliable segmentation of femurs from CT-scans is of major importance for patient-specific autonomous finite element analysis (AFE) to determine bone's stiffness and strength. We present a fully automated segmentation algorithm for whole and partial femurs with or without tumors, and clinical applications of the AFE [1] in clinical practice. The segmentation is based on an U-Net convolutional neural network, resulting a 3D mask representing the desired femur in a CT scan. It is robust, independent of the scanning parameters such as slice spacing, pixel size, scanner manufacturer or the femoral length available in the scan. The U-Net was trained on 178 manually segmented femurs (23,721 images) and tested on 43. The performance evaluation resulted in a Dice similarity score (DSC) of 0.9924, intersection over union (IoU) of 0.9849, Hausdorff distance of 4.3315 mm and symmetric average surface distance (ASD) of 0.1326 mm. The algorithm is competitive with the best state-of-the-art femoral segmentation methodologies available. Based on the segmentation an automatic p-FE mesh is generated and physiological boundary conditions representing sidewise falls or stance are being applied automatically to improve the performance of the AFE described in [1]. New examples of the usage of the AFE in endocrinology and orthopedic oncology demonstrate this disruptive technology in actual clinical practice. We present the use of AFE for predicting hip fracture risk in the elderly population due to a sidewise fall and the identification of patients who require a prophylactic surgery due to metastatic tumors in their femurs.",
        "affiliation_name": "Tel Aviv University",
        "affiliation_city": "Tel Aviv-Yafo",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Ecosystem responses dominate the trends of annual gross primary productivity over terrestrial ecosystems of China during 2000–2020",
        "paper_author": "Zhu X.J.",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "The annual gross primary productivity (AGPP) forms the foundation for terrestrial carbon sink. AGPP trends stem from the combined impacts of environmental factors and ecosystem responses to those factors. These responses include model structure modifications altering both the structural properties (represented by leaf area index) and the functional properties (represented by per leaf AGPP). Understanding the contributions of ecosystem responses to AGPP trends is crucial for accurately assessing spatiotemporal variations in AGPP, which aids in effective carbon management. Based on eddy covariance measurements of AGPP in China, we generated AGPP during 2000–2020 by constructing yearly AGPP mapping schemes from site measurements and analyzed AGPP trends. The roles of ecosystem responses and their pathways were further elucidated by employing analysis of variance. Results showed that the total AGPP in China was 7.39 ± 0.62 PgC yr−1, with an increasing trend of 0.095 PgC yr−2. This increase primarily sourced from the total AGPP in Subtropical Evergreen Needleleaf Forest. AGPP trends spatially decreased from east to west, with most regions showing positive values. Structural and functional properties contributed similarly to AGPP trends, with varying regional contributions. The structural properties played a dominant role in north regions while the functional properties were more important in south and west regions. Ecosystem responses similarly determined the trends of ecosystem properties, which decreased from west to east. Ecosystem responses thus dominated AGPP trends through the structural properties in north regions but through the functional properties in south and west regions. Therefore, Chinese AGPP exhibited a spatially varied increasing trend during 2000–2020. Ecosystem responses dominated AGPP trends through divergent properties across regions. Our results highlight the significanc of ecosystem responses in AGPP trends and their divergent pathways across regions. This also provides independent data support for quantifying regional carbon budgets.",
        "affiliation_name": "Northwest Institute of Eco-Environment and Resources",
        "affiliation_city": "Lanzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sparse Bayesian machine learning for the interpretable identification of nonlinear structural dynamics: Towards the experimental data-driven discovery of a quasi zero stiffness device",
        "paper_author": "Chatterjee T.",
        "publication": "Mechanical Systems and Signal Processing",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Data-driven discovery of governing laws for complex nonlinear structural dynamic systems remains a challenging issue of paramount importance. This work addresses the above issue by leveraging the available noisy data and integrating sparse Bayesian machine learning (ML) techniques to discover the governing equations. The problem of discovery is re-cast as the automatic relevance determination of models (model selection) from the library of potential candidate basis terms and their coefficients are determined (parameter identification) using sparse Bayesian linear regression. Two sparsity promoting ML algorithms based on relevance vector machines have been employed. Both these approaches use Bayesian statistics and quantify the uncertainty associated with the model predictions. Results from four representative numerical examples of nonlinear structural dynamics illustrate excellent performance of both proposed approaches. The results have been validated with the true governing equations and time response data. Comparison has also been made with a recent and popular sparse discovery approach. Finally, the proposed framework is applied to real datasets that were generated from an in-house designed experimental setup of a quasi zero stiffness device and good performance has been observed.",
        "affiliation_name": "University of Surrey",
        "affiliation_city": "Guildford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Multiscale graph neural network autoencoders for interpretable scientific machine learning",
        "paper_author": "Barwey S.",
        "publication": "Journal of Computational Physics",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "The goal of this work is to address two limitations in autoencoder-based models: latent space interpretability and compatibility with unstructured meshes. This is accomplished here with the development of a novel graph neural network (GNN) autoencoding architecture with demonstrations on complex fluid flow applications. To address the first goal of interpretability, the GNN autoencoder achieves reduction in the number nodes in the encoding stage through an adaptive graph reduction procedure. This reduction procedure essentially amounts to flowfield-conditioned node sampling and sensor identification, and produces interpretable latent graph representations tailored to the flowfield reconstruction task in the form of so-called masked fields. These masked fields allow the user to (a) visualize where in physical space a given latent graph is active, and (b) interpret the time-evolution of the latent graph connectivity in accordance with the time-evolution of unsteady flow features (e.g. recirculation zones, shear layers) in the domain. To address the goal of unstructured mesh compatibility, the autoencoding architecture utilizes a series of multi-scale message passing (MMP) layers, each of which models information exchange among node neighborhoods at various lengthscales. The MMP layer, which augments standard single-scale message passing with learnable coarsening operations, allows the decoder to more efficiently reconstruct the flowfield from the identified regions in the masked fields. Analysis of latent graphs produced by the autoencoder for various model settings are conducted using unstructured snapshot data sourced from large-eddy simulations in a backward-facing step (BFS) flow configuration with an OpenFOAM-based flow solver at high Reynolds numbers.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Development and validation of machine learning-based transient identification models in a liquid-fueled molten salt reactor system",
        "paper_author": "Zhou T.",
        "publication": "Nuclear Engineering and Design",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Safety is the most important aspect of nuclear power plants. Rapid identification and effective prevention of accidents in nuclear reactor system is a significant method to enhance the safety of the current fleet of reactors. Machine learning (ML) has been introduced in engineering applications of nuclear power plants and is becoming increasingly practical and powerful in recent years. Consequently, ML can also benefit rapid transient identification in nuclear power plants. The feasibility of ML-based identification models to identify transient events in liquid-fueled Molten Salt Reactor (MSR) is presented. Four transient identification models based on recurrent neural network (RNN), support vector machine (SVM), decision tree (DT) and k-nearest neighbor (KNN) were developed and validated. RELAP5-TMSR code was used to generate datasets including eleven operation conditions, and these datasets were used to train, optimize, and validate the identification models. Four metrics including accuracy, precision, recall and F1 score were utilized to evaluate all four identification models. Moreover, the robustness of the models under noise was tested. The four ML-based models were successfully applied to transient identification of liquid-fueled MSRs. The KNN-based model has the best performance and achieves high test scores under noise. In the future, these proposed intelligent identification models will have good potential and prospects in supporting the operation of nuclear power plants.",
        "affiliation_name": "Shanghai Institute of Applied Physics, Chinese Academy of Sciences",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "High-power hybrid alkali-acid fuel cell for synchronous glycerol valorization implemented by high-entropy sulfide electrocatalyst",
        "paper_author": "Wang P.",
        "publication": "Nano Energy",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "Developing highly efficient electrocatalysts for selective glycerol oxidation reaction (GOR) is crucial to implement biomass valorization and to advance the energy conversion efficiency of glycerol fuel cells. Herein, a hybrid alkali-acid direct glycerol fuel cell (DGFC) that can not only deliver a high power density but also enable glycerol valorization conversion is demonstrated. Such double-benefits electrochemical device is implemented by in situ growth of FeCoNiCrMnS2 nanoparticles on carbon cloth (FeCoNiCrMnS2/CC) as anode, which exhibits high activity and selectivity for GOR with low overpotential and high Faradaic efficiency toward the formate product. Based on the results of finite element method simulations of element distribution on FeCoNiCrMnS2, the electrocatalytic sites was investigate by density functional theory in conjunction with Monte Carlo and machine learning simulations and confirmed that the desired catalytic properties primarily originate from the Ni and Co sites, while Cr and Mn optimized the electronic structure of these sites. The as-developed DGFC can release a maximum peak power density of 50.1 mW cm−2 and stably generate formate with high selectivity. The present work may inspire to contrive the newly advanced energy device and provide fresh impetus for the development of newly high-entropy materials for a variety of application.",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "From prediction to design: Recent advances in machine learning for the study of 2D materials",
        "paper_author": "He H.",
        "publication": "Nano Energy",
        "citied_by": "32",
        "cover_date": "2023-12-15",
        "Abstract": "Although data-driven approaches have made significant strides in various scientific fields, there has been a lack of systematic summaries and discussions on their application in 2D materials science. This review comprehensively surveys the multifaceted applications of machine learning (ML) in the study of 2D materials, filling this research gap. We summarize the latest developments in using ML for bandgap prediction, magnetic classification, catalyst material screening, and material synthesis design. Furthermore, we discuss the future directions of ML applications in various domains, providing robust references and guidance for future research in this field. Compared to traditional methods, we particularly emphasize the unique advantages of ML in predicting the bandgap of 2D materials, such as the introduction of advanced feature engineering and algorithms to enhance research efficiency. We also summarize ML algorithms for classifying the magnetism of 2D materials, showing that complex pattern recognition can precisely interpret the correlation between magnetic moments and atomic structures. Additionally, the review outlines how ML algorithms can efficiently sift through large-scale material databases to identify candidates with specific catalytic properties, thereby greatly accelerating the discovery process for new catalysts. ML has become a powerful tool in the field of materials science, promoting the discovery of new materials, improving their properties, and accelerating research across various application domains.",
        "affiliation_name": "Wuhan University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Driving style-aware energy management for battery/supercapacitor electric vehicles using deep reinforcement learning",
        "paper_author": "Wu Y.",
        "publication": "Journal of Energy Storage",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Driving style can significantly affect the energy consumption, battery lifespan, and driving economy of electric vehicles. In this context, this paper proposes a novel driving style-aware energy management strategy for electric vehicles with battery/supercapacitor hybrid energy storage systems based on deep reinforcement learning. Firstly, a semi-supervised support vector machine-based driving style recognition method is presented to recognize the driving style, where twenty features are extracted from limited labeled velocity/acceleration data and then reduced to six dimensions by locally linear embedding. The six dimension features are used to obtain accurate recognition results. Then a proximal policy optimization-based energy management strategy is proposed with the driving style as an additional input state, to optimize the power allocation and minimize the battery capacity loss cost. Extensive results illustrate the effectiveness of the proposed methods, e.g., the proposed driving style recognition method can recognize the real-time driving style with an accuracy of over 95%. Taking the recognized style as input, the proposed driving style-aware energy management strategy can reduce the battery capacity loss cost by 3.30–4.19% and 1.77–8.15%, compared with no driving style and incorrect driving style input energy management methods, respectively.",
        "affiliation_name": "Changsha University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Impact of air pollutants on climate change and prediction of air quality index using machine learning models",
        "paper_author": "Ravindiran G.",
        "publication": "Environmental Research",
        "citied_by": "25",
        "cover_date": "2023-12-15",
        "Abstract": "The impact of air pollution in Chennai metropolitan city, a southern Indian coastal city was examined to predict the Air Quality Index (AQI). Regular monitoring and prediction of the Air Quality Index (AQI) are critical for combating air pollution. The current study created machine learning models such as XGBoost, Random Forest, BaggingRegressor, and LGBMRegressor for the prediction of the AQI using the historical data available from 2017 to 2022. According to historical data, the AQI is highest in January, with a mean value of 104.6 g/gm, and the lowest in August, with a mean AQI value of 63.87 g/gm. Particulate matter, gaseous pollutants, and meteorological parameters were used to predict AQI, and the heat map generated showed that of all the parameters, PM2.5 has the greatest impact on AQI, with a value of 0.91. The log transformation method is used to normalize datasets and determine skewness and kurtosis. The XGBoost model demonstrated strong performance, achieving an R2 (correlation coefficient) of 0.9935, a mean absolute error (MAE) of 0.02, a mean square error (MSE) of 0.001, and a root mean square error (RMSE) of 0.04. In comparison, the LightGBM model's prediction was less effective, as it attained an R2 of 0.9748. According to the study, the AQI in Chennai has been increasing over the last two years, and if the same conditions persist, the city's air pollution will worsen in the future. Furthermore, accurate future air quality level predictions can be made using historical data and advanced machine learning algorithms.",
        "affiliation_name": "Karpaga Vinayaga College of Engineering and Technology",
        "affiliation_city": "Maduranthakam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Experimental Uncertainty in Training Data for Protein-Ligand Binding Affinity Prediction Models",
        "paper_author": "Hernández-Garrido C.A.",
        "publication": "Artificial Intelligence in the Life Sciences",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The accuracy of machine learning models for protein-ligand binding affinity prediction depends on the quality of the experimental data they are trained on. Most of these models are trained and tested on different subsets of the PDBbind database, which is the main source of protein-ligand complexes with annotated binding affinity in the public domain. However, estimating its experimental uncertainty is not straightforward because just a few protein-ligand complexes have more than one measurement associated. In this work, we analyze bioactivity data from ChEMBL to estimate the experimental uncertainty associated with the three binding affinity measures included in the PDBbind (Ki, Kd, and IC50), as well as the effect of combining them. The experimental uncertainty of combining these three affinity measures was characterized by a mean absolute error of 0.78 logarithmic units, a root mean square error of 1.04 and a Pearson correlation coefficient of 0.76. These estimations were contrasted with the performances obtained by state-of-the-art machine learning models for binding affinity prediction, showing that these models tend to be overoptimistic when evaluated on the core set from PDBbind.",
        "affiliation_name": "Instituto de Investigaciones en Matemáticas Aplicadas y en Sistemas",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Advancements in Artificial Neural Networks for health management of energy storage lithium-ion batteries: A comprehensive review",
        "paper_author": "Zou Y.",
        "publication": "Journal of Energy Storage",
        "citied_by": "34",
        "cover_date": "2023-12-15",
        "Abstract": "Lithium-ion batteries, growing in prominence within energy storage systems, necessitate rigorous health status management. Artificial Neural Networks, adept at deciphering complex non-linear relationships, emerge as a preferred tool for overseeing the health of these energy storage lithium-ion batteries. This paper presents a comprehensive review of the current research in this field. The discussion initiates with the distinctions between energy storage batteries and power batteries, the composition and management of battery energy storage systems, and common evaluation metrics such as State of Health, State of Charge, and Remaining Useful Life. This is followed by outlining common open datasets, data preprocessing techniques, health feature extraction methods, and battery health prediction approaches. Emphasis is laid on the utilization of Artificial Neural Networks for lithium-ion battery health management, encompassing a spectrum of networks from Feedforward Neural Network, Extreme Learning Machine, Convolutional Neural Network, Recurrent Neural Network (with Long Short-Term Memory and Gated Recurrent Unit) to Transformer and methodologies like transfer learning and the integration of traditional techniques with Artificial Neural Networks. Concluding remarks ponder over the future prospects and challenges of using Artificial Neural Networks for lithium-ion battery health management.",
        "affiliation_name": "Macau University of Science and Technology",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "A green approach for multivariate consecutive extraction of essential oils and flavonoids from Citrus aurantium L. var. amara Engl.: Process optimization and mechanistic insights based on machine learning methods",
        "paper_author": "Zhou P.",
        "publication": "Industrial Crops and Products",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "In this study, a green approach for the multivariate consecutive extraction of essential oils and total flavonoids from Daidaihua was proposed, which combined classical steam distillation with alkali extraction and acid precipitation. The process parameters were optimized through single-factor experiments and Box-Behnken design, and the model for evaluating and predicting the process was constructed by combining artificial neural network and genetic algorithm. The artificial neural network and genetic algorithm model demonstrated satisfactory predictive capabilities, and the following optimal parameters resulted: solid-liquid ratio 1:15.3 (g:mL), distillation time 94.1 h, NaOH concentration 5.4%, extraction temperature 46.7 ℃and extraction time 52.9 min. Under these conditions, the extraction yields of essential oils and total flavonoids reached 0.81 ± 0.07% and 5.52 ± 0.18%, respectively. Significantly, the mass transfer mechanism of the multivariate consecutive extraction process was clearly elucidated using the mass transfer theory model and physical characterization. The essential oils were vaporized from the Daidaihua cells along with water vapor, promoting the destruction of cell structure, reducing the extraction resistance of flavonoids, and speeding up the diffusion of sodium hydroxide solution rapidly into the cell interior and dissolving the flavonoids, improving the efficiency of the mass transfer of flavonoids from the inside to the outside of the cell, consequently the flavonoids extraction yield and efficiency were significantly improved. Obviously, the extraction process dovetailed neatly with environmentally friendly and low-carbon needs. Meanwhile, the composition of the essential oils and total flavonoids was identified by GC-MS and HPLC-MS analysis, respectively. Overall, this research presented a green and clean multivariate consecutive extraction process of Daidaihua, which could contribute to promoting the upgrading and sustainable development of the plant extraction industry.",
        "affiliation_name": "Central South University of Forestry and Technology",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A circuit complexity formulation of algorithmic information theory",
        "paper_author": "Wyeth C.",
        "publication": "Physica D: Nonlinear Phenomena",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Inspired by Solomonoff's theory of inductive inference (Solomonoff, 1964), we propose a prior based on circuit complexity. There are several advantages to this approach. First, it relies on a complexity measure that does not depend on the choice of Universal Turing machine (UTM). There is one universal definition for Boolean circuits involving a universal operation (e.g. NAND) with simple conversions to alternative definitions (with AND, OR, and NOT). Second, there is no analogue of the halting problem. The output value of a circuit can be calculated recursively by computer in time proportional to the number of gates, while a short program may run for a very long time. Our prior assumes that a Boolean function (or equivalently, Boolean string of fixed length) is generated by some Bayesian mixture of circuits. This model is appropriate for learning Boolean functions from partial information, a problem often encountered within machine learning as “binary classification.” We argue that an inductive bias towards simple explanations as measured by circuit complexity is appropriate for this problem.",
        "affiliation_name": "College of Science and Engineering",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multiple domain dynamic feature adaption transfer learning method for stranded wires health monitoring under variable vibration working conditions using laser-generated ultrasonic guided wave",
        "paper_author": "Yang D.",
        "publication": "Engineering Structures",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Laser-generated ultrasonic guided wave is proved as a promising way to the structural health monitoring (SHM) of Stranded wires. However, variable vibrations would greatly affect the damage identification precision of stranded wires for the consequent distribution changes to collected signals. Aiming at this problem, a robust domain adversarial adaptation capsule network (DAACN) is proposed to reduce the influence of vibration and achieve reliable health state identification. Firstly, the UGW signals are preprocessed by normalization, phase alignment and bandpass filtering. Afterward, these preprocessed signals are divided into source and target signals and mapped to a high-dimensional feature domain space by deep feature extractor. Furthermore, an adversarial learning model, which contains a global domain discriminator and a local domain discriminator, is designed to help align the marginal distribution and conditional distribution of the two domain features. Then, a damage decoupled capsule network is built to obtain the relationship between the source features and damage labels. Finally, by joint adversarial training among the damage decoupled capsule network, global and local discriminator, the final model is obtained to identify the real structural state of test signals. Experimental results show that the proposed DAACN method can effectively align the damage feature under different vibration working conditions. Identification precision of more than 99% in all conditions also proves the superiority of the proposed method.",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Bayesian framework for learning governing partial differential equation from data",
        "paper_author": "More K.S.",
        "publication": "Physica D: Nonlinear Phenomena",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "The discovery of partial differential equations (PDEs) is a challenging task that involves both theoretical and empirical methods. Machine learning approaches have been developed and used to solve this problem; however, it is important to note that existing methods often struggle to identify the underlying equation accurately in the presence of noise. In this study, we present a new approach to discovering PDEs by combining variational Bayes and sparse linear regression. The problem of PDE discovery has been posed as a problem in learning relevant basis from a predefined dictionary of basis functions. To accelerate the overall process, a variational Bayes-based approach for discovering partial differential equations is proposed. To ensure sparsity, we employ a spike and slab prior. We illustrate the efficacy of our strategy in several examples, including Burgers, Korteweg–de Vries, Kuramoto Sivashinsky, wave equation, and heat equation (1D as well as 2D). Our method offers a promising avenue for discovering PDEs from data and has potential applications in fields such as physics, engineering, and biology.",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Development of modular and reusable AI models for fast predicting fire behaviour of steel columns in structural systems",
        "paper_author": "Qiu J.",
        "publication": "Engineering Structures",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "It is important to model the local failure of structural members as well as the global responses of a structural system when it is exposed to fire. The local failure of columns such as buckling requires high-resolution models, which could be not used for modelling a structural system for its computational cost. Inspired by the hybrid simulation technique, this paper aims to develop modular AI models as a first attempt to predict the local performance of a specific steel column exposed to fires and to enable the future communication with structural system model. Two kinds of machine learning methods namely artificial neural network (ANN) and support vector regression (SVR) are utilized to train AI models based on a large numerical dataset extended from a 3D detailed shell model of columns after validation against fire test results. The excellent prediction performance of AI models is shown regarding the mean squared error (MSE), mean absolute error (MAE), coefficient of the variation of the root mean square error (cvRMSE), variance accounting for (VAL) and coefficient of determination (R2). Moreover, the capability of AI models is demonstrated in predicting fire behaviour of columns in untrained steady heating and transient heating scenarios. A further demonstration is performed within a plane-frame structure simulated with a hybrid-scale model and considering standard fire heating on columns, which shows great potential of the AI models towards further implementation in hybrid simulation.",
        "affiliation_name": "State Key Laboratory of Disaster Reduction in Civil Engineering",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Physics-informed neural networks for approximating dynamic (hyperbolic) PDEs of second order in time: Error analysis and algorithms",
        "paper_author": "Qian Y.",
        "publication": "Journal of Computational Physics",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "We consider the approximation of a class of dynamic partial differential equations (PDEs) of second order in time by the physics-informed neural network (PINN) approach, and provide an error analysis of PINN for the wave equation, the nonlinear Klein-Gordon equation and the linear elastodynamic equation. Our analyses show that, with feed-forward neural networks having two hidden layers and the tanh activation function, the PINN approximation errors for the solution field, its time derivative and its gradient field can be effectively bounded by the training loss and the number of training data points (quadrature points). Our analyses further suggest new forms for the training loss function, which contain certain residuals that are crucial to the error estimate but would be absent from the canonical PINN loss formulation. Adopting these new forms for the loss function leads to a variant PINN algorithm. We present ample numerical experiments with the new PINN algorithm for the wave equation, the Sine-Gordon equation and the linear elastodynamic equation, which show that the method can capture the solution well.",
        "affiliation_name": "Xiangtan University",
        "affiliation_city": "Xiangtan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Global and direct solar irradiance estimation using deep learning and selected spectral satellite images",
        "paper_author": "Chen S.",
        "publication": "Applied Energy",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "To fully exploit the spectral information of modern geostationary satellites, this work proposes a deep learning framework using convolutional neural networks (CNNs) and attention mechanism for 5-min ground-level global horizontal irradiance (GHI) and direct normal irradiance (DNI) estimations. The inputs are spectral satellite images with the target ground station in the center, and the labels are irradiance measurements normalized by their clear-sky estimations. The use of CNNs and attention mechanism aims to better extract the spatial information for estimating ground-level solar irradiance. To improve the modeling efficiency, only a subset of spectral bands is selected based on correlation analysis, which has comparable performance with the usage of all satellite bands. The results show that the proposed method produces GHI estimation with a normalized root mean squared error (nRMSE) of 20.57% and a normalized mean bias error (nMBE) of −2.04%, and the DNI estimation has an nRMSE of 23.63% and the nMBE is 0.36%. Compared with the national solar radiation database (NSRDB), GHI and DNI estimations of the proposed method has the nRMSE reduction of 5.15% and 13.77%, respectively. Meanwhile, the proposed models generally yield better GHI and DNI estimations under different intervals of clear-sky index than NSRDB. The combination of deep learning and remote sensing shows potential in better extracting the cloud information via multispectral satellite images, which can better support solar resource assessment, especially for cloudy conditions.",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "A novel online learning-based linear quadratic regulator for vanadium redox flow battery in DC microgrids",
        "paper_author": "Liu Y.",
        "publication": "Journal of Power Sources",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "This paper proposes a novel learning-based linear quadratic regulator (LQR) to overcome the long-lasting problem of model dependency in the existing vanadium redox flow battery (VRB) control approaches. Compared to the conventional model-dependent control methods, such as PI control and model predictive control (MPC), the proposed method automatically updates the optimal control policy through the online learning mechanism without any knowledge of the VRB system dynamics. The ability of the proposed method to handle uncertainties is verified by simulations under various scenarios.",
        "affiliation_name": "The University of Western Australia",
        "affiliation_city": "Perth",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Altered brain regional homogeneity is associated with cognitive dysfunction in first-episode drug-naive major depressive disorder: A resting-state fMRI study",
        "paper_author": "Ni S.",
        "publication": "Journal of Affective Disorders",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Background: Our study aimed to explore the abnormal spontaneous brain activity by regional homogeneity (ReHo) and its association with cognitive function to understand the neuropathology of major depressive disorder (MDD). Methods: ReHo was used to investigate brain activities of 60 patients with first-episode drug-naive MDD and 60 healthy controls (HCs). Partial correlation analysis was conducted on altered ReHo values and the severity of symptoms and cognitive deficits. Moreover, support vector machine analysis was used to evaluate the accuracy of abnormal ReHo values in distinguishing patients with MDD from HCs. Results: Compared with HCs, patients with MDD showed significantly increased ReHo values in the right cerebellum crus2 and right thalamus and decreased ReHo values in the right angular gyrus (AG) and right precuneus (PCUN). The ReHo values in right cerebellum crus2 and right AG were positively associated with working memory and visual learning, respectively. Furthermore, the combination of ReHo values in the right cerebellum crus2 and right PCUN discriminated the patients with MDD from HCs with specificity, sensitivity, and accuracy of 0.9688, 0.6250, and 0.90, respectively. Limitations: The design of repeated cross-sectional surveys does not allow analyses of within individual changes. Conclusions: Our study revealed that the pathophysiology mechanism of cognitive deficits in MDD may be related to abnormal spontaneous brain activity. Moreover, the combination of ReHo values in the right cerebellum crus2 and right PCUN can be used to discriminate patients with MDD from HCs effectively.",
        "affiliation_name": "Nanjing Brain Hospital",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Prediction of antidepressant responses to non-invasive brain stimulation using frontal electroencephalogram signals: Cross-dataset comparisons and validation",
        "paper_author": "Li C.T.",
        "publication": "Journal of Affective Disorders",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Background: 10-Hz repetitive transcranial magnetic stimulation(rTMS) and intermittent theta-burst stimulation(iTBS) over left prefrontal cortex are FDA-approved, effective options for treatment-resistant depression (TRD). Optimal prediction models for iTBS and rTMS remain elusive. Therefore, our primary objective was to compare prediction accuracy between classification by frontal theta activity alone and machine learning(ML) models by linear and non-linear frontal signals. The second objective was to study an optimal ML model for predicting responses to rTMS and iTBS. Methods: Two rTMS and iTBS datasets (n = 163) were used: one randomized controlled trial dataset (RCTD; n = 96) and one outpatient dataset (OPD; n = 67). Frontal theta and non-linear EEG features that reflect trend, stability, and complexity were extracted. Pretreatment frontal EEG and ML algorithms, including classical support vector machine(SVM), random forest(RF), XGBoost, and CatBoost, were analyzed. Responses were defined as ≥50 % depression improvement after treatment. Response rates between those with and without pretreatment prediction in another independent outpatient cohort (n = 208) were compared. Results: Prediction accuracy using combined EEG features by SVM was better than frontal theta by logistic regression. The accuracy for OPD patients significantly dropped using the RCTD-trained SVM model. Modern ML models, especially RF (rTMS = 83.3 %, iTBS = 88.9 %, p-value(ACC > NIR) < 0.05 for iTBS), performed significantly above chance and had higher accuracy than SVM using both selected features (p < 0.05, FDR corrected for multiple comparisons) or all EEG features. Response rates among those receiving prediction before treatment were significantly higher than those without prediction (p = 0.035). Conclusion: The first study combining linear and non-linear EEG features could accurately predict responses to left PFC iTBS. The bootstraps-based ML model (i.e., RF) had the best predictive accuracy for rTMS and iTBS.",
        "affiliation_name": "National Yang-Ming University Taiwan",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Prediction of Molecular Conformation Using Deep Generative Neural Networks",
        "paper_author": "Xu C.",
        "publication": "Chinese Journal of Chemistry",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The accurate prediction of molecular conformations with high efficiency is crucial in various fields such as materials science, computational chemistry and computer-aided drug design, as the three-dimensional structures accessible at a given condition usually determine the specific physical, chemical, and biological properties of a molecule. Traditional approaches for the conformational sampling of molecules such as molecular dynamics simulations and Markov chain Monte Carlo methods either require an exponentially increasing amount of time as the degree of freedom of the molecule increases or suffer from systematic errors that fail to obtain important conformations, thus presenting significant challenges for conformation sampling with both high efficiency and high accuracy. Recently, deep learning-based generative models have emerged as a promising solution to this problem. These models can generate a large number of molecular conformations in a short time, and their accuracy is comparable and, in some cases, even better than that of current popular open-source and commercial software. This Emerging Topic introduces the recent progresses of using deep learning for predicting molecular conformations and briefly discusses the potential and challenges of this emerging field.",
        "affiliation_name": "Southern University of Science and Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Protocol for evaluating mechanistic pathways associated with HIV acquisition via nested Least Absolute Shrinkage and Selective Operator analysis",
        "paper_author": "Dasgupta S.",
        "publication": "STAR Protocols",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Statistical analysis to evaluate mechanistic pathways can be limited by non-causal associations as well as co-linearity of high-dimensional data. Here, we present a protocol evaluating statistical associations between multiple exposure variables (sociodemographic and behavioral), immune biomarkers, and HIV acquisition. We describe steps for study setup, combining Least Absolute Shrinkage and Selective Operator with the standard regression approach, and building nested models. This approach can determine to what extent associations between risks for exposure contributes to HIV acquisition with or without associated changes in immune activation. For complete details on the use and execution of this protocol, please refer to Bender Ignacio et al.1",
        "affiliation_name": "Fred Hutchinson Cancer Center",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A hybrid study of a 4-stage compressed solar distiller based on experimental, computational and deep learning methods",
        "paper_author": "Akhlaghi Ardekani R.",
        "publication": "Desalination",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "In the present study, a hybrid technique is employed to demonstrate the thermal performance of a 4-stage compressed solar distiller with hydrophilic evaporators (CSDHE) regarding the role of natural convection in the air gap domain. Initially, the test is conducted under simulated solar radiation of 2.13 W·m−2 over 5400 s. A thermodynamic model incorporating diffusion is developed for the next step to analyze internal transient temperatures. In the third step, a 3D single-phase natural convection model of the CSDHE is simulated to achieve the research objectives. Based on experimental, thermal modeling, and computational results, a dual deep neural network is developed to predict the thermal behavior of the system and the variation of convection heat transfer coefficient for different air gap thicknesses over 10,000 s. The experimental results revealed a distilled water production rate of 3.806 kg·m−2h−1 with a gained output ratio (GOR) of 112 %. Moreover, the findings demonstrate that conduction accounts for 84.23 % of total heat transfer, while convection accounts for 6.36 % during 5400 s. We also found that, by employing a convolutional neural network (CNN) and directly harvesting data from pre-defined contours, the hybrid training dataset for deep forward neural network (DFNN) is trained 28.35 % faster than conventional methods.",
        "affiliation_name": "Technical University of Denmark",
        "affiliation_city": "Lyngby",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Dynamical analysis of position-sensitive water-robot in radioactively contaminated areas by machine learning (ML) algorithm",
        "paper_author": "Ho Woo T.",
        "publication": "Annals of Nuclear Energy",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "It is analyzed for the water-robot which works in radioactively contaminated areas of nuclear accident sites where the core-melted accident in the Fukushima and Chernobyl disasters is the target modeling of controlling the behavior in the harsh areas by radiation. The radiation detector is a particular characteristic of the water-robot in the nuclear power plant (NPP)’s disaster areas in which the artificial intelligence (AI) algorithm is analyzed for the performance of the robot. A figure shows the comparisons of parameters in which Specificity and Accuracy are quite higher in the time step of 0.25 min. The normalized radioactivity is simulated in a time step of 0.25 min. The radioactive decay graph decreases in exponential form. Following the robot movements, the radioactivity decreases gradually showing the discrete oscillating. The system is easy to be designed, because the moving path by the radiation distribution, because the contaminated structures give the radiation data.",
        "affiliation_name": "The Cyber University of Korea",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Machine learning for beyond Li-ion batteries: Powering the research",
        "paper_author": "Kilic A.",
        "publication": "Journal of Energy Storage",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "New alternatives for various elements of Li-ion battery (LIB) have been investigated to overcome its limitations, creating a new class of batteries called beyond LIBs. There has been a great deal of effort to find more functional materials and better design parameters to improve the performance of these systems, and machine learning (ML) is also used extensively for this purpose. We assessed the state of the art in beyond LIBs, briefly reviewed ML applications, and provided our viewpoints on the potential contribution of ML to the field. It seems that, while the diversity of the materials, parameters, and problems in different beyond LIB systems should be taken into account, the new approaches, including the construction of battery-specific databases or other data-sharing mechanisms, should be developed to transfer the knowledge from more frequently studied systems to others as well as from the material-level performance to system-level performance.",
        "affiliation_name": "Boğaziçi Üniversitesi",
        "affiliation_city": "Bebek",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Degradation and modeling of large-format commercial lithium-ion cells as a function of chemistry, design, and aging conditions",
        "paper_author": "Gasper P.",
        "publication": "Journal of Energy Storage",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "Demand for large-format (>10 Ah) lithium-ion batteries has increased substantially in recent years, due to the growth of both electric vehicle and stationary energy storage markets. The economics of these applications is sensitive to the lifetime of the batteries, and end-of-life can either be due to energy or power limitations. Despite this, there is little information from cell manufacturers on the sensitivity of cell degradation to environmental conditions or battery use. This work reports accelerated aging test data from four commercial large-format lithium-ion batteries from three manufacturers, with varying design (thickness, casings, …), chemistry (lithium‑iron-phosphate (LFP) or lithium‑nickel‑manganese‑cobalt-oxide positive electrodes (NMC), with graphite (Gr) negative electrodes), and capacity (50 to 250 Amp∙hours). The tested LFP|Gr cell is found to be relatively insensitive to cycling conditions like temperature or voltage window, while NMC|Gr cells have varying sensitivity. Degradation trends are further investigated by training predictive models: simple polynomial trend lines, a semi-empirical reduced-order model, and an empirical reduced-order model identified using machine-learning based on symbolic regression. Calendar and cycle life are simulated over a variety of conditions to directly compare the various batteries. Cell size and thickness are found to substantially impact sensitivity to temperature during cycle aging, while electrode chemistry impacts depth-of-discharge sensitivity. Real-world battery lifetime is evaluated by simulating residential energy storage and commercial frequency containment reserve systems in several U.S. climate regions. Predicted lifetime across cell types varies from 7 years to 20+ years, though all cells are predicted to have at least 10 year life in certain conditions.",
        "affiliation_name": "Shell Global",
        "affiliation_city": "The Hague",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Estimating electric power consumption of in-situ residential heat pump systems: A data-driven approach",
        "paper_author": "Song Y.",
        "publication": "Applied Energy",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "International Energy Agency predicts that the global number of installed heat pumps (HP) will increase from 180 million in 2020 to approximately 600 million by 2030, covering 20% of buildings heating needs. Electric power consumption is one of the main key performance indicators for the heat pump systems from techno-economic perspective. However a common issue prevalent in many existing heat pumps is the lack of electric power measurement. The modern installations might be equipped with electric power measurement sensors but this comes at a higher system cost for the manufacturers and end-users. The primary objective of this work is to propose a virtual measurement for estimating power consumption, thereby eliminating the need for field measurement of power for heat pumps. To achieve the objective, a data-driven approach is proposed. Firstly, the in-situ data is preprocessed through data merging, cleaning, and normalization. Then, input features are pre-selected using Spearman correlation coefficients, and further refined by addressing multicollinearity problem. Following this, Extreme Gradient Boosting (XGBoost) models and polynomial models are developed by considering different features as inputs. All models are finally validated against the in-situ data from multi-units of ground source heat pump (GSHP) and air source heat pump (ASHP) installations. The results showed that the electric power consumption of GSHP can be estimated with high accuracy (99% for R2, 10 W for MAE, and 1% for MAPE) through generic data-driven models using only four easy-to-measure input features. Taking three input features as inputs for ASHP generic model, the accuracy can be reached to 83% for R2, 125 W for MAE, and 9% for MAPE. The method presented in this paper can be applied to estimate power consumption of millions of heat pumps and consequently add a significant value as well as provide different types of services, such as cost-saving benefits for manufacturers and end-users, flexibility services for aggregators and electricity grids.",
        "affiliation_name": "Austrian Institute of Technology",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Accelerated discovery of perovskite materials guided by machine learning techniques",
        "paper_author": "Kumar S.",
        "publication": "Materials Letters",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "In this work, machine learning (ML) techniques are used to discover perovskite structures. ML models are built using the bandgap, as a proxy to represent the efficiency of the solar cell materials. The dataset containing well-known perovskite materials along with bandgaps listed in the open-source database, is used in the learning process. 10-fold cross-validation results show that the random forest (RF) algorithm has better performance as compared to other models. A prediction pool of ∼ 240 K compounds with 7 different prototype structures is created, many of these compounds have never been explored. The RF model is then used to predict the bandgap of new perovskite materials. By screening materials based on formability 6855 new candidates are obtained. For the validation of results, DFT calculation is performed and compared with ML-predicted properties for a new compound.",
        "affiliation_name": "Khalifa University of Science and Technology",
        "affiliation_city": "Abu Dhabi",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Early prediction of Lithium-ion cell degradation trajectories using signatures of voltage curves up to 4-minute sub-sampling rates",
        "paper_author": "Ibraheem R.",
        "publication": "Applied Energy",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Feature-based machine learning models for capacity and internal resistance (IR) curve prediction have been researched extensively in literature due to their high accuracy and generalization power. Most such models work within the high frequency of data availability regime, e.g., voltage response recorded every 1–4 s. Outside premium fee cloud monitoring solutions, data may be recorded once every 3, 5 or 10 min. In this low-data regime, there are little to no models available. This literature gap is addressed here via a novel methodology, underpinned by strong mathematical guarantees, called ‘path signature’. This work presents a feature-based predictive model for capacity fade and IR rise curves from only constant-current (CC) discharge voltage corresponding to the first 100 cycles. Included is a comprehensive feature analysis for the model via a relevance, redundancy, and complementarity feature trade-off mechanism. The ability to predict from subsampled ‘CC voltage at discharge’ data is investigated using different time steps ranging from 4 s to 4 min. It was discovered that voltage measurements taken at the end of every 4 min are enough to generate features for curve prediction with End of Life (EOL) and its corresponding IR values predicted with a mean absolute percentage error (MAPE) of approximately 13.2% and 2.1%, respectively. Our model under higher frequency (4 s) produces an improved accuracy with EOL predicted with an MAPE of 10%. Full implementation code publicly available.",
        "affiliation_name": "Maxwell Institute for Mathematical Sciences",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A novel transfer CNN with spatiotemporal input for accurate nuclear power fault diagnosis under different operating conditions",
        "paper_author": "Liu J.",
        "publication": "Annals of Nuclear Energy",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "Deep Neural Network (DNN) models, recognized for their exceptional feature extraction and end-to-end diagnostic capabilities, have gained considerable attention from researchers in the realm of nuclear power fault diagnosis. However, existing deep-learning based diagnostic technologies present certain challenges when applied to practical engineering scenarios. A significant issue is the limited adaptability of data-based machine learning diagnostic methods to dynamic and evolving operational conditions, leading to inconsistent accuracy under different operating parameters. To solve this problem, a spatiotemporal Convolutional Neural Network (CNN) model is proposed. A novel input scheme, considering both spatial and temporal aspects, is specially designed for nuclear power plant fault diagnosis and MLP convolutional layer are used to improve the feature extraction capability of the model. Finally, the performance of the model is analyzed through a series of experiments based on simulation data and data visualization. The results show that the proposed method outperforms traditional CNNs in diagnosing nuclear power system faults with higher accuracy. Furthermore, by employing a transfer learning strategy, the model exhibits improved speed for cross-operating condition fault diagnosis.",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Natural gas pipeline leak detection based on acoustic signal analysis and feature reconstruction",
        "paper_author": "Yao L.",
        "publication": "Applied Energy",
        "citied_by": "21",
        "cover_date": "2023-12-15",
        "Abstract": "The natural gas pipeline leakage detection task based on acoustic signal has some problems such as background noise coverage, lack of effective features, and low fault identification accuracy caused by small sample data. However, only one of these problems was usually studied in previous technologies. Almost no one has attempted to challenge multiple issues at the same time. In this study, a natural gas pipeline leak detection model that integrates acoustic feature processing techniques and feature reconstruction is proposed to resolve the above problems collaboratively. This model consists of two components. The first component is a feature processing technique of the acoustic signal that integrates frequency domain vector denoising and time domain associative function feature enhancement. The second component is a one-dimensional convolutional neural network with an expanded structural feature encoder (FAE) for feature reconstruction (FAE-1D-CNN). In the feature processing stage of the acoustic signal, firstly, the acoustic signal collected by the acoustic sensor is discretized into a digital signal. Secondly, the energy modal function is used to perform high/low energy modal clustering of digital signal features. The feature validity is enhanced by adding association factors to the low-energy modal features matrix. A low-pass filtering method is then used in the high-energy modal features to remove the background noise coverage of the high-frequency components. In the fault feature extraction stage, a feature encoder (FAE) is introduced in the 1D-CNN network to extract effective fault features while performing secondary reconstruction of local spatial features, addressing the problem of small sample leakage signals with few effective fault characteristics. The global average pooling layer is used instead of the fully connected layer, and the Softmax function is adopted as the classifier for fault discrimination. The performance of the proposed method was evaluated on the GPLA-12 dataset, and the fault identification accuracy is up to 95.17%. Compared with other competing methods, the method in this paper exhibits optimal performance and has broad application prospects.",
        "affiliation_name": "Chongqing University of Science and Technology",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning screening based strategy for the synthesis of a molecularly imprinted ionic liquid polymer for specific adsorption of perfluorooctanoic acid",
        "paper_author": "Zhang Y.",
        "publication": "Separation and Purification Technology",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Perfluorooctanoic acid (PFOA) is a persistent organic pollutant that poses a significant environmental threat due to its resistance to degradation in both aquatic and terrestrial environments. Ionic liquids (ILs) are a type of salt that is liquid at or near room temperature and have been widely used in separation science, as well as showing great potential in environmental applications. However, the large number and variety of ILs make them impractical to assess the suitability of all possible ILs for PFOA adsorption using purely experimental methods. To address this issue, a high-throughput machine learning method was employed in this study to screen more than a thousand ILs and identify the most appropriate molecular for designing IL based molecularly imprinted polymer (MIP) with high affinity and selectivity of PFOA. The synthesized MIP, (Vim)C3(L-Pro)@MIP, has been proven to effectively and specifically recognize and adsorb PFOA in water. It has a maximum adsorption capacity of 568.18 mg g−1 and removal efficiency of over 99%, making it a highly efficient and selective option for PFOA removal in environmental remediation applications. This study showcases the promising potential of integrating high-throughput computer screening with experimental verification in the initial stages of MIP material design and development. By doing so, it is possible to create MIP materials that can effectively remove various pollutants, and potentially extend to other IL doped materials and applications.",
        "affiliation_name": "College of Pharmaceutical Sciences, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Production prediction modeling of food waste anaerobic digestion for resources saving based on SMOTE-LSTM",
        "paper_author": "Han Y.",
        "publication": "Applied Energy",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "The global energy shortage and resource waste are becoming more and more prominent. With the massive production of food waste, anaerobic digestion through food waste is a key way to solve the resource shortage problem. To better study the anaerobic digestion process of food waste, a novel production prediction model of food waste process based on a long short-term memory (LSTM) method integrating the synthetic minority oversampling technique (SMOTE) based data expansion method is proposed. The minority class samples are analyzed and extended using the SMOTE, which are used as inputs of the LSTM. Then, the production prediction model can be built to reduce the influence of a few samples on the prediction model. Finally, the proposed method is applied in the methane production prediction model of actual food waste process plants. Compared with the back Propagation (BP) neural network, the extreme learning machine (ELM), the radial basis function (RBF) neural network, the support vector machine (SVM), the LSTM and the convolutional neural network (CNN), the experimental results have verified the higher applicability of the proposed method for the methane prediction result including an accuracy of 99.75% and the highest R2 of 0.9913 with minimal training and generalization errors. Moreover, by analyzing the prediction result and the actual methane production, the proposed method can effectively guide and timely adjustment the feed allocation for increasing the methane production per m3 of feed by 25.77%.",
        "affiliation_name": "Facebook, Inc.",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Photogrammetry-based computational fluid dynamics",
        "paper_author": "Wang X.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Computational fluid dynamics (CFD) is the cornerstone of the design and analysis process in many engineering applications. Not only has it been applied in the design phase, but it has also been employed for analyzing the fluid flow phenomena during the operation phase for many in-use structures, such as vehicles, buildings, and landscapes. However, creating a 3D mesh-based model of in-use structures that can be used by conventional boundary-fitted CFD methods is labor-intensive, time-consuming, and sometimes impossible. Due to the challenges introduced by geometry complexity and lack of design information, it is often difficult to perform an accurate and efficient CFD analysis of these objects. This paper aims to overcome such challenges by proposing a novel photogrammetry-based CFD framework for simulating in-use structures whose design models and analysis meshes are hard to obtain. The proposed framework integrates machine learning-based 3D point cloud reconstruction of structures from 2D images obtained from portable devices (e.g., cell phones and drones) and an immersogeometric approach that can carry out flow analysis directly on reconstructed point clouds. We first present the technical details of point cloud reconstruction techniques and the immersogeometric analysis method. We then simulate the flow past a standard 12 oz soda can reconstructed using photogrammetry and compare the results with reference solutions to assess the accuracy of the approach. Finally, the proposed photogrammetry-based CFD is applied to simulations of a bell tower and the Kavita and Lalit Bahl Smart Bridge on the University of Illinois Urbana-Champaign (UIUC) campus to demonstrate the robustness of the framework and its applicability to real-world in-use civil structures.",
        "affiliation_name": "The Grainger College of Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Where in the brain do internally generated and externally presented visual information interact?",
        "paper_author": "Alho J.",
        "publication": "Brain Research",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Conscious experiences normally result from the flow of external input into our sensory systems. However, we can also create conscious percepts independently of sensory stimulation. These internally generated percepts are referred to as mental images, and they have many similarities with real visual percepts. Consequently, mental imagery is often referred to as “seeing in the mind's eye”. While the neural basis of imagery has been widely studied, the interaction between internal and external sources of visual information has received little interest. Here we examined this question by using fMRI to record brain activity of healthy human volunteers while they were performing visual imagery that was distracted with a concurrent presentation of a visual stimulus. Multivariate pattern analysis (MVPA) was used to identify the brain basis of this interaction. Visual imagery was reflected in several brain areas in ventral temporal, lateral occipitotemporal, and posterior frontal cortices, with a left-hemisphere dominance. The key finding was that imagery content representations in the left lateral occipitotemporal cortex were disrupted when a visual distractor was presented during imagery. Our results thus demonstrate that the representations of internal and external visual information interact in brain areas associated with the encoding of visual objects and shapes.",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Prediction of elastic wave propagation in composite bars using deep learning techniques",
        "paper_author": "Zhang X.",
        "publication": "Materials Letters",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "In this work, we developed a deep learning model based on a multilayer perceptron to predict the elastic wave output from composite bars. The model takes a vector representing the microstructure of the composite and the input wave applied at the left edge of the bar as features, with the target being the output elastic waves collected at the right edge of the bar. To train the model, we randomly generated composite bars with corresponding input waves and simulated them using finite element modeling. The results indicate that the proposed method can accurately and efficiently predict the output elastic waves.",
        "affiliation_name": "Jiangsu University of Science and Technology",
        "affiliation_city": "Zhenjiang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Engineered Features and Artificial Neural Networks for the Identification of Temperature-Dependent Radiative Characteristics in Porous Media",
        "paper_author": "Eghtesad A.",
        "publication": "International Journal of Heat and Mass Transfer",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "The accurate and efficient prediction of radiative properties of materials plays a crucial role in numerous industrial and engineering applications. However, experimental measurement can be cumbersome, particularly for complex materials. As a result, numerical techniques such as Monte Carlo ray tracing (MCRT) have been developed to assess radiative properties. MCRT is a well-known tool for solving radiation heat transport (RHT). Despite its advantages, MCRT requires tracing a large bundle of light beams for convergency and veracity of outcomes, which necessitates further advancements in its employment. To this end, supervised learning algorithms can be used in conjunction with MCRT to provide a quick and accurate substitution for typical MCRT simulations. In this study, machine learning algorithms employing expertly designed features are used to evaluate the radiative properties of heterogeneous porous media, while considering the effects of conductive heat transfer. Directional features have been introduced into the sets of the features implemented in our previous study for the enhancement of predictions. The results show that the applied method can improve prediction accuracy compared to prior studies. Moreover, this approach is generalizable to other radiative heat transfer problems by extracting relevant characteristics in accordance with the involved physics.",
        "affiliation_name": "Stevens Institute of Technology",
        "affiliation_city": "Hoboken",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Can we trust ECG for diagnosing hyperkalemia? A challenging question for clinicians and bioengineers",
        "paper_author": "Regolisti G.",
        "publication": "International Journal of Cardiology",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "NA",
        "affiliation_name": "Università degli Studi di Milano-Bicocca",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Nonlinear autoregressive models for high accuracy early prediction of Li-ion battery end-of-life",
        "paper_author": "Shah A.A.",
        "publication": "Journal of Energy Storage",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Predictions of the state-of-health (SOH) of Li-ion batteries is an important goal in the monitoring and management of electric vehicles. In recent years, a number of pure machine-learning methods have been proposed for such predictions. In this paper, we instead consider autoregression methods and embedding strategies, which are specifically tailored to time-series problems. For the first time, we comprehensively compare both linear and nonlinear approaches, including six deep learning architectures, autoregressive integrated moving average (ARIMA) models and seasonal ARIMA models. In particular, for the first time we introduce Gaussian process nonlinear autoregression (GPNAR) for SOH prediction and show that it is superior in terms of accuracy and computational costs to the other autoregressive approaches. On the basis of two different datasets, we also demonstrate that accurate early predictions of the end-of-life (based on 50% of the data) is achievable with GPNAR without the use of features, which keeps data acquisition and processing to a minimum. Finally, we show that GPNAR is capable of capturing seasonal trends such as regeneration without additional time-consuming data analyses. Comparisons to other state-of-the-art methods in the recent literature confirm the superior performance of GPNAR.",
        "affiliation_name": "Chongqing University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Hot deformation behavior of near-β titanium alloy Ti-3Mo-6Cr-3Al-3Sn based on phenomenological constitutive model and machine learning algorithm",
        "paper_author": "Liu X.",
        "publication": "Journal of Alloys and Compounds",
        "citied_by": "26",
        "cover_date": "2023-12-15",
        "Abstract": "To overcome the disadvantages of the phenomenological constitutive model, which is sensitive to data and limited by model structure and assumptions, and to enhance the prediction accuracy of the flow behavior of near-β titanium alloy during hot deformation, a machine learning prediction model was established using the whale optimized neural network algorithm (WOA-BP). To validate the model's accuracy, hot compression experiments were conducted on a near-β titanium alloy, Ti-3Mo-6Cr-3Al-3Sn. Subsequently, the phenomenological constitutive model and WOA-BP model for the hot deformation process of the alloy were established. The analysis of flow stress prediction errors revealed significant improvements in comparison to the modified J-C constitutive structure model and Arrhenius constitutive structure model. Specifically, the WOA-BP model showed an increased error correlation coefficient (R) by 0.030063 and 0.17252, respectively, along with reduced average relative errors (AARE) to 14.92575 and 7.70414, respectively. The root mean square error (MSE) and mean absolute error (MAE) were significantly reduced to 22.51002 and 3.652993, respectively. The WOA-BP model greatly improved the accuracy of flow stress predictions. Using the flow stress prediction value from the WOA-BP model, the hot processing map was established at a true strain of 0.6. At a power dissipation factor (η) of 0.53–0.59, fully recrystallized grains appeared in the microstructure, exhibiting a relatively uniform grain size. Conversely, at η values of 0.17–0.21, significant deformation bands formed in the microstructure, making it unsuitable for thermal processing. This trend aligns with the power dissipation values, demonstrating the hot processing map's accuracy.",
        "affiliation_name": "The State Key Laboratory of Rolling and Automation, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Event-driven forecasting of wholesale electricity price and frequency regulation price using machine learning algorithms",
        "paper_author": "Sai W.",
        "publication": "Applied Energy",
        "citied_by": "18",
        "cover_date": "2023-12-15",
        "Abstract": "The wholesale electricity market is composed of real-time market and procurement. Since the fully liberalization of the energy market in Singapore in 2018, competition among the market participants has become intensive. Therefore, the forecast of the electricity price, including both Uniform Singapore Energy Price (USEP) and regulation price (REG), is essential for market participants to trade at the best possible price. This study proposes an event-driven forecast model to provide a real-time automatical price forecast of the wholesale electricity price using the cutting-edge regression tree ensembled algorithm, XGBoost. The model is triggered every half of an hour by the dispatch of the latest electricity price, which will be also used as the input together with other necessary training data from the historical price database. The training is finished within 1–2 min and the model makes the predictions on prices of the next 6 h. A better prediction has been demonstrated benchmarked to the forecast provided commercially by Energy Market Company. The forecast model only takes commercially available data as the input and is embedded with messaging broker, enabling online collaboration of different modules. The model is readily implemented, and thus can serve as an effective supplementary tool in virtual power plant operation with a higher renewable energy penetration in the future.",
        "affiliation_name": "Energy Research Institute @NTU",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "High-resolution maps of vegetation nitrogen density on the Tibetan Plateau: An intensive field-investigation",
        "paper_author": "Li X.",
        "publication": "Science of the Total Environment",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Nitrogen (N) is a vital macronutrient in plant growth and development that plays a crucial role in the regulation of numerous physiological processes. The Tibetan Plateau is among the most species-diverse vegetation zones in the world, and is sensitive to climate change; however, research on vegetation N in the region remains limited. This study used field grid-sampling of 2040 plant communities to investigate the spatial variation and driving factors of vegetation N on the Tibetan Plateau. The results yielded an average N content, density and storage in vegetation of 8.48 mg g−1, 27.02 g m−2, and 29.84Tg, respectively. The ratio-based optimal partitioning hypothesis appears to be more suitable than the isometric allocation hypothesis to explain variation in vegetation N on the Tibetan Plateau. Variation in vegetation N density, was influenced by several environmental factors of which the most significant was radiation. Based on these results, a Random Forest model was used to predict a N density distribution map at 1 km resolution, achieving an accuracy (R2) of 0.72 (aboveground N density), 0.61 (belowground N density), and 0.69 (total vegetation N density). Trends for high densities were predicted in the southeast and low densities in the northwest of the region. Our findings and maps could be used to provide key N cycle parameters, contributing to future remote sensing, radar analyses, modeling and ecological management.",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Multi-view broad learning system for electricity theft detection",
        "paper_author": "Yang K.",
        "publication": "Applied Energy",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Electricity theft poses a huge hazard to the economic efficiency of power companies and the safe operation of the power system. Analysis of smart grid data can help to identify abnormal electricity usage patterns of the thieves. However, existing models may suffer from underfitting issues due to the high dimensionality and imbalanced class distribution in the electricity dataset. To address these challenges and improve the performance of electricity theft detection, this study proposes a multi-view detection model based on broad learning system (BLS). First, a new multi-view framework is presented to map the raw power data into different sub-views, thereby reducing redundant electricity data features. Then, an adaptive weighting strategy based on the regional distribution of the data is developed. The optimized sub-views are obtained by considering the sample size and dispersion of the data. Finally, a power theft detection model is constructed by combining the region distribution weighted BLS and the multi-view rotation BLS. Comparative experiments on real-world electricity dataset demonstrate the superiority of our proposed approach.",
        "affiliation_name": "Peng Cheng Laboratory",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An ensemble learning framework for rooftop photovoltaic project site selection",
        "paper_author": "Hou Y.",
        "publication": "Energy",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "The selection of suitable locations for rooftop photovoltaic projects (RPVP) is critical for optimizing power generation efficiency and return on investment. However, traditional methods of site selection that rely on subjective assessments of index weights can compromise accuracy, while complex calculations may limit adaptability to changing real-world data. In this study, we proposed a data-driven ensemble learning framework that integrates socio-economic, environmental, climate, and geography factors to optimize RPVP site selection. Using data from 1589 counties in China, we mapped eight criteria to feature variables to facilitate machine learning classification. Furthermore, the K-means algorithm was employed to enhance the model's robustness against outliers. The findings indicate that the proposed stacking model exhibits superior performance in comparison to other classifiers, as evidenced by the higher scores of performance metrics. Specifically, for positive instance prediction, the stacking model achieves the highest Precision scores. According to the rankings of Precision scores derived from the four ensembled models, we categorized counties suitable for RPVP development into five priority tiers. The ensemble learning framework provides a valuable and reusable tool for advancing county-level RPVP site selection and serves as a motivation for selecting other renewable power plant sites.",
        "affiliation_name": "Nanjing Xiaozhuang College",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Selective identification and quantification of VOCs using metal nanoparticles decorated SnO<inf>2</inf> hollow-spheres based sensor array and machine learning",
        "paper_author": "Acharyya S.",
        "publication": "Journal of Alloys and Compounds",
        "citied_by": "20",
        "cover_date": "2023-12-15",
        "Abstract": "Accurate and selective detection of target gas/volatile organic compounds (VOCs) is of utmost importance. The chemiresistive gas sensors have been a desirable candidate due to their compact footprint and ease of fabrication, but they show poor selectivity. This work presents a combination of nanomaterials-based chemiresistive gas sensors with machine learning (ML) techniques to achieve sensitive, selective, and quantified detection of tested VOCs. The sensor array consists of four separate sensing layers over interdigitated electrodes-based platform. The sensing materials were comprised of silver, gold, palladium, and platinum nanoparticles decorated on tin oxide hollow-sphere structures which were successfully synthesized through chemical routes and characterized accordingly. Surface decoration of different metal nanoparticles has produced sensitive and diverse sensing patterns among the tested VOCs. The sensing mechanism and related gas sensing kinetics were then analyzed to explain high sensitivity and diverse sensing phenomena. The subsequent incorporation of ML models has resulted in qualitative and quantitative detection of VOCs. A comparative analysis was carried out among different types of applied features and ML models with reasoning. Particularly, a deep neural network (DNN) model with time series (TS) response sequence as input information, delivered the best performance. The DNN_TS model presented an average classification accuracy of 98.33 %, in conjunction with excellent concentration prediction. The DNN_TS model showed a very fast prediction time of 2.74 µs with adaptive learning while utilizing minimum computing resources, which favors the real-time sensing capability. The reported results promote the development of an autonomous, smart, and selective gas sensor system for real-time applications.",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Survey on Secure and Private Federated Learning Using Blockchain: Theory and Application in Resource-Constrained Computing",
        "paper_author": "Moore E.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Federated learning (FL) has gained widespread popularity in recent years due to the fast booming of advanced machine learning and artificial intelligence, along with emerging security and privacy threats. Federated learning (FL) enables efficient model generation from local data storage of the edge devices without revealing the sensitive data to any entities. While this paradigm partly mitigates the privacy issues of users' sensitive data, the performance of the FL process can be threatened and reach a bottleneck due to the growing cyber threats and privacy violation techniques. To expedite the proliferation of the FL process, the integration of blockchain for FL environments has drawn increasing attention from academia and industry. Blockchain has the potential to prevent security and privacy threats with its decentralization, immutability, consensus, and transparency characteristics. However, if the blockchain mechanism requires costly computational resources, then the resource-constrained FL clients cannot be involved in the training. Considering that, this survey focuses on reviewing the challenges, solutions, and future directions for the successful deployment of blockchain in resource-constrained FL environments. We comprehensively review variant blockchain mechanisms suitable for the FL process and discuss their tradeoffs for a limited resource budget. Furthermore, we extensively analyze the cyber threats that could be observed in a resource-constrained FL environment, and how blockchain can play a key role in blocking those cyberattacks. To this end, we highlight some potential solutions for the coupling of blockchain and FL that can offer high levels of reliability, data privacy, and distributed computing performance.",
        "affiliation_name": "FIU College of Engineering and Computing",
        "affiliation_city": "Miami",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Co-optimization of miller degree and geometric compression ratio of a large-bore natural gas generator engine with novel Knock models and machine learning",
        "paper_author": "Cao J.",
        "publication": "Applied Energy",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Large-bore natural gas reciprocating generator engines will play crucial roles in future low-carbon energy systems. Knock, as an abnormal combustion phenomenon, is a bottleneck for long time to restrict the engine performance improvement. Development and application of the reliable knock model can contribute the predictive engine control and optimization to further improve the engine efficiency and performance. The biggest challenge of developing the predictive knock model is the stochastic nature of the knock phenomenon. To bridge the technological gap, this study aims to develop a novel predictive knock model for a large-bore natural gas engine and showcase its application for co-optimization of the engine design and control parameters, together with the machine learning. The knock model, taking the effects of hot spots heat release rate and energy density into account, is calibrated by the statistical phenomenological knock factor. The 1-D engine simulation model embedded with the knock model is built and calibrated. The data-driven model based on machine learning is developed and used to predict the relation between the key parameters and the engine performance. The genetic algorithms are employed to achieve the multi-objectives global optimization of geometric compression ratio, Miller degree and other control parameters of the engine to reduce the exhaust gas temperature and improve the engine performance. The co-optimized results show that the engine exhaust gas temperature can be remarkably lowered and the indicated thermal efficiency is increased by 1–3% depending on the operational conditions, without degrading the engine power output and increasing the exhaust NOx emissions.",
        "affiliation_name": "State Key Laboratory of Ocean Engineering",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An effective multitask neural networks for predicting mechanical properties of steel",
        "paper_author": "Ban Y.",
        "publication": "Materials Letters",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "An effective multitask neural network was carried out to predict the mechanical properties of steels based on their chemical compositions. The multitask neural network model outperforms other neural networks, and conventional algorithms. It achieved high prediction accuracy for both tensile strength and elongation, with R2 values of 0.9204 and 0.9409, respectively. Benefiting from the strong inter-task relationships, the multitask neural network enhances performance and parameter efficiency by sharing a potent representation across tasks. Additionally, we analyzed the influence of chemical composition on mechanical properties using the model's parameters, providing valuable insights into the relationship between different chemical compositions and the mechanical properties of steels.",
        "affiliation_name": "Engineering Laboratory of Operations Analytics and Optimization for Smart Industry, Liaoning Province, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Leveraging Machine Learning for Disease Diagnoses Based on Wearable Devices: A Survey",
        "paper_author": "Jiang Z.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "Many countries around the world are facing a shortage of healthcare resources, especially during the post-epidemic era, leading to a dramatic increase in the need for self-detection and self-management of diseases. The popularity of smart wearable devices, such as smartwatches, and the development of machine learning (ML) bring new opportunities for the early detection and management of various prevalent diseases, such as cardiovascular diseases, Parkinson's disease, and diabetes. In this survey, we comprehensively review the articles related to specific diseases or health issues based on small wearable devices and ML. More specifically, we first present an overview of the articles selected and classify them according to their targeted diseases. Then, we summarize their objectives, wearable device and sensor data, ML techniques, and wearing locations. Based on the literature review, we discuss the challenges and propose future directions from the perspectives of privacy concerns, security concerns, transmission latency and reliability, energy consumption, multimodality, multisensor, multidevices, evaluation metrics, explainability, generalization and personalization, social influence, and human factors, aiming to inspire researchers in this field.",
        "affiliation_name": "Försvarshögskolan",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Exploring new horizons: Empowering computer-assisted drug design with few-shot learning",
        "paper_author": "Silva-Mendonça S.",
        "publication": "Artificial Intelligence in the Life Sciences",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Computational approaches have revolutionized the field of drug discovery, collectively known as Computer-Assisted Drug Design (CADD). Advancements in computing power, data generation, digitalization, and artificial intelligence (AI) techniques have played a crucial role in the rise of CADD. These approaches offer numerous benefits, enabling the analysis and interpretation of vast amounts of data from diverse sources, such as genomics, structural information, and clinical trials data. By integrating and analyzing these multiple data sources, researchers can efficiently identify potential drug targets and develop new drug candidates. Among the AI techniques, machine learning (ML) and deep learning (DL) have shown tremendous promise in drug discovery. ML and DL models can effectively utilize experimental data to accurately predict the efficacy and safety of drug candidates. However, despite these advancements, certain areas in drug discovery face data scarcity, particularly in neglected, rare, and emerging viral diseases. Few-shot learning (FSL) is an emerging approach that addresses the challenge of limited data in drug discovery. FSL enables ML models to learn from a small number of examples of a new task, achieving commendable performance by leveraging knowledge learned from related datasets or prior information. It often involves meta-learning, which trains a model to learn how to learn from few data. This ability to quickly adapt to new tasks with low data circumvents the need for extensive training on large datasets. By enabling efficient learning from a small amount of data, few-shot learning has the potential to accelerate the drug discovery process and enhance the success rate of drug development. In this review, we introduce the concept of few-shot learning and its application in drug discovery. Furthermore, we demonstrate the valuable application of few-shot learning in the identification of new drug targets, accurate prediction of drug efficacy, and the design of novel compounds possessing desired biological properties. This comprehensive review draws upon numerous papers from the literature to provide extensive insights into the effectiveness and potential of few-shot learning in these critical areas of drug discovery and development.",
        "affiliation_name": "Universidade Federal de Goiás",
        "affiliation_city": "Goiania",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Analysis of self-organizing maps and explainable artificial intelligence to identify hydrochemical factors that drive drinking water quality in Haor region",
        "paper_author": "Mia M.Y.",
        "publication": "Science of the Total Environment",
        "citied_by": "22",
        "cover_date": "2023-12-15",
        "Abstract": "Water contamination undermines human survival and economic growth. Water resource protection and management require knowledge of water hydrochemistry and drinking water quality characteristics, mechanisms, and factors. Self-organizing maps (SOM) have been developed using quantization and topographic error approaches to cluster hydrochemistry datasets. The Piper diagram, saturation index (SI), and cation exchange method were used to determine the driving mechanism of hydrochemistry in both surface and groundwater, while the Gibbs diagram was used for surface water. In addition, redundancy analysis (RDA) and a generalized linear model (GLM) were used to determine the key drinking water quality parameters in the study area. Additionally, the study aimed to utilize Explainable Artificial Intelligence (XAI) techniques to gain insights into the relative importance and impact of different parameters on the entropy water quality index (EWQI). The SOM results showed that thirty neurons generated the hydrochemical properties of water and were organized into four clusters. The Piper diagram showed that the primary hydrochemical facies were HCO3−-Ca2+ (cluster 4), Cl—Na+ (all clusters), and mixed (clusters 1 and 4). Results from SI and cation exchange show that demineralization and ion exchange are the driving mechanisms of water hydrochemistry. About 45 % of the studied samples are classified as “medium quality”,” that could be suitable as drinking water with further refinement. Cl− may pose increased non-carcinogenic risk to adults, with children at double risk. Cluster 4 water is low-risk, supporting EWQI findings. The RDA and GLM observations agree in that Ca2+, Mg2+, Na+, Cl− and HCO3− all have a positive and significant effect on EWQI, with the exception of K+. TDS, EC, Na+, and Ca2+ have been identified as influencing factors based on bagging-based XAI analysis at global and local levels. The analysis also addressed the importance of SO4, HCO3, Cl, Mg2+, K+, and pH at specific locations.",
        "affiliation_name": "Institute of National Analytical Research and Service (INARS)",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Deep neural network architectures for cardiac image segmentation",
        "paper_author": "El-Taraboulsi J.",
        "publication": "Artificial Intelligence in the Life Sciences",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "Imaging plays a fundamental role in the effective diagnosis, staging, management, and monitoring of various cardiac pathologies. Successful radiological analysis relies on accurate image segmentation, a technically arduous process, prone to human-error. To overcome the laborious and time-consuming nature of cardiac image analysis, deep learning approaches have been developed, enabling the accurate, time-efficient, and highly personalised diagnosis, staging and management of cardiac pathologies. Here, we present a review of over 60 papers, proposing deep learning models for cardiac image segmentation. We summarise the theoretical basis of Convolutional Neural Networks, Fully Convolutional Neural Networks, U-Net, V-Net, No-New-U-Net (nnU-Net), Transformer Networks, DeepLab, Generative Adversarial Networks, Auto Encoders and Recurrent Neural Networks. In addition, we identify pertinent performance-enhancing measures including adaptive convolutional kernels, atrous convolutions, attention gates, and deep supervision modules. Top-performing models in ventricular, myocardial, atrial and aortic segmentation are explored, highlighting U-Net and nnU-Net-based model architectures achieving state-of-the art segmentation accuracies. Additionally, key gaps in the current research and technology are identified, and areas of future research are suggested, aiming to guide the innovation and clinical adoption of automated cardiac segmentation methods.",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "An industrial evaluation of proteochemometric modelling: Predicting drug-target affinities for kinases",
        "paper_author": "Stroobants A.",
        "publication": "Artificial Intelligence in the Life Sciences",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Deep learning proteochemometric (PCM) models have been reported to achieve excellent performances on public benchmarking datasets. Nevertheless, numerous papers have cast doubt on commonly used evaluation metrics, suggesting they do not reflect true prospective predictive abilities. The aim of this study is to provide a comprehensive assessment of performance of a state-of-the-art PCM model on proprietary data and evaluate its potential over other modelling approaches as a virtual screening tool for kinase inhibitors. Whilst the model has been shown to achieve an RMSE of 0.48 on a public benchmarking dataset, an impaired overall performance was observed for the proprietary dataset in this study, with an RMSE of 0.85 and a Pearson Correlation Coefficient of 0.65 using a temporal splitting strategy. We hypothesise that the more limited performance can be in part attributed to a shift in the chemical space observed over time in an industrial setting, which is not considered by the more lenient random ligand splitting strategy, more commonly used on benchmarking datasets. The overall performance of the PCM model was statistically similar to a multitask model and only slightly superior to a KNN and random forest PCM model. A comprehensive analysis of performance was performed to capture the key challenges faced in the design of competitive kinase inhibitors, which revealed the key limitations of PCM modelling. For example, the model showed poor predictive abilities for understudied targets, and a limited ability to assess ligand selectivity and promiscuity, with no improved performance over a multitask model or a random forest PCM model. Overall, these findings reveal that the PCM model assessed in this study does not provide significant benefits over less complex models such as multitask model or a random forest PCM model as a virtual screening tool for kinase inhibitors in an industrial setting. Taken together, this study highlights the need for more robust evaluations of PCM models by using stricter splitting strategies, more extensive benchmarking and more comprehensive performance analysis beyond traditional metrics.",
        "affiliation_name": "AstraZeneca",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A natural language processing system for the efficient updating of highly curated pathophysiology mechanism knowledge graphs",
        "paper_author": "Babaiha N.S.",
        "publication": "Artificial Intelligence in the Life Sciences",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Background: Biomedical knowledge graphs (KG) have become crucial for describing biological findings in a structured manner. To keep up with the constantly changing flow of knowledge, their embedded information must be regularly updated with the latest findings. Natural language processing (NLP) has created new possibilities for automating this upkeep by facilitating information extraction from free text. However, due to annotated and labeled biomedical data limitations, the development of completely autonomous information extraction systems remains a substantial scientific and technological hurdle. This study aims to explore methodologies best suited to support the automatic extraction of causal relationships from biomedical literature with the aim of regular and rapid updating of disease-specific pathophysiology mechanism KGs. Methods: Our proposed approach first searches and retrieves PubMed abstracts using the desired terms and keywords. The extension corpora are then passed through the NLP pipeline for automatic information extraction. We then identify triples representing cause-and-effect relationships and encode this content using the Biological Expression Language (BEL). Finally, domain experts perform an analysis of the completeness, relevance, accuracy, and novelty of the extracted triples. Results: In our test scenario, which is focused on the KG regarding the phosphorylation of the Tau protein, our pipeline successfully contributed novel data, which was then subsequently used to update the KG leading to the identification of six additional upstream regulators of Tau phosphorylation. Conclusion: Here, it is demonstrated that the NLP-based workflow we created is capable of rapidly updating pathophysiology mechanism graphs. As a result, production-scale, semi-automated updating of pre-existing, curated mechanism graphs is enabled.",
        "affiliation_name": "Bonn-Aachen International Center for Information Technology",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Machine learning integrated high quantum yield blue light carbon dots for real-time and on-site detection of Cr(VI) in groundwater and drinking water",
        "paper_author": "Zhang M.",
        "publication": "Science of the Total Environment",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "The safety of groundwater and drinking water is directly related to the well-being of human beings and ecosystems. On-site monitoring and timely response to heavy metals in these water sources are crucial for water supply security. Fluorescent probes combined with machine learning technology have been applied to on-site detection of heavy metals. However, they were primarily focused on industrial-level detection and lacked the sensitivity required for detecting Cr(VI) in groundwater and drinking water. In this study, we developed an machine learning-integrated approach using high-quantum-yield (QY) N-doped blue-light carbon dots (N-BCDs) for instant detection of Cr(VI) in groundwater and drinking water. N-BCDs were synthesized within 3 min using a household microwave oven with citric acid and 1,2-diaminobenzene, resulting in a QY of approximately 90 %. The fluorescence of N-BCDs was quenched via the internal filter effect (IFE), enabling the detection of Cr(VI) within 1 min, with a detection limit of 0.1574 μg L−1 for Cr(VI) concentrations ranging from 0 to 60 μg L−1. We employed machine learning methods to determine Cr(VI) concentrations from simple shots, based on the red-green-blue (RGB) feature and Kmeans feature extraction. These features were input into four models (Ridge, XGB, SVR, and Linear), achieving a fitness of 95.2 %. Furthermore, the accuracies for Cr(VI) concentration identification in actual groundwater and drinking water were as high as 95.71 % and 96.81 %, respectively. Our work successfully extended the detection range of Cr(VI) to the μg level, significantly improving the practical applicability of the method and providing a new approach for on-site detection of Cr(VI) in groundwater and drinking water.",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of high-dimensional uniform manifold approximation and projection (UMAP) to cluster existing landfills on the basis of geographical and environmental features",
        "paper_author": "Yu T.T.",
        "publication": "Science of the Total Environment",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Due to extreme conditions, which are influenced by the location of landfills, the release of pollutants has been recently proven to be more severe in estuary landfills, as these landfill locations are affected by both sea-water and river-water interactions. To identify geographic and environmental features linked to the extreme conditions of certain landfills, a high-dimensional clustering method combining Uniform Manifold Approximation and Projection (UMAP) with the Louvain algorithm is proposed. A case study was conducted using 17 noteworthy features that transform to Landfill Suitability Index (LSI) applied to hundreds of landfill sites in Taiwan. This study clustered landfills into 10 clusters and identified several clusters with significant extreme locations, including estuary landfills (7.9 %), fault-water-body landfills (8.2 %), and densely-populated-water-body landfills (17.6 %). Furthermore, a critical discovery of endangered Platalea minor habitats near these estuary landfills was made. Additionally, this work identified “healthy” landfills (11.2 %) that are minimally affected by the considered features. These findings demonstrate the promising potential of our framework for managers to systematically improve landfill management strategies. Moreover, our framework was tested by incorporating rainfall and flooding features in relation to climate change scenarios. To address the demand for land release from occupied landfills in Taiwan, there is a pressing need to expedite the transition to a circular economy, and our framework can provide further assistance in this regard. This approach is promising, as it provides a new method to evaluate the environmental risks linked to landfills and also identifies potential opportunities related to landfill mining. Finally, this work was extended to include a case study in England, which has 19,801 landfills and a dataset containing 15 relevant landfill features; in this case study, our framework identified 110 landfill clusters, and several placed in extreme locations, demonstrating that our framework is flexible for use in other regions outside of Taiwan.",
        "affiliation_name": "National Taipei University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Predicting household energy consumption in an aging society",
        "paper_author": "Shi Z.",
        "publication": "Applied Energy",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Social aging will significantly affect energy consumption in the residential sector, with a critical influence on the demand side of the energy sector, especially for megacities. Despite previous studies on the total change in energy demand due to aging, limited research has focused on high-frequency effects. Using a machine learning model, this study examines how social aging will affect household hourly consumption patterns, covering both the change in total consumption and the hourly distribution. We first unsupervised cluster household high-frequency consumption patterns in Shanghai from 2016 to 2018 into 12 groups, and then trained a finite mixture model to analyze the correlation between clusters and household features. We further used the well-tuned model based on the out-of-sample result to simulate the consumption patterns under scenarios of social aging and income growth. The simulation results demonstrate that in addition to increasing overall energy consumption, an aging society will also change the hourly consumption pattern, leading to a larger gap between peak and non-peak periods.",
        "affiliation_name": "Fudan University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Fuzzy rough sets based on fuzzy quantification",
        "paper_author": "Theerens A.",
        "publication": "Fuzzy Sets and Systems",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Classical (fuzzy) rough sets exhibit sensitivity to noise, which is particularly undesirable for machine learning applications. One approach to solve this issue is by making use of fuzzy quantifiers, as done by the vaguely quantified fuzzy rough set (VQFRS) model. While this idea is intuitive, the VQFRS model suffers from both theoretical flaws as well as from suboptimal performance in applications. In this paper, we improve on VQFRS by introducing fuzzy quantifier-based fuzzy rough sets (FQFRS), which proposes an intuitive fuzzy rough approximation operator that utilizes general unary and binary quantification models. We show how several existing models fit inside FQFRS, as well as how it inspires novel ones. Additionally, we propose several binary quantification models to be used with FQFRS. Furthermore, we conduct a theoretical study of their properties, and investigate their potential by applying them to classification problems. In particular, we highlight the effectiveness of Yager's Weighted Implication-based (YWI) binary quantification model, which induces a fuzzy rough set model that is both a significant improvement on VQFRS, as well as a worthy competitor to the popular ordered weighted averaging based fuzzy rough set (OWAFRS) model.",
        "affiliation_name": "Universiteit Gent",
        "affiliation_city": "Ghent",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Machine learning based prediction and experimental validation of arsenite and arsenate sorption on biochars",
        "paper_author": "Zhang W.",
        "publication": "Science of the Total Environment",
        "citied_by": "18",
        "cover_date": "2023-12-15",
        "Abstract": "Arsenic (As) contamination in water is a significant environmental concern with profound implications for human health. Accurate prediction of the adsorption capacity of arsenite [As(III)] and arsenate [As(V)] on biochar is vital for the reclamation and recycling of polluted water resources. However, comprehending the intricate mechanisms that govern arsenic accumulation on biochar remains a formidable challenge. Data from the literature on As adsorption to biochar was compiled and fed into machine learning (ML) based modelling algorithms, including AdaBoost, LGBoost, and XGBoost, in order to build models to predict the adsorption efficiency of As(III) and As(V) to biochar, based on the compositional and structural properties. The XGBoost model showed superior accuracy and performance for prediction of As adsorption efficiency (for As(III): coefficient of determination (R2) = 0.93 and root mean square error (RMSE) = 1.29; for As(V), R2 = 0.99, RMSE = 0.62). The initial concentrations of As(III) and As(V) as well as the dosage of the adsorbent were the most significant factors influencing adsorption, explaining 48 % and 66 % of the variability for As(III) and As(V), respectively. The structural properties and composition of the biochar explained 12 % and 40 %, respectively, of the variability of As(III) adsorption, and 13 % and 21 % of that of As(V). The XGBoost models were validated using experimental data. R2 values were 0.9 and 0.84, and RMSE values 6.5 and 8.90 for As(III) and As(V), respectively. The ML approach can be a valuable tool for improving the treatment of inorganic As in aqueous environments as it can help estimate the optimal adsorption conditions of As in biochar-amended water, and serve as an early warning for As-contaminated water.",
        "affiliation_name": "Universiteit Gent",
        "affiliation_city": "Ghent",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Synoptic circulation patterns of urban floods for the city of Hyderabad",
        "paper_author": "Mohammed A.",
        "publication": "International Journal of Climatology",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Synoptic fingerprinting of flood driving rainfall events over the Hyderabad city, India were assessed through an unsupervised machine learning technique—self-organizing maps (SOM) for the period 1979–2020. Flood dates were identified using nonscientific data sources, and then large-scale climate variables, that is, integrated vapour transport (IVT) and geopotential height at 500 hPa (Z500) along with rainfall at daily scale were considered. SOM was applied on IVT and results indicated large spatial scale- and season-specific mechanisms in addition to local circulation systems—this highlights SOM's ability to cluster circulation mechanisms as per the relevance. The rainy seasons, that is, monsoon and postmonsoon showed well-known moisture pathways. While synoptic systems can be easily linked with monsoon and postmonsoon mechanisms, it is interesting to note that the local systems exist even during the monsoon and postmonsoon season in addition to the summer season. Spatial patterns of Z500 corresponding to SOM nodes of IVT showed the presence of low-pressure systems (LPSs), tropical cyclones and trough systems. Further analysis was performed, and a total of 35 atmospheric rivers (ARs) were identified. Plots of back trajectories for the selected AR events indicated that Arabian Sea is the main source of moisture in the monsoon season followed by Bay of Bengal for postmonsoon and tropical cyclones in summer season events. Additionally, moisture from land is also observed as another source of moisture. Back-trajectory analysis further indicated AR-LPS interaction during the monsoon and ARs feeding moisture to LPSs. Overall, well-known and season-specific synoptic systems that brought significant rainfall to the study region were identified by the SOM. The proposed framework is adaptable for different locations, and as floods in cities across the globe are on the rise, these findings will have a prominent role in urban flood forecasting and management.",
        "affiliation_name": "Indian Institute of Technology Hyderabad",
        "affiliation_city": "Sangareddy",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Estimating the heterogeneous effect of life satisfaction on cognitive functioning among older adults: Evidence of US and UK national surveys",
        "paper_author": "Komura T.",
        "publication": "SSM - Mental Health",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Backgrounds: The emerging field of positive psychology suggests higher life satisfaction, a form of psychological well-being, may improve cognitive functioning. Although evidence exists for population-average associations between psychological well-being and better cognitive function, little is known about how the relationship varies across individuals. Methods: We analyzed a national sample of US and UK adults aged ≥50 from the Health and Retirement Study (HRS) (n = 10,650) and the English Longitudinal Survey of Aging (ELSA) (n = 5514). We assessed life satisfaction at baseline using the Satisfaction with Life Scale. Cognitive functioning was assessed using a modified version of the Telephone Interview for Cognitive Status score after 4-year follow-up. We estimated the population-average association between life satisfaction and cognitive functioning in each sample via doubly-robust targeted maximum likelihood estimation with SuperLearning. To assess effect heterogeneity, we estimated conditional average effects via a causal forest algorithm. Results: We did not find reliable evidence of a population-average association between life satisfaction and higher cognitive functioning in HRS (HRS: β = -0.12; 95%CI: -0.30, 0.06) and ELSA (ELSA: β = 0.39; 95%CI: -0.00, 0.79). Our machine-learning-based approach for estimating effect heterogeneity discovered the effect of life satisfaction on cognitive function can substantially vary across individuals. Life satisfaction appeared less beneficial, or even detrimental, among individuals with lower socioeconomic status, poor health status, and more negative psychological conditions, both in the US and UK samples. Conclusions: Further research is needed to uncover mechanisms underlying the heterogeneous effects of life satisfaction on cognitive function, as it may have unintended adverse consequences among some subgroups.",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The use of artificial neural networks in modelling migration pollutants from the degradation of microplastics",
        "paper_author": "Kida M.",
        "publication": "Science of the Total Environment",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "The objective of this article was to assess the effectiveness of simulation models in predicting the emission of additives from microplastics. The variety of plastics, their chemical structure, physicochemical properties, as well as the influence of environmental factors on their decomposition generate countless cases for analysis in the laboratory. The search for methods to reduce unnecessary laboratory analyses is a necessary action to protect the environment and ensure economic efficiency. In this study, machine learning techniques, specifically the methodology of artificial neural networks (ANNs), were employed to predict the leaching of contaminants from microplastics. The network's development was based on laboratory test results obtained using gas chromatography coupled to a mass spectrometer (GC–MS). The conducted research revealed the significant utility of the multilayer perceptron (MLP) - type networks, which exhibited correlation levels exceeding 95 % for various predicted values. One comprehensive ANN was developed, encompassing all the parameters analyzed, alongside individual networks for each parameter. A common network for all factors enabled for satisfactory results. Temperature and holding time had the greatest influence on the values of parameters such as the electrolytic conductivity of water (EC), dissolved organic carbon (DOC), and di(2-ethylhexyl) phthalate (DEHP). Correlation results ranged from 0.94 to 0.99 for EC, DEHP and DOC between the model data and laboratory data in each set of training, test, and validation data. The conducted research demonstrated that ANNs are a valuable machine learning method for analyzing and predicting pollutant emissions during the decomposition of microplastics.",
        "affiliation_name": "Politechnika Rzeszowska im. Ignacego Łukasiewicza",
        "affiliation_city": "Rzeszow",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Satellite-estimated air-sea CO<inf>2</inf> fluxes in the Bohai Sea, Yellow Sea, and East China Sea: Patterns and variations during 2003–2019",
        "paper_author": "Yu S.",
        "publication": "Science of the Total Environment",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "The Bohai Sea (BS), Yellow Sea (YS), and East China Sea (ECS) together form one of the largest marginal sea systems in the world, including enclosed and semi-enclosed ocean margins and a wide continental shelf influenced by the Changjiang River and the strong western boundary current (Kuroshio). Based on in situ seawater pCO2 data collected on 51 cruises/legs over the past two decades, a satellite retrieval algorithm for seawater pCO2 was developed by combining the semi-mechanistic algorithm and machine learning method (MeSAA-ML-ECS). MeSAA-ML-ECS introduced semi-analytical parameters, including the temperature-dependent seawater pCO2 (pCO2,therm) and upwelling index (UISST), to characterise the combined effect of atmospheric CO2 forcing, thermodynamic effects, and multiple mixing processes on seawater pCO2. The best-selected machine learning algorithm is XGBoost. The satellite-derived pCO2 achieved excellent performance in this complicated marginal sea, with low root mean square error (RMSE = 20 μatm) and mean absolute percentage deviation (APD = 4.12 %) for independent in situ validation dataset. During 2003–2019, the annual average CO2 sinks in the BS, YS, ECS, and entire study area were 0.16 ± 0.26, 3.85 ± 0.68, 14.80 ± 3.09, and 18.81 ± 3.81 Tg C/yr, respectively. Under continuously increasing atmospheric CO2 concentration, the BS changed from a weak source to a weak sink, the YS experienced interannual fluctuations but did not show significant trend, while the ECS acted as a strong sink with CO2 absorption increased from ∼10 Tg C in 2003 to ∼19 Tg C in 2019. In total, CO2 uptake in the entire study area increased by 85 % in 17 years. For the first time, we present the most refined variation in the satellite-derived pCO2 and air-sea CO2 flux dataset. These complete ocean carbon sink statistics and new insights will benefit further research on carbon fixation and its potential capacity.",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Importance of secondary decomposition in the accurate prediction of daily-scale ozone pollution by machine learning",
        "paper_author": "Du X.",
        "publication": "Science of the Total Environment",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning (ML) models have been proven as a reliable tool in predicting ambient pollution concentrations at various places in the world. However, their performance in predicting the maximum daily 8-h averaged ozone (MDA8 O3), the metric often used for O3 pollution assessment and management, is relatively poorer. This is largely resulted from more irregular data fluctuations of the MDA8 O3 levels governed collectively by the synoptic condition, local photochemistry, and long-range transport. In order to improve the prediction accuracy of MDA8 O3, this study developed a secondary decomposition ML model framework which coupled the complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) as the primary decomposition, the variational mode decomposition (VMD) as secondary decomposition, and the gate recurrent unit (GRU) ML model. By applying this secondary decomposition model framework on MDA8 O3 prediction for the first time, we showed that the prediction accuracy of MDA8 O3 is largely improved from R2 of 0.46 and RMSE of 30.4 μg/m3 for GRU without decomposition to R2 of 0.91 and RMSE of 12.6 μg/m3 over the Pearl River Delta of China. We also found that the prediction accuracy rate of O3 pollution non-attainments, an essential indicator for initiating contingency O3 pollution control, improved greatly from 14.9 % for GRU without decomposition to 72.5 %. The performance of O3 pollution non-attainment prediction is relatively higher in southwestern PRD, which is mainly due to greater number and severity of O3 non-attainments in southwestern cities located downwind of the emission hotspot area at central PRD. This study underscored the importance of secondary decomposition in accurately predicting daily-scale O3 concentration and non-attainments over the PRD, which can be extended to other photochemically active region worldwide to improve their O3 prediction accuracy and assist in O3 contingency control.",
        "affiliation_name": "South China Institute Of Environmental Sciences",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Physics-informed neural networks for studying heat transfer in porous media",
        "paper_author": "Xu J.",
        "publication": "International Journal of Heat and Mass Transfer",
        "citied_by": "28",
        "cover_date": "2023-12-15",
        "Abstract": "Numerous efforts have been devoted to studying heat transfer problems in porous media. Physics-based models, numerical methods and experiments are commonly adopted to obtain the temperature and heat flux fields, along with effective thermophysical properties like effective thermal conductivity for heat conduction, which exert significant impact on analyzing the heat transfer efficiency in porous systems. Recently, using data-driven machine learning methods to predict temperature/heat flux fields and effective thermal conductivity of porous media has gained attention, demonstrating the potential to achieve higher accuracy than physics-based models while requiring less computational time than numerical methods. However, machine learning approaches are commonly restricted by the requirement for sufficient labeled training data, which can be difficult and time-consuming to acquire. In this work, we apply physics-informed neural networks to investigate heat conduction in porous media. We show that, without any labeled training data, accurate predictions for temperature/heat flux fields in porous media can be achieved. The obtained effective thermal conductivity values for an ensemble of porous media samples have an average relative error of only 2.49%. Compared with numerical calculations, a computation acceleration of 5 orders of magnitude has been achieved. Compared with data-driven machine learning methods, this method offers enhanced flexibility since no labeled data is required. Furthermore, we also illustrate that physics-informed neural networks can be easily extended to predict nonlinear heat conduction in porous media. Our work demonstrates that physics-informed neural networks are promising tools for studying heat conduction problems and can also be possibly extended to study other complex heat transfer problems in porous media.",
        "affiliation_name": "UM-SJTU Joint Institute",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Hysteresis response of groundwater depth on the influencing factors using an explainable learning model framework with Shapley values",
        "paper_author": "Niu X.",
        "publication": "Science of the Total Environment",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning has been widely used for groundwater prediction. However, the hysteresis response of groundwater depth (GD) to input features has not been fully investigated. This study uses an interpretation method to reveal the interplay between climate, human activity, and GD while considering the response of groundwater to multiple factors. Six factors [precipitation (P), wind speed (WS), temperature (T), population (POP), gross domestic product (GDP), and effective irrigated area (EIA)] were selected to analyze the hysteresis response of GD in terms of the lag correlation coefficient and lag time. The correlation between climatic variables and GD was weaker than that of anthropogenic variables. The lag time between variables and different types of GD was less than four months at most sites, except for EIA and WS in deep groundwater. The SVM model achieved satisfactory performance in 89 % of the sites. If there were sharp changes in GD during the testing period or significant variations in its seasonal patterns at different times, the SVM model performed poorly. The model was interpreted using the Shapley additive explanation method. The impact of POP and GDP on deep groundwater in irrigated areas was higher than that of shallow groundwater. In urban areas with intensive human activities, anthropogenic variables were the main factors affecting shallow groundwater while the impact of climate was gradually increasing in the suburbs. The influence of precipitation on shallow groundwater was decreased after water transfer from the South-to-North Water Diversion project. Furthermore, this study proposed a multifactor-driven conceptual model that can provide recommendations for analyzing groundwater dynamics in similar areas.",
        "affiliation_name": "The University of Alabama",
        "affiliation_city": "Tuscaloosa",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Interpretable machine learning-based analysis of mechanical properties of extruded Mg-Al-Zn-Mn-Ca-Y alloys",
        "paper_author": "Suh J.S.",
        "publication": "Journal of Alloys and Compounds",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "In this study, the mechanical properties of as-extruded Mg-Al-Zn-Mn-Ca-Y alloys were quantitatively investigated with respect to alloying elements, extrusion temperature, microstructure and texture through interpretable machine learning (IML). To overcome the lack of data, two methods were devised to augment the existing dataset by 39 times using the mean and standard deviation of the measured data. Artificial neural networks predicted room-temperature tensile properties with an accuracy ranging from 0.842 to 0.997 based on R2 using 12 predictors for a total of 1179 data points. Shapley additive explanation identified that Al and Mn are the key determinants for strength and elongation, respectively. Partial dependence plots investigated the interaction of all features to understand the quantitative correlation between features. This IML approach revealed that texture, solid solution and secondary particles are related to the main strengthening mechanism of as-extruded Mg alloys. These results can provide insights into the utilization of IML approach to predict material properties and describe key variables for designing lightweight structural metals.",
        "affiliation_name": "Korea Institute of Materials Science",
        "affiliation_city": "Changwon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Stochastic PDE representation of random fields for large-scale Gaussian process regression and statistical finite element analysis",
        "paper_author": "Koh K.J.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "The efficient representation of random fields on geometrically complex domains is crucial for Bayesian modelling in engineering and machine learning, including Gaussian process regression and statistical finite element analysis. Today's prevalent random field representations are either intended for unbounded domains or are too restrictive in terms of possible field properties. Because of these limitations, new techniques leveraging the historically established link between stochastic PDEs (SPDEs) and random fields have been gaining interest in the statistics and engineering literature. The SPDE representation is especially appealing for engineering applications with complex geometries which already have a finite element discretisation for solving the physical conservation equations. In contrast to the dense covariance matrix of a random field, its inverse, the precision matrix, is usually sparse and equal to the stiffness matrix of an elliptic SPDE. In this paper, we use the SPDE representation to develop a scalable framework for large-scale statistical finite element analysis and Gaussian process (GP) regression on geometrically complex domains. The statistical finite element method (statFEM) introduced by Girolami et al. (2022) is a novel approach for synthesising measurement data and finite element models. In both statFEM and GP regression, we use the SPDE formulation to obtain the relevant prior probability densities with a sparse precision matrix. The properties of the priors are governed by the parameters and possibly fractional order of the SPDE so that we can model on bounded domains and manifolds anisotropic, non-stationary random fields with arbitrary smoothness. We use for assembling the sparse precision matrix the same finite element mesh used for solving the physical conservation equations. The observation models for statFEM and GP regression are such that the posterior probability densities are Gaussians with a closed-form mean and precision. The expressions for the mean vector and the precision matrix do not contain dense matrices and can be evaluated using only sparse matrix operations. We demonstrate the versatility of the proposed framework and its convergence properties with one and two-dimensional Poisson and thin-shell examples.",
        "affiliation_name": "Department of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Artificial intelligence based prediction of optimum operating conditions of a plate and fin heat exchanger under uncertainty: A gray-box approach",
        "paper_author": "Khan J.S.",
        "publication": "International Journal of Heat and Mass Transfer",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "This study is based on gray-box modeling for the prediction of optimum mass flow rates of inlet streams of a Plate and Fin Heat Exchanger under uncertainty. A first principle model of the Plate and Fin Heat Exchanger was developed in Aspen Exchanger Design and Rating. Genetic algorithm was integrated with the first principle model to achieve the highest possible exit temperature of the cold process stream under uncertainty. A dataset of uncertain process conditions and their corresponding optimum inlet flow rates derived through the first principle-genetic algorithm integration was used to develop an artificial neural networks model. The artificial neural networks model was then integrated with the first principle model by replacing the genetic algorithm to form a novel gray-box framework. The proposed gray box model, i.e., artificial neural networks and first principle integration, achieved a higher effectiveness and higher outlet temperature than those derived through the straight run first principle model. The performance of the gray box framework was also comparable to the first principle integrated genetic algorithm approach and significantly minimized the computation time needed for estimating the optimum process conditions. First principle integrated genetic algorithm approach enhanced the effectiveness of the straight run model by 3.05%. Performance of the proposed gray-box model was comparable to the integrated framework of the genetic algorithm with the first principle model but was significantly faster. The developed artificial neural networks model was employed as a surrogate in Sobol and FAST sensitivity analysis framework to identify the impact of input variables on output variables. The proposed gray box based method enhanced the capability of the plate and fin heat exchanger to recover energy from the process stream and its robustness to cope with uncertainty. The proposed approach is suitable for real-time application and would contribute to laying a foundation for petroleum refinery 4.0.",
        "affiliation_name": "Usak University",
        "affiliation_city": "Usak",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Assessing spatiotemporal variability in the concentration and composition of dissolved organic matter and its impact on iron solubility in tropical freshwater systems through a machine learning approach",
        "paper_author": "Kikuchi T.",
        "publication": "Science of the Total Environment",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "Dissolved organic matter (DOM) plays important roles not only in maintaining the productivity and functioning of aquatic ecosystems but also in the global carbon cycle, although the sources and biogeochemical functions of terrestrially derived DOM have not been fully elucidated, particularly in the tropics and subtropics. This study aimed to evaluate the factors influencing spatiotemporal variability in (i) the concentration and composition of DOM, including dissolved organic carbon (DOC), ultraviolet absorption coefficient at 254-nm wavelength (a254), and components identified by fluorescence excitation–emission matrix coupled with parallel factor analysis (EEM-PARAFAC), and (ii) the concentration of dissolved iron (DFe) across freshwater systems (rivers, forested streams, and dam reservoirs) on a tropical island (Ishigaki Island, Japan) based on the results of water quality monitoring at 2-month intervals over a 2-year period. Random forests (RF) machine learning algorithm was employed, with the catchment characteristics (land use, soil type) and water temperature as the predictor variables for DOM and the composition of DOM (EEM-PARAFAC components) and hydrochemistry (water temperature, pH, and concentrations of divalent cations) as the predictor variables for DFe. The RF models for DOC, a254, and three humic-like components exhibited excellent predictive performance, indicating that these DOM properties are not only seasonally variable but also strongly influenced by the compositions of land uses and soil types in the upstream watershed. Poorly drained riparian lowland soil (Gleyic Fluvisols) was identified as the most important catchment parameter that positively influences these DOM variables. The RF model also explained a large portion of the variation in DFe, while terrestrial humic-like components were the most important parameters, emphasizing their significance as organic ligands for iron. These results improve our understanding of the impacts of terrestrial DOM and iron loadings on tropical and subtropical coastal ecosystems as well as on regional and global carbon budgets.",
        "affiliation_name": "Ibaraki Kasumigaura Environmental Science Center",
        "affiliation_city": "Tsuchiura",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Associations between long-term exposure to PM<inf>2.5</inf> chemical constituents and allergic diseases: evidence from a large cohort study in China",
        "paper_author": "Feng C.",
        "publication": "Science of the Total Environment",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Background: Exposure to air pollutants may cause immune responses and further allergic diseases, but existing studies have mostly, if not all, focused on effects of short-term exposure to PM2.5 on allergic diseases. Objectives: We estimated associations of long-term exposure to PM2.5 chemical constituents with allergic disease risks and effect modification. Methods: We used the baseline of a newly established, provincially representative cohort of 51,480 participants in southwest China. The presence of allergic rhinitis, allergic asthma, urticaria, and allergic conjunctivitis was self-reported by following a formed questionnaire in face-to-face interviews. The average concentrations of PM2.5 chemical constituents (NO3−, SO42−, NH4+, organic matter [OM], and black carbon [BC]) over participants' residence were estimated using machine learning models. Logistic regression with double robust estimator and weighted quantile sum regression were used to estimate the effects of PM2.5 chemical constituents on allergic disease risks, as well as relative importance of each PM2.5 chemical constituent. Results: Per interquartile range increase in the concentration of all PM2.5 chemical constituents was associated with the elevated risks for allergic asthma (OR = 1.79 [1.41–2.26]), allergic conjunctivitis (1.54 [1.19–2.00]), urticaria (1.36 [1.25–1.48]), and allergic rhinitis (1.18 [1.11–1.26]). NO3− contributed more to risks for allergic asthma (weight = 46.05 %), urticaria (72.29 %), and allergic conjunctivitis (47.65 %), while NH4+ contributed more to allergic rhinitis (78.07 %). OM contributed most to the risks for allergic asthma (30.81 %) and allergic conjunctivitis (31.40 %). BC was also associated with allergic rhinitis, urticaria, and allergic conjunctivitis, only with a considerable weight for urticaria (24.59 %). Joint effects of PM2.5 chemical constituents on risks for allergic rhinitis and urticaria were stronger in minorities and farmers than their counterparts. Conclusion: Long-term exposure to PM2.5 chemical constituents was associated with the increased allergic disease risks, with NO3− and NH4+ accounting for the largest variance of the associations. Our findings would serve as scientific evidence for developing more explicit strategies of air pollution control.",
        "affiliation_name": "Yunnan Provincial Centers for Disease Control and Prevention",
        "affiliation_city": "Kunming",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Prediction model of type and band gap for photocatalytic g-GaN-based van der Waals heterojunction of density functional theory and machine learning techniques",
        "paper_author": "Zhao Z.",
        "publication": "Applied Surface Science",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Applying suitable two-dimensional (2D) heterojunctions to photocatalytic water cracking reaction can obtain excellent catalytic performance. However, due to many candidate materials and complex interface effects, finding suitable heterojunctions combinations has become a challenge for the above applications. Based on about 1000 pieces of material data in the computational 2D material database, we adopted a simple energy band shift hypothesis to creatively build a machine learning prediction model of g-GaN based 2D Van der Waals (vdW) heterostructures’ type with good performance, and carried out a first-principle calculation to verify the hypothesis. The results show that the band shift hypothesis is valid for the g-GaN based vdW heterojunctions combination without the participation of elements located in the first transitional period and this classification model with the area under curve (AUC) value of 0.93. In addition, we further built a regression prediction model for the band gap value of type Ⅱ g-GaN based vdW heterojunctions in line with the band edge position of photocatalytic water-splitting reaction, with a mean absolute error (MAE) of 0.24 eV. This work establishes a machine learning screening process for g-GaN based vdW heterojunction applied in the field of photocatalysis, which greatly improves the research efficiency.",
        "affiliation_name": "School of Materials Science and Engineering Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Evaluation of fused multisource data of air temperature based on dropsonde and satellite observation",
        "paper_author": "Wei X.",
        "publication": "Science of the Total Environment",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Continuous vertical air temperature (AT) from in-situ observation is of crucial importance for understanding the atmospheric environment, but the satellite data that have complete spatial coverage lacked vertical in-situ observation data, and the vertical dropsonde data from in-situ observations only were single-point observations. Therefore, this article introduced machine learning algorithms for fusing in-situ observation and multi-satellite data to achieve spatial continuity of vertical data on a large scale. Specially, random forest (RF), support vector regression (SVR), artificial neural network (ANN) and recurrent neural network (RNN) were employed to capture the non-linear relationships between the variables and estimated AT. The pre-training process and fine-tuning process ensured the prediction of AT spatiotemporal distribution. The four models were implemented for three-dimensional AT estimating across China. Additionally, we used the radiosonde observation data to evaluate the accuracy of estimated AT data under conventional weather and typhoon conditions. Our results revealed that the RF model performed the best with the R of 0.9992, the MAE of 0.70 °C, and the RMSE of 1.04 °C at the national scale, followed by the SVR and ANN models. The RNN model exhibited promising results under typhoon conditions, which will be valuable insights for further research on the applicability of machine learning models under different weather conditions. Besides, having a larger sample size does not necessarily result in reduced errors. For instance, the MAE value for SVR in the pressure height range of 100–200 hPa was larger than that in the pressure height range of 300–400 hPa, but the former sample size was 16,324, which was 7433 higher than the latter.",
        "affiliation_name": "China Meteorological Administration",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Improving predictions and understanding of primary and ultimate biodegradation rates with machine learning models",
        "paper_author": "Jiang S.",
        "publication": "Science of the Total Environment",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "This study aimed to develop machine learning based quantitative structure biodegradability relationship (QSBR) models for predicting primary and ultimate biodegradation rates of organic chemicals, which are essential parameters for environmental risk assessment. For this purpose, experimental primary and ultimate biodegradation rates of high consistency were compiled for 173 organic compounds. A significant number of descriptors were calculated with a collection of quantum/computational chemistry software and tools to achieve comprehensive representation and interpretability. Following a pre-screening process, multiple QSBR models were developed for both primary and ultimate endpoints using three algorithms: extreme gradient boosting (XGBoost), support vector machine (SVM), and multiple linear regression (MLR). Furthermore, a unified QSBR model was constructed using the knowledge transfer technique and XGBoost. Results demonstrated that all QSBR models developed in this study had good performance. Particularly, SVM models exhibited high level of goodness of fit (coefficient of determination on the training set of 0.973 for primary and 0.980 for ultimate), robustness (leave-one-out cross-validated coefficient of 0.953 for primary and 0.967 for ultimate), and external predictive ability (external explained variance of 0.947 for primary and 0.958 for ultimate). The knowledge transfer technique enhanced model performance by learning from properties of two biodegradation endpoints. Williams plots were used to visualize the application domains of the models. Through SHapley Additive exPlanations (SHAP) analysis, this study identified key features affecting biodegradation rates. Notably, MDEO-12, APC2D1_C_O, and other features contributed to primary biodegradation, while AATS0v, AATS2v, and others inhibited it. For ultimate biodegradation, features like No. of Rotatable Bonds, APC2D1_C_O, and minHBa were contributors, while C1SP3, Halogen Ratio, GGI4, and others hindered the process. Also, the study quantified the contributions of each feature in predictions for individual chemicals. This research provides valuable tools for predicting both primary and ultimate biodegradation rates while offering insights into the mechanisms.",
        "affiliation_name": "Key Laboratory of Pollution Control and Ecosystem Restoration in Industry Clusters, Ministry of Education",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning-guided underlying decisive factors of high-performance membrane distillation system: Membrane properties, operation conditions and solution composition",
        "paper_author": "Ma J.",
        "publication": "Separation and Purification Technology",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Membrane distillation (MD) is considered as one of the promising membrane technologies with the potential to effectively produce freshwater from high concentration brines. Increasing demand for freshwater necessitates a deep understanding of the high-performance MD systems. Traditional experimental approaches are limited in their ability to comprehensively explore factors from multiple perspectives. Herein, a comprehensive machine learning (ML) workflow comprising of four distinct modules was devised to elucidate the decisive factors of high-performance MD systems. A comprehensive database was constructed consisting of 25 input features with membrane properties, operating conditions, and solution composition, along with the inclusion of three output performance indices, namely flux, wetting, and fouling. Leveraging automated machine learning (AutoML) algorithms, three ML models have been developed for accurately predicting the performance of MD system. We interpreted the ML models and extracted meaningful insights pertaining to the contributions of important factors on performances. The results indicated that ML can capture the important roles of the temperature difference between feed and permeate (ΔT). Furthermore, the water contact angle (WCA) made considerable contributions to membrane wetting, and module size attached more importance to membrane fouling. Based on the predictive models, the particle swarm optimization (PSO) effectively inferred 6 optimal parameters to achieve high-performance for the MD system. Our work represents a paradigm shift in the field of membrane technologies, highlighting the potential of ML-guided methods to elucidate the fundamental mechanisms of high-performance MD systems.",
        "affiliation_name": "Victoria University Melbourne, Institute of Sustainable Industries and Liveable Cities",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A novel ternary nanocomposite based electrochemical sensor coupled with regularized neural network for nanomolar detection of sunset yellow FCF",
        "paper_author": "Balram D.",
        "publication": "Journal of Alloys and Compounds",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Synthetic dyes are extensively used worldwide although they instigate adverse environmental and health issues at higher concentrations. A reliable and ultrasensitive electrochemical sensor for nanomolar determination of common food colorant sunset yellow FCF is reported in this paper. The electrochemical sensor was integrated with a regularized neural network to enable intelligent sensing of this azo dye. The sensor was fabricated using a ternary nanocomposite based on silver doped spinel Co3O4 nanorods embedded functionalized multi-walled carbon nanotubes (fCNTs). Co-precipitation method was employed for synthesis of porous Co3O4 nanorods and CNTs were functionalized using acid-treatment approach. Electrochemical investigations based on cyclic voltammetry and differential pulse voltammetry techniques revealed stupendous electrocatalytic performance towards sunset yellow detection. A nanomolar detection limit of 0.8 nM and high sensitivity of 8.79 μA μM−1 cm−2 was exhibited by the developed sensor and real sample analysis experiment was conducted in commercial beverages to validate its practical feasibility.",
        "affiliation_name": "Shoolini University",
        "affiliation_city": "Solan",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Isogeometric Convolution Hierarchical Deep-learning Neural Network: Isogeometric analysis with versatile adaptivity",
        "paper_author": "Zhang L.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "We are witnessing a rapid transition from Software 1.0 to 2.0. Software 1.0 focuses on manually designed algorithms, while Software 2.0 leverages data and machine learning algorithms (or artificial intelligence) for optimized, fast, and accurate solutions. For the past few years, we have been developing Convolution Hierarchical Deep-learning Neural Network Artificial Intelligence (C-HiDeNN-AI), which enables the realization of Engineering Software 2.0 by opening the next-generation neural network-based computational tools that can simultaneously train data and solve mechanistic equations. This paper focuses on solving partial differential equations with C-HiDeNN. Still, the same neural network can be used for training and calibration with experimental data, which will be discussed in a separate paper. This paper presents a computational framework combining the C-HiDeNN theory with isogeometric analysis (IGA), called Convolution IGA (C-IGA). C-IGA has five key features that advance IGA: (1) arbitrarily high-order smoothness and convergence rates without increasing degrees of freedom; (2) a Kronecker delta property that enables direct imposition of Dirichlet boundary conditions; (3) automatic and flexible global/local mesh-adaptivity with built-in length scale control and adjustable radial basis functions; (4) ability to handle irregular meshes and triangular/tetrahedral elements; and (5) GPU implementation that speeds up the program as fast as finite element method (FEM). Mathematically, we prove that both IGA and C-IGA mappings are equivalent, and by taking a special design and modified anchors as nodes, C-IGA degenerates to IGA. We demonstrate the accuracy, convergence rates, mesh-adaptivity, and performance of C-IGA with several 1D, 2D, and 3D numerical examples. The future applications of C-IGA from topology optimization to product manufacturing with multi-GPU programming are discussed.",
        "affiliation_name": "College of Engineering and Information Technology",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neural network based rate- and temperature-dependent Hosford–Coulomb fracture initiation model",
        "paper_author": "Li X.",
        "publication": "International Journal of Mechanical Sciences",
        "citied_by": "14",
        "cover_date": "2023-12-15",
        "Abstract": "The accurate description of the strain rate and temperature dependent response of metals is a perpetual quest in crashworthiness and forming applications. In the present study, experiments are carried out to probe the onset of ductile fracture for an aluminum alloy AA7075-T6 for 136 combinations of stress state, strain rate and temperature. The experimental campaign covers strain rates ranging from 0.001/s to 100/s, and temperatures ranging from 20 °C to 360 °C. We combine a YLD2000 yield surface with a neural network based hardening law to describe the large deformation plasticity response of the material. The NN-based hardening law is trained on experimental data, achieving 3.9% accuracy on force predictions including the post-necking regime. The loading paths to fracture are extracted for each simulation, showcasing non-proportionally evolving stress triaxiality, Lode angle parameter, strain rate and temperature. A neural network parameterized Hosford–Coulomb fracture locus is proposed, which is trainable using these evolving loading histories. The accuracy of the proposed fracture model is validated against the experimental onset of fracture, predicting the fracture onset at an error of 8%.",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Quantitative evaluation of collector flotation performance I: The creation of a flotation index based on mineral recovery",
        "paper_author": "Zhang W.",
        "publication": "Separation and Purification Technology",
        "citied_by": "6",
        "cover_date": "2023-12-15",
        "Abstract": "Collectors are crucial for successful flotation, and their performance evaluation is one of the most important steps in their development process. It is urgent to create new evaluation indices/methods because the existing indices/methods are not ideal in terms of standardization and universality. Collector flotation performance is conventionally evaluated using two parameters, i.e., collecting ability and selectivity. Thus, a two-dimensional evaluation space exists. Through the creation and normalization of a flotation index (FI), based solely upon mineral recovery, this evaluation space may be reduced to one-dimension, in the range of 0 ∼ 1 and verified mathematically. In the construction of FI, the relative recovery (Rr; collector-induced recovery) of the target mineral replaces the absolute recovery (R; used for the existing indices/methods), quantifying actual collecting ability and excluding the adverse effects of variable minerals’ natural or inherent floatability (Rn). Moreover, selectivity is quantified by the recovery gap (ΔR) between the target and gangue minerals. Compared with separation efficiency (SE; a conventional evaluation index), FI fills a gap in collector performance evaluation for single minerals by a convenient process. Additionally, FI can qualitatively/semi-quantitatively evaluate collector flotation performance for mineral mixtures and industrial ores based on the evaluation results for single minerals, reducing laboratory costs. It should be noted that if FI is directly used to calculate collector flotation performance for mineral mixtures and industrial ores, grade analysis is indispensable. The normalized and dimensionless FI is more universal, providing a standardized comparison of collector flotation performance for different flotation systems, different minerals/ores or the same mineral/ore from different mining areas. As the scoring function of flotation performance, FI is the basis for the subsequent construction of a standardized method to comprehensively and quantitatively predict collector flotation performance in combination with quantitative structure–activity relationship (QSAR), machine learning (ML) and Quantum chemistry (QC).",
        "affiliation_name": "University of South Australia",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Machine learning-assisted constitutive modeling of a novel powder metallurgy superalloy",
        "paper_author": "Wen H.",
        "publication": "International Journal of Mechanical Sciences",
        "citied_by": "23",
        "cover_date": "2023-12-15",
        "Abstract": "The flow behavior and microstructure evolution during thermomechanical processing (TMP) of powder metallurgy superalloys are very important for their service behavior. In this contribution, a machine learning-assisted physical model was proposed to predict the flow stress, dynamic recrystallization (DRX) kinetic, and grain size evolution of a novel FGH4113A superalloy during the TMP. The work hardening and dynamic softening stages were modeled separately to predict the flow stress. The novel aspect of the proposed model is that the strong coupled effects of deformation temperature, strain rate, true stain, and primary γ' precipitates on the DRX kinetic were quantitatively described by the genetic algorithm-based artificial neural network (GA-ANN). Besides, the grain size modeling considered the pinning effect by primary γ' precipitates and the deformation-induced DRXed grain growth. Comparing the experimental and predicted flow curves, DRX fraction, and average grain size reveals that the proposed model has a preferable prediction accuracy than the conventional model. Then the specific DRX kinetic and grain size evolution characteristics were revealed. The promoting effect of strain rate on the DRX degree was gradually increased with the deformation temperature. Finally, the 3D processing map based on the developed model was established to guide TMP's optimized design and microstructure control. Three domains were divided and discussed: grain refinement, constant, and growth. The optimal processing window is defined as 1000–1050 °C/0.001–0.006 s−1 and 1075–1100 °C/0.008–0.01 s−1.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Long-term spatiotemporal variations in surface NO<inf>2</inf> for Beijing reconstructed from surface data and satellite retrievals",
        "paper_author": "Zhao Z.",
        "publication": "Science of the Total Environment",
        "citied_by": "7",
        "cover_date": "2023-12-15",
        "Abstract": "Remote sensing data from the Ozone Monitoring Instrument (OMI) and the TROPOspheric Monitoring Instrument (TROPOMI) play important roles in estimating surface nitrogen dioxide (NO2), but few studies have compared their differences for application in surface NO2 reconstruction. This study aims to explore the effectiveness of incorporating the tropospheric NO2 vertical column density (VCD) from OMI and TROPOMI (hereafter referred to as OMI and TROPOMI, respectively, for conciseness) for deriving surface NO2 and to apply the resulting data to revisit the spatiotemporal variations in surface NO2 for Beijing over the 2005–2020 period during which there were significant reductions in nitrogen oxide emissions. In the OMI versus TROPOMI performance comparison, the cross-validation R2 values were 0.73 and 0.72, respectively, at 1 km resolution and 0.69 for both at 100 m resolution. The comparisons between satellite data sources indicate that even though TROPOMI has a finer resolution it does not improve upon OMI for deriving surface NO2 at 1 km resolution, especially for analyzing long-term trends. In light of the comparison results, we used a hybrid approach based on machine learning to derive the spatiotemporal distribution of surface NO2 during 2005–2020 based on OMI. We had novel, independent passive sampling data collected weekly from July to September of 2008 for hindcasting validation and found a spatiotemporal R2 of 0.46 (RMSE = 7.0 ppb). Regarding the long-term trend of surface NO2, the level in 2008 was obviously lower than that in 2007 and 2009, as expected, which was attributed to pollution restrictions during the Olympic Games. The NO2 level started to steadily decline from 2015 and fell below 2008's level after 2017. Based on OMI, a long-term and fine-resolution surface NO2 dataset was developed for Beijing to support future environmental management questions and epidemiological research.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "AI-driven colorimetric nucleic acid test for tilapia lake virus: A large-scale, point-of-care diagnostic model for future emerging diseases",
        "paper_author": "Jaroenram W.",
        "publication": "Aquaculture",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "It is indisputable that the world is currently facing several health challenges, which include outbreaks of diseases. One way to limit the spread of such diseases is to have simple yet efficient bioassays that work well in large-scale operation. To address this issue, a new artificial intelligence (AI) based colorimetric DNA/RNA detection platform was developed using tilapia lake virus as a model. The assay uses a newly formulated indicator dye and colorimetric nucleic acid amplification done in a thermos or a simple heating block to produce visible results that can be observed by the naked eye. To ensure high-throughput screening, an AI-based analysis web application was developed that can be used on computers, tablets, and smartphones to accurately and quickly determine the colorimetric results. With a genetic material extraction procedure that takes only 5 min and requires no equipment, our assay can be completed within an hour from sampling to readout, with 96% accuracy and a sensitivity approaching a single copy of the target virus. The entire assay incubation can be done in a simple thermos, as a substitute for thermal cyclers, rendering its potential use in remote areas where access to electricity is restricted. To demonstrate the versatility of our platform, we modified our testing solution by changing pathogen-specific primers and tested it on various target pathogens that infect humans, animals, and plants. The results were accurate, indicating that the platform has the potential to be used for point-of-care disease diagnosis in the future.",
        "affiliation_name": "Faculty of Science, Mahidol University",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Trends in marine pollution mitigation technologies: Scientometric analysis of published literature (1990-2022)",
        "paper_author": "Anthony D.",
        "publication": "Regional Studies in Marine Science",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "Marine pollution presents a pressing environmental issue in the oceanic realm. To examine the identification, detection, and mitigation technologies employed for marine pollution, a chronological review and analysis were conducted using a systematic search of 90,893 peer-reviewed Scopus-indexed journal articles on the SCOPUS database. From 1990 to 2022, research on marine pollution encompassed a wide range of topics including heavy metal pollution, oil spills, microplastics, and eutrophication. Detection technologies such as image processing, biomonitoring, spectroscopy, and microscopy emerged as prominent technologies, while mitigation strategies revolved around physical, chemical, and biological methods. In order to enhance the effectiveness of marine pollution mitigation, emerging technologies such as cloud-native platforms, decision intelligence, artificial intelligence (AI) and machine learning (ML) should be employed. This review highlights the importance of interdisciplinary involvement and the need to reinforce scientific areas to prevent future marine disasters and pollution, such as the recent incident with the X-Press Pearl.",
        "affiliation_name": "University of Sri Jayewardenepura",
        "affiliation_city": "Nugegoda",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Transition metals anchored on two-dimensional p-BN support with center-coordination scaling relationship descriptor for spontaneous visible-light-driven photocatalytic nitrogen reduction",
        "paper_author": "Zong J.",
        "publication": "Journal of Colloid and Interface Science",
        "citied_by": "12",
        "cover_date": "2023-12-15",
        "Abstract": "Solar energy has the potential to revolutionize the production of ammonia, as it could provide a reliable and uninterrupted source of energy for the chemical reaction involved. However, improving the catalytic performance of catalysts often leads to a reduction in their band gaps, which results in insufficient photogenerated electron potential to realize the nitrogen reduction reaction (NRR), and thus the development of NRR efficient photocatalysts remains a great challenge. Herein, based on the density functional theory (DFT), a series of single-atom photocatalysts with transition metals (TMs) doped on porous boron nitride (p-BN) nanosheet are proposed for NRR. Among them, Re-B3@p-BN could effectively catalyze gas-phase N2 through the corresponding pathways with limiting potentials of 0.31 V. Meanwhile, it exhibits excellent light absorption efficiency under illumination and could spontaneously catalyse nitrogen fixation reactions due to the suitable forbidden band and high photogenerated electron potential. Moreover, a linear relationship descriptor based on the intrinsic properties has been established, using a machine learning approach by considering the combined effects of the central metal atom and the coordination atoms. This descriptor could help accelerate the development of rational and improved 2D NRR photocatalysts with high catalytic activity and high selectivity.",
        "affiliation_name": "School of Material Science and Engineering, Xi’an Jiao Tong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Closed-Loop Soft Robot Control Frameworks with Coordinated Policies Based on Reinforcement Learning and Proprioceptive Self-Sensing",
        "paper_author": "Ju H.",
        "publication": "Advanced Functional Materials",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Recent advances in soft robots have been achieved by using compliant materials and exploiting the advantages of the soft structural designs of living organisms. Living organisms (which have theoretically infinite degrees of freedom) are not only mechanically soft but are also capable of smooth harmonic motions, thanks to global coordination and the individual sensing and control of local tissues. Despite improvements in structural designs, few soft robot control frameworks for global object-oriented behaviors are reported. Such a framework will require the use of multiple segments, with local sensing and independent control using coordinated policies. Here, a class of reinforcement learning based control frameworks for soft robots (with high degrees of freedom) is presented, and their ability to conduct global tasks is demonstrated. Coordinated control policies are formulated to control multiple segments with independently controllable embedded actuators, based on localized proprioceptive self-sensing capabilities. The control frameworks are employed to develop soft physical robots. Demonstrations and experiments include the forward and backward locomotion of multichannel soft robotic flatworms. This approach is applicable to multifunctional, high degrees of freedom soft robots, as demonstrated by experiments with light-sensitive locomotion.",
        "affiliation_name": "Gwangju Institute of Science and Technology",
        "affiliation_city": "Gwangju",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Design and characterization of low Young's modulus Ti-Zr-Nb-based medium entropy alloys assisted by extreme learning machine for biomedical applications",
        "paper_author": "Eldabah N.M.",
        "publication": "Journal of Alloys and Compounds",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "Medium entropy alloys are considered midway between traditional and high entropy alloys. Consequently, typical design techniques are challenging for developing such alloys. In this study, the extreme learning machine approach was effectively used for the compositional design of Ti-Zr-Nb-Mo medium entropy alloys to obtain low Young's modulus with moderate strength for biomedical applications. The newly developed alloys exhibited low Young's modulus as low as 69.5 GPa, with a yield strength of more than 600 MPa. The difference between experimental and simulated results was slight, indicating that neural networks can be used to design medium entropy alloys. Furthermore, the introduced alloys displayed adequate bio characteristics such as decreased magnetic susceptibility and over 98% cell viability. These novel Ti-Zr-Nb-M medium entropy alloys are promising candidates for biomedical implantation because of their superior biomedical properties.",
        "affiliation_name": "Faculty of Engineering",
        "affiliation_city": "New Borg El Arab",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "A novel multi-strategy hydrological feature extraction (MHFE) method to improve urban waterlogging risk prediction, a case study of Fuzhou City in China",
        "paper_author": "Huang H.",
        "publication": "Science of the Total Environment",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "Reliable hydrological data ensure the precision of the urban waterlogging simulation. To reduce the simulation error caused by insufficient basic data, a multi-strategy method (MHFE) for extracting hydrological features is proposed, which includes land use/land cover (LULC) extraction (LE) and digital elevation model (DEM) reconstruction (DR). First, the high-resolution remote image, satellite DEM, precipitation, flood points and depth, and planned LULC were collected. Second, the buildings, roads, and other areas of the satellite image were segmented using the U-Net model, and the LULC data with drainage features were extracted by combining the segmentation result with the planned LULC and drainage data. Then, the terrain features of the road were enhanced to construct high-precision DEM based on the fusion of multi-source data, such as elevation points, LULC, and satellite DEM. Finally, the waterlogging model was implemented under different return periods of rainfalls and typhoon rainfall to obtain the waterlogging distribution and water depth. The simulation results were compared with historical waterlogging event data and water depth observations. The results indicated that the proposed method significantly improved the accuracy of the simulation. In terms of identifying the waterlogging points, the average F1 score increased by 0.36, 0.20, and 0.07 compared to the raw model and the single LE and DR methods, respectively. In terms of water depth simulation, the average Nash-Sutcliffe efficiency (NSE) was increased from −0.24 to 0.86, with DR and LE contributing to 79.1 % and 20.9 %, respectively. The principal contribution and novelty of this paper is to explore the generic method that enhance the hydrological data, and the findings of this study improved the performance of urban waterlogging simulation.",
        "affiliation_name": "Central South University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Bayesian model calibration for diblock copolymer thin film self-assembly using power spectrum of microscopy data and machine learning surrogate",
        "paper_author": "Cao L.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Identifying parameters of computational models from experimental data, or model calibration, is fundamental for assessing and improving the predictability and reliability of computer simulations. In this work, we propose a method for Bayesian calibration of models that predict morphological patterns of diblock copolymer (Di-BCP) thin film self-assembly while accounting for various sources of uncertainties in pattern formation and data acquisition. This method extracts the azimuthally-averaged power spectrum (AAPS) of the top-down microscopy characterization of Di-BCP thin film patterns as summary statistics for Bayesian inference of model parameters via the pseudo-marginal method. We derive the analytical and approximate form of a conditional likelihood for the AAPS of image data. We demonstrate that AAPS-based image data reduction retains the mutual information, particularly on important length scales, between image data and model parameters while being relatively agnostic to the aleatoric uncertainties associated with the random long-range disorder of Di-BCP patterns. Additionally, we propose a phase-informed prior distribution for Bayesian model calibration. Furthermore, reducing image data to AAPS enables us to efficiently build surrogate models to accelerate the proposed Bayesian model calibration procedure. We present the formulation and training of two multi-layer perceptrons for approximating the parameter-to-spectrum map, which enables fast integrated likelihood evaluations. We validate the proposed Bayesian model calibration method through numerical examples, for which the neural network surrogate delivers a fivefold reduction of the number of model simulations performed for a single calibration task.",
        "affiliation_name": "Oden Institute for Computational Engineering and Sciences",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multi-model chain for climate change scenario analysis to support coastal erosion and water quality risk management for the Metropolitan city of Venice",
        "paper_author": "Pham H.V.",
        "publication": "Science of the Total Environment",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "Under the influence of anthropogenic climate change, hazardous climate and weather events are increasing in frequency and severity, with wide-ranging impacts across ecosystems and landscapes, especially fragile and dynamic coastal zones. The presented multi-model chain approach combines ocean hydrodynamics, wave fields, and shoreline extraction models to build a Bayesian Network-based coastal risk assessment model for the future analysis of shoreline evolution and seawater quality (i.e., suspended particulate matter, diffuse attenuation of light). In particular, the model was designed around a baseline scenario exploiting historical shoreline and oceanographic data within the 2015–2017 timeframe. Shoreline erosion and water quality changes along the coastal area of the Metropolitan city of Venice were evaluated for 2021–2050, under the RCP8.5 future scenario. The results showed a destabilizing trend in both shoreline evolution and seawater quality under the selected climate change scenario. Specifically, after a stable period (2021–2030), the shoreline will be affected by periods of erosion (2031–2040) and then accretion (2041–2050), with a simultaneous decrease in seawater quality in terms of higher turbidity. The decadal analysis and sensitivity evaluation of the input variables demonstrates a strong influence of oceanographic variables on the assessed endpoints, highlighting how the factors are strongly connected. The integration of regional and global climate models with Machine Learning and satellite imagery within the proposed multi-model chain represents an innovative update on state-of-the-art techniques. The validated outputs represent a good promise for better understanding the varying impacts due to future climate change conditions (e.g., wind, wave, tide, and sea-level). Moreover, the flexibility of the approach allows for the quick integration of climate and multi-risk data as it becomes available, and would represent a useful tool for forward-looking coastal risk management for decision-makers.",
        "affiliation_name": "Scuola Universitaria Superiore IUSS di Pavia",
        "affiliation_city": "Pavia",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Multimodal Data Integration Advances Longitudinal Prediction of the Naturalistic Course of Depression and Reveals a Multimodal Signature of Remission During 2-Year Follow-up",
        "paper_author": "Habets P.C.",
        "publication": "Biological Psychiatry",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Background: The ability to predict the disease course of individuals with major depressive disorder (MDD) is essential for optimal treatment planning. Here, we used a data-driven machine learning approach to assess the predictive value of different sets of biological data (whole-blood proteomics, lipid metabolomics, transcriptomics, genetics), both separately and added to clinical baseline variables, for the longitudinal prediction of 2-year remission status in MDD at the individual-subject level. Methods: Prediction models were trained and cross-validated in a sample of 643 patients with current MDD (2-year remission n = 325) and subsequently tested for performance in 161 individuals with MDD (2-year remission n = 82). Results: Proteomics data showed the best unimodal data predictions (area under the receiver operating characteristic curve = 0.68). Adding proteomic to clinical data at baseline significantly improved 2-year MDD remission predictions (area under the receiver operating characteristic curve = 0.63 vs. 0.78, p = .013), while the addition of other omics data to clinical data did not yield significantly improved model performance. Feature importance and enrichment analysis revealed that proteomic analytes were involved in inflammatory response and lipid metabolism, with fibrinogen levels showing the highest variable importance, followed by symptom severity. Machine learning models outperformed psychiatrists’ ability to predict 2-year remission status (balanced accuracy = 71% vs. 55%). Conclusions: This study showed the added predictive value of combining proteomic data, but not other omics data, with clinical data for the prediction of 2-year remission status in MDD. Our results reveal a novel multimodal signature of 2-year MDD remission status that shows clinical potential for individual MDD disease course predictions from baseline measurements.",
        "affiliation_name": "Amsterdam Neuroscience",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Federated Learning Based on CTC for Heterogeneous Internet of Things",
        "paper_author": "Gao D.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "25",
        "cover_date": "2023-12-15",
        "Abstract": "Federated learning (FL) is a machine learning technique that allows for on-site data collection and processing without sacrificing data privacy and transmission. Heterogeneity is a key challenge in federated settings. Recently, cross-technology communication (CTC) has emerged as a solution for Internet of Things (IoT) heterogeneity, enabling direct communication between different wireless devices without the need for hardware modifications or gateway intervention. For example, a sophisticated WiFi device can serve as a central coordinator for other heterogeneous devices, such as LoRa, ZigBee, Bluetooth, and LTE, leading to more efficient and ubiquitous cross-network information exchange. However, heterogeneous wireless technologies present different data transmission rates and computing resources, making it difficult to achieve high accuracy in predictions due to large amounts of multidimensional data, communication delays, transmission latency, limited processing capacity, and data privacy concerns. In this work, we propose an FL framework based on CTC for heterogeneous IoT applications, called FLCTC. To demonstrate the usability of FLCTC, we implemented FLCTC and a specific solution for forest fire prediction. FLCTC was concretely implemented as a federal deep learning based on long and short-term memory and used for forest fire prediction, addressing the challenge of data characterization in heterogeneous IoT networks. FLCTC promises to improve communication efficiency and prediction accuracy. Our platform-based evaluation results show that FLCTC is feasible, with a recall of 96% and an accuracy of 88%, offering valuable insights into the use of FL with CTC for heterogeneous IoT applications.",
        "affiliation_name": "School of Communications and Information Engineering",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "OCro: Open-Set Cross-Domain Human Activity Recognition Based on Radio Frequency",
        "paper_author": "Lv P.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "With the help of machine learning, models are trained to recognize human activity based on radio frequency signals, which are widely used in human-computer interaction, healthcare, etc. Cross-domain human activity recognition (HAR) aims to adapt a model trained in a specific source domain (including environment and user) for another target domain. Most existing cross-domain recognition methods are proposed under an ideal closed-set assumption, which means the training set and the testing set contain the same categories of human activities. However, when a model is applied in practice for HAR, it often encounters new categories of activities which are not contained in the training set. Under such open-set condition, the traditional closed-set cross-domain recognition model usually incorrectly identifies the new activity as a known activity, which decline the recognition accuracy. In this article, a model is proposed for open-set cross-domain HAR. The model is established based on generative adversarial network, and a unique generation module is designed to generate confusing samples whose features are similar to known classes. Thanks to such design, the proposed model can autonomously select appropriate unlabeled samples under the open-set condition to improve the open-set recognition ability of the model in the target domain. Extensive experiments are conducted based on four real data sets, one is collected by ourselves and the other three are public. The results show that the proposed model outperforms other state-of-the-art methods in the open-set and the cross-domain contexts.",
        "affiliation_name": "City University of Macau",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "A new perspective on predicting the reaction rate constants of hydrated electrons for organic contaminants: Exploring molecular structure characterization methods and ambient conditions",
        "paper_author": "Zhu T.",
        "publication": "Science of the Total Environment",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Hydrated electrons (eaq−) exhibit rapid degradation of diverse persistent organic contaminants (OCs) and hold great promise as a formidable reducing agent in water treatment. However, the diverse structures of compounds exert different influences on the second-order rate constant of hydrated electron reactions (keaq−), while the same OCs demonstrate notable discrepancies in keaq− values across different pH levels. This study aims to develop machine learning (ML) models that can effectively simulate the intricate reaction kinetics between eaq− and OCs. Furthermore, the introduction of the pH variable enables a comprehensive investigation into the impact of ambient conditions on this process, thereby improving the practicality of the model. A dataset encompassing 701 keaq− values derived from 351 peer-reviewed publications was compiled. To comprehensively investigate compound properties, this study introduced molecular descriptor (MD), molecular fingerprint (MF), and the integration of both (MD + MF) as model variables. Furthermore, 60 sets of predictive models were established utilizing two variable screening methodologies (MLR and RF) and ten prominent algorithms. Through statistical parameter analysis, it was determined that descriptors combined with MD and MF, the RF screening method, and the symbolism algorithm exhibited the best predictive efficacy. Importantly, the combination of descriptor models exhibited significantly superior performance compared to individual MF and MD models. Notably, the optimal model, denoted as RF - (MF + MD) - LGB, exhibited highly satisfactory predictive results (R2tra = 0.967, Q2tra = 0.840, R2ext = 0.761). The mechanistic explanation study based on Shapley Additive Explanations (SHAP) values further elucidated the crucial influences of polarity, pH, molecular weight, electronegativity, carbon–carbon double bonds, and molecular topology on the degradation of OCs by eaq−. The proposed modeling approach, particularly the integration of MF and MD, alongside the introduction of pH, may furnish innovative ideas for advanced reduction or oxidation processes (ARPs/AOPs) and machine learning applications in other domains.",
        "affiliation_name": "Yangzhou University",
        "affiliation_city": "Yangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A comprehensive literature mining and analysis of nitrous oxide emissions from different innovative mainstream anammox-based biological nitrogen removal processes",
        "paper_author": "Liu S.",
        "publication": "Science of the Total Environment",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "The biological nitrogen removal (BNR) process in wastewater treatment plants generates a substantial volume of nitrous oxide (N2O), which possesses a potent greenhouse gas effect. A limited number of studies have systematically investigated the N2O emissions of anammox-based systems with different BNR processes under mainstream conditions. Based on extensive big data statistical analysis, it had been revealed that simultaneous nitritation, anammox and denitrification (SNAD), partial nitritation anammox (PNA) and partial denitrification anammox (PDA), exhibit significantly lower N2O emission factors when compared to traditional BNR processes. The median values for N2O emission factors were determined to be 1.01 %, 1.15 % and 1.43 % for SNAD, PNA and PDA, respectively. Based on nitrogen removal data and N2O emission factors, the N2O emissions from PNA, SNAD and PDA processes were calculated to be 0.016 g·d−1, 0.037 g·d−1 and 0.008 g·d−1, respectively. Furthermore, the machine learning models (SVM and ANN) exhibited excellent predictive performance for N2O emissions in the BNR processes. However, after removing environmental factors, the R2 value of the SVM model sharply decreased. The SHAP feature analysis demonstrated the significant impact of environmental factors on the accuracy of predictive performance in machine learning models. Spearman correlation analysis was employed to investigate the relationship between N2O emissions and operational factors as well as microbial communities. The results demonstrated a negative correlation between HRT, temperature and C/N with N2O emissions. Moreover, strong associations were observed between Nitrosomonas, Nitrospira, Denitratisoma, Thauera species and N2O emissions. The contribution of N2O production via AOB pathways played a key role that was quantitatively calculated to be 93 %, 80 % and 48 % in the PNA, SNAD and PDA processes, respectively. These findings highlight the potential of these innovative BNR processes in mitigating N2O emissions.",
        "affiliation_name": "Tianjin University of Science &amp; Technology",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep learning-based analysis of the main controlling factors of different gas-fields recovery rate",
        "paper_author": "Li D.",
        "publication": "Energy",
        "citied_by": "4",
        "cover_date": "2023-12-15",
        "Abstract": "Due to the importance of the main controlling factors for oil and gas field development, numerical simulation methods, physical experimental methods and other methods have been used to study the problem. However, it is difficult to find the main controlling factors of a certain type of gas field using these methods. Therefore, a two-fold three-network model is proposed to solve the difficulties by coupling dynamic production data and static geological engineering data in this paper. First fold is consisted of 1D convolution network and Long Short-Term Memory neural network (LSTM), can perform good feature extraction and learn long time sequence dependence for dynamic production sequence data. Second fold made of BP neural network, is mainly dealing with static geological engineering data. By combining the two folds, the model can couple dynamic production data and static geological engineering data at the same time. Finally, the Garson feature selection are used to obtain the main controlling factors of gas field recovery rate based on trained network model. The experimentally obtained trained model can fit the recovery rate of gas field well. This shows that the proposed method can effectively discover the main controlling factors for gas field for different types, which has wide application for gas development.",
        "affiliation_name": "Research Institute of Petroleum Exploration and Development",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Energy-Efficient and QoS-Aware Data Transfer in Q-Learning-Based Small-World LPWANs",
        "paper_author": "Chilamkurthy N.S.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "3",
        "cover_date": "2023-12-15",
        "Abstract": "The widespread use of the Internet of Things (IoT) necessitates large-scale communication among smart IoT devices (IoDs) across a wide geographical area. However, due to the limited radio range and scalability issues of traditional wireless sensor networks, wide-area communication among IoDs is not feasible. As a solution, a low-power wide-area network (LPWAN) is emerging as one of the techniques that can provide long-range communication with minimal power consumption. Nevertheless, the direct data transmission approach will no longer be viable due to its short network lifetime. As such, multihop data routing strategies for LPWANs are proposed in the literature. However, multihop data transmission has several challenges, including increased data latency, energy imbalance, poor bandwidth utilization, and low data throughput. To address these challenges, we propose a novel method that uses the machine learning technique for an energy-efficient and Quality-of-Service (QoS)-aware data transfer based on a recent breakthrough in social networks known as small-world characteristics (SWC). The network having SWC (i.e., low average path length and high average clustering coefficient) uses long-range links to reduce the number of intermediate hops for data transmission. In particular, a Q -learning framework is utilized for introducing optimal long-range links between the selected IoDs, resulting in the development of a small-world LPWAN (SW-LPWAN). Furthermore, the performance of the proposed method is computed in terms of energy efficiency and QoS. Moreover, the results are compared with existing data routing techniques, such as low-energy adaptive clustering hierarchy (LEACH), modified LEACH, conventional multihop, and direct data transmission. Specifically, the proposed method maintains 29% more alive nodes, 18% higher residual energy, and 22% higher data throughput compared to the second-best-performing method. As such, the obtained experimental results validate that the proposed method outperforms other existing methods in the context of energy consumption and QoS.",
        "affiliation_name": "SRM University-AP",
        "affiliation_city": "Mangalagiri",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Data-Augmentation-Based Federated Learning",
        "paper_author": "Zhang H.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "With the rapid growth of the number of devices generating and collecting data, dispersion becomes an important feature of data in Internet of Things. Federated learning (FL) provides a feasible way to mine information in such distributed data. It involves training machine learning models over multiple distributed participants without raw data transmission. However, due to the data heterogeneity among participants, the performance of the FL model degrades dramatically. Currently, improved methods mainly reduce data heterogeneity from the perspective of modifying the process of model training, which usually have problems, such as high-resource consumption or the need for auxiliary data. In this article, we enhance FL model from another perspective, focusing on data rather than model training. We reduce data heterogeneity by enhancing the trained local data to improve FL performance. Specifically, we propose an FL method based on data augmentation (abbreviated as FedM-UNE), implementing the classic data augmentation method MixUp in federated scenarios without transferring raw data. Furthermore, in order to adapt this method to regression tasks, we first modify MixUp by bilateral neighborhood expansion (MixUp-BNE), and then propose a federated data augmentation method named FedM-BNE based on it. Compared with the conventional FL method, both FedM-UNE and FedM-BNE increase negligible overhead. To demonstrate the effectiveness, we conduct exhaustive experiments on six data sets employing a variety of loss functions. The results indicate that FedM-UNE and FedM-BNE consistently improve the performance of the FL model. Moreover, our methods are compatible with existing FL enhancements, which yield further improvements in performance.",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The Security and Privacy of Mobile-Edge Computing: An Artificial Intelligence Perspective",
        "paper_author": "Wang C.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "26",
        "cover_date": "2023-12-15",
        "Abstract": "Mobile-edge computing (MEC) is a new computing paradigm that enables cloud computing and information technology (IT) services to be delivered at the network's edge. By shifting the load of cloud computing to individual local servers, MEC helps meet the requirements of ultralow latency, localized data processing, and extends the potential of the Internet of Things (IoT) for end-users. However, the crosscutting nature of MEC and the multidisciplinary components necessary for its deployment have presented additional security and privacy concerns. Fortunately, artificial intelligence (AI) algorithms can cope with excessively unpredictable and complex data, which offers a distinct advantage in dealing with sophisticated and developing adversaries in the security industry. Hence, in this article, we comprehensively provide a survey of security and privacy in MEC from the perspective of AI. On the one hand, we use European Telecommunications Standards Institute (ETSI) MEC reference architecture as our-based framework while merging the software-defined network (SDN) and network function virtualization (NFV) to better illustrate a serviceable platform of MEC. On the other hand, we focus on new security and privacy issues, as well as potential solutions from the viewpoints of AI. Finally, we comprehensively discuss the opportunities and challenges associated with applying AI to MEC security and privacy as possible future research directions.",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Rapid machine-learning enabled design and control of precise next-generation cryogenic surgery in dermatology",
        "paper_author": "Zohdi T.I.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "In the field of dermatology, the use of cryogenic processes, such as cryoablation, cryotherapy, etc., have grown dramatically over the last decade. This usually entails using a cryoprobe to freeze and destroy unwanted tissue, such as cancer cells. The focus of this work is to develop a digital-twin (a digital replica) of the performance of a cryogenic probe, which can be used to pre-plan and optimize surgical procedures, in order to maximize successful outcomes. Specifically, we model the optimal cryoprobe-induced cooling protocol needed to eliminate cells/tissue in specific regions, while minimizing damage to nearby tissue. The modeling approach is to develop mathematical surface point-source heat extraction kernels and then to create optimal surface patterns that the cryoprobe induces, by arranging the point-sources accordingly. Spatial and temporal control of the heat extraction is modeled. The entire subdermal thermal field is then constructed by superposing the solutions, enabling precise cryogenic treatment. Finally, a Machine Learning Algorithm (MLA) is then applied to optimize the set of parameters to deliver a precise response, making it an ideal real-time surgical tool.",
        "affiliation_name": "Department of Mechanical Engineering",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Smart Grid Meets URLLC: A Federated Orchestration With Improved Communication for Efficient Energy Resources Management",
        "paper_author": "Hossain M.B.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "1",
        "cover_date": "2023-12-15",
        "Abstract": "Efficient data communication and machine learning aspects are crucial for orchestrating the distributed resources of smart grid (SG) networks. 5G telecom technologies have enabled ultrareliable low-latency communication (URLLC) to provide low-latency data communication and accelerate distributed machine learning [such as federated learning (FL)] with high reliability. For critical SG operations, such as islanding detection and instability of frequency regulation, the adoption of URLLC and FL appears paramount to enable near real-time communication and collaborative decision making for resource management. However, SG with URLLC and/or FL has been poorly studied in the literature. We develop a novel framework and demonstrate our findings on the importance of URLLC and FL for efficient energy trading between distributed energy sources and to minimize energy loss by enhancing the resilience of critical SG operations. Extensive experiments using real-time data sets validate our design assumptions and ideas.",
        "affiliation_name": "Deakin University",
        "affiliation_city": "Geelong",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A Social Robot Architecture for Personalized Real-Time Human-Robot Interaction",
        "paper_author": "Foggia P.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "10",
        "cover_date": "2023-12-15",
        "Abstract": "In the age of the Internet of Things (IoT), the combination of robotics and artificial intelligence has paved the way for the development of social robots able to undertake realistic conversations with humans, making them the perfect human interface in applications like for instance, robotic house assistants and hotel concierges. Despite the several solutions developed in recent years, the definition of social robot requirements and the software modules needed to meet such requirements has not yet been formalized. In this article, we define the requirements of a social robot and propose a software architecture that includes all the necessary modules to meet them. The proposed architecture, implemented using robot operating system (ROS) nodes, is hardware-independent, enabling its reuse across different robotic platforms with interchangeable types of sensors and actuators. We deployed a social robot based on this architecture to interact with attendees of a real exhibition context and validated the reliability of our proposed solution through a survey of 161 users. The results of the user study indicated a high-quality user experience with the social robot, with scores ranging from 4 to 5 (being 5 the maximum score). Sharing these design choices and evaluation results could significantly benefit the development of future social robotics applications in the context of IoT.",
        "affiliation_name": "Università degli Studi di Salerno",
        "affiliation_city": "Salerno",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Efficient Model Extraction by Data Set Stealing, Balancing, and Filtering",
        "paper_author": "Yang P.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Model extraction replicates the functionality of machine learning models deployed as a service. Recently, generative adversarial networks (GANs)-based methods have achieved remarkable performance in data-free model extraction. However, previous methods generate random data in every training batch, resulting in slow convergence and redundant queries. We propose to tackle the task with a much simpler paradigm. Specifically, we steal a data set with GAN before training the clone model rather than during every training batch. Benefiting from full use of the generated data, the proposed paradigm needs less training time and query cost. To improve the class distribution of data, a balancing strategy is applied. Furthermore, the balanced data set is filtered based on adversarial robustness for better quality. Combining the above strategies, we propose an efficient model extraction by data set stealing, balancing, and filtering (DSBF). Experiments on three widely used data sets show that DSBF outperforms previous methods while converging faster and costing fewer queries.",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An Automatic Malaria Disease Diagnosis Framework Integrating Blockchain-Enabled Cloud-Edge Computing and Deep Learning",
        "paper_author": "Chen S.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Malaria is a life-threatening disease, which mainly occurs in developing countries and regions with poor sanitary conditions. Early diagnosis of malaria will effectively decrease the death rate. In this article, we develop an automatic malaria disease diagnosis framework integrating blockchain-enabled cloud-edge computing and deep learning. The diagnosis task is divided into malaria parasite segmentation from blood smear images and classification of parasite species and stages. To meet the massive demand for deep learning training, we design a diagnosis pipeline that is deployed in a cloud-edge paradigm to utilize both local and remote resources. At edge nodes, preprocessed data sets are classified by U-Net in a supervised approach to generate coarse probability maps. Then, the normalized images and generated probability maps are uploaded to the cloud server. At the cloud, the uploaded probability maps are used to weakly supervise the stacked dilated U-Net (SDU-Net) to segment infected cells. Further classifications of malaria parasites species and stages are conducted by a pretrained MobileNet V1. The blockchain technology is adopted during the data transmission process. The diagnosis results will be sent back to the original local hospital immediately through the cloud. Our framework improves the diagnosis accuracy and eases the burden of deep learning training. Evaluation on real data collection MP-IDB demonstrated the effectiveness of our method.",
        "affiliation_name": "Key Laboratory of Embedded System and Service Computing, Ministry of Education",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Remaining useful life prediction and state of health diagnosis for lithium-ion batteries based on improved grey wolf optimization algorithm-deep extreme learning machine algorithm",
        "paper_author": "Zhou Y.",
        "publication": "Energy",
        "citied_by": "32",
        "cover_date": "2023-12-15",
        "Abstract": "The prediction of SOH for Lithium-ion battery systems determines the safety of Electric vehicles and stationary energy storage devices powered by LIBs. State of health diagnosis and remaining useful life prediction also rely significantly on excellent algorithms and effective indicators extraction. Since the data obtained from the aging experiment of Lithium-ion batteries is rich in electrochemical and dynamic information, useful health indicators can be extracted for SOH and RUL prediction of machine learning. This paper presents a method for predicting SOH and RUL based on a data-driven model of deep extreme learning machine based on improved Grey Wolf optimization algorithm. Firstly, GWO algorithm is improved by piecewise chaotic distribution and sine-cosine algorithm, and then multi-layer superposition is performed on an extreme learning machine to form DELM. Additionally, the experimental data of the Center for Advanced Life Cycle Engineering data set was extracted and analyzed, the aging state of batteries was analyzed and verified from multiple scales, and the strong correlation of aging characteristics was extracted and verified. After that, the model was driven by the extracted health indicators, and the accuracy and robustness of the results were checked.",
        "affiliation_name": "Robert Gordon University",
        "affiliation_city": "Aberdeen",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Cooperative Physical Layer Authentication With Reputation-Inspired Collaborator Selection",
        "paper_author": "Zhang T.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Machine learning (ML)-based physical layer authentication (PLA) has attracted much attention since neural networks can be constructed to identify channel characteristics in complex wireless environments. This enables high-authentication performance and lightweight deployment in the Internet of Things (IoTs). Due to the booming growth of IoT connections, the workload of the central authenticator increases significantly. As a result, resource-constrained terminals are unable to independently handle the computationally complex ML task. Therefore, cooperative PLA (CoPLA), which introduces multiple supervised nodes as task-sharing entities, is emerged as a promising solution to address this concern. However, in existing CoPLA studies, some critical issues have been overlooked. For example, the consideration of which collaborative nodes are eligible or best suited for cooperation to maximize the authentication gains. Moreover, the security threats posed by untrusted collaborators are equally challenging. In this article, we propose a federated learning (FL)-based CoPLA scheme that utilizes a group of edge devices to jointly build an authenticator. This ensures privacy preservation and higher robustness. To figure out the optimal collaborator selection in CoPLA, an adaptive search procedure via reinforcement learning (RL) is customized. Furthermore, we introduce a lightweight reputation estimation method to evaluate each collaborator's credibility, thereby uncovering underperforming devices or hidden internal attackers. Finally, simulations and real-world experiments are carried out. The results show that the authentication accuracy of our scheme is 9.52% higher than that of blind cooperation. And, it outperforms other existing CoPLA schemes in terms of time efficiency and robustness.",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Label-free learning of elliptic partial differential equation solvers with generalizability across boundary value problems",
        "paper_author": "Zhang X.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "Traditional numerical discretization-based solvers of partial differential equations (PDEs) are fundamentally agnostic to domains, boundary conditions and coefficients. In contrast, machine learnt solvers have a limited generalizability across these elements of boundary value problems. This is strongly true in the case of surrogate models that are typically trained on direct numerical simulations of PDEs applied to one specific boundary value problem. In a departure from this direct approach, the label-free machine learning of solvers is centered on a loss function that does not use computed field solutions as labels. Instead, the PDE and boundary conditions are directly incorporated in residual form to express the loss function during training. However, their generalization across boundary conditions is limited and they remain strongly domain-dependent. Here, we present a framework that generalizes across domains, boundary conditions and coefficients while simultaneously learning the PDE in weak form. Our work explores the ability of convolutional neural network (CNN)-based encoder–decoder architectures to learn to solve a PDE in greater generality than its restriction to a particular boundary value problem. In this first Communication, we take the canonical path through elliptic PDEs and focus on steady-state diffusion, linear and nonlinear elasticity. Importantly, the learning happens independently of any labeled field data from either experiments or direct numerical solutions. We develop probabilistic CNNs in the Bayesian setting using variational inference. Extensive results for these problem classes demonstrate the framework's ability to learn PDE solvers that generalize across hundreds of thousands of domains, boundary conditions and coefficients, including extrapolation beyond the learning regime. Once trained, the machine learning solvers are orders of magnitude faster than discretization-based solvers. They therefore have relevance to high-throughput solutions of PDEs on varied domains, boundary conditions and coefficients, such as for inverse modeling, optimization, design and decision-making. We place our work in the context of other recent machine learning solvers of PDEs including continuous operator learning frameworks, as well as make comparisons of performance where possible. Finally, we note extensions to transfer learning, active learning and reinforcement learning.",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Enhancing wettability prediction in the presence of organics for hydrogen geo-storage through data-driven machine learning modeling of rock/H<inf>2</inf>/brine systems",
        "paper_author": "Tariq Z.",
        "publication": "Fuel",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "The success of geological H2 storage relies significantly on rock–H2–brine interactions and wettability. Experimentally assessing the H2 wettability of storage/caprocks as a function of thermos-physical conditions is arduous because of high H2 reactivity and embrittlement damages. Data-driven machine learning (ML) modeling predictions of rock–H2–brine wettability are less strenuous and more precise. They can be conducted at geo-storage conditions that are impossible or hazardous to attain in the laboratory. Thus, ML models were utilized in this research to accurately model the wettability behavior of a ternary system consisting of H2, rock minerals (quartz and mica), and brine at different operating geological conditions. The results revealed that the ML models accurately captured the wettability behavior at different geo-storage conditions by yielding less than 5% mean absolute percent error and above 0.95 coefficient of determination values. The partial dependency or sensitivity plots were generated to evaluate the impact of individual features on the trained models. These plots revealed that the models accurately captured the physics behind the problem. Furthermore, a mathematical equation is derived from the trained ML model to predict the wettability behavior without using any ML software. The accuracy of the predictions of the ML model can be beneficial for exactly predicting the H2 geo-storage capacities and assessing of H2 containment security of storage and caprocks for large-scale geo-storage projects.",
        "affiliation_name": "Edith Cowan University",
        "affiliation_city": "Perth",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A multi-population particle swarm optimization-based time series predictive technique",
        "paper_author": "Kuranga C.",
        "publication": "Expert Systems with Applications",
        "citied_by": "19",
        "cover_date": "2023-12-15",
        "Abstract": "In several businesses, forecasting is needed to predict expenses, future revenue, and profit margin. As such, accurate forecasting is pivotal to the success of those businesses. Due to the effects of different exogenous factors, such as economic fluctuations, and weather conditions, time series is susceptible to nonlinearity and complexity, making accurate predictions difficult. This work proposes a machine-learning-based time series forecasting technique to improve the precision and computation performance of an induced time series forecasting model. The proposed technique, a multi-population particle swarm optimization-based nonlinear time series predictive model, decomposes a predictive task into three sub-tasks: observation window optimization, predictive model induction task, and forecasting horizon prediction. Each sub-task is optimized by a particle swarm optimization sub-swarm in which the sub-swarms are executed in parallel. The proposed technique was experimentally evaluated on fifteen Electric load time series using root mean square error, mean absolute percentage error, and computation time as performance measures. The results obtained show that the proposed technique was effective to induce a forecasting model of improved predictive and computation performance to outperform the benchmark techniques on all datasets. Also, the proposed algorithm was competitive with state-of-the-art techniques. The future direction of this work will consider an empirical analysis of the search and solution spaces of the proposed technique and perform a fitness landscape analysis.",
        "affiliation_name": "Manicaland State University of Applied Sciences",
        "affiliation_city": "Mutare",
        "affiliation_country": "Zimbabwe"
    },
    {
        "paper_title": "An evolutionary ensemble convolutional neural network for fault diagnosis problem",
        "paper_author": "Najaran M.H.T.",
        "publication": "Expert Systems with Applications",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Automatic fault diagnosis in many systems is performed via the analysis of vibration data in the time or frequency domain. In the literature, many approaches for extracting featured from signals for fault diagnosis have been proposed. In this paper, we apply a variety of transform functions including Fourier, Wavelet, etc. to extract features from the vibration data, which includes the statistical features and some features automatically extracted via Convolutional Neural Networks (CNNs). For each of these feature extraction approaches, a learning algorithm is trained to diagnose the faults and their results are aggregated in an ensemble machine learning algorithm. The weights of the base learner algorithms are optimized via an evolutionary algorithm to achieve the best-weighted voting scheme. The architecture of CNNs has a significant effect on the performance of the algorithm, thus, in this paper, an evolutionary algorithm is proposed to find the best architecture for CNNs in fault diagnosis. The CNNs are trained via gradient descent algorithms which suffer from getting stuck in local optima. To manage this, we propose an evolutionary algorithm that benefits from the speed of gradient descent and the global search of evolutionary algorithms. The proposed algorithm is tested on a number of benchmark problems and the experimental results are presented.",
        "affiliation_name": "University of Hertfordshire",
        "affiliation_city": "Hatfield",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Predicting minimum miscible pressure in pure CO<inf>2</inf> flooding using machine learning: Method comparison and sensitivity analysis",
        "paper_author": "F. Al-Khafaji H.",
        "publication": "Fuel",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "CO2 injection for enhanced oil recovery (EOR) is widely recognized as an efficient technique for carbon capture, utilization, and storage (CCUS). This operation has a significant impact on various technical parameters, emphasizing the need to carefully consider and select the optimum approach. Among these factors, the minimum miscible pressure (MMP) plays a crucial role in determining the effectiveness and performance of CO2 injection. Therefore, this study aims to assess the reliability of machine learning (ML) in predicting the MMP of pure CO2 and examine the influence of different independent parameters. To achieve this, five ML methods were employed to predict the pure CO2 MMP, and the results were compared to statistical evaluations based on empirical correlations. In addition, three types of data with different functional input parameters were used in this research. Two types of data were obtained from existing literature, while the third category was collected from the thesis and PVT reports for specific Iraqi oil fields. The ML models were constructed by splitting the dataset into 20% for testing and 80% for training using Python programming. The significance of this study lies in its ability to identify the most efficient approach for forecasting MMP. The results of this work revealed that the K-nearest neighbors (KNN) model indicated the best statistical evaluation among the ML learning algorithms for two types of data (2) and (3) in predicting the MMP for pure CO2 flooding. This was evidenced by the lowest mean square error and the highest coefficient of determination. Additionally, the findings indicated that the support vector regression (SVR) method is an effective technique for smaller datasets. Moreover, the sensitivity analysis and assessment of the relative impacts of various input parameters revealed that the prediction of MMP is most sensitive to the composition of the injected gas and temperature, accounting for 46% and 28.5% of the variation, respectively. Finally, the presented ML models indicate exceptional accuracy, speed, adaptability in handling diverse conditions, and cost-effectiveness when compared to conventional approaches. These results verify the ability of ML models to provide high-quality predictions.",
        "affiliation_name": "Ministry of Oil, Republic of Iraq",
        "affiliation_city": "Baghdad",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Classification of olive cultivars by machine learning based on olive oil chemical composition",
        "paper_author": "Skiada V.",
        "publication": "Food Chemistry",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "Extra virgin olive oil traceability and authenticity are important quality indicators, and are currently the subject of exhaustive research, for developing methods to secure olive oil origin-related issues. The aim of this study was the development of a classification model capable of olive cultivar identification based on olive oil chemical composition. To achieve our aim, 385 samples of two Greek and three Italian olive cultivars were collected during two successive crop years from different locations in the coastline part of western Greece and southern Italy and analyzed for their chemical characteristics. Principal Component Analysis showed trends of differentiation among olive cultivars within or between the crop years. Artificial intelligence model of the XGBoost machine learning algorithm showed high performance in classifying the five olive cultivars from the pooled samples.",
        "affiliation_name": "University of Patras",
        "affiliation_city": "Rio",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "A hybrid machine learning framework for forecasting house price",
        "paper_author": "Zhan C.",
        "publication": "Expert Systems with Applications",
        "citied_by": "13",
        "cover_date": "2023-12-15",
        "Abstract": "House price prediction is one of the most important factors affecting national real estate policies. However, developing an accurate housing price prediction model is a significant challenge for the real estate market. This study presents a framework of house price prediction models that address this issue by improving forecasting performance, explicitly demonstrating the novelty in the Hybrid Bayesian Optimization (HBO) models combined with Stacking (HBOS), Bagging (HBOB), and Transformer (HBOT) techniques. These hybrid models employ Bayesian Optimization for hyperparameter tuning, leading to superior prediction accuracy and stability. Additionally, the proposed framework can assess a statistical and accurate assessment of the predictive performance of house price forecasting models in different scenarios. Furthermore, we constructed a multi-source dataset containing 1,898,175 transactions of the Hong Kong real estate market covering a period from January 2, 1996, to May 13, 2021. This dataset, another major contribution to the field, enables comprehensive model testing and could be a valuable resource for future research. Then, the proposed hybrid models are compared with 18 benchmark models. Thirteen evaluation metrics are used to evaluate the predictive performance, while the non-parametric testing, including Friedman, Iman–Davenport, and Nemenyi post-hoc tests methods, are adopted to assess the significance of differences in the predictive performance of each model. The experimental results show that the HBOS models are superior to the other benchmark models for application in the house price prediction problem. The HBOS-CatBoost model showed superior performance in terms of RMSE compared to both the HBOB-XGBoost and HBOT-ConvLSTM models, with relative RMSE reductions of 5.11% and 25.56%, respectively. The main contributions of this work are the creation of a rich multi-source dataset, the proposal of novel hybrid models for improved house price prediction, and a comprehensive performance evaluation framework. These findings offer a significant step forward in the housing price prediction field.",
        "affiliation_name": "Nanfang College of Sun Yet-sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Mapping Neurophysiological Subtypes of Major Depressive Disorder Using Normative Models of the Functional Connectome",
        "paper_author": "Sun X.",
        "publication": "Biological Psychiatry",
        "citied_by": "18",
        "cover_date": "2023-12-15",
        "Abstract": "Background: Major depressive disorder (MDD) is a highly heterogeneous disorder that typically emerges in adolescence and can occur throughout adulthood. Studies aimed at quantitatively uncovering the heterogeneity of individual functional connectome abnormalities in MDD and identifying reproducibly distinct neurophysiological MDD subtypes across the lifespan, which could provide promising insights for precise diagnosis and treatment prediction, are still lacking. Methods: Leveraging resting-state functional magnetic resonance imaging data from 1148 patients with MDD and 1079 healthy control participants (ages 11–93), we conducted the largest multisite analysis to date for neurophysiological MDD subtyping. First, we characterized typical lifespan trajectories of functional connectivity strength based on the normative model and quantitatively mapped the heterogeneous individual deviations among patients with MDD. Then, we identified neurobiological MDD subtypes using an unsupervised clustering algorithm and evaluated intersite reproducibility. Finally, we validated the subtype differences in baseline clinical variables and longitudinal treatment predictive capacity. Results: Our findings indicated great intersubject heterogeneity in the spatial distribution and severity of functional connectome deviations among patients with MDD, which inspired the identification of 2 reproducible neurophysiological subtypes. Subtype 1 showed severe deviations, with positive deviations in the default mode, limbic, and subcortical areas and negative deviations in the sensorimotor and attention areas. Subtype 2 showed a moderate but converse deviation pattern. More importantly, subtype differences were observed in depressive item scores and the predictive ability of baseline deviations for antidepressant treatment outcomes. Conclusions: These findings shed light on our understanding of different neurobiological mechanisms underlying the clinical heterogeneity of MDD and are essential for developing personalized treatments for this disorder.",
        "affiliation_name": "National Yang Ming Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Optimized variable selection and machine learning models for olive oil quality assessment using portable near infrared spectroscopy",
        "paper_author": "Reda R.",
        "publication": "Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",
        "citied_by": "13",
        "cover_date": "2023-12-15",
        "Abstract": "Olive oil is a key component of the Mediterranean diet, rich in antioxidants and beneficial monounsaturated fatty acids. As a result, high-quality olive oil is in great demand, with its price varying depending on its quality. Traditional chemical tests for assessing olive oil quality are expensive and time-consuming. To address these limitations, this study explores the use of near infrared spectroscopy (NIRS) in predicting key quality parameters of olive oil, including acidity, K232, and K270. To this end, a set of 200 olive oil samples was collected from various agricultural regions of Morocco, covering all three quality categories (extra virgin, virgin, and ordinary virgin). The findings of this study have implications for reducing analysis time and costs associated with olive oil quality assessment. To predict olive oil quality parameters, chemical analysis was conducted in accordance with international standards, while the spectra were obtained using a portable NIR spectrometer. Partial least squares regression (PLSR) was employed along with various variable selection algorithms to establish the relationship between wavelengths and chemical data in order to accurately predict the quality parameters. Through this approach, the study aimed to enhance the efficiency and accuracy of olive oil quality assessment. The obtained results show that NIRS combined with machine learning accurately predicted the acidity using iPLS methods for variable selection, it generates a PLSR with coefficients of determination R2 = 0.94, root mean square error RMSE = 0.32 and ratios of standard error of performance to standard deviation RPD = 4.2 for the validation set. Also, the use of variable selection methods improves the quality of the prediction. For K232 and K270 the NIRS shows moderate prediction performance, it gave an R2 between 0.60 and 0.75. Generally, the results showed that it was possible to predict acidity K232, and K270 parameters with excellent to moderate accuracy for the two last parameters. Moreover, it was also possible to distinguish between different quality groups of olive oil using the principal component analysis PCA, and the use of variable selection helps to use the useful wavelength for the prediction olive oil using a portable NIR spectrometer.",
        "affiliation_name": "Université Sidi Mohamed Ben Abdellah",
        "affiliation_city": "Fez",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "MetaNO: How to transfer your knowledge on learning hidden physics",
        "paper_author": "Zhang L.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "2",
        "cover_date": "2023-12-15",
        "Abstract": "Gradient-based meta-learning methods have primarily been applied to classical machine learning tasks such as image classification. Recently, partial differential equation (PDE)-solving deep learning methods, such as neural operators, are starting to make an important impact on learning and predicting the response of a complex physical system directly from observational data. Taking the material modeling problems for example, the neural operator approach learns a surrogate mapping from the loading field to the corresponding material response field, which can be seen as learning the solution operator of a hidden PDE. The microstructure and mechanical parameters of each material specimen correspond to the (possibly heterogeneous) parameter field in this hidden PDE. Due to the limitation on experimental measurement techniques, the data acquisition for each material specimen is commonly challenging and may also be costly. This fact calls for the utilization and transfer of existing knowledge to new and unseen material specimens, which corresponds to sampling efficient learning of the solution operator of a hidden PDE with a different parameter field. Herein, we propose a novel meta-learning approach for neural operators that can be seen as transferring the knowledge of solution operators between governing (unknown) PDEs with varying parameter fields. Our approach is a provably universal solution operator for multiple PDE solving tasks, with a key theoretical observation that underlying parameter fields can be captured in the first layer of neural operator models, in contrast to typical final-layer transfer in existing meta-learning methods. As applications, we demonstrate the efficacy of our proposed approach on PDE-based datasets and a real-world material modeling problem, illustrating that our method can handle complex and nonlinear physical response learning tasks while greatly improving the sampling efficiency in unseen tasks.",
        "affiliation_name": "Gallogly College of Engineering",
        "affiliation_city": "Norman",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Client Selection in Federated Learning: Principles, Challenges, and Opportunities",
        "paper_author": "Fu L.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "77",
        "cover_date": "2023-12-15",
        "Abstract": "As a privacy-preserving paradigm for training machine learning (ML) models, federated learning (FL) has received tremendous attention from both industry and academia. In a typical FL scenario, clients exhibit significant heterogeneity in terms of data distribution and hardware configurations. Thus, randomly sampling clients in each training round may not fully exploit the local updates from heterogeneous clients, resulting in lower model accuracy, slower convergence rate, degraded fairness, etc. To tackle the FL client heterogeneity problem, various client selection algorithms have been developed, showing promising performance improvement. In this article, we systematically present recent advances in the emerging field of FL client selection and its challenges and research opportunities. We hope to facilitate practitioners in choosing the most suitable client selection mechanisms for their applications, as well as inspire researchers and newcomers to better understand this exciting research topic.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Columbus",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning-guided REIMS pattern recognition of non-dairy cream, milk fat cream and whipping cream for fraudulence identification",
        "paper_author": "Cui Y.",
        "publication": "Food Chemistry",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "The illegal adulteration of non-dairy cream in milk fat cream during the manufacturing process of baked goods has significantly hindered the robust growth of the dairy industry. In this study, a method based on rapid evaporative ionization mass spectrometry (REIMS) lipidomics pattern recognition integrated with machine learning algorithms was established. A total of 26 ions with importance were picked using multivariate statistical analysis as salient contributing features to distinguish between milk fat cream and non-dairy cream. Furthermore, employing discriminant analysis, decision trees, support vector machines, and neural network classifiers, machine learning models were utilized to classify non-dairy cream, milk fat cream, and minute quantities of non-dairy cream adulterated in milk fat cream. These approaches were enhanced through hyperparameter optimization and feature engineering, yielding accuracy rates at 98.4–99.6%. This artificial intelligent method of machine learning-guided REIMS pattern recognition can accurately identify adulteration of whipped cream and might help combat food fraud.",
        "affiliation_name": "Dalian Polytechnic University",
        "affiliation_city": "Dalian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Knowledge-embedded meta-learning model for lift coefficient prediction of airfoils",
        "paper_author": "Xie H.",
        "publication": "Expert Systems with Applications",
        "citied_by": "5",
        "cover_date": "2023-12-15",
        "Abstract": "The evaluation of aerodynamic performance is a crucial aspect of aircraft design optimization. However, traditional methods are time-consuming and expensive. While machine learning techniques can achieve high accuracy, their application in engineering is challenging due to their poor generalization and ”black box” nature. In this paper, a knowledge-embedded meta-learning model is proposed that integrates data with theoretical knowledge to predict lift coefficients for a supercritical airfoil at various angles of attack. The model employs a primary network to capture the relationship between lift and angle of attack, and a hyper network to encode geometry information and predict unknown parameters in the primary network. Three models are trained with different architectures to provide various interpretations. The model exhibits better generalization capabilities and competitive prediction accuracy compared to conventional neural networks. Additionally, interpretable analysis is performed using Integrated Gradients and Saliency methods, revealing that this model can assess the influence of airfoil geometry on physical characteristics. Furthermore, exceptional cases are investigated where the model's performance is reduced, analyzing the impact of knowledge limitations on a knowledge-embedded predictive model.",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The State of AI-Empowered Backscatter Communications: A Comprehensive Survey",
        "paper_author": "Xu F.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "22",
        "cover_date": "2023-12-15",
        "Abstract": "The Internet of Things (IoT) is undergoing significant advancements, driven by the emergence of backscatter communication (BC) and artificial intelligence (AI). BC is an energy-saving and cost-effective communication method where passive backscatter devices (BDs) communicate by modulating ambient radio-frequency (RF) carriers. AI has the potential to transform our way of communicating and interacting and represents a powerful tool for enabling the next generation of IoT devices and networks. By integrating AI with BC, we can create new opportunities for energy-efficient and low-cost communication and open the door to a range of innovative applications that were previously not possible. This article brings these two technologies together to investigate the current state of AI-powered BC. We begin with an introduction to BC and an overview of the AI algorithms employed in BC. Then, we delve into the recent advances in AI-based BC, covering key areas, such as backscatter signal detection, channel estimation, and jammer control to ensure security, mitigate interference, and improve throughput and latency. We also explore the exciting frontiers of AI in BC using B5G/6G technologies, including backscatter-assisted relay and cognitive communication networks, backscatter-assisted MEC networks, and BC with reconfigurable intelligent surfaces (RISs), UAV, and vehicular networks. Finally, in the discussion section, we summarize the solutions, provide lessons learned and challenges, and present new research opportunities in AI-powered BC. This survey provides a comprehensive overview of the potential of AI-powered BC and its insightful impact on the future of IoT.",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning filters out efficient electrocatalysts in the massive ternary alloy space for fuel cells",
        "paper_author": "Park Y.",
        "publication": "Applied Catalysis B: Environmental",
        "citied_by": "9",
        "cover_date": "2023-12-15",
        "Abstract": "Despite their potential promise, multicomponent materials have not been actively considered as catalyst materials to date, mainly due to the massive compositional space. Here, targeting ternary electrocatalysts for fuel cells, we present a machine learning (ML)-driven catalyst screening protocol with the criteria of structural stability, catalytic performance, and cost-effectiveness. This process filters out only 10 and 37 candidates out of over three thousand test materials in the alloy core@shell (X3Y@Z) for each cathode and anode of fuel cells. These candidates are potentially synthesizable, lower-cost and higher-performance than conventional Pt. A thin film of Cu3Au@Pt, one of the final candidates for oxygen reduction reactions, was experimentally fabricated, which indeed outperformed a Pt film as confirmed by the approximately 2-fold increase in kinetic current density with the 2.7-fold reduction in the Pt usage. This demonstration supports that our ML-driven design strategy would be useful for exploring general multicomponent systems and catalysis problems.",
        "affiliation_name": "Korea Institute of Energy Research",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Incipient fault detection of planetary gearbox under steady and varying condition",
        "paper_author": "Liu J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "13",
        "cover_date": "2023-12-15",
        "Abstract": "As an important component in rotating machines, gearbox failure will lead to costly economic losses. Generally, incipient fault features of gearbox are weak and concealed in a set of time-varying vibration signals that are challenging to identify effectively. Based on that, a new method is proposed for incipient fault detection(FD) under steady and variable conditions of gearboxes based on improved octave convolution in this paper. First, the vibration signals are transferred into images via the symmetrized dot pattern(SDP) method. Then, the proposed method enhances image detail learning by adding convolution kernels and introducing residual connections in the high-frequency component of the octave convolution. Meanwhile, self-attention units are introduced in the information interaction branches. After that, the improved octave convolution is applied to the ResNet50 backbone network(IOC-ResNet50) to mine deep fault features. Compared with other published methods, the results indicate that the proposed performs superiorly in both time-varying conditions and steady state.",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "High-precision prediction of blood glucose concentration utilizing Fourier transform Raman spectroscopy and an ensemble machine learning algorithm",
        "paper_author": "Song S.",
        "publication": "Spectrochimica Acta - Part A: Molecular and Biomolecular Spectroscopy",
        "citied_by": "11",
        "cover_date": "2023-12-15",
        "Abstract": "Raman spectroscopy has gained popularity in analyzing blood glucose levels due to its non-invasive identification and minimal interference from water. However, the challenge lies in how to accurately predict blood glucose concentrations in human blood using Raman spectroscopy. This paper researches a novel integrated machine learning algorithm called Bagging-ABC-ELM. The optimal input weights and biases of extreme learning machine (ELM) model are obtained by artificial bee colony (ABC) algorithm. The bagging algorithm is used to obtain a better the stability of the model and higher performance than ELM algorithm. The results show that the mean value of coefficient of determination is 0.9928, and root mean square error is 0.1928. Compared to other regression models, the Bagging-ABC-ELM model exhibited superior prediction accuracy, robustness, and generalization capability. The Bagging-ABC-ELM model presents a promising alternative for analyzing blood glucose levels in clinical and research settings.",
        "affiliation_name": "College of Information Science and Engineering, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An explainable machine learning approach for student dropout prediction",
        "paper_author": "Krüger J.G.C.",
        "publication": "Expert Systems with Applications",
        "citied_by": "24",
        "cover_date": "2023-12-15",
        "Abstract": "School dropout is a relevant socio-economic problem across the globe. Predictive models have been developed to determine the likelihood of students dropping out of their studies precociously to overcome such a problem. Academic systems, which gather data from many students, are potential sources for datasets that feed dropout prediction algorithms, thus leading to general improvements in education quality. Despite successful past attempts to predict dropout, several works depict small datasets with features that are hard to reproduce. Furthermore, predicting whether a student will drop out is not enough to diagnose and prevent the problem as it is also necessary to provide potential justifications for the dropout. This paper proposes an approach for creating and enriching a dataset for dropout prediction, which has been applied for dropout prediction using data from 19 schools in Brazil. With this dataset and using classifiers and model explaining techniques, our experiments achieved Area Under the Precision–Recall Curve (AUC-PR) scores of up to 89.5%, Precision up to 95%, Recall up to 93%, and Kolmogorov–Smirnov (KS) rates up to 97% when predicting dropout at different year moments. This study also shows differences when predicting dropouts in different educational stages, such as preschool and secondary education, with the former being more complex than the latter. In addition to the high recognition rates, our proposal identifies potential reasons for student dropout, which are relevant for educational institutions to take preemptive actions.",
        "affiliation_name": "Pontifícia Universidade Católica do Paraná",
        "affiliation_city": "Curitiba",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Great Wall Construction Algorithm: A novel meta-heuristic algorithm for engineer problems",
        "paper_author": "Guan Z.",
        "publication": "Expert Systems with Applications",
        "citied_by": "44",
        "cover_date": "2023-12-15",
        "Abstract": "In recent years, the optimization community has witnessed a surge in the popularity of population-based optimization methods. However, many of these methods suffer from various shortcomings, including unclear performance characteristics, incomplete validation, excessive reliance on metaphors, inadequate exploration and exploitation components, and compromised trade-offs between exploration and exploitation in real-world scenarios. As a result, users often find themselves needing to extensively modify and fine-tune these methods to achieve faster convergence, stable balance, and high-quality results. To shift the optimization community's focus towards performance rather than metaphorical changes, we propose a general population-based optimization technique called the Great Wall Construction Algorithm (GWCA). This study presents GWCA as a simple yet robust method with competitive performance for efficiently solving constrained and unconstrained problems. GWCA draws inspiration from the competition and elimination mechanisms observed among workers during the construction of the ancient Great Wall. It introduces a mathematical model of the labor movement to simulate the algorithm's dynamics. Unlike other methods that employ multiple models to generate new solutions, GWCA randomly assigns a single predefined motion model to each worker in every iteration. This unique approach showcases GWCA's dynamic nature, simple structure, high convergence performance, and ability to deliver satisfactory solution quality, thus outperforming existing optimization methods in terms of efficiency. To validate GWCA, we conduct extensive comparisons with popular and advanced algorithms on the IEEE CEC 2017 benchmark suite across different dimensions (D = 10, 30, 50, 100). Additionally, GWCA is applied to solve 16 constrained engineering problems and 6 NP-Hard problems, demonstrating its applicability in handling constrained and complex nonlinear problems. Finally, we compare GWCA's optimized solutions with those obtained from 33 advanced meta-heuristic algorithms, including the winner of CEC 2017. The results confirm the effectiveness of the proposed optimizer in solving a wide range of single-objective problems, surpassing popular base optimizers, advanced variants of existing methods, and several CEC winners. We present GWCA as an open-source population-based method that can serve as a standard optimization tool across various domains of artificial intelligence and machine learning. It exhibits a range of exploratory and exploitative features, offering high performance and optimization capabilities. The method is highly flexible, scalable, and can be further extended in terms of structure and application to accommodate diverse forms of optimization scenarios. https://github.com/guangian/Great-Wall-Construction-Algorithm-a-novel-meta-heuristic-algorithm-for-global-optimization.",
        "affiliation_name": "Nanchang Institute of Technology",
        "affiliation_city": "Nanchang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Non-destructive quality classification of rice taste properties based on near-infrared spectroscopy and machine learning algorithms",
        "paper_author": "Díaz E.O.",
        "publication": "Food Chemistry",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "The taste quality of rice is determined by protein and amylose percentages, with low levels indicating high-quality taste in Japan. However, accurate non-destructive screening remains a challenge for the industry. We explored the use of machine learning models and near-infrared spectra to classify rice taste quality. Three models were optimized using 796 brown rice samples from Hokkaido, Japan, produced between 2008 and 2016, and tested on 278 distinct samples from the same region produced between 2017 and 2019. Logistic regression and support vector machine models outperformed the partial least-squares discriminant analysis model, achieving high accuracy (94%), f1-score (90%), average precision (0.94), and low classification error (4%) and allowing accurate non-destructive classification of rice quality. These results not only improve rice quality, post-harvest technology, and producer output in Japan but also could enhance quality control processes and foster the production of high-quality products for other agricultural goods and food commodities worldwide.",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Dual-channel MIRECL portable devices with impedance effect coupled smartphone and machine learning system for tyramine identification and quantification",
        "paper_author": "Lu Z.",
        "publication": "Food Chemistry",
        "citied_by": "16",
        "cover_date": "2023-12-15",
        "Abstract": "We designed a novel, portable, and visual dual-potential molecularly imprinted ratiometric electrochemiluminescence (MIRECL) sensor for tyramine (TYM) detection based on smartphone and deep learning-assisted optical devices. Molecularly imprinted polymer-Ce2Sn2O7 (MIP-Ce2Sn2O7) layers were fabricated by in-situ electropolymerization method as the capture and signal amplification probe. Oxygen vacancies in Ce2Sn2O7 not only enhance the electrochemical redox capability but also accelerate the energy transfer, thereby enhancing the luminescence of cathode ECL. Under optimal conditions, the ECL signals of MIP-Ce2Sn2O7 at the cathode and the anode response of Ru(bpy)32+ was reduced, thus a wide linear range from 0.01 μM to 1000 μM with the detection limit as low as 0.005 μM. Interestingly, combined with an artificial intelligence image recognition algorithm and the principle of optical signal reading by smartphone, the developed MIRECL sensor has been applied to the portable and visual determination of TYM in aquatic samples, and its practicability has been satisfactorily verified.",
        "affiliation_name": "Sichuan Agricultural University",
        "affiliation_city": "Ya'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Anomaly detection in streaming data: A comparison and evaluation study",
        "paper_author": "Iglesias Vázquez F.",
        "publication": "Expert Systems with Applications",
        "citied_by": "8",
        "cover_date": "2023-12-15",
        "Abstract": "The detection of anomalies in streaming data faces complexities that make traditional static methods unsuitable due to computational costs and nonstationarity. We test and evaluate eight state of the art algorithms against prominent challenges related to streaming data. Results show insights regarding accuracy, memory-dependency, parameterization, and pre-knowledge exploitation, thus revealing the high impact of some data characteristics to establish a most appropriate algorithm, namely: locality (i.e., whether outlierness is relative to local contexts), relativeness (i.e., if past data defines outlierness), and concept drift (if it is expected, its intensity and frequency). In most applied cases, such factors can be inferred in advance through the use of historical data and domain knowledge. Assuming the viability of the studied methods in terms of time efficiency, this work discloses key findings to achieve optimal designs of streaming data anomaly detection in real-life applications.",
        "affiliation_name": "Syddansk Universitet",
        "affiliation_city": "Odense",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Doubts on the reliability of parallel corpus filtering",
        "paper_author": "Moon H.",
        "publication": "Expert Systems with Applications",
        "citied_by": "0",
        "cover_date": "2023-12-15",
        "Abstract": "Parallel corpus filtering (PCF) aims to filter out low-quality data residing in parallel corpora. Recently, deep learning-based methods have been employed to assess the quality of sentence pairs in a parallel corpus, along with rule-based filtering that filters out noisy data depending on the pre-defined error types. Despite their utilization, to the best of our knowledge, a comprehensive investigation into the practical applicability and interpretability of PCF techniques remains unexplored. In this study, we raise two doubts on deep learning-based PCF: (i) Can deep learning-based PCF extract high-quality data? and (ii) Are scoring functions of PCF reliable? To answer these questions, we conduct comparative experiments on various PCF techniques with four datasets on two language pairs, English–Korean, and English–Japanese. Through the experiments, we demonstrate that the performance of the deep learning-based PCF highly depends on the targeting parallel corpus, and shows fluctuating adaptability depending on their characteristics. In particular, we figure out that high-scored sentences derived by the PCF technique do not necessarily guarantee high-quality results, rather it shows unintended preference.",
        "affiliation_name": "NAVER Corporation",
        "affiliation_city": "Seongnam",
        "affiliation_country": "South Korea"
    }
]