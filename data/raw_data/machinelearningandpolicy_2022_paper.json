[
    {
        "paper_title": "Sector-Based Stock Price Prediction with Machine Learning Models",
        "paper_author": "Kocaoğlu D.",
        "publication": "Sakarya University Journal of Computer and Information Sciences",
        "citied_by": "0",
        "cover_date": "2022-12-31",
        "Abstract": "Stock price prediction is an important topic for investors and companies. The increasing effect of machine learning methods in every field also applies to stock forecasting. In this study, it is aimed to predict the future prices of the stocks of companies in different sectors traded on the Borsa Istanbul (BIST) 30 Index. For the study, the data of two companies selected as examples from each of the holding, white goods, petrochemical, iron and steel, transportation and communication sectors were analyzed. In the study, in addition to the share analysis of the sectors, the price prediction performances of the machine learning algorithm on a sectoral basis were examined. For these tests, XGBoost, Support Vector Machines (SVM), K-nearest neighbors (KNN) and Random Forest (RF) algorithms were used. The obtained results were analyzed with mean absolute error (MAE), mean absolute percent error (MAPE), mean squared error (MSE), and R2 correlation metrics. The best estimations on a sectoral basis were made for companies in the Iron and Steel and Petroleum field. One of the most important innovations in the study is the examination of the effect of current macro changes on the forecasting model. As an example, the effect of the changes in the Central Bank Governors, which took place three times in the 5-year period, on the forecast was investigated. The results showed that the unpredictable effects on the policies after the change of Governors also negatively affected the forecast performance.",
        "DOI": "10.35377/saucis...1200151",
        "affiliation_name": "Kocaeli Üniversitesi",
        "affiliation_city": "İzmit",
        "affiliation_country": "Turkey",
        "affiliation_id": "60028583",
        "affiliation_state": "Kocaeli"
    },
    {
        "paper_title": "Intelligent Transportation Systems Architecture: Recommendation for K-AUS",
        "paper_author": "Çapalı B.",
        "publication": "El-Cezeri Journal of Science and Engineering",
        "citied_by": "2",
        "cover_date": "2022-12-31",
        "Abstract": "The latest advances in technology and the improvement of decision processes with learning methods based on artificial intelligence have put the word \"intelligent\" ahead of all systems that make human life easier. Based on intelligent transportation systems, it is aimed to reduce the damage to the country’s economy and the environment while providing technology-based and faster, safer, more accessible, more sustainable and more efficient transportation. The main goal of creating the intelligent transportation systems architecture is to design and implement human-focused, sustainable transportation systems together with cutting-edge technologies such as industry 4.0 technologies, mobile applications, augmented reality, and the internet of things. Intelligent transportation systems architecture needs to be updated according to C-ITS systems that provide interoperability and data integrity. Therefore, the main factor in creating the architecture of intelligent transport systems is to create system architecture by making complex systems with data integrity and numerous insignificant idle data into systems that communicate with each other and reach the level of interoperability. In this study, intelligent transportation systems policies in the world have been analyzed and systems that have reached the level of interoperability that will provide the basis of C-ITS and intelligent transportation system architecture have been proposed.",
        "DOI": "10.31202/ecjse.1132804",
        "affiliation_name": "Süleyman Demirel Üniversitesi",
        "affiliation_city": "Isparta",
        "affiliation_country": "Turkey",
        "affiliation_id": "60000231",
        "affiliation_state": "Isparta"
    },
    {
        "paper_title": "Climatic water balance forecasting with machine learning and deep learning models over Bangladesh",
        "paper_author": "Jalal Uddin M.",
        "publication": "International Journal of Climatology",
        "citied_by": "6",
        "cover_date": "2022-12-30",
        "Abstract": "Understanding the impact of input variables on black-box machine learning and deep learning models is necessary. Therefore, this study proposed SHapley Additive exPlanations (SHAP) values to address the problem of the interpretability of the output of the support vector machine (SVM), random forest (RF), convolutional neural network (CNN), and long short-term memory (LSTM) models to forecast climatic water balance (CWB) within 1–3 months lead-time. The current study uses two Koppen–Geiger climate zones over Bangladesh: the humid subtropical climate with dry winter and hot summer (Cwa) and the tropical climate (Af-Am). Monthly antecedent CWB, potential evapotranspiration (PET), convective available potential energy (CAPE), relative humidity (RH), air temperature (TEM), El Niño–Southern Oscillation (ENSO), Indian Ocean Dipole (IOD), and North Atlantic oscillation (NAO) are used as the inputs to the proposed model. SHAP values show that CWB (current month) for both climate zones has the maximum impact on the prediction. The effects of atmospheric variables and ocean–atmospheric teleconnections on CWB forecasts over Bangladesh are low. Forecasting results show that the SVM model shows the best performance for CWB forecasts in the Cwa and Af-Am climate zones in terms of antecedent CWB as input. And this model effectively decreases the negative effect of increasing forecast lead-time. Since the proposed model can predict CWB in 3-months lead-time, it would help policy-makers and practitioners to reduce the drought and flood impacts in the future by adopting better preparedness plans.",
        "DOI": "10.1002/joc.7885",
        "affiliation_name": "Southern Marine Science and Engineering Guangdong Laboratory",
        "affiliation_city": "Zhuhai",
        "affiliation_country": "China",
        "affiliation_id": "60272416",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "A new comprehensive monitoring and diagnostic approach for early detection of mechanical degradation in helicopter transmission systems",
        "paper_author": "Leoni J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "10",
        "cover_date": "2022-12-30",
        "Abstract": "Helicopters vulnerabilities specifically lie in single-load-path critical parts that transmit the engine's power to the rotors. A fault in even one single trans- mission's gear component may compromise the whole helicopter, yielding high maintenance costs and safety hazards. In this work, we present an effective di- agnosis and monitoring system for the early detection of the mechanical degra- dation in such components, also capable of providing insights on the damage's causes. The classification task is performed by an ensemble of two learners: a convolutional autoencoder and a distance&density-based unsupervised classifier that use as regressors specific Health Indexes (HIs) and flight parameters. The proposed approach employs the autoencoder reconstruction error information to infer the most probable cause of each detected fault, and enacts post-processing filtering policies that effectively reduce the number of false alarms. Extensive experimental validation witnesses the good performances and the robustness of the proposed approach.",
        "DOI": "10.1016/j.eswa.2022.118412",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy",
        "affiliation_id": "60023256",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Importance-Aware Data Pre-Processing and Device Scheduling for Multi-Channel Edge Learning",
        "paper_author": "Huang X.",
        "publication": "Journal of Communications and Information Networks",
        "citied_by": "1",
        "cover_date": "2022-12-25",
        "Abstract": "The large-scale deployment of intelligent Internet of things (IoT) devices have brought increasing needs for computation support in wireless access networks. Applying machine learning (ML) algorithms at the network edge, i.e., edge learning, requires efficient training, in order to adapt themselves to the varying environment. However, the transmission of the training data collected by devices requires huge wireless resources. To address this issue, we exploit the fact that data samples have different importance for training, and use an influence function to represent the importance. Based on the importance metric, we propose a data pre-processing scheme combining data filtering that reduces the size of dataset and data compression that removes redundant information. As a result, the number of data samples as well as the size of every data sample to be transmitted can be substantially reduced while keeping the training accuracy. Furthermore, we propose device scheduling policies, including rate-based and Monte-Carlo-based policies, for multi-device multi-channel systems, maximizing the summation of data importance of scheduled devices. Experiments show that the proposed device scheduling policies bring more than 2% improvement in training accuracy.",
        "DOI": "10.23919/JCIN.2022.10005217",
        "affiliation_name": "Beijing National Research Center for Information Science and Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60104026",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Exploring the multidimensional factors and emergence mechanisms of industrial symbiotic relationships based on machine learning",
        "paper_author": "Wang S.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "5",
        "cover_date": "2022-12-25",
        "Abstract": "Industrial symbiosis is widely sought for industrial sustainability in recent years. While multiple factors are identified important for industrial symbiosis occurrence, the complex interactions among these factors and the emergence mechanisms of industrial symbiotic relationships (SR) remain not well explored in the literature, especially not with empirical data. In this study, we aim to address this knowledge gap based on machine learning and first-hand data collected from a survey of 201 enterprises in Chun'an County, Zhejiang Province, China. The mechanisms behind these symbiotic relationships were explored by simulating the interactions and nonlinear effects of 37 selected factors categorized into sociopolitical, economic, and technological dimensions. We found that the sociopolitical dimension factors (particularly the enterprises' demand for cleaner production and the indirect influence from similar environmental protection behaviors of other enterprises) play the most important role behind industrial SR establishment. Imperfect regulations or lack of legal basis, the scale of economy for SR participation, and the varying quality of reused raw materials or products are identified as key obstacles. Our multidimensional analysis revealed non-linear effects suggests that such a system understanding on influencing factors and the emergence mechanism of industrial SR is necessary and important to formulate relevant policy for boosting industrial symbiosis and thus industrial sustainability.",
        "DOI": "10.1016/j.jclepro.2022.135169",
        "affiliation_name": "Syddansk Universitet",
        "affiliation_city": "Odense",
        "affiliation_country": "Denmark",
        "affiliation_id": "60019160",
        "affiliation_state": "Syddanmark"
    },
    {
        "paper_title": "Climate change adaptation of smallholders on the Tibetan plateau under government interventions",
        "paper_author": "He X.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "13",
        "cover_date": "2022-12-25",
        "Abstract": "The increasing severity of climate change has posed a great challenge to smallholders' livelihoods. In addition to smallholders' autonomous adaptations, policy-makers need to consider how to make sound government interventions to help smallholders effectively adapt to climate change. This study aims to explore how smallholders adapt to climate change under government interventions, and in turn provide recommendations for the government to better promote smallholder adaptation. To achieve this purpose, 1552 household survey data were collected in four agro-pastoral regions of the Tibetan Plateau (TP). A machine learning approach (boosted regression tree, BRT) was used to explore the factors influencing the adaption strategies of smallholders to climate change, especially the role of government interventions in this process. The results show that the smallholders mainly adopted four adaptation strategies (off-home activities, nature reclaiming farmland, raising more livestock, and crop management), while local governments helped them by providing subsidies, training, credit, insurance, and improved varieties; building roads and irrigation facilities; and organizing cooperatives. The results of the BRT model show that the natural capital indicators (elevation, farmland area) were still important factors influencing the smallholders' adoption of adaptation strategies, because natural capital reflects the livelihood basis of smallholders to some extent. The results also suggest that government interventions such as subsidies, cooperatives, and training played an important role in this process. Based on these results, we propose targeted policy recommendations to help local governments improve existing government interventions and to provide lessons for governments in other regions or countries to plan government interventions to promote smallholder adaptation.",
        "DOI": "10.1016/j.jclepro.2022.135171",
        "affiliation_name": "Southwest University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China",
        "affiliation_id": "60122052",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Analysis of the Relationship between Social Protection Program Status and the Incidence of Food Insecure Households in Aceh Province",
        "paper_author": "Ramadhani E.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2022-12-22",
        "Abstract": "One of the government's targets in achieving social development is to reduce food insecurity. Limited economic access for households to obtain sufficient food can cause food insecurity. The social protection program is a policy that plays an important role in efforts to fulfil economic access for households to reduce the incidence of food insecurity. A study about the contribution of social protection programs to food insecurity events needs to be carried out. One of the machine learning methods, namely classification tree can be applied to achieve this goal. The data used in this study is from the 2020 Indonesian Social Economic Survey (SUSENAS) in Aceh Province which consists of food insecurity status as an output variable and 7 input variables; PKH, KKS, BPNT, Local Government Assistance, BPJS, Jamkesda, and PIP. The results obtained are that BPJS provides the largest contribution in determining the status of food insecurity with an AUC value of 0.60.",
        "DOI": "10.1063/5.0112345",
        "affiliation_name": "Universitas Jember",
        "affiliation_city": "Jember",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069412",
        "affiliation_state": "East Java"
    },
    {
        "paper_title": "Automated circuit sizing with multi-objective optimization based on differential evolution and Bayesian inference",
        "paper_author": "Vişan C.",
        "publication": "Knowledge-Based Systems",
        "citied_by": "21",
        "cover_date": "2022-12-22",
        "Abstract": "Manual sizing of analog circuit specifications has become challenging owing to their ever-increasing complexity. Especially for innovative, large-scale circuit designs with numerous design variables, operating conditions, and conflicting objectives to optimize, analog designers must run time-consuming simulations for several weeks to find the optimum configuration. Recently, machine learning and optimization techniques have been applied in the field of analog circuit design, wherein evolutionary algorithms and Bayesian models have shown good results for circuit sizing tasks. In this context, we introduce multi-objective optimization based on differential evolution and Bayesian inference (MODEBI)—a design optimization method based on generalized differential evolution 3 (GDE3) and Gaussian processes (GPs). The proposed method can perform sizing for complex circuits that require optimization of many design variables and conflicting objectives. Although state-of-the-art methods reduce multi-objective problems to single-objective optimization and potentially induce a priori bias, the proposed method searches directly over the multi-objective space using Pareto dominance and ensures that designers are provided with diverse solutions to choose from. To reduce optimization time, we propose using GPs to model the circuit and employing this surrogate model to preselect candidates. However, this results in a more complex offspring selection process, and the diversity in population survival must be specifically addressed. This paper proposes several solutions to these problems, resulting in multiple MODEBI variations. To the best of our knowledge, this is the first method that specifically addresses solution diversity and simultaneously focuses on minimizing the number of simulations required to obtain feasible configurations. The evaluation performed on two voltage regulators with different complexity levels showed that the proposed offspring selection method and survival policy can obtain highly diverse feasible solutions considerably faster than GDE3 or Bayesian optimization-based algorithms.",
        "DOI": "10.1016/j.knosys.2022.109987",
        "affiliation_name": "Infineon Technologies AG",
        "affiliation_city": "Neubiberg",
        "affiliation_country": "Germany",
        "affiliation_id": "60030823",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Exploring Vegetative Indices for Yield Prediction using Sentinel 2 Data – A Study in a Select Region of Karnataka",
        "paper_author": "Geetha M.",
        "publication": "International Journal of Intelligent Systems and Applications in Engineering",
        "citied_by": "2",
        "cover_date": "2022-12-20",
        "Abstract": "India is an agrarian economy and largest share of population depend on agriculture. Though there are mechanisms to approximately estimate crop yield by means of controlled experiments or past data, the reliability is limited. As a matter of fact, the crop yield is based on estimates that may suffer from multiple bias. In recent years, remote sensing images augmented with machine learning and deep learning techniques help us get the efficient crop yield statistics based on the crop on the field which help policymakers in devising better policies and governance. Remote sensing images of crops under study when subjected to machine learning techniques, one can classify the images into homogenous crop classes and record crop health / growth indicators such as Normalized Difference Vegetation Index (NDVI), Normalized Difference Water Index (NDWI) and Soil Adjusted Vegetative Index (SAVI) based on the training dataset and image quality, which further leads to crop yield estimates with desired level of accuracy. The present study investigates the relationship between yield influencing parameters such as physical variables, soil, weather characteristics and vegetation indices. Using correlation and multiple regression analysis, most efficient parameters that best estimate the crop yield is determined using the satellite data obtained for a study region in central part of the state of Karnataka. It was found that one of the vegetation indices, Soil Adjusted Vegetative Index values can predict near to accurate crop yield values by the end of 81 days after transplantation of paddy where as NDVI and NDVI can give yield estimated only after 116 days of transplantation. Thus crop yield estimates using SAVI works better in terms of predicting paddy yield at least one month before (after 81 days of transplantation) actual harvesting i.e., after 120 days as practiced by farmers in the study area.",
        "DOI": "NA",
        "affiliation_name": "Dayananda Sagar College of Engineering",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India",
        "affiliation_id": "60114492",
        "affiliation_state": "KA"
    },
    {
        "paper_title": "Teaching artificial intelligence as a fundamental toolset of medicine",
        "paper_author": "Ötleş E.",
        "publication": "Cell Reports Medicine",
        "citied_by": "14",
        "cover_date": "2022-12-20",
        "Abstract": "Artificial intelligence (AI) is transforming the practice of medicine. Systems assessing chest radiographs, pathology slides, and early warning systems embedded in electronic health records (EHRs) are becoming ubiquitous in medical practice. Despite this, medical students have minimal exposure to the concepts necessary to utilize and evaluate AI systems, leaving them under prepared for future clinical practice. We must work quickly to bolster undergraduate medical education around AI to remedy this. In this commentary, we propose that medical educators treat AI as a critical component of medical practice that is introduced early and integrated with the other core components of medical school curricula. Equipping graduating medical students with this knowledge will ensure they have the skills to solve challenges arising at the confluence of AI and medicine.",
        "DOI": "10.1016/j.xcrm.2022.100824",
        "affiliation_name": "University of Michigan Medical School",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States",
        "affiliation_id": "60033182",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Global and regional models for identification of cooling technology in thermal power generation for water demand estimations in water-energy nexus studies",
        "paper_author": "Lohrmann A.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "9",
        "cover_date": "2022-12-20",
        "Abstract": "Water-energy nexus studies aim to connect the process of power generation with the corresponding water demand. The lack of information on the currently installed cooling systems at individual power plants is a challenge for the assessment of the water use on the power plant-level, which complicates decision-making in water management, especially in water-stressed regions. In this study, we investigate the spatial and temporal trends in cooling technology installations globally. Based on that, we propose a machine learning model for cooling technology identification on a regional and global level, which uses a combination of feature selection and classification algorithms. The global model demonstrates an average test set accuracy of 85.42%, which corresponds to only a minor underestimation of the actual global water footprint of 1.78% when the cooling technology and water footprint of individual power plant units is unknown. Apart from that, a special emphasis was placed on regions characterized by high and extremely high water stress, where mistakes in water policy planning and water management may lead to an unsustainable water use or even to an overexploitation of water resources. In these regions, the calculated test set accuracy was 80.83%, which is significantly larger than the average accuracy of a majority class model. The results and the method proposed in this study enable cooling system identification in individual power units using information available from other sources, such as the water stress score or seasonal freshwater availability in the region.",
        "DOI": "10.1016/j.jclepro.2022.134842",
        "affiliation_name": "LUT kauppakorkeakoulu",
        "affiliation_city": "Lappeenranta",
        "affiliation_country": "Finland",
        "affiliation_id": "60226620",
        "affiliation_state": "South Karelia"
    },
    {
        "paper_title": "Routing network traffic predict based on firewall logs using Machine Learning",
        "paper_author": "Li Y.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2022-12-16",
        "Abstract": "This paper employs firewall system log data to address the internet traffic issue caused by misconfigured firewall policies. The UCI machine learning library provided the data set. Data sets are processed using feature engineering to produce classifiable results. Machine learning techniques are used to predict permissible base traffic for specific network traffic based on log data. The machine learning model should be able to predict actions that should be taken quickly in order to avoid unnecessary network latency, which can be detrimental to network performance. The test time must be short, regardless of the complexity of the training. This article tested several machine learning approaches and discovered that LBGM is the most effective.",
        "DOI": "10.1145/3584376.3584525",
        "affiliation_name": "Xinjiang University",
        "affiliation_city": "Urumqi",
        "affiliation_country": "China",
        "affiliation_id": "60015780",
        "affiliation_state": "Xinjiang"
    },
    {
        "paper_title": "Semi-supervised learning based framework for urban level building electricity consumption prediction",
        "paper_author": "Jin X.",
        "publication": "Applied Energy",
        "citied_by": "13",
        "cover_date": "2022-12-15",
        "Abstract": "The spatial feature of building energy consumption in a city is essential for urban level energy planning and policy making. With the increasing availability of urban level building energy benchmarking datasets, machine learning has shown a powerful capability of making data-driven predictions on urban level building energy consumption. However, the building energy benchmarking datasets usually only cover large buildings, which are not sufficient representations of all buildings in a city. Besides building energy benchmarking datasets, many other urban level open datasets are also valuable to building energy prediction, but they do not contain building energy use data, in other words, they are unlabeled. This study proposes a novel framework based on semi-supervised learning to make effective use of the unlabeled datasets to develop more generic urban level data-driven building energy prediction models, and energy mapping with higher space resolution. The framework consists of preliminary labeling, selection of pseudo labeled samples and predictive modelling. Several machine learning algorithms are proposed and compared for generating pseudo labels of building electricity consumption for unlabeled datasets of small and medium-sized buildings. A selection process consisting of convergence testing and screening is designed to select pseudo labeled samples with high credibility to enlarge the labeled dataset. A novel two-level performance evaluation method is proposed to evaluate the performance of the framework at both urban level and district level to enhance the spatial resolution of the predictions. The framework is implemented to model and map the individual electricity consumptions of all buildings in two years in the districts of New York City using multiple open datasets. The results show significant improvement in terms of prediction accuracy at both levels. In addition, the applicability of the model to various buildings in the city is remarkably enhanced.",
        "DOI": "10.1016/j.apenergy.2022.120210",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008928",
        "affiliation_state": "Hong Kong"
    },
    {
        "paper_title": "Deep reinforcement learning-based strategy for charging station participating in demand response",
        "paper_author": "Jin R.",
        "publication": "Applied Energy",
        "citied_by": "22",
        "cover_date": "2022-12-15",
        "Abstract": "The trend of zero-carbonization has accelerated the prevalence of electric vehicles (EVs) owing to their advantages of low carbon emissions and high energy efficiency. The stochastic and high charging load of EVs results in a non-negligible challenge that may cause grid overload. A promising approach is the participation of charging stations in demand response as load aggregators by coordinating the charging power of electric vehicles. However, improper coordination of charging load may lead to unfulfilled charging demand, which would cause dissatisfaction on the demand side. In this study, the incentive-based and time-varying demand response mechanism is considered when charging stations coordinate charging of multiple EVs. A decentralized decision-making framework is innovatively applied to provide charging power of each EV. The charging process is modeled as a Markov decision process, and a virtual price is designed to help decide the charging power. Deep reinforcement learning algorithms such as deep deterministic policy gradient are applied to determine the charging strategy of multiple and heterogeneous EVs. Numerical experiments are performed to validate the effectiveness of the proposed method. A comparison with an optimal charging strategy and a heuristic rule-based method shows that the proposed method can trade off the revenue from demand response and user satisfaction, as well as reduce the peak load of the charging station. Furthermore, a test with inaccurate departure information indicates the robustness of the proposed method.",
        "DOI": "10.1016/j.apenergy.2022.120140",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A machine learning approach to investigate the build-up of surface ozone in Mexico-City",
        "paper_author": "Ahmad M.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "12",
        "cover_date": "2022-12-15",
        "Abstract": "Ground-level ozone is an important pollutant regarding air quality and climate. Mexico City frequently experiences severe ozone episodes due to a combination of strong ozone precursor emissions and its specific topographical environment which critically impacts meteorological conditions. High ozone levels during these episodes cause harmful effects to the public health and the environment. This necessitates ranking air quality and meteorological variables according to their contributions towards the build-up of ozone. In this study, three machine learning models are used to learn a prediction function with hourly data of eight predictors as input and hourly ground-level ozone mixing ratios as output. One-year hourly data of eight predictors collected in Mexico-City from March 2015 to February 2016 is employed to train and test the models. The best model, capturing ozone peak levels with 92% accuracy during 6–18 March 2016, is used to rank the predictors according to their importance in the build-up of ozone applying a shapley additive explanations approach based on the game theory shapley values. This 6–18 March 2016 period encompassed different meteorological and emission conditions and included a severe ozone smog episode from 12 to 17 March 2016. Such ranking of the air quality and meteorological variables is crucial for policy-making decisions regarding the prevention and mitigation of ozone detrimental effects during severe ozone episodes and provides insight into the functional dependency of ozone on its predictors. The proposed approach showcases Mexico City, but its principles can be applied for ozone episodes at any other location.",
        "DOI": "10.1016/j.jclepro.2022.134638",
        "affiliation_name": "The FM Global Group",
        "affiliation_city": "Johnstown",
        "affiliation_country": "United States",
        "affiliation_id": "60281252",
        "affiliation_state": "RI"
    },
    {
        "paper_title": "An interpretable forecasting framework for energy consumption and CO<inf>2</inf> emissions",
        "paper_author": "Aras S.",
        "publication": "Applied Energy",
        "citied_by": "34",
        "cover_date": "2022-12-15",
        "Abstract": "It is a well-established fact that energy consumption and production, as the primary sources of greenhouse gases, contribute to climate change and global warming issues. The analysis and estimation of the factors that contribute to these harmful gases will be of great assistance in the development of policies to reduce carbon dioxide emissions. In addition to identifying the factors related to energy consumption and CO2 emissions, forecasting the variable of interest as accurately as possible has a key role in increasing the efficiency of energy strategies to be implemented. Unlike studies in the literature, this study not only forecasts the future value of energy consumption and CO2 emissions but also determines the relationship between the predictions and the influential variables by revealing the contribution of each variable to the prediction. For this purpose, the study proposes an interpretable forecasting framework based on values of the Shapley additive explanation (SHAP) to provide a simpler explanation of machine learning (ML) models in forecasting energy consumption and CO2 emissions. The results obtained show that the total electricity generation from different energy sources is found to be the most important variable interacting positively with both energy consumption and CO2 emissions. Also, the influence of the predictors on projections made before and after COVID-19 has changed dramatically. The proposed method may assist policymakers in making future energy investments and establishing energy laws more accurately and efficiently as it explains the drivers of the forecasts.",
        "DOI": "10.1016/j.apenergy.2022.120163",
        "affiliation_name": "Van Yüzüncü Yıl Üniversitesi",
        "affiliation_city": "Van",
        "affiliation_country": "Türkiye",
        "affiliation_id": "60021828",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessing the ecological risk induced by PM<inf>2.5</inf> pollution in a fast developing urban agglomeration of southeastern China",
        "paper_author": "Wang L.",
        "publication": "Journal of Environmental Management",
        "citied_by": "14",
        "cover_date": "2022-12-15",
        "Abstract": "High PM2.5 concentration threats ecosystem functions but limited quantitative studies have recognized PM2.5 pollution as an individual stressor in evaluating ecological risk. In this study, we applied a machine-learning-based simulation model incorporating full-coverage satellite-driven PM2.5 dataset to estimate high-resolution ground PM2.5 concentration for the Golden Triangle of Southern Fujian Province, China (GTSF) in 2030 under two Representative Concentration Pathways (RCPs). Based on the simulation output, the ecological risk's spatiotemporal change and the risk for different land cover types, which were caused by PM2.5 pollution, were assessed. We found that the PM2.5 levels and ecological risk in the GTSF under RCP 4.5 would be reduced while those under RCP 8.5 would continue to increase. The regions with the highest ecological risk under RCP 4.5 are the most urbanized and industrialized districts, while those with the highest ecological risk under RCP 8.5 are of the highest rate in urbanization and the greatest decrease in planetary potential layer height. For both base years and 2030 under two RCPs, the ecological risk on developed land is the highest, while that on the forest is the lowest. Our study can provide useful information for environmental policy risk assessment.",
        "DOI": "10.1016/j.jenvman.2022.116284",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60027363",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Performance Assessment of Reinforcement Learning Policies for Battery Lifetime Extension in Mobile Multi-RAT LPWAN Scenarios",
        "paper_author": "Stusek M.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "2",
        "cover_date": "2022-12-15",
        "Abstract": "Considering the dynamically changing nature of the radio propagation environment, the envisioned battery lifetime of the end device (ED) for massive machine-type communication (mMTC) stands for a critical challenge. As the selected radio technology bounds the battery lifetime, the possibility of choosing among several low-power wide-area network (LPWAN) technologies integrated at a single ED may dramatically improve its lifetime. In this article, we propose a novel approach of battery lifetime extension utilizing reinforcement learning (RL) policies. Notably, the system assesses the radio environment conditions and assigns the appropriate rewards to minimize the overall power consumption and increase reliability. To this aim, we carry out extensive propagation and power measurements campaigns at the city-scale level and then utilize these results for composing real-life use cases for static and mobile deployments. Our numerical results show that RL-based techniques allow for a noticeable increase in EDs' battery lifetime when operating in the multi-RAT mode. Furthermore, out of all considered schemes, the performance of the weighted average policy shows the most consistent results for both considered deployments. Specifically, all RL policies can achieve 90% of their maximum gain during the initialization phase for the stationary EDs while utilizing less than 50 messages. Considering the mobile deployment, the improvements in battery lifetime could reach 200%.",
        "DOI": "10.1109/JIOT.2022.3197834",
        "affiliation_name": "Brno University of Technology, Faculty of Electrical Engineering and Communication",
        "affiliation_city": "Brno",
        "affiliation_country": "Czech Republic",
        "affiliation_id": "60108593",
        "affiliation_state": "South Moravian Region"
    },
    {
        "paper_title": "Explainable Bayesian networks applied to transport vulnerability",
        "paper_author": "de Waal A.",
        "publication": "Expert Systems with Applications",
        "citied_by": "14",
        "cover_date": "2022-12-15",
        "Abstract": "To deal with increasing amounts of data, decision and policymakers frequently turn to advances in machine learning and artificial intelligence to capitalise on the potential reward. But there is also a reluctance to trust black-box models, especially when such models are used to support decisions and policies that affect people directly, like those associated with transport and people's mobility. Recent developments focus on explainable artificial intelligence to bolster models’ trustworthiness. In this paper, we demonstrate the use of an explainable-by-design model, Bayesian Networks, on travel behaviour. The model incorporates various demographic and socioeconomic variables to describe full day activity chains: activity and mode choice, as well as the activity and trip durations. More importantly, this paper shows how the model can be used to provide the most relevant explanation for people's observed travel behaviour. The overall goal is to show that model explanations can be quantified and, therefore, assist policymakers to truly make evidence-based decisions. This goal is achieved through two case studies to explain people's vulnerability as it pertains to their total trip duration.",
        "DOI": "10.1016/j.eswa.2022.118348",
        "affiliation_name": "University of Pretoria",
        "affiliation_city": "Pretoria",
        "affiliation_country": "South Africa",
        "affiliation_id": "60021902",
        "affiliation_state": "Gauteng"
    },
    {
        "paper_title": "Machine-Learning-Empowered Passive Beamforming and Routing Design for Multi-RIS-Assisted Multihop Networks",
        "paper_author": "Huang C.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "14",
        "cover_date": "2022-12-15",
        "Abstract": "This article proposes a novel machine-learning-based routing optimization for the multiple reconfigurable intelligent surfaces (M-RIS)-assisted multihop cooperative networks, in which a practical phase model for reconfigurable intelligent surface (RIS) with the amplitude variation based on the corresponding discrete phase shift is considered. We aim to maximize the end-to-end data rate in the proposed network by jointly optimizing the data transmission path, the passive beamforming design of RIS, and transmit power allocation. To tackle this complicated nonconvex problem, we divide it into two subtasks: 1) the passive beamforming design of the RIS and 2) joint routing and power allocation optimization. First, for the passive beamforming design of RIS, we develop a distributed learning algorithm that employs a cascade forward backpropagation network in each relay node to solve the RIS coefficients optimization problem by directly using the optimization target to train the cascade networks. This solution can avoid the curse of dimensionality of traditional reinforcement learning algorithms in the RIS optimization problem. Then, based on the result of RIS optimization, we introduce the proximal policy optimization (PPO) algorithm with the clipping method to find solutions for joint optimization of routing and power allocation via achieving the long-term benefit in the Markov decision process (MDP). Simulation results show that the proposed learning-based scheme can learn from the environment to improve its policy stability and efficiency in the iterative training process for optimizing routing and RIS and significantly outperform the benchmark schemes.",
        "DOI": "10.1109/JIOT.2022.3195543",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "60151362",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Aspect2Labels: A novelistic decision support system for higher educational institutions by using multi-layer topic modelling approach",
        "paper_author": "Hussain S.",
        "publication": "Expert Systems with Applications",
        "citied_by": "22",
        "cover_date": "2022-12-15",
        "Abstract": "Aspect-based sentiment analysis (ABSA) has gained a rising concentration recently. It aims to provide a set of aspect terms and sentiments from a piece of text. Educational Data Mining (EDM) is now an essential tool for analysing pedagogical data. In academic institutions, student feedback is an influential gauge to measure the quality of the teaching–learning process. It helps higher education institutions to reconsider and improve their policies for student recruitment and retention. This paper proposed a situation awareness multi-layer topic modelling and enhanced hybrid machine learning approach for evaluating students’ textual feedback data in academic institutions. The proposed Aspect2Labels (A2L) approach is divided our system into three layers. To preserve semantic information, we extracted general aspects terms in the first layer known as high-level aspects. We pulled low-level aspects terms associated with high-level aspect terms in the second layer and the third layer used for sentiment orientation. We used zero-shot learning, LDA, and different variants of LDA for the aspect extraction process. We performed annotation on unlabelled students’ comments using our proposed A2L approach, and we obtained 91.3% accuracy in this process. We developed and tested novel algorithms for aspect terms mapping to label each aspect term to corresponding feedback. Different machine learning algorithms have been used to classify sentiments according to extracted aspects. We have also proposed and used Variable Global Feature Selection Scheme (VGFSS) and Variable Stopwords Filtering (VSF) to improve the performance of classifiers. We have managed to get 97% and 93% accuracy on the test dataset using Support Vector Machine (SVM) and Artificial Neural Networks (ANN), respectively. We highly suggest that our novel approach of aspect-oriented sentiment analysis could provide adequate understanding to analyse students’ feedback.",
        "DOI": "10.1016/j.eswa.2022.118119",
        "affiliation_name": "The Islamia University of Bahawalpur",
        "affiliation_city": "Bahawalpur",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60037241",
        "affiliation_state": "Punjab"
    },
    {
        "paper_title": "Renewable energy strategy analysis in relation to environmental pollution for BRICS, G7, and EU countries by using a machine learning framework and panel data analysis",
        "paper_author": "Cristea D.S.",
        "publication": "Frontiers in Environmental Science",
        "citied_by": "2",
        "cover_date": "2022-12-14",
        "Abstract": "The present research uses machine learning, panel data and time series prediction and forecasting techniques to establish a framework between a series of renewable energy and environmental pollution parameters, considering data for BRICS, G7, and EU countries, which can serve as a tool for optimizing the policy strategy in the sustainable energy production sector. The results indicates that XGBoost model for predicting the renewable energy production capacity reveals the highest feature importance among independent variables is associated with the gas consumption parameter in the case of G7, oil consumption for EU block and GHG emissions for BRICS, respectively. Furthermore, the generalized additive model (GAM) predictions for the EU block reveal the scenario of relatively constant renewable energy capacity if gas consumption increases, while oil consumption increases determine an increase in renewable energy capacity until a kick point, followed by a decrease. The GAM models for G7 revealed the scenario of an upward trend of renewable energy production capacity, as gas consumption increases and renewable energy production capacity decreases while oil consumption increases. In the case of the BRICS geopolitical block, the prediction scenario reveals that, in time, an increase in gas consumption generates an increase in renewable energy production capacity. The PCA emphasizes that renewable energy production capacity and GHG, respectively CO2 emissions, are highly correlated and are integrated into the first component, which explains more than 60% of the variance. The resulting models represent a good prediction capacity and reveal specific peculiarities for each analyzed geopolitical block. The prediction models conclude that the EU economic growth scenario is based on fossil fuel energy sources during the first development stage, followed by a shift to renewable energy sources once it reaches a kick point, during the second development stage. The decrease in renewable energy production capacity when oil consumption increases indicates that fossil fuels are in trend within the G7 economy. In the case of BRICS, it is assumed that gas consumption appears because of increasing the industrial capacity, followed by the increase of economic sustainability, respectively. In addition, the generalized additive models emphasize evolution scenarios with different peculiarities, specific for each analyzed geopolitical block.",
        "DOI": "10.3389/fenvs.2022.1005806",
        "affiliation_name": "Universitatea Transilvania din Brașov",
        "affiliation_city": "Brasov",
        "affiliation_country": "Romania",
        "affiliation_id": "60023654",
        "affiliation_state": "Brasov"
    },
    {
        "paper_title": "An immediate-return reinforcement learning for the atypical Markov decision processes",
        "paper_author": "Pan Z.",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "2",
        "cover_date": "2022-12-13",
        "Abstract": "The atypical Markov decision processes (MDPs) are decision-making for maximizing the immediate returns in only one state transition. Many complex dynamic problems can be regarded as the atypical MDPs, e.g., football trajectory control, approximations of the compound Poincaré maps, and parameter identification. However, existing deep reinforcement learning (RL) algorithms are designed to maximize long-term returns, causing a waste of computing resources when applied in the atypical MDPs. These existing algorithms are also limited by the estimation error of the value function, leading to a poor policy. To solve such limitations, this paper proposes an immediate-return algorithm for the atypical MDPs with continuous action space by designing an unbiased and low variance target Q-value and a simplified network framework. Then, two examples of atypical MDPs considering the uncertainty are presented to illustrate the performance of the proposed algorithm, i.e., passing the football to a moving player and chipping the football over the human wall. Compared with the existing deep RL algorithms, such as deep deterministic policy gradient and proximal policy optimization, the proposed algorithm shows significant advantages in learning efficiency, the effective rate of control, and computing resource usage.",
        "DOI": "10.3389/fnbot.2022.1012427",
        "affiliation_name": "Hunan University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60032356",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "Energy Management Strategy for Hybrid Electric Vehicle Based on the Deep Reinforcement Learning Method",
        "paper_author": "Chen Z.",
        "publication": "Diangong Jishu Xuebao/Transactions of China Electrotechnical Society",
        "citied_by": "9",
        "cover_date": "2022-12-10",
        "Abstract": "To resolve the problem of poor adaptability to varying driving cycles when energy management strategy for hybrid electric vehicles is running online, a design method of energy management strategy (EMS) with deep reinforcement learning ability is proposed. The presented method determines the optimal change rate of engine power based on the deep deterministic policy gradient algorithm and then establishes the power management strategy of the onboard energy system. The established control strategy includes a two-layer logical framework of offline interactive learning and online update learning. The control parameters are dynamically updated according to the vehicle operation characteristics to improve the vehicle energy-saving effect in online applications. To verify the proposed control strategy, the effectiveness of the algorithm is analyzed with the practical vehicle test data in Shenyang, and compared with the control effect of the particle swarm optimization algorithm. The results show that the proposed deep reinforcement learning EMS can achieve energy-saving effects better than particle swarm optimization-based strategy. Especially when the driving characteristics of vehicles change suddenly, deep reinforcement learning control strategy can achieve better adaptability.",
        "DOI": "10.19595/j.cnki.1000-6753.tces.211342",
        "affiliation_name": "School of Mechanical Engineering and Automation, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60118695",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Characterizing carbon emissions from China V and China VI gasoline vehicles based on portable emission measurement systems",
        "paper_author": "Zhu X.h.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "46",
        "cover_date": "2022-12-10",
        "Abstract": "On-road vehicle has been a prominent emission source, hence a key target of control for environment, health, and climate concerns. While considerable efforts have been made to investigate criteria pollutants such as adverse gaseous and particulate emissions across the world, there is limited systematic research to characterize on-road carbon emissions, especially as countries strive to set and achieve various climate goals (i.e., carbon neutrality, carbon peaking by a certain year, etc.) through cleaner vehicle technologies such as the latest vehicle emission standard, China VI (2020). This study used the portable emission measurement system (PEMS) to reveal the real-world emissions from two light-duty gasoline vehicles, one meeting the China V standard and the other China VI. The PEMS measurements were performed secondly in urban and suburban areas respectively, and finally yielded 10 h of rich and finely resolved emissions data. In addition of single-factor analysis, this study employed two machine learning models, stepwise regression and light gradient boosting machine (LightGBM), to investigate the coupling effects among vehicle/traffic parameters and identify driving behavior, engine condition, and external environment as key determining factors that affect vehicular carbon emissions. In particular, engine load percent and engine speed were confirmed to be the most dominant factors affecting vehicular carbon emissions under both China V and China VI standards, explaining ∼60% of variability in carbon emissions. As a result, vehicle specific power (VSP) is derived from vehicle travel parameters and used as a surrogate for carbon emission estimation. The external facility and environmental factors turned out significant as well in affecting vehicle carbon emissions: carbon emissions from the same vehicle were significantly higher in an urban setting then in suburban areas, mostly due to the more aggressive driving patterns in congested urban traffic. Travelling under relatively better traffic conditions on expressways gave the lowest per-distance emission factors of CO2, CO, and NOx. Comparing between the China V and VI vehicle, our PEMS data show significant carbon emission reduction benefits (15.9% in CO2, 28.8% in CO) as we move to the new China VI standard, although such benefit was not observed in NOx emissions.",
        "DOI": "10.1016/j.jclepro.2022.134458",
        "affiliation_name": "State Key Laboratory of Ocean Engineering",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60123520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Understanding robustness in multiscale nutrient abatement: Probabilistic simulation-optimization using Bayesian network emulators",
        "paper_author": "Dong F.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "8",
        "cover_date": "2022-12-10",
        "Abstract": "Ecosystem management in the face of uncertain disturbances has triggered increasing practices of resilience thinking. A multiscale probabilistic simulation-optimization framework is developed based on the nested nature of watersheds to inform decision robustness for Best Management Practices (BMPs). We presented a novel approach using hybrid Bayesian Networks (BNs) as interpretable and probabilistic emulators of process-based models. The hybrid BNs established at the scale of Hydrologic Response Units (HRUs) are embedded into simulation-optimization, whereby we analyze the cost-effectiveness-robustness of candidate BMP strategies at the subbasin scale. The optimal strategy is identified in compliance with water quality standards using watershed-scale integer programming. We apply the approaches in a typical intensively cultivated plateau watershed adjacent to Lake Dianchi, one of the three most eutrophic lakes in China. Our findings suggest that the hybrid BNs, incorporating both quantitative and qualitative information, are reliable emulators of the Soil and Water Assessment Tool (SWAT) in capturing critical pathways of diffuse phosphorus. Tradeoffs among cost, effectiveness, and robustness follow the law of diminishing marginal benefits. The optimum BMP strategies vary with policymakers’ preference toward robustness levels. Our findings indicate that robustness should be accounted for as an additional decision attribute besides costs and pollution mitigation. The benefits of the modeling framework are to (i) reduce over 99% computation complexity and support efficient decision-making under multifaceted uncertainties; (ii) improve interpretability and reliability of machine learning emulators; and (iii) inform policymakers of robustness with the probability of water quality restoration success.",
        "DOI": "10.1016/j.jclepro.2022.134394",
        "affiliation_name": "School of Civil and Environmental Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60118451",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Impacts of traffic-related particulate matter pollution on semen quality: A retrospective cohort study relying on the random forest model in a megacity of South China",
        "paper_author": "Yu X.",
        "publication": "Science of the Total Environment",
        "citied_by": "15",
        "cover_date": "2022-12-10",
        "Abstract": "Background: Emerging evidence shows the detrimental impacts of particulate matter (PM) on poor semen quality. High-resolution estimates of PM concentrations are conducive to evaluating accurate associations between traffic-related PM exposure and semen quality. Methods: In this study, we firstly developed a random forest model incorporating meteorological factors, land-use information, traffic-related variables, and other spatiotemporal predictors to estimate daily traffic-related PM concentrations, including PM2.5, PM10, and PM1. Then we enrolled 1310 semen donors corresponding to 4912 semen samples during the study period from January 1, 2019, and December 31, 2019 in Guangzhou city, China. Linear mixed models were employed to associate individual exposures to traffic-related PM during the entire (0–90 lag days) and key periods (0–37 and 34–77 lag days) with semen quality parameters, including sperm concentration, sperm count, progressive motility and total motility. Results: The results showed that decreased sperm concentration was associated with PM10 exposures (β: -0.21, 95 % CI: −0.35, −0.07), sperm count was inversely related to both PM2.5 (β: -0.19, 95 % CI: −0.35, −0.02) and PM10 (β: -0.19, 95 % CI: −0.33, −0.05) during the 0–90 days lag exposure window. Besides, PM2.5 and PM10 might diminish sperm concentration by mainly affecting the late phase of sperm development (0–37 lag days). Stratified analyses suggested that PBF and drinking seemed to modify the associations between PM exposure and sperm motility. We did not observe any significant associations of PM1 exposures with semen parameters. Conclusion: Our results indicate that exposure to traffic-related PM2.5 and PM10 pollution throughout spermatogenesis may adversely affect semen quality, especially sperm concentration and count. The findings provided more evidence for the negative associations between traffic-related PM exposure and semen quality, highlighting the necessity to reduce ambient air pollution through environmental policy.",
        "DOI": "10.1016/j.scitotenv.2022.158387",
        "affiliation_name": "College of Computer, Mathematical, &amp; Natural Sciences",
        "affiliation_city": "College Park",
        "affiliation_country": "United States",
        "affiliation_id": "60151558",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Energy system digitization in the era of AI: A three-layered approach toward carbon neutrality",
        "paper_author": "Xie L.",
        "publication": "Patterns",
        "citied_by": "7",
        "cover_date": "2022-12-09",
        "Abstract": "The transition toward carbon-neutral electricity is one of the biggest game changers in addressing climate change since it addresses the dual challenges of removing carbon emissions from the two largest sectors of emitters: electricity and transportation. The transition to a carbon-neutral electric grid poses significant challenges to conventional paradigms of modern grid planning and operation. Much of the challenge arises from the scale of the decision-making and the uncertainty associated with the energy supply and demand. Artificial intelligence (AI) could potentially have a transformative impact on accelerating the speed and scale of carbon-neutral transition, as many decision-making processes in the power grid can be cast as classic, though challenging, machine-learning tasks. We point out that to amplify AI's impact on carbon-neutral transition of the electric energy systems, the AI algorithms originally developed for other applications should be tailored in three layers of technology, markets, and policy.",
        "DOI": "10.1016/j.patter.2022.100640",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "College Station",
        "affiliation_country": "United States",
        "affiliation_id": "60148980",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Using apple watch ECG data for heart rate variability monitoring and stress prediction: A pilot study",
        "paper_author": "Velmovitsky P.E.",
        "publication": "Frontiers in Digital Health",
        "citied_by": "11",
        "cover_date": "2022-12-09",
        "Abstract": "Stress is an increasingly prevalent mental health condition that can have serious effects on human health. The development of stress prediction tools would greatly benefit public health by allowing policy initiatives and early stress-reducing interventions. The advent of mobile health technologies including smartphones and smartwatches has made it possible to collect objective, real-time, and continuous health data. We sought to pilot the collection of heart rate variability data from the Apple Watch electrocardiograph (ECG) sensor and apply machine learning techniques to develop a stress prediction tool. Random Forest (RF) and Support Vector Machines (SVM) were used to model stress based on ECG measurements and stress questionnaire data collected from 33 study participants. Data were stratified into socio-demographic classes to further explore our prediction model. Overall, the RF model performed slightly better than SVM, with results having an accuracy within the low end of state-of-the-art. Our models showed specificity in their capacity to assess “no stress” states but were less successful at capturing “stress” states. Overall, the results presented here suggest that, with further development and refinement, Apple Watch ECG sensor data could be used to develop a stress prediction tool. A wearable device capable of continuous, real-time stress monitoring would enable individuals to respond early to changes in their mental health. Furthermore, large-scale data collection from such devices would inform public health initiatives and policies.",
        "DOI": "10.3389/fdgth.2022.1058826",
        "affiliation_name": "Institute of Health Policy, Management and Evaluation",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60193840",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "A generic learning simulation framework to assess security strategies in cyber-physical production systems",
        "paper_author": "Koïta M.",
        "publication": "Computer Networks",
        "citied_by": "2",
        "cover_date": "2022-12-09",
        "Abstract": "Connected systems through computerized networks are at the heart of the Industry of the future. As they merge physical entities with cyber spaces, they fall under the paradigm of cyber-physical production systems. Cybersecurity is a key challenge for such systems, as they are subject to daily attempts of intruders to gain unauthorized access to their internal resources or to compromise their integrity. The fast increase of new attack strategies requires the rapid design and assessment of new defense strategies. It entails a complex, error-prone and time-consuming process, including the clear specification of the attack and defense strategies involved, and the design and implementation of the simulation model allowing to evaluate the performances of the defense strategy. This work intends to make such a process transparent to cybersecurity managers by limiting their workload to the sole specification of the characteristics of the system and the logic of the attack and the defense. It provides a generic hybrid simulation framework for flexible evaluation of cybersecurity policies, which is demonstrated on a SYN flooding application. Therefore, the contribution is twofold: (1) The proposed framework offers a high-level environment allowing various experts to collaborate by graphically modeling a given attack strategy and the envisioned defense strategy, without engaging in heavy implementation efforts. Then the framework's executable infrastructure, which combines simulation with machine learning to understanding the interactions between the attackers & the defender, will allow them assessing the performances of these strategies. The proposed framework differs from state-of-the-art cybersecurity simulation environments in its uniqueness to combining the expressive power of a universal simulation modeling formalism with the user-friendliness of a visual simulation tool. Therefore, it offers at one side, a very high modeling flexibility for easy exploration of various cybersecurity strategies, and at the other side, integrated learning capabilities for allowing self-adaptive user-based cybersecurity strategy design. (2) The application demonstrating the framework focuses on the most encountered and still uncontrolled threats in cybersecurity, i.e. the SYN-Flooding based Denial of Service (DoS) attack. The application targeted is not meant to propose yet another SYN flood detection algorithm or to improve the state-of-the-art in that domain, but to prove the framework operationality. The experimental results obtained showcase the ability of the framework to support learning simulation-based SYN flood defense algorithm design and validation.",
        "DOI": "10.1016/j.comnet.2022.109381",
        "affiliation_name": "Université des Sciences, des Techniques et des Technologies de Bamako",
        "affiliation_city": "Bamako",
        "affiliation_country": "Mali",
        "affiliation_id": "60280005",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A robust control-theory-based exploration strategy in deep reinforcement learning for virtual network embedding",
        "paper_author": "Dandachi G.",
        "publication": "Computer Networks",
        "citied_by": "6",
        "cover_date": "2022-12-09",
        "Abstract": "Network slice management and, more generally, resource orchestration should be fully automated in 6G networks, as envisioned by the ETSI ENI. In this context, artificial intelligence (AI) and context-aware policies are certainly major options to move in this direction and to adapt service delivery to changing user needs, environmental conditions and business objectives. In this paper, we step towards this objective by addressing the problem of optimal placement of dynamic virtual networks through a self-adaptive learning-based strategy. These constantly evolving networks present, however, several challenges, mainly due to their stochastic nature, and the high dimensionality of the state and the action spaces. This curse of dimensionality requires, indeed, a broader exploration, which is not always compatible with a real-time execution in an operational network. Thus, we propose DQMC, a new strategy for virtual network embedding in mobile networks combining a Deep Reinforcement Learning (DRL) strategy, namely a Deep Q-Network (DQN), and Monte Carlo (MC). As learning is costly in time and computing resources, and sensitive to changes in the network, we suggest a control-theory-based techniques to dynamically leverage exploration in DQMC. This leads to fast, efficient, and sober learning compared to a Monte Carlo-based strategy. This also ensures a reliable solution even in the case of a change in the requests’ sizes or a node's failure, showing promising perspectives for solutions combining control-theory and machine learning.",
        "DOI": "10.1016/j.comnet.2022.109366",
        "affiliation_name": "Université de Lille",
        "affiliation_city": "Lille",
        "affiliation_country": "France",
        "affiliation_id": "60104665",
        "affiliation_state": "Hauts-de-France"
    },
    {
        "paper_title": "Supporting responsible machine learning in heliophysics",
        "paper_author": "Narock A.",
        "publication": "Frontiers in Astronomy and Space Sciences",
        "citied_by": "0",
        "cover_date": "2022-12-07",
        "Abstract": "Over the last decade, Heliophysics researchers have increasingly adopted a variety of machine learning methods such as artificial neural networks, decision trees, and clustering algorithms into their workflow. Adoption of these advanced data science methods had quickly outpaced institutional response, but many professional organizations such as the European Commission, the National Aeronautics and Space Administration (NASA), and the American Geophysical Union have now issued (or will soon issue) standards for artificial intelligence and machine learning that will impact scientific research. These standards add further (necessary) burdens on the individual researcher who must now prepare the public release of data and code in addition to traditional paper writing. Support for these is not reflected in the current state of institutional support, community practices, or governance systems. We examine here some of these principles and how our institutions and community can promote their successful adoption within the Heliophysics discipline.",
        "DOI": "10.3389/fspas.2022.1064233",
        "affiliation_name": "ADNET Systems, Inc.",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States",
        "affiliation_id": "60111960",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Deductive Learning in Wireless Mobile Networks Using QoE-Driven Data Analysis",
        "paper_author": "Prakash E.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2022-12-07",
        "Abstract": "Current research studies provide details analysis of mobile networks using QoE based detection. In situations where the overall resource of the system cannot support loading, we propose a QoE-dnven optimization technique. The strict data forwarding policies conventionally prevent this situation. But this would lead to a high probability of blocking and loose revenues for operators. We propose re-adapting the applications, taking into consideration the applications' utility functions. This strategy improves the quality of experience for certain systems and for a fixed number of users and allows more users to be admitted to a predetermined quality. This approach has the potential to be critical in the development of future ultra-dense and environmentally friendly mobile communication networks that are expected to be self-organizing and self-healing. The above diagram represents that accuracy levels of various Classifiers. The Bagging has 72.94% of accuracy level. CV Parameter Selection classifier has 65.93% of accuracy level. The AdaBoostMl classifier has 54.89% of accuracy level. The Classification Via Regression classifier has 56.89% of accuracy level. The Attribute Selected Classifier classifier has 56.89% of accuracy level. The Cost Sensitive Classifier classifier has 65.92% of accuracy level.",
        "DOI": "10.1063/5.0111630",
        "affiliation_name": "Bharath Institute of Higher Education and Research",
        "affiliation_city": "Chennai",
        "affiliation_country": "India",
        "affiliation_id": "60104605",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Editorial: Rising stars: Clinical diabetes 2021",
        "paper_author": "Al Madhoun A.",
        "publication": "Frontiers in Endocrinology",
        "citied_by": "0",
        "cover_date": "2022-12-07",
        "Abstract": "NA",
        "DOI": "10.3389/fendo.2022.1106804",
        "affiliation_name": "Dasman Diabetes Institute",
        "affiliation_city": "Dasman",
        "affiliation_country": "Kuwait",
        "affiliation_id": "60121864",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Prediction of differential performance between advanced placement exam scores and class grades using machine learning",
        "paper_author": "Suzuki H.",
        "publication": "Frontiers in Education",
        "citied_by": "5",
        "cover_date": "2022-12-06",
        "Abstract": "Introduction: Past studies have found students to perform differently between class grades and standardized test scores – two essential and complementary measures of student achievement. This study examines predictors of the relative performance between these two measures in the context of the advanced placement (AP) program, namely, we compared students’ AP exam scores to the class grade they received in the corresponding AP course. For example, if a student received a high AP class grade but a low AP exam score, what characteristics about the student or their learning context might explain such discrepancy? Methods: We used machine learning, specifically random forests, and model interpretation methods on data collected from 381 high school students enrolled in an AP Statistics course in the 2017–2018 academic year, and additionally replicated our analyses on a separate cohort of 422 AP Statistics students from the 2018–2019 academic year. Results: Both analyses highlighted students’ school and behavioral engagement as predictors of differential performance between AP class grades and AP exam scores. Discussion: Associations between behavioral engagement and differential performance suggest that the ways in which a student interacts with AP course material to obtain high class grades can differ from study habits that lead to optimal performance on the AP exam. Additionally, school-level differences in relative performance pose equity concerns towards the use of AP exam scores in high-stakes decisions, such as college admissions. Implications are discussed from a pedagogical and policy perspective.",
        "DOI": "10.3389/feduc.2022.1007779",
        "affiliation_name": "University of Notre Dame",
        "affiliation_city": "Notre Dame",
        "affiliation_country": "United States",
        "affiliation_id": "60021508",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "DitDetector: Bimodal Learning based on Deceptive Image and Text for Macro Malware Detection",
        "paper_author": "Yan J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "10",
        "cover_date": "2022-12-05",
        "Abstract": "Macro malware has always been a severe threat to cyber security although the Microsoft Office suite applies the default macro-disabling policy. Among the defense solutions at different stages of the attack chain, document analysis is more targeted through detecting malicious documents with macro malware. It is effective, especially with machine learning methods, but still faces problems handling malware variants, supporting file formats, and attack countermeasures with advanced attack techniques (e.g., Excel 4.0 macro and remote template injection). In this paper, we find it promising to detect deceptive information embedded in documents which tricks users into enabling macros instead of detecting file metadata or extracted macro codes. Thus, we propose a novel solution for macro malware detection named DitDetector, which leverages bimodal learning based on deceptive images and text. Specifically, we extract preview images of documents based on an image export SDK of Oracle and extract textual information from preview images based on an open-source OCR engine. The bimodal model of DitDetector contains a visual encoder, a textual encoder, and a forward neural network, which learns based on the joint representation of the two encoders' outputs. We evaluate DitDetector on three datasets, including an open-source malicious document dataset (i.e., MalDoc) and two collected real-world adversary datasets (i.e., a database of Excel macros and a database of remote template injection samples). Our experiments show that DitDetector outperforms four existing macro code-based machine learning methods and five reputable Anti-Virus engines. Especially in the real-world test of advanced macro malware, DitDetector gets the F1-score of 99.93% which is at least 3.16% higher than compared solutions.",
        "DOI": "10.1145/3564625.3567982",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60027363",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Risk-aware Fine-grained Access Control in Cyber-physical Contexts",
        "paper_author": "Liu J.",
        "publication": "Digital Threats: Research and Practice",
        "citied_by": "3",
        "cover_date": "2022-12-05",
        "Abstract": "Access to resources by users may need to be granted only upon certain conditions and contexts, perhaps particularly in cyber-physical settings. Unfortunately, creating and modifying context-sensitive access control solutions in dynamic environments creates ongoing challenges to manage the authorization contexts. This article proposes RASA, a context-sensitive access authorization approach and mechanism leveraging unsupervised machine learning to automatically infer risk-based authorization decision boundaries. We explore RASA in a healthcare usage environment, wherein cyber and physical conditions create context-specific risks for protecting private health information. The risk levels are associated with access control decisions recommended by a security policy. A coupling method is introduced to track coexistence of the objects within context using frequency and duration of coexistence, and these are clustered to reveal sets of actions with common risk levels; these are used to create authorization decision boundaries. In addition, we propose a method for assessing the risk level and labelling the clusters with respect to their corresponding risk levels. We evaluate the promise of RASA-generated policies against a heuristic rule-based policy. By employing three different coupling features (frequency-based, duration-based, and combined features), the decisions of the unsupervised method and that of the policy are more than 99% consistent.",
        "DOI": "10.1145/3480468",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada",
        "affiliation_id": "60028897",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Reinforcement learning for intelligent building energy management system control",
        "paper_author": "Kotevska O.",
        "publication": "Intelligent Data Mining and Analysis in Power and Energy Systems: Models and Applications for Smarter Efficient Power Systems",
        "citied_by": "0",
        "cover_date": "2022-12-02",
        "Abstract": "A building energy management system (BEMS) is a computer-based system designed to monitor and control a building's energy needs. Modern BEMS rely on the sensing and connectivity capabilities of Internet of Things (IoT) technology to intelligently adjust the energy consumption to reduce cost while respecting the consumers' preferences. Increasingly, control decisions are made based on predictions by models trained using supervised machine learning methods, which still requires control policies to be formulated in a rule-based fashion. When using reinforcement learning (RL) instead, control policies are learned by observing the utility in terms of cost and comfort associated with actions such as a change in the heating system's setpoint. The resulting RL-based controllers can capture not only the dynamics of the building and the associated electrical devices, but also fluctuations in electricity prices and user demand, avoiding the need to combine multiple predictive models with tailored control policies. This chapter will provide an overview of RL-based approaches for BEMS. After sketching the taxonomy of general RL methods, we discuss the implications of relying on the individual methods in a BEMS context. Existing work applying RL is presented along the key devices controlled by BEMS systems. Finally, we summarize the state-of-the-art and sketch limitations and open research directions.",
        "DOI": "10.1002/9781119834052.ch18",
        "affiliation_name": "Oak Ridge National Laboratory",
        "affiliation_city": "Oak Ridge",
        "affiliation_country": "United States",
        "affiliation_id": "60024266",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Cocreative interaction: Somax2 and the reach project",
        "paper_author": "Assayag G.",
        "publication": "Computer Music Journal",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Somax2 is an artificial intelligence (AI)-based multiagent system for human–machine “coimprovisation” that generates stylistically coherent streams while continuously listening and adapting to musicians or other agents. The model on which it is based can be used with little configuration to interact with humans in full autonomy, but it also allows fine real-time control of its generative processes and interaction strategies, closer in this case to a “smart” digital instrument. An offspring of the Omax system, conceived at the Institut de Recherche et Coordination Acoustique/Musique (IRCAM), the Somax2 environment is part of the European Research Council Raising Cocreativity in Cyber–Human Musicianship (REACH) project, which studies distributed creativity as a general template for symbiotic interaction between humans and digital systems. It fosters mixed musical reality involving cocreative AI agents. The REACH project puts forward the idea that cocreativity in cyber–human systems results from the emergence of complex joint behavior, produced by interaction and featuring cross-learning mechanisms. Somax2 is a first step toward this ideal, and already shows life-size achievements. This article describes Somax2 extensively, from its theoretical model to its system architecture, through its listening and learning strategies, representation spaces, and interaction policies.",
        "DOI": "10.1162/comj_a_00662",
        "affiliation_name": "Sciences et Technologies de la Musique et du Son",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60158039",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Using machine learning to predict clean energy stock prices: How important are market volatility and economic policy uncertainty?",
        "paper_author": "Sadorsky P.",
        "publication": "Journal of Climate Finance",
        "citied_by": "22",
        "cover_date": "2022-12-01",
        "Abstract": "The disruptive impacts of climate change have created an urgent need to transition to a low carbon economy and an important part of this transition is an increase in the usage of clean energy. The greater adoption of clean energy is creating new opportunities for clean energy equity investing. The existing literature mostly focuses on the dynamic relationship between clean energy equities, oil prices, technology stock prices, and other important macroeconomic variables like market volatility and economic policy uncertainty. However, there is a shortage of literature on forecasting clean energy stock prices. Forecasting clean energy equity prices is important for making investment decisions. This paper uses machine learning methods to predict the direction of clean energy stock prices. The analysis reveals that random forests, extremely randomized trees, stochastic gradient boosting, and support vector machine have higher prediction accuracy than Lasso or Naïve Bayes. For forecasts in the 10-day to 20-day range, random forests, extremely randomized trees, stochastic gradient boosting, and support vector machine achieve prediction accuracies greater than 85 %. In some cases, prediction accuracy reaches 90%. Lasso prediction accuracy is higher than Naïve Bayes but never greater than 65 %. The MA200, MA50, and WAD technical indicators are, on average, the features most important for predicting clean energy stock price direction. Of the non-technical indicators, VIX and OVX are consistently ranked high in importance. In most cases, EPU is not one of the most important features, Of the forecasting methods considered, extremely randomized trees are very impressive due to high accuracy and short computational time.",
        "DOI": "10.1016/j.jclimf.2022.100002",
        "affiliation_name": "Schulich School of Business",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada",
        "affiliation_id": "60119111",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Distance to semi-natural habitats matters for arbuscular mycorrhizal fungi in wheat roots and wheat performance in a temperate agricultural landscape",
        "paper_author": "Pirhofer Walzl K.",
        "publication": "Journal of Sustainable Agriculture and Environment",
        "citied_by": "0",
        "cover_date": "2022-12-01",
        "Abstract": "Introduction: The proximity of semi-natural habitats and agricultural fields in an agricultural landscape leads to unavoidable biological, chemical, and physical interactions. Fungi can negatively influence, but also support crop growth in agricultural fields. Therefore, in this field study we investigated the colonisation of arbuscular mycorrhizal (AM) fungi and non-AM fungi in winter-wheat roots as well as winter-wheat performance in distance to semi-natural habitats. Materials and Methods: We sampled in an intensively managed agricultural landscape in North-east Germany along agricultural transition zones, that is, along 50 m-transects from semi-natural habitats like hedgerows and glacially created in-field ponds—so-called kettle holes—into agricultural fields. Results: To our knowledge, we show for the first time that AM fungal colonisation in winter-wheat roots decreased linearly with increasing distance to semi-natural habitats while non-AM fungal root colonisation did not change. Winter-wheat grain yield and biomass slightly increased with increasing distance to hedgerows but not to kettle holes. This clearly shows that there is a difference between different crop performance parameters. Random forest machine learning algorithms confirmed the particular importance of distance to semi-natural habitats for AM fungal root colonisation and for winter-wheat grain yield. Less intensive agricultural management close to semi-natural habitats, for example, no herbicide and pesticide applications as a result of nature protection regulations, may partly explain this pattern. However, spatial response patterns of AM but not of non-AM fungi in wheat roots also point to changed ecological interactions close to semi-natural habitats. Conclusion: Semi-natural and natural habitats in agricultural landscapes are slowly recognised not only to be important for biodiversity conservation, but also for sustainable crop production. Additionally, they may also be a tool for farmers and policy makers to improve sustainable landscape management. And agricultural transition zones are spatially and temporally complex dynamic ecosystems that should be the focus of further investigations.",
        "DOI": "10.1002/sae2.12032",
        "affiliation_name": "Eastern Switzerland University of Applied Sciences",
        "affiliation_city": "Rapperswil",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60268809",
        "affiliation_state": "St. Gallen"
    },
    {
        "paper_title": "A computational approach to analyzing climate strategies of cities pledging net zero",
        "paper_author": "Sachdeva S.",
        "publication": "npj Urban Sustainability",
        "citied_by": "14",
        "cover_date": "2022-12-01",
        "Abstract": "Cities have become primary actors on climate change and are increasingly setting goals aimed at net-zero emissions, which warrants closer examination to understand how they intend to meet these goals. The incomplete and heterogeneous nature of city climate policy documents, however, has made systemic analysis challenging. We analyze 318 climate action documents from cities with net-zero targets using machine learning-based natural language processing (NLP) techniques. We aim to accomplish two goals: (1) determine text patterns that predict ‘ambitious’ net-zero targets; and (2) perform a sectoral analysis to identify patterns and trade-offs in climate action themes. We find that cities with ambitious climate actions tend to emphasize quantitative metrics and specific high-emitting sectors in their plans. Cities predominantly emphasize energy-related actions in their plans, but often at the expense of other sectors, including land-use and climate impacts. The method presented in this paper provides a replicable, scalable approach to analyzing climate action plans and a first step towards facilitating cross-city learning.",
        "DOI": "10.1038/s42949-022-00065-x",
        "affiliation_name": "Yale School of the Environment",
        "affiliation_city": "New Haven",
        "affiliation_country": "United States",
        "affiliation_id": "60278760",
        "affiliation_state": "CT"
    },
    {
        "paper_title": "Construction Direction and Development Path of Digital Educational Resources in the Era of New Educational Infrastructure Construction",
        "paper_author": "Ke Q.",
        "publication": "Frontiers of Education in China",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Digital educational resources have become essential elements of modern educational public services. China’s national program on new educational infrastructure construction has proposed to take new infrastructure construction of digital educational resources as one of the critical tasks. This paper aims to provide a theoretical basis for advancing the reform and development of digital educational resources in the new era. It classifies the current development and realistic challenges of China’s digital educational resources, and summaries and interprets the directions of the three construction projects of new type resources and tools, the resource supply system, and the resource supervisory system. It depicts the prospect of digital educational resource construction in the intelligent era in the combination of the strategic layout of the policies on new educational infrastructure construction. It also discusses such key technologies supporting new infrastructure construction of digital educational resources as multimodal learning analytics, disciplinary knowledge graphs, machine learning, and blockchain. It finally proposes a specific development path for new infrastructure construction of digital educational resources.",
        "DOI": "10.3868/s110-007-022-0022-1",
        "affiliation_name": "South China Normal University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60005816",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Online medical privacy protection strategy under information value-added mechanism",
        "paper_author": "Ming S.",
        "publication": "Chinese Journal of Network and Information Security",
        "citied_by": "0",
        "cover_date": "2022-12-01",
        "Abstract": "China’s economic level and people’s living standards have developed rapidly in recent years, and the medical level and medical technology have made breakthroughs continuously. With the promotion and deepening of “Internet Plus” to business model innovation in various fields, the development of “Internet Plus” medical has been rapidly developed. Due to the continuous development of data processing technologies such as machine learning and data mining, the risk of users’ personal medical data disclosure in the process of online medical treatment has also attracted the attention of researchers. Considering the deductibility of information, the discount mechanism was adopted to describe the change of user’s private information value in different stages of the game. Combined with the current research status in the field of online medical privacy protection motivation, how to mobilize the enthusiasm of both players from the level of privacy protection motivation was explored with game analysis. In view of the game characteristics of users’ strong willingness to continually use the online medical platform and intermittently provide privacy, the repeated game method was adopted to better describe the game process between users and the online medical platform. The tendency change law of the players on both sides of the game was obtained. Moreover, the Nash equilibrium of the game model was analyzed under different model parameters and the change trend of the game strategy of both sides with the progress of the game stage. When the parameters were met 2(cp−cn)≥lp(pn−pp), the user started to choose from “agree to share private data” to “refuse to share private data”. The above conclusion was verified by simulation experiments. Based on the above conclusions, from the perspective of online medical platform and users, policy suggestions on how to realize privacy protection from the level of privacy protection motivation in the process of online medical treatment were given.",
        "DOI": "10.11959/j.issn.2096-109x.2022072",
        "affiliation_name": "Central University of Finance and Economics",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60013131",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The Importance of Price, Income, and Affordability in the Demand for Cigarettes in Spain",
        "paper_author": "Cadahia P.",
        "publication": "Addicta: the Turkish Journal on Addictions",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "In the literature it is commonly accepted that the best mechanism to control smoking is by increasing tobacco prices via taxes. However, there are some studies that indicate that the decrease in tobacco consumption when prices rise is because consumer income is not capable of counteracting said rise. The empirical analysis was developed using a panel of data from the Spanish provinces covering 2002 to 2018. By using Machine Learning assembly models, the importance of price, GDP and affordability as a mechanism for controlling the demand for cigarettes is estimated. The importance of affordability to control tobacco consumption in Spain has grown over time. Furthermore, until 2010, income has generally better explained the demand for cigarettes in the Spanish provinces. However, as of 2010, price is the explanatory variable of the demand function that best explains the behavior of the demand for cigarettes. In these circumstances, the separate estimates of price and income elasticity that have been carried out in Spain so far must be interpreted considering that as of 2010, price is more important than income in explaining the demand for cigarettes. Furthermore, when the relative income price reaches 1%, there seems to be a positive relationship between this variable and the importance of price in explaining the demand for tobacco. Although the demand functions estimated so far are useful to make predictions about the behavior of cigarette demand, the government must consider that price is a good tool to control tobacco consumption from a certain point of affordability. Specifically, it appears that when the relative income price exceeds 1%, the importance of price as a tool to control legal cigarette sales grows each time the relative income price rises.",
        "DOI": "10.5152/ADDICTA.2022.22054",
        "affiliation_name": "International University of La Rioja",
        "affiliation_city": "Logrono",
        "affiliation_country": "Spain",
        "affiliation_id": "60104175",
        "affiliation_state": "La Rioja"
    },
    {
        "paper_title": "BEYOND WINDOW DRESSING: PUBLIC PARTICIPATION FOR MARGINALIZED COMMUNITIES IN THE DATAFIED SOCIETY",
        "paper_author": "Gilman M.E.",
        "publication": "Fordham Law Review",
        "citied_by": "5",
        "cover_date": "2022-12-01",
        "Abstract": "We live in a datafied society in which our personal data is being constantly harvested, analyzed, and sold by public and private entities, and yet we have little control over our data and little voice in how it is used. In light of the impacts of algorithmic decision-making systems—including those that run on machine learning and artificial intelligence—there are increasing calls to integrate public participation into the adoption, design, and oversight of these tech tools. Stakeholder input is particularly crucial for members of marginalized groups, who bear the disproportionate harms of data-centric technologies. Yet, recent calls for public participation have been mostly hortatory and without specific strategies or realistic recommendations. As this Article explains, policy makers need not operate from a blank slate. For decades, a variety of American statutory regimes have mandated public participation, such as in the areas of environmental law, land use law, and anti-poverty programs. Such mandates have had outsized effects on communities suffering from economic disadvantage and racial and ethnic discrimination. This Article contends that we should examine these regulatory mandates in thinking about how to include the perspectives of marginalized stakeholders in the datafied society. The core takeaway is that meaningful public participation is extremely challenging and does not happen without intentional and inclusive design. At its best, public input can improve outputs and empower stakeholders. At its worst, it operates as a form of “window dressing,” in which marginalized communities have no real power to effect outcomes, thus generating distrust and alienation. Case studies show that meaningful public participation is most likely to result when there are hard-law requirements for public participation and when decision-makers operate transparently and recognize the value of the public’s expertise. In addition, impacted communities must be provided with capacity-building tools and resources to support their engagement. As legislative proposals to enhance tech accountability—through algorithmic impact assessments, audits, and other tools—gain steam, we must heed these lessons.",
        "DOI": "NA",
        "affiliation_name": "University of Baltimore",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60028611",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "The Importance of Forecasting in Industrial Enterprise Management Using Machine Learning",
        "paper_author": "Vorobev A.V.",
        "publication": "Scientific and Technical Information Processing",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Abstract: In this work, the assessment of the importance of forecasting in making a management decision during an operational control of an enterprise without including individual cases of dominating impact of forecasted values, including the investing policies and strategic enterprise management, was considered. As an alternative to the expert method, a forecast importance assessment method based on gradient-boosted machine learning algorithm analysis of a decision informational field with the subsequent interpretation of acquired results with Shapley values, allowing for a numerical representation of importance. This method is suggested for use as a tool to increase efficiency of intellectual decision-making support systems by the means of including it in the procedure of automated analysis of importance of features. This work is interdisciplinary, and it concerns problems of systems analysis, economics, and psychology.",
        "DOI": "10.3103/S0147688222050173",
        "affiliation_name": "Kursk State University",
        "affiliation_city": "Kursk",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60109910",
        "affiliation_state": "Kursk Oblast"
    },
    {
        "paper_title": "Application of a predictive Q-learning algorithm on the multiple-effect evaporator in a sugarcane ethanol biorefinery",
        "paper_author": "Emori E.Y.",
        "publication": "Digital Chemical Engineering",
        "citied_by": "10",
        "cover_date": "2022-12-01",
        "Abstract": "With the recent development of machine learning, reinforcement learning is an interesting alternative to PID controllers. In this context, a discrete predictive Q-learning approach is applied in the control of a sugarcane biorefinery multiple-effect evaporation system. The algorithm is built using Scilab and learns to control the multiple-effect evaporator outlet concentration by manipulating its feed steam flow rate. Based on multiple episodes, the state-actions that consist of discrete changes in steam flow rate are chosen with a greedy algorithm. In order to increase the training efficiency and overcome the large dead time of the system, a neural network is applied to predict the outlet concentration of each control action after reaching the steady-state. The control policy was built and tested through simulations on a phenomenological model. The controller performance was evaluated in set-point tracking and disturbance rejection tests and compared with PID responses. The research showed that the Q-learning controller exhibited better performance than the PID controller.",
        "DOI": "10.1016/j.dche.2022.100049",
        "affiliation_name": "Universidade Estadual de Maringá",
        "affiliation_city": "Maringa",
        "affiliation_country": "Brazil",
        "affiliation_id": "60029498",
        "affiliation_state": "PR"
    },
    {
        "paper_title": "A Machine Learning-Based Energy Management Agent for Fine Dust Concentration Control in Railway Stations",
        "paper_author": "Kwon K.B.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "This study developed a reinforcement learning-based energy management agent that controls the fine dust concentration by controlling facilities such as blowers and air conditioners to efficiently manage the fine dust concentration in the station. To this end, we formulated an optimization problem based on the Markov decision-making process and developed a model for predicting the concentration of fine dust in the station by training an artificial neural network (ANN) based on supervised learning to develop the transfer function. In addition to the prediction model, the optimal policy for controlling the blower and air conditioner according to the current state was obtained based on the ANN to which the Deep Q-Network (DQN) algorithm was applied. In the case study, it is confirmed that the ANN and DQN of the predictive model were trained based on the actual data of Nam-Gwangju Station to converge to the optimal policy. The comparison between the proposed method and conventional method shows that the proposed method can use less power consumption but achieved better performance on reducing fine dust concentration than the conventional method. In addition, by increasing the value of the ratio that represents the compensation due to the fine dust reduction, the learned agent achieved more reduction on the fine dust concentration by increasing the power consumption of the blower and air conditioner.",
        "DOI": "10.3390/su142315550",
        "affiliation_name": "Cockrell School of Engineering",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60150401",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Landslide Susceptibility Mapping Using Deep Neural Network and Convolutional Neural Network",
        "paper_author": "Gong S.H.",
        "publication": "Korean Journal of Remote Sensing",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "Landslides are one of the most prevalent natural disasters, threating both humans and property. Also landslides can cause damage at the national level, so effective prediction and prevention are essential. Research to produce a landslide susceptibility map with high accuracy is steadily being conducted, and various models have been applied to landslide susceptibility analysis. Pixel-based machine learning models such as frequency ratio models, logistic regression models, ensembles models, and Artificial Neural Networks have been mainly applied. Recent studies have shown that the kernel-based convolutional neural network (CNN) technique is effective and that the spatial characteristics of input data have a significant effect on the accuracy of landslide susceptibility mapping. For this reason, the purpose of this study is to analyze landslide vulnerability using a pixel-based deep neural network model and a patch-based convolutional neural network model. The research area was set up in Gangwon-do, including Inje, Gangneung, and Pyeongchang, where landslides occurred frequently and damaged. Landslide-related factors include slope, curvature, stream power index (SPI), topographic wetness index (TWI), topographic position index (TPI), timber diameter, timber age, lithology, land use, soil depth, soil parent material, lineament density, fault density, normalized difference vegetation index (NDVI) and normalized difference water index (NDWI) were used. Landslide-related factors were built into a spatial database through data preprocessing, and landslide susceptibility map was predicted using deep neural network (DNN) and CNN models. The model and landslide susceptibility map were verified through average precision (AP) and root mean square errors (RMSE), and as a result of the verification, the patch-based CNN model showed 3.4% improved performance compared to the pixel-based DNN model. The results of this study can be used to predict landslides and are expected to serve as a scientific basis for establishing land use policies and landslide management policies.",
        "DOI": "10.7780/kjrs.2022.38.6.2.12",
        "affiliation_name": "University of Seoul",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60027652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "PV self-consumption prediction methods using supervised machine learning",
        "paper_author": "Tóth M.",
        "publication": "E3S Web of Conferences",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "The increased prevalence of photovoltaic (PV) self-consumption policies across Europe and the world place an increased importance on accurate predictions for life-cycle costing during the planning phase. This study presents several machine learning and regression models for predicting self-consumption, trained on a variety of datasets from Sweden. The results show that advanced ML models have an improved performance over simpler regressions, where the highest performing model, Random Forest, has a mean average error of 1.5 percentage points and an R2 of 0.977. Training models using widely available typical meteorological year (TMY) climate data is also shown to introduce small, acceptable errors when tested against spatially and temporally matched climate and load data. The ability to train the ML models with TMY climate data makes their adoption easier and builds on previous work by demonstrating the robustness of the methodology as a self-consumption prediction tool. The low error and high R2 are a notable improvement over previous estimation models and the minimal input data requirements make them easy to adopt and apply in a wide array of applications.",
        "DOI": "10.1051/e3sconf/202236202003",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden",
        "affiliation_id": "60002014",
        "affiliation_state": "Stockholms"
    },
    {
        "paper_title": "The Impact of Digital Technologies on Neoclassical Labour Market",
        "paper_author": "Petrová K.",
        "publication": "Danube",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Labour market economics works on the principle of a neoclassical approach. Competitive forces, corporate policy, collective bargaining, and state intervention create the reality of the market. Technological progress in advanced technology, robotics, and artificial intelligence is strengthening the economies of several countries. The article deals with the actual influence of digital technologies on the neoclassical paradigm of the labour market and the impacts on the tasks and requirements for the competencies of workers and the level of their qualifications. Research is based on secondary data from relevant sources with emphasis on the quality using the interface Primo database, enabling the search for data in full-fledged databases (Web of Science, ProQuest, etc.). The real minimum wage, employment rate and jobs at risk of automation were analysed to compare the situation in European countries. The main objective is to analyse the magnitude of the impact of digital technologies on the labour market. The results point to technological progress, especially automation, which eliminates job positions by substituting low-skilled workers with machine learning robots. Government can ensure more balanced inclusive growth in the area of education. The change in the concept of teaching leads to higher qualifications and skills for future employees.",
        "DOI": "10.2478/danb-2022-0020",
        "affiliation_name": "Brno University of Technology",
        "affiliation_city": "Brno",
        "affiliation_country": "Czech Republic",
        "affiliation_id": "60013826",
        "affiliation_state": "South Moravian Region"
    },
    {
        "paper_title": "Manufacturing Resource Scheduling Based on Deep Q-Network",
        "paper_author": "Zhang Y.",
        "publication": "Wuhan University Journal of Natural Sciences",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "To optimize machine allocation and task dispatching in smart manufacturing factories, this paper proposes a manufacturing resource scheduling framework based on reinforcement learning (RL). The framework formulates the entire scheduling process as a multi-stage sequential decision problem, and further obtains the scheduling order by the combination of deep convolutional neural network (CNN) and improved deep Q-network (DQN). Specifically, with respect to the representation of the Markov decision process (MDP), the feature matrix is considered as the state space and a set of heuristic dispatching rules are denoted as the action space. In addition, the deep CNN is employed to approximate the state-action values, and the double dueling deep Q-network with prioritized experience replay and noisy network (D3QPN2) is adopted to determine the appropriate action according to the current state. In the experiments, compared with the traditional heuristic method, the proposed method is able to learn high-quality scheduling policy and achieve shorter makespan on the standard public datasets.",
        "DOI": "10.1051/wujns/2022276531",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60073652",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Passive and Privacy-Preserving Human Localization: A Social Distancing Approach Using Commercial Millimeter-Wave Access Points",
        "paper_author": "Devoti F.",
        "publication": "IEEE Vehicular Technology Magazine",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "The pandemic outbreak has profoundly changed our life, especially our social habits and communication behaviors. While this dramatic shock has heavily impacted human interaction rules, novel localization techniques are emerging to help society in complying with new policies, such as social distancing. Wireless sensing and machine learning are well suited to alleviate virus propagation in a privacy-preserving manner. However, their wide deployment requires cost-effective installation and operational solutions.",
        "DOI": "10.1109/MVT.2022.3202025",
        "affiliation_name": "NEC Laboratories Europe GmbH",
        "affiliation_city": "Heidelberg",
        "affiliation_country": "Germany",
        "affiliation_id": "60078342",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Energy saving strategy of cloud data computing based on convolutional neural network and policy gradient algorithm",
        "paper_author": "Yang D.",
        "publication": "PLoS ONE",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Cloud Data Computing (CDC) is conducive to precise energy-saving management of user data centers based on the real-time energy consumption monitoring of Information Technology equipment. This work aims to obtain the most suitable energy-saving strategies to achieve safe, intelligent, and visualized energy management. First, the theory of Convolutional Neural Network (CNN) is discussed. Besides, an intelligent energy-saving model based on CNN is designed to ameliorate the variable energy consumption, load, and power consumption of the CDC data center. Then, the core idea of the policy gradient (PG) algorithm is introduced. In addition, a CDC task scheduling model is designed based on the PG algorithm, aiming at the uncertainty and volatility of the CDC scheduling tasks. Finally, the performance of different neural network models in the training process is analyzed from the perspective of total energy consumption and load optimization of the CDC center. At the same time, simulation is performed on the CDC task scheduling model based on the PG algorithm to analyze the task scheduling demand. The results demonstrate that the energy consumption of the CNN algorithm in the CDC energy-saving model is better than that of the Elman algorithm and the ecoCloud algorithm. Besides, the CNN algorithm reduces the number of virtual machine migrations in the CDC energy-saving model by 9.30% compared with the Elman algorithm. The Deep Deterministic Policy Gradient (DDPG) algorithm performs the best in task scheduling of the cloud data center, and the average response time of the DDPG algorithm is 141. In contrast, the Deep Q Network algorithm performs poorly. This paper proves that Deep Reinforcement Learning (DRL) and neural networks can reduce the energy consumption of CDC and improve the completion time of CDC tasks, offering a research reference for CDC resource scheduling.",
        "DOI": "10.1371/journal.pone.0279649",
        "affiliation_name": "Xinjiang University",
        "affiliation_city": "Urumqi",
        "affiliation_country": "China",
        "affiliation_id": "60015780",
        "affiliation_state": "Xinjiang"
    },
    {
        "paper_title": "Data Exploration and Classification of News Article Reliability: Deep Learning Study",
        "paper_author": "Zhan K.",
        "publication": "JMIR Infodemiology",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "Background: During the ongoing COVID-19 pandemic, we are being exposed to large amounts of information each day. This \"infodemic\"is defined by the World Health Organization as the mass spread of misleading or false information during a pandemic. This spread of misinformation during the infodemic ultimately leads to misunderstandings of public health orders or direct opposition against public policies. Although there have been efforts to combat misinformation spread, current manual fact-checking methods are insufficient to combat the infodemic. Objective: We propose the use of natural language processing (NLP) and machine learning (ML) techniques to build a model that can be used to identify unreliable news articles online. Methods: First, we preprocessed the ReCOVery data set to obtain 2029 English news articles tagged with COVID-19 keywords from January to May 2020, which are labeled as reliable or unreliable. Data exploration was conducted to determine major differences between reliable and unreliable articles. We built an ensemble deep learning model using the body text, as well as features, such as sentiment, Empath-derived lexical categories, and readability, to classify the reliability. Results: We found that reliable news articles have a higher proportion of neutral sentiment, while unreliable articles have a higher proportion of negative sentiment. Additionally, our analysis demonstrated that reliable articles are easier to read than unreliable articles, in addition to having different lexical categories and keywords. Our new model was evaluated to achieve the following performance metrics: 0.906 area under the curve (AUC), 0.835 specificity, and 0.945 sensitivity. These values are above the baseline performance of the original ReCOVery model. Conclusions: This paper identified novel differences between reliable and unreliable news articles; moreover, the model was trained using state-of-the-art deep learning techniques. We aim to be able to use our findings to help researchers and the public audience more easily identify false information and unreliable media in their everyday lives.",
        "DOI": "10.2196/38839",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada",
        "affiliation_id": "60030835",
        "affiliation_state": "AB"
    },
    {
        "paper_title": "Behavioral Repertoire via Generative Adversarial Policy Networks",
        "paper_author": "Jegorova M.",
        "publication": "IEEE Transactions on Cognitive and Developmental Systems",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Learning algorithms are enabling robots to solve increasingly challenging real-world tasks. These approaches often rely on demonstrations and reproduce the behavior shown. Unexpected changes in the environment or in robot morphology may require using different behaviors to achieve the same effect, for instance, to reach and grasp an object in changing clutter. An emerging paradigm addressing this robustness issue is to learn a diverse set of successful behaviors for a given task, from which a robot can select the most suitable policy when faced with a new environment. In this article, we explore a novel realization of this vision by learning a generative model over policies. Rather than learning a single policy, or a small fixed repertoire, our generative model for policies compactly encodes an unbounded number of policies and allows novel controller variants to be sampled. Leveraging our generative policy network, a robot can sample novel behaviors until it finds one that works for a new scenario. We demonstrate this idea with an application of robust ball throwing in the presence of obstacles, as well as joint-damage-robust throwing. We show that this approach achieves a greater diversity of behaviors than an existing evolutionary approach, while maintaining good efficacy of sampled behaviors, allowing a Baxter robot to hit targets more often when ball throwing in the presence of varying obstacles or joint impediments.",
        "DOI": "10.1109/TCDS.2020.3008574",
        "affiliation_name": "Institut des Systèmes Intelligents et de Robotique",
        "affiliation_city": "Paris",
        "affiliation_country": "France",
        "affiliation_id": "60069769",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Inferring turbulent environments via machine learning",
        "paper_author": "Buzzicotti M.",
        "publication": "European Physical Journal E",
        "citied_by": "6",
        "cover_date": "2022-12-01",
        "Abstract": "Abstract: The problem of classifying turbulent environments from partial observation is key for some theoretical and applied fields, from engineering to earth observation and astrophysics, e.g., to precondition searching of optimal control policies in different turbulent backgrounds, to predict the probability of rare events and/or to infer physical parameters labeling different turbulent setups. To achieve such goal one can use different tools depending on the system’s knowledge and on the quality and quantity of the accessible data. In this context, we assume to work in a model-free setup completely blind to all dynamical laws, but with a large quantity of (good quality) data for training. As a prototype of complex flows with different attractors, and different multi-scale statistical properties we selected 10 turbulent ‘ensembles’ by changing the rotation frequency of the frame of reference of the 3d domain and we suppose to have access to a set of partial observations limited to the instantaneous kinetic energy distribution in a 2d plane, as it is often the case in geophysics and astrophysics. We compare results obtained by a machine learning (ML) approach consisting of a state-of-the-art deep convolutional neural network (DCNN) against Bayesian inference which exploits the information on velocity and entropy moments. First, we discuss the supremacy of the ML approach, presenting also results at changing the number of training data and of the hyper-parameters. Second, we present an ablation study on the input data aimed to perform a ranking on the importance of the flow features used by the DCNN, helping to identify the main physical contents used by the classifier. Finally, we discuss the main limitations of such data-driven methods and potential interesting applications. Graphical Abstract: [Figure not available: see fulltext.].",
        "DOI": "10.1140/epje/s10189-022-00258-3",
        "affiliation_name": "Università degli Studi di Roma \"Tor Vergata\"",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy",
        "affiliation_id": "60027509",
        "affiliation_state": "RM"
    },
    {
        "paper_title": "Achieving Brazil's Deforestation Target Will Reduce Fire and Deliver Air Quality and Public Health Benefits",
        "paper_author": "Butt E.W.",
        "publication": "Earth's Future",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Climate, deforestation, and forest fires are closely coupled in the Amazon, but models of fire that include these interactions are lacking. We trained machine learning models on temperature, rainfall, deforestation, land-use, and fire data to show that spatial and temporal patterns of fire in the Amazon are strongly modified by deforestation. We find that fire count across the Brazilian Amazon increases by 0.44 percentage points for each percentage point increase in deforestation rate. We used the model to predict that the increased deforestation rate in the Brazilian Amazon from 2013 to 2020 caused a 42% increase in fire counts in 2020. We predict that if Brazil had achieved the deforestation target under the National Policy on Climate Change, there would have been 32% fewer fire counts across the Brazilian Amazon in 2020. Using a regional chemistry-climate model and exposure-response associations, we estimate that the improved air quality due to reduced smoke emission under this scenario would have resulted in 2,300 fewer deaths due to reduced exposure to fine particulate matter. Our analysis demonstrates the air quality and public health benefits that would accrue from reducing deforestation in the Brazilian Amazon.",
        "DOI": "10.1029/2022EF003048",
        "affiliation_name": "Universität Augsburg",
        "affiliation_city": "Augsburg",
        "affiliation_country": "Germany",
        "affiliation_id": "60016060",
        "affiliation_state": "Bayern"
    },
    {
        "paper_title": "Analysis of Spatial Concentration of Accommodation Establishments Using Machine Learning Techniques and Spatial Analysis Tools",
        "paper_author": "Parra H.",
        "publication": "Journal of Environmental Management and Tourism",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Tourism as an economic activity is influenced by social dynamics that can be measured by spatial analysis processes where phenomena such as concentration, trajectory and extension are evidenced, which can guide policy makers effectively for decision-making. In this document, the results of a study of spatial analysis of the concentration of accommodation establishments in the department of Boyacá, Colombia are presented in order to identify the correlation that exists between the territorial concentration, the natural attractions of the department and the type of establishment. It was found that there is evidence of a strong concentration in five clusters associated with three municipalities of the department's offer, however it is observed that statistically there is a high level of dispersion of the establishments explained by the road corridors and a growing development towards the natural attractions which are not fully covered by the current offer.",
        "DOI": "10.14505/jemt.v13.8(64).18",
        "affiliation_name": "Universidad Santo Tomás",
        "affiliation_city": "Bogota",
        "affiliation_country": "Colombia",
        "affiliation_id": "60104910",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Data Mining and Visualisation of Basic Educational Resources for Quality Education",
        "paper_author": "Inusah F.",
        "publication": "International Journal of Engineering Trends and Technology",
        "citied_by": "11",
        "cover_date": "2022-12-01",
        "Abstract": "With an increase in educational resources for the growing population, data for Basic Education (BE) is becoming larger, requiring technical data tools to analyze and interpret. This research uses classification and clustering techniques to analyze the data from public schools in Ghana to identify the challenges. Nine (9) data mining algorithms in rapid miner studio 9.10 were used for the analysis to know the most efficient algorithm suitable for the data. These are; Generalized Linear Module (GLM), Naïve Bayes (NB), Logistic Regression (LR), Deep Learning (DL), Decision Tree (DT), Fast Large Margins (FLM), Gradient Boosted Tree (GBT), Random Forest (RF), and Support Vector Machines (SVM). The performance of GBT was seen as more appropriate, and this algorithm's results were presented. Excerpts from the reports are also included in the form of qualitative data. A diagrammatic representation of the interoperability among levels of education for quality education has also been presented. A proposed Neural Network model has been designed for the challenges and solutions. The conclusions draw that addressing the challenges of BE requires educational policy stability and enforcement to maximize resources and minimize the challenges in schools at all levels of education.",
        "DOI": "10.14445/22315381/IJETT-V70I12P228",
        "affiliation_name": "University for Development Studies Ghana",
        "affiliation_city": "Tamale",
        "affiliation_country": "Ghana",
        "affiliation_id": "60071894",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Statistics and Machine Learning in Aviation Environmental Impact Analysis: A Survey of Recent Progress",
        "paper_author": "Gao Z.",
        "publication": "Aerospace",
        "citied_by": "15",
        "cover_date": "2022-12-01",
        "Abstract": "The rapid growth of global aviation operations has made its negative environmental impact an international concern. Accurate modeling of aircraft fuel burn, emissions, and noise is the prerequisite for informing new operational procedures, technologies, and policies towards a more sustainable future of aviation. In the past decade, due to the advances in big data technologies and effective algorithms, the transformative data-driven analysis has begun to play a substantial role in aviation environmental impact analysis. The integration of statistical and machine learning methods in the workflow has made such analysis more efficient and accurate. Through summarizing and classifying the representative works in this intersection area, this survey paper aims to extract prevailing research trends and suggest research opportunities for the future. The methodology overview section presents a comprehensive development process and landscape of statistical and machine learning methods for applied researchers. In the main section, relevant works in the literature are organized into seven application themes: data reduction, efficient computation, predictive modeling, uncertainty quantification, pattern discovery, verification and validation, and infrastructure and tools. Each theme contains background information, in-depth discussion, and a summary of representative works. The paper concludes with the proposal of five future opportunities for this research area.",
        "DOI": "10.3390/aerospace9120750",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60136858",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Comparison of Machine Learning-Based Prediction of Qualitative and Quantitative Digital Soil-Mapping Approaches for Eastern Districts of Tamil Nadu, India",
        "paper_author": "Kumaraperumal R.",
        "publication": "Land",
        "citied_by": "12",
        "cover_date": "2022-12-01",
        "Abstract": "The soil–environmental relationship identified and standardised over the years has expedited the growth of digital soil-mapping techniques; hence, various machine learning algorithms are involved in predicting soil attributes. Therefore, comparing the different machine learning algorithms is essential to provide insights into the performance of the different algorithms in predicting soil information for Indian landscapes. In this study, we compared a suite of six machine learning algorithms to predict quantitative (Cubist, decision tree, k-NN, multiple linear regression, random forest, support vector regression) and qualitative (C5.0, k-NN, multinomial logistic regression, naïve Bayes, random forest, support vector machine) soil information separately at a regional level. The soil information, including the quantitative (pH, OC, and CEC) and qualitative (order, suborder, and great group) attributes, were extracted from the legacy soil maps using stratified random sampling procedures. A total of 4479 soil observations sampled were non-spatially partitioned and intersected with 39 environmental covariate parameters. The predicted maps depicted the complex soil–environmental relationships for the study area at a 30 m spatial resolution. The comparison was facilitated based on the evaluation metrics derived from the test datasets and visual interpretations of the predicted maps. Permutation feature importance analysis was utilised as the model-agnostic interpretation tool to determine the contribution of the covariate parameters to the model’s calibration. The R2 values for the pH, OC, and CEC ranged from 0.19 to 0.38; 0.04 to 0.13; and 0.14 to 0.40, whereas the RMSE values ranged from 0.75 to 0.86; 0.25 to 0.26; and 8.84 to 10.49, respectively. Irrespective of the algorithms, the overall accuracy percentages for the soil order, suborder, and great group class ranged from 31 to 67; 26 to 65; and 27 to 65, respectively. The tree-based ensemble random forest and rule-based tree models’ (Cubist and C5.0) algorithms efficiently predicted the soil properties spatially. However, the efficiency of the other models can be substantially increased by advocating additional parameterisation measures. The range and scale of the quantitative soil attributes, in addition to the sampling frequency and design, greatly influenced the model’s output. The comprehensive comparison of the algorithms can be utilised to support model selection and mapping at a varied scale. The derived digital soil maps will help farmers and policy makers to adopt precision information for making decisions at the farm level leading to productivity enhancements through the optimal use of nutrients and the sustainability of the agricultural ecosystem, ensuring food security.",
        "DOI": "10.3390/land11122279",
        "affiliation_name": "Tamil Nadu Agricultural University",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India",
        "affiliation_id": "60025123",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "A New Framework for Winter Wheat Yield Prediction Integrating Deep Learning and Bayesian Optimization",
        "paper_author": "Di Y.",
        "publication": "Agronomy",
        "citied_by": "24",
        "cover_date": "2022-12-01",
        "Abstract": "Early prediction of winter wheat yield at the regional scale is essential for food policy making and food security, especially in the context of population growth and climate change. Agricultural big data and artificial intelligence (AI) are key technologies for smart agriculture, bringing cost-effective solutions to the agricultural sector. Deep learning-based crop yield forecast has currently emerged as one of the key methods for guiding agricultural production. In this study, we proposed a Bayesian optimization-based long- and short-term memory model (BO-LSTM) to construct a multi-source data fusion-driven crop growth feature extraction algorithm for winter wheat yield prediction. The yield prediction performance of BO-LSTM, support vector machine (SVM), and least absolute shrinkage and selection operator (Lasso) was then compared with multi-source data as input variables. The results showed that effective deep learning hyperparameter optimization is made possible by Bayesian optimization. The BO-LSTM (RMSE = 177.84 kg/ha, R2 = 0.82) model had the highest accuracy of yield prediction with the input combination of “GPP + Climate + LAI + VIs”. BO-LSTM and SVM (RMSE = 185.7 kg/ha, R2 = 0.80) methods outperformed linear regression Lasso (RMSE = 214.5 kg/ha, R2 = 0.76) for winter wheat yield estimation. There were also differences between machine learning and deep learning, BO-LSTM outperformed SVM. indicating that the BO-LSTM model was more effective at capturing data correlations. In order to further verify the robustness of the BO-LSTM method, we explored the performance estimation performance of BO-LSTM in different regions. The results demonstrated that the BO-LSTM model could obtain higher estimation accuracy in regions with concentrated distribution of winter wheat cultivation and less influence of human factors. The approach used in this study can be expected to forecast crop yields, both in regions with a deficit of data and globally; it can also simply and effectively forecast winter wheat yields in a timely way utilizing publicly available multi-source data.",
        "DOI": "10.3390/agronomy12123194",
        "affiliation_name": "Ministry of Agriculture of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60087826",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Information in Streetscapes—Research on Visual Perception Information Quantity of Street Space Based on Information Entropy and Machine Learning",
        "paper_author": "Liu Z.",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "Urban street space is a critical reflection of a city’s vitality and image and a critical component of urban planning. While visual perceptual information about an urban street space can reflect the composition of place elements and spatial relationships, it lacks a unified and comprehensive quantification system. It is frequently presented in the form of element proportions without accounting for realistic factors, such as occlusion, light and shadow, and materials, making it difficult for the data to accurately describe the complex information found in real scenes. The conclusions of related studies are insufficiently focused to serve as a guide for designing solutions, remaining merely theoretical paradigms. As such, this study employed semantic segmentation and information entropy models to generate four visual perceptual information quantity (VPIQ) measures of street space: (1) form; (2) line; (3) texture; and (4) color. Then, at the macro level, the streetscape coefficient of variation (SCV) and K-means cluster entropy (HCK) were proposed to quantify the street’s spatial variation characteristics based on VPIQ. Additionally, we used geographically weighted regression (GWR) to investigate the relationship between VPIQ and street elements at the meso level as well as its practical application. This method can accurately and objectively describe and detect the current state of street spaces, assisting urban planners and decision-makers in making decisions about planning policies, urban regeneration schemes, and how to manage the street environment.",
        "DOI": "10.3390/ijgi11120628",
        "affiliation_name": "PowerChina Huadong Engineering Corporation Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60274761",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Phenological normalization can improve in-season classification of maize and soybean: A case study in the central US Corn Belt",
        "paper_author": "Kerner H.R.",
        "publication": "Science of Remote Sensing",
        "citied_by": "11",
        "cover_date": "2022-12-01",
        "Abstract": "Within-season estimates of crop-specific planted area, conditions, and expected yields are critical for decision- and policy-making related to agriculture and food security. However, these estimates require in-season crop type maps which are not currently widely available. Machine learning and remote sensing data can be used to create crop type maps that provide crop-specific land cover classifications to enable timely analysis at field scales throughout the growing season to complement traditional reporting efforts. However, existing methods are often limited by lower performance on test data from seasons with different patterns not seen during training and inability to provide classifications during the growing season when most operationally relevant. We present a new approach to in-season crop type mapping that addresses inter-annual domain shift by normalizing satellite observations by land surface phenology stage. These phenology-normalized observations are input to a neural network that extracts temporal and spatial features using both recurrent and convolutional layers respectively. Using Harmonized Landsat and Sentinel-2 (HLS) and Sentinel-1 SAR observations with test data from the U.S. states of Iowa in 2019 (late planting year) and Illinois in 2020 (standard year), we showed that this method enabled good performance in both scenarios throughout the growing season (71% and 72% in early-season, 80% and 84% in mid-season, 81% and 85% in late-season for Iowa 2019 and Illinois 2020 respectively).",
        "DOI": "10.1016/j.srs.2022.100059",
        "affiliation_name": "United States Department of Agriculture",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60032280",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Detecting and Quantifying Structural Breaks in Climate",
        "paper_author": "Ericsson N.R.",
        "publication": "Econometrics",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "Structural breaks have attracted considerable attention recently, especially in light of the financial crisis, Great Recession, the COVID-19 pandemic, and war. While structural breaks pose significant econometric challenges, machine learning provides an incisive tool for detecting and quantifying breaks. The current paper presents a unified framework for analyzing breaks; and it implements that framework to test for and quantify changes in precipitation in Mauritania over 1919–1997. These tests detect a decline of one third in mean rainfall, starting around 1970. Because water is a scarce resource in Mauritania, this decline—with adverse consequences on food production—has potential economic and policy consequences.",
        "DOI": "10.3390/econometrics10040033",
        "affiliation_name": "Johns Hopkins University School of Advanced International Studies",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States",
        "affiliation_id": "60025786",
        "affiliation_state": "DC"
    },
    {
        "paper_title": "Improving Public Health Policy by Comparing the Public Response during the Start of COVID-19 and Monkeypox on Twitter in Germany: A Mixed Methods Study",
        "paper_author": "AL-Ahdal T.",
        "publication": "Vaccines",
        "citied_by": "6",
        "cover_date": "2022-12-01",
        "Abstract": "Little is known about monkeypox public concerns since its widespread emergence in many countries. Tweets in Germany were examined in the first three months of COVID-19 and monkeypox to examine concerns and issues raised by the public. Understanding views and positions of the public could help to shape future public health campaigns. Few qualitative studies reviewed large datasets, and the results provide the first instance of the public thinking comparing COVID-19 and monkeypox. We retrieved 15,936 tweets from Germany using query words related to both epidemics in the first three months of each one. A sequential explanatory mixed methods research joined a machine learning approach with thematic analysis using a novel rapid tweet analysis protocol. In COVID-19 tweets, there was the selfing construct or feeling part of the emerging narrative of the spread and response. In contrast, during monkeypox, the public considered othering after the fatigue of the COVID-19 response, or an impersonal feeling toward the disease. During monkeypox, coherence and reconceptualization of new and competing information produced a customer rather than a consumer/producer model. Public healthcare policy should reconsider a one-size-fits-all model during information campaigns and produce a strategic approach embedded within a customer model to educate the public about preventative measures and updates. A multidisciplinary approach could prevent and minimize mis/disinformation.",
        "DOI": "10.3390/vaccines10121985",
        "affiliation_name": "Braunschweiger Zentrum für Systembiologie",
        "affiliation_city": "Braunschweig",
        "affiliation_country": "Germany",
        "affiliation_id": "60203637",
        "affiliation_state": "Niedersachsen"
    },
    {
        "paper_title": "Deep Reinforcement Learning for Flow Control Exploits Different Physics for Increasing Reynolds Number Regimes",
        "paper_author": "Varela P.",
        "publication": "Actuators",
        "citied_by": "21",
        "cover_date": "2022-12-01",
        "Abstract": "The increase in emissions associated with aviation requires deeper research into novel sensing and flow-control strategies to obtain improved aerodynamic performances. In this context, data-driven methods are suitable for exploring new approaches to control the flow and develop more efficient strategies. Deep artificial neural networks (ANNs) used together with reinforcement learning, i.e., deep reinforcement learning (DRL), are receiving more attention due to their capabilities of controlling complex problems in multiple areas. In particular, these techniques have been recently used to solve problems related to flow control. In this work, an ANN trained through a DRL agent, coupled with the numerical solver Alya, is used to perform active flow control. The Tensorforce library was used to apply DRL to the simulated flow. Two-dimensional simulations of the flow around a cylinder were conducted and an active control based on two jets located on the walls of the cylinder was considered. By gathering information from the flow surrounding the cylinder, the ANN agent is able to learn through proximal policy optimization (PPO) effective control strategies for the jets, leading to a significant drag reduction. Furthermore, the agent needs to account for the coupled effects of the friction- and pressure-drag components, as well as the interaction between the two boundary layers on both sides of the cylinder and the wake. In the present work, a Reynolds number range beyond those previously considered was studied and compared with results obtained using classical flow-control methods. Significantly different forms of nature in the control strategies were identified by the DRL as the Reynolds number (Formula presented.) increased. On the one hand, for (Formula presented.), the classical control strategy based on an opposition control relative to the wake oscillation was obtained. On the other hand, for (Formula presented.), the new strategy consisted of energization of the boundary layers and the separation area, which modulated the flow separation and reduced the drag in a fashion similar to that of the drag crisis, through a high-frequency actuation. A cross-application of agents was performed for a flow at (Formula presented.), obtaining similar results in terms of the drag reduction with the agents trained at (Formula presented.) and 2000. The fact that two different strategies yielded the same performance made us question whether this Reynolds number regime ((Formula presented.)) belongs to a transition towards a nature-different flow, which would only admits a high-frequency actuation strategy to obtain the drag reduction. At the same time, this finding allows for the application of ANNs trained at lower Reynolds numbers, but are comparable in nature, saving computational resources.",
        "DOI": "10.3390/act11120359",
        "affiliation_name": "Centro Nacional de Supercomputación",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain",
        "affiliation_id": "60097745",
        "affiliation_state": "Barcelona"
    },
    {
        "paper_title": "Research on the Effectiveness of Deep Learning−Based Agency Cost Suppression Strategy: A Case Study of State−Owned Enterprises in Mainland China",
        "paper_author": "Zhai D.",
        "publication": "Systems",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "The mixed ownership reform aims to improve the property rights structure of the state−owned enterprises (SOEs) and reduce agency costs, and the current mixed reform strategies mainly include equity blending by introducing external non−state capital, executive assignments, and employee stock ownership. In this paper, 953 valid data of A−shares listed in Shanghai and Shenzhen from 2008 to 2020 are used as samples to construct the indicators of mixed reform strategy by the literature statistics method. After obtaining multiple impact indicators, the regression impact model of corporate agency cost suppression strategy is constructed by MATLAB software using a machine learning algorithm. On this basis, the performance of multiple machine learning algorithms is compared, and it is found that the integrated optimization−based bag−boosting model is used to study the effect of hybrid reform strategy to reduce the agency costs of SOEs, and the proportional setting of indicators when the effect is optimal is also explored. Finally, the laws of different influencing factors on the agency costs of enterprises are explored separately by the eigenvalue method. The results of the study show that the proportion of shareholding of the first largest non−state shareholder is sin−functional with the agency costs of SOEs when non−state majority shareholders are introduced into SOEs’ equity mix, and the agency costs tend to decrease after SOEs become privately held enterprises. The greater the number and proportion of supervisors appointed by non−state shareholders, the greater the supervisory restraint effect on SOE managers and the better the effect of suppressing agency costs. The participation of non−state−owned shareholders in the company’s business decisions by appointed executives and the special resource advantages of SOEs intensify the occurrence of the self−interest of appointed executives and the increase of agency costs of SOEs. The implementation of an employee stock ownership plan plays the role of employee supervision and restraint on SOE managers, which reduces the agency costs of SOEs. Based on this, it can provide support for the government to improve the hybrid reform policy and promote the process layer by layer, and also provide theoretical reference for SOEs to deepen the equity mix, incentivize employee shareholding, and empower non−state shareholders to govern and thus reduce agency costs.",
        "DOI": "10.3390/systems10060242",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60019616",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Reducing Children’s Obesity in the Age of Telehealth and AI/IoT Technologies in Gulf Countries",
        "paper_author": "Faisal M.",
        "publication": "Systems",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "Childhood obesity has become one of the major health issues in the global population. The increasing prevalence of childhood obesity is associated with serious health issues and comorbidities related to obesity. Several studies mentioned that childhood obesity became even worse recently due to the effect of COVID-19 and the consequent policies and regulations. For that reason, Internet of Things (IoT) technologies should be utilized to overcome the challenges related to obesity management and provide care from a distance to improve the health care services for obesity. However, IoT by itself is a limited resource and it is important to consider other artificial intelligent (AI) components. Thus, this paper contributes into the literature of child obesity management by introducing a comprehensive survey for obesity management covering clinical work measuring the association between sleep disturbances and childhood obesity alongside physical activity and diet and comparatively analyzing the emerging technologies used to prevent childhood obesity. It further contributes to the literature by proposing an interactive smart framework that combines clinical and emerging AI/telehealth technologies to manage child obesity. The proposed framework can be used to reduce children obesity and improve their quality of life using Machine Learning (ML). It utilizes IoT devices to integrate information from different sources and complement it with a mobile application and web-based platform to connect parents and physicians with their child.",
        "DOI": "10.3390/systems10060241",
        "affiliation_name": "Kuwait College of Science &amp; Technology",
        "affiliation_city": "Doha",
        "affiliation_country": "Kuwait",
        "affiliation_id": "60121848",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "DRLLA: Deep Reinforcement Learning for Link Adaptation",
        "paper_author": "Geiser F.",
        "publication": "Telecom",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "Link adaptation (LA) matches transmission parameters to conditions on the radio link, and therefore plays a major role in telecommunications. Improving LA is within the requirements for next-generation mobile telecommunication systems, and by refining link adaptation, a higher channel efficiency can be achieved (i.e., an increased data rate thanks to lower required bandwidth). Furthermore, by replacing traditional LA algorithms, radio transmission systems can better adapt themselves to a dynamic environment. There are several drawbacks to current state-of-the-art approaches, including predefined and static decision boundaries or relying on a single, low-dimensional metric. Nowadays, a broadly used approach to handle a variety of related input variables is a neural network (NN). NNs are able to make use of multiple inputs, and when combined with reinforcement learning (RL), the so-called deep reinforcement learning (DRL) approach emerges. Using DRL, more complex parameter relationships can be considered in order to recommend the modulation and coding scheme (MCS) used in LA. Hence, this work examines the potential of DRL and includes experiments on different channels. The main contribution of this work lies in using DRL algorithms for LA, optimized for throughput based on a subcarrier observation matrix and a packet success rate feedback system. We apply Natural Actor-Critic (NAC) and Proximal Policy Optimization (PPO) algorithms on simulated channels with a subsequent feasibility study on a prerecorded real-world channel. Empirical results produced by experiments on the examined channels hint that Deep Reinforcement Learning for Link Adaptation (DRLLA) offers good performance indicated by a promising data rate on the additive white Gaussian noise (AWGN) channel, the non-line-of-sight (NLOS) channel, and a prerecorded real-world channel. No matter the channel impairment, the agent is able to respond to changing signal-to-interference-plus-noise-ratio (SINR) levels, as exhibited by expected changes in the effective data rate.",
        "DOI": "10.3390/telecom3040037",
        "affiliation_name": "Nokia Bell Labs",
        "affiliation_city": "Murray",
        "affiliation_country": "United States",
        "affiliation_id": "60021378",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "A Time Series Model Based on Deep Learning and Integrated Indicator Selection Method for Forecasting Stock Prices and Evaluating Trading Profits",
        "paper_author": "Cheng C.H.",
        "publication": "Systems",
        "citied_by": "10",
        "cover_date": "2022-12-01",
        "Abstract": "A stock forecasting and trading system is a complex information system because a stock trading system needs to be analyzed and modeled using data science, machine learning, and artificial intelligence. Previous time series models have been widely used to forecast stock prices, but due to several shortcomings, these models cannot apply all available information to make a forecast. The relationship between stock prices and related factors is nonlinear and involves nonstationary fluctuations, and accurately forecasting stock prices is not an easy task. Therefore, this study used support vector machines (linear and radial basis functions), gene expression programming, multilayer perceptron regression, and generalized regression neural networks to calculate the importance of indicators. We then integrated the five indicator selection methods to find the key indicators. Next, we used long short-term memory (LSTM) and gated recurrent units (GRU) to build time series models for forecasting stock prices and compare them with the listing models. To evaluate the effectiveness of the proposed model, we collected six different stock market data from 2011 to 2019 to evaluate their forecast performance based on RMSE and MAPE metrics. It is worth mentioning that this study proposes two trading policies to evaluate trading profits and compare them with the listing methods, and their profits are pretty good to investors. After the experiments, the proposed time series model (GRU/LSTM combined with the selected key indicators) exhibits better forecast ability in fluctuating and non-fluctuating environments than the listing models, thus presenting an effective reference for stakeholders.",
        "DOI": "10.3390/systems10060243",
        "affiliation_name": "I-Shou University",
        "affiliation_city": "Kaohsiung",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60024908",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting VO<inf>2</inf>max in Children and Adolescents Aged between 6 and 17 Using Physiological Characteristics and Participation in Sport Activities: A Cross-Sectional Study Comparing Different Regression Models Stratified by Gender",
        "paper_author": "Carayanni V.",
        "publication": "Children",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Background: The aim of this study is to use different regression models to capture the association between cardiorespiratory fitness VO2max (measured in mL/kg/min) and somatometric characteristics and sports activities and making better predictions. Methods: multiple linear regression (MLR), quantile regression (QR), ridge regression (RR), support vector regression (SVR) with three different kernels, artificial neural networks (ANNs), and boosted regression trees (RTs) were compared to explain and predict VO2max and to choose the best performance model. The sample consisted of 4908 children (2314 males and 2594 females) aged between 6 and 17. Cardiorespiratory fitness was assessed by the 20 m maximal multistage shuttle run test and maximal oxygen uptake (VO2max) was calculated. Welch t-tests, Mann–Whitney-U tests, X2 tests, and ANOVA tests were performed. The performance measures were root mean square error (RMSE), mean absolute error (MAE), and coefficient of determination (R2). All analyses were stratified by gender. Results: A comparison of the statistical indices for both the predicted and actual data indicated that in boys, the MLR model outperformed all other models in all indices, followed by the linear SVR model. In girls, the MLR model performed better than the other models in R2 but was outperformed by SVR-RBF in terms of RMSE and MAE. The overweight and obesity categories in both sexes (p < 0.001) and maternal prepregnancy obesity in girls had a significant negative effect on VO2max. Age, weekly football training, track and field, basketball, and swimming had different positive effects based on gender. Conclusion: The MLR model showed remarkable performance against all other models and was competitive with the SVR models. In addition, this study’s data showed that changes in cardiorespiratory fitness were dependent, to a different extent based on gender, on BMI category, weight, height, age, and participation in some organized sports activities. Predictors that are not considered modifiable, such as gender, can be used to guide targeted interventions and policies.",
        "DOI": "10.3390/children9121935",
        "affiliation_name": "University of West Attica",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece",
        "affiliation_id": "60110806",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "Reinforcement Learning Control of Hydraulic Servo System Based on TD3 Algorithm",
        "paper_author": "Yuan X.",
        "publication": "Machines",
        "citied_by": "11",
        "cover_date": "2022-12-01",
        "Abstract": "This paper aims at the characteristics of nonlinear, time-varying and parameter coupling in a hydraulic servo system. An intelligent control method is designed that uses self-learning without a model or prior knowledge, in order to achieve certain control effects. The control quantity can be obtained at the current moment through the continuous iteration of a strategy–value network, and the online self-tuning of parameters can be realized. Taking the hydraulic servo system as the experimental object, a twin delayed deep deterministic (TD3) policy gradient was used to reinforce the learning of the system. Additionally, the parameter setting was compared using a deep deterministic policy gradient (DDPG) and a linear–quadratic–Gaussian (LQG) based on linear quadratic Gaussian objective function. To compile the reinforcement learning algorithm and deploy it to the test platform controller for testing, we used the Speedgoat prototype target machine as the controller to build the fast prototype control test platform. MATLAB/Coder and compute unified device architecture (CUDA) were used to generate an S-function. The results show that, compared with other parameter tuning methods, the proposed algorithm can effectively optimize the controller parameters and improve the dynamic response of the system when tracking signals.",
        "DOI": "10.3390/machines10121244",
        "affiliation_name": "Yanshan University",
        "affiliation_city": "Qinhuangdao",
        "affiliation_country": "China",
        "affiliation_id": "60018465",
        "affiliation_state": "Hebei"
    },
    {
        "paper_title": "Drug Abuse Ontology to Harness Web-Based Data for Substance Use Epidemiology Research: Ontology Development Study",
        "paper_author": "Lokala U.",
        "publication": "JMIR Public Health and Surveillance",
        "citied_by": "10",
        "cover_date": "2022-12-01",
        "Abstract": "Background: Web-based resources and social media platforms play an increasingly important role in health-related knowledge and experience sharing. There is a growing interest in the use of these novel data sources for epidemiological surveillance of substance use behaviors and trends. Objective: The key aims were to describe the development and application of the drug abuse ontology (DAO) as a framework for analyzing web-based and social media data to inform public health and substance use research in the following areas: determining user knowledge, attitudes, and behaviors related to nonmedical use of buprenorphine and illicitly manufactured opioids through the analysis of web forum data Prescription Drug Abuse Online Surveillance; analyzing patterns and trends of cannabis product use in the context of evolving cannabis legalization policies in the United States through analysis of Twitter and web forum data (eDrugTrends); assessing trends in the availability of novel synthetic opioids through the analysis of cryptomarket data (eDarkTrends); and analyzing COVID-19 pandemic trends in social media data related to 13 states in the United States as per Mental Health America reports. Methods: The domain and scope of the DAO were defined using competency questions from popular ontology methodology (101 ontology development). The 101 method includes determining the domain and scope of ontology, reusing existing knowledge, enumerating important terms in ontology, defining the classes, their properties and creating instances of the classes. The quality of the ontology was evaluated using a set of tools and best practices recognized by the semantic web community and the artificial intelligence community that engage in natural language processing. Results: The current version of the DAO comprises 315 classes, 31 relationships, and 814 instances among the classes. The ontology is flexible and can easily accommodate new concepts. The integration of the ontology with machine learning algorithms dramatically decreased the false alarm rate by adding external knowledge to the machine learning process. The ontology is recurrently updated to capture evolving concepts in different contexts and applied to analyze data related to social media and dark web marketplaces. Conclusions: The DAO provides a powerful framework and a useful resource that can be expanded and adapted to a wide range of substance use and mental health domains to help advance big data analytics of web-based data for substance use epidemiology research.",
        "DOI": "10.2196/24938",
        "affiliation_name": "College of Engineering and Computer Science at Wright State University",
        "affiliation_city": "Dayton",
        "affiliation_country": "United States",
        "affiliation_id": "60279413",
        "affiliation_state": "OH"
    },
    {
        "paper_title": "Predicting the Environmental Change of Carbon Emission Patterns in South Asia: A Deep Learning Approach Using BiLSTM",
        "paper_author": "Aamir M.",
        "publication": "Atmosphere",
        "citied_by": "25",
        "cover_date": "2022-12-01",
        "Abstract": "China’s economy has made significant strides in the past three decades. As a direct result of China’s “one belt, one road” (OBOR) initiative, the country’s rate of industrialization and urbanization is currently the fastest in the entire world. This rapid development is largely dependent on the enormous amounts of energy currently being consumed and forms the foundation of the world’s high levels of carbon emissions. It is generally agreed that the production of greenhouse gases, particularly carbon dioxide, is the primary contributor to the current state of climate change. In this paper, a CO2 emission prediction model based on Bi-LSTM is constructed. In order to conduct empirical tests on the model, this study uses data from South Asian countries and China from 2001 to 2020. China’s CO2 emissions from 2022 to 2030 were predicted along with those of other countries in order to study the combined effects of the scientific and technological progress, industrial structures, and energy structure factors affecting CO2 emissions. When compared with the LSTM and GRU methods, the Bi-LSTM model’s results produced lower MAE, MSE, and MAPE values, indicating that it performs better. According to the findings, carbon emissions represent a significant problem that will become much worse in the future due to China and India’s high emissions, particularly in the next 10 years, if the government does not implement policies that help reduce those emissions.",
        "DOI": "10.3390/atmos13122011",
        "affiliation_name": "BUITEMS - Balochistan University of Information Technology, Engineering and Management Sciences",
        "affiliation_city": "Quetta",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60089696",
        "affiliation_state": "Balochistan"
    },
    {
        "paper_title": "A Hybrid Rule-Based and Data-Driven Approach to Illegal Transshipment Identification with Interpretable Behavior Features",
        "paper_author": "Deng L.",
        "publication": "Sensors",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "Illegal transshipment of maritime ships is usually closely related to illegal activities such as smuggling, human trafficking, piracy plunder, and illegal fishing. Intelligent identification of illegal transshipment has become an important technical means to ensure the safety of maritime transport. However, due to different geographical environments, legal policies and regulatory requirements in each sea area, there are differences in the movement characteristics and geographical distribution of illegal transshipment behavior in different time and space. Moreover, in areas with dense traffic flow, normal navigation behavior can easily be identified as illegal transshipment, resulting in a high rate of misidentification. This paper proposes a hybrid rule-based and data-driven approach to solve the problem of missing identification in fixed threshold methods and introduces a traffic density feature to reduce the misidentification rate in dense traffic areas. The method is both interpretable and adaptable through unsupervised clustering to get suitable threshold distribution combination for regulatory sea areas. The evaluation results in two different sea areas show that the proposed method is applicable. Compared with other widely used identification methods, this method identifies more illegal transshipment events, which are highly suspicious, and gives warning much earlier. The proposed method can even filter out misidentification events from compared methods’ results, which account for more than half of the total number.",
        "DOI": "10.3390/s22249581",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022381",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Similarity Analysis in Understanding Online News in Response to Public Health Crisis",
        "paper_author": "Cezario S.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "Background: The “Syphilis No!” campaign the Brazilian Ministry of Health (MoH) launched between November 2018 and March 2019, brought forward the concept \"Test, Treat and Cure\" to remind the population of the importance of syphilis prevention. In this context, this study aims to analyze the similarity of syphilis online news to comprehend how public health communication interventions influence media coverage of the syphilis issue. Methods: This paper presented a computational approach to assess the effectiveness of communication actions on a public health problem. Data were collected between January 2015 and December 2019 and processed using the Hermes ecosystem, which utilizes text mining and machine learning algorithms to cluster similar content. Results: Hermes identified 1049 google-indexed web pages containing the term ’syphilis’ in Brazil. Of these, 619 were categorized as news stories. In total, 157 were grouped into clusters of at least two similar news items and a single cluster with 462 news classified as “single” for not featuring similar news items. From these, 19 clusters were identified in the pre-campaign period, 23 during the campaign, and 115 in the post-campaign. Conclusions: The findings presented in this study show that the volume of syphilis-related news reports has increased in recent years and gained popularity after the SNP started, having been boosted during the campaign and escalating even after its completion.",
        "DOI": "10.3390/ijerph192417049",
        "affiliation_name": "University of Coimbra, Centre for Informatics and System",
        "affiliation_city": "Coimbra",
        "affiliation_country": "Portugal",
        "affiliation_id": "60106440",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessing and mapping soil erosion risk zone in Ratlam District, central India",
        "paper_author": "Saha S.",
        "publication": "Regional Sustainability",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "Evaluation of physical and quantitative data of soil erosion is crucial to the sustainable development of the environment. The extreme form of land degradation through different forms of erosion is one of the major problems in the sub-tropical monsoon-dominated region. In India, tackling soil erosion is one of the major geo-environmental issues for its environment. Thus, identifying soil erosion risk zones and taking preventative actions are vital for crop production management. Soil erosion is induced by climate change, topographic conditions, soil texture, agricultural systems, and land management. In this research, the soil erosion risk zones of Ratlam District was determined by employing the Geographic Information System (GIS), Revised Universal Soil Loss Equation (RUSLE), Analytic Hierarchy Process (AHP), and machine learning algorithms (Random Forest and Reduced Error Pruning (REP) tree). RUSLE measured the rainfall eosivity (R), soil erodibility (K), length of slope and steepness (LS), Land cover and management (C), and support practices (P) factors. Kappa statistic was used to configure model reliability and it was found that Random Forest and AHP have higher reliability than other models. About 14.73% (715.94 km2) of the study area has very low risk to soil erosion, with an average soil erosion rate of 0.00–7.00 × 103 kg/(hm2·a), while about 7.46% (362.52 km2) of the study area has very high risk to soil erosion, with an average soil erosion rate of 30.00 × 103–48.00 × 103 kg/(hm2·a). Slope, elevation, stream density, Stream Power Index (SPI), rainfall, and land use and land cover (LULC) all affect soil erosion. The current study could help the government and non-government agencies to employ developmental projects and policies accordingly. However, the outcomes of the present research also could be used to prevent, monitor, and control soil erosion in the study area by employing restoration measures.",
        "DOI": "10.1016/j.regsus.2022.11.005",
        "affiliation_name": "Raiganj University",
        "affiliation_city": "Raiganj",
        "affiliation_country": "India",
        "affiliation_id": "60209646",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Hand Gesture Recognition Using EMG-IMU Signals and Deep Q-Networks",
        "paper_author": "Vásconez J.P.",
        "publication": "Sensors",
        "citied_by": "14",
        "cover_date": "2022-12-01",
        "Abstract": "Hand gesture recognition systems (HGR) based on electromyography signals (EMGs) and inertial measurement unit signals (IMUs) have been studied for different applications in recent years. Most commonly, cutting-edge HGR methods are based on supervised machine learning methods. However, the potential benefits of reinforcement learning (RL) techniques have shown that these techniques could be a viable option for classifying EMGs. Methods based on RL have several advantages such as promising classification performance and online learning from experience. In this work, we developed an HGR system made up of the following stages: pre-processing, feature extraction, classification, and post-processing. For the classification stage, we built an RL-based agent capable of learning to classify and recognize eleven hand gestures—five static and six dynamic—using a deep Q-network (DQN) algorithm based on EMG and IMU information. The proposed system uses a feed-forward artificial neural network (ANN) for the representation of the agent policy. We carried out the same experiments with two different types of sensors to compare their performance, which are the Myo armband sensor and the G-force sensor. We performed experiments using training, validation, and test set distributions, and the results were evaluated for user-specific HGR models. The final accuracy results demonstrated that the best model was able to reach up to (Formula presented.) and (Formula presented.) for the classification and recognition, respectively, with regard to static gestures, and (Formula presented.) and (Formula presented.) for the classification and recognition, respectively, with regard to dynamic gestures with the Myo armband sensor. The results obtained in this work demonstrated that RL methods such as the DQN are capable of learning a policy from online experience to classify and recognize static and dynamic gestures using EMG and IMU signals.",
        "DOI": "10.3390/s22249613",
        "affiliation_name": "Escuela Politécnica Nacional",
        "affiliation_city": "Quito",
        "affiliation_country": "Ecuador",
        "affiliation_id": "60072054",
        "affiliation_state": "Pichincha"
    },
    {
        "paper_title": "Assessment of water consumption in households using statistical analysis and regression trees",
        "paper_author": "Grespan A.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "29",
        "cover_date": "2022-12-01",
        "Abstract": "Understanding the drivers of water consumption is essential for effective water resources management. This paper evaluates how socioeconomic and demographic variables, construction characteristics and behavioral aspects of residents influence domestic water consumption in the city of Joinville, Southern Brazil, analyzing data from 394 households. Statistical analysis and Univariate Regression Trees were applied to the data set. The results show that the average per capita consumption is 143.67 L/person/day, while the average household monthly water consumption is 14.53 m³/household/month. Amidst the findings in the statistical analysis, socioeconomic aspects such as number of residents, income and presence of children in the household showed an effect on water consumption, as well as building age and typology, number of bathrooms and presence of a bathtub and a swimming pool. The regression trees allowed identifying that the number of residents and area per capita are the variables with greater importance to estimate household and per capita water consumption, respectively. As a key implication of this study, the analysis presented herein provides additional empirical support for the body of knowledge on the factors that influence residential water consumption and can help decision-makers to direct actions and public policies aimed at water conservation in the built environment.",
        "DOI": "10.1016/j.scs.2022.104186",
        "affiliation_name": "Universidade do Estado de Santa Catarina",
        "affiliation_city": "Florianopolis",
        "affiliation_country": "Brazil",
        "affiliation_id": "60024094",
        "affiliation_state": "SC"
    },
    {
        "paper_title": "Discovering mechanisms for materials microstructure optimization via reinforcement learning of a generative model",
        "paper_author": "Vasudevan R.K.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "6",
        "cover_date": "2022-12-01",
        "Abstract": "The design of materials structure for optimizing functional properties and potentially, the discovery of novel behaviors is a keystone problem in materials science. In many cases microstructural models underpinning materials functionality are available and well understood. However, optimization of average properties via microstructural engineering often leads to combinatorically intractable problems. Here, we explore the use of the reinforcement learning (RL) for microstructure optimization targeting the discovery of the physical mechanisms behind enhanced functionalities. We illustrate that RL can provide insights into the mechanisms driving properties of interest in a 2D discrete Landau ferroelectrics simulator. Intriguingly, we find that non-trivial phenomena emerge if the rewards are assigned to favor physically impossible tasks, which we illustrate through rewarding RL agents to rotate polarization vectors to energetically unfavorable positions. We further find that strategies to induce polarization curl can be non-intuitive, based on analysis of learned agent policies. This study suggests that RL is a promising machine learning method for material design optimization tasks, and for better understanding the dynamics of microstructural simulations.",
        "DOI": "10.1088/2632-2153/aca004",
        "affiliation_name": "Oak Ridge National Laboratory",
        "affiliation_city": "Oak Ridge",
        "affiliation_country": "United States",
        "affiliation_id": "60024266",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Unearned premium risk and machine learning techniques",
        "paper_author": "Manathunga V.",
        "publication": "Frontiers in Applied Mathematics and Statistics",
        "citied_by": "2",
        "cover_date": "2022-12-01",
        "Abstract": "Insurance companies typically divide premiums into earned and unearned premiums. Unearned premium is the portion of premium that is allocated for the remaining period of a policy or premium that still needs to be earned. The unearned premium risk arises when an unearned premium is insufficient to cover future losses. Reserves allocated for the unearned premium risk are called premium deficiency reserves (PDRs). PDR received less attention from the actuarial community compared to other reserves such as reserves for reported but not fully settled (RBNS) claims, and incurred but not reported (IBNR) claims. Existing research on PDR mainly focused on utilizing statistical models. In this article, we apply machine learning models to calculate PDR. We use an extended warranty dataset, which comes under long-duration P & C insurance contracts to demonstrate our models. Using two statistical and two machine learning models, we show that machine learning models predict reserves more accurately than the traditional statistical model. Thus, this article encourages actuaries to consider machine learning models when calculating PDRs for the unearned premium risk.",
        "DOI": "10.3389/fams.2022.1056529",
        "affiliation_name": "Middle Tennessee State University",
        "affiliation_city": "Murfreesboro",
        "affiliation_country": "United States",
        "affiliation_id": "60018466",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Revealing underlying factors of absenteeism: A machine learning approach",
        "paper_author": "Bowen F.",
        "publication": "Frontiers in Psychology",
        "citied_by": "5",
        "cover_date": "2022-12-01",
        "Abstract": "Introduction: The basis of support is understanding. In machine learning, understanding happens through assimilated knowledge and is centered on six pillars: big data, data volume, value, variety, velocity, and veracity. This study analyzes school attendance problems (SAP), which encompasses its legal statutes, school codes, students’ attendance behaviors, and interventions in a school environment. The support pillars include attention to the physical classroom, school climate, and personal underlying factors impeding engagement, from which socio-emotional factors are often the primary drivers. Methods: This study asked the following research question: What can we learn about specific underlying factors of absenteeism using machine learning approaches? Data were retrieved from one school system available through the proprietary Building Dreams (BD) platform, owned by the Fight for Life Foundation (FFLF), whose mission is to support youth in underserved communities. The BD platform, licensed to K-12 schools, collects student-level data reported by educators on core values associated with in-class participation (a reported—negative or positive—behavior relative to the core values) based on Social–Emotional Learning (SEL) principles. We used a multi-phased approach leveraging several machine learning techniques (clustering, qualitative analysis, classification, and refinement of supervised and unsupervised learning). Unsupervised technique was employed to explore strong boundaries separating students using unlabeled data. Results: From over 20,000 recorded behaviors, we were able to train a classifier with 90.2% accuracy and uncovered a major underlying factor directly affecting absenteeism: the importance of peer relationships. This is an important finding and provides data-driven support for the fundamental idea that peer relationships are a critical factor affecting absenteeism. Discussion: The reported results provide a clear evidence that implementing socio-emotional learning components within a curriculum can improve absenteeism by targeting a root cause. Such knowledge can drive impactful policy and programming changes necessary for supporting the youth in communities overwhelmed with adversities.",
        "DOI": "10.3389/fpsyg.2022.958748",
        "affiliation_name": "Butler University",
        "affiliation_city": "Indianapolis",
        "affiliation_country": "United States",
        "affiliation_id": "60020268",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Experiences and perceptions of COVID-19 infection and vaccination among Palestinian refugees in Jerash camp and Jordanian citizens: a comparative cross-sectional study by face-to-face interviews",
        "paper_author": "Al-Hatamleh M.A.I.",
        "publication": "Infectious Diseases of Poverty",
        "citied_by": "9",
        "cover_date": "2022-12-01",
        "Abstract": "Background: During the COVID-19 vaccination, the access to vaccines has been unequal among countries and individuals, for example low-income countries displayed significant low levels of vaccination. Furthermore, most refugees are living in developing low-income countries which struggling to access the essential health-care services including vaccination. Thus, the objective of this study was to assess the experiences and perceptions of COVID-19 infection and vaccination among Palestine refugees in Jerash camp compared to resident Jordanian citizens. Methods: A face-to-face interview-based comparative cross-sectional study was carried out among Palestine refugees in Jerash camp located in northern Jordan and Jordanian citizens from different cities in Jordan from October, 2021 to March, 2022. A Chi-square test was used to determine the differences in the experiences and perceptions of COVID-19 infection and vaccination between Palestinian refugees and resident Jordanian citizens. Logistic regression analysis was performed to predict factors associated with the beliefs, barriers and hesitancy towards COVID-19 vaccines. Results: The total number of participants was 992, with 501 (50.5%) Palestinian refugees and 491 (49.5%) Jordanian citizens. Most participants (64.1%) who have never been tested for COVID-19 were from the refugees (P < 0.001), whereas about 80.3% of the participants tested for COVID-19 at private healthcare institutions were citizens (P < 0.001). While 70.0% of the participants who tested positive for COVID-19 (n = 303) were from the refugees (P < 0.001). Compared to the citizens, the refugees had significantly lower levels of beliefs about the safety (P = 0.008) and efficiency (P < 0.001) of COVID-19 vaccines. They also had lower rates of vaccine hesitancy (P = 0.002) and vaccine uptake (P < 0.001), and a higher rate of facing difficulties during registration for COVID-19 vaccination (P < 0.001). Furthermore, refugees have more negative attitudes toward the importance and implementation of COVID-19 precautionary activities, including wearing face masks, practicing social distancing and following proper prevention hygiene compared to citizens (P < 0.001). The regression analysis showed that gender (P < 0.001), age (P < 0.001) and level of education (P = 0.001) were significantly associated with COVID-19 vaccine hesitancy. Also, being a refugee (P < 0.001) and being a male (P = 0.012) were significantly associated with facing more difficulties upon the registration to receive a COVID-19 vaccine. Conclusions: This study showed that, compared to citizens, refugees had lower attitudes and practices toward COVID-19 infection and vaccination. They also had and a lower rate of COVID-19 vaccine hesitancy and uptake with limited access to vaccines. Government sectors and non-government organizations should implement policies and regulations to raise the awareness of refugees towards COVID-19 infection, testing, preventive measures, and the safety and efficacy of vaccines.",
        "DOI": "10.1186/s40249-022-01047-y",
        "affiliation_name": "School of Medicine",
        "affiliation_city": "Amman",
        "affiliation_country": "Jordan",
        "affiliation_id": "60199635",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Emerging paradigms in sepsis",
        "paper_author": "Vincent J.L.",
        "publication": "eBioMedicine",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.ebiom.2022.104398",
        "affiliation_name": "Hôpital Erasme",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium",
        "affiliation_id": "60068575",
        "affiliation_state": "BRU"
    },
    {
        "paper_title": "HomeMonitor: An Enhanced Device Event Detection Method for Smart Home Environment",
        "paper_author": "Zhao M.",
        "publication": "Sensors",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "As more and more smart devices are deployed in homes, the communication between these smart home devices and elastic computing services may face some risks of privacy disclosure. Different device events (such as the camera on, video on, etc.) will generate different data traffic during communication. However, the current smart home system lacks monitoring of these device events, which may cause the disclosure of private data collected by these devices. In this paper, we present our device event monitor system, HomeMonitor. HomeMonitor runs in the OpenWRT system and supports complete event monitoring for smart home devices. HomeMoitor solves the problem that machine learning models for detecting device events do not scale flexibly. It uses the network packet size and the direction of the device event for unique identification during training. When detecting, it only needs to get the packet size and timestamp and then query the policy table for signature matching to control the device events. We evaluated the effectiveness of HomeMonitor, and the experiments show that the match rate of our method is 98.8%, the false positive rate is 1.8%, and the detection time is only 16.67% for PINBALL. The results mean that our method achieves the balance of applicable protocol scope, detection performance, and detection accuracy.",
        "DOI": "10.3390/s22239389",
        "affiliation_name": "Guangzhou University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60025345",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Remote Sensing and Machine Learning Tools to Support Wetland Monitoring: A Meta-Analysis of Three Decades of Research",
        "paper_author": "Jafarzadeh H.",
        "publication": "Remote Sensing",
        "citied_by": "19",
        "cover_date": "2022-12-01",
        "Abstract": "Despite their importance to ecosystem services, wetlands are threatened by pollution and development. Over the last few decades, a growing number of wetland studies employed remote sensing (RS) to scientifically monitor the status of wetlands and support their sustainability. Considering the rapid evolution of wetland studies and significant progress that has been made in the field, this paper constitutes an overview of studies utilizing RS methods in wetland monitoring. It investigates publications from 1990 up to the middle of 2022, providing a systematic survey on RS data type, machine learning (ML) tools, publication details (e.g., authors, affiliations, citations, and publications date), case studies, accuracy metrics, and other parameters of interest for RS-based wetland studies by covering 344 papers. The RS data and ML combination is deemed helpful for wetland monitoring and multi-proxy studies, and it may open up new perspectives for research studies. In a rapidly changing wetlands landscape, integrating multiple RS data types and ML algorithms is an opportunity to advance science support for management decisions. This paper provides insight into the selection of suitable ML and RS data types for the detailed monitoring of wetland-associated systems. The synthesized findings of this paper are essential to determining best practices for environmental management, restoration, and conservation of wetlands. This meta-analysis establishes avenues for future research and outlines a baseline framework to facilitate further scientific research using the latest state-of-art ML tools for processing RS data. Overall, the present work recommends that wetland sustainability requires a special land-use policy and relevant protocols, regulation, and/or legislation.",
        "DOI": "10.3390/rs14236104",
        "affiliation_name": "C-Core Research Institute",
        "affiliation_city": "St John's",
        "affiliation_country": "Canada",
        "affiliation_id": "60189778",
        "affiliation_state": "NL"
    },
    {
        "paper_title": "Intelligent air defense task assignment based on hierarchical reinforcement learning",
        "paper_author": "Liu J.Y.",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "1",
        "cover_date": "2022-12-01",
        "Abstract": "Modern air defense battlefield situations are complex and varied, requiring high-speed computing capabilities and real-time situational processing for task assignment. Current methods struggle to balance the quality and speed of assignment strategies. This paper proposes a hierarchical reinforcement learning architecture for ground-to-air confrontation (HRL-GC) and an algorithm combining model predictive control with proximal policy optimization (MPC-PPO), which effectively combines the advantages of centralized and distributed approaches. To improve training efficiency while ensuring the quality of the final decision. In a large-scale area air defense scenario, this paper validates the effectiveness and superiority of the HRL-GC architecture and MPC-PPO algorithm, proving that the method can meet the needs of large-scale air defense task assignment in terms of quality and speed.",
        "DOI": "10.3389/fnbot.2022.1072887",
        "affiliation_name": "Air Force Engineering University China",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60069720",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Does media sentiment affect stock prices? Evidence from China’s STAR market",
        "paper_author": "Dong X.",
        "publication": "Frontiers in Psychology",
        "citied_by": "4",
        "cover_date": "2022-12-01",
        "Abstract": "Objective: This paper explores the impact of media sentiment on stock prices on the Shanghai Stock Exchange Science and Technology Innovation Board (hereinafter the STAR market) from a behavioral finance perspective. Methods: We collect Baidu News coverage of STAR-listed firms as the text, and measure text sentiment using a machine learning-based text analysis technique. We then empirically examine the impact of media sentiment on STAR market stock prices from two aspects: IPO pricing efficiency and IPO first-day stock performance. Results: (1) Media sentiment has no significant impact on IPO pricing efficiency, thus suggesting that institutional investors participating in such offerings are generally not affected by media sentiment. (2) Optimistic media sentiment has a positive impact on IPO first-day returns, which indicates that individual investors are more easily influenced by media sentiment and therefore likely to abandon their rational judgment. (3) Media sentiment had a greater impact on IPO first-day returns during the COVID-19 pandemic than those before it, which suggests that individual investors are more influenced by media sentiment during pandemics. Discussion: Our findings deepen the understanding of stock price formation on the STAR market, which provide a statistical basis for formulating policy directions and investment strategies.",
        "DOI": "10.3389/fpsyg.2022.1040171",
        "affiliation_name": "Cheng Shiu University",
        "affiliation_city": "Kaohsiung",
        "affiliation_country": "Taiwan",
        "affiliation_id": "60019330",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Predicting the Forest Canopy Height from LiDAR and Multi-Sensor Data Using Machine Learning over India",
        "paper_author": "Ghosh S.M.",
        "publication": "Remote Sensing",
        "citied_by": "19",
        "cover_date": "2022-12-01",
        "Abstract": "Forest canopy height estimates, at a regional scale, help understand the forest carbon storage, ecosystem processes, the development of forest management and the restoration policies to mitigate global climate change, etc. The recent availability of the NASA’s Global Ecosystem Dynamics Investigation (GEDI) LiDAR data has opened up new avenues to assess the plant canopy height at a footprint level. Here, we present a novel approach using the random forest (RF) for the wall-to-wall canopy height estimation over India’s forests (i.e., evergreen forest, deciduous forest, mixed forest, plantation, and shrubland) by employing the high-resolution top-of-the-atmosphere (TOA) reflectance and vegetation indices, the synthetic aperture radar (SAR) backscatters, the topography and tree canopy density, as the proxy variables. The variable importance plot indicated that the SAR backscatters, tree canopy density and the topography are the most influential height predictors. 33.15% of India’s forest cover demonstrated the canopy height <10 m, while 44.51% accounted for 10–20 m and 22.34% of forests demonstrated a higher canopy height (>20 m). This study advocates the importance and use of GEDI data for estimating the canopy height, preferably in data-deficit mountainous regions, where most of India’s natural forest vegetation exists.",
        "DOI": "10.3390/rs14235968",
        "affiliation_name": "Birla Institute of Technology, Mesra",
        "affiliation_city": "Ranchi",
        "affiliation_country": "India",
        "affiliation_id": "60026714",
        "affiliation_state": "JH"
    },
    {
        "paper_title": "A RoBERTa Approach for Automated Processing of Sustainability Reports",
        "paper_author": "Angin M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "10",
        "cover_date": "2022-12-01",
        "Abstract": "There is a strong need and demand from the United Nations, public institutions, and the private sector for classifying government publications, policy briefs, academic literature, and corporate social responsibility reports according to their relevance to the Sustainable Development Goals (SDGs). It is well understood that the SDGs play a major role in the strategic objectives of various entities. However, linking projects and activities to the SDGs has not always been straightforward or possible with existing methodologies. Natural language processing (NLP) techniques offer a new avenue to identify linkages for SDGs from text data. This research examines various machine learning approaches optimized for NLP-based text classification tasks for their success in classifying reports according to their relevance to the SDGs. Extensive experiments have been performed with the recently released Open Source SDG (OSDG) Community Dataset, which contains texts with their related SDG label as validated by community volunteers. Results demonstrate that especially fine-tuned RoBERTa achieves very high performance in the attempted task, which is promising for automated processing of large collections of sustainability reports for detection of relevance to SDGs.",
        "DOI": "10.3390/su142316139",
        "affiliation_name": "United Nations Development Programme",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60078210",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Grid-Based Essential Urban Land Use Classification: A Data and Model Driven Mapping Framework in Xiamen City",
        "paper_author": "Wang X.",
        "publication": "Remote Sensing",
        "citied_by": "5",
        "cover_date": "2022-12-01",
        "Abstract": "Accurate and timely mapping of essential urban land use categories (EULUC) is vital to understanding urban land use distribution, pattern, and composition. Recent advances in leveraging big open data and machine learning algorithms have demonstrated the possibility of large-scale mapping of EULUC in a new cost-effective way. However, they are still limited by the transferability of samples, models, and classification results across space, particularly across different cities. Given the heterogeneities of environmental and socioeconomic conditions among cities, in-depth studies of data and model adaptation towards city-specific EULUC mappings are highly required to support policy making, and urban renewal planning and management practices. In addition, the trending need for timely and detailed small land unit data processing with finer data granularity becomes increasingly important. We proposed a City Meta Unit (CMU) data model and classification framework driven by multisource data and artificial intelligence (AI) algorithms to address these challenges. The CMU Framework was innovatively applied to systematically set up a grid-based data model and classify urban land use with an improved AI algorithm by applying Moore neighborhood correlations. Specifically, we selected Xiamen, Fujian, in China, a coastal city, as the typical testbed to implement this proposed framework and apply an AI transfer learning technique for grid and parcel land-use study. Experimental results with our proposed CMU framework showed that the grid-based land use classification performance achieves overall accuracies of 81.17% and 76.55% for level I (major classes) and level II (minor classes), which is much higher than the parcel-based land use classification (overall accuracies of 72.37% for level I, and 68.99% for level II). We further investigated the relationship between training sample size and classification performance and quantified the contribution of different data sources to urban land use classifications. The CMU framework makes data collections and processing intelligent and efficient, with finer granularity, saving time and cost by using existing open social data. Incorporating the CMU framework with the proposed grid-based model is an effective and new approach for urban land use classification, which can be flexibly extended and applied to various cities.",
        "DOI": "10.3390/rs14236143",
        "affiliation_name": "Peng Cheng Laboratory",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China",
        "affiliation_id": "60271961",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Economic aspects of the detection of new strains in a multi-strain epidemiological–mathematical model",
        "paper_author": "Shami L.",
        "publication": "Chaos, Solitons and Fractals",
        "citied_by": "15",
        "cover_date": "2022-12-01",
        "Abstract": "Mankind has struggled with pathogens throughout history. In this context, the contribution of vaccines to the continued economic and social prosperity of humanity is enormous, but it is constantly threatened by the development of vaccine-resistant strains of the pathogen. In this study, we investigate the usage of genomic sequencing tests to detect new strains of a pathogen in a multi-strain pandemic scenario using a mathematical–epidemiological–genomic–economic model. Our model provides a theoretical framework to explore the influence of an extensive number of pharmaceutical interventions in a dynamic multi-strain pandemic. Specifically, we show that while a genomic sequence testing policy can be both economically and epidemiologically efficient, a random sample of the population provides sub-optimal results. Moreover, we demonstrate that the optimal policy is sensitive to the social and economic settings of the population, and provide a machine learning based model that offers a solution to these challenges.",
        "DOI": "10.1016/j.chaos.2022.112823",
        "affiliation_name": "Western Galilee College",
        "affiliation_city": "Acre",
        "affiliation_country": "Israel",
        "affiliation_id": "60080487",
        "affiliation_state": "HaZafon"
    },
    {
        "paper_title": "Effect of dockless bike-sharing scheme on the demand for London Cycle Hire at the disaggregate level using a deep learning approach",
        "paper_author": "Ding H.",
        "publication": "Transportation Research Part A: Policy and Practice",
        "citied_by": "11",
        "cover_date": "2022-12-01",
        "Abstract": "To evaluate the dynamic effects of the dockless bike-sharing scheme on the demand of the London Cycle Hire (LCH) scheme at the station level, a novel bicycle demand prediction model is proposed using the deep learning approach, based on the transaction records at 645 docking stations of LCH in the period between July 2017 and March 2018. First, an intervention response module (IRM) is established to model the time-series trends of bicycle demands at individual LCH docking stations, with and without the dockless bike-sharing scheme. Then, the Graph Neural Networks (GNN) predictors are adopted to predict the demand for LCH, incorporating the learned effects from IRM. Results indicate that the proposed bicycle demand prediction model can achieve promising prediction performances, with higher R-squared (R2), lower Root Mean Squared Errors (RMSE) and lower Mean Absolute Errors (MAE), compared to conventional prediction models. More importantly, the proposed model can recognize the dynamic effects of the dockless bike-sharing scheme on the demand for LCH. For instance, there are possible spillover effects for the influence area of dockless bike-sharing scheme, especially for the neighboring areas that have well-integrated bicycle facilities (e.g., cycle lanes). In addition, the effect of dockless bike sharing on the demand for LCH can magnify over time. Moreover, influences on the demands on weekends are more remarkable than that on weekdays. Findings should improve the understanding on the interdependency between the demands of dockless and docked bike-sharing systems. This should shed light to the optimal management strategy for the docked bike-sharing system that can maximize the operational efficiency and cost-effectiveness.",
        "DOI": "10.1016/j.tra.2022.10.013",
        "affiliation_name": "State Key Laboratory of Internet of Things for Smart City",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao",
        "affiliation_id": "60202520",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Energy Demand of the Road Transport Sector of Saudi Arabia—Application of a Causality-Based Machine Learning Model to Ensure Sustainable Environment",
        "paper_author": "Rahman M.M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "7",
        "cover_date": "2022-12-01",
        "Abstract": "The road transportation sector in Saudi Arabia has been observing a surging growth of demand trends for the last couple of decades. The main objective of this article is to extract insightful information for the country’s policymakers through a comprehensive investigation of the rising energy trends. In the first phase, it employs econometric analysis to provide the causal relationship between the energy demand of the road transportation sector and different socio-economic elements, including the gross domestic product (GDP), number of registered vehicles, total population, the population in the urban agglomeration, and fuel price. Then, it estimates future energy demand for the sector using two machine-learning models, i.e., artificial neural network (ANN) and support vector regression (SVR). The core features of the future demand model include: (i) removal of the linear trend, (ii) input data projection using a double exponential smoothing technique, and (iii) energy demand prediction using the machine learning models. The findings of the study show that the GDP and urban population have a significant causal relationship with energy demand in the road transportation sector in both the short and long run. The greenhouse gas emissions from the road transportation in Saudi Arabia are directly proportional to energy consumption because the demand is solely met by fossil fuels. Therefore, appropriate policy measures should be taken to reduce energy intensity without compromising the country’s development. In addition, the SVR model outperformed the ANN model in predicting the future energy demand of the sector based on the achieved performance indices. For instance, the correlation coefficients of the SVR and the ANN models were 0.8932 and 0.9925, respectively, for the test datasets. The results show that the SVR is better for predicting energy consumption than the ANN. It is expected that the findings of the study will assist the decision-makers of the country in achieving environmental sustainability goals by initiating appropriate policies.",
        "DOI": "10.3390/su142316064",
        "affiliation_name": "John and Marcia Price College of Engineering",
        "affiliation_city": "Salt Lake City",
        "affiliation_country": "United States",
        "affiliation_id": "60150772",
        "affiliation_state": "UT"
    },
    {
        "paper_title": "A Hybrid Model for China’s Soybean Spot Price Prediction by Integrating CEEMDAN with Fuzzy Entropy Clustering and CNN-GRU-Attention",
        "paper_author": "Liu D.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "3",
        "cover_date": "2022-12-01",
        "Abstract": "China’s soybean spot price has historically been highly volatile due to the combined effects of long-term massive import dependence and intricate policies, as well as inherent environmental elements. The accurate prediction of the price is crucial for reducing the amount of soybean-linked risks worldwide and valuable for the long-term sustainability of global agriculture. Therefore, a hybrid prediction model that combines component clustering and a neural network with an attention mechanism has been developed. After fully integrated complete ensemble empirical mode decomposition with adaptive noise (CEEMDAN) processing of the price series, the fuzzy entropy of each component is measured as the complexity characteristic. K-means clustering and reconstruction are applied to the components before being input to the CNN-GRU-Attention network for prediction to improve the model ability and adaptability of the sequences. In the empirical analysis, the proposed model outperforms other decomposition techniques and machine learning algorithms regarding prediction accuracy. After applying the decomposition part, the results have RMSE, MAPE, and MAE values of 49.59%, 22.58%, and 21.99% lower than those of the individual prediction part, respectively. This research presents a novel approach for market participants in the soybean industry for risk response. It gives a new perspective on agricultural product prices in sustainable agricultural marketing, while also providing practical tools for developing public policies and decision-making.",
        "DOI": "10.3390/su142315522",
        "affiliation_name": "Fujian Agriculture and Forestry University",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China",
        "affiliation_id": "60004630",
        "affiliation_state": "Fujian"
    },
    {
        "paper_title": "The inequalities of different dimensions of visible street urban green space provision: A machine learning approach",
        "paper_author": "Wang R.",
        "publication": "Land Use Policy",
        "citied_by": "21",
        "cover_date": "2022-12-01",
        "Abstract": "Awareness is growing that the uneven provision of street urban green space (UGS) may lead to environmental injustice. Most previous studies have focused on the over-head perspective of street UGS provision. However, only a few studies have evaluated the disparities in visible street UGS provision. While a plethora of studies have focused on a single dimension of visible UGS provision, no previous studies have developed a framework for systematically evaluating visible street UGS provision. This study therefore proposes a novel 4 ‘A′ framework, and aims to assess different dimensions (namely: availability; accessibility; attractiveness; and aesthetics) of visible street UGS provision, using Beijing as a case study. It investigates inequities in different dimensions of visible street UGS provision. In addition, it also explores the extent to which a neighbourhood's economic level is associated with different dimensions of visible street UGS. Our results show that, in Beijing, the four chosen dimensions of visible street UGS provision significantly differ in terms of spatial distribution and the association between them. Furthermore, we found that the value of the Gini index and Moran's I index for attractiveness and aesthetics are higher than those for availability and accessibility, which indicates a more unequal distribution of visible street UGS from a qualitative perspective. We also found that a community's economic level is positively associated with attractiveness and aesthetics, while no evidence was found to support the claim that the economic level of a community associated with availability and accessibility. This study suggests that visible street UGS provision is unequal; therefore, urban planning policy should pay more attention to disparities in visible street UGS provision, particularly in urban areas.",
        "DOI": "10.1016/j.landusepol.2022.106410",
        "affiliation_name": "Queen's University Belfast",
        "affiliation_city": "Belfast",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60029738",
        "affiliation_state": "Northern Ireland"
    }
]