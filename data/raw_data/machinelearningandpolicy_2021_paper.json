[
    {
        "paper_title": "Reinforcement learning-based register renaming policy for simultaneous multithreading CPUs[Formula presented]",
        "paper_author": "Zhan H.",
        "publication": "Expert Systems with Applications",
        "citied_by": "1",
        "cover_date": "2021-12-30",
        "Abstract": "Simultaneous multithreading (SMT) improves the performance of superscalar CPUs by exploiting thread-level parallelism with shared entries for better utilization of resources. A key issue for this out-of-order execution is that the occupancy latency of a physical rename register can be undesirably long due to many program execution-dependent factors that result in performance degradation. Such an issue becomes even more problematic in an SMT environment in which these registers are shared among concurrently running threads. Smartly managing this critical shared resource to ensure that slower threads do not block faster threads’ execution is essential to the advancement of SMT performance. In this paper, an actor–critic style reinforcement learning (RL) algorithm is proposed to dynamically assigning an upper-bound (cap) of the rename registers any thread is allowed to use according to the threads’ real-time demand. In particular, a critic network projects the current Issue Queues (IQ) usage, register file usage, and the cap value to a reward; an actor network is trained to project the current IQ usage and register file usage to the optimal real-time cap value via ascending the instructions per cycle (IPC) gradient within the trajectory distribution. The proposed method differs from the state-of-the-art (Wang and Lin, 2018) as the cap for the rename registers for each thread is adjusted in real-time according to the policy and state transition from self-play. The proposed method shows an improvement in IPC up to 162.8% in a 4-threaded system, 154.8% in a 6-threaded system and up to 101.7% in an 8-threaded system. The code is now available open source at https://github.com/98k-bot/RL-based-SMT-Register-Renaming-Policy.",
        "DOI": "10.1016/j.eswa.2021.115717",
        "affiliation_name": "Edward E. Whitacre Jr. College of Engineering",
        "affiliation_city": "Lubbock",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An approach to managing innovation to protect financial sector against cybercrime",
        "paper_author": "Kuzmenko O.V.",
        "publication": "Polish Journal of Management Studies",
        "citied_by": "11",
        "cover_date": "2021-12-29",
        "Abstract": "Ensuring the cyber security management is an ever-increasing challenge for the financial institutions and the national financial regulators. The main purpose of the research is to improve cyber security management through analyzing large data volumes of information which helps to identify potential cyber threats at an early stage. The factors of the rapid cybercrime growth via supervised learning models with associated learning (SVM) were identified and evaluated in the paper. The object of research is 21 EU countries. The paper presents the results of an empirical analysis, which showed that the cyber threats are caused by the growth of using online banking (0.49), improvement of internet user skills (0.42), expansion of activities online (0.41). The results of the research can be useful for financial institutions, national regulators and cybersecurity professionals.",
        "DOI": "10.17512/pjms.2021.24.2.17",
        "affiliation_name": "Hungarian University of Agriculture and Life Sciences",
        "affiliation_city": "Godollo",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "A study on smart city research activity using bibliometric and natural language processing methods",
        "paper_author": "Wang J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "3",
        "cover_date": "2021-12-22",
        "Abstract": "Smart cities have become a new urban development paradigm and draw much interest from the research community and society. Based on academic publications of smart city-related research, this study employs bibliometrics, natural language machine learning methods to analyze 10,000 papers indexed by Web of Science from 2009 to 2020. Bibliometrics results show that: (1) A total of 114 countries or regions worldwide have participated in smart city research, and China is the country with the highest amount of participation in the field of smart cities. (2) Smart city research has gone through three stages: the initial stage (2009-2012), the in-depth advancement stage (2013-2016), and the leap-up stage (2017-2020). Researchers paid more attention to urban attractiveness indicators such as sustainability in the early stage. In the later period, most of the research topics were clustered on improving the overall function of the city. Latent Dirichlet Allocation (LDA) topic model results revealed that research topics could be categorized into five aspects: policy research on the status quo of smart cities, data analysis and application, infrastructure construction, urban governance, and network security. Current research on smart city technologies mainly focuses on theoretical systems, technologies, and application fields. There is a lack of in-depth research and exploration in long-term construction and operation mechanisms. This research provides insight into the research status of smart city technologies and helps researchers decide on future study direction.",
        "DOI": "10.1145/3512576.3512638",
        "affiliation_name": "Chinese Academy of Agricultural Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Revisiting academic health sciences systems a decade later: discovery to health to population to society",
        "paper_author": "Dzau V.J.",
        "publication": "The Lancet",
        "citied_by": "22",
        "cover_date": "2021-12-18",
        "Abstract": "NA",
        "DOI": "10.1016/S0140-6736(21)01752-9",
        "affiliation_name": "Emory Healthcare",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Machine Learning Approach to Predict Groundwater Levels in California Reveals Ecosystems at Risk",
        "paper_author": "Rohde M.M.",
        "publication": "Frontiers in Earth Science",
        "citied_by": "19",
        "cover_date": "2021-12-17",
        "Abstract": "Groundwater dependent ecosystems (GDEs) are increasingly threatened worldwide, but the shallow groundwater resources that they are reliant upon are seldom monitored. In this study, we used satellite-based remote sensing to predict groundwater levels under groundwater dependent ecosystems across California, USA. Depth to groundwater was modelled for a 35-years period (1985–2019) within all groundwater dependent ecosystems across the state (n = 95,135). Our model was developed within Google Earth Engine using Landsat satellite imagery, climate data, and field-based groundwater data [n = 627 shallow (< 30 m) monitoring wells] as predictors in a Random Forest model. Our findings show that 1) 44% of groundwater dependent ecosystems have experienced a significant long-term (1985–2019) decline in groundwater levels compared to 28% with a significant increase; 2) groundwater level declines have intensified during the most recent two decades, with 39% of groundwater dependent ecosystems experiencing declines in the 2003–2019 period compared to 27% in the 1985–2002 period; and 3) groundwater declines are most prevalent within GDEs existing in areas of the state where sustainable groundwater management is absent. Our results indicate that declining shallow groundwater levels may be adversely impacting California’s groundwater dependent ecosystems. Particularly where groundwater levels have fallen beneath plant roots or streams thereby affecting key life processes, such as forest recruitment/succession, or hydrological processes, such as streamflow that affects aquatic habitat. In the absence of groundwater monitoring well data, our model and findings can be used to help state and local water agencies fill in data gaps of shallow groundwater conditions, evaluate potential effects on GDEs, and improve sustainable groundwater management policy in California.",
        "DOI": "10.3389/feart.2021.784499",
        "affiliation_name": "Nature Conservancy",
        "affiliation_city": "Arlington",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Enhance load forecastability: Optimize data sampling policy by reinforcing user behaviors",
        "paper_author": "Xie G.",
        "publication": "European Journal of Operational Research",
        "citied_by": "5",
        "cover_date": "2021-12-16",
        "Abstract": "Load forecasting has long been a key task for reliable power systems planning and operation. Over the recent years, advanced metering infrastructure has proliferated in industry. This has given rise to many load forecasting methods based on frequent measurements of power states obtained by smart meters. Meanwhile, real-world constraints arising in this new setting present both challenges and opportunities to achieve high load forecastability. The bandwidth constraints often imposed on the transmission between data concentrators and utilities are one of them, which limit the amount of data that can be sampled from customers. There lacks a sampling-rate control policy that is self-adaptive to users’ load behaviors through online data interaction with the smart grid environment. In this paper, we formulate the bandwidth-constrained sampling-rate control problem as a Markov decision process (MDP) and provide a reinforcement learning (RL)-based algorithm to solve the MDP for an optimal sampling-rate control policy. The resulting policy can be updated in real time to accommodate volatile load behaviors observed in the smart grid. Numerical experiments show that the proposed RL-based algorithm outperforms competing algorithms and delivers superior predictive performance.",
        "DOI": "10.1016/j.ejor.2021.03.032",
        "affiliation_name": "Virginia Tech College of Engineering",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neural networks with disabilities: An introduction to complementary artificial intelligence",
        "paper_author": "Terziyan V.",
        "publication": "Neural Computation",
        "citied_by": "7",
        "cover_date": "2021-12-15",
        "Abstract": "Machine learning is a good tool to simulate human cognitive skills as it is about mapping perceived information to various labels or action choices, aiming at optimal behavior policies for a human or an artificial agent operating in the environment. Regarding autonomous systems, objects and situations are perceived by some receptors as divided between sensors. Reactions to the input (e.g., actions) are distributed among the particular capability providers or actuators. Cognitive models can be trained as, for example, neural networks. We suggest training such models for cases of potential disabilities. Disability can be either the absence of one or more cognitive sensors or actuators at different levels of cognitive model. We adapt several neural network architectures to simulate various cognitive disabilities. The idea has been triggered by the “coolability” (enhanced capability) paradox, according to which a person with some disability can be more efficient in using other capabilities. Therefore, an autonomous system (human or artificial) pretrained with simulated disabilities will be more efficient when acting in adversarial conditions. We consider these coolabilities as complementary artificial intelligence and argue on the usefulness if this concept for various applications.",
        "DOI": "10.1162/neco_a_01449",
        "affiliation_name": "University of Jyväskylä",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "A comparative analysis of Statistical and Computational Intelligence methodologies for the prediction of traffic-induced fine particulate matter and NO<inf>2</inf>",
        "paper_author": "Kokkinos K.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "15",
        "cover_date": "2021-12-15",
        "Abstract": "With the urbanization increase, urban mobility and transportation induce higher traffic volumes causing environmental, economic and social impacts. This is due to continuous usage of fossil fuel energy resources generating air pollutants, such as nitrogen oxides (NOx), sulfur dioxide (SO2), carbon monoxide (CO), ozone (O3) and particulate matter (PM10 and PM2.5), which impact on climate and air quality and adversely affect the human health. The present paper aims at training an ensemble of forecasting methodologies for traffic-induced pollutant emissions and implementing it for predicting PM10, PM2.5 and NO2 for the case study of Cambridge, UK inner-city region. Such an ensemble enables decision makers to evaluate the impact of various transportation policies and measures on human health and the ecosystem, and subsequently contribute towards urban resilience and sustainability. Since the chemical synthesis of air pollution is triggered by meteorological factors, the forecasting incorporates them along with the traffic volumes. We opted to combine Statistical and Computational Intelligence learning methods including Adaptive Neuro Fuzzy Inference Systems (ANFIS), Long Short-Term Memory (LSTM) recurrent neural networks and Extreme Learning Machines (ELM). Initially, Multivariate Imputation by Chained Equation (MICE) and trend and seasonality removal was performed at data preprocessing and then Principal Component Analysis (PCA) highlighted the principal parameters for ANFIS to predict next day's PM10, PM2.5 and NO2 values. LSTM and ELM methods estimated next day values and compared with the ANFIS model results for hourly time series data of length 2703. The performance of the embedded models was quantified by the Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Square Error (MSE), and Coefficient of Determination (R2) indices. The ensemble was found to be superior in predicting PM10, PM2.5 and NO2 emissions when compared with existing traditional models.",
        "DOI": "10.1016/j.jclepro.2021.129500",
        "affiliation_name": "University of Thessaly",
        "affiliation_city": "Volos",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Integrating satellite-derived climatic and vegetation indices to predict smallholder maize yield using deep learning",
        "paper_author": "Zhang L.",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "78",
        "cover_date": "2021-12-15",
        "Abstract": "Timely and accurately estimating smallholder crop yield is essential for optimizing agronomic management, guiding investment and policy-making to reduce poverty and improve food security. However, the productivity of most smallholder farms around the world is still poorly estimated due to absence of technologies and field-scale data, especially for the largest smallholders across China. Here, we integrated 11,857 of field-surveyed yields across maize cultivation areas in China and heterogeneous geospatial data to predict field-level maize yield using three data-driven approaches, i.e., Least Absolute Shrinkage and Selection Operator (LASSO), Light Gradient Boosting Machine (LightGBM) and Long Short-Term Memory (LSTM). We determined the most suitable vegetation index (VI), compared the performances of satellite-derived and ground-observed climate data, and identified the optimal combination of input variables and the best method for maize yield estimation. We found that the green chlorophyll vegetation index (GCVI) outperformed the traditional visible and near-infrared-based VIs. Combining Land Surface Temperature (LST), cumulative precipitation (Pgs) and standardized precipitation index (SPI) explained about 70% of the yield variation, which was comparable to ground-observed indices. Integrating GCVI improved R2 by 0.01–0.20 depending on the methods, suggesting valuable information on biotic or abiotic stress contained by GCVI. Maize yield could be predicted 1–2-month ahead before harvesting in all agro-ecological zones. The data collected during silking period contributed more information. The LSTM model did better than LightGBM and LASSO, because of its neural network characterizing the cumulative effects of environmental factors on yield. Our study demonstrates an effective mean for large-scale crop yield estimation using publicly available data, particularly for smallholder systems where ground observations are currently limited and sparse.",
        "DOI": "10.1016/j.agrformet.2021.108666",
        "affiliation_name": "Ministry of Agriculture of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Urban soils as a spatial indicator of quality for urban socio-ecological systems",
        "paper_author": "Bonilla-Bedoya S.",
        "publication": "Journal of Environmental Management",
        "citied_by": "8",
        "cover_date": "2021-12-15",
        "Abstract": "The development of criteria and indicators to quantify the transition to sustainability of the urban socio-ecological systems quality is determinant for planning policies and the 21st century urban agenda. This study models the spatial variation in the concentration and distribution of some macronutrients, micronutrients, and trace nutrients in the soil of a high-altitude city in the Andes. Meanwhile, machine learning methods were employed to study some interactions between the different dimensions that constitute an urban socio-ecosystem that caused these variations. We proposed a methodology that considered two phases: a) field work to collect data on 300 soil samples; laboratory analysis to measure the concentrations of 24 macronutrients, micronutrients, and trace nutrients; and the design of geophysical, spectral, and urban co-variables; b) statistical and geo-informatics analysis, where multivariate analysis grouped the elements into factors; and, machine learning integrated with co-variables was applied to derive the intensity of each factor across the city. Multivariate statistics described the variation in soil co-concentrations with a moderate percentage (42%). Four factors were determined that grouped some of the analyzed elements, as follows: F1 (Zn, S, Cu, Pb, Ni, and Cr), F2 (Ba, Ag, K, In, and Mg), F3 (B, V, Li, and Sr), and F4 (Si and Mn). The percentage R2 out-of-bag of the spatial model were: F1 = 20%, F2 = 8%, F3 = 14%, and F4 = 10%. Our outputs show that the enrichment and contamination by anthropogenic factors, such as the increase in population density, land use, road network, and traffic generated by fossil fuel vehicles, should be prioritized in urban planning decisions.",
        "DOI": "10.1016/j.jenvman.2021.113556",
        "affiliation_name": "Universidad Regional Amazónica Ikiam",
        "affiliation_city": "Tena",
        "affiliation_country": "Ecuador"
    },
    {
        "paper_title": "Quantum Reinforcement Learning Applied to Board Games",
        "paper_author": "Teixeira M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2021-12-14",
        "Abstract": "Reinforcement learning is a machine learning paradigm where an agent learns how to optimize its behavior solely through its interaction with the environment. It has been extensively studied and successfully applied to complex problems of many different domains in the past decades, i.e., robotics, games, scheduling. However, the performance of these algorithms becomes limited as the complexity and dimension of the state-action space increases. Recent advances in quantum computing and quantum information have sparked interest in possible applications to machine learning. By taking advantage of quantum mechanics, it is possible to efficiently process immense quantities of information and improve computational speed. In this work, we combined quantum computing with reinforcement learning and studied its application to a board game to assess the benefits that it can introduce, namely its impact on the learning efficiency of an agent. From the results, we concluded that the proposed quantum exploration policy improved the convergence rate of the agent and promoted a more efficient exploration of the state space.",
        "DOI": "10.1145/3486622.3493944",
        "affiliation_name": "Universidade do Porto",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Tunable Neural Encoding of a Symbolic Robotic Manipulation Algorithm",
        "paper_author": "Katz G.E.",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "2",
        "cover_date": "2021-12-14",
        "Abstract": "We present a neurocomputational controller for robotic manipulation based on the recently developed “neural virtual machine” (NVM). The NVM is a purely neural recurrent architecture that emulates a Turing-complete, purely symbolic virtual machine. We program the NVM with a symbolic algorithm that solves blocks-world restacking problems, and execute it in a robotic simulation environment. Our results show that the NVM-based controller can faithfully replicate the execution traces and performance levels of a traditional non-neural program executing the same restacking procedure. Moreover, after programming the NVM, the neurocomputational encodings of symbolic block stacking knowledge can be fine-tuned to further improve performance, by applying reinforcement learning to the underlying neural architecture.",
        "DOI": "10.3389/fnbot.2021.744031",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "College Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Artificial Intelligence and Machine Learning in Sport Research: An Introduction for Non-data Scientists",
        "paper_author": "Chmait N.",
        "publication": "Frontiers in Sports and Active Living",
        "citied_by": "49",
        "cover_date": "2021-12-08",
        "Abstract": "In the last two decades, artificial intelligence (AI) has transformed the way in which we consume and analyse sports. The role of AI in improving decision-making and forecasting in sports, amongst many other advantages, is rapidly expanding and gaining more attention in both the academic sector and the industry. Nonetheless, for many sports audiences, professionals and policy makers, who are not particularly au courant or experts in AI, the connexion between artificial intelligence and sports remains fuzzy. Likewise, for many, the motivations for adopting a machine learning (ML) paradigm in sports analytics are still either faint or unclear. In this perspective paper, we present a high-level, non-technical, overview of the machine learning paradigm that motivates its potential for enhancing sports (performance and business) analytics. We provide a summary of some relevant research literature on the areas in which artificial intelligence and machine learning have been applied to the sports industry and in sport research. Finally, we present some hypothetical scenarios of how AI and ML could shape the future of sports.",
        "DOI": "10.3389/fspor.2021.682287",
        "affiliation_name": "Victoria University Melbourne, Institute for Health and Sport",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "The Clinical Course of Alcohol Use Disorder Depicted by Digital Biomarkers",
        "paper_author": "Zetterström A.",
        "publication": "Frontiers in Digital Health",
        "citied_by": "4",
        "cover_date": "2021-12-07",
        "Abstract": "Aims: This study introduces new digital biomarkers to be used as precise, objective tools to measure and describe the clinical course of patients with alcohol use disorder (AUD). Methods: An algorithm is outlined for the calculation of a new digital biomarker, the recovery and exacerbation index (REI), which describes the current trend in a patient's clinical course of AUD. A threshold applied to the REI identifies the starting point and the length of an exacerbation event (EE). The disease patterns and periodicity are described by the number, length, and distance between EEs. The algorithms were tested on data from patients from previous clinical trials (n = 51) and clinical practice (n = 1,717). Results: Our study indicates that the digital biomarker-based description of the clinical course of AUD might be superior to the traditional self-reported relapse/remission concept and conventional biomarkers due to higher data quality (alcohol measured) and time resolution. We found that EEs and the REI introduce distinct tools to identify qualitative and quantitative differences in drinking patterns (drinks per drinking day, phosphatidyl ethanol levels, weekday and holiday patterns) and effect of treatment time. Conclusions: This study indicates that the disease state—level, trend and periodicity—can be mathematically described and visualized with digital biomarkers, thereby improving knowledge about the clinical course of AUD and enabling clinical decision-making and adaptive care. The algorithms provide a basis for machine-learning-driven research that might also be applied for other disorders where daily data are available from digital health systems.",
        "DOI": "10.3389/fdgth.2021.732049",
        "affiliation_name": "Ridgeview Instruments AB",
        "affiliation_city": "Uppsala",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Predictive auto-scaling with OpenStack Monasca",
        "paper_author": "Lanciano G.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "4",
        "cover_date": "2021-12-06",
        "Abstract": "Cloud auto-scaling mechanisms are typically based on reactive automation rules that scale a cluster whenever some metric, e.g., the average CPU usage among instances, exceeds a predefined threshold. Tuning these rules becomes particularly cumbersome when scaling-up a cluster involves non-negligible times to bootstrap new instances, as it happens frequently in production cloud services. To deal with this problem, we propose an architecture for auto-scaling cloud services based on the status in which the system is expected to evolve in the near future. Our approach leverages on time-series forecasting techniques, like those based on machine learning and artificial neural networks, to predict the future dynamics of key metrics, e.g., resource consumption metrics, and apply a threshold-based scaling policy on them. The result is a predictive automation policy that is able, for instance, to automatically anticipate peaks in the load of a cloud application and trigger ahead of time appropriate scaling actions to accommodate the expected increase in traffic. We prototyped our approach as an open-source OpenStack component, which relies on, and extends, the monitoring capabilities offered by Monasca, resulting in the addition of predictive metrics that can be leveraged by orchestration components like Heat or Senlin. We show experimental results using a recurrent neural network and a multi-layer perceptron as predictor, which are compared with a simple linear regression and a traditional non-predictive auto-scaling policy. However, the proposed framework allows for the easy customization of the prediction policy as needed.",
        "DOI": "10.1145/3468737.3494104",
        "affiliation_name": "Scuola Normale Superiore di Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks",
        "paper_author": "Yang Z.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "5",
        "cover_date": "2021-12-06",
        "Abstract": "Privacy-centric mobile social network (PC-MSN), which allows users to build intimate and private social circles, is an increasingly popular type of online social networks (OSNs). Because of strict usage policy enforced by PC-MSNs (such as restricted account and content access), malicious accounts (or users) have to act like normal accounts to accumulate credentials before committing malicious activities. Therefore, analysis merely relying on static account profile information or social graphs is ineffective to detect such growing-up accounts. Besides, existing behavior-based malicious account detection methods fail to effectively detect growing-up accounts who pretend to be benign and have similar behaviors to benign users during the growing-up stage. In this paper, we present the first comprehensive study of growing-up behaviors of malicious accounts in WeChat, one of the major PC-MSNs with billions of daily active users across the globe. Our analysis reveals that the behavior patterns of growing-up accounts are very similar to that of benign users, and yet quite different from typical malicious accounts. Based on this observation, we design Muses, a detection system that can automatically identify subtle yet effective behaviors (features) to distinguish growing-up accounts before they engage in obvious malicious campaigns. Muses is unsupervised so that it can adapt to new malicious campaigns even if the behavior patterns of malicious accounts are unknown a priori. In particular, Muses addresses the limitations of the previous supervised techniques, i.e., requiring manually labeled training sets, which is time-consuming and costly. We evaluate Muses on a large-scale anonymized dataset from WeChat with roughly 440k accounts. The experimental results show that Muses achieves 2x recall, with similar precision, compared with the previous methods. Specifically, Muses detects over 82% growing-up accounts with a precision of 90% and achieves an AUC of 0.95. Notably, Muses can also effectively detect growing-up accounts even if malicious users applied various evasion strategies.",
        "DOI": "10.1145/3485832.3488013",
        "affiliation_name": "Tencent",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Distilling Arbitration Logic from Traces using Machine Learning: A Case Study on NoC",
        "paper_author": "Zhou Y.",
        "publication": "Proceedings - Design Automation Conference",
        "citied_by": "4",
        "cover_date": "2021-12-05",
        "Abstract": "Arbitration logic is extensively used in modern computer architectures to dynamically determine how shared hardware resources are allocated or accessed. Recent work has shown that machine learning techniques can learn non-obvious yet effective arbitration policies, which in simulation demonstrate superior performance over human-designed heuristics. However, existing methods based on deep learning are too expensive to be directly implemented as an arbitration unit in hardware. While some prior efforts managed to manually analyze and reduce a deep learning model into relatively small circuits in certain cases, such ad hoc and labor-intensive approaches cannot easily generalize. In this work, we propose a new methodology to automatically 'distill' the arbitration logic from simulation traces. Starting by training a deep learning model, we leverage tree-based models as a bridge to convert the more complex model to a compact logic implementation. This paper presents a case study of the proposed methodology on a network-on-chip port arbitration task. Compared with an array of combinational multipliers that exactly computes the neural network output, our arbitration logic achieves up to 282x area reduction without significant performance degradation. Under the training traffic, our arbitration logic achieves up to 64x reduction in average packet latency and up to 5% increase in network throughput over the FIFO arbitration policy. The distilled arbitration policy is also able to generalize to different injection rates and traffic patterns.",
        "DOI": "10.1109/DAC18074.2021.9586301",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Cyber-securing IoT infrastructure by modeling network traffic",
        "paper_author": "Gharakheili H.H.",
        "publication": "Security and Privacy in the Internet of Things: Architectures, Techniques, and Applications",
        "citied_by": "3",
        "cover_date": "2021-12-03",
        "Abstract": "In recent years, there has been growing recognition that machine learning is not a \"silver bullet\" that can magically detect all cyber-security threats, but is instead more effective in a narrower context - when the threat model is clear and the scope of the target activity is narrow. This chapter begins by highlighting Internet-of-Things (IoT) network threats and attack vectors, as well as existing countermeasures and their limitations. Next, a systematic approach to model the network behavior of IoT devices is developed, automatically enforcing their behavior and monitoring real-time activity using a set of flow-based anomaly detectors. The chapter outlines Software-Defined Networking-based system to enforce Manufacturer Usage Description (MUD) policies and dynamically inspect exception traffic (nonconforming to MUD profile) which is a small fraction of total packets to/from IoT devices.",
        "DOI": "10.1002/9781119607755.ch6",
        "affiliation_name": "University of New South Wales, School of Electrical Engineering and Telecommunications",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A Mean-variance Optimization DQN in Autonomous Driving",
        "paper_author": "Zhao Z.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2021-12-03",
        "Abstract": "Deep reinforcement learning is a popular and effective approach for autonomous driving to achieve safe and complex self-driving with little or no human input. However, in the random and intricate driving scenarios with surrounding traffic, conventional RL-algorithms based on greedy policy might be unstable and inefficient in training because of their lack in risk sensitivity. This paper proposes an RL-learning approach for autonomous driving which includes the estimation of expected cumulative future reward and its standard deviation. We utilize the difference between expectation and standard deviation as the decision foundation to improve the risk sensitivity of policy and training performance. The proposed algorithm is implemented in the CARLA simulation environment and the results demonstrate that vehicle agent based on our learning algorithm is able to learn more efficiently and drive more safely.",
        "DOI": "10.1145/3518781.3519208",
        "affiliation_name": "SAIC",
        "affiliation_city": "San Diego",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Contrasting urban greenness across cities with varying trends in above-normal weather events",
        "paper_author": "George J.S.",
        "publication": "Nature-Based Solutions",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "Effective urban management demands global empirical research findings. The work aims to determine whether green areas are more significant in cities where above-normal wet events have plateaued. This work compares the green surface cover characteristics of the entire city and identified zones of 54 cities representing cities worldwide. These cities experience varying amounts of above-normal weather conditions. This article classifies the cities in the data set into two groups: Group 1 – frequency of extreme wet weather events has plateaued, and Group 2 – frequency of extreme weather events are increasing or decreasing at higher rates. Next, the work uses structural features of co-located spatial networks, roads and terrain, to identify zones. Finally, high-resolution satellite imagery quantified urban green spaces in the city and identified zones of the two city groups using geospatial and machine learning methods for 2000 and 2020. The data is compared for two groups to understand the pattern of green spaces in cities. Empirical analysis results recognise a higher greenness index in the zones and the entire city amongst the cities of Group1. The pattern in the temporal change in the greenness index of the zones is helpful to formulate a priority plan for locating inter-linked green spaces in urban areas paving the way for Nature-based Solutions. The findings can guide planners and policy-makers to identify and prioritise locations to incorporate a robust green infrastructure network to build resilient cities by 'nature bringing a solution’, the essential concept of Nature-based Solutions.",
        "DOI": "10.1016/j.nbsj.2021.100008",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A PRESCRIPTIVE ANALYTICS FRAMEWORK FOR OPTIMAL POLICY DEPLOYMENT USING HETEROGENEOUS TREATMENT EFFECTS",
        "paper_author": "McFowland E.",
        "publication": "MIS Quarterly: Management Information Systems",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "We define a prescriptive analytics framework that addresses the needs of a constrained decision-maker facing, ex ante, unknown costs and benefits of multiple policy levers. The framework is general in nature and can be deployed in any utility-maximizing context, public or private. It relies on randomized field experiments for causal inference, machine learning for estimating heterogeneous treatment effects, and on the optimization of an integer linear program for converting predictions into decisions. The net result is the discovery of individual-level targeting of policy interventions to maximize overall utility under a budget constraint. The framework is set in the context of the four pillars of analytics and is especially valuable for companies that already have an existing practice of running A/B tests. The key contribution of this work is to develop and operationalize a framework to exploit both within- and between-treatment arm heterogeneity in the utility response function in order to derive benefits from future (optimized) prescriptions. We demonstrate the value of this framework as compared to benchmark practices—i.e., the use of the average treatment effect, uplift modeling, as well as an extension to contextual bandits—in two different settings. Unlike these standard approaches, our framework is able to recognize, adapt to, and exploit the (potential) presence of different subpopulations that experience varying costs and benefits within a treatment arm while also exhibiting differential costs and benefits across treatment arms. As a result, we find a targeting strategy that produces an order of magnitude improvement in expected total utility for the case where significant within- and between-treatment arm heterogeneity exists.",
        "DOI": "10.25300/MISQ/2021/15684",
        "affiliation_name": "Carlson School of Management",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Monitoring rice cropping system in Cambodia and its influencing factors using time series MODIS images",
        "paper_author": "Huang C.",
        "publication": "Resources Science",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "Cambodia has abundant arable land resources, suitable temperature, and great potential for rice plantation. Timely acquisition of rice cropping system information is important for regional rice production management, disaster risk assessment, and food policy formulation. Most traditional rice remote sensing monitoring studies only provide spatial patterns of rice distribution at the interannual scale, and information on rice planting and harvesting at the intraannual scale is often lacking. In this study, first all available MODIS time series data in a year were used to construct an image-based MODIS NDVI annual time series curve; the maximum value, minimum value, mean value, and standard deviation were selected to calculate the image- by- image time series statistical parameter features, and the FastDTW algorithm was used to calculate the similarity features between the image-by-image time series curve and the rice reference time series curve, and then the time series statistical features were combined with the time series curve similarity features, and the rice maturation information was extracted by supervised classification through machine learning using a random forest classifier. Finally, the rice phenological features extracted from the time series curves were combined to generate rice harvest time information for the identification of rice cultivation types. The study showed that rice cultivation in Cambodia is mainly concentrated in the lowland plains around the Tonle Sap Lake and the lower Mekong River. Although the thermal conditions in Cambodia are suitable for rice cultivation throughout the year, water access constraints have a significant impact on the spatial and temporal patterns of rice cultivation in the country. The rice maturity mode indicates that production was dominated by single-season rice, which accounted for about 80% of the annual rice cultivation area and had a stable distribution area; double-season rice accounted for about 20% of the area and showed a large interannual variation in the spatial distribution of cultivation. Wet season rice was the main type of rice cultivation in the country, and the planted area accounted for about 70% of the annual rice area with little interannual variation; dry season rice and ex-rainy season rice accounted for about 30% of the area, with significant interannual variation in spatial distribution. The analysis of rice cropping patterns in 2011 and 2016 showed that irrigation conditions and flooding had important spatial and temporal effects on rice cultivation in Cambodia. This study identified the main influencing factors through high-precision monitoring of the interannual and intraannual spatial and temporal patterns of rice cultivation in Cambodia, which provide a reference for the development of a locally adapted and resilient rice cultivation system to ensure food security in the country.",
        "DOI": "10.18402/resci.2021.12.03",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "QSPCA: A two-stage efficient power control approach in D2D communication for 5G networks",
        "paper_author": "Chandra S.",
        "publication": "Intelligent and Converged Networks",
        "citied_by": "10",
        "cover_date": "2021-12-01",
        "Abstract": "The existing literature on device-to-device (D2D) architecture suffers from a dearth of analysis under imperfect channel conditions. There is a need for rigorous analyses on the policy improvement and evaluation of network performance. Accordingly, a two-stage transmit power control approach (named QSPCA) is proposed: First, a reinforcement Q-learning based power control technique and; second, a supervised learning based support vector machine (SVM) model. This model replaces the unified communication model of the conventional D2D setup with a distributed one, thereby requiring lower resources, such as D2D throughput, transmit power, and signal-to-interference-plus-noise ratio as compared to existing algorithms. Results confirm that the QSPCA technique is better than existing models by at least 15.31% and 19.5% in terms of throughput as compared to SVM and Q-learning techniques, respectively. The customizability of the QSPCA technique opens up multiple avenues and industrial communication technologies in 5G networks, such as factory automation.",
        "DOI": "10.23919/ICN.2021.0021",
        "affiliation_name": "National Institute of Technology Patna",
        "affiliation_city": "Patna",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine learning models of tobacco susceptibility and current use among adolescents from 97 countries in the Global Youth Tobacco Survey, 2013-2017",
        "paper_author": "Kim N.",
        "publication": "PLOS Global Public Health",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "Adolescents are particularly vulnerable to tobacco initiation and escalation. Identifying factors associated with adolescent tobacco susceptibility and use can guide tobacco prevention efforts. Novel machine learning (ML) approaches efficiently identify interactive relations among factors of tobacco risks and identify high-risk subpopulations that may benefit from targeted prevention interventions. Nationally representative cross-sectional 2013–2017 Global Youth Tobacco Survey (GYTS) data from 97 countries (28 high-income and 69 low-and middle-income countries) from 342,481 adolescents aged 13–15 years (weighted N = 52,817,455) were analyzed using ML regression tree models, accounting for sampling weights. Predictors included demographics (sex, age), geography (region, country-income), and self-reported exposure to tobacco marketing, secondhand smoke, and tobacco control policies. 11.9% (95% CI 11.1%-12.6%) of tobacco-naïve adolescents were susceptible to tobacco use and 11.7% (11.0%-12.5%) of adolescents reported using any tobacco product (cigarettes, other smoked tobacco, smokeless tobacco) in the past 30 days. Regression tree models found that exposure or receptivity to tobacco industry promotions and secondhand smoke exposure predicted increased risks of susceptibility and use, while support for smoke-free air policies predicted decreased risks of tobacco susceptibility and use. Anti-tobacco school education and health warning messages on product packs predicted susceptibility or use, but their protective effects were not evident across all adolescent subgroups. Sex, region, and country-income moderated the effects of tobacco promotion and control factors on susceptibility or use, showing higher rates of susceptibility and use in males and high-income countries, Africa and the Americas (susceptibility), and Europe and Southeast Asia (use). Tobacco policy-related factors robustly predicted both tobacco susceptibility and use in global adolescents, and interacted with adolescent characteristics and other environments in complex ways that stratified adolescents based on their tobacco risk. These findings emphasize the importance of efficient ML modeling of interactions in tobacco risk prediction and suggest a role for targeted prevention strategies for high-risk adolescents.",
        "DOI": "10.1371/journal.pgph.0000060",
        "affiliation_name": "School of Computer, Data &amp; Information Sciences",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Soil carbon-food synergy: sizable contributions of small-scale farmers",
        "paper_author": "Iizumi T.",
        "publication": "CABI Agriculture and Bioscience",
        "citied_by": "8",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Benefits to agricultural yield improvement, soil degradation prevention, and climate mitigation are central to the synergies of soil organic carbon (SOC) build-up. However, the contributions of small-scale farmers, the main target of recent agricultural and rural development policies, to SOC enhancement are understudied. Here, we present a global analysis of small-scale farmers’ contributions to the potential of additional SOC stocks and the associated increase in crop production. Methods: We applied random forest machine learning models to global gridded datasets on crop yield (wheat, maize, rice, soybean, sorghum and millet), soil, climate and agronomic management practices from the 2000s (n = 1808 to 8123). Using the established crop-specific SOC-yield relationships, the potentials of additional SOC build-up and crop production increase were simulated. The estimated SOC increase was converted into global decadal mean temperature change using the temperature sensitivity to cumulative total anthropogenic CO2 emissions from preindustrial levels. The amount of inorganic nitrogen (N) input that would result in the same yield outcome as the SOC build-up was derived from the crop-specific N-yield relationships. Results: SOC contributes to yields in addition to management and climatic factors. Additional SOC sums up to 12.78 GtC (11.55–14.05 GtC) of global SOC stock, which earns 38.24 Mt (22.88–57.48 Mt) of additional crop production and prevents warming by 0.030 °C (0.019–0.041 °C). This production increase equates to what would be achieved by an inorganic N input of 5.82 Mt N (3.89–7.14 Mt N). Small-scale farmers account for 28% (26–30%) of the additional SOC build-up and 17% (15–20%) of the production increase. Key crops and regions in terms of small-scale farmers’ contributions include Sub-Saharan African maize and rice, Latin American and Caribbean soybean and maize, and South Asian rice and wheat. Conclusions: The contribution of small-scale farmers to the potential increase in SOC stock and crop production is sizable, which in theory further leads to saving inorganic N input. These findings emphasize the importance of linking soil management to sustainable land and climate mitigation with institutions and policy for small-scale farmers. Such a joint policy would assist multiple development goals.",
        "DOI": "10.1186/s43170-021-00063-6",
        "affiliation_name": "Institute for Agro-Environmental Sciences, NARO",
        "affiliation_city": "Tsukuba",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Simulation of Urban Land Use Growth Scenarios Using the Cellular Automata Method of SLEUTH",
        "paper_author": "Jahanishakib F.",
        "publication": "Journal of Environmental Studies",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "Accelerating urban expansion is increasingly challenging the sustainable use of land, since modeling urban growth is important in order to adapt to balanced development. This study was carried out with the aim of simulating the future urban expansion of Birjand Metropolitan from 2020 to 2050 using Cellular Automata (CA) methodology in the SLEUTH modeling considering two scenarios: historical and environmental growth. Calibration results of the SLEUTH model showed Diffusion (65) and slope resistance coefficients (42) have the most effect on historical and environmental growth, respectively. The model was calibrated in three stages: coarse, fine and final, using the best fitted values of OSM and Leesale indices. The simulation results showed that urban expansion in the historical and environmental growth scenarios will be 2201.85 and 2150.91 hectares, respectively, so increasing the area of Birjand metropolis is inevitable in both scenarios. A comparison of the two scenarios denoted that in the historical growth scenario, the urban growth rate is higher and the vegetation destruction is maximal. The findings of this study can help policy makers and managers in formulating informed urban planning strategies to have the least destructive effect on the environment in the future.",
        "DOI": "10.22059/JES.2021.328447.1008215",
        "affiliation_name": "University of Zabol",
        "affiliation_city": "Zabol",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Temporal Variations and Spatial Disparities in Public Sentiment Toward COVID-19 and Preventive Practices in the United States: Infodemiology Study of Tweets",
        "paper_author": "Kahanek A.",
        "publication": "JMIR Infodemiology",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "Background: During the COVID-19 pandemic, US public health authorities and county, state, and federal governments recommended or ordered certain preventative practices, such as wearing masks, to reduce the spread of the disease. However, individuals had divergent reactions to these preventive practices. Objective: The purpose of this study was to understand the variations in public sentiment toward COVID-19 and the recommended or ordered preventive practices from the temporal and spatial perspectives, as well as how the variations in public sentiment arerelated to geographical and socioeconomic factors. Methods: The authors leveraged machine learning methods to investigate public sentiment polarity in COVID-19-related tweets from January 21, 2020 to June 12, 2020. The study measured the temporal variations and spatial disparities in public sentiment toward both general COVID-19 topics and preventive practices in the United States. Results: In the temporal analysis, we found a 4-stage pattern from high negative sentiment in the initial stage to decreasing and low negative sentiment in the second and third stages, to the rebound and increase in negative sentiment in the last stage. We also identified that public sentiment to preventive practices was significantly different in urban and rural areas, while poverty rate and unemployment rate were positively associated with negative sentiment to COVID-19 issues. Conclusions: The differences between public sentiment toward COVID-19 and the preventive practices imply that actions need to be taken to manage the initial and rebound stages in future pandemics. The urban and rural differences should be considered in terms of the communication strategies and decision making during a pandemic. This research also presents a framework to investigate time-sensitive public sentiment at the county and state levels, which could guide local and state governments and regional communities in making decisions and developing policies in crises.",
        "DOI": "10.2196/31671",
        "affiliation_name": "University of North Texas",
        "affiliation_city": "Denton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Smoothing and the environmental manifold",
        "paper_author": "Unnithan Kumar S.",
        "publication": "Ecological Informatics",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "How the observed occurrences of a species relate to environmental gradients is a fundamental question in community ecology. In this paper, we present a new approach to address this question, using the smoothing function, a method not previously recruited into this ecological context. Using simulation techniques, we explore its accuracy in recovering known species distributions from simulated noisy data, and we compare the smoothing function's predictive abilities to two widely used methods in this field, the generalised linear model (GLM) and random forest machine learning. In studying the smoothing function, we are led to consider a new analytical tool for ecology, which we call the environmental manifold. It is given by the shape of the data cloud of sampled environmental predictor variables, and has deep relevance to ecological niche theory. Hitherto not considered in ecological analyses, it plays a fundamental role in understanding the species-environment relationship, and we utilise it to compare the performance and behaviour of these three methods. The results of our analysis find both random forest and smoothing to be robust to the complexities of the species-environment relationship, and also, to a degree, the shape of the environmental manifold. In contrast, the GLM's accuracy depends heavily on the complexity of the species-environment relationship, and is also affected by the geometry of the environmental manifold. Furthermore, the smoothing function is seen to be more accurate than random forest in every combination of species-environment relationship and environmental manifold shape, and also less affected by sampling bias. This suggests the promising role that such smoothing functions can have in ecological analyses. Our results also support the robustness of random forest machine learning to nonlinearity in both the species-environment relationship, and for the first time, the complexity of the shape of the environmental manifold. We conclude by discussing the implications and uses of the environmental manifold in ecological practice and theory, including its importance for niche theory, understanding species distributions, and conservation policy.",
        "DOI": "10.1016/j.ecoinf.2021.101472",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A three-level hierachical framework for additive manufacturing",
        "paper_author": "Ren Y.M.",
        "publication": "Digital Chemical Engineering",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "Metal alloy additive manufacturing (AM) has gained wide industrial interest in the past decade due to its capability to efficiently deliver complicated mechanical parts with high quality. However, due to a lack of understanding of the fundamental correlation between the operating conditions and build quality, the exploration of the optimal operating policy of the AM process is costly and difficult. In this work, a data-driven process optimization framework has been proposed for the additive manufacturing process, integrating machine learning, finite-element method (FEM) modeling, and cloud-edge data storage/transfer optimization. A three-level hierarchy of local machines, factory clouds, and a research center is introduced with each level responsible for its dedicated tasks. In addition, to ensure the efficiency of data transfer and storage, an edge-cloud data transfer scheme is constructed, which serves as a guideline for the data flow in the AM framework. Moreover, an overview of the connections between the proposed framework and the Industry 4.0 framework is presented.",
        "DOI": "10.1016/j.dche.2021.100001",
        "affiliation_name": "UCLA Samueli School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Statistical Machine Learning Approaches to Liver Disease Prediction",
        "paper_author": "Mostafa F.",
        "publication": "Livers",
        "citied_by": "30",
        "cover_date": "2021-12-01",
        "Abstract": "Medical diagnoses have important implications for improving patient care, research, and policy. For a medical diagnosis, health professionals use different kinds of pathological methods to make decisions on medical reports in terms of the patients’ medical conditions. Recently, clinicians have been actively engaged in improving medical diagnoses. The use of artificial intelligence and machine learning in combination with clinical findings has further improved disease detection. In the modern era, with the advantage of computers and technologies, one can collect data and visualize many hidden outcomes such as dealing with missing data in medical research. Statistical machine learning algorithms based on specific problems can assist one to make decisions. Machine learning (ML), data-driven algorithms can be utilized to validate existing methods and help researchers to make potential new decisions. The purpose of this study was to extract significant predictors for liver disease from the medical analysis of 615 humans using ML algorithms. Data visualizations were implemented to reveal significant findings such as missing values. Multiple imputations by chained equations (MICEs) were applied to generate missing data points, and principal component analysis (PCA) was used to reduce the dimensionality. Variable importance ranking using the Gini index was implemented to verify significant predictors obtained from the PCA. Training data ((Formula presented.)) for learning and testing data ((Formula presented.)) in the ML methods were used for predicting classifications. The study compared binary classifier machine learning algorithms (i.e., artificial neural network, random forest (RF), and support vector machine), which were utilized on a published liver disease data set to classify individuals with liver diseases, which will allow health professionals to make a better diagnosis. The synthetic minority oversampling technique was applied to oversample the minority class to regulate overfitting problems. The RF significantly contributed ((Formula presented.)) to a higher accuracy score of 98.14% compared to the other methods. Thus, this suggests that ML methods predict liver disease by incorporating the risk factors, which may improve the inference-based diagnosis of patients.",
        "DOI": "10.3390/livers1040023",
        "affiliation_name": "Texas Tech University Health Sciences Center at Lubbock",
        "affiliation_city": "Lubbock",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning-based approach: Global trends, research directions, and regulatory standpoints",
        "paper_author": "Pugliese R.",
        "publication": "Data Science and Management",
        "citied_by": "168",
        "cover_date": "2021-12-01",
        "Abstract": "The field of machine learning (ML) is sufficiently young that it is still expanding at an accelerating pace, lying at the crossroads of computer science and statistics, and at the core of artificial intelligence (AI) and data science. Recent progress in ML has been driven both by the development of new learning algorithms theory, and by the ongoing explosion in the availability of vast amount of data (often referred to as “big data”) and low-cost computation. The adoption of ML-based approaches can be found throughout science, technology and industry, leading to more evidence-based decision-making across many walks of life, including healthcare, biomedicine, manufacturing, education, financial modeling, data governance, policing, and marketing. Although the past decade has witnessed the increasing interest in these fields, we are just beginning to tap the potential of these ML algorithms for studying systems that improve with experience. In this paper, we present a comprehensive view on geo worldwide trends (taking into account China, the USA, Israel, Italy, the UK, and the Middle East) of ML-based approaches highlighting rapid growth in the last 5 years attributable to the introduction of related national policies. Furthermore, based on the literature review, we also discuss the potential research directions in this field, summarizing some popular application areas of machine learning technology, such as healthcare, cyber-security systems, sustainable agriculture, data governance, and nanotechnology, suggesting that the “dissemination of research” in the ML scientific community has undergone the exceptional growth in the time range of 2018–2020, reaching a value of 16,339 publications. Finally, we report the challenges and the regulatory standpoints for managing ML technology. Overall, we hope that this work will help to explain the geo trends of ML approaches and their applicability in various real-world domains, as well as serve as a reference point for both academia and industry professionals, particularly from a technical, ethical and regulatory point of view.",
        "DOI": "10.1016/j.dsm.2021.12.002",
        "affiliation_name": "Asst Grande Ospedale Metropolitano Niguarda",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Who determines United States Healthcare out-of-pocket costs? Factor ranking and selection using ensemble learning",
        "paper_author": "Zhang C.",
        "publication": "Health Information Science and Systems",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "Purpose: Healthcare out-of-pocket (OOP) costs consist of the annual expenses paid by individuals or families that are not reimbursed by insurance. In the U.S, broadening healthcare disparities are caused by the rapid increase in OOP costs. With a precise forecast of the OOP costs, governments can improve the design of healthcare policies to better control the OOP costs. This study designs a purely data-driven ensemble learning procedure to achieve a collection of factors that best predict OOP costs. Methods: We propose a voting ensemble learning procedure to rank and select factors of OOP costs based on the Medical Expenditure Panel Survey dataset. The method involves utilizing votes from the base learners forward subset selection, backward subset selection, random forest, and LASSO. Results: The top-ranking factors selected by our proposed method are insurance type, age, asthma, family size, race, and number of physician office visits. The predictive models using these factors outperform the models that employ the factors commonly considered by the literature through improving the prediction error (test MSE of the OOP costs’ log-odds) from 0.462 to 0.382. Conclusion: Our results indicate a set of factors which best explain the OOP costs behavior based on a purely data-driven solution. These findings contribute to the discussions regarding demand-side needs for containing rapidly rising OOP costs. Instead of estimating the impact of a single factor on OOP costs, our proposed method allows for the selection of arbitrary-sized factors to best explain OOP costs.",
        "DOI": "10.1007/s13755-021-00153-9",
        "affiliation_name": "Claremont Graduate University",
        "affiliation_city": "Claremont",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Software Identification by Standard Machine Learning Tools",
        "paper_author": "Sukhoparov M.E.",
        "publication": "Automatic Control and Computer Sciences",
        "citied_by": "0",
        "cover_date": "2021-12-01",
        "Abstract": "Abstract: This article considers tools for controlling software installed on personal computers of automated system users. The flaws of these software solutions are grounded, and an approach to identifying executable files with the help of a machine learning algorithm is developed and presented. This algorithm consists in the gradient decision tree boosting on the basis of such libraries as XGBoost, LightGBM, CatBoost. The identification of programs with the help of XGBoost and LightGBM is executed. The experimental results are compared with the results of earlier studies conducted by other authors. The findings show that the developed method allows for identifying violations in the adopted security policy during information processing in automated systems.",
        "DOI": "10.3103/S0146411621080459",
        "affiliation_name": "Russian Academy of Sciences",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Industry 4.0 - Policy-based approaches to efficient implementation in SMEs",
        "paper_author": "Łabȩdzka J.",
        "publication": "Engineering Management in Production and Services",
        "citied_by": "8",
        "cover_date": "2021-12-01",
        "Abstract": "Industry 4.0 (I4.0), driven by the need to access real-time insights and information across the manufacturing process, creates a disruptive impact on industries. Large-scale machine-to-machine communication, virtual reality (VR), the Internet of Things (IoT), simulation technologies and network management are integrated for increased automation, machine learning, self-controlled social and technical systems (Smart Factories). The uptake of advanced manufacturing solutions represents a challenge for businesses and SMEs in particular. SMEs possess neither the organisational capability nor financial resources to systematically investigate the potential and risks of introducing Industry 4.0. However, the so-called Fourth Industrial Revolution is a matter of technology and cooperation between European regions to share knowledge concerning alternative regional and national approaches to reinforcing the I4.0 uptake. Therefore, this paper primarily aims to analyse practical experience on how European policies related to the European Regional Development Fund (ERDF) can unlock the full potential of Industry 4.0 and overcome the fragmentation of Industry 4.0 solutions. Case studies of successful transfer of I4.0 to SMEs in Europe and supporting regional policy instruments presented in the paper could inspire and enable the potential of digitalisation by dealing with main challenges hampering their diffusion into the business ecosystem.",
        "DOI": "10.2478/emj-2021-0032",
        "affiliation_name": "Łukasiewicz - Instytut Technologii Eksploatacji",
        "affiliation_city": "Radom",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "INODE: Building an End-to-End Data Exploration System in Practice",
        "paper_author": "Amer-Yahia S.",
        "publication": "SIGMOD Record",
        "citied_by": "10",
        "cover_date": "2021-12-01",
        "Abstract": "A full-fledged data exploration system must combine different access modalities with a powerful concept of guiding the user in the exploration process, by being reactive and anticipative both for data discovery and for data linking. Such systems are a real opportunity for our community to cater to users with different domain and data science expertise. We introduce INODE - an end-to-end data exploration system - that leverages, on the one hand, Machine Learning and, on the other hand, semantics for the purpose of Data Management (DM). Our vision is to develop a classic unified, comprehensive platform that provides extensive access to open datasets, and we demonstrate it in three significant use cases in the fields of Cancer Biomarker Research, Research and Innovation Policy Making, and Astrophysics. INODE offers sustainable services in (a) data modeling and linking, (b) integrated query processing using natural language, (c) guidance, and (d) data exploration through visualization, thus facilitating the user in discovering new insights. We demonstrate that our system is uniquely accessible to a wide range of users from larger scientific communities to the public. Finally, we briefly illustrate how this work paves the way for new research opportunities in DM.",
        "DOI": "10.1145/3516431.3516436",
        "affiliation_name": "Université Grenoble Alpes",
        "affiliation_city": "Saint Martin d'Heres",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Understanding the Middle East through the eyes of Japan's Newspapers: A topic modelling and sentiment analysis approach",
        "paper_author": "Ghasiya P.",
        "publication": "Digital Scholarship in the Humanities",
        "citied_by": "6",
        "cover_date": "2021-12-01",
        "Abstract": "For Japan-a country that has always been described with virtually no major natural resources such as oil, gas, and coal-the Middle Eastern region has a special place in its economic and foreign policy. In 2017, 39% of Japan's energy came from oil, and 87% of Japan's imported oil came from the Middle East, predominantly Saudi Arabia and the UAE. The above facts are enough to discern the critical significance of the Middle Eastern region for Japan. For Japan to have an unhindered supply of oil and other natural resources, it is pertinent that this region remains peaceful. In this scenario, the Middle East-related articles in Japan's newspapers can help understand Japan's perspective towards the Middle East. This paper would first apply the topic modelling approach non-negative matrix factorization (NMF) on Middle East-related articles from three newspapers of Japan. After discovering crucial topics, we would utilize traditional supervised machine learning algorithms to determine the overall and topic-specific sentiments from the collected headlines. Our topic modelling results discovered that the Japanese media widely reported issues like Islamic State, the refugee crisis, the Syrian civil war, Qasem Soleimani killing, and Iran nuclear deal. Further, the news related to Saudi Arabia, Syria, and Trump garnered high negative sentiment.",
        "DOI": "10.1093/llc/fqab019",
        "affiliation_name": "Kyushu University",
        "affiliation_city": "Fukuoka",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Gene-editable materials for future transportation infrastructure: a review for polyurethane-based pavement",
        "paper_author": "Hong B.",
        "publication": "Journal of Infrastructure Preservation and Resilience",
        "citied_by": "21",
        "cover_date": "2021-12-01",
        "Abstract": "With the rapid development of society and industry, novel technologies and materials related to pavement engineering are constantly emerging. However, with the continuous improvement of people’s demands, pavement engineering also faces more and more enormous challenges that the pavement materials must have excellent engineering properties and environmental benefits. Meanwhile, the intelligence is the mainstream development direction of modern society, and the development trend of future transportation infrastructure. Materials Genome Initiative, a program for the development of new materials that materials design is conducted by up-front simulations and predictions, followed by key validation experiments, the rapid development of science and technology and AI toolset (big data and machine learning) provide new opportunities and strong technical supports for pavement materials development that shorten the development-application cycle of new material, reduce cost and promote the application of new carriers such as intelligent sensing components in transportation engineering, to achieve the intelligence of transportation engineering. However, traditional pavement materials possess several unavoidable shortcomings, indicating that it is exceedingly difficult for them to meet the above requirements for future pavement materials. Therefore, the development of future new pavement materials, which can be designed on-demand as well as possessing enough mechanical properties, high durability, practical functionality, and high environmental protection, is urgent. In recent years, as a “designable” polymer material with various excellent engineering performances, polyurethane (PU) has been widely applied in pavement practices by changing the chemical structures of raw materials and their mix proportions, for instance pavement repairing material, permeable pavement material, tunnel paving material and bridge deck paving materials, etc. Although PU material has been widely applied in practices, a systematically summarization is still quite necessary for further understanding the working mechanism of PU materials and optimization it’s engineering applications. To fill the gap, this article puts forward the special requirements for future transportation infrastructure materials, and introduces the basic properties and working mechanism of PU materials in order to make up for the defects of conventional road materials. Based on this, this article also summarizes the engineering performances and environmental benefits of applying PU as the binder for different road infrastructure materials in recent years. Considering the gene-editable nature of polyurethane, further research of the on-demand design principles of PU pavement materials is recommended. The establishment of raw material gene database, material terminal performance database and their structure-activity relationship are highlighted. The current research is essential to the practice guidance and further optimization of the PU materials for road infrastructures, which in line with the future Carbon neutral policy.",
        "DOI": "10.1186/s43065-021-00039-w",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep reinforcement learning for shared control of mobile robots",
        "paper_author": "Tian C.",
        "publication": "IET Cyber-systems and Robotics",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "Shared control of mobile robots integrates manual input with auxiliary autonomous controllers to improve the overall system performance. However, prior work that seeks to find the optimal shared control ratio needs an accurate human model, which is usually challenging to obtain. In this study, the authors develop an extended Twin Delayed Deep Deterministic Policy Gradient (DDPG) (TD3X)-based shared control framework that learns to assist a human operator in teleoperating mobile robots optimally. The robot's states, shared control ratio in the previous time step, and human's control input is used as inputs to the reinforcement learning (RL) agent, which then outputs the optimal shared control ratio between human input and autonomous controllers without knowing the human model. Noisy softmax policies are developed to make the TD3X algorithm feasible under the constraint of a shared control ratio. Furthermore, to accelerate the training process and protect the robot, a navigation demonstration policy and a safety guard are developed. A neural network (NN) structure is developed to maintain the correlation of sensor readings among heterogeneous input data and improve the learning speed. In addition, an extended DAGGER (DAGGERX) human agent is developed for training the RL agent to reduce human workload. Robot simulations and experiments with humans in the loop are conducted. The results show that the DAGGERX human agent can simulate real human inputs in the worst-case scenarios with a mean square error of 0.0039. Compared to the original TD3 agent, the TD3X-based shared control system decreased the average collision number from 387.3 to 44.4 in a simplistic environment and 394.2 to 171.2 in a more complex environment. The maximum average return increased from 1043 to 1187 with a faster converge speed in the simplistic environment, while the performance is equally good in the complex environment because of the use of an advanced human agent. In the human subject tests, participants' average perceived workload was significantly lower in shared control than that in exclusively manual control (26.90 vs. 40.07, p = 0.013).",
        "DOI": "10.1049/csy2.12036",
        "affiliation_name": "Clemson University College of Engineering, Computing and Applied Sciences",
        "affiliation_city": "Clemson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Projecting armed conflict risk in Africa towards 2050 along the SSP-RCP scenarios: a machine learning approach",
        "paper_author": "Hoch J.M.",
        "publication": "Environmental Research Letters",
        "citied_by": "23",
        "cover_date": "2021-12-01",
        "Abstract": "In the past decade, several efforts have been made to project armed conflict risk into the future. This study broadens current approaches by presenting a first-of-its-kind application of machine learning (ML) methods to project sub-national armed conflict risk over the African continent along three Shared Socioeconomic Pathway (SSP) scenarios and three Representative Concentration Pathways towards 2050. Results of the open-source ML framework CoPro are consistent with the underlying socioeconomic storylines of the SSPs, and the resulting out-of-sample armed conflict projections obtained with Random Forest classifiers agree with the patterns observed in comparable studies. In SSP1-RCP2.6, conflict risk is low in most regions although the Horn of Africa and parts of East Africa continue to be conflict-prone. Conflict risk increases in the more adverse SSP3-RCP6.0 scenario, especially in Central Africa and large parts of Western Africa. We specifically assessed the role of hydro-climatic indicators as drivers of armed conflict. Overall, their importance is limited compared to main conflict predictors but results suggest that changing climatic conditions may both increase and decrease conflict risk, depending on the location: in Northern Africa and large parts of Eastern Africa climate change increases projected conflict risk whereas for areas in the West and northern part of the Sahel shifting climatic conditions may reduce conflict risk. With our study being at the forefront of ML applications for conflict risk projections, we identify various challenges for this arising scientific field. A major concern is the limited selection of relevant quantified indicators for the SSPs at present. Nevertheless, ML models such as the one presented here are a viable and scalable way forward in the field of armed conflict risk projections, and can help to inform the policy-making process with respect to climate security.",
        "DOI": "10.1088/1748-9326/ac3db2",
        "affiliation_name": "International Peace Research Institute, Oslo",
        "affiliation_city": "Oslo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Vigorous IDS on Nefarious Operations and Threat Analysis Using Ensemble Machine Learning",
        "paper_author": "Musa U.S.",
        "publication": "Revue d'Intelligence Artificielle",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "The geometric increase in the usage of computer networking activities poses problems with the management of network normal operations. These issues had drawn the attention of network security researchers to introduce different kinds of intrusion detection systems (IDS) which monitor data flow in a network for unwanted and illicit operations. The violation of security policies with nefarious motive is what is known as intrusion. The IDS therefore examine traffic passing through networked systems checking for nefarious operations and threats, which then sends warnings if any of these malicious activities are detected. There are 2 types of detection of malicious activities, misuse detection, in this case the information about the passing network traffic is gathered, analyzed, which is then compared with the stored predefined signatures. The other type of detection is the Anomaly detection which is detecting all network activities that deviates from regular user operations. Several researchers have done various works on IDS in which they employed different machine learning (ML), evaluating their work on various datasets. In this paper, an efficient IDS is built using Ensemble machine learning algorithms which is evaluated on CIC-IDS2017, an updated dataset that contains most recent attacks. The results obtained show a great increase in the rate of detection, increase in accuracy as well as reduction in the false positive rates (FPR).",
        "DOI": "10.18280/ria.350604",
        "affiliation_name": "LLoyd Institute of Engineering &amp; Technology",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Gradus et al. Respond to \"Machine Learning and Suicide Prevention: New Directions\"",
        "paper_author": "Gradus J.L.",
        "publication": "American Journal of Epidemiology",
        "citied_by": "0",
        "cover_date": "2021-12-01",
        "Abstract": "NA",
        "DOI": "10.1093/aje/kwab113",
        "affiliation_name": "VA Boston Healthcare System",
        "affiliation_city": "West Roxbury",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Measuring anomalies in cigarette sales using official data from Spanish provinces: Are the anomalies detected by the Empty Pack Surveys (EPSs) used by Transnational Tobacco Companies (TTCs) the only anomalies?",
        "paper_author": "Cadahia P.",
        "publication": "Tobacco Induced Diseases",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "INTRODUCTION There is a literature that questions the veracity of the studies commissioned by transnational tobacco companies (TTCs) to measure the illicit tobacco trade. Furthermore, there are studies that have indicated that the empty pack surveys (EPSs) ordered by TTCs overestimate the size of this trade. This study simultaneously analyzed whether the EPSs established in each of the 47 Spanish provinces were accurate and measured anomalies observed in provinces where sales exceed expected values. METHODS To achieve the objectives of this study, provincial data on cigarette sales, prices and GDP per capita were used. These data were modeled with machine learning techniques that are widely used to detect anomalies in other areas. RESULTS The magnitude of the average anomaly in provinces where sales are higher than their expected values exceeds 40%, while the average anomaly in provinces where sales are lower than their expected values (as detected by the EPSs) is <15%. Furthermore, the results reveal that there is a clear geographical pattern to the provinces in which sales below reasonable values are observed. In addition, the values provided by the EPSs in Spain, as indicated in the previous literature, are slightly overestimated. Finally, some regions bordering other countries or that are highly influenced by tourism have observed sales that are higher than their expected values. CONCLUSIONS Cooperation between countries in their tobacco control policies can have better effects than policies developed based on information from a single country. The lack of control over the transactions of tourists and the inhabitants of bordering countries can cause important anomalies that distort the understanding of tobacco consumption that governments have based on official data.",
        "DOI": "10.18332/tid/143321",
        "affiliation_name": "International University of La Rioja",
        "affiliation_city": "Logrono",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Is preclinical research in cancer biology reproducible enough?",
        "paper_author": "Kane P.B.",
        "publication": "eLife",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "The Reproducibility Project: Cancer Biology (RPCB) was established to provide evidence about reproducibility in basic and preclinical cancer research, and to identify the factors that influence reproducibility more generally. In this commentary we address some of the scientific, ethical and policy implications of the project. We liken the basic and preclinical cancer research enterprise to a vast ‘diagnostic machine’ that is used to determine which clinical hypotheses should be advanced for further development, including clinical trials. The results of the RPCB suggest that this diagnostic machine currently recommends advancing many findings that are not reproducible. While concerning, we believe that more work needs to be done to evaluate the performance of the diagnostic machine. Specifically, we believe three questions remain unanswered: How often does the diagnostic machine correctly recommend against advancing real effects to clinical testing?; what are the relative costs to society of false positive and false negatives?; and how well do scientists and others interpret the outputs of the machine?.",
        "DOI": "10.7554/eLife.67527",
        "affiliation_name": "McGill Faculty of Medicine and Health Sciences",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Exploring stakeholder attitudes towards AI in clinical practice",
        "paper_author": "Scott I.A.",
        "publication": "BMJ Health and Care Informatics",
        "citied_by": "73",
        "cover_date": "2021-12-01",
        "Abstract": "Objectives Different stakeholders may hold varying attitudes towards artificial intelligence (AI) applications in healthcare, which may constrain their acceptance if AI developers fail to take them into account. We set out to ascertain evidence of the attitudes of clinicians, consumers, managers, researchers, regulators and industry towards AI applications in healthcare. Methods We undertook an exploratory analysis of articles whose titles or abstracts contained the terms € artificial intelligence' or € AI' and € medical' or € healthcare' and € attitudes', € perceptions', € opinions', € views', € expectations'. Using a snowballing strategy, we searched PubMed and Google Scholar for articles published 1 January 2010 through 31 May 2021. We selected articles relating to non-robotic clinician-facing AI applications used to support healthcare-related tasks or decision-making. Results Across 27 studies, attitudes towards AI applications in healthcare, in general, were positive, more so for those with direct experience of AI, but provided certain safeguards were met. AI applications which automated data interpretation and synthesis were regarded more favourably by clinicians and consumers than those that directly influenced clinical decisions or potentially impacted clinician-patient relationships. Privacy breaches and personal liability for AI-related error worried clinicians, while loss of clinician oversight and inability to fully share in decision-making worried consumers. Both clinicians and consumers wanted AI-generated advice to be trustworthy, while industry groups emphasised AI benefits and wanted more data, funding and regulatory certainty. Discussion Certain expectations of AI applications were common to many stakeholder groups from which a set of dependencies can be defined. Conclusion Stakeholders differ in some but not all of their attitudes towards AI. Those developing and implementing applications should consider policies and processes that bridge attitudinal disconnects between different stakeholders.",
        "DOI": "10.1136/bmjhci-2021-100450",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Predictive maintenance decision-making for serial production lines based on deep reinforcement learning",
        "paper_author": "Cui P.",
        "publication": "Jisuanji Jicheng Zhizao Xitong/Computer Integrated Manufacturing Systems, CIMS",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "Predictive maintenance is designed to perform maintenance activities based on the condition of equipment, which can improve the business bottom line by reducing maintenance cost and improving production performance. The modeling, analysis and decision-making of serial production lines with machine degradation process were studied. A Markov chain model was developed by analyzing the dynamics of a serial production line with machine failures and predictive maintenance, and the analytical formulas of transient performance measures were derived. A predictive maintenance decision model was established as a Markov decision process to minimize the work-in-process, backlog and maintenance costs. A deep reinforcement learning method was utilized to explore optimum maintenance policies, which was obtained through the training of neural network with dataset generated from Markov chain model. Case study was performed to validate the effectiveness of the proposed decision model. The results indicated that the maintenance and production related costs were significantly reduced.",
        "DOI": "10.13196/j.cims.2021.12.004",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Child stature, maternal education, and early childhood development in Nigeria",
        "paper_author": "Skoufias E.",
        "publication": "PLoS ONE",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "Data from the 2016–17 Multiple Indicator Cluster Survey from Nigeria are used to study the relationship between child stature, mother’s years of education, and indicators of early childhood development (ECD). The relationships are contrasted between two empirical approaches: the conventional approach whereby control variables are selected in an ad-hoc manner, and the double machine-learning (DML) approach that employs data-driven methods to select controls from a much wider set of variables and thus reducing potential omitted variable bias. Overall, the analysis confirms that maternal education and the incidence of chronic malnutrition have a significant direct effect on measures of early childhood development. The point estimates based on the ad-hoc specification tend to be larger in absolute value than those based on the DML specification. Frequently, the point estimates based on the ad-hoc specification fall inside the confidence interval of the DML point estimates, suggesting that in these cases the omitted variable bias is not serious enough to prevent making causal inferences based on the ad-hoc specification. However, there are instances where the omitted variable bias is sufficiently large for the ad hoc specification to yield a statistically significant relationship when in fact the more robust DML specification suggests there is none. The DML approach also reveals a more complex picture that highlights the role of context. In rural areas, mother’s education affects early childhood development both directly and indirectly through its impact on the nutritional status of both older and younger children. In contrast, in urban areas, where the average level of maternal education is much higher, increases in a mother’s education have only a direct effect on child ECD measures but no indirect effect through child nutrition. Thus, DML provides a practical and feasible approach to reducing threats to internal validity for robust inferences and policy design based on observational data.",
        "DOI": "10.1371/journal.pone.0260937",
        "affiliation_name": "The World Bank, USA",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Digital topics on cultural heritage investigated: how can data-driven and data-guided methods support to identify current topics and trends in digital heritage?",
        "paper_author": "Münster S.",
        "publication": "Built Heritage",
        "citied_by": "15",
        "cover_date": "2021-12-01",
        "Abstract": "In research and policies, the identification of trends as well as emerging topics and topics in decline is an important source of information for both academic and innovation management. Since at present policy analysis mostly employs qualitative research methods, the following article presents and assesses different approaches – trend analysis based on questionnaires, quantitative bibliometric surveys, the use of computer-linguistic approaches and machine learning and qualitative investigations. Against this backdrop, this article examines digital applications in cultural heritage and, in particular, built heritage via various investigative frameworks to identify topics of relevance and trendlines, mainly for European Union (EU)-based research and policies. Furthermore, this article exemplifies and assesses the specific opportunities and limitations of the different methodical approaches against the backdrop of data-driven vs. data-guided analytical frameworks. As its major findings, our study shows that both research and policies related to digital applications for cultural heritage are mainly driven by the availability of new technologies. Since policies focus on meta-topics such as digitisation, openness or automation, the research descriptors are more granular. In general, data-driven approaches are promising for identifying topics and trendlines and even predicting the development of near future trends. Conversely, qualitative approaches are able to answer “why” questions with regard to whether topics are emerging due to disruptive innovations or due to new terminologies or whether topics are becoming obsolete because they are common knowledge, as is the case for the term “internet”.",
        "DOI": "10.1186/s43238-021-00045-7",
        "affiliation_name": "Friedrich-Schiller-Universität Jena",
        "affiliation_city": "Jena",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "What Makes a Tax Policy Popular? Predicting Referendum Votes from Policy Text",
        "paper_author": "Martin I.W.",
        "publication": "Socius",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "What kinds of taxation are most politically sustainable in a democracy? The authors answer this question by applying natural language processing and machine learning techniques to a large, new corpus of digitized documents describing municipal tax policies of heterogeneous design that have been directly subjected to popular referendum in the state of California. The authors find that tax policies of different description vary systematically in their popularity with voters. In particular, official textual summaries of tax policy differ along two social dimensions that are associated with voters’ willingness to approve the tax. The authors interpret these dimensions as risk pooling and community orientation and show that measuring these dimensions can modestly improve the ability to predict the popularity of a tax, relative to a conventional regression specification that omits information about qualitative policy design. The authors discuss implications for the study of the sociology of taxation.",
        "DOI": "10.1177/23780231211066069",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Evaluating fishing capacity based on dea and regression analysis of china’s offshore fishery",
        "paper_author": "Liu S.",
        "publication": "Journal of Marine Science and Engineering",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "The analysis of offshore fishing capacity is of great significance and practical value to the sustainable utilization and conservation of marine fishery resources. Based on the 2004–2020 China Fishery Statistical Yearbook, data envelopment analysis (DEA) was applied for measuring fishing capacity using a number of fishing vessels, total power, total tonnage, and the number of professional fishermen as the input measures and the annual catch as the output measure. Capacity utilization had a calculated range from 80.7 to 100%, and its average is 93.5%. In the first four years of 2003–2007, the excess investment rate of fishing vessels, total tonnage, total power, and fishermen was low (<5%). There was a consistent sharp upward trend in 2007, a gradual downward trend from 2007 to 2015, and an upward trend after reaching a low point in 2015, with the highest gross tonnage of fishing vessels reaching 25.5%. Four regression models that incorporate machine learning algorithms are used, including Lasso, Ridge, KNN, and Polynomial Features. The goodness of fit for the four models was used as the evaluation index, and the offshore annual catch based on the evaluation index was proposed. The forecasting annual catch of the polynomial model can reach 0.98. Furthermore, a comparative simulation of the DEA incorporating the polynomial model was carried out. The results show that DEA can evaluate input factors under the conditions of a given range, and the polynomial model has more advantages in forecasting annual catches. Furthermore, the combined application of DEA and polynomial model was used to analyze and discuss the management policies of China’s offshore fishery, which can provide help and reference for future management.",
        "DOI": "10.3390/jmse9121402",
        "affiliation_name": "Shanghai Ocean University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sports participation and value of elite sports in predicting well-being",
        "paper_author": "Silva A.",
        "publication": "Sports",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "This work contributes to an emerging literature focused on the role of physical activity on the subjective well-being of populations. Unlike the existing literature, it proposes an approach that uses algorithms to predict subjective well-being. The aims of this study were to determine the relative importance of sports participation and perceived value of elite sports on the subjective well-being of individuals. A total of 511 participants completed an online questionnaire. The statistical analysis used several machine learning techniques, including three algorithms, Decision Tree Classifier (DTC), Random Forest Classifier (RFC), and Gradient Boosting Classifier (GBC). In the three algorithms tested, sports participation, expressed as the weekly frequency and the time spent engaging in vigorous physical activity, showed a greater importance (between 47% and 53%) in determining subjective well-being. It also highlights the effect of perceived value of elite sport on the prediction of subjective well-being. This study provides evidence for public sport policy makers/authorities and for managers of physical activity and sport development programs. The surprising effect of the perceived value of elite sport on the prediction of subjective well-being.",
        "DOI": "10.3390/sports9120173",
        "affiliation_name": "Polytechnic Institute of Leiria",
        "affiliation_city": "Leiria",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Event study: Advanced machine learning and statistical technique for analyzing sustainability in banking stocks",
        "paper_author": "Dogra V.",
        "publication": "Mathematics",
        "citied_by": "13",
        "cover_date": "2021-12-01",
        "Abstract": "Machine learning has grown in popularity in recent years as a method for evaluating financial text data, with promising results in stock price projection from financial news. Various research has looked at the relationship between news events and stock prices, but there is little evidence on how different sentiments (negative, neutral, and positive) of such events impact the performance of stocks or indices in comparison to benchmark indices. The goal of this paper is to analyze how a specific banking news event (such as a fraud or a bank merger) and other co-related news events (such as government policies or national elections), as well as the framing of both the news event and news-event sentiment, impair the formation of the respective bank’s stock and the banking index, i.e., Bank Nifty, in Indian stock markets over time. The task is achieved through three phases. In the first phase, we extract the banking and other co-related news events from the pool of financial news. The news events are further categorized into negative, positive, and neutral sentiments in the second phase. This study covers the third phase of our research work, where we analyze the impact of news events concerning sentiments or linguistics in the price movement of the respective bank’s stock, identified or recognized from these news events, against benchmark index Bank Nifty and the banking index against benchmark index Nifty50 for the short to long term. For the short term, we analyzed the movement of banking stock or index to benchmark index in terms of CARs (cumulative abnormal returns) surrounding the publication day (termed as D) of the news event in the event windows of (−1,D), (D,1), (−1,1), (D,5), (−5,−1), and (−5,5). For the long term, we analyzed the movement of banking stock or index to benchmark index in the event windows of (D,30), (−30,−1), (−30,30), (D,60), (−60,−1), and (−60,60). We explore the deep learning model, bidirectional encoder representations from transformers, and statistical method CAPM for this research.",
        "DOI": "10.3390/math9243319",
        "affiliation_name": "Chandigarh University",
        "affiliation_city": "Mohali",
        "affiliation_country": "India"
    },
    {
        "paper_title": "An operational Sentinel-2 based monitoring system for the management and control of direct aids to the farmers in the context of the Common Agricultural Policy (CAP): A case study in mainland Portugal",
        "paper_author": "Navarro A.",
        "publication": "International Journal of Applied Earth Observation and Geoinformation",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "The European Union (EU) member states are expected to develop new procedures, based on automatic earth observation data analysis, for the management and control of direct aids to the farmers, as part of the Common Agricultural Policy (CAP) reform of 2020. Here, we propose an operational monitoring system based on Sentinel-2 surface reflectance (SR) data and machine learning (ML) algorithms, consisting of a hierarchical approach triggering 3 color-coded warning alerts to distinguish among compliant (green), non-compliant (red), and inconclusive (yellow) parcels comparatively to the farmer's declaration. A Random Forest (RF) model is applied to a 5-day interpolated SR time series to generate a preliminary crop map, where all the parcels whose predicted and declared crop type match are flagged as compliant. Next, a refinement procedure is adopted to improve the discrimination between temporary and permanent crops. At this stage, VI temporal metrics and texture are used as input to a Support Vector Machine (SVM) classifier trained using only the previous compliant parcels. Through a set of decision rules, SVM crop class predictions are flagged as compliant, non-compliant and inconclusive. The system was tested for a significant area in mainland Portugal, using the 2019 Land Parcel Information System (LPIS) data. The system returned 96.5%, 2.5% and 1% of the parcels as compliant, inconclusive, and non-compliant, respectively. Comparison with field inspections for the subsidy control of 2019 revealed that only 1.1% of the correct declarations were classified by the system as non-compliant (5% as admissible value), while less than 5% of the real non-compliant declarations passed through the system (10–20%).",
        "DOI": "10.1016/j.jag.2021.102469",
        "affiliation_name": "Faculdade de Ciências da Universidade de Lisboa",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "The prediction of carbon emission information in yangtze river economic zone by deep learning",
        "paper_author": "Huang H.",
        "publication": "Land",
        "citied_by": "28",
        "cover_date": "2021-12-01",
        "Abstract": "This study aimed to respond to the national “carbon peak” mid-and long-term policy plan, comprehensively promote energy conservation and emission reduction, and accurately manage and predict carbon emissions. Firstly, the proposed method analyzes the Yangtze River Economic Belt as well as its “carbon peak” and carbon emissions. Secondly, a support vector regression (SVR) machine prediction model is proposed for the carbon emission information prediction of the Yangtze River Economic Zone. This experiment uses a long short-term memory neural network (LSTM) to train the model and realize the experiment’s prediction of carbon emissions. Finally, this study obtained the fitting results of the prediction model and the training model, as well as the prediction results of the prediction model. Information indicators such as the scale of industry investment, labor efficiency output, and carbon emission intensity that affect carbon emissions in the “Yangtze River Economic Belt” basin can be used to accurately predict the carbon emissions information under this model. Therefore, the experiment shows that the SVR model for solving complex nonlinear problems can achieve a relatively excellent prediction effect under the training of LSTM. The deep learning model adopted herein realized the accurate prediction of carbon emission information in the Yangtze River Economic Zone and expanded the application space of deep learning. It provides a reference for the model in related fields of carbon emission information prediction, which has certain reference significance.",
        "DOI": "10.3390/land10121380",
        "affiliation_name": "Hefei Normal University",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sustainability: A public policy, a concept, or a competence? efforts on the implementation of sustainability as a transversal competence throughout higher education programs",
        "paper_author": "Membrillo-Hernández J.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "24",
        "cover_date": "2021-12-01",
        "Abstract": "The concept of sustainability emerged globally in the 1987 Brundtland Report. Initially, it comprised three dimensions: environmental, social, and economic. Over time, sustainability became a global necessity that led to the establishment in 2015 of the 17 Sustainable Development Goals (SDGs), so that sustainability became a public policy of extreme urgency. Thirty-four years later, there is an imperative need to expand the original concept not in a public policy but in a competence that graduates of higher education develop, regardless of their studied academic program. We propose sustainability as a transversal competence. Our work describes the path that a higher education institution in Mexico, Tecnologico de Monterrey, has followed to accomplish this task. The new educational model Tec21 based on challenge-based learning experiences has a focus on the development of sustainability competences and actions ownership towards solving the problems described in the 17 SDGs. Our proposed definition for the sustainability transversal competence is: “The student possesses the knowledge, skills and attitudes necessary for the successful performance of the task and the resolution of problems related to the challenges and opportunities for sustainability in today’s world”. Thus, education is both an objective and a means to achieve all the other SDGs.",
        "DOI": "10.3390/su132413989",
        "affiliation_name": "Tecnológico de Monterrey",
        "affiliation_city": "Monterrey",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Smart technologies for sustainable water management: An urban analysis",
        "paper_author": "Aivazidou E.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "30",
        "cover_date": "2021-12-01",
        "Abstract": "As projections highlight that half of the global population will be living in regions facing severe water scarcity by 2050, sustainable water management policies and practices are more im-perative than ever. Following the Sustainable Development Goals for equitable water access and prudent use of natural resources, emerging digital technologies may foster efficient monitoring, control, optimization, and forecasting of freshwater consumption and pollution. Indicatively, the use of sensors, Internet of Things, machine learning, and big data analytics has been catalyzing smart water management. With two-thirds of the global population to be living in urban areas by 2050, this research focuses on the impact of digitization on sustainable urban water management. More specifically, existing scientific literature studies were explored for providing meaningful insights on smart water technologies implemented in urban contexts, emphasizing supply and distribution networks. The review analysis outcomes were classified according to three main pillars identified: (i) level of analysis (i.e., municipal or residential/industrial); (ii) technology used (e.g., sensors, algo-rithms); and (iii) research scope/focus (e.g., monitoring, optimization), with the use of a systematic approach. Overall, this study is expected to act as a methodological tool and guiding map of the most pertinent state-of-the-art research efforts to integrate digitalization in the field of water stewardship and improve urban sustainability.",
        "DOI": "10.3390/su132413940",
        "affiliation_name": "Centre for Research and Technology-Hellas",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Stargazing through the lens of AI in clinical oncology",
        "paper_author": "Lehman C.D.",
        "publication": "Nature Cancer",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "NA",
        "DOI": "10.1038/s43018-021-00307-4",
        "affiliation_name": "Harvard Medical School",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Vaccine technologies and platforms for infectious diseases: Current progress, challenges, and opportunities",
        "paper_author": "Ghattas M.",
        "publication": "Vaccines",
        "citied_by": "90",
        "cover_date": "2021-12-01",
        "Abstract": "Vaccination is a key component of public health policy with demonstrated cost-effective benefits in protecting both human and animal populations. Vaccines can be manufactured under multiple forms including, inactivated (killed), toxoid, live attenuated, Virus-like Particles, synthetic peptide, polysaccharide, polysaccharide conjugate (glycoconjugate), viral vectored (vector-based), nucleic acids (DNA and mRNA) and bacterial vector/synthetic antigen presenting cells. Several processes are used in the manufacturing of vaccines and recent developments in medical/biomedical engineering, biology, immunology, and vaccinology have led to the emergence of innovative nucleic acid vaccines, a novel category added to conventional and subunit vaccines. In this review, we have summarized recent advances in vaccine technologies and platforms focusing on their mechanisms of action, advantages, and possible drawbacks.",
        "DOI": "10.3390/vaccines9121490",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reinforcement learning assisted oxygen therapy for COVID-19 patients under intensive care",
        "paper_author": "Zheng H.",
        "publication": "BMC Medical Informatics and Decision Making",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Patients with severe Coronavirus disease 19 (COVID-19) typically require supplemental oxygen as an essential treatment. We developed a machine learning algorithm, based on deep Reinforcement Learning (RL), for continuous management of oxygen flow rate for critically ill patients under intensive care, which can identify the optimal personalized oxygen flow rate with strong potentials to reduce mortality rate relative to the current clinical practice. Methods: We modeled the oxygen flow trajectory of COVID-19 patients and their health outcomes as a Markov decision process. Based on individual patient characteristics and health status, an optimal oxygen control policy is learned by using deep deterministic policy gradient (DDPG) and real-time recommends the oxygen flow rate to reduce the mortality rate. We assessed the performance of proposed methods through cross validation by using a retrospective cohort of 1372 critically ill patients with COVID-19 from New York University Langone Health ambulatory care with electronic health records from April 2020 to January 2021. Results: The mean mortality rate under the RL algorithm is lower than the standard of care by 2.57% (95% CI: 2.08–3.06) reduction (P < 0.001) from 7.94% under the standard of care to 5.37% under our proposed algorithm. The averaged recommended oxygen flow rate is 1.28 L/min (95% CI: 1.14–1.42) lower than the rate delivered to patients. Thus, the RL algorithm could potentially lead to better intensive care treatment that can reduce the mortality rate, while saving the oxygen scarce resources. It can reduce the oxygen shortage issue and improve public health during the COVID-19 pandemic. Conclusions: A personalized reinforcement learning oxygen flow control algorithm for COVID-19 patients under intensive care showed a substantial reduction in 7-day mortality rate as compared to the standard of care. In the overall cross validation cohort independent of the training data, mortality was lowest in patients for whom intensivists’ actual flow rate matched the RL decisions.",
        "DOI": "10.1186/s12911-021-01712-6",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Informing equitable water and food policies through accurate spatial information on irrigated areas in smallholder farming systems",
        "paper_author": "Magidi J.",
        "publication": "Water (Switzerland)",
        "citied_by": "14",
        "cover_date": "2021-12-01",
        "Abstract": "Accurate information on irrigated areas’ spatial distribution and extent are crucial in enhancing agricultural water productivity, water resources management, and formulating strategic policies that enhance water and food security and ecologically sustainable development. However, data are typically limited for smallholder irrigated areas, which is key to achieving social equity and equal distribution of financial resources. This study addressed this gap by delineating disaggregated smallholder and commercial irrigated areas through the random forest algorithm, a non-parametric machine learning classifier. Location within or outside former apartheid “homelands” was taken as a proxy for smallholder, and commercial irrigation. Being in a medium rainfall area, the huge irrigation potential of the Inkomati-Usuthu Water Management Area (UWMA) is already well developed for commercial crop production outside former homelands. However, information about the spatial distribution and extent of irrigated areas within former homelands, which is largely informal, was missing. Therefore, we first classified cultivated lands in 2019 and 2020 as a baseline, from where the Normalised Difference Vegetation Index (NDVI) was used to distinguish irrigated from rainfed, focusing on the dry winter period when crops are predominately irrigated. The mapping accuracy of 84.9% improved the efficacy in defining the actual spatial extent of current irrigated areas at both smallholder and commercial spatial scales. The proportion of irrigated areas was high for both commercial (92.5%) and smallholder (96.2%) irrigation. Moreover, smallholder irrigation increased by over 19% between 2019 and 2020, compared to slightly over 7% in the commercial sector. Such information is critical for policy formulation regarding equitable and inclusive water allocation, irrigation expansion, land reform, and food and water security in smallholder farming systems.",
        "DOI": "10.3390/w13243627",
        "affiliation_name": "International Water Management Institute Ghana",
        "affiliation_city": "Accra",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Is it all the same? Mapping and characterizing deprived urban areas using worldview-3 superspectral imagery. a case study in nairobi, kenya",
        "paper_author": "Georganos S.",
        "publication": "Remote Sensing",
        "citied_by": "16",
        "cover_date": "2021-12-01",
        "Abstract": "In the past two decades, Earth observation (EO) data have been utilized for studying the spatial patterns of urban deprivation. Given the scope of many existing studies, it is still unclear how very-high-resolution EO data can help to improve our understanding of the multidimensionality of deprivation within settlements on a city-wide scale. In this work, we assumed that multiple facets of deprivation are reflected by varying morphological structures within deprived urban areas and can be captured by EO information. We set out by staying on the scale of an entire city, while zooming into each of the deprived areas to investigate deprivation through land cover (LC) variations. To test the generalizability of our workflow, we assembled multiple WorldView-3 datasets (multispectral and shortwave infrared) with varying numbers of bands and image features, allowing us to explore computational efficiency, complexity, and scalability while keeping the model architecture consistent. Our workflow was implemented in the city of Nairobi, Kenya, where more than sixty percent of the city population lives in deprived areas. Our results indicate that detailed LC information that characterizes deprivation can be mapped with an accuracy of over seventy percent by only using RGB-based image features. Including the near-infrared (NIR) band appears to bring significant improvements in the accuracy of all classes. Equally important, we were able to categorize deprived areas into varying profiles manifested through LC variability using a gridded mapping approach. The types of deprivation profiles varied significantly both within and between deprived areas. The results could be informative for practical interventions such as land-use planning policies for urban upgrading programs.",
        "DOI": "10.3390/rs13244986",
        "affiliation_name": "Universidad de Navarra",
        "affiliation_city": "Pamplona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "The economic impact of schistosomiasis",
        "paper_author": "Rinaldo D.",
        "publication": "Infectious Diseases of Poverty",
        "citied_by": "22",
        "cover_date": "2021-12-01",
        "Abstract": "Background: The economic impact of schistosomiasis and the underlying tradeoffs between water resources development and public health concerns have yet to be quantified. Schistosomiasis exerts large health, social and financial burdens on infected individuals and households. While irrigation schemes are one of the most important policy responses designed to reduce poverty, particularly in sub-Saharan Africa, they facilitate the propagation of schistosomiasis and other diseases. Methods: We estimate the economic impact of schistosomiasis in Burkina Faso via its effect on agricultural production. We create an original dataset that combines detailed household and agricultural surveys with high-resolution geo-statistical disease maps. We develop new methods that use the densities of the intermediate host snails of schistosomiasis as instrumental variables together with panel, spatial and machine learning techniques. Results: We estimate that the elimination of schistosomiasis in Burkina Faso would increase average crop yields by around 7%, rising to 32% for high infection clusters. Keeping schistosomiasis unchecked, in turn, would correspond to a loss of gross domestic product of approximately 0.8%. We identify the disease burden as a shock to the agricultural productivity of farmers. The poorest households engaged in subsistence agriculture bear a far heavier disease burden than their wealthier counterparts, experiencing an average yield loss due to schistosomiasis of between 32 and 45%. We show that the returns to water resources development are substantially reduced once its health effects are taken into account: villages in proximity of large-scale dams suffer an average yield loss of around 20%, and this burden decreases as distance between dams and villages increases. Conclusions: This study provides a rigorous estimation of how schistosomiasis affects agricultural production and how it is both a driver and a consequence of poverty. It further quantifies the tradeoff between the economics of water infrastructures and their impact on public health. Although we focus on Burkina Faso, our approach can be applied to any country in which schistosomiasis is endemic. Graphical Abstract: [Figure not available: see fulltext.]",
        "DOI": "10.1186/s40249-021-00919-z",
        "affiliation_name": "Institut de hautes études internationales et du développement,Geneve",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Climate-based regionalization and inclusion of spectral indices for enhancing transboundary land-use/cover classification using deep learning and machine learning",
        "paper_author": "Kavhu B.",
        "publication": "Remote Sensing",
        "citied_by": "18",
        "cover_date": "2021-12-01",
        "Abstract": "Accurate land use and cover data are essential for effective land-use planning, hydrological modeling, and policy development. Since the Okavango Delta is a transboundary Ramsar site, managing natural resources within the Okavango Basin is undoubtedly a complex issue. It is often difficult to accurately map land use and cover using remote sensing in heterogeneous landscapes. This study investigates the combined value of climate-based regionalization and integration of spectral bands with spectral indices to enhance the accuracy of multi-temporal land use/cover classification using deep learning and machine learning approaches. Two experiments were set up, the first entailing the integration of spectral bands with spectral indices and the second involving the combined integration of spectral indices and climate-based regionalization based on Koppen–Geiger climate zones. Landsat 5 TM and Landsat 8 OLI images, machine learning classifiers (random forest and extreme gradient boosting), and deep learning (neural network and deep neural network) clas-sifiers were used in this study. Supervised classification using a total of 5140 samples was conducted for the years 1996, 2004, 2013, and 2020. Average overall accuracy and Kappa coefficients were used to validate the results. The study found that the integration of spectral bands with indices improves the accuracy of land use/cover classification using machine learning and deep learning. Post-feature selection combinations yield higher accuracies in comparison to combinations of bands and indices. A combined integration of spectral indices with bands and climate-based regionalization did not significantly improve the accuracy of land use/cover classification consistently for all the classifiers (p < 0.05). However, post-feature selection combinations and climate-based regionalization significantly improved the accuracy for all classifiers investigated in this study. Findings of this study will improve the reliability of land use/cover monitoring in complex heterogeneous TDBs.",
        "DOI": "10.3390/rs13245054",
        "affiliation_name": "Zimbabwe Parks and Wildlife Management Authority",
        "affiliation_city": "Causeway",
        "affiliation_country": "Zimbabwe"
    },
    {
        "paper_title": "Benchmarking ghg emissions forecasting models for global climate policy",
        "paper_author": "Tudor C.",
        "publication": "Electronics (Switzerland)",
        "citied_by": "21",
        "cover_date": "2021-12-01",
        "Abstract": "Climate change and pollution fighting have become prominent global concerns in the twenty-first century. In this context, accurate estimates for polluting emissions and their evolution are critical for robust policy-making processes and ultimately for solving stringent global climate challenges. As such, the primary objective of this study is to produce more accurate forecasts of greenhouse gas (GHG) emissions. This in turn contributes to the timely evaluation of the progress achieved towards meeting global climate goals set by international agendas and also acts as an early-warning system. We forecast the evolution of GHG emissions in 12 top polluting economies by using data for the 1970–2018 period and employing six econometric and machine-learning models (the exponential smoothing state-space model (ETS), the Holt–Winters model (HW), the TBATS model, the ARIMA model, the structural time series model (STS), and the neural network autoregression model (NNAR)), along with a naive model. A battery of robustness checks is performed. Results confirm a priori expectations and consistently indicate that the neural network autoregression model (NNAR) presents the best out-of-sample forecasting performance for GHG emissions at different forecasting horizons by reporting the lowest average RMSE (root mean square error) and MASE (mean absolute scaled error) within the array of predictive models. Predictions made by the NNAR model for the year 2030 indicate that total GHG emissions are projected to increase by 3.67% on average among the world’s 12 most polluting countries until 2030. Only four top polluters will record decreases in total GHG emissions values in the coming decades (i.e., Canada, the Russian Federation, the US, and China), although their emission levels will remain in the upper decile. Emission increases in a handful of developing economies will see significant growth rates (a 22.75% increase in GHG total emissions in Brazil, a 15.75% increase in Indonesia, and 7.45% in India) that are expected to offset the modest decreases in GHG emissions projected for the four countries. Our findings, therefore, suggest that the world’s top polluters cannot meet assumed pollution reduction targets in the form of NDCs under the Paris agreement. Results thus highlight the necessity for more impactful policies and measures to bring the set targets within reach.",
        "DOI": "10.3390/electronics10243149",
        "affiliation_name": "Bucharest University of Economic Studies",
        "affiliation_city": "Bucharest",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "Can central bank speeches predict financial market turbulence? Evidence from an adaptive NLP sentiment index analysis using XGBoost machine learning technique",
        "paper_author": "Petropoulos A.",
        "publication": "Central Bank Review",
        "citied_by": "20",
        "cover_date": "2021-12-01",
        "Abstract": "Central Bank speeches usually function as aggregators of internal quantitative and qualitative analysis of the institutions regarding the macro economy, the monetary policy and the health of the financial systems. Speeches usually function as a summary of the current status of a countries economic health, the undergoing trends and some future perspectives of the global economy. In this study departing from classical econometrics we employ natural language processing technologies in combination with machine learning techniques in order to filter out the most important signals in the corpus of speeches and translate into a sentiment index for forecasting the future financial markets behaviour. In our analysis, it is evident that central banker's expectations on economy tend to exhibit a predictive ability for financial markets turmoil. Using a combination of dictionaries which are either predefined or build based on historical speeches of the corpus we train an Extreme Gradient Boosting model that generates a sentiment index which signals turmoil with acceptable accuracy when passing a specific threshold.",
        "DOI": "10.1016/j.cbrev.2021.12.002",
        "affiliation_name": "Bank of Greece",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Toward accelerated training of parallel support vector machines based on voronoi diagrams",
        "paper_author": "Alfaro C.",
        "publication": "Entropy",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "Typical applications of wireless sensor networks (WSN), such as in Industry 4.0 and smart cities, involves acquiring and processing large amounts of data in federated systems. Important challenges arise for machine learning algorithms in this scenario, such as reducing energy consumption and minimizing data exchange between devices in different zones. This paper introduces a novel method for accelerated training of parallel Support Vector Machines (pSVMs), based on ensembles, tailored to these kinds of problems. To achieve this, the training set is split into several Voronoi regions. These regions are small enough to permit faster parallel training of SVMs, reducing computational payload. Results from experiments comparing the proposed method with a single SVM and a standard ensemble of SVMs demonstrate that this approach can provide comparable performance while limiting the number of regions required to solve classification tasks. These advantages facilitate the development of energy-efficient policies in WSN.",
        "DOI": "10.3390/e23121605",
        "affiliation_name": "Universidad Rey Juan Carlos",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Adaptive Virtual Machine Consolidation Method Based on Deep Reinforcement Learning",
        "paper_author": "Yu X.",
        "publication": "Jisuanji Yanjiu yu Fazhan/Computer Research and Development",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "The problem of service quality optimization with energy consumption restriction has always been one of the big challenges for virtual machine (VM) resource management in data centers. Although existing work has reduced energy consumption and improved system service quality to a certain extent through VM consolidation technology, these methods are usually difficult to achieve long-term optimal management goals. Moreover, their performance is susceptible to the change of application scenarios, such that they are difficult to be replaced and will produce much management cost. In view of the problem that VM resource management in data center is hard to achieve long-term optimal energy efficiency and service quality, and also has poor flexibility in policy adjustment, this paper proposes an adaptive VM consolidation method based on deep reinforcement learning. This method builds an end-to-end decision-making model from data center system state to VM migration strategy through state tensor representation, deterministic action output, convolution neural network and weighted reward mechanism; It also designs an automatic state generation mechanism and an inverting gradient limitation mechanism to improve deep deterministic strategy gradient algorithm, speed up the convergence speed of VM migration decision-making model, and guarantee the approximately optimal management performance. Simulation experiment results based on real VM load data show that compared with popular VM consolidation methods in open source cloud platforms, this method can effectively reduce energy consumption and improve system service quality.",
        "DOI": "10.7544/issn1000-1239.2021.20200366",
        "affiliation_name": "Institute of Computing Technology Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Spatio-Clock Synchronous Constraint Guided Safe Reinforcement Learning for Autonomous Driving",
        "paper_author": "Wang J.",
        "publication": "Jisuanji Yanjiu yu Fazhan/Computer Research and Development",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "Autonomous driving systems integrate complex interactions between hardware and software. In order to ensure the safe and reliable operations, formal methods are used to provide rigorous guarantees to satisfy logical specifications and safety-critical requirements in the design stage. As a widely employed machine learning architecture, deep reinforcement learning (DRL) focuses on finding an optimal policy that maximizes a cumulative discounted reward by interacting with the environment, and has been applied to autonomous driving decision-making modules. However, black-box DRL-based autonomous driving systems cannot provide guarantees of safe operation and reward definition interpretability techniques for complex tasks, especially when they face unfamiliar situations and reason about a greater number of options. In order to address these problems, spatio-clock synchronous constraint is adopted to augment DRL safety and interpretability. Firstly, we propose a dedicated formal properties specification language for autonomous driving domain, i.e., spatio-clock synchronous constraint specification language, and present domain-specific knowledge requirements specification that is close to natural language to make the reward functions generation process more interpretable. Secondly, we present domain-specific spatio-clock synchronous automata to describe spatio-clock autonomous behaviors, i.e., controllers related to certain spatio- and clock-critical actions, and present safe state-action space transition systems to guarantee the safety of DRL optimal policy generation process. Thirdly, based on the formal specification and policy learning, we propose a formal spatio-clock synchronous constraint guided safe reinforcement learning method with the goal of easily understanding the safe reward function. Finally, we demonstrate the effectiveness of our proposed approach through an autonomous lane changing and overtaking case study in the highway scenario.",
        "DOI": "10.7544/issn1000-1239.2021.20211023",
        "affiliation_name": "Nanjing University of Aeronautics and Astronautics",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A bibliometric analysis and benchmark of machine learning and automl in crash severity prediction: The case study of three colombian cities",
        "paper_author": "Angarita-Zapata J.S.",
        "publication": "Sensors",
        "citied_by": "15",
        "cover_date": "2021-12-01",
        "Abstract": "Traffic accidents are of worldwide concern, as they are one of the leading causes of death globally. One policy designed to cope with them is the design and deployment of road safety systems. These aim to predict crashes based on historical records, provided by new Internet of Things (IoT) technologies, to enhance traffic flow management and promote safer roads. Increasing data availability has helped machine learning (ML) to address the prediction of crashes and their severity. The literature reports numerous contributions regarding survey papers, experimental comparisons of various techniques, and the design of new methods at the point where crash severity prediction (CSP) and ML converge. Despite such progress, and as far as we know, there are no comprehensive research articles that theoretically and practically approach the model selection problem (MSP) in CSP. Thus, this paper introduces a bibliometric analysis and experimental benchmark of ML and automated machine learning (AutoML) as a suitable approach to automatically address the MSP in CSP. Firstly, 2318 bibliographic references were consulted to identify relevant authors, trending topics, keywords evolution, and the most common ML methods used in related-case studies, which revealed an opportunity for the use AutoML in the transportation field. Then, we compared AutoML (AutoGluon, Auto-sklearn, TPOT) and ML (CatBoost, Decision Tree, Extra Trees, Gradient Boosting, Gaussian Naive Bayes, Light Gradient Boosting Machine, Random Forest) methods in three case studies using open data portals belonging to the cities of Medellín, Bogotá, and Bucaramanga in Colombia. Our experimentation reveals that AutoGluon and CatBoost are competitive and robust ML approaches to deal with various CSP problems. In addition, we concluded that general-purpose AutoML effectively supports the MSP in CSP without developing domain-focused AutoML methods for this supervised learning problem. Finally, based on the results obtained, we introduce challenges and research opportunities that the community should explore to enhance the contributions that ML and AutoML can bring to CSP and other transportation areas.",
        "DOI": "10.3390/s21248401",
        "affiliation_name": "Universidad Cooperativa de Colombia",
        "affiliation_city": "Medellin",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "Packet flow capacity autonomous operation based on reinforcement learning",
        "paper_author": "Barzegar S.",
        "publication": "Sensors",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "As the dynamicity of the traffic increases, the need for self-network operation becomes more evident. One of the solutions that might bring cost savings to network operators is the dynamic capacity management of large packet flows, especially in the context of packet over optical net-works. Machine Learning, particularly Reinforcement Learning, seems to be an enabler for auto-nomicity as a result of its inherent capacity to learn from experience. However, precisely because of that, RL methods might not be able to provide the required performance (e.g., delay, packet loss, and capacity overprovisioning) when managing the capacity of packet flows, until they learn the optimal policy. In view of that, we propose a management lifecycle with three phases: (i) a self-tuned threshold-based approach operating just after the packet flow is set up and until enough data on the traffic characteristics are available; (ii) an RL operation based on models pre-trained with a generic traffic profile; and (iii) an RL operation with models trained for real traffic. Exhaustive sim-ulation results confirm the poor performance of RL algorithms until the optimal policy is learnt and when traffic characteristics change over time, which prevents deploying such methods in operators’ networks. In contrast, the proposed lifecycle outperforms benchmarking approaches, achieving no-ticeable performance from the beginning of operation while showing robustness against traffic changes.",
        "DOI": "10.3390/s21248306",
        "affiliation_name": "Universitat Politècnica de Catalunya",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Investigating young employee stressors in contemporary society based on user-generated contents",
        "paper_author": "Wang N.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "Understanding stressors is an effective measure to decrease employee stress and improve employee mental health. The extant literature mainly focuses on a singular stressor among various aspects of their work or life. In addition, the extant literature generally uses questionnaires or interviews to obtain data. Data obtained in such ways are often subjective and lack authenticity. We propose a novel machine–human hybrid approach to conduct qualitative content analysis of user-generated online content to explore the stressors of young employees in contemporary society. The user-generated online contents were collected from a famous Q&A platform in China and we adopted natural language processing and deep learning technology to discover knowledge. Our results identified three kinds of new stressors, that is, affection from leaders, affection from the social circle, and the gap between dream and reality. These new identified stressors were due to the lack of social security and regulation, frequent occurrences of social media fearmongering, and subjective cognitive bias, respectively. In light of our findings, we offer valuable practical insights and policy recommendations to relieve stress and improve mental health of young employees. The primary contributions of our work are two-fold, as follows. First, we propose a novel approach to explore the stressors of young employees in contemporary society, which is applicable not only in China, but also in other countries and regions. Second, we expand the scope of job demands-resources (JD-R) theory, which is an important framework for the classification of employee stressors.",
        "DOI": "10.3390/ijerph182413109",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Automatic risk adjustment for profit maximization in renewable dominated short-term electricity markets",
        "paper_author": "Bottieau J.",
        "publication": "International Transactions on Electrical Energy Systems",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "State-of-the-art trading strategies in short-term electricity markets use risk awareness for reducing, inter alia, their exposure to the volatility of electricity prices. To ensure an optimal balance between risk and profit, risk-aversion parameters are traditionally fine-tuned via an offline out-of-sample analysis. Such a computationally-intensive analysis is typically run once, which yields time-invariant risk policies. Instead, this paper proposes the use of machine learning to select, in an online fashion, optimal risk-aversion parameters. This novel automatic risk-tuning approach offers the benefit of continuously adjusting the risk policy based on the dynamically changing market operating conditions. Our approach is tested on two risk-aversion parameters, that is, the confidence level of the conditional value-at-risk and the budget of uncertainty, respectively considering scenario-based and robust optimization frameworks. A set of performed case studies—focusing on the very short-term dispatch of a market actor participating in electricity markets—using real-world market data from the Belgian power system demonstrate the ability of the proposed methodology to outperform traditional offline risk policies.",
        "DOI": "10.1002/2050-7038.13152",
        "affiliation_name": "KU Leuven Energie Instituut",
        "affiliation_city": "Heverlee",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Learning efficient navigation in vortical flow fields",
        "paper_author": "Gunnarson P.",
        "publication": "Nature Communications",
        "citied_by": "46",
        "cover_date": "2021-12-01",
        "Abstract": "Efficient point-to-point navigation in the presence of a background flow field is important for robotic applications such as ocean surveying. In such applications, robots may only have knowledge of their immediate surroundings or be faced with time-varying currents, which limits the use of optimal control techniques. Here, we apply a recently introduced Reinforcement Learning algorithm to discover time-efficient navigation policies to steer a fixed-speed swimmer through unsteady two-dimensional flow fields. The algorithm entails inputting environmental cues into a deep neural network that determines the swimmer’s actions, and deploying Remember and Forget Experience Replay. We find that the resulting swimmers successfully exploit the background flow to reach the target, but that this success depends on the sensed environmental cue. Surprisingly, a velocity sensing approach significantly outperformed a bio-mimetic vorticity sensing approach, and achieved a near 100% success rate in reaching the target locations while approaching the time-efficiency of optimal navigation trajectories.",
        "DOI": "10.1038/s41467-021-27015-y",
        "affiliation_name": "California Institute of Technology Division of Engineering and Applied Science",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Planning maize hybrids adaptation to future climate change by integrating crop modelling with machine learning",
        "paper_author": "Zhang L.",
        "publication": "Environmental Research Letters",
        "citied_by": "22",
        "cover_date": "2021-12-01",
        "Abstract": "Crop hybrid improvement is an efficient and environmental-friendly option to adapt to climate change and increase grain production. However, the adaptability of existing hybrids to a changing climate has not been systematically investigated. Therefore, little is known about the appropriate timing of hybrid adaptation. Here, using a novel hybrid model which coupled CERES-Maize with machine learning, we critically investigated the impacts of climate change on maize productivity with an ensemble of hybrid-specific estimations in China. We determined when and where current hybrids would become unviable and hybrid adaptation need be implemented, as well as which hybrid traits would be desirable. Climate change would have mostly negative impacts on maize productivity, and the magnitudes of yield reductions would highly depend on the growth cycle of the hybrids. Hybrid replacement could partially, but not completely, offset the yield loss caused by projected climate change. Without adaptation, approximately 53% of the cultivation areas would require hybrid renewal before 2050 under the RCP 4.5 and RCP 8.5 emission scenarios. The medium-maturing hybrids with a long grain-filling duration and a high light use efficiency would be promising, although the ideotypic traits could be different for a specific environment. The findings highlight the necessity and urgency of breeding climate resilient hybrids, providing policy-makers and crop breeders with the early signals of when, where and what hybrids will be required, which stimulate proactive investment to facilitate breeding. The proposed crop modelling approach is scalable, largely data-driven and can be used to tackle the longstanding problem of predicting hybrids' future performance to accelerate development of new crop hybrids.",
        "DOI": "10.1088/1748-9326/ac32fd",
        "affiliation_name": "Ministry of Agriculture of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Trend of the spread of COVID-19 in Indonesia using the machine learning prophet algorithm",
        "paper_author": "Hayati N.",
        "publication": "Indonesian Journal of Electrical Engineering and Computer Science",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "Based on information on the BNPB website on 2 September 2020, the positive rate for coronavirus disease (COVID-19) in Indonesia reached 25.25% on 30 August 2020. This is a big challenge for the Indonesian government to reduce the positivity rate to meet the standards safe accepted by World Health Organization (WHO) is 5%. To ensure the accuracy of government policies, accurate data predictions are needed. Therefore, the prophet's machine learning algorithm can be used to see trends in the spread of COVID-19 in the next one year. This algorithm has a fairly high level of accuracy because the data contains time variables which are adjusted to the dataset. In several previous research, the dataset was vast uncertain and small. Meanwhile in this research, data was taken from 2 March 2020 to 12 February 2021 on the KawalCOVID19 website. This data is used to predict from 13 February 2021 to 12 February 2022. There are 3 data used; namely data confirmed, recovered and died. Based on the analysis, the confirmed patient was 22.60-42.11%, died amounted to 21.67%-39.00%, and recovered by 22.53-41.82%. The prediction percentage that the average cases died was 2.43% every day. The accuracy of data confirmed was 43.97%, died was 72.50% and recovered was 84.24%.",
        "DOI": "10.11591/ijeecs.v24.i3.pp1780-1788",
        "affiliation_name": "Nasional University",
        "affiliation_city": "South Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Linking multi-media modeling with machine learning to assess and predict lake chlorophyll a concentrations",
        "paper_author": "Feng Chang C.",
        "publication": "Journal of Great Lakes Research",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "Eutrophication and excessive algal growth pose a threat on aquatic organisms and the health of the public, environment, and the economy. Understanding what drives excessive algal growth can inform mitigation measures and aid in advance planning to minimize impacts. We demonstrate how simulated data from weather, hydrological, and agroecosystem numerical prediction models can be combined with machine learning (ML) to assess and predict chlorophyll a (chl a) concentrations, a proxy for lake eutrophication and algal biomass. The study area is Lake Erie for a 16-year period, 2002–2017. A total of 20 environmental variables from linked and coupled physical models are used as input features to train the ML model with chl a observations from 16 measuring stations. Included are meteorological variables from the Weather Research and Forecasting (WRF) model, hydrological variables from the Variable Infiltration Capacity (VIC) model, and agricultural management practice variables from the Environmental Policy Integrated Climate (EPIC) agroecosystem model. The consolidation of these variables is conducive to a successful prediction of chl a. Aside from the synergistic effects that weather, hydrology, and fertilizers have on eutrophication and excessive algal growth, we found that the application of different forms of both P and N fertilizers are highly ranked for the prediction of chl a concentration. The developed ML model successfully predicts chl a with a coefficient of determination of 0.81, bias of −0.12 μg/l and RMSE of 4.97 μg/l. The developed ML-based modeling approach can be used for impact assessment of agriculture practices in a changing climate that affect chl a concentrations in Lake Erie.",
        "DOI": "10.1016/j.jglr.2021.09.011",
        "affiliation_name": "University of Connecticut Avery Point Campus",
        "affiliation_city": "Groton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Quantitative impact analysis of climate change on residents’ health conditions with improving eco-efficiency in china: A machine learning perspective",
        "paper_author": "Wang X.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "Climate change affects public health, and improving eco-efficiency means reducing the various pollutants that are the result of economic activities. This study provided empirical evidence of the quantitative impact analysis of climate change on the health conditions of residents across China due to improvements that have been made to eco-efficiency. First, the indicators that were collected present adequate graphical trends and regional differences with a priori evidence about their relationships to each other; second, the present study applied Sensitivity Evaluation with Support Vector Machines (SE-SVM) to Chinese provincial panel data, taking the Visits to Hospitals, Outpatients with Emergency Treatment, and Number of Inpatients as proxy variables for the health conditions of the residents in each area and temperature, humidity, precipitation, and sunshine as the climate change variables, simultaneously incorporating the calculated eco-efficiency with six controlling indicators; third, we compared in-sample forecasting to acquire the optimal model in order to conduct elasticity analysis. The results showed that (1) temperature, humidity, precipitation, and sunshine performed well in forecasting the health conditions of the residents and that climate change was a good forecaster for resident health conditions; (2) from the national perspective, climate change had a positive relationship with Visits to Hospitals and Outpatients with Emergency Treatment but a negative relationship with the Number of Inpatients; (3) An increase in regional eco-efficiency of 1% increase the need for Visits to Hospitals and Outpatients with Emergency Treatment by 0.2242% and 0.2688%, respectively, but decreased the Number of Inpatients by 0.6272%; (4) increasing the regional eco-efficiency did not show any positive effects for any individual region because a variety of local activities, resource endowment, and the level of medical technology available in each region played different roles. The main findings of the present study are helpful for decision makers who are trying to optimize policy formulation and implementation measures in the cross-domains of economic, environmental, and public health.",
        "DOI": "10.3390/ijerph182312842",
        "affiliation_name": "Chongqing Normal University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning in Earth and environmental science requires education and research policy reforms",
        "paper_author": "Fleming S.W.",
        "publication": "Nature Geoscience",
        "citied_by": "28",
        "cover_date": "2021-12-01",
        "Abstract": "NA",
        "DOI": "10.1038/s41561-021-00865-3",
        "affiliation_name": "USDA Natural Resources Conservation Service",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep reinforcement learning-based accurate control of planetary soft landing",
        "paper_author": "Xu X.",
        "publication": "Sensors",
        "citied_by": "13",
        "cover_date": "2021-12-01",
        "Abstract": "Planetary soft landing has been studied extensively due to its promising application prospects. In this paper, a soft landing control algorithm based on deep reinforcement learning (DRL) with good convergence property is proposed. First, the soft landing problem of the powered descent phase is formulated and the theoretical basis of Reinforcement Learning (RL) used in this paper is introduced. Second, to make it easier to converge, a reward function is designed to include process rewards like velocity tracking reward, solving the problem of sparse reward. Then, by including the fuel consumption penalty and constraints violation penalty, the lander can learn to achieve velocity tracking goal while saving fuel and keeping attitude angle within safe ranges. Then, simulations of training are carried out under the frameworks of Deep deterministic policy gradient (DDPG), Twin Delayed DDPG (TD3), and Soft Actor Critic (SAC), respectively, which are of the classical RL frameworks, and all converged. Finally, the trained policy is deployed into velocity tracking and soft landing experiments, results of which demonstrate the validity of the algorithm proposed.",
        "DOI": "10.3390/s21238161",
        "affiliation_name": "Harbin Institute of Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Analysis of factors influencing forest loss in south Korea: Statistical models and machine-learning model",
        "paper_author": "Park J.",
        "publication": "Forests",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "Analyzing the current status of forest loss and its causes is crucial for understanding and preparing for future forest changes and the spatial pattern of forest loss. We investigated spatial patterns of forest loss in South Korea and assessed the effects of various factors on forest loss based on spatial heterogeneity. We used the local Moran’s I to classify forest loss spatial patterns as high–high clusters, low–low clusters, high–low outliers, and high–low outliers. Additionally, to assess the effect of factors on forest loss, two statistical models (i.e., ordinary least squares regression (OLS) and geographically weighted regression (GWR) models) and one machine-learning model (i.e., random forest (RF) model) were used. The accuracy of each model was determined using the R2, RMSE, MAE, and AICc. Across South Korea, the forest loss rate was highest in the Seoul–Incheon–Gyeonggi region. Moreover, high–high spatial clusters were found in the Seoul–Incheon–Gyeonggi and Daejeon– Chungnam regions. Among the models, the GWR model was the most accurate. Notably, according to the GWR model, the main factors driving forest loss were road density, cropland area, number of households, and number of tertiary industry establishments. However, the factors driving forest loss had varying degrees of influence depending on the location. Therefore, our findings suggest that spatial heterogeneity should be considered when developing policies to reduce forest loss.",
        "DOI": "10.3390/f12121636",
        "affiliation_name": "Kangwon National University",
        "affiliation_city": "Chuncheon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "The contribution of trees outside of forests to landscape carbon and climate change mitigation in west Africa",
        "paper_author": "Skole D.L.",
        "publication": "Forests",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "While closed canopy forests have been an important focal point for land cover change monitoring and climate change mitigation, less consideration has been given to methods for large scale measurements of trees outside of forests. Trees outside of forests are an important but often overlooked natural resource throughout sub-Saharan Africa, providing benefits for livelihoods as well as climate change mitigation and adaptation. In this study, the development of an individual tree cover map using very high-resolution remote sensing and a comparison with a new automated machine learning mapping product revealed an important contribution of trees outside of forests to landscape tree cover and carbon stocks in a region where trees outside of forests are important components of livelihood systems. Here, we test and demonstrate the use of allometric scaling from remote sensing crown area to provide estimates of landscape-scale carbon stocks. Prominent biomass and carbon maps from global-scale remote sensing greatly underestimate the “invisible” carbon in these sparse tree-based systems. The measurement of tree cover and carbon in these landscapes has important application in climate change mitigation and adaptation policies.",
        "DOI": "10.3390/f12121652",
        "affiliation_name": "Institut Sénégalais de Recherches Agricoles Dakar",
        "affiliation_city": "Dakar",
        "affiliation_country": "Senegal"
    },
    {
        "paper_title": "Drug resistance mutations in HIV: new bioinformatics approaches and challenges",
        "paper_author": "Blassel L.",
        "publication": "Current Opinion in Virology",
        "citied_by": "32",
        "cover_date": "2021-12-01",
        "Abstract": "Drug resistance mutations appear in HIV under treatment pressure. Resistant variants can be transmitted to treatment-naive individuals, which can lead to rapid virological failure and can limit treatment options. Consequently, quantifying the prevalence, emergence and transmission of drug resistance is critical to effectively treating patients and to shape health policies. We review recent bioinformatics developments and in particular describe: (1) the machine learning approaches intended to predict and explain the level of resistance of HIV variants from their sequence data; (2) the phylogenetic methods used to survey the emergence and dynamics of resistant HIV transmission clusters; (3) the impact of deep sequencing in studying within-host and between-host genetic diversity of HIV variants, notably regarding minority resistant variants.",
        "DOI": "10.1016/j.coviro.2021.09.009",
        "affiliation_name": "Edinburgh Medical School",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Mobility in blue-green spaces does not predict COVID-19 transmission: A global analysis",
        "paper_author": "Venter Z.S.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "Mobility restrictions during the COVID-19 pandemic ostensibly prevented the public from transmitting the disease in public places, but they also hampered outdoor recreation, despite the importance of blue-green spaces (e.g., parks and natural areas) for physical and mental health. We assess whether restrictions on human movement, particularly in blue-green spaces, affected the transmission of COVID-19. Our assessment uses a spatially resolved dataset of COVID-19 case numbers for 848 administrative units across 153 countries during the first year of the pandemic (February 2020 to February 2021). We measure mobility in blue-green spaces with planetary-scale aggregate and anonymized mobility flows derived from mobile phone tracking data. We then use machine learning forecast models and linear mixed-effects models to explore predictors of COVID-19 growth rates. After controlling for a number of environmental factors, we find no evidence that increased visits to blue-green space increase COVID-19 transmission. By contrast, increases in the total mobility and relaxation of other non-pharmaceutical interventions such as containment and closure policies predict greater transmission. Ultraviolet radiation stands out as the strongest environmental mitigant of COVID-19 spread, while temperature, humidity, wind speed, and ambient air pollution have little to no effect. Taken together, our analyses produce little evidence to support public health policies that restrict citizens from outdoor mobility in blue-green spaces, which corroborates experimental studies showing low risk of outdoor COVID-19 transmission. However, we acknowledge and discuss some of the challenges of big data approaches to ecological regression analyses such as this, and outline promising directions and opportunities for future research.",
        "DOI": "10.3390/ijerph182312567",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Prevalence and predicting factors of perceived stress among Bangladeshi university students using machine learning algorithms",
        "paper_author": "Rois R.",
        "publication": "Journal of Health, Population and Nutrition",
        "citied_by": "33",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Stress-related mental health problems are one of the most common causes of the burden in university students worldwide. Many studies have been conducted to predict the prevalence of stress among university students, however most of these analyses were predominantly performed using the basic logistic regression (LR) model. As an alternative, we used the advanced machine learning (ML) approaches for detecting significant risk factors and to predict the prevalence of stress among Bangladeshi university students. Methods: This prevalence study surveyed 355 students from twenty-eight different Bangladeshi universities using questions concerning anthropometric measurements, academic, lifestyles, and health-related information, which referred to the perceived stress status of the respondents (yes or no). Boruta algorithm was used in determining the significant prognostic factors of the prevalence of stress. Prediction models were built using decision tree (DT), random forest (RF), support vector machine (SVM), and LR, and their performances were evaluated using parameters of confusion matrix, receiver operating characteristics (ROC) curves, and k-fold cross-validation techniques. Results: One-third of university students reported stress within the last 12 months. Students’ pulse rate, systolic and diastolic blood pressures, sleep status, smoking status, and academic background were selected as the important features for predicting the prevalence of stress. Evaluated performance revealed that the highest performance observed from RF (accuracy = 0.8972, precision = 0.9241, sensitivity = 0.9250, specificity = 0.8148, area under the ROC curve (AUC) = 0.8715, k-fold accuracy = 0.8983) and the lowest from LR (accuracy = 0.7476, precision = 0.8354, sensitivity = 0.8250, specificity = 0.5185, AUC = 0.7822, k-fold accuracy = 07713) and SVM with polynomial kernel of degree 2 (accuracy = 0.7570, precision = 0.7975, sensitivity = 0.8630, specificity = 0.5294, AUC = 0.7717, k-fold accuracy = 0.7855). Overall, the RF model performs better and authentically predicted stress compared with other ML techniques, including individual and interaction effects of predictors. Conclusion: The machine learning framework can be detected the significant prognostic factors and predicted this psychological problem more accurately, thereby helping the policy-makers, stakeholders, and families to understand and prevent this serious crisis by improving policy-making strategies, mental health promotion, and establishing effective university counseling services.",
        "DOI": "10.1186/s41043-021-00276-5",
        "affiliation_name": "Jahangirnagar University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Current applications of artificial intelligence in vascular surgery",
        "paper_author": "Fischer U.M.",
        "publication": "Seminars in Vascular Surgery",
        "citied_by": "20",
        "cover_date": "2021-12-01",
        "Abstract": "Basic foundations of artificial intelligence (AI) include analyzing large amounts of data, recognizing patterns, and predicting outcomes. At the core of AI are well-defined areas, such as machine learning, natural language processing, artificial neural networks, and computer vision. Although research and development of AI in health care is being conducted in many medical subspecialties, only a few applications have been implemented in clinical practice. This is true in vascular surgery, where applications are mostly in the translational research stage. These AI applications are being evaluated in the realms of vascular diagnostics, perioperative medicine, risk stratification, and outcome prediction, among others. Apart from the technical challenges of AI and research outcomes on safe and beneficial use in patient care, ethical issues and policy surrounding AI will present future challenges for its successful implementation. This review will give a brief overview and a basic understanding of AI and summarize the currently available and used clinical AI applications in vascular surgery.",
        "DOI": "10.1053/j.semvascsurg.2021.10.008",
        "affiliation_name": "South Texas Veterans Health Care System",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Landslide susceptibility mapping using artificial neural network tuned by metaheuristic algorithms",
        "paper_author": "Mehrabi M.",
        "publication": "Environmental Earth Sciences",
        "citied_by": "68",
        "cover_date": "2021-12-01",
        "Abstract": "As a frequent natural disaster, landslides incur significant economic and human losses worldwide. The main idea of this paper is to propose novel integrative models for landslide susceptibility evaluation in a prone area of Chaharmahal va Bakhtiari Province in Iran. To do this, four metaheuristic techniques, namely chimp optimization algorithm (ChOA), crow search algorithm (CSA), satin bowerbird optimization (SBO), and water cycle algorithm (WCA) are used to supervise the training of an artificial neural network (ANN). A spatial database is created by 170 historical landslides and 14 most common conditioning factors. The models are optimized in terms of hyper-parameters and elite ones are then used to produce the susceptibility maps. During the training phase, all models could acquire a reliable understanding of the landslide pattern. The obtained accuracy index of area under the receiving operating characteristic curve (AUROC) showed that the maps produced by the WCA-ANN (AUROC = 0.925) and SBO-ANN (AUROC = 0.900) are more accurate than those of the ChOA-ANN (AUROC = 0.851) and CSA-ANN (AUROC = 0.855). Considering this assessment, the suggested hybrid models are reliable enough for landslide susceptibility modeling. Accordingly, the generated susceptibility map can be used for urban planning and generating alert systems over the studied area.",
        "DOI": "10.1007/s12665-021-10098-7",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Machine-learning-based prediction of land prices in Seoul, South Korea",
        "paper_author": "Kim J.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "8",
        "cover_date": "2021-12-01",
        "Abstract": "The accurate estimation of real estate value helps the development of real estate policies that can respond to the complexities and instability of the real estate market. Previously, statistical methods were used to estimate real estate value, but machine learning methods have gained popularity because their predictions are more accurate. In contrast to existing studies that use various machine learning methods to estimate the transactions or list prices of real estate properties without separating the building and land prices, this study estimates land price using a large amount of land-use information obtained from various land-and building-related datasets. The random forest and XGBoost methods were used to estimate 52,900 land prices in Seoul, South Korea, from January 2017 to December 2020. The models were also separately trained for different land uses and different time periods. Overall, the results revealed that XGBoost yields a higher prediction accuracy. Whereas the XGBoost models were more accurate on the 2020 data than on the 2017–2020 data when analyzing residential areas, the random forest models were more accurate on the 2017–2020 data than on the 2020 data. Further analysis will extend the prediction model to consider submarkets determined by price volatility and locality.",
        "DOI": "10.3390/su132313088",
        "affiliation_name": "University of Texas of the Permian Basin",
        "affiliation_city": "Odessa",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advancing health equity with artificial intelligence",
        "paper_author": "Thomasian N.M.",
        "publication": "Journal of Public Health Policy",
        "citied_by": "61",
        "cover_date": "2021-12-01",
        "Abstract": "Population and public health are in the midst of an artificial intelligence revolution capable of radically altering existing models of care delivery and practice. Just as AI seeks to mirror human cognition through its data-driven analytics, it can also reflect the biases present in our collective conscience. In this Viewpoint, we use past and counterfactual examples to illustrate the sequelae of unmitigated bias in healthcare artificial intelligence. Past examples indicate that if the benefits of emerging AI technologies are to be realized, consensus around the regulation of algorithmic bias at the policy level is needed to ensure their ethical integration into the health system. This paper puts forth regulatory strategies for uprooting bias in healthcare AI that can inform ongoing efforts to establish a framework for federal oversight. We highlight three overarching oversight principles in bias mitigation that maps to each phase of the algorithm life cycle.",
        "DOI": "10.1057/s41271-021-00319-5",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Providence",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Inflation Rate Forecasting Using Extreme Learning Machine and Improved Particle Swarm Optimization",
        "paper_author": "Mahmudy W.F.",
        "publication": "International Journal of Intelligent Engineering and Systems",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "Inflation is an important tool to assess the current condition of a nation economy. Uncontrolled inflation rate may have a lot of negative impacts on economic development. Forecasting can be used to control the inflation by making appropriate economic policies. However, uncertainty pattern of the inflation rate may make it hard to forecast. This study proposes an extreme learning machine (ELM) for the inflation rate forecasting. As part of the machine learning algorithm, the ELM has an ability to address uncertainty in data input pattern. However, ELM had weakness in determining initial weights that may produce inaccurate results. So, we propose particle swarm optimization (PSO) to determine good initial weights for the ELM. PSO is a metaheuristic method that gives good results in local searches but requires longer computation time to locate its particles on the global optimum point in the vast search space area. To overcome this problem, auto-speed acceleration algorithm is employed to drive particles of the PSO in searching of the global optimum with lower computation time. The performance of the proposed approach is evaluated using root mean square error (RMSE). A series of computational experiments prove that the proposed approach achieves better results with the average RMSE of 0.01926. This result is better than RMSE of 0.02020 achieved by the original version of ELM.",
        "DOI": "10.22266/ijies2021.1231.09",
        "affiliation_name": "Brawijaya University",
        "affiliation_city": "Malang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "It's not easy being green",
        "paper_author": "The Lancet Digital Health ",
        "publication": "The Lancet Digital Health",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "NA",
        "DOI": "10.1016/S2589-7500(21)00257-0",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Comparative study of groundwater level forecasts using hybrid neural network models",
        "paper_author": "Afkhamifar S.",
        "publication": "Proceedings of the Institution of Civil Engineers: Water Management",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "Groundwater is the world’s central supply of fresh water. Water supply policies, particularly in dry seasons, thus need to be based on accurate modelling of groundwater level (GWL) fluctuations. In the work reported in this paper, a hybrid wavelet-transform-based extreme learning machine (ELM) model was investigated for predicting GWL. Two other popular models – a wavelet-transform based artificial neural network and a wavelet-transform-based adaptive neuro-fuzzy interference system – were used to evaluate the model. GWL data and mean temperatures of observation wells in an Iranian watershed between 1981 and 2017 were used in the study. The performance of the models was assessed be evaluating their root mean square error, correlation coefficient and mean absolute error. The wavelet-transform-based ELM model outperformed the other two models with a correlation coefficient of 0.983 during a 1 month period. The model was also superior to the others in terms of training and testing speeds.",
        "DOI": "10.1680/jwama.20.00062",
        "affiliation_name": "Islamic Azad University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Machine learning methods for “wicked” problems: exploring the complex drivers of modern slavery",
        "paper_author": "Lavelle-Hill R.",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "Forty million people are estimated to be in some form of modern slavery across the globe. Understanding the factors that make any particular individual or geographical region vulnerable to such abuse is essential for the development of effective interventions and policy. Efforts to isolate and assess the importance of individual drivers statistically are impeded by two key challenges: data scarcity and high dimensionality, typical of many “wicked problems”. The hidden nature of modern slavery restricts available data points; and the large number of candidate variables that are potentially predictive of slavery inflate the feature space exponentially. The result is a “small n, large p” setting, where overfitting and significant inter-correlation of explanatory variables can render more traditional statistical approaches problematic. Recent advances in non-parametric computational methods, however, offer scope to overcome such challenges and better capture the complex nature of modern slavery. We present an approach that combines non-linear machine-learning models and strict cross-validation methods with novel variable importance techniques, emphasising the importance of stability of model explanations via a Rashomon-set analysis. This approach is used to model the prevalence of slavery in 48 countries, with results bringing to light the importance of new predictive factors—such as a country’s capacity to protect the physical security of women, which has been previously under-emphasised in quantitative models. Further analyses uncover that women are particularly vulnerable to exploitation in areas where there is poor access to resources. Our model was then leveraged to produce new out-of-sample estimates of slavery prevalence for countries where no survey data currently exists.",
        "DOI": "10.1057/s41599-021-00938-z",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "The role of good governance in the race for global vaccination during the COVID-19 pandemic",
        "paper_author": "Tatar M.",
        "publication": "Scientific Reports",
        "citied_by": "28",
        "cover_date": "2021-12-01",
        "Abstract": "Governments have developed and implemented various policies and interventions to fight the COVID-19 pandemic. COVID-19 vaccines are now being produced and distributed globally. This study investigated the role of good governance and government effectiveness indicators in the acquisition and administration of COVID-19 vaccines at the population level. Data on six World Bank good governance indicators for 172 countries for 2019 and machine-learning methods (K-Means Method and Principal Component Analysis) were used to cluster countries based on these indicators and COVID-19 vaccination rates. XGBoost was used to classify countries based on their vaccination status and identify the relative contribution of each governance indicator to the vaccination rollout in each country. Countries with the highest COVID-19 vaccination rates (e.g., Israel, United Arab Emirates, United States) also have higher effective governance indicators. Regulatory Quality is the most important indicator in predicting COVID-19 vaccination status in a country, followed by Voice and Accountability, and Government Effectiveness. Our findings suggest that coordinated global efforts led by the World Health Organization and wealthier nations may be necessary to assist in the supply and distribution of vaccines to those countries that have less effective governance.",
        "DOI": "10.1038/s41598-021-01831-0",
        "affiliation_name": "Institute for Advanced Studies in Basic Sciences, Zanjan",
        "affiliation_city": "Zanjan",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Antibiotic resistance in microbes: History, mechanisms, therapeutic strategies and future prospects",
        "paper_author": "Uddin T.M.",
        "publication": "Journal of Infection and Public Health",
        "citied_by": "601",
        "cover_date": "2021-12-01",
        "Abstract": "Antibiotics have been used to cure bacterial infections for more than 70 years, and these low-molecular-weight bioactive agents have also been used for a variety of other medicinal applications. In the battle against microbes, antibiotics have certainly been a blessing to human civilization by saving millions of lives. Globally, infections caused by multidrug-resistant (MDR) bacteria are on the rise. Antibiotics are being used to combat diversified bacterial infections. Synthetic biology techniques, in combination with molecular, functional genomic, and metagenomic studies of bacteria, plants, and even marine invertebrates are aimed at unlocking the world's natural products faster than previous methods of antibiotic discovery. There are currently only few viable remedies, potential preventive techniques, and a limited number of antibiotics, thereby necessitating the discovery of innovative medicinal approaches and antimicrobial therapies. MDR is also facilitated by biofilms, which makes infection control more complex. In this review, we have spotlighted comprehensively various aspects of antibiotics viz. overview of antibiotics era, mode of actions of antibiotics, development and mechanisms of antibiotic resistance in bacteria, and future strategies to fight the emerging antimicrobial resistant threat.",
        "DOI": "10.1016/j.jiph.2021.10.020",
        "affiliation_name": "Sarhad University of Science and IT",
        "affiliation_city": "Peshawar",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Spatial disparity of individual and collective walking behaviors: A new theoretical framework",
        "paper_author": "Jiang Y.",
        "publication": "Transportation Research Part D: Transport and Environment",
        "citied_by": "45",
        "cover_date": "2021-12-01",
        "Abstract": "The creation of walkable environments, and the promotion of walkability for health and environmental benefits have been widely advocated. However, the term “walkability” is often associated with two related but distinct walking behaviors: individual and collective walking behaviors. It is unclear whether spatial disparity exists between them, and whether built environment characteristics have distinctive effects on them. This research was the first to explore the spatial disparity between the two types of walking behaviors. Collective walking behaviors were measured using the citywide pedestrian volume, extracted from 219,248 street view images. Individual walking behaviors were measured form a population-level survey. Spatial mismatches were found between the two types of walking behaviors and built environment elements had stronger associations with collective walking behaviors. Therefore, it is prudent to theoretically differentiate collective and individual walking behaviors, and targeted planning policies must be developed to promote one or both types of walking behaviors.",
        "DOI": "10.1016/j.trd.2021.103096",
        "affiliation_name": "City University of Hong Kong Shenzhen Research Institute",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Truck body type classification using a deep representation learning ensemble on 3D point sets",
        "paper_author": "Li Y.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "10",
        "cover_date": "2021-12-01",
        "Abstract": "Understanding the spatiotemporal distribution of commercial vehicles is essential for facilitating strategic pavement design, freight planning, and policy making. Hence, transportation agencies have been increasingly interested in collecting truck body configuration data due to its strong association with industries and freight commodities, to better understand their distinct operational characteristics and impacts on infrastructure and the environment. The rapid advancement of Light Detection and Ranging (LiDAR) technology has facilitated the development of non-intrusive detection solutions that are able to accurately classify truck body types in detail. This paper proposes a new truck classification method using a LiDAR sensor oriented to provide a wide field-of-view of roadways. In order to enrich the sparse point cloud obtained from the sensor, point clouds originating from the same truck across consecutive frames were grouped and combined using a two-stage vehicle reconstruction framework to generate a dense three-dimensional (3D) point cloud representation of each truck. Subsequently, PointNet – a deep representation learning algorithm – was adopted to train the classification model from reconstructed point clouds. The model utilizes low-level features extracted from the 3D point clouds and detects key features associated with each truck class. Finally, model ensemble techniques were explored to reduce the generalization error by averaging the results of seven PointNet models and further enhancing the overall model performance. The optimal number of models in the ensemble was determined through a comprehensive sensitivity analysis with the consideration of the average correct classification rate (CCR), the variability of the prediction results, and the computation efficiency. The developed model is capable of distinguishing passenger vehicles and 29 different truck body configurations with an average CCR of 83 percent. The average correct classification rate of the developed method on the test dataset was 90 percent for trucks pulling a large trailer(s).",
        "DOI": "10.1016/j.trc.2021.103461",
        "affiliation_name": "Samueli School of Engineering",
        "affiliation_city": "Irvine",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Crowd-Out and Emergency Department Utilization",
        "paper_author": "Ellis C.M.",
        "publication": "Journal of Health Economics",
        "citied_by": "6",
        "cover_date": "2021-12-01",
        "Abstract": "When consumers gain Medicaid, their cost of healthcare changes. The direction of this change determines how utilization changes. The previously uninsured see a stark decrease in the price of primary care after gaining public insurance. Due to charity care, they may face an increase in the price of emergency department care. The previously insured see a reduction in emergency department prices and decreased access to primary care. We examine the impact of the prior insurance status of the newly publicly insured on substitution between healthcare. We base our identification on California's LIHP and ACA Medicaid expansions. One challenge we face is estimating crowd-out. We use machine learning techniques to predict prior insurance status based on observable covariates in cross-sectional data. We find an increase in emergency department utilization caused entirely by those crowded-out whose access to primary care has decreased. We find the opposite utilization patterns for the previously uninsured.",
        "DOI": "10.1016/j.jhealeco.2021.102542",
        "affiliation_name": "Fox School of Business",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Low-value care and excess out-of-pocket expenditure among older adults with incident cancer – A machine learning approach",
        "paper_author": "Iloabuchi C.",
        "publication": "Journal of Cancer Policy",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "Objective: To evaluate the association of low-value care with excess out-of-pocket expenditure among older adults diagnosed with incident breast, prostate, colorectal cancers, and Non-Hodgkin's Lymphoma. Methods: We used a retrospective cohort study design with 12-month baseline and follow-up periods. We identified a cohort of older adults (age ≥ 66 years) diagnosed with breast, prostate, colorectal cancers, or Non-Hodgkin's lymphoma between January 2014 and December 2014. We assessed low-value care and patient out-of-pocket expenditure in the follow-up period. We identified relevant low-value services using ICD9/ICD10 and CPT/HCPCS codes from the linked health claims and patient out-of-pocket expenditure from Medicare claim files and expressed expenditure in 2016 USD. Results: About 29 % of older adults received at least one low-value care procedure during the follow-up period. Low-value care differed by gender, and rates were higher in women with colorectal cancer (32.7 %) vs. (28.8 %) and NHL (40 %) vs. (39 %) compared to men. Individuals who received one or more low-value care procedures had significantly higher mean out-of-pocket expenditure ($8,726 ± $7,214) vs. ($6,802 ± $6,102). XGBOOST, a machine learning algorithm revealed that low-value care was among the five leading predictors of OOP expenditure. Conclusion: One in four older adults with incident cancer received low-value care in 12-months after a cancer diagnosis. Across all cancer populations, individuals who received low-value care had significantly higher out-of-pocket expenditure. Excess out-of-pocket expenditure was driven by low-value care, fragmentation of care, and an increasing number of pre-existing chronic conditions. Policy Statement: This study focuses on health policy issues, specifically value-based care and its findings have important clinical and policy implications for Centers for Medicare and Medicaid Services (CMS) which has issued a roadmap for states to accelerate the adoption of value-based care, with the Department of Health and Human Services (HHS) setting a goal of converting 50 % of traditional Medicare payment systems to alternative payment models tied to value-based care by 2022.",
        "DOI": "10.1016/j.jcpo.2021.100312",
        "affiliation_name": "WVU Health Sciences Center Morgantown",
        "affiliation_city": "Morgantown",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neural predictor based quantum architecture search",
        "paper_author": "Zhang S.X.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "51",
        "cover_date": "2021-12-01",
        "Abstract": "Variational quantum algorithms (VQAs) are widely speculated to deliver quantum advantages for practical problems under the quantum–classical hybrid computational paradigm in the near term. Both theoretical and practical developments of VQAs share many similarities with those of deep learning. For instance, a key component of VQAs is the design of task-dependent parameterized quantum circuits (PQCs) as in the case of designing a good neural architecture in deep learning. Partly inspired by the recent success of AutoML and neural architecture search (NAS), quantum architecture search (QAS) is a collection of methods devised to engineer an optimal task-specific PQC. It has been proven that QAS-designed VQAs can outperform expert-crafted VQAs in various scenarios. In this work, we propose to use a neural network based predictor as the evaluation policy for QAS. We demonstrate a neural predictor guided QAS can discover powerful quantum circuit ansatz, yielding state-of-the-art results for various examples from quantum simulation and quantum machine learning. Notably, neural predictor guided QAS provides a better solution than that by the random-search baseline while using an order of magnitude less of circuit evaluations. Moreover, the predictor for QAS as well as the optimal ansatz found by QAS can both be transferred and generalized to address similar problems.",
        "DOI": "10.1088/2632-2153/ac28dd",
        "affiliation_name": "Tencent",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Vision-Language Navigation Policy Learning and Adaptation",
        "paper_author": "Wang X.",
        "publication": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "Vision-language navigation (VLN) is the task of navigating an embodied agent to carry out natural language instructions inside real 3D environments. In this paper, we study how to address three critical challenges for this task: the cross-modal grounding, the ill-posed feedback, and the generalization problems. First, we propose a novel Reinforced Cross-Modal Matching (RCM) approach that enforces cross-modal grounding both locally and globally via reinforcement learning (RL). Particularly, a matching critic is used to provide an intrinsic reward to encourage global matching between instructions and trajectories, and a reasoning navigator is employed to perform cross-modal grounding in the local visual scene. Evaluation on a VLN benchmark dataset shows that our RCM model significantly outperforms baseline methods by 10 percent on Success Rate weighted by Path Length (SPL) and achieves the state-of-the-art performance. To improve the generalizability of the learned policy, we further introduce a Self-Supervised Imitation Learning (SIL) method to explore and adapt to unseen environments by imitating its own past, good decisions. We demonstrate that SIL can approximate a better and more efficient policy, which tremendously minimizes the success rate performance gap between seen and unseen environments (from 30.7 to 11.7 percent).",
        "DOI": "10.1109/TPAMI.2020.2972281",
        "affiliation_name": "UC Santa Barbara College of Engineering",
        "affiliation_city": "Santa Barbara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Analysis of the effectiveness of face-coverings on the death ratio of COVID-19 using machine learning",
        "paper_author": "Lafzi A.",
        "publication": "Scientific Reports",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "The recent outbreak of the COVID-19 led to death of millions of people worldwide. To stave off the spread of the virus, the authorities in the US employed different strategies, including the mask mandate order issued by the states’ governors. In the current work, we defined a parameter called average death ratio as the monthly average of the number of daily deaths to the monthly average number of daily cases. We utilized survey data to quantify people’s abidance by the mask mandate order. Additionally, we implicitly addressed the extent to which people abide by the mask mandate order, which may depend on some parameters such as population, income, and education level. Using different machine learning classification algorithms, we investigated how the decrease or increase in death ratio for the counties in the US West Coast correlates with the input parameters. The results showed that for the majority of counties, the mask mandate order decreased the death ratio, reflecting the effectiveness of such a preventive measure on the West Coast. Additionally, the changes in the death ratio demonstrated a noticeable correlation with the socio-economic condition of each county. Moreover, the results showed a promising classification accuracy score as high as 90%.",
        "DOI": "10.1038/s41598-021-01005-y",
        "affiliation_name": "Swanson School of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Estimation of the rice water footprint based on machine learning algorithms",
        "paper_author": "Mokhtar A.",
        "publication": "Computers and Electronics in Agriculture",
        "citied_by": "21",
        "cover_date": "2021-12-01",
        "Abstract": "It is essential to investigate the impact of climate change on the water footprint (WF) of rice from both historical simulation and future projections. In this study, four machine learning (ML) models, including random tree (RT), random forest (RF), additive regression (AR) and reduced error pruning tree (REPT) were used to model blue and green water footprint (BWFP and GWFP) for the present and future stages in the Yunnan Province, southwest China. Climate variables of daily precipitation, temperature, solar radiation, sunshine hours, wind speed, relative humidity and vapor pressure deficit data, yield and sown areas of rice were collected form 16 districts from 1990 to 2018. Six different scenarios (Sc1-Sc6) with different combinations of climate variables, crop coefficient and sown areas were used as inputs of the ML models for each of blue and green water footprint. Also, future climate projections of maximum (Tmax) and minimum (Tmin) temperatures, precipitation and sunshine were adopted for two different emission scenarios, RCP 4.5 and 8.5 from 2021to 2050, based on Geophysical Fluid Dynamics Laboratory (GFDL-ESM2M) model. For BWFP, the RT model in Sc1 with inputs of solar radiation, humidity, and vapor pressure deficit, was superior to the other scenarios with root mean square error (RMSE) and mean average percentage error (MAPE) values of 11.82 (m3 ton-1) and 0.5%, respectively. Sc4 (sown area, Tmin, sunshine hours) and Sc5 (sown area, Tmin, Tmax, crop coefficient) were the best two scenarios for all models applied for BWFP, while addition of precipitation to these two scenarios were the best for GWFP. Further, GWFP was highly negative anomaly in 2011 by 46%, 34% and 32% for the districts 5, 1 and 2 respectively, followed by 2010. Predictions of variable trends in the future showed that crop evapotranspiration during the growing season would increase in all the districts, although effective precipitation (Peff) would have both decreasing and increasing trends. Furthermore, BWFP and GWFP will have an upward trend in the future based on RCP4.5 in Sc4. This investigation addresses water footprint prediction which may assist in mitigation plans such as policies for sustainable water-use and development plans for food security.",
        "DOI": "10.1016/j.compag.2021.106501",
        "affiliation_name": "Faculty of Agriculture",
        "affiliation_city": "Mansoura",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "A Hybrid Deep Reinforcement Learning for Autonomous Vehicles Smart-Platooning",
        "paper_author": "Prathiba S.B.",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "82",
        "cover_date": "2021-12-01",
        "Abstract": "The development of Autonomous Vehicles (AVs) envisions the promising technology of future Intelligent Transportation Systems (ITS). However, the complex road structures and increased vehicles cause traffic congestion and road safety, which eventually leads to horrible accidents. Cooperative driving of AVs, a groundbreaking initiative of vehicle platooning, epitomizes the next wave in vehicular technology through minimizing accident risks, transport times, costs, energy, and fuel consumption. However, the traditional machine learning-based platooning approaches fail to regulate the policy with the dynamic feature of AVs. This paper proposes a hybrid Deep Reinforcement learning and Genetic algorithm for Smart-Platooning (DRG-SP) the AVs. The leverage of the deep reinforcement learning mechanism addresses the computational complexity and accommodates the high dynamic platoon environments. Adopting the Genetic Algorithm in Deep Reinforcement learning overcomes the slow convergence problem and offers long-term performance. The simulation results reveal that the Smart-Platooning effectively forms and maintains the platoons by minimizing traffic congestion and fuel consumption.",
        "DOI": "10.1109/TVT.2021.3122257",
        "affiliation_name": "University of Petroleum and Energy Studies",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Exploration of the investment patterns of potential retail banking customers using two-stage cluster analysis",
        "paper_author": "Kovács T.",
        "publication": "Journal of Big Data",
        "citied_by": "17",
        "cover_date": "2021-12-01",
        "Abstract": "Identifying investment patterns as part of customer segmentation is one of the most important tasks in retail banking. Clustering customers effectively is an important element of improving marketing policy and strategic planning. There are several methods for identifying similar groups of customers and describing their characteristics to offer them appropriate products. However, using machine learning methods is rare, and the application is limited for certain types of data. The aim of this study is to investigate the benefits of using a two-stage clustering method using neural-network-based Kohonen self-organizing maps followed by hierarchical clustering for identifying the investment patterns of potential retail banking customers. The unique benefit of this method is the ability to use both categorical and numerical variables at the same time. This research examined 1,542 responses received for an online investment survey, focusing on the questions that are related to the respondents’ investment preferences and their current financial assets. The research utilizes descriptive statistics and multiple correspondence analysis (MCA) to understand the variables and Kohonen self-organizing maps (SOMs), in combination with hierarchical clustering, to identify customer groups and describe the characteristics of these clusters. The analysis was able to identify clusters of potential customers with similar preferences and gained insights into their investment patterns related to their investment portfolio and investment behavior, including their savings profile, attitude to risk-taking, and preferences for investment advice. These findings were supported by additional insights through the application of multiple correspondence analysis (MCA) describing patterns of financial instruments and portfolios. The main contribution of the research is the combined application of the machine learning methods Kohonen SOM, hierarchical clustering, and MCA for investment pattern analysis in the retail banking business.",
        "DOI": "10.1186/s40537-021-00529-4",
        "affiliation_name": "Budapesti Corvinus Egyetem",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "Incident Reporting Systems: What Will It Take to Make Them Less Frustrating and Achieve Anything Useful?: Incident Reporting Systems",
        "paper_author": "Shojania K.G.",
        "publication": "Joint Commission Journal on Quality and Patient Safety",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.jcjq.2021.10.001",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Reshaping energy policy based on social and human dimensions: an analysis of human-building interactions among societies in transition in GCC countries",
        "paper_author": "Ghofrani A.",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "Without major structural changes, social sciences can potentially bolster economic diversification and strategic planning efforts in developing countries. This article presents an analysis of a set of human-oriented dimensions to enhance energy policies associated with the building sector in developing countries with similarities to the Gulf Cooperation Council union (GCC). A clear understanding of human dimensions in the GCC union’s energy policy is crucial due to social complexities and large numbers of expatriate communities and migrant workers with unknown cultural, behavioral, and financial diversities with respect to local communities. This study evaluates the correlations of demographic, socioeconomic, and behavioral dimensions with human–building interactions to identify the main contributors that create discrepancies in human habits, well-being, motivations, responsibilities, and energy use based on a sample of 2200 respondents in Qatar. Moreover, this study is extended to explore human indoor comfort perception dependencies with building features. Behavioral associations with financial drivers, including energy subsidies and demand response programs, are investigated. The patterns in the data are analyzed and attributed to applications in energy policy concerning awareness, social well-being, and interventions. The sample is clustered into various consumer classes, and a feature importance analysis is conducted via machine learning methods to find the key contributors to consumer behavior. The outcomes show profound insight into how human factors influence consumption, consequence awareness, self-responsibility, habits, norms, and comfort perception in residential and work environments. The findings of this study can assist decision-makers in creating targeted strategies to enhance the efficacy of energy policies and improve sustainability performance indicators.",
        "DOI": "10.1057/s41599-021-00904-9",
        "affiliation_name": "Department of International Affairs, College of Arts and Sciences, Qatar University",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar"
    },
    {
        "paper_title": "Coverage path planning for maritime search and rescue using reinforcement learning",
        "paper_author": "Ai B.",
        "publication": "Ocean Engineering",
        "citied_by": "65",
        "cover_date": "2021-12-01",
        "Abstract": "In maritime search and rescue (SAR), the planning of the search path will directly affect the efficiency of searching for people overboard in the search area. However, traditional SAR decision-making schemes often adopt a fixed search path planning mode, but the limits are poor flexibility, low efficiency, and insufficient intelligence. This paper plans a search path with the shortest time-consuming and priority coverage of high-probability areas, considering complete coverage of maritime SAR areas and avoiding maritime obstacles. Firstly, a maritime SAR environment model is built using marine environmental field data and electronic charts. Secondly, an autonomous coverage path planning model for maritime SAR is proposed based on reinforcement learning, in which a reward function with multiple constraints is designed to guide the navigation action of the vessel agent. In the iterative training process of the path planning model, the random action selection probability is dynamically adjusted by the nonlinear action selection policy to ensure the stable convergence of the model. Finally, the experimental verification is conducted in different small-scale maritime SAR simulation scenarios. The results indicate that the search path can cover the high-probability areas preferentially with lower repeated coverage and shorter path length compared with other path planning algorithms.",
        "DOI": "10.1016/j.oceaneng.2021.110098",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sensitivity analysis: A discipline coming of age",
        "paper_author": "Saltelli A.",
        "publication": "Environmental Modelling and Software",
        "citied_by": "44",
        "cover_date": "2021-12-01",
        "Abstract": "Sensitivity analysis (SA) as a ‘formal’ and ‘standard’ component of scientific development and policy support is relatively young. Many researchers and practitioners from a wide range of disciplines have contributed to SA over the last three decades, and the SAMO (sensitivity analysis of model output) conferences, since 1995, have been the primary driver of breeding a community culture in this heterogeneous population. Now, SA is evolving into a mature and independent field of science, indeed a discipline with emerging applications extending well into new areas such as data science and machine learning. At this growth stage, the present editorial leads a special issue consisting of one Position Paper on “The future of sensitivity analysis” and 11 research papers on “Sensitivity analysis for environmental modelling” published in Environmental Modelling & Software in 2020–21.",
        "DOI": "10.1016/j.envsoft.2021.105226",
        "affiliation_name": "Innovation Academy for Precision Measurement Science and Technology,CAS",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Mathematical model and enhanced cooperative co-evolutionary algorithm for scheduling energy-efficient manufacturing cell",
        "paper_author": "Cheng L.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "16",
        "cover_date": "2021-12-01",
        "Abstract": "Owing to the rapid exhaustion of energy in the manufacturing sector, energy-efficient scheduling has become a research hotspot. This work addresses an energy-efficient manufacturing cell scheduling problem, in which three major energy-saving strategies, machine off/on criterion, speed-scaling policy and transportation optimization strategy, are simultaneously utilized to save energy comprehensively. A mixed-integer linear programming model is hereafter developed to reduce the transportation energy, processing energy and standby energy via cell formation, cell scheduling and machine off/on decision respectively. To solve this problem efficiently, an enhanced cooperative co-evolutionary algorithm (ECCA) with two improvements is developed. Specifically, four energy-oriented heuristic rules are designed to create initial sub-swarms with lower energy consumption; a Q-learning-based sub-swarm size adjustment mechanism is developed to maximize the exploration efficiency across all sub-problem domains and escape from local optima. Experimental results indicate that the two improvements in ECCA are effective, and the proposed ECCA significantly outperforms six state-of-the-art algorithms with a p-value much less than 0.0001. More importantly, by simultaneously employing the three major energy-saving strategies in manufacturing cells, the resulted energy-saving ratio is above 5%.",
        "DOI": "10.1016/j.jclepro.2021.129248",
        "affiliation_name": "Wuhan University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Bitcoin transaction strategy construction based on deep reinforcement learning",
        "paper_author": "Liu F.",
        "publication": "Applied Soft Computing",
        "citied_by": "32",
        "cover_date": "2021-12-01",
        "Abstract": "The emerging cryptocurrency market has lately received great attention for asset allocation due to its decentralization uniqueness. However, its volatility and brand new trading mode has made it challenging to devising an acceptable automatically-generating strategy. This study proposes a framework for automatic high-frequency bitcoin transactions based on a deep reinforcement learning algorithm — proximal policy optimization (PPO). The framework creatively regards the transaction process as actions, returns as awards and prices as states to align with the idea of reinforcement learning. It compares advanced machine learning-based models for static price predictions including support vector machine (SVM), multi-layer perceptron (MLP), long short-term memory (LSTM), temporal convolutional network (TCN), and Transformer by applying them to the real-time bitcoin price and the experimental results demonstrate that LSTM outperforms. Then an automatically-generating transaction strategy is constructed building on PPO with LSTM as the basis to construct the policy. Extensive empirical studies validate that the proposed method perform superiorly to various common trading strategy benchmarks for a single financial product. The approach is able to trade bitcoins in a simulated environment with synchronous data and obtains a 31.67% more return than that of the best benchmark, improving the benchmark by 12.75%. The proposed framework can earn excess returns through both the period of volatility and surge, which opens the door to research on building a single cryptocurrency trading strategy based on deep learning. Visualizations of trading the process show how the model handles high-frequency transactions to provide inspiration and demonstrate that it can be expanded to other financial products.",
        "DOI": "10.1016/j.asoc.2021.107952",
        "affiliation_name": "Hanyang University ERICA Campus",
        "affiliation_city": "Ansan",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Multi-agent machine learning in self-organizing systems",
        "paper_author": "Hejazi E.",
        "publication": "Information Sciences",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "This paper develops a novel insight and procedure that includes a variety of algorithms for finding the best solution in a structured multi-agent system with internal communications and a global purpose. In other words, it finds the optimal communication structure among agents and the optimal policy in this structure. First, a unique reinforcement learning algorithm is proposed to find the optimal policy of each agent in a fixed structure with non-linear function approximators like artificial neural networks (ANN) and with eligibility traces. Secondly, a mechanism is presented to perform self-organization based on the information of the learned policy. Finally, an algorithm that can discover an appropriate inter-structure mapping and then can transfer the previous knowledge to the new structure is developed, which increases the speed of the learning in this new environment after self-organization. This paper is one of the first works that analyzes the problem fully theoretically and devises some algorithms to find the best solution. We use a simplified version of the distributed task allocation problem (DTAP) as our case study. The experimental results verify the stability of our approach and show the high speed of finding the optimal solution as a result of using transfer learning.",
        "DOI": "10.1016/j.ins.2021.09.013",
        "affiliation_name": "Sharif University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Evolving hierarchical memory-prediction machines in multi-task reinforcement learning",
        "paper_author": "Kelly S.",
        "publication": "Genetic Programming and Evolvable Machines",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "A fundamental aspect of intelligent agent behaviour is the ability to encode salient features of experience in memory and use these memories, in combination with current sensory information, to predict the best action for each situation such that long-term objectives are maximized. The world is highly dynamic, and behavioural agents must generalize across a variety of environments and objectives over time. This scenario can be modeled as a partially-observable multi-task reinforcement learning problem. We use genetic programming to evolve highly-generalized agents capable of operating in six unique environments from the control literature, including OpenAI’s entire Classic Control suite. This requires the agent to support discrete and continuous actions simultaneously. No task-identification sensor inputs are provided, thus agents must identify tasks from the dynamics of state variables alone and define control policies for each task. We show that emergent hierarchical structure in the evolving programs leads to multi-task agents that succeed by performing a temporal decomposition and encoding of the problem environments in memory. The resulting agents are competitive with task-specific agents in all six environments. Furthermore, the hierarchical structure of programs allows for dynamic run-time complexity, which results in relatively efficient operation.",
        "DOI": "10.1007/s10710-021-09418-4",
        "affiliation_name": "Michigan State University",
        "affiliation_city": "East Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "SLO-Aware Inference Scheduler for Heterogeneous Processors in Edge Platforms",
        "paper_author": "Seo W.",
        "publication": "ACM Transactions on Architecture and Code Optimization",
        "citied_by": "30",
        "cover_date": "2021-12-01",
        "Abstract": "With the proliferation of applications with machine learning (ML), the importance of edge platforms has been growing to process streaming sensor, data locally without resorting to remote servers. Such edge platforms are commonly equipped with heterogeneous computing processors such as GPU, DSP, and other accelerators, but their computational and energy budget are severely constrained compared to the data center servers. However, as an edge platform must perform the processing of multiple machine learning models concurrently for multimodal sensor data, its scheduling problem poses a new challenge to map heterogeneous machine learning computation to heterogeneous computing processors. Furthermore, processing of each input must provide a certain level of bounded response latency, making the scheduling decision critical for the edge platform. This article proposes a set of new heterogeneity-Aware ML inference scheduling policies for edge platforms. Based on the regularity of computation in common ML tasks, the scheduler uses the pre-profiled behavior of each ML model and routes requests to the most appropriate processors. It also aims to satisfy the service-level objective (SLO) requirement while reducing the energy consumption for each request. For such SLO supports, the challenge of ML computation on GPUs and DSP is its inflexible preemption capability. To avoid the delay caused by a long task, the proposed scheduler decomposes a large ML task to sub-Tasks by its layer in the DNN model.",
        "DOI": "10.1145/3460352",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Device Hopping: Transparent Mid-Kernel Runtime Switching for Heterogeneous Systems",
        "paper_author": "Metzger P.",
        "publication": "ACM Transactions on Architecture and Code Optimization",
        "citied_by": "0",
        "cover_date": "2021-12-01",
        "Abstract": "Existing OS techniques for homogeneous many-core systems make it simple for single and multithreaded applications to migrate between cores. Heterogeneous systems do not benefit so fully from this flexibility, and applications that cannot migrate in mid-execution may lose potential performance. The situation is particularly challenging when a switch of language runtime would be desirable in conjunction with a migration. We present a case study in making heterogeneous CPU + GPU systems more flexible in this respect. Our technique for fine-grained application migration, allows switches between OpenMP, OpenCL, and CUDA execution, in conjunction with migrations from GPU to CPU, and CPU to GPU. To achieve this, we subdivide iteration spaces into slices, and consider migration on a slice-by-slice basis. We show that slice sizes can be learned offline by machine learning models. To further improve performance, memory transfers are made migration-Aware. The complexity of the migration capability is hidden from programmers behind a high-level programming model. We present a detailed evaluation of our mid-kernel migration mechanism with the First Come, First Served scheduling policy. We compare our technique in a focused evaluation scenario against idealized kernel-by-kernel scheduling, which is typical for current systems, and makes perfect kernel to device scheduling decisions, but cannot migrate kernels mid-execution. Models show that up to 1.33× speedup can be achieved over these systems by adding fine-grained migration. Our experimental results with all nine applicable SHOC and Rodinia benchmarks achieve speedups of up to 1.30× (1.08× on average) over an implementation of a perfect but kernel-migration incapable scheduler when migrated to a faster device. Our mechanism and slice size choices introduce an average slowdown of only 2.44% if kernels never migrate. Lastly, our programming model reduces the code size by at least 88% if compared to manual implementations of migratable kernels.",
        "DOI": "10.1145/3471909",
        "affiliation_name": "The University of Edinburgh",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Advanced machine learning decision policies for diameter control of carbon nanotubes",
        "paper_author": "Rao R.",
        "publication": "npj Computational Materials",
        "citied_by": "16",
        "cover_date": "2021-12-01",
        "Abstract": "The diameters of single-walled carbon nanotubes (SWCNTs) are directly related to their electronic properties, making diameter control highly desirable for a number of applications. Here we utilized a machine learning planner based on the Expected Improvement decision policy that mapped regions where growth was feasible vs. not feasible and further optimized synthesis conditions to selectively grow SWCNTs within a narrow diameter range. We maximized two ranges corresponding to Raman radial breathing mode frequencies around 265 and 225 cm−1 (SWCNT diameters around 0.92 and 1.06 nm, respectively), and our planner found optimal synthesis conditions within a hundred experiments. Extensive post-growth characterization showed high selectivity in the optimized growth experiments compared to the unoptimized growth experiments. Remarkably, our planner revealed significantly different synthesis conditions for maximizing the two diameter ranges in spite of their relative closeness. Our study shows the promise for machine learning-driven diameter optimization and paves the way towards chirality-controlled SWCNT growth.",
        "DOI": "10.1038/s41524-021-00629-y",
        "affiliation_name": "Department of Materials Design and Innovation",
        "affiliation_city": "Buffalo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Understanding differences between static and dynamic nitrogen fertilizer tools using simulation modeling",
        "paper_author": "Mandrini G.",
        "publication": "Agricultural Systems",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "CONTEXT: Improving nitrogen (N) fertilizer recommendations for maize (Zea mays L.) in the US Midwest has been the focus of much research, yet there is no agreement for which methodology is the best to balance trade-offs between production and environmental outcomes. This study investigated the strengths and limitations of two broad approaches: dynamic and static recommendation tools. Dynamic tools use advanced technology to predict the Economically Optimum N Rate (EONR) using year-specific soil, weather, and crop growth characteristics to detect conditions that need lower or higher N rates. Static tools provide regional N recommendations that are static over time, maximizing long-term profits rather than predicting the best EONR for each field and season. OBJECTIVE: The objective of this work was to explain the interactions between the accuracy, profitability, and environmental losses for different N recommendation tools under a wide range of production scenarios. METHODS: For this, we used a calibrated synthetic dataset of 4200 fields over 30 years. In the first part, we compared multiple N recommendations tools belonging to the static and dynamic groups. In the second part, we selected each group's best tools and compared them in detail. RESULTS AND CONCLUSION: From an economic view, results indicate that increasing profitability by increasing the accuracy in EONR predictions with dynamic tools is challenging. The reason is that these more accurate tools are not perfect, and around half of the time, they under predict. In that situation, the yield penalty is higher, and the economic loss is usually not compensated by savings in N fertilizer costs associated with other more accurate recommendations. The static recommendations avoid this penalty by recommending slightly higher N rates, providing similar profits. From an environmental view, both tools can reduce N leaching by 15%, dynamic tool by being more accurate overall, but the static tool could achieve it by recommending on the lower end of their current recommended N profitable range. SIGNIFICANCE: Our analysis suggests that we need to re-think the goals of N management tools. Higher complexity in N management may not necessarily increase profits and reduce N leaching. In fact, there is current potential to reduce N leaching by simply reducing static recommendations without hurting profits. For either approach, this study highlights the need to develop other ways (education, environmental awareness, policies) to account for environmental benefits and provide clear incentives for farmers to adopt these tools and increase the eco-efficiency of agriculture.",
        "DOI": "10.1016/j.agsy.2021.103275",
        "affiliation_name": "University of Nebraska–Lincoln",
        "affiliation_city": "Lincoln",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Political, economic, social, technological, legal and environmental dimensions of electric vehicle adoption in the United States: A social-media interaction analysis",
        "paper_author": "Debnath R.",
        "publication": "Renewable and Sustainable Energy Reviews",
        "citied_by": "62",
        "cover_date": "2021-12-01",
        "Abstract": "Many governments have begun to adopt aggressive targets for electric vehicles. However, studies of the drivers of electric vehicle (EV) adoption are scarce. Social media interactions can provide a new data-driven vantage point to explore such drivers. This study uses data from 36,000 public posts on Facebook to investigate intersectionality in EV-communication as per the Political, Economic, Social, Technological, Legal and Environmental (PESTLE) categories. A computational social science methodology was adopted using a mixed-method application of social network analysis and machine learning-based topic modelling through Latent Dirichlet Allocation algorithm on a 600,000-text corpus extracted from the Facebook posts. Results showed that political, economic, and legal posts had dense clusters around the technology policy of EV, the institutional discourse of electrification of the federal vehicle fleet, and tax and credit framework politics. The environmental and social dimensions had a higher discourse for social justice, clean air, and better health and well-being. A market shift towards EV as a service industry was observed in the technology and economics-related posts. These findings can help policymakers, and planners design contextualised energy policy for influencing EV adoption in the U.S. and other countries.",
        "DOI": "10.1016/j.rser.2021.111707",
        "affiliation_name": "Centre for Research in the Arts, Social Sciences and Humanities",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Public parts, resocialized autonomous communal life",
        "paper_author": "Rodrigues Silva Dória D.",
        "publication": "International Journal of Architectural Computing",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "Commoning embodies the product of social contracts and behaviors between groups of individuals. In the case of social housing and the establishment of physical domains for life, commoning is an intersection of these contracts and the restrictions and policies that prohibit and allow them to occur within municipalities. Via a platform-based project entitled Public Parts (2020), this article will also present positions on the reification of the common through a set of design methodologies and implementations of automation. This platform seeks to subvert typical platform models to decrease ownership, increase access, and produce a new form of communal autonomous life amongst individuals that constitute the rapidly expanding freelance, work from home, and gig economies. Furthermore, this text investigates the consequences of merging domestic space with artificial intelligence by implementing machine learning to reconfigure spaces and program. The problems that arise from the deployment of machine learning algorithms involve issues of collection, usage, and ownership of data. Through the physical design of space, and a central AI which manages the platform and the automated management of space, the core objective of Public Parts is to reify the common through architecture and collectively owned data.",
        "DOI": "10.1177/14780771211039085",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A machine learning model to estimate ambient PM<inf>2.5</inf> concentrations in industrialized highveld region of South Africa",
        "paper_author": "Zhang D.",
        "publication": "Remote Sensing of Environment",
        "citied_by": "20",
        "cover_date": "2021-12-01",
        "Abstract": "Exposure to fine particulate matter (PM2.5) has been linked to a substantial disease burden globally, yet little has been done to estimate the population health risks of PM2.5 in South Africa due to the lack of high-resolution PM2.5 exposure estimates. We developed a random forest model to estimate daily PM2.5 concentrations at 1 km2 resolution in and around industrialized Gauteng Province, South Africa, by combining satellite aerosol optical depth (AOD), meteorology, land use, and socioeconomic data. We then compared PM2.5 concentrations in the study domain before and after the implementation of the new national air quality standards. We aimed to test whether machine learning models are suitable for regions with sparse ground observations such as South Africa and which predictors played important roles in PM2.5 modeling. The cross-validation R2 and Root Mean Square Error of our model was 0.80 and 9.40 μg/m3, respectively. Satellite AOD, seasonal indicator, total precipitation, and population were among the most important predictors. Model-estimated PM2.5 levels successfully captured the temporal pattern recorded by ground observations. Spatially, the highest annual PM2.5 concentration appeared in central and northern Gauteng, including northern Johannesburg and the city of Tshwane. Since the 2016 changes in national PM2.5 standards, PM2.5 concentrations have decreased in most of our study region, although levels in Johannesburg and its surrounding areas have remained relatively constant. This is anadvanced PM2.5 model for South Africa with high prediction accuracy at the daily level and at a relatively high spatial resolution. Our study provided a reference for predictor selection, and our results can be used for a variety of purposes, including epidemiological research, burden of disease assessments, and policy evaluation.",
        "DOI": "10.1016/j.rse.2021.112713",
        "affiliation_name": "North-West University",
        "affiliation_city": "Potchefstroom",
        "affiliation_country": "South Africa"
    },
    {
        "paper_title": "National scale mapping of larch plantations for Wales using the Sentinel-2 data archive",
        "paper_author": "Punalekar S.M.",
        "publication": "Forest Ecology and Management",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "Accurate spatial information regarding forest types and tree species is immensely important for efficient forest management strategies. In the UK and particularly in Wales, creating a spatial inventory of larch (Larix sps.) plantations that encompasses both the public and private forests has become one of the highest priorities of woodland management policies, particularly given the need to respond to the rapid spread of Phytophthora ramorum fungal disease. For directing disease control measures, national scale, regularly updated mapping of larch distributions is essential. In this study, we applied a ExtraTree classifier machine learning algorithm to multi-year (June 2015 and December 2019) multi-path composites of vegetation indices derived from 10 m Sentinel-2 satellite data (spectral range used in this study: 490–2190 nm) to map the extent of larch plantations across Wales. For areas identified as woody vegetation, areas under larch plantations were associated with a needle-leaved leaf type and deciduous phenology, allowing differentiation from broad-leaved deciduous and needle-leaved evergreen types. The model accuracies for validation, which included overall accuracy, producer's and user's accuracies, exceeded 95% and the F1-score was greater than 0.97 for all forest types. Comparison against an independent reference dataset indicated all map accuracies above 90% (F1-score higher than 0.92) with the lowest value being 90.3% for the producer's accuracy for larch. Short wave infrared and red-edge based indices were particularly useful for discriminating larch from other forest types. Capacity for updating information on clear-felling of larch stands through annual updates of a woody mask was also introduced. The resulting maps of larch plantations for Wales are the most current for Wales covering public as well as private woodlands and can be routinely updated. The classification approach has potential to be transferred to a wider geographical area given the availability of open-source multi-year Sentienl-2 datasets and robust calibration datasets.",
        "DOI": "10.1016/j.foreco.2021.119679",
        "affiliation_name": "Aberystwyth University",
        "affiliation_city": "Aberystwyth",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Improving time to palliative care review with predictive modeling in an inpatient adult population: study protocol for a stepped-wedge, pragmatic randomized controlled trial",
        "paper_author": "Wilson P.M.",
        "publication": "Trials",
        "citied_by": "6",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Palliative care is a medical specialty centered on improving the quality of life (QOL) of patients with complex or life-threatening illnesses. The need for palliative care is increasing and with that the rigorous testing of triage tools that can be used quickly and reliably to identify patients that may benefit from palliative care. Methods: To that aim, we will conduct a two-armed stepped-wedge cluster randomized trial rolled out to two inpatient hospitals to evaluate whether a machine learning algorithm accurately identifies patients who may benefit from a comprehensive review by a palliative care specialist and decreases time to receiving a palliative care consult in hospital. This is a single-center study which will be conducted from August 2019 to November 2020 at Saint Mary’s Hospital & Methodist Hospital both within Mayo Clinic Rochester in Minnesota. Clusters will be nursing units which will be chosen to be a mix of complex patients from Cardiology, Critical Care, and Oncology and had previously established relationships with palliative medicine. The stepped wedge design will have 12 units allocated to a design matrix of 5 treatment wedges. Each wedge will last 75 days resulting in a study period of 12 months of recruitment unless otherwise specified. Data will be analyzed with Bayesian hierarchical models with credible intervals denoting statistical significance. Discussion: This intervention offers a pragmatic approach to delivering specialty palliative care to hospital patients in need using machine learning, thereby leading to high value care and improved outcomes. It is not enough for AI to be utilized by simply publishing research showing predictive performance; clinical trials demonstrating better outcomes are critically needed. Furthermore, the deployment of an AI algorithm is a complex process that requires multiple teams with varying skill sets. To evaluate a deployed AI, a pragmatic clinical trial can accommodate the difficulties of clinical practice while retaining scientific rigor. Trial registration: ClinicalTrials.gov NCT03976297. Registered on 6 June 2019, prior to trial start.",
        "DOI": "10.1186/s13063-021-05546-5",
        "affiliation_name": "Mayo Clinic Education and Research",
        "affiliation_city": "Rochester",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning nodes: machine learning-based energy and data management strategy",
        "paper_author": "Kim Y.",
        "publication": "Eurasip Journal on Wireless Communications and Networking",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "The efficient use of resources in wireless communications has always been a major issue. In the Internet of Things (IoT), the energy resource becomes more critical. The transmission policy with the aid of a coordinator is not a viable solution in an IoT network, since a node should report its state to the coordinator for scheduling and it causes serious signaling overhead. Machine learning algorithms can provide the optimal distributed transmission mechanism with little overhead. A node can learn by itself by utilizing the machine learning algorithm and make the optimal transmission decision on its own. In this paper, we propose a novel learning Medium Access Control (MAC) protocol with learning nodes. Nodes learn the optimal transmission policy, i.e., minimizing the data and energy queue levels, using the Q-learning algorithm. The performance evaluation shows that the proposed scheme enhances the queue states and throughput.",
        "DOI": "10.1186/s13638-021-02047-6",
        "affiliation_name": "Sungkyunkwan University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A novel hourly PM2.5 concentration prediction model based on feature selection, training set screening, and mode decomposition-reorganization",
        "paper_author": "Sun W.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "36",
        "cover_date": "2021-12-01",
        "Abstract": "Accurate prediction of PM2.5 and other air pollutants concentration can provide early warning information for sustainable urban pollution control, urban construction and travel planning. In this paper, combined with feature selection, training set selection, mode decomposition and reorganization, machine learning, a new PM2.5 concentration hybrid prediction model is established. Firstly, historical data were screened by random forest (RF) and grey system approximation model (GSA). Secondly, the processed data is decomposed by time varying filtering based empirical mode decomposition (TVFEMD). Then, the extreme learning machine (ELM) optimized by moth flame optimization algorithm (MFO) is used for prediction. Based on the data of four cities in Beijing Tianjin Hebei region, the following conclusions can be drawn: (1) The effectiveness and robustness of the proposed model are verified, and the evaluation indexes are the best. (2) RF-GSA can effectively improve the quality of training set. (3) Mode decomposition and reorganization can effectively improve the prediction accuracy. The model can provide a reference for government policy-making and residents travel.",
        "DOI": "10.1016/j.scs.2021.103348",
        "affiliation_name": "North China Electric Power University (Baoding)",
        "affiliation_city": "Baoding",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Automated predictive analytics tool for rainfall forecasting",
        "paper_author": "Raval M.",
        "publication": "Scientific Reports",
        "citied_by": "24",
        "cover_date": "2021-12-01",
        "Abstract": "Australia faces a dryness disaster whose impact may be mitigated by rainfall prediction. Being an incredibly challenging task, yet accurate prediction of rainfall plays an enormous role in policy making, decision making and organizing sustainable water resource systems. The ability to accurately predict rainfall patterns empowers civilizations. Though short-term rainfall predictions are provided by meteorological systems, long-term prediction of rainfall is challenging and has a lot of factors that lead to uncertainty. Historically, various researchers have experimented with several machine learning techniques in rainfall prediction with given weather conditions. However, in places like Australia where the climate is variable, finding the best method to model the complex rainfall process is a major challenge. The aim of this paper is to: (a) predict rainfall using machine learning algorithms and comparing the performance of different models. (b) Develop an optimized neural network and develop a prediction model using the neural network (c) to do a comparative study of new and existing prediction techniques using Australian rainfall data. In this paper, rainfall data collected over a span of ten years from 2007 to 2017, with the input from 26 geographically diverse locations have been used to develop the predictive models. The data was divided into training and testing sets for validation purposes. The results show that both traditional and neural network-based machine learning models can predict rainfall with more precision.",
        "DOI": "10.1038/s41598-021-95735-8",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modelling the relationship of driver license and offense history with fatal and serious injury (FSI) crash involvement",
        "paper_author": "Meyer D.",
        "publication": "Journal of Safety Research",
        "citied_by": "10",
        "cover_date": "2021-12-01",
        "Abstract": "Introduction: Previous research has indicated that increases in traffic offenses are linked to increased crash involvement rates, making reductions in offending an appropriate measure for evaluating road safety interventions in the short-term. However, the extent to which traffic offending predicts fatal and serious injury (FSI) crash involvement risk is not well established, prompting this new Victorian (Australia) study. Method: A preliminary cluster analysis was performed to describe the offense data and assess FSI crash involvement risk for each cluster. While controlling demographic and licensing variables, the key traffic offenses that predict future FSI crash involvement were then identified. The large sample size allowed the use of machine learning methods such as random forests, gradient boosting, and Least Absolute Shrinkage and Selection Operator (LASSO) regression. This was done for the ‘all driver’ sample and five sometimes overlapping groups of drivers; the young, the elderly, and those with a motorcycle license, a heavy vehicle license endorsement and/or a history of license bans. Results: With the exception of the group of drivers who had a history of bans, offense history significantly improved the accuracy of models predicting future FSI crash involvement using demographic and licensing data, suggesting that traffic offenses may be an important factor to consider when analyzing FSI crash involvement risk and the effects of road safety countermeasures. Conclusions: The results are helpful for identifying driver groups to target with further road safety countermeasures, and for showing that machine learning methods have an important role to play in research of this nature. Practical Application: This research indicates with whom road safety interventions should particularly be applied. Changes to driver demerit policies to better target offenses related to FSI crash involvement and repeat traffic offenders, who are at greater risk of FSI crash involvement, are recommended.",
        "DOI": "10.1016/j.jsr.2021.08.008",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Sustainability insights on emerging solar district heating technologies to boost the nearly zero energy building concept",
        "paper_author": "Abokersh M.H.",
        "publication": "Renewable Energy",
        "citied_by": "21",
        "cover_date": "2021-12-01",
        "Abstract": "Arising the Nearly Zero Energy Buildings (NZEB) concept in Europe, the solar district heating systems (SDHS) present a potential solution to meet the buildings sector's European energy performance directive. Nevertheless, current practices face several technological and economical barriers to ensure service quality. In this context, our work presents a sustainability analysis (technical, economic, environmental, and social) for SDHS integration in the residential sector to meet the NZEB and positive energy building goals. This paper proposes an application of a machine learning model incorporating multi-objective optimization and multi-criteria decision making to facilitate a sustainability index for the decision-making stakeholders and policymakers. The proposed analysis application is illustrated through retrofitted residential communities with building energy rating (D) at different sizes (10, 25, 50, 100, and 500 houses) located in Emmen (Netherlands) and compared to a standard decentralized heat pump. The optimization results show the ability of SDHS to provide a solar fraction up to 95% in the community of 500 houses. Furthermore, achieving a NZEB status is only approved economically from a community size of 100 houses with a life cycle cost of 41 €/m2 and a payback period of 25 years. These results align with a substantial environmental and social improvement of 78.2% and 29.7%, respectively, compared to the decentralized heat pump. Overall, this study provides policy decision making with an evaluation for positive energy communities and suggests the SDHS integration to meet the global sustainability goals.",
        "DOI": "10.1016/j.renene.2021.08.091",
        "affiliation_name": "Irish Manufacturing Research",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Machine learning guided postnatal gestational age assessment using new-born screening metabolomic data in South Asia and sub-Saharan Africa",
        "paper_author": "Sazawal S.",
        "publication": "BMC Pregnancy and Childbirth",
        "citied_by": "9",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Babies born early and/or small for gestational age in Low and Middle-income countries (LMICs) contribute substantially to global neonatal and infant mortality. Tracking this metric is critical at a population level for informed policy, advocacy, resources allocation and program evaluation and at an individual level for targeted care. Early prenatal ultrasound examination is not available in these settings, gestational age (GA) is estimated using new-born assessment, last menstrual period (LMP) recalls and birth weight, which are unreliable. Algorithms in developed settings, using metabolic screen data, provided GA estimates within 1–2 weeks of ultrasonography-based GA. We sought to leverage machine learning algorithms to improve accuracy and applicability of this approach to LMICs settings. Methods: This study uses data from AMANHI-ACT, a prospective pregnancy cohorts in Asia and Africa where early pregnancy ultrasonography estimated GA and birth weight are available and metabolite screening data in a subset of 1318 new-borns were also available. We utilized this opportunity to develop machine learning (ML) algorithms. Random Forest Regressor was used where data was randomly split into model-building and model-testing dataset. Mean absolute error (MAE) and root mean square error (RMSE) were used to evaluate performance. Bootstrap procedures were used to estimate confidence intervals (CI) for RMSE and MAE. For pre-term birth identification ROC analysis with bootstrap and exact estimation of CI for area under curve (AUC) were performed. Results: Overall model estimated GA had MAE of 5.2 days (95% CI 4.6–6.8), which was similar to performance in SGA, MAE 5.3 days (95% CI 4.6–6.2). GA was correctly estimated to within 1 week for 85.21% (95% CI 72.31–94.65). For preterm birth classification, AUC in ROC analysis was 98.1% (95% CI 96.0–99.0; p < 0.001). This model performed better than Iowa regression, AUC Difference 14.4% (95% CI 5–23.7; p = 0.002). Conclusions: Machine learning algorithms and models applied to metabolomic gestational age dating offer a ladder of opportunity for providing accurate population-level gestational age estimates in LMICs settings. These findings also point to an opportunity for investigation of region-specific models, more focused feasible analyte models, and broad untargeted metabolome investigation.",
        "DOI": "10.1186/s12884-021-04067-y",
        "affiliation_name": "The Aga Khan University",
        "affiliation_city": "Karachi",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Coevolution of COVID-19 research and China’s policies",
        "paper_author": "Cheng X.",
        "publication": "Health Research Policy and Systems",
        "citied_by": "12",
        "cover_date": "2021-12-01",
        "Abstract": "Background: In the era of evidence-based policy-making (EBPM), scientific outputs and public policy should engage with each other in a more interactive and coherent way. Notably, this is becoming increasingly critical in preparing for public health emergencies. Methods: To explore the coevolution dynamics between science and policy (SAP), this study explored the changes in, and development of, COVID-19 research in the early period of the COVID-19 outbreak in China, from 30 December 2019 to 26 June 2020. In this study, VOSviewer was adopted to calculate the link strength of items extracted from scientific publications, and machine learning clustering analysis of scientific publications was carried out to explore dynamic trends in scientific research. Trends in relevant policies that corresponded to changing trends in scientific research were then traced. Results: The study observes a salient change in research content as follows: an earlier focus on “children and pregnant patients”, “common symptoms”, “nucleic acid test”, and “non-Chinese medicine” was gradually replaced with a focus on “aged patients”, “pregnant patients”, “severe symptoms and asymptomatic infection”, “antibody assay”, and “Chinese medicine”. “Mental health” is persistent throughout China’s COVID-19 research. Further, our research reveals a correlation between the evolution of COVID-19 policies and the dynamic development of COVID-19 research. The average issuance time of relevant COVID-19 policies in China is 8.36 days after the launching of related research. Conclusions: In the early stage of the outbreak in China, the formulation of research-driven-COVID-19 policies and related scientific research followed a similar dynamic trend, which is clearly a manifestation of a coevolution model (CEM). The results of this study apply more broadly to the formulation of policies during public health emergencies, and provide the foundation for future EBPM research.",
        "DOI": "10.1186/s12961-021-00770-6",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Identifying urban built environment factors in pregnancy care and maternal mental health outcomes",
        "paper_author": "Zhang Y.",
        "publication": "BMC Pregnancy and Childbirth",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "Backgrounds: Risk factors related to the built environment have been associated with women’s mental health and preventive care. This study sought to identify built environment factors that are associated with variations in prenatal care and subsequent pregnancy-related outcomes in an urban setting. Methods: In a retrospective observational study, we characterized the types and frequency of prenatal care events that are associated with the various built environment factors of the patients’ residing neighborhoods. In comparison to women living in higher-quality built environments, we hypothesize that women who reside in lower-quality built environments experience different patterns of clinical events that may increase the risk for adverse outcomes. Using machine learning, we performed pattern detection to characterize the variability in prenatal care concerning encounter types, clinical problems, and medication prescriptions. Structural equation modeling was used to test the associations among built environment, prenatal care variation, and pregnancy outcome. The main outcome is postpartum depression (PPD) diagnosis within 1 year following childbirth. The exposures were the quality of the built environment in the patients’ residing neighborhoods. Electronic health records (EHR) data of pregnant women (n = 8,949) who had live delivery at an urban academic medical center from 2015 to 2017 were included in the study. Results: We discovered prenatal care patterns that were summarized into three common types. Women who experienced the prenatal care pattern with the highest rates of PPD were more likely to reside in neighborhoods with homogeneous land use, lower walkability, lower air pollutant concentration, and lower retail floor ratios after adjusting for age, neighborhood average education level, marital status, and income inequality. Conclusions: In an urban setting, multi-purpose and walkable communities were found to be associated with a lower risk of PPD. Findings may inform urban design policies and provide awareness for care providers on the association of patients’ residing neighborhoods and healthy pregnancy.",
        "DOI": "10.1186/s12884-021-04056-1",
        "affiliation_name": "Tencent",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Identification of on-road vehicle CO<inf>2</inf> emission pattern in China: A study based on a high-resolution emission inventory",
        "paper_author": "Xu Y.",
        "publication": "Resources, Conservation and Recycling",
        "citied_by": "37",
        "cover_date": "2021-12-01",
        "Abstract": "As the country with the largest anthropogenic CO2 emission, China is greatly influential on fighting with climate change. However, CO2 emitted from on-road vehicles in China is a barrier to its carbon neutral due to the inevitable increase trend of vehicle quantity. Thus, to meet the requirement of refined policy-making for vehicular CO2 abatement, we calculated the CO2 emissions from 37 vehicular types and 3 fuel categories across 339 cities in China through the bottom-up method, and developed a national vehicular CO2 emission inventory in a high spatial resolution (1 km × 1 km). Additionally, machine learnings were conducted to the inventory for the emission pattern identification. It was found that the total vehicular CO2 emission in 2019 was 1090 million tons, and 77.1% of CO2 was emitted by vehicles of light-duty gasoline vehicle (LDGV) and heavy-duty diesel truck (HDDT). In addition, for the grids accompanying CO2 emissions, 75% of vehicular CO2 emissions were contributed by 15% of grids (hot grids). Furthermore, results of machine learning showed that LDGVs mainly distributed in economically advanced regions of which vehicular structures were relatively simple, while HDDTs were widely applied on the national scale. Based on the results above, two measures were proposed: (1) Electric cars have to be strongly promoted in hot grids for the LDGV replacement. (2) Long-distance freight tool replacements are urgently required in the national wide. Our study provided a studying base for further investigations on decarbonization and a new insight of China's vehicular CO2 emission controls.",
        "DOI": "10.1016/j.resconrec.2021.105891",
        "affiliation_name": "College of Environmental and Resource Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "COVID-19 pandemic spread against countries’ non-pharmaceutical interventions responses: a data-mining driven comparative study",
        "paper_author": "Xylogiannopoulos K.F.",
        "publication": "BMC Public Health",
        "citied_by": "15",
        "cover_date": "2021-12-01",
        "Abstract": "Background: The first half of 2020 has been marked as the era of COVID-19 pandemic which affected the world globally in almost every aspect of the daily life from societal to economical. To prevent the spread of COVID-19, countries have implemented diverse policies regarding Non-Pharmaceutical Intervention (NPI) measures. This is because in the first stage countries had limited knowledge about the virus and its contagiousness. Also, there was no effective medication or vaccines. This paper studies the effectiveness of the implemented policies and measures against the deaths attributed to the virus between January and May 2020. Methods: Data from the European Centre for Disease Prevention and Control regarding the identified cases and deaths of COVID-19 from 48 countries have been used. Additionally, data concerning the NPI measures related policies implemented by the 48 countries and the capacity of their health care systems was collected manually from their national gazettes and official institutes. Data mining, time series analysis, pattern detection, machine learning, clustering methods and visual analytics techniques have been applied to analyze the collected data and discover possible relationships between the implemented NPIs and COVID-19 spread and mortality. Further, we recorded and analyzed the responses of the countries against COVID-19 pandemic, mainly in urban areas which are over-populated and accordingly COVID-19 has the potential to spread easier among humans. Results: The data mining and clustering analysis of the collected data showed that the implementation of the NPI measures before the first death case seems to be very effective in controlling the spread of the disease. In other words, delaying the implementation of the NPI measures to after the first death case has practically little effect on limiting the spread of the disease. The success of implementing the NPI measures further depends on the way each government monitored their application. Countries with stricter policing of the measures seems to be more effective in controlling the transmission of the disease. Conclusions: The conducted comparative data mining study provides insights regarding the correlation between the early implementation of the NPI measures and controlling COVID-19 contagiousness and mortality. We reported a number of useful observations that could be very helpful to the decision makers or epidemiologists regarding the rapid implementation and monitoring of the NPI measures in case of a future wave of COVID-19 or to deal with other unknown infectious pandemics. Regardless, after the first wave of COVID-19, most countries have decided to lift the restrictions and return to normal. This has resulted in a severe second wave in some countries, a situation which requires re-evaluating the whole process and inspiring lessons for the future.",
        "DOI": "10.1186/s12889-021-11251-4",
        "affiliation_name": "Hellenic Air Force Academy",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Machine learning dismantling and early-warning signals of disintegration in complex systems",
        "paper_author": "Grassia M.",
        "publication": "Nature Communications",
        "citied_by": "70",
        "cover_date": "2021-12-01",
        "Abstract": "From physics to engineering, biology and social science, natural and artificial systems are characterized by interconnected topologies whose features – e.g., heterogeneous connectivity, mesoscale organization, hierarchy – affect their robustness to external perturbations, such as targeted attacks to their units. Identifying the minimal set of units to attack to disintegrate a complex network, i.e. network dismantling, is a computationally challenging (NP-hard) problem which is usually attacked with heuristics. Here, we show that a machine trained to dismantle relatively small systems is able to identify higher-order topological patterns, allowing to disintegrate large-scale social, infrastructural and technological networks more efficiently than human-based heuristics. Remarkably, the machine assesses the probability that next attacks will disintegrate the system, providing a quantitative method to quantify systemic risk and detect early-warning signals of system’s collapse. This demonstrates that machine-assisted analysis can be effectively used for policy and decision-making to better quantify the fragility of complex systems and their response to shocks.",
        "DOI": "10.1038/s41467-021-25485-8",
        "affiliation_name": "Bruno Kessler Foundation",
        "affiliation_city": "Trento",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Development of a high-performance machine learning model to predict ground ozone pollution in typical cities of China",
        "paper_author": "Cheng Y.",
        "publication": "Journal of Environmental Management",
        "citied_by": "35",
        "cover_date": "2021-12-01",
        "Abstract": "High ozone concentrations have adverse effects on human health and ecosystems. In recent years, the ambient ozone concentration in China has shown an upward trend, and high-quality prediction of ozone concentrations has become critical to support effective policymaking. In this study, a novel hybrid model combining wavelet decomposition (WD), a gated recurrent unit (GRU) neural network and a support vector regression (SVR) model was developed to predict the daily maximum 8 h ozone. We used the ground ozone observation data in six representative megacities across China from Jan. 1, 2015 to Jun. 15, 2020 for model training, and we used data from Jun. 15 to Dec. 31, 2020 for model testing. The results show that the developed model performs very well for megacities; against observations, the model obtains an average cross-validated R2 (coefficient of determination) ranging from 0.90 for Shanghai to 0.97 for Chengdu in the one-step predictions, thereby indicating that the model outperformed any single algorithm or other hybrid algorithms reported. The developed model can also capture high ozone pollution episodes with an average accuracy of 92% for the next five days in inland cities. This study will be useful for the environmental health community to prevent high ozone exposure more efficiently in megacities in China and shows great potential for accurate ozone prediction using machine learning approaches.",
        "DOI": "10.1016/j.jenvman.2021.113670",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Prediction of vaccine hesitancy based on social media traffic among Israeli parents using machine learning strategies",
        "paper_author": "Bar-Lev S.",
        "publication": "Israel Journal of Health Policy Research",
        "citied_by": "17",
        "cover_date": "2021-12-01",
        "Abstract": "Introduction: Vaccines have contributed to substantial reductions of morbidity and mortality from vaccine-preventable diseases, mainly in children. However, vaccine hesitancy was listed by the World Health Organization (WHO) in 2019 as one of the top ten threats to world health. Aim: To employ machine-learning strategies to assess how on-line content regarding vaccination affects vaccine hesitancy. Methods: We collected social media posts and responses from vaccination discussion groups and forums on leading social platforms, including Facebook and Tapuz (A user content website that contains blogs and forums). We investigated 65,603 records of children aged 0–6 years who are insured in Maccabi’s Health Maintenance Organization (HMO). We applied three machine learning algorithms (Logistic regression, Random forest and Neural networks) to predict vaccination among Israeli children, based on demographic and social media traffic. Results: Higher hesitancy was associated with more social media traffic, for most of the vaccinations. The addition of the social media traffic features improved the performances of most of the models. However, for Rota virus, Hepatitis A and hepatitis B, the performances of all algorithms (with and without the social media features) were close to random (accuracy up to 0.63 and F1 up to 0.65). We found a negative association between on-line discussions and vaccination. Conclusions: There is an association between social media traffic and vaccine hesitancy. Policy makers are encouraged to perceive social media as a main channel of communication during health crises. Health officials and experts are encouraged to take part in social media discussions, and be equipped to readily provide the information, support and advice that the public is looking for, in order to optimize vaccination actions and to improve public health",
        "DOI": "10.1186/s13584-021-00486-6",
        "affiliation_name": "Ruppin Academic Center",
        "affiliation_city": "Emek Hefer",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Modelling of Chinese corporate bond default – A machine learning approach",
        "paper_author": "Lu Z.",
        "publication": "Accounting and Finance",
        "citied_by": "6",
        "cover_date": "2021-12-01",
        "Abstract": "We apply machine learning techniques to construct a series of models of corporate bond defaults. By combining Chinese accounting information and corporate bond data from January 2012 to December 2019, we construct an out-of-sample forecast that significantly improves the identification rate of corporate bond defaults, with an area under the receiver operating characteristics curve greater than 90 percent. Our models are robust to different machine learning models, including stacking, boosting, and bagging ensembling models. Our models consider cross-sectional heterogeneity, such as different ownership structures, accessibility to external finance, industry heterogeneity, different sample periods, and government policy impact.",
        "DOI": "10.1111/acfi.12846",
        "affiliation_name": "NHH Norwegian School of Economics",
        "affiliation_city": "Bergen",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "A comparative approach of support vector machine kernel functions for GIS-based landslide susceptibility mapping",
        "paper_author": "Kamran K.V.",
        "publication": "Applied Geomatics",
        "citied_by": "28",
        "cover_date": "2021-12-01",
        "Abstract": "Landslides are among the most destructive natural hazards with severe socio-economic ramifications all around the world. Understanding the critical combination of geoenvironmental factors involved in the occurrence of landslides can mitigate the adverse impacts ascribed to them. Among the several scenarios for studying and investigating this phenomenon, landslide susceptibility mapping (LSM) is the most prominent method. Applying the machine learning (ML) algorithms integrated with the geographic information systems (GIS) has become a trending means for accurate and rapid landslide mapping practices in the scientific community. Support vector machine (SVM) has been the most commonly applied ML algorithm for LSM in recent years. The current study aims to implement different SVM kernel functions including polynomial kernel function (PKF) (degree 1 to 5), radial basis function (RBF), sigmoid, and linear kernels, for a GIS-based LSM over the Tabriz Basin (TB). To this end, a total number of 9 conditioning parameters being involved in the occurrence of the landslide events were determined and utilized. The LSM maps of the TB were generated based on the different SVM kernels and were statistically validated according to the landslide inventory. The findings revealed that the polynomial-degree-2 (PKF-2) model (AUC = 0.9688) outperforms the rest of the utilized kernels. According to the SLM map generated through PKF-2, the northernmost parts of the TB are extremely susceptible to slope failures than the rest; therefore, the developmental policies over these parts have to be taken into account with privileged priority to hinder any humanitarian as well as environmental catastrophes.",
        "DOI": "10.1007/s12518-021-00393-0",
        "affiliation_name": "Dokuz Eylül Üniversitesi",
        "affiliation_city": "Izmir",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Detecting speculative bubbles in metal prices: Evidence from GSADF test and machine learning approaches",
        "paper_author": "Ozgur O.",
        "publication": "Resources Policy",
        "citied_by": "21",
        "cover_date": "2021-12-01",
        "Abstract": "The importance of metal prices to real economic activity and financial markets has increased the focus on detecting price bubbles in precious and industrial metals. Several studies looked at the influence of macroeconomic factors in the formation of a single metal bubble and tried to identify bubble dates. Our study extends the literature and analyzes monthly gold, platinum, palladium, rhodium, silver, and aluminum, copper, lead, nickel, steel, tin prices over 1980M1-2019M12, and contributes to the literature in two ways: First, the analysis incorporates the Generalized Supremum Augmented Dickey-Fuller (GSADF) test to detect potential bubbles. Second, the study evaluates the impact of potential financial, real, and speculative factors in the likelihood of price bubbles using the random forest method. Our findings indicate that financial factors are more critical in predicting precious metal price bubbles. The monetary policy rate and the production index are important to predict bubbles in industrial metal prices. However, our findings suggest that speculative activity may not adequately predict metal price bubbles.",
        "DOI": "10.1016/j.resourpol.2021.102306",
        "affiliation_name": "Ankara Yildirim Beyazit University",
        "affiliation_city": "Ankara",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Unsupervised discovery of thin-film photovoltaic materials from unlabeled data",
        "paper_author": "Wang Z.",
        "publication": "npj Computational Materials",
        "citied_by": "20",
        "cover_date": "2021-12-01",
        "Abstract": "Quaternary chalcogenide semiconductors (I2-II-IV-X4) are key materials for thin-film photovoltaics (PVs) to alleviate the energy crisis. Scaling up of PVs requires the discovery of I2-II-IV-X4 with good photoelectric properties; however, the structure search space is significantly large to explore exhaustively. The scarcity of available data impedes even many machine learning (ML) methods. Here, we employ the unsupervised learning (UL) method to discover I2-II-IV-X4 that alleviates the challenge of data scarcity. We screen all the I2-II-IV-X4 from the periodic table as the initial data and finally select eight candidates through UL. As predicted by ab initio calculations, they exhibit good optical conversion efficiency, strong optical responses, and good thermal stabilities at room temperatures. This typical case demonstrates the potential of UL in material discovery, which overcomes the limitation of data scarcity, and shortens the computational screening cycle of I2-II-IV-X4 by ~12.1 years, providing a research avenue for rapid material discovery.",
        "DOI": "10.1038/s41524-021-00596-4",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Two-Dimensional Task Offloading for Mobile Networks: An Imitation Learning Framework",
        "paper_author": "Yan Z.",
        "publication": "IEEE/ACM Transactions on Networking",
        "citied_by": "12",
        "cover_date": "2021-12-01",
        "Abstract": "Mobile computing network is envisioned as a powerful framework to support the growing computation-intensive applications in the era of the Internet of Things (IoT). In this paper, we exploit the potential of a multi-layer network via a two-dimensional (2-D) task offloading scheme, which enables horizontal cooperations among the edge nodes. To minimize the average task offloading delay for all the mobile users, we formulate a mixed non-linear programming (MINLP) by jointly optimizing the 2-D offloading decisions and communication/computational resource allocation. To address this very challenging problem, we exploit the unique algorithmic structure of the optimal branch-and-bound (BB) algorithm, and propose a novel Gaussian process imitation learning (GPIL) method to learn how to discover the shortcut for node searching in the BB enumeration tree and significantly accelerate the BB algorithm. When the network key parameters change, we further propose a novel recursive GPIL (RGPIL) method to agilely adapt to the new scenario with a fast policy update, where the new posterior distribution can be recursively updated based on a few new training data. Our simulation results show that the proposed method can achieve a near optimal solution with a significantly reduced complexity (e.g., a reduction of 98.7% in the number of searched nodes for a typical case). On this basis, the advantage of 2-D offloading scheme over the conventional schemes is also verified.",
        "DOI": "10.1109/TNET.2021.3093452",
        "affiliation_name": "Faculty of Engineering",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Determination of critical decision points for COVID-19 measures in Japan",
        "paper_author": "Kim J.",
        "publication": "Scientific Reports",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "Coronavirus disease 2019 (COVID-19) has spread throughout the world. The prediction of the number of cases has become essential to governments’ ability to define policies and take countermeasures in advance. The numbers of cases have been estimated using compartment models of infectious diseases such as the susceptible-infected-removed (SIR) model and its derived models. However, the required use of hypothetical future values for parameters, such as the effective reproduction number or infection rate, increases the uncertainty of the prediction results. Here, we describe our model for forecasting future COVID-19 cases based on observed data by considering the time delay (tdelay). We used machine learning to estimate the future infection rate based on real-time mobility, temperature, and relative humidity. We then used this calculation with the susceptible-exposed-infectious-removed (SEIR) model to forecast future cases with less uncertainty. The results suggest that changes in mobility affect observed infection rates with 5–10 days of time delay. This window should be accounted for in the decision-making phase especially during periods with predicted infection surges. Our prediction model helps governments and medical institutions to take targeted early countermeasures at critical decision points regarding mobility to avoid significant levels of infection rise.",
        "DOI": "10.1038/s41598-021-95617-z",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Learning Autonomy in Management of Wireless Random Networks",
        "paper_author": "Lee H.",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "This paper presents a machine learning strategy that tackles a distributed optimization task in a wireless network with an arbitrary number of randomly interconnected nodes. Individual nodes decide their optimal states with distributed coordination among other nodes through randomly varying backhaul links. This poses a technical challenge in distributed universal optimization policy robust to a random topology of the wireless network, which has not been properly addressed by conventional deep neural networks (DNNs) with rigid structural configurations. We develop a flexible DNN formalism termed distributed message-passing neural network (DMPNN) with forward and backward computations independent of the network topology. A key enabler of this approach is an iterative message-sharing strategy through arbitrarily connected backhaul links. The DMPNN provides a convergent solution for iterative coordination by learning numerous random backhaul interactions. The DMPNN is investigated for various configurations of the power control in wireless networks, and intensive numerical results prove its universality and viability over conventional optimization and DNN approaches.",
        "DOI": "10.1109/TWC.2021.3089701",
        "affiliation_name": "Singapore University of Technology and Design",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Who has given up on mathematics? A data analysis",
        "paper_author": "Ko H.K.",
        "publication": "Asia Pacific Education Review",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "The newly coined term supoza (giving up mathematics, 수포자, 數抛者) describes a critical social issue that needs to be addressed in South Korea’s educational policy. Although the term has not received precise definition, it refers to students who have given up on learning mathematics. A precise definition would require detailing the current supoza situation and identifying its characteristics. This study therefore conducted a statistical investigation of commonalities among students who have given up on learning mathematics; the study results revealed that these students can be characterized by their affective domain for mathematics learning. We found that a statistical model could determine the likelihood that a particular student would report having given up mathematics based on responses to questions related to the affective domain of mathematics learning. This aspect suggests the possibility of understanding supoza with the exclusive use of affective factors and emphasizes the significance of the affective domain of mathematics learning. Additionally, this study provides a working example to show how exploratory analysis using big data can be used in relation to mathematical education.",
        "DOI": "10.1007/s12564-021-09709-6",
        "affiliation_name": "Kyushu University",
        "affiliation_city": "Fukuoka",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Impact of vaccine supplies and delays on optimal control of the COVID-19 pandemic: mapping interventions for the Philippines",
        "paper_author": "Estadilla C.D.S.",
        "publication": "Infectious Diseases of Poverty",
        "citied_by": "25",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Around the world, controlling the COVID-19 pandemic requires national coordination of multiple intervention strategies. As vaccinations are globally introduced into the repertoire of available interventions, it is important to consider how changes in the local supply of vaccines, including delays in administration, may be addressed through existing policy levers. This study aims to identify the optimal level of interventions for COVID-19 from 2021 to 2022 in the Philippines, which as a developing country is particularly vulnerable to shifting assumptions around vaccine availability. Furthermore, we explore optimal strategies in scenarios featuring delays in vaccine administration, expansions of vaccine supply, and limited combinations of interventions. Methods: Embedding our work within the local policy landscape, we apply optimal control theory to the compartmental model of COVID-19 used by the Philippine government’s pandemic surveillance platform and introduce four controls: (a) precautionary measures like community quarantines, (b) detection of asymptomatic cases, (c) detection of symptomatic cases, and (d) vaccinations. The model is fitted to local data using an L-BFGS minimization procedure. Optimality conditions are identified using Pontryagin’s minimum principle and numerically solved using the forward–backward sweep method. Results: Simulation results indicate that early and effective implementation of both precautionary measures and symptomatic case detection is vital for averting the most infections at an efficient cost, resulting in > 99 % reduction of infections compared to the no-control scenario. Expanding vaccine administration capacity to 440,000 full immunizations daily will reduce the overall cost of optimal strategy by 25 % , while allowing for a faster relaxation of more resource-intensive interventions. Furthermore, delays in vaccine administration require compensatory increases in the remaining policy levers to maintain a minimal number of infections. For example, delaying the vaccines by 180 days (6 months) will result in an 18 % increase in the cost of the optimal strategy. Conclusion: We conclude with practical insights regarding policy priorities particularly attuned to the Philippine context, but also applicable more broadly in similar resource-constrained settings. We emphasize three key takeaways of (a) sustaining efficient case detection, isolation, and treatment strategies; (b) expanding not only vaccine supply but also the capacity to administer them, and; (c) timeliness and consistency in adopting policy measures. Graphic Abstract: [Figure not available: see fulltext.].",
        "DOI": "10.1186/s40249-021-00886-5",
        "affiliation_name": "Caraga State University",
        "affiliation_city": "Butuan",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "A synthetic building operation dataset",
        "paper_author": "Li H.",
        "publication": "Scientific Data",
        "citied_by": "29",
        "cover_date": "2021-12-01",
        "Abstract": "This paper presents a synthetic building operation dataset which includes HVAC, lighting, miscellaneous electric loads (MELs) system operating conditions, occupant counts, environmental parameters, end-use and whole-building energy consumptions at 10-minute intervals. The data is created with 1395 annual simulations using the U.S. DOE detailed medium-sized reference office building, and 30 years’ historical weather data in three typical climates including Miami, San Francisco, and Chicago. Three energy efficiency levels of the building and systems are considered. Assumptions regarding occupant movements, occupants’ diverse temperature preferences, lighting, and MELs are adopted to reflect realistic building operations. A semantic building metadata schema - BRICK, is used to store the building metadata. The dataset is saved in a 1.2 TB of compressed HDF5 file. This dataset can be used in various applications, including building energy and load shape benchmarking, energy model calibration, evaluation of occupant and weather variability and their influences on building performance, algorithm development and testing for thermal and energy load prediction, model predictive control, policy development for reinforcement learning based building controls.",
        "DOI": "10.1038/s41597-021-00989-6",
        "affiliation_name": "Lawrence Berkeley National Laboratory",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An integrated approach of field, weather, and satellite data for monitoring maize phenology",
        "paper_author": "Nieto L.",
        "publication": "Scientific Reports",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "Efficient, more accurate reporting of maize (Zea mays L.) phenology, crop condition, and progress is crucial for agronomists and policy makers. Integration of satellite imagery with machine learning models has shown great potential to improve crop classification and facilitate in-season phenological reports. However, crop phenology classification precision must be substantially improved to transform data into actionable management decisions for farmers and agronomists. An integrated approach utilizing ground truth field data for maize crop phenology (2013–2018 seasons), satellite imagery (Landsat 8), and weather data was explored with the following objectives: (i) model training and validation—identify the best combination of spectral bands, vegetation indices (VIs), weather parameters, geolocation, and ground truth data, resulting in a model with the highest accuracy across years at each season segment (step one) and (ii) model testing—post-selection model performance evaluation for each phenology class with unseen data (hold-out cross-validation) (step two). The best model performance for classifying maize phenology was documented when VIs (NDVI, EVI, GCVI, NDWI, GVMI) and vapor pressure deficit (VPD) were used as input variables. This study supports the integration of field ground truth, satellite imagery, and weather data to classify maize crop phenology, thereby facilitating foundational decision making and agricultural interventions for the different members of the agricultural chain.",
        "DOI": "10.1038/s41598-021-95253-7",
        "affiliation_name": "Kansas State University",
        "affiliation_city": "Manhattan",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Estimating soil organic carbon stock change at multiple scales using machine learning and multivariate geostatistics",
        "paper_author": "Szatmári G.",
        "publication": "Geoderma",
        "citied_by": "56",
        "cover_date": "2021-12-01",
        "Abstract": "Many national and international initiatives rely on spatially explicit information on soil organic carbon (SOC) stock change at multiple scales to support policies aiming at land degradation neutrality and climate change mitigation. In this study, we used regression cokriging with random forest and spatial stochastic cosimulation to predict the SOC stock change between two years (i.e. 1992 and 2010) in Hungary at multiple aggregation levels (i.e. point support, 1 × 1 km, 10 × 10 km square blocks, Hungarian counties and entire Hungary). We also quantified the uncertainty associated with these predictions in order to identify and delimit areas with statistically significant SOC stock change. Our study highlighted that prediction of spatial totals and averages with quantified uncertainty requires a geostatistical approach and cannot be solved by machine learning alone, because it does not account for spatial correlation in prediction errors. The total topsoil SOC stock for Hungary was predicted to increase between 1992 and 2010 with 14.9 Tg, with lower and upper limits of a 90% prediction interval equal to 11.2 Tg and 18.2 Tg, respectively. Results also showed that both the predictions and uncertainties of the average SOC stock change were smaller for larger spatial supports, while spatial aggregation also made it easier to obtain statistically significant SOC stock changes. The latter is important for carbon accounting studies that need to prove in Measurement, Reporting and Verification protocols that observed SOC stock changes are not only practically but also statistically significant.",
        "DOI": "10.1016/j.geoderma.2021.115356",
        "affiliation_name": "ISRIC - World Soil Information",
        "affiliation_city": "Wageningen",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Comparing COVID-19 risk factors in Brazil using machine learning: the importance of socioeconomic, demographic and structural factors",
        "paper_author": "Baqui P.",
        "publication": "Scientific Reports",
        "citied_by": "27",
        "cover_date": "2021-12-01",
        "Abstract": "The COVID-19 pandemic continues to have a devastating impact on Brazil. Brazil’s social, health and economic crises are aggravated by strong societal inequities and persisting political disarray. This complex scenario motivates careful study of the clinical, socioeconomic, demographic and structural factors contributing to increased risk of mortality from SARS-CoV-2 in Brazil specifically. We consider the Brazilian SIVEP-Gripe catalog, a very rich respiratory infection dataset which allows us to estimate the importance of several non-laboratorial and socio-geographic factors on COVID-19 mortality. We analyze the catalog using machine learning algorithms to account for likely complex interdependence between metrics. The XGBoost algorithm achieved excellent performance, producing an AUC-ROC of 0.813 (95% CI 0.810–0.817), and outperforming logistic regression. Using our model we found that, in Brazil, socioeconomic, geographical and structural factors are more important than individual comorbidities. Particularly important factors were: The state of residence and its development index; the distance to the hospital (especially for rural and less developed areas); the level of education; hospital funding model and strain. Ethnicity is also confirmed to be more important than comorbidities but less than the aforementioned factors. In conclusion, socioeconomic and structural factors are as important as biological factors in determining the outcome of COVID-19. This has important consequences for policy making, especially on vaccination/non-pharmacological preventative measures, hospital management and healthcare network organization.",
        "DOI": "10.1038/s41598-021-95004-8",
        "affiliation_name": "UCLA Samueli School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Onset of effects of non-pharmaceutical interventions on COVID-19 infection rates in 176 countries",
        "paper_author": "Nader I.W.",
        "publication": "BMC Public Health",
        "citied_by": "20",
        "cover_date": "2021-12-01",
        "Abstract": "Background: During the initial phase of the global COVID-19 outbreak, most countries responded with non-pharmaceutical interventions (NPIs). In this study we investigate the general effectiveness of these NPIs, how long different NPIs need to be in place to take effect, and how long they should be in place for their maximum effect to unfold. Methods: We used global data and a non-parametric machine learning model to estimate the effects of NPIs in relation to how long they have been in place. We applied a random forest model and used accumulated local effect (ALE) plots to derive estimates of the effectiveness of single NPIs in relation to their implementation date. In addition, we used bootstrap samples to investigate the variability in these ALE plots. Results: Our results show that closure and regulation of schools was the most important NPI, associated with a pronounced effect about 10 days after implementation. Restrictions of mass gatherings and restrictions and regulations of businesses were found to have a more gradual effect, and social distancing was associated with a delayed effect starting about 18 days after implementation. Conclusions: Our results can inform political decisions regarding the choice of NPIs and how long they need to be in place to take effect.",
        "DOI": "10.1186/s12889-021-11530-0",
        "affiliation_name": "Universität Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Developing China’s workforce skill taxonomy reveals extent of labor market polarization",
        "paper_author": "Xu W.",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "China, the world’s second largest economy, is transitioning into an advanced, knowledge-based economy after four decades of rapid economic development. However, China still lacks a detailed understanding of the skills that underly the Chinese labor force, and the development and spatial distribution of these skills. Similar data has proven essential in other contexts; for example, the US standardized skill taxonomy, Occupational Information Network (O*NET), played an important role in understanding the dynamics of manufacturing and knowledge-based work, and the potential risks from automation and outsourcing. Here, we use Machine Learning techniques to bridge this gap, creating China’s first workforce skill taxonomy, and map it to O*NET. This enables us to reveal workforce skill polarization into social-cognitive skills and sensory-physical skills, and to explore China’s regional inequality in light of workforce skills, and compare it to traditional metrics such as education. We build an online tool for the public and policy makers to explore the skill taxonomy: skills.sysu.edu.cn. We also make the taxonomy dataset publicly available for other researchers.",
        "DOI": "10.1057/s41599-021-00862-2",
        "affiliation_name": "School of Computing and Information",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Exploring the application of machine learning to the assembly line feeding problem",
        "paper_author": "Moretti E.",
        "publication": "Operations Management Research",
        "citied_by": "8",
        "cover_date": "2021-12-01",
        "Abstract": "As a large number of companies are resorting to increased product variety and customization, a growing attention is being put on the design and management of part feeding systems. Recent works have proved the effectiveness of hybrid feeding policies, which consist in using multiple feeding policies in the same assembly system. In this context, the assembly line feeding problem (ALFP) refers to the selection of a suitable feeding policy for each part. In literature, the ALFP is addressed either by developing optimization models or by categorizing the parts and assigning these categories to policies based on some characteristics of both the parts and the assembly system. This paper presents a new approach for selecting a suitable feeding policy for each part, based on supervised machine learning. The developed approach is applied to an industrial case and its performance is compared with the one resulting from an optimization approach. The application to the industrial case allows deepening the existing trade-off between efficiency (i.e., amount of data to be collected and dedicated resources) and quality of the ALFP solution (i.e., closeness to the optimal solution), discussing the managerial implications of different ALFP solution approaches and showing the potential value stemming from machine learning application.",
        "DOI": "10.1007/s12063-021-00201-3",
        "affiliation_name": "Universiteit Gent",
        "affiliation_city": "Ghent",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Energy-Efficient Resource Management for Federated Edge Learning with CPU-GPU Heterogeneous Computing",
        "paper_author": "Zeng Q.",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "135",
        "cover_date": "2021-12-01",
        "Abstract": "Edge machine learning involves the deployment of learning algorithms at the network edge to leverage massive distributed data and computation resources to train artificial intelligence (AI) models. Among others, the framework of federated edge learning (FEEL) is popular for its data-privacy preservation. FEEL coordinates global model training at an edge server and local model training at devices that are connected by wireless links. This work contributes to the energy-efficient implementation of FEEL in wireless networks by designing joint computation-and-communication resource management ( C2 RM). The design targets the state-of-the-art heterogeneous mobile architecture where parallel computing using both CPU and GPU, called heterogeneous computing, can significantly improve both the performance and energy efficiency. To minimize the sum energy consumption of devices, we propose a novel C2 RM framework featuring multi-dimensional control including bandwidth allocation, CPU-GPU workload partitioning and speed scaling at each device, and C2 time division for each link. The key component of the framework is a set of equilibriums in energy rates with respect to different control variables that are proved to exist among devices or between processing units at each device. The results are applied to designing efficient algorithms for computing the optimal C2 RM policies faster than the standard optimization tools. Based on the equilibriums, we further design energy-efficient schemes for device scheduling and greedy spectrum sharing that scavenges 'spectrum holes' resulting from heterogeneous C2 time divisions among devices. Using a real dataset, experiments are conducted to demonstrate the effectiveness of C2 RM on improving the energy efficiency of a FEEL system.",
        "DOI": "10.1109/TWC.2021.3088910",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Clinical subphenotypes in COVID-19: derivation, validation, prediction, temporal patterns, and interaction with social determinants of health",
        "paper_author": "Su C.",
        "publication": "npj Digital Medicine",
        "citied_by": "17",
        "cover_date": "2021-12-01",
        "Abstract": "The coronavirus disease 2019 (COVID-19) is heterogeneous and our understanding of the biological mechanisms of host response to the viral infection remains limited. Identification of meaningful clinical subphenotypes may benefit pathophysiological study, clinical practice, and clinical trials. Here, our aim was to derive and validate COVID-19 subphenotypes using machine learning and routinely collected clinical data, assess temporal patterns of these subphenotypes during the pandemic course, and examine their interaction with social determinants of health (SDoH). We retrospectively analyzed 14418 COVID-19 patients in five major medical centers in New York City (NYC), between March 1 and June 12, 2020. Using clustering analysis, 4 biologically distinct subphenotypes were derived in the development cohort (N = 8199). Importantly, the identified subphenotypes were highly predictive of clinical outcomes (especially 60-day mortality). Sensitivity analyses in the development cohort, and rederivation and prediction in the internal (N = 3519) and external (N = 3519) validation cohorts confirmed the reproducibility and usability of the subphenotypes. Further analyses showed varying subphenotype prevalence across the peak of the outbreak in NYC. We also found that SDoH specifically influenced mortality outcome in Subphenotype IV, which is associated with older age, worse clinical manifestation, and high comorbidity burden. Our findings may lead to a better understanding of how COVID-19 causes disease in different populations and potentially benefit clinical trial development. The temporal patterns and SDoH implications of the subphenotypes may add insights to health policy to reduce social disparity in the pandemic.",
        "DOI": "10.1038/s41746-021-00481-w",
        "affiliation_name": "Memorial Sloan-Kettering Cancer Center",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep transfer learning framework for the identification of malicious activities to combat cyberattack",
        "paper_author": "Singh D.",
        "publication": "Future Generation Computer Systems",
        "citied_by": "27",
        "cover_date": "2021-12-01",
        "Abstract": "The people having a perpetrating mind and the facilitation in advanced technologies cause the criminogenic activities in cyberspace, thereby creating societal problems. Darknet is an internet-based technology that builds on an encrypted network. Darknet networks can be accessed using a specific software with a specific network configuration; its content does not index by any search engines. Since its beginning, Darknet has been used for criminogenic tasks and applauded primarily for cybercrime promotion, including arms and drug dealing. Few countries have control over digital media and are ruled by a suppressive government. They have formulated strict policies for freedom fighters and journalism, using the Darknet anonymously. Also, many people use it for illegal purposes. Therefore, we have both positive and negative impacts of the darknet on human society and just cannot be discarded. However, in this paper, our prime concern emanates from the darknet network detection from the network traffic data through the deep transfer learning model. To provide a more accurate result, we transform time-based features into a three-dimensional image and then feed it into a pre-trained model for the extraction of promising features. In this study, we considered the DeepInsight method to transform the numerical features into image data. These features were then used in a proposed bi-level classification system to classify the input data into malicious activities. To identify the optimized pretrained network this paper utilized 10 pre-trained models: AlexNet, ResNet18, ResNet50, ResNet101, DenseNet, GoogLeNet, VGG16, VGG19, Inceptionv3, and SqueezeNet with three different baseline classifiers, namely support vector machine, decision tree, and random forest. In addition to malicious activity prediction, the proposed model could also predict the type of traffic. The experiment results illustrate that the VGG19 based features along with random forest can classify the traffic data with 96% of accuracy.",
        "DOI": "10.1016/j.future.2021.07.015",
        "affiliation_name": "Bennett University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Using deep learning neural networks to predict the knowledge economy index for developing and emerging economies",
        "paper_author": "Andrés A.R.",
        "publication": "Expert Systems with Applications",
        "citied_by": "12",
        "cover_date": "2021-12-01",
        "Abstract": "Missing values and the inconsistency of the measures of the knowledge economy remain vexing problems that hamper policy-making and future research in developing and emerging economies. This paper contributes to the new and evolving literature that seeks to advance better understanding of the importance of the knowledge economy for policy and further research in developing and emerging economies. In this paper we use a supervised machine deep learning neural network (DLNN) approach to predict the knowledge economy index of 71 developing and emerging economies during the 1995–2017 period. Applied in combination with a data imputation procedure based on the K-closest neighbor algorithm, DLNN is capable of handling missing data problems better than alternative methods. A 10-fold validation of the DLNN yielded low quadratic and absolute error (0,382 +- 0,065). The results are robust and efficient, and the model's predictive power is high. There is a difference in the predictive power when we disaggregate countries in all emerging economies versus emerging Central European countries. We explain this result and leave the rest to future endeavors. Overall, this research has filled in gaps due to missing data thereby allowing for effective policy strategies. At the aggregate level development agencies, including the World Bank that originated the KEI, would benefit from our approach until substitutes come along.",
        "DOI": "10.1016/j.eswa.2021.115514",
        "affiliation_name": "VSB – Technical University of Ostrava",
        "affiliation_city": "Ostrava",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Evaluating the relationship between citation set size, team size and screening methods used in systematic reviews: a cross-sectional study",
        "paper_author": "O’Hearn K.",
        "publication": "BMC Medical Research Methodology",
        "citied_by": "2",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Standard practice for conducting systematic reviews (SRs) is time consuming and involves the study team screening hundreds or thousands of citations. As the volume of medical literature grows, the citation set sizes and corresponding screening efforts increase. While larger team size and alternate screening methods have the potential to reduce workload and decrease SR completion times, it is unknown whether investigators adapt team size or methods in response to citation set sizes. Using a cross-sectional design, we sought to understand how citation set size impacts (1) the total number of authors or individuals contributing to screening and (2) screening methods. Methods: MEDLINE was searched in April 2019 for SRs on any health topic. A total of 1880 unique publications were identified and sorted into five citation set size categories (after deduplication): < 1,000, 1,001–2,500, 2,501–5,000, 5,001–10,000, and > 10,000. A random sample of 259 SRs were selected (~ 50 per category) for data extraction and analysis. Results: With the exception of the pairwise t test comparing the under 1000 and over 10,000 categories (median 5 vs. 6, p = 0.049) no statistically significant relationship was evident between author number and citation set size. While visual inspection was suggestive, statistical testing did not consistently identify a relationship between citation set size and number of screeners (title-abstract, full text) or data extractors. However, logistic regression identified investigators were significantly more likely to deviate from gold-standard screening methods (i.e. independent duplicate screening) with larger citation sets. For every doubling of citation size, the odds of using gold-standard screening decreased by 15 and 20% at title-abstract and full text review, respectively. Finally, few SRs reported using crowdsourcing (n = 2) or computer-assisted screening (n = 1). Conclusions: Large citation set sizes present a challenge to SR teams, especially when faced with time-sensitive health policy questions. Our study suggests that with increasing citation set size, authors are less likely to adhere to gold-standard screening methods. It is possible that adjunct screening methods, such as crowdsourcing (large team) and computer-assisted technologies, may provide a viable solution for authors to complete their SRs in a timely manner.",
        "DOI": "10.1186/s12874-021-01335-5",
        "affiliation_name": "McMaster University",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Modeling land use change and forest carbon stock changes in temperate forests in the United States",
        "paper_author": "Fitts L.A.",
        "publication": "Carbon Balance and Management",
        "citied_by": "19",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Forests provide the largest terrestrial sink of carbon (C). However, these C stocks are threatened by forest land conversion. Land use change has global impacts and is a critical component when studying C fluxes, but it is not always fully considered in C accounting despite being a major contributor to emissions. An urgent need exists among decision-makers to identify the likelihood of forest conversion to other land uses and factors affecting C loss. To help address this issue, we conducted our research in California, Colorado, Georgia, New York, Texas, and Wisconsin. The objectives were to (1) model the probability of forest conversion and C stocks dynamics using USDA Forest Service Forest Inventory and Analysis (FIA) data and (2) create wall-to-wall maps showing estimates of the risk of areas to convert from forest to non-forest. We used two modeling approaches: a machine learning algorithm (random forest) and generalized mixed-effects models. Explanatory variables for the models included ecological attributes, topography, census data, forest disturbances, and forest conditions. Model predictions and Landsat spectral information were used to produce wall-to-wall probability maps of forest change using Google Earth Engine. Results: During the study period (2000–2017), 3.4% of the analyzed FIA plots transitioned from forest to mixed or non-forested conditions. Results indicate that the change in land use from forests is more likely with increasing human population and housing growth rates. Furthermore, non-public forests showed a higher probability of forest change compared to public forests. Areas closer to cities and coastal areas showed a higher risk of transition to non-forests. Out of the six states analyzed, Colorado had the highest risk of conversion and the largest amount of aboveground C lost. Natural forest disturbances were not a major predictor of land use change. Conclusions: Land use change is accelerating globally, causing a large increase in C emissions. Our results will help policy-makers prioritize forest management activities and land use planning by providing a quantitative framework that can enhance forest health and productivity. This work will also inform climate change mitigation strategies by understanding the role that land use change plays in C emissions.",
        "DOI": "10.1186/s13021-021-00183-6",
        "affiliation_name": "University of Minnesota Twin Cities",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A deep neural network approach for sentiment analysis of medically related texts: an analysis of tweets related to concussions in sports",
        "paper_author": "Tirdad K.",
        "publication": "Brain Informatics",
        "citied_by": "8",
        "cover_date": "2021-12-01",
        "Abstract": "Annually, over three million people in North America suffer concussions. Every age group is susceptible to concussion, but youth involved in sporting activities are particularly vulnerable, with about 6% of all youth suffering a concussion annually. Youth who suffer concussion have also been shown to have higher rates of suicidal ideation, substance and alcohol use, and violent behaviors. A significant body of research over the last decade has led to changes in policies and laws intended to reduce the incidence and burden of concussions. However, it is also clear that youth engaging in high-risk activities like sport often underreport concussion, while others may embellish reports for specific purposes. For such policies and laws to work, they must operate effectively within a facilitative social context so understanding the culture around concussion becomes essential to reducing concussion and its consequences. We present an automated deep neural network approach to analyze tweets with sport-related concussion context to identify the general public’s sentiment towards concerns in sport-related concussion. A single-layer and multi-layer convolutional neural networks, Long Short-Term Memory (LSTM) networks, and Bidirectional LSTM were trained to classify the sentiments of the tweets. Afterwards, we train an ensemble model to aggregate the predictions of our networks to provide a final decision of the tweet’s sentiment. The system achieves an evaluation F1 score of 62.71% based on Precision and Recall. The trained system is then used to analyze the tweets in the FIFA World Cup 2018 to measure audience reaction to events involving concussion. The neural network system provides an understanding of the culture around concussion through sentiment analysis.",
        "DOI": "10.1186/s40708-021-00134-4",
        "affiliation_name": "Li Ka Shing Knowledge Institute",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Application of machine learning to assess the value of information in polymer flooding",
        "paper_author": "Tadjer A.",
        "publication": "Petroleum Research",
        "citied_by": "4",
        "cover_date": "2021-12-01",
        "Abstract": "In this work, we provide a more consistent alternative for performing value of information (VOI) analyses to address sequential decision problems in reservoir management and generate insights on the process of reservoir decision-making. These sequential decision problems are often solved and modeled as stochastic dynamic programs, but once the state space becomes large and complex, traditional techniques, such as policy iteration and backward induction, quickly become computationally demanding and intractable. To resolve these issues and utilize fewer computational resources, we instead make use of a viable alternative called approximate dynamic programming (ADP), which is a powerful solution technique that can handle complex, large-scale problems and discover a near-optimal solution for intractable sequential decision making. We compare and test the performance of several machine learning techniques that lie within the domain of ADP to determine the optimal time for beginning a polymer flooding process within a reservoir development plan. The approximate dynamic approach utilized here takes into account both the effect of the information obtained before a decision is made and the effect of the information that might be obtained to support future decisions while significantly improving both the timing and the value of the decision, thereby leading to a significant increase in economic performance.",
        "DOI": "10.1016/j.ptlrs.2021.05.006",
        "affiliation_name": "Equinor ASA",
        "affiliation_city": "Stavanger",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "A machine learning model of national competitiveness with regional statistics of public expenditure",
        "paper_author": "Zaragoza-Ibarra A.",
        "publication": "Computational and Mathematical Organization Theory",
        "citied_by": "1",
        "cover_date": "2021-12-01",
        "Abstract": "Competitiveness, defined as the rate of success in attracting and maintaining industries to foster the sustained improvement in citizens’ wellbeing, has been a long-pursued goal for regions and nations. Today’s rapid advancements in technology, especially in telecommunications, open challenges for decision and policy makers to generate effective and efficient solutions in a global scenario. In this context, the latest developments in artificial intelligence, machine learning and deep learning open new paths for describing, analyzing, and representing complex phenomena in systemic environments. This paper presents a model using a neural network to predict the behavior of competitive benchmarks using public expenditure variables. The theory of control, in which the neural network approach is based, offers some advantages such as solving the problem while considering the dynamic nature of the phenomenon and allowing control blocks to be implemented in a straightforward method. The present paper establishes a neural network model that links control, administration, and systems theories in a statistically sound approach that connects both sets of variables, opening the path for extensions that allow optimal allocation of resources.",
        "DOI": "10.1007/s10588-021-09338-9",
        "affiliation_name": "Universidad Michoacana de San Nicolás de Hidalgo",
        "affiliation_city": "Morelia",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Online hate network spreads malicious COVID-19 content outside the control of individual social media platforms",
        "paper_author": "Velásquez N.",
        "publication": "Scientific Reports",
        "citied_by": "42",
        "cover_date": "2021-12-01",
        "Abstract": "We show that malicious COVID-19 content, including racism, disinformation, and misinformation, exploits the multiverse of online hate to spread quickly beyond the control of any individual social media platform. We provide a first mapping of the online hate network across six major social media platforms. We demonstrate how malicious content can travel across this network in ways that subvert platform moderation efforts. Machine learning topic analysis shows quantitatively how online hate communities are sharpening COVID-19 as a weapon, with topics evolving rapidly and content becoming increasingly coherent. Based on mathematical modeling, we provide predictions of how changes to content moderation policies can slow the spread of malicious content.",
        "DOI": "10.1038/s41598-021-89467-y",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Leveraging artificial intelligence for pandemic preparedness and response: a scoping review to identify key use cases",
        "paper_author": "Syrowatka A.",
        "publication": "npj Digital Medicine",
        "citied_by": "68",
        "cover_date": "2021-12-01",
        "Abstract": "Artificial intelligence (AI) represents a valuable tool that could be widely used to inform clinical and public health decision-making to effectively manage the impacts of a pandemic. The objective of this scoping review was to identify the key use cases for involving AI for pandemic preparedness and response from the peer-reviewed, preprint, and grey literature. The data synthesis had two parts: an in-depth review of studies that leveraged machine learning (ML) techniques and a limited review of studies that applied traditional modeling approaches. ML applications from the in-depth review were categorized into use cases related to public health and clinical practice, and narratively synthesized. One hundred eighty-three articles met the inclusion criteria for the in-depth review. Six key use cases were identified: forecasting infectious disease dynamics and effects of interventions; surveillance and outbreak detection; real-time monitoring of adherence to public health recommendations; real-time detection of influenza-like illness; triage and timely diagnosis of infections; and prognosis of illness and response to treatment. Data sources and types of ML that were useful varied by use case. The search identified 1167 articles that reported on traditional modeling approaches, which highlighted additional areas where ML could be leveraged for improving the accuracy of estimations or projections. Important ML-based solutions have been developed in response to pandemics, and particularly for COVID-19 but few were optimized for practical application early in the pandemic. These findings can support policymakers, clinicians, and other stakeholders in prioritizing research and development to support operationalization of AI for future pandemics.",
        "DOI": "10.1038/s41746-021-00459-8",
        "affiliation_name": "IBM Watson Health",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Benchmarking machine learning algorithms for adaptive quantum phase estimation with noisy intermediate-scale quantum sensors",
        "paper_author": "Costa N.F.",
        "publication": "EPJ Quantum Technology",
        "citied_by": "15",
        "cover_date": "2021-12-01",
        "Abstract": "Quantum phase estimation is a paradigmatic problem in quantum sensing and metrology. Here we show that adaptive methods based on classical machine learning algorithms can be used to enhance the precision of quantum phase estimation when noisy non-entangled qubits are used as sensors. We employ the Differential Evolution (DE) and Particle Swarm Optimization (PSO) algorithms to this task and we identify the optimal feedback policies which minimize the Holevo variance. We benchmark these schemes with respect to scenarios that include Gaussian and Random Telegraph fluctuations as well as reduced Ramsey-fringe visibility due to decoherence. We discuss their robustness against noise in connection with real experimental setups such as Mach–Zehnder interferometry with optical photons and Ramsey interferometry in trapped ions, superconducting qubits and nitrogen-vacancy (NV) centers in diamond.",
        "DOI": "10.1140/epjqt/s40507-021-00105-y",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Mapping chronic disease prevalence based on medication use and socio-demographic variables: an application of LASSO on administrative data sources in healthcare in the Netherlands",
        "paper_author": "Füssenich K.",
        "publication": "BMC Public Health",
        "citied_by": "5",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Policymakers generally lack sufficiently detailed health information to develop localized health policy plans. Chronic disease prevalence mapping is difficult as accurate direct sources are often lacking. Improvement is possible by adding extra information such as medication use and demographic information to identify disease. The aim of the current study was to obtain small geographic area prevalence estimates for four common chronic diseases by modelling based on medication use and socio-economic variables and next to investigate regional patterns of disease. Methods: Administrative hospital records and general practitioner registry data were linked to medication use and socio-economic characteristics. The training set (n = 707,021) contained GP diagnosis and/or hospital admission diagnosis as the standard for disease prevalence. For the entire Dutch population (n = 16,777,888), all information except GP diagnosis and hospital admission was available. LASSO regression models for binary outcomes were used to select variables strongly associated with disease. Dutch municipality (non-)standardized prevalence estimates for stroke, CHD, COPD and diabetes were then based on averages of predicted probabilities for each individual inhabitant. Results: Adding medication use data as a predictor substantially improved model performance. Estimates at the municipality level performed best for diabetes with a weighted percentage error (WPE) of 6.8%, and worst for COPD (WPE 14.5%)Disease prevalence showed clear regional patterns, also after standardization for age. Conclusion: Adding medication use as an indicator of disease prevalence next to socio-economic variables substantially improved estimates at the municipality level. The resulting individual disease probabilities could be aggregated into any desired regional level and provide a useful tool to identify regional patterns and inform local policy.",
        "DOI": "10.1186/s12889-021-10754-4",
        "affiliation_name": "Rijksinstituut voor Volksgezondheid en Milieu",
        "affiliation_city": "Bilthoven",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Intrusion detection systems using long short-term memory (LSTM)",
        "paper_author": "Laghrissi F.E.",
        "publication": "Journal of Big Data",
        "citied_by": "165",
        "cover_date": "2021-12-01",
        "Abstract": "An intrusion detection system (IDS) is a device or software application that monitors a network for malicious activity or policy violations. It scans a network or a system for a harmful activity or security breaching. IDS protects networks (Network-based intrusion detection system NIDS) or hosts (Host-based intrusion detection system HIDS), and work by either looking for signatures of known attacks or deviations from normal activity. Deep learning algorithms proved their effectiveness in intrusion detection compared to other machine learning methods. In this paper, we implemented deep learning solutions for detecting attacks based on Long Short-Term Memory (LSTM). PCA (principal component analysis) and Mutual information (MI) are used as dimensionality reduction and feature selection techniques. Our approach was tested on a benchmark data set, KDD99, and the experimental outcomes show that models based on PCA achieve the best accuracy for training and testing, in both binary and multiclass classification.",
        "DOI": "10.1186/s40537-021-00448-4",
        "affiliation_name": "Hassan II University of Casablanca",
        "affiliation_city": "Casablanca",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Computational medication regimen for Parkinson’s disease using reinforcement learning",
        "paper_author": "Kim Y.",
        "publication": "Scientific Reports",
        "citied_by": "19",
        "cover_date": "2021-12-01",
        "Abstract": "Our objective is to derive a sequential decision-making rule on the combination of medications to minimize motor symptoms using reinforcement learning (RL). Using an observational longitudinal cohort of Parkinson’s disease patients, the Parkinson’s Progression Markers Initiative database, we derived clinically relevant disease states and an optimal combination of medications for each of them by using policy iteration of the Markov decision process (MDP). We focused on 8 combinations of medications, i.e., Levodopa, a dopamine agonist, and other PD medications, as possible actions and motor symptom severity, based on the Unified Parkinson Disease Rating Scale (UPDRS) section III, as reward/penalty of decision. We analyzed a total of 5077 visits from 431 PD patients with 55.5 months follow-up. We excluded patients without UPDRS III scores or medication records. We derived a medication regimen that is comparable to a clinician’s decision. The RL model achieved a lower level of motor symptom severity scores than what clinicians did, whereas the clinicians’ medication rules were more consistent than the RL model. The RL model followed the clinician’s medication rules in most cases but also suggested some changes, which leads to the difference in lowering symptoms severity. This is the first study to investigate RL to improve the pharmacological approach of PD patients. Our results contribute to the development of an interactive machine-physician ecosystem that relies on evidence-based medicine and can potentially enhance PD management.",
        "DOI": "10.1038/s41598-021-88619-4",
        "affiliation_name": "University of Texas Health Science Center at Houston",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Reinforcement Learning-Based Vehicle Platoon Control Strategy for Reducing Energy Consumption in Traffic Oscillations",
        "paper_author": "Li M.",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "76",
        "cover_date": "2021-12-01",
        "Abstract": "The vehicle platoon will be the most dominant driving mode on future roads. To the best of our knowledge, few reinforcement learning (RL) algorithms have been applied in vehicle platoon control, which has large-scale action and state spaces. Some RL-based methods were applied to solve single-agent problems. If we need to tackle multiagent problems, we will use multiagent RL algorithms since the parameters space grows exponentially with the increasing number of agents involved. Previous multiagent RL algorithms generally may provide redundant information to agents, indicating a large amount of useless or unrelated information, which may cause to be difficult for convergence training and pattern extractions from shared information. Also, random actions usually contribute to crashes, especially at the beginning of training. In this study, a communication proximal policy optimization (CommPPO) algorithm was proposed to tackle the above issues. In specific, the CommPPO model adopts a parameter-sharing structure to allow the dynamic variation of agent numbers, which can well handle various platoon dynamics, including splitting and merging. The communication protocol of the CommPPO consists of two parts. In the state part, the widely used predecessor-leader follower typology in the platoon is adopted to transmit global and local state information to agents. In the reward part, a new reward communication channel is proposed to solve the spurious reward and 'lazy agent' problems in some existing multiagent RLs. Moreover, a curriculum learning approach is adopted to reduce crashes and speed up training. To validate the proposed strategy for platoon control, two existing multiagent RLs and a traditional platoon control strategy were applied in the same scenarios for comparison. Results showed that the CommPPO algorithm gained more rewards and achieved the largest fuel consumption reduction (11.6%).",
        "DOI": "10.1109/TNNLS.2021.3071959",
        "affiliation_name": "University of South Australia",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Research Screener: a machine learning tool to semi-automate abstract screening for systematic reviews",
        "paper_author": "Chai K.E.K.",
        "publication": "Systematic Reviews",
        "citied_by": "90",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Systematic reviews and meta-analyses provide the highest level of evidence to help inform policy and practice, yet their rigorous nature is associated with significant time and economic demands. The screening of titles and abstracts is the most time consuming part of the review process with analysts required review thousands of articles manually, taking on average 33 days. New technologies aimed at streamlining the screening process have provided initial promising findings, yet there are limitations with current approaches and barriers to the widespread use of these tools. In this paper, we introduce and report initial evidence on the utility of Research Screener, a semi-automated machine learning tool to facilitate abstract screening. Methods: Three sets of analyses (simulation, interactive and sensitivity) were conducted to provide evidence of the utility of the tool through both simulated and real-world examples. Results: Research Screener delivered a workload saving of between 60 and 96% across nine systematic reviews and two scoping reviews. Findings from the real-world interactive analysis demonstrated a time saving of 12.53 days compared to the manual screening, which equates to a financial saving of USD 2444. Conservatively, our results suggest that analysts who scan 50% of the total pool of articles identified via a systematic search are highly likely to have identified 100% of eligible papers. Conclusions: In light of these findings, Research Screener is able to reduce the burden for researchers wishing to conduct a comprehensive systematic review without reducing the scientific rigour for which they strive to achieve.",
        "DOI": "10.1186/s13643-021-01635-3",
        "affiliation_name": "Curtin University",
        "affiliation_city": "Perth",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Enhanced concept-level sentiment analysis system with expanded ontological relations for efficient classification of user reviews",
        "paper_author": "Khattak A.",
        "publication": "Egyptian Informatics Journal",
        "citied_by": "28",
        "cover_date": "2021-12-01",
        "Abstract": "Background/introduction: Concept-level sentiment analysis deals with the extraction and classification of concepts and features from user reviews expressed online about products and other entities like political leaders, government policies, and others. The prior studies on concept-level sentiment analysis have used a limited set of linguistic rules for extracting concepts and their associated features. Furthermore, the ontological relations used in the early works for performing concept-level sentiment analysis need enhancement in terms of the extended set of features concepts and ontological relations. Methods: This work aims at addressing the aforementioned issues and tries to bridge the literature gap by proposing an extended set of linguistic rules for concept-feature pair extraction along with enhanced set ontological relations. Additionally, a supervised a machine learning technique is implemented for performing concept-level sentiment analysis. Results and conclusions: Experimental results depict the effectiveness of the proposed system in terms of improved efficiency (P: 88%, R: 88%, F-score: 88%, and A: 87.5%).",
        "DOI": "10.1016/j.eij.2021.03.001",
        "affiliation_name": "University of Gujrat",
        "affiliation_city": "Gujrat",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Machine learning approach to drivers of bank lending: evidence from an emerging economy",
        "paper_author": "Ozgur O.",
        "publication": "Financial Innovation",
        "citied_by": "14",
        "cover_date": "2021-12-01",
        "Abstract": "The study analyzes the performance of bank-specific characteristics, macroeconomic indicators, and global factors to predict the bank lending in Turkey for the period 2002Q4–2019Q2. The objective of this study is first, to clarify the possible nonlinear and nonparametric relationships between outstanding bank loans and bank-specific, macroeconomic, and global factors. Second, it aims to propose various machine learning algorithms that determine drivers of bank lending and benefits from the advantages of these techniques. The empirical findings indicate favorable evidence that the drivers of bank lending exhibit some nonlinearities. Additionally, partial dependence plots depict that numerous bank-specific characteristics and macroeconomic indicators tend to be important variables that influence bank lending behavior. The study’s findings have some policy implications for bank managers, regulatory authorities, and policymakers.",
        "DOI": "10.1186/s40854-021-00237-1",
        "affiliation_name": "Ankara Yildirim Beyazit University",
        "affiliation_city": "Ankara",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Swine growth promotion with antibiotics or alternatives can increase antibiotic resistance gene mobility potential",
        "paper_author": "Muurinen J.",
        "publication": "Scientific Reports",
        "citied_by": "39",
        "cover_date": "2021-12-01",
        "Abstract": "Even though the use of antibiotics for food-producing animals may contribute to the emergence of antimicrobial resistance, antibiotics are still used as growth promoters. Due to consumer and regulatory pressures, the use of alternatives to antibiotics as growth promoters is increasing, thus more information is needed on their capability to disseminate antimicrobial resistance compared to antibiotics. We investigated the impacts of carbadox (antibiotic), copper sulfate and zinc oxide (metals) and mushroom powder (natural product) on the pig fecal resistome and microbiome. Antibiotic resistance gene (ARG) and mobile genetic element (MGE) abundances were measured using a high-throughput qPCR array with 382 primer pairs. Bacterial community composition was determined by 16S rRNA gene sequencing. More ARGs co-occurred with MGEs in the growth promoter group samples than in the control group samples. Community composition could not be linked to resistome in the growth promoter group samples, indicating a potential decoupling of ARGs and phylogeny. Additionally, machine-learning methods aided in defining the community and resistome differences in response to treatments. Since increased ARG mobility potential was the primary response to the dietary additives used in this study, we suggest that ARG mobility should be considered when designing antimicrobial use policies and antimicrobial resistance surveillances.",
        "DOI": "10.1038/s41598-021-84759-9",
        "affiliation_name": "College of Agriculture",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "African soil properties and nutrients mapped at 30 m spatial resolution using two-scale ensemble machine learning",
        "paper_author": "Hengl T.",
        "publication": "Scientific Reports",
        "citied_by": "163",
        "cover_date": "2021-12-01",
        "Abstract": "Soil property and class maps for the continent of Africa were so far only available at very generalised scales, with many countries not mapped at all. Thanks to an increasing quantity and availability of soil samples collected at field point locations by various government and/or NGO funded projects, it is now possible to produce detailed pan-African maps of soil nutrients, including micro-nutrients at fine spatial resolutions. In this paper we describe production of a 30 m resolution Soil Information System of the African continent using, to date, the most comprehensive compilation of soil samples (N≈ 150 , 000) and Earth Observation data. We produced predictions for soil pH, organic carbon (C) and total nitrogen (N), total carbon, effective Cation Exchange Capacity (eCEC), extractable—phosphorus (P), potassium (K), calcium (Ca), magnesium (Mg), sulfur (S), sodium (Na), iron (Fe), zinc (Zn)—silt, clay and sand, stone content, bulk density and depth to bedrock, at three depths (0, 20 and 50 cm) and using 2-scale 3D Ensemble Machine Learning framework implemented in the mlr (Machine Learning in R) package. As covariate layers we used 250 m resolution (MODIS, PROBA-V and SM2RAIN products), and 30 m resolution (Sentinel-2, Landsat and DTM derivatives) images. Our fivefold spatial Cross-Validation results showed varying accuracy levels ranging from the best performing soil pH (CCC = 0.900) to more poorly predictable extractable phosphorus (CCC = 0.654) and sulphur (CCC = 0.708) and depth to bedrock. Sentinel-2 bands SWIR (B11, B12), NIR (B09, B8A), Landsat SWIR bands, and vertical depth derived from 30 m resolution DTM, were the overall most important 30 m resolution covariates. Climatic data images—SM2RAIN, bioclimatic variables and MODIS Land Surface Temperature—however, remained as the overall most important variables for predicting soil chemical variables at continental scale. This publicly available 30-m Soil Information System of Africa aims at supporting numerous applications, including soil and fertilizer policies and investments, agronomic advice to close yield gaps, environmental programs, or targeting of nutrition interventions.",
        "DOI": "10.1038/s41598-021-85639-y",
        "affiliation_name": "International Center for Soil Fertility and Agricultural Development",
        "affiliation_city": "Muscle Shoals",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Personalized hypertension management based on serial assessment and telemedicine (PHMA): a cluster randomize controlled trial protocol in Anhui, China",
        "paper_author": "Shen X.",
        "publication": "BMC Cardiovascular Disorders",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Despite tremendous investment worldwide, hypertension treatment and control rates remain low. The complexity and long-term dynamics of influencing factors make personalized management inevitable and challenging. This protocol describes Personalized Hypertension Management in Anhui, China (PHMA), a project that uses a package of innovative approaches in tailoring interventions to individual patient’s dynamic complications and contexts. Methods/design: PHMA strives to reduce hypertension harms by eight “objective behaviors” (e.g., self-monitoring and reporting, healthy diet, physical exercise/activities). These objective behaviors are promoted through five intervention measures: support for self- monitoring, supervised machine communications, daily education or reminder messages, weekly blood pressure notification, and quarterly signed feedback. PHMA uses ten categories and over 300 variables in selecting and refining intervention procedures and content for individual patients. Efficacy of the intervention package is evaluated using a cluster randomized controlled trial design involving a total of 60 site communities and 3352 hypertension patients. Primary measure for the evaluation is systolic and diastolic blood pressure; while secondary evaluation measures include quality of life (EQ5D-5L), occurrence of hypertension-related complications (such as cerebral hemorrhage, coronary heart disease, myocardial or cerebral infarction), healthcare utilization and scores of objective behaviors. Discussion: PHMA uses novel, low cost and sustainable approaches to tailor interventions to the dynamic conditions and contexts of individual patients. Unlike contemporary approaches to hypertension management which are mainly population based, each participant patient in PHMA applies a unique intervention package and all messages, feedbacks and other materials sent out to individual patients are different from each other. PHMA is the first project that adopts comprehensive tailoring and if proved effective, it should have important implications for future research, practice and policy-making. Trial registration ISRCTN10999269. July 17, 2020; https://doi.org/10.1186/ISRCTN10999269.",
        "DOI": "10.1186/s12872-021-01943-5",
        "affiliation_name": "The First Affiliated Hospital of USTC",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Community detection using unsupervised machine learning techniques on COVID-19 dataset",
        "paper_author": "Chaudhary L.",
        "publication": "Social Network Analysis and Mining",
        "citied_by": "24",
        "cover_date": "2021-12-01",
        "Abstract": "COVID-19 has been considered to be the most destructive pandemic ever happened in the history of mankind. The worldwide research community has put a tenacious effort to carry out research on the COVID-19 to analyse its impact on economic, medical and sociolgoical fields. They are trying to solve many crucial issues related to this disease and derive strategies to deal with this global pandemic. In this paper, we have analysed the trend, countries affected regionally and the variation of cases at the country level on COVID-19 dataset. We have used the Principal component analysis on the COVID-19 dataset variables to reduce the dimensionality and find the most significant variables. Further, we have unveiled the hidden community structure of countries by applying the unsupervised clustering approach, K-means. We have compared the results with the K-means method. The communities achieved after applying the PCA are more precise. The resulted communities can be beneficial to researchers, scientists, sociologists, different policy makers and managers of health sector.",
        "DOI": "10.1007/s13278-021-00734-2",
        "affiliation_name": "Jawaharlal Nehru University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Combining expert knowledge and machine-learning to classify herd types in livestock systems",
        "paper_author": "Brock J.",
        "publication": "Scientific Reports",
        "citied_by": "22",
        "cover_date": "2021-12-01",
        "Abstract": "A detailed understanding of herd types is needed for animal disease control and surveillance activities, to inform epidemiological study design and interpretation, and to guide effective policy decision-making. In this paper, we present a new approach to classify herd types in livestock systems by combining expert knowledge and a machine-learning algorithm called self-organising-maps (SOMs). This approach is applied to the cattle sector in Ireland, where a detailed understanding of herd types can assist with on-going discussions on control and surveillance for endemic cattle diseases. To our knowledge, this is the first time that the SOM algorithm has been used to differentiate livestock systems. In compliance with European Union (EU) requirements, relevant data in the Irish livestock register includes the birth, movements and disposal of each individual bovine, and also the sex and breed of each bovine and its dam. In total, 17 herd types were identified in Ireland using 9 variables. We provide a data-driven classification tree using decisions derived from the Irish livestock registration data. Because of the visual capabilities of the SOM algorithm, the interpretation of results is relatively straightforward and we believe our approach, with adaptation, can be used to classify herd type in any other livestock system.",
        "DOI": "10.1038/s41598-021-82373-3",
        "affiliation_name": "Animal Health Ireland",
        "affiliation_city": "Carrick-on-Shannon",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Societies within peace systems avoid war and build positive intergroup relationships",
        "paper_author": "Fry D.P.",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "19",
        "cover_date": "2021-12-01",
        "Abstract": "A comparative anthropological perspective reveals not only that some human societies do not engage in war, but also that peaceful social systems exist. Peace systems are defined as clusters of neighbouring societies that do not make war with each other. The mere existence of peace systems is important because it demonstrates that creating peaceful intergroup relationships is possible whether the social units are tribal societies, nations, or actors within a regional system. Peace systems have received scant scientific attention despite holding potentially useful knowledge and principles about how to successfully cooperate to keep the peace. Thus, the mechanisms through which peace systems maintain peaceful relationships are largely unknown. It is also unknown to what degree peace systems may differ from other types of social systems. This study shows that certain factors hypothesised to contribute to intergroup peace are more developed within peace systems than elsewhere. A sample consisting of peace systems scored significantly higher than a comparison group regarding overarching common identity; positive social interconnectedness; interdependence; non-warring values and norms; non-warring myths, rituals, and symbols; and peace leadership. Additionally, a machine learning analysis found non-warring norms, rituals, and values to have the greatest relative importance for a peace system outcome. These results have policy implications for how to promote and sustain peace, cohesion, and cooperation among neighbouring societies in various social contexts, including among nations. For example, the purposeful promotion of peace system features may facilitate the international cooperation necessary to address interwoven global challenges such as global pandemics, oceanic pollution, loss of biodiversity, nuclear proliferation, and climate change.",
        "DOI": "10.1057/s41599-020-00692-8",
        "affiliation_name": "Columbia University",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A unified machine learning approach to time series forecasting applied to demand at emergency departments",
        "paper_author": "Vollmer M.A.C.",
        "publication": "BMC Emergency Medicine",
        "citied_by": "35",
        "cover_date": "2021-12-01",
        "Abstract": "Background: There were 25.6 million attendances at Emergency Departments (EDs) in England in 2019 corresponding to an increase of 12 million attendances over the past ten years. The steadily rising demand at EDs creates a constant challenge to provide adequate quality of care while maintaining standards and productivity. Managing hospital demand effectively requires an adequate knowledge of the future rate of admission. We develop a novel predictive framework to understand the temporal dynamics of hospital demand. Methods: We compare and combine state-of-the-art forecasting methods to predict hospital demand 1, 3 or 7 days into the future. In particular, our analysis compares machine learning algorithms to more traditional linear models as measured in a mean absolute error (MAE) and we consider two different hyperparameter tuning methods, enabling a faster deployment of our models without compromising performance. We believe our framework can readily be used to forecast a wide range of policy relevant indicators. Results: We find that linear models often outperform machine learning methods and that the quality of our predictions for any of the forecasting horizons of 1, 3 or 7 days are comparable as measured in MAE. Our approach is able to predict attendances at these emergency departments one day in advance up to a mean absolute error of ±14 and ±10 patients corresponding to a mean absolute percentage error of 6.8% and 8.6% respectively. Conclusions: Simple linear methods like generalized linear models are often better or at least as good as ensemble learning methods like the gradient boosting or random forest algorithm. However, though sophisticated machine learning methods are not necessarily better than linear models, they improve the diversity of model predictions so that stacked predictions can be more robust than any single model including the best performing one.",
        "DOI": "10.1186/s12873-020-00395-y",
        "affiliation_name": "Imperial College Healthcare NHS Trust",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "The association of Coronavirus Disease-19 mortality and prior bacille Calmette-Guerin vaccination: a robust ecological analysis using unsupervised machine learning",
        "paper_author": "Brooks N.A.",
        "publication": "Scientific Reports",
        "citied_by": "27",
        "cover_date": "2021-12-01",
        "Abstract": "Population-level data have suggested that bacille Calmette-Guerin (BCG) vaccination may lessen the severity of Coronavirus Disease-19 (COVID-19) prompting clinical trials in this area. Some reports have demonstrated conflicting results. We performed a robust, ecologic analysis comparing COVID-19 related mortality (CRM) between strictly selected countries based on BCG vaccination program status utilizing publicly available databases and machine learning methods to define the association between active BCG vaccination programs and CRM. Validation was performed using linear regression and country-specific modeling. CRM was lower for the majority of countries with a BCG vaccination policy for at least the preceding 15 years (BCG15). CRM increased significantly for each increase in the percent population over age 65. A higher total population of a country and BCG15 were significantly associated with improved CRM. There was a consistent association between countries with a BCG vaccination for the preceding 15 years, but not other vaccination programs, and CRM. BCG vaccination programs continued to be associated with decreased CRM even for populations < 40 years old where CRM events are less frequent.",
        "DOI": "10.1038/s41598-020-80787-z",
        "affiliation_name": "Mater Private Cork",
        "affiliation_city": "Cork",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "The sequence of disease-modifying anti-rheumatic drugs: pathways to and predictors of tocilizumab monotherapy",
        "paper_author": "Solomon D.H.",
        "publication": "Arthritis Research and Therapy",
        "citied_by": "7",
        "cover_date": "2021-12-01",
        "Abstract": "Background: There are numerous non-biologic and biologic disease-modifying anti-rheumatic drugs (bDMARDs) for rheumatoid arthritis (RA). Typical sequences of bDMARDs are not clear. Future treatment policies and trials should be informed by quantitative estimates of current treatment practice. Methods: We used data from Corrona, a large real-world RA registry, to develop a method for quantifying sequential patterns in treatment with bDMARDs. As a proof of concept, we study patients who eventually use tocilizumab monotherapy (TCZm), an IL-6 antagonist with similar benefits used as monotherapy or in combination. Patients starting a bDMARD were included and were followed using a discrete-state Markov model, observing changes in treatments every 6 months and determining whether they used TCZm. A supervised machine learning algorithm was then employed to determine longitudinal patient factors associated with TCZm use. Results: 7300 patients starting a bDMARD were followed for up to 5 years. Their median age was 58 years, 78% were female, median disease duration was 5 years, and 57% were seropositive. During follow-up, 287 (3.9%) reported use of TCZm with median time until use of 25.6 (11.5, 56.0) months. Eighty-two percent of TCZm use began within 3 years of starting any bDMARD. Ninety-three percent of TCZm users switched from TCZ combination, a TNF inhibitor, or another bDMARD. Very few patients are given TCZm as their first DMARD (0.6%). Variables associated with the use of TCZm included prior use of TCZ combination therapy, older age, longer disease duration, seronegative, higher disease activity, and no prior use of a TNF inhibitor. Conclusions: Improved understanding of treatment sequences in RA may help personalize care. These methods may help optimize treatment decisions using large-scale real-world data.",
        "DOI": "10.1186/s13075-020-02408-4",
        "affiliation_name": "Genentech, Inc",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A New Reinforcement Learning Based Learning Rate Scheduler for Convolutional Neural Network in Fault Classification",
        "paper_author": "Wen L.",
        "publication": "IEEE Transactions on Industrial Electronics",
        "citied_by": "99",
        "cover_date": "2021-12-01",
        "Abstract": "Convolutional neural network (CNN) has gained increasing attention in fault classification. However, the performance of CNN is sensitive to its learning rate. Some previous works have been done to tune the learning rate, including the 'trial and error' and manual search, which heavily depend on the experts' experiences and should be conducted repeatedly on every dataset. Because of the variety of the fault data, it is time-consuming and labor intensive to use these traditional tuning methods for fault classification. To overcome this problem, in this article, we develop a novel learning rate scheduler based on the reinforcement learning (RL) for convolutional neural network (RL-CNN) in fault classification, which can schedule the learning rate efficiently and automatically. First, a new RL agent is designed to learn the policies about the learning rate adjustment during the training process. Second, a new structure of RL-CNN is developed to balance the exploration and exploitation of the agent. Third, the bagging ensemble version of RL-CNN (RL-CNN-Ens) is presented. Three bearing datasets are used to test the performance of RL-CNN-Ens. The results show that RL-CNN-Ens outperforms the traditional DLs and machine learning methods. Meanwhile, RL-CNN-Ens can find the state-of-the-art learning rate schedulers as human designed, showing its potential in fault classification.",
        "DOI": "10.1109/TIE.2020.3044808",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting risk of early discontinuation of exclusive breastfeeding at a Brazilian referral hospital for high-risk neonates and infants: a decision-tree analysis",
        "paper_author": "Silva M.D.B.",
        "publication": "International Breastfeeding Journal",
        "citied_by": "17",
        "cover_date": "2021-12-01",
        "Abstract": "Background: Determinants at several levels may affect breastfeeding practices. Besides the known historical, socio-economic, cultural, and individual factors, other components also pose major challenges to breastfeeding. Predicting existing patterns and identifying modifiable components are important for achieving optimal results as early as possible, especially in the most vulnerable population. The goal of this study was building a tree-based analysis to determine the variables that can predict the pattern of breastfeeding at hospital discharge and at 3 and 6 months of age in a referral center for high-risk infants. Methods: This prospective, longitudinal study included 1003 infants and was conducted at a high-risk public hospital in the following three phases: hospital admission, first visit after discharge, and monthly telephone interview until the sixth month of the infant’s life. Independent variables were sorted into four groups: factors related to the newborn infant, mother, health service, and breastfeeding. The outcome was breastfeeding as per the categories established by the World Health Organization (WHO). For this study, we performed an exploratory analysis at hospital discharge and at 3 and at 6 months of age in two stages, as follows: (i) determining the frequencies of baseline characteristics stratified by breastfeeding indicators in the three mentioned periods and (ii) decision-tree analysis. Results: The prevalence of exclusive breastfeeding (EBF) was 65.2% at hospital discharge, 51% at 3 months, and 20.6% at 6 months. At hospital discharge and the sixth month, the length of hospital stay was the most important predictor of feeding practices, also relevant at the third month. Besides the mother’s and child’s characteristics (multiple births, maternal age, and parity), the social context, work, feeding practice during hospitalization, and hospital practices and policies on breastfeeding influenced the breastfeeding rates. Conclusions: The combination algorithm of decision trees (a machine learning technique) provides a better understanding of the risk predictors of breastfeeding cessation in a setting with a large variability in expositions. Decision trees may provide a basis for recommendations aimed at this high-risk population, within the Brazilian context, in light of the hospital stay at a neonatal unit and period of continuous feeding practice.",
        "DOI": "10.1186/s13006-020-00349-x",
        "affiliation_name": "Universidade Federal do Estado do Rio de Janeiro",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Modelling for risk and biosecurity related to forest health",
        "paper_author": "Robinet C.",
        "publication": "Emerging Topics in Life Sciences",
        "citied_by": "3",
        "cover_date": "2021-12-01",
        "Abstract": "Modelling the invasion and emergence of forest pests and pathogens (PnPs) is necessary to quantify the risk levels for forest health and provide key information for policy makers. Here, we make a short review of the models used to quantify the invasion risk of exotic species and the emergence risk of native species. Regarding the invasion process, models tackle each invasion phase, e.g. pathway models to describe the risk of entry, species distribution models to describe potential establishment, and dispersal models to describe (human-assisted) spread. Concerning the emergence process, models tackle each process: spread or outbreak. Only a few spread models describe jointly dispersal, growth, and establishment capabilities of native species while some mechanistic models describe the population temporal dynamics and inference models describe the probability of outbreak. We also discuss the ways to quantify uncertainty and the role of machine learning. Overall, promising directions are to increase the models' genericity by parameterization based on meta-analysis techniques to combine the effect of species traits and various environmental drivers. Further perspectives consist in considering the models' interconnection, including the assessment of the economic impact and risk mitigation options, as well as the possibility of having multi-risks and the reduction in uncertainty by collecting larger fit-for-purpose datasets.",
        "DOI": "10.1042/ETLS20200062",
        "affiliation_name": "Unité de Recherche Zoologie Forestière (URZF)",
        "affiliation_city": "Orleans",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Predictors of Turnover Intention in U.S. Federal Government Workforce: Machine Learning Evidence That Perceived Comprehensive HR Practices Predict Turnover Intention",
        "paper_author": "Kang I.G.",
        "publication": "Public Personnel Management",
        "citied_by": "25",
        "cover_date": "2021-12-01",
        "Abstract": "This study aims to identify important predictors of turnover intention and to characterize subgroups of U.S. federal employees at high risk for turnover intention. Data were drawn from the 2018 Federal Employee Viewpoint Survey (FEVS, unweighted N = 598,003), a nationally representative sample of U.S. federal employees. Machine learning Classification and Regression Tree (CART) analyses were conducted to predict turnover intention and accounted for sample weights. CART analyses identified six at-risk subgroups. Predictor importance scores showed job satisfaction was the strongest predictor of turnover intention, followed by satisfaction with organization, loyalty, accomplishment, involvement in decisions, likeness to job, satisfaction with promotion opportunities, skill development opportunities, organizational tenure, and pay satisfaction. Consequently, Human Resource (HR) departments should seek to implement comprehensive HR practices to enhance employees’ perceptions on job satisfaction, workplace environments and systems, and favorable organizational policies and supports and make tailored interventions for the at-risk subgroups.",
        "DOI": "10.1177/0091026020977562",
        "affiliation_name": "University of Kansas",
        "affiliation_city": "Lawrence",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Off-Policy Deep Reinforcement Learning Based on Steffensen Value Iteration",
        "paper_author": "Cheng Y.",
        "publication": "IEEE Transactions on Cognitive and Developmental Systems",
        "citied_by": "11",
        "cover_date": "2021-12-01",
        "Abstract": "As an important machine learning method, deep reinforcement learning (DRL) has been rapidly developed in recent years and has achieved breakthrough results in many fields, such as video games, natural language processing, and robot control. However, due to the inherit trial-and-error learning mechanism of reinforcement learning and the time-consuming training of deep neural network itself, the convergence speed of DRL is very slow and consequently limits the real applications of DRL. In this article, aiming to improve the convergence speed of DRL, we proposed a novel Steffensen value iteration (SVI) method by applying the Steffensen iteration to the value function iteration of off-policy DRL from the perspective of fixed-point iteration. The proposed SVI is theoretically proved to be convergent and have a faster convergence speed than Bellman value iteration. The proposed SVI has versatility, which can be easily combined with existing off-policy RL algorithms. In this article, we proposed two speedy off-policy DRLs by combining SVI with DDQN and TD3, respectively, namely, SVI-DDQN and SVI-TD3. Experiments on several discrete-action and continuous-action tasks from the Atari 2600 and MuJoCo platforms demonstrated that our proposed SVI-based DRLs can achieve higher average reward in a shorter time than the comparative algorithm.",
        "DOI": "10.1109/TCDS.2020.3034452",
        "affiliation_name": "China University of Mining and Technology",
        "affiliation_city": "Xuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Understanding house price appreciation using multi-source big geo-data and machine learning",
        "paper_author": "Kang Y.",
        "publication": "Land Use Policy",
        "citied_by": "135",
        "cover_date": "2021-12-01",
        "Abstract": "Understanding house price appreciation benefits place-based decision makings and real estate market analyses. Although large amounts of interests have been paid in the house price modeling, limited work has focused on evaluating the price appreciation rate. In this study, we propose a data-fusion framework to examine how well house price appreciation potentials can be predicted by combining multiple data sources. We used data sets including house structural attributes, house photos, locational amenities, street view images, transportation accessibility, visitor patterns, and socioeconomic attributes of neighborhoods to enrich our understanding of the real estate appreciation and its predictive modeling. As a case study, we investigate more than 20,000 houses in the Greater Boston Area, and discuss the spatial dependency of house price appreciations, influential variables and their relationships. In detail, we extract deep features from street view images and house photos using a deep learning model, merging features from multi-source data and modeling house price appreciation using machine learning models and the geographically weighted regression at two spatial scales: fine-scale point level and aggregated neighborhood level. Results show that the house price appreciation rate can be modeled with high accuracy using the proposed framework (R2=0.74 for gradient boosting machine at neighborhood-scale). We discovered that houses with low house prices and small house areas may have a higher house appreciation potential. Our results provide insights into how multi-source big geo-data can be employed in machine learning frameworks to characterize real estate price trends and help understand human settlements for policy-making.",
        "DOI": "10.1016/j.landusepol.2020.104919",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "1st International Conference on Applied Mathematics, Modeling and Simulation in Engineering, AMSE 2021",
        "paper_author": "NA",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-11-30",
        "Abstract": "The proceedings contain 83 papers. The topics discussed include: assessing wear out of tire using Opencv & convolutional neural networks; predict diabetes mellitus using machine learning algorithms; performance analysis of biomass energy using machine and deep learning approaches; MAC based security integration using face recognition in cloud environment; a system to automate the development of anomaly-based network intrusion detection model; secure cloud risk architecture analysis for mobile banking system and its performance analysis based on machine learning approaches; Indian currency denomination recognition and fake currency identification; an approach to detect multiple diseases using machine learning algorithm; and simplified ciphertext-policy attribute-based encryption scheme with attribute level collusion resistance for cloud storage.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Assessing the effect of human factors in healthcare cyber security practice: An empirical study",
        "paper_author": "Ketseridou S.N.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-11-26",
        "Abstract": "Emergency Departments globally suffer overcrowding due to the lack of adequate capacity and/or guidelines and policies for triaging patients. Medical service quality improvement requires optimal patient prioritization according to their level of urgency. This study aims to evaluate classification models predicting the admission or discharge of incidents triaged as level 3 according to the Emergency Severity Index algorithm. As such, adult patient visits were examined from a publicly available dataset. Feature Importance was used for the assessment of each variable contribution in predictions and a subset of 196 out of 972 variables of the original dataset was sampled. XGBoost, random forest, convolutional neural network, and k-nearest neighbors algorithms were deployed and evaluated regarding hospitalization prediction. Convolutional neural network utilization required a tabular data to image transformation which was applied using the Image Data Generator to Tabular Data (IGTD) algorithm. Benchmarking among the four algorithms showed that XGBoost outperformed the others, achieving an accuracy of 0.75, an area under the receiver operating curve of 0.74 and an area under the precision-recall curve of 0.54. Overall, machine learning-based assessment of the disposition of medium-risk patients according to ESI may lead to predictive models which constitute useful decision support tools.",
        "DOI": "10.1145/3503823.3503912",
        "affiliation_name": "University General Hospital of Thessaloniki \"AHEPA\"",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Integrating Human Mobility into the Epidemiological Models of COVID-19: Progress and Challenges",
        "paper_author": "Yin L.",
        "publication": "Journal of Geo-Information Science",
        "citied_by": "6",
        "cover_date": "2021-11-25",
        "Abstract": "The spread of infectious diseases is usually a highly nonlinear space-time diffusion process. Epidemiological models can not only be used to predict the epidemic trend, but also be used to systematically and scientifically study the transmission mechanism of the complex processes under different hypothetical intervention scenarios, which provide crucial analytical and planning tools for public health studies and policy-making. Since host behavior is one of the critical driven factors for the dynamics of infectious diseases, it is important to effectively integrate human spatiotemporal behavior into the epidemiological models for human-hosted infectious diseases. Due to the rapid development of human mobility research and applications aided by big trajectory data, many of the epidemiological models for Coronavirus Disease 2019 (COVID-19) have already coupled human mobility. By incorporating real trajectory data such as mobile phone location data at an individual or aggregated level, researchers are working towards the direction of accurately depicting the real world, so as to improve the effectiveness of the model in guiding actual epidemic prevention and control. The epidemic trend prediction, Non-pharmaceutical Interventions (NPIs) evaluation, vaccination strategy design, and transmission driven factors have been studied by the epidemiological models coupled with human mobility, which provides scientific decision-making aid for controlling epidemic in different countries and regions. In order to systematically understand this important progress of epidemiological models, this study collected and summarized relevant literatures. First, the interactions between the COVID-19 epidemic and human mobility were analyzed, which demonstrated the necessity of integrating the complex spatiotemporal behavior, such as population-based or individual-based mobility, activity, and contact interaction, into the epidemiological models. Then, according to the modeling purpose and mechanism, the models integrated with human mobility were discussed by two types: short-term epidemic prediction models and process simulation models. Among them, based on the coupling methods of human mobility, short-term epidemic prediction models can further be divided into models coupled with first-order and second-order human mobility, while process simulation models can be divided into models coupled with population-based mobility and individual-based mobility. Finally, we concluded that epidemiological models integrating human mobility should be developed towards more complex human spatiotemporal behaviors with a fine spatial granularity. Besides, it is in urgent need to improve the model capability to better understand the disease spread processes over space and time, break through the bottleneck of the huge computational cost of fine-grained models, cooperate cutting-edge artificial intelligence approaches, and develop more universal and accessible modeling data sets and tools for general users.",
        "DOI": "10.12082/dqxxkx.2021.210091",
        "affiliation_name": "Shenzhen Institute of Advanced Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Spatiotemporal variation of tropospheric formaldehyde concentration and its driving factors in Yangtze River",
        "paper_author": "Qian Y.",
        "publication": "Zhongguo Huanjing Kexue/China Environmental Science",
        "citied_by": "2",
        "cover_date": "2021-11-20",
        "Abstract": "This study uses OMI satellite data to analyse the temporal and spatial changes of the tropospheric formaldehyde column concentration in the Yangtze River Delta from 2005 to 2016. The BP and RBFN neural network models are used to perform regression simulation on the tropospheric formaldehyde column concentration at the county scale and analysis of the proportion of emissions from various departments using non-methane volatile organic compounds (NMVOC) data in 2008 and 2010. The results show that the tropospheric formaldehyde column concentration in the Yangtze River Delta urban agglomeration has an increasing trend from 2005 to 2010 and a downward trend from 2011 to 2016. The concentrations are higher in northern Anhui, northern Jiangsu, Shanghai and nearby areas, while those in southwestern Zhejiang are lower. In addition, NMVOC have significantly increased the concentration of formaldehyde in economically developed areas. The industrial sector's emissions are widely distributed in the Yangtze River Delta, and the VOC emissions from the power sector are much smaller than those from the industrial sector, and the distribution is also very sparse. The amount of VOC emissions generated by residents' lives is between the above two, with a clear North-South differentiation. Those from the transportation sector are mainly concentrated in southern Jiangsu, northern Zhejiang and Shanghai, and are distributed in strips along the transportation lines. What's more, the fitting accuracy of the neural network can reach 0.6~0.8, which is 0.3~0.4 higher than that of the linear regression, which proves that machine learning algorithms can better simulate the concentration of the formaldehyde column with NMVOC. The VOC emissions generated by residents' lives contribute most to the tropospheric formaldehyde column concentration. Studying the long-term temporal and spatial changes of the tropospheric formaldehyde column concentration and its influencing factors is conducive to in-depth study of ozone pollution, and it also provides a scientific basis for atmospheric governance and policy making.",
        "DOI": "NA",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "CISBAT 2021 - Carbon-Neutral Cities - Energy Efficiency and Renewables in the Digital Era",
        "paper_author": "NA",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-11-18",
        "Abstract": "The proceedings contain 185 papers. The topics discussed include: targeting building energy efficiency using thermal infrared earth observation telescopes; quantification of the suitable rooftop area for solar panel installation from overhead imagery using convolutional neural networks; presentation of new geospatial datasets for renewable thermal energy systems modelling in Switzerland; deep reinforcement learning for room temperature control: a black-box pipeline from data to policies; an adaptive control framework based on reinforcement learning to balance energy, comfort and hygiene in heat pump water heating systems; artificial intelligence for detecting indoor visual discomfort from facial analysis of building occupants; statistical analysis of 200 digital twins for thermal load of Swiss buildings created from smart grid monitoring data; and using machine learning to estimate the technical potential of shallow ground-source heat pumps with thermal interference.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Residential density classification for sustainable housing development using a machine learning approach",
        "paper_author": "Mohajeri N.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-11-18",
        "Abstract": "Using Machine Learning (ML) algorithms for classification of the existing residential neighbourhoods and their spatial characteristics (e.g. density) so as to provide plausible scenarios for designing future sustainable housing is a novel application. Here we develop a methodology using a Random Forests algorithm (in combination with GIS spatial data processing) to detect and classify the residential neighbourhoods and their spatial characteristics within the region between Oxford and Cambridge, that is, the 'Oxford-Cambridge Arc'. The classification model is based on four pre-defined urban classes, that is, Centre, Urban, Suburban, and Rural for the entire region. The resolution is a grid of 500 m × 500 m. The features for classification include (1) dwelling geometric attributes (e.g. garden size, building footprint area, building perimeter), (2) street networks (e.g. street length, street density, street connectivity), (3) dwelling density (number of housing units per hectare), (4) building residential types (detached, semi-detached, terraced, and flats), and (5) characteristics of the surrounding neighbourhoods. The classification results, with overall average accuracy of 80% (accuracy per class: Centre: 38%, Urban 91%, Suburban 83%, and Rural 77%), for the Arc region show that the most important variables were three characteristics of the surrounding area: residential footprint area, dwelling density, and number of private gardens. The results of the classification are used to establish a baseline for the current status of the residential neighbourhoods in the Arc region. The results bring data-driven decision-making processes to the level of local authority and policy makers in order to support sustainable housing development at the regional scale.",
        "DOI": "10.1088/1742-6596/2042/1/012017",
        "affiliation_name": "École Polytechnique Fédérale de Lausanne",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "CT 2.0",
        "paper_author": "Tedre M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "18",
        "cover_date": "2021-11-17",
        "Abstract": "CT has been the central rallying point for K-12 computing education at least since the early 2010s. Many teachers, school administrators, and policymakers have joined the movement. A consensus has emerged over the conceptual landscape of CT. Meanwhile, machine learning (ML) has triggered some major changes in many sectors of computing. Children's lives today are full of ML-driven services - take TikTok's spot-on recommendations, social media's automatic tagging of their friends in photos, and targeted personalized advertisement, just to mention a few. Children cannot learn to think about and design ML technology from learning classical programming. ML is poised to upend the CT consensus. Look at some of the changes ML has already triggered in computing. It has enabled greatly improved speech and image recognition, powerful recommendations on streaming services, autonomous navigation of cars, super-human performance in board and computer games, and even alternative-reality \"deepfake\"videos. Most advances in topics above are due to hardware evolution to non-traditional, special purpose architectures, new algorithms such as convolutional neural networks (CNN) or generative adversarial networks (GAN), and new objectives and measures of success. We will show that several key CT concepts, including debugging, problem-solving workflow, correctness, and notional machines, are insufficient for ML and need to be extended. Moreover, ML introduces new concepts including neural networks, curating and training data, and reinforcement learning that are not part of CT at all. All these changes challenge the traditional views related to teaching CT in K-12. ML is not the only emerging technology appearing in the computing landscape. Quantum computing and biological computing are not far behind. We need to start rethinking how CT must evolve to anticipate and meet these challenges.",
        "DOI": "10.1145/3488042.3488053",
        "affiliation_name": "Itä-Suomen yliopisto",
        "affiliation_city": "Kuopio",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Resilient Communities: A Novel Workflow",
        "paper_author": "Carta S.",
        "publication": "Frontiers in Built Environment",
        "citied_by": "5",
        "cover_date": "2021-11-16",
        "Abstract": "This study presents a novel workflow to define how resilient communities can be analysed and improved through the optimisation of sustainable design principles through quantitative methods. Our model analyses successful sustainable communities extracting information about daily routines (commuting, working, use of buildings etc.). From these routines, we infer a set of key successful aspects based on location, density and proximity. We then model a resilient community and analyse it using a combination of clustering techniques to find patterns and correlations in the success of existing communities. The proposed workflow is applied to the city of Copenhagen as a case study. The aim of the proposed model is to suggest to designers and city-level policy makers improvements (with manipulation of variables like density, proximity and location of urban typologies) to help them to achieve different levels of sustainable goals as set out by the United Nations Global Challenges including integration inclusiveness and resilience. By using a clustering technique, patterns of proximity have been identified along with density and initial correlations in the observed urban typologies. Some of these correlations were used to illustrate the potential of this novel workflow.",
        "DOI": "10.3389/fbuil.2021.767779",
        "affiliation_name": "University of Hertfordshire",
        "affiliation_city": "Hatfield",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Machine Learning Approach for the Prediction of Consumer Food Price Index",
        "paper_author": "Sarangi P.K.",
        "publication": "2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions), ICRITO 2021",
        "citied_by": "4",
        "cover_date": "2021-11-15",
        "Abstract": "The price of food and food related items are dynamic. A measure change in the price affects the buying behaviour of the consumer and monetary policies by the Government. The Consumer Food Price Index (CFPI) reflects the variations in food prices during a certain period. In India, the CFPI is released monthly by the Central Statistical Organization. It also reflects the inflation and helps the Government to take corrective measures in time. In this paper we have applied the machine learning approach in forecasting the consumer food price index in India. In specific, this work has focused on the applicability of Artificial Neural Network (ANN) models with back propagation learning in predicting the future values of CFPI. The monthly data for rural, urban and combined from the period 2013 to 2021 have been used to train and validate the models. The Mean Absolute Percentage Error (MAPE) values have been used to validate the accuracy of the models. The experimental results show that a simple ANN model with back propagation algorithm is highly capable in forecasting the future values of CFPI.",
        "DOI": "10.1109/ICRITO51393.2021.9596527",
        "affiliation_name": "Chitkara University, Punjab",
        "affiliation_city": "Rajpura",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Blockchain and Machine Learning based Framework for Efficient Health Insurance Management",
        "paper_author": "Goyal A.",
        "publication": "SenSys 2021 - Proceedings of the 2021 19th ACM Conference on Embedded Networked Sensor Systems",
        "citied_by": "11",
        "cover_date": "2021-11-15",
        "Abstract": "Having a health insurance is important for everybody, bearing in mind the increasing medical costs. Medical emergencies can have a severe financial and emotional impact. However, the current insurance system is very expensive and the claim settlement process is excessively lengthy, making it tedious. This results in policyholders not being able to successfully make a claim with their insurance company. In this paper, we focus on developing a fast and cost-effective framework based on blockchain technology and machine learning for the health insurance industry. Blockchain is capable of removing all third-party organisations by forming a smart contract, making the entire process more smooth, secure, and efficient. The contract settles the claim on documents submitted by the claimant. A ridge regression model is used for computing the premiums optimally, based on the total amount claimed under the current policy tenure, along with several other factors. A random forest classifier is applied for predicting the risk that helps in the computation of risk-rated premium rebate.",
        "DOI": "10.1145/3485730.3493685",
        "affiliation_name": "Jaypee Institute of Information Technology",
        "affiliation_city": "Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Application of machine learning in determination of the permissible level of traction current asymmetry",
        "paper_author": "Isaicheva A.G.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "5",
        "cover_date": "2021-11-15",
        "Abstract": "Approaches to solving the problem of determination of the permissible level of traction current asymmetry in railway transport that is required for the transition from service according to the standard value to the actual service are reviewed in the article. The presented solutions, which are based on the machine learning method, comply with the policy of the Russian Railways company in the field of transformation of the railway automation and telemechanics economy. Methods for collection of information from devices subject to the influence of traction current asymmetry are proposed to solve the problem. Method for calculation of the traction current asymmetry coefficient based on machine learning methods is selected and justified. The Lasso method is used as a machine learning method for solving the regression problem. This method allows to predict the required value with high accuracy, including cases of work with big data.",
        "DOI": "10.1063/5.0071644",
        "affiliation_name": "Samara State University of Railway Transport",
        "affiliation_city": "Samara",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "TLDR: Deep Learning-Based Automated Privacy Policy Annotation with Key Policy Highlights",
        "paper_author": "Alabduljabbar A.",
        "publication": "WPES 2021 - Proceedings of the 20th Workshop on Privacy in the Electronic Society, co-located with CCS 2021",
        "citied_by": "17",
        "cover_date": "2021-11-15",
        "Abstract": "Privacy policies are the primary channel where service providers inform users about their data collection and use practices. However, privacy policies are often long and lack any specific structure. The average user struggles to understand their contents and usually skips them, regardless of their importance. Moreover, privacy policies may lack information on critical practices used by the service providers, such as data collection, use disclosure, tracking, and access. We tackle these challenges by introducing TLDR, a machine learning-based automated ensemble of privacy policy classifiers, for (i) categorizing the content into nine privacy policy categories with high performance and (ii) detecting missing information in the privacy policies. Towards addressing the length of the privacy policies, TLDR labels each paragraph in a policy by its content class, which enables users to focus on paragraphs of interest, such as paragraphs with information regarding data collection or tracking practices used by the service operators. TLDR reduces the average reading time by 39.14% by reducing the presented information to users. This process results in an increased understanding of the privacy policies by 18.84%. TLDR reduces the number of paragraphs and words required to be read by the user. This, in turn, reduces the required efforts to understand the service operator's practices.",
        "DOI": "10.1145/3463676.3485608",
        "affiliation_name": "University of Central Florida",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "First mode damping ratio oriented optimal design procedure for damped outrigger systems with additional linear viscous dampers",
        "paper_author": "Asai T.",
        "publication": "Engineering Structures",
        "citied_by": "14",
        "cover_date": "2021-11-15",
        "Abstract": "The damped outrigger system is in widespread use as a damping modification system for tall buildings that provides high additional damping in addition to the bending back effect against the core. However, while the enhanced seismic performance of damped outrigger systems was confirmed in previous studies all over the world, a general-purpose optimal design method focusing on modal damping ratios has not been established yet. This paper proposes an optimal damper design kit composed of a first mode damping ratio oriented design policy, simple equations of optimal damper-connection stiffness ratio to maximize first mode damping ratio, a machine learning model to estimate first mode natural period and damping ratio. The tenability of the first mode damping ratio-oriented design policy was confirmed by performing complex modal analyses on single to quad damped outrigger systems incorporating linear viscous dampers and assigning realistic stiffness values to the outrigger trusses. The simple design equations of optimal damper-connection stiffness ratio and the machine learning model for first mode characteristics were developed based on a large number of analytical results. The proposed optimal design kit has been made available as a web application-based design tool.",
        "DOI": "10.1016/j.engstruct.2021.113229",
        "affiliation_name": "Institute of Science Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Forecasting seasonal electricity generation in European countries under Covid-19-induced lockdown using fractional grey prediction models and machine learning methods",
        "paper_author": "Şahin U.",
        "publication": "Applied Energy",
        "citied_by": "62",
        "cover_date": "2021-11-15",
        "Abstract": "Balances in the energy sector have changed since the implementation of the Covid-19 pandemic lockdown in Europe. This paper analyses how the lockdown affected electricity generation in European countries and how it will reshape future energy generation. Monthly electricity generation from total renewables and non-renewables in France, Germany, Spain, Turkey, and the UK from January 2017 to September 2020 were evaluated and compared. Four seasonal grey prediction models and three machine learning methods were used for forecasting; the quarterly results are presented to the end of 2021. Additionally, the share of electricity generation from renewables in total electricity generation from 2017 to 2021 for the selected countries was compared. Electricity generation from total non-renewables in the second quarter of 2020 for France, Germany, Spain, and the UK decreased by 21%–25% compared to the same period of 2019; the decline in Turkey was approximately 11%. Additionally, electricity generation from non-renewables in the third quarter of 2020 for all countries, except Turkey, decreased compared to the same period of the previous year. All grey prediction models and support vector machine method forecast that the share of renewables in total electricity generation will increase continuously in France, Germany, Spain, and the UK to the end of 2021. The forecasting methods provided by this study open new avenues for research on the impact of the Covid-19 pandemic on the future of the energy sector.",
        "DOI": "10.1016/j.apenergy.2021.117540",
        "affiliation_name": "Hebei University of Engineering",
        "affiliation_city": "Handan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The effect of green energy, global environmental indexes, and stock markets in predicting oil price crashes: Evidence from explainable machine learning",
        "paper_author": "Ben Jabeur S.",
        "publication": "Journal of Environmental Management",
        "citied_by": "87",
        "cover_date": "2021-11-15",
        "Abstract": "This study aims to predict oil prices during the 2019 novel coronavirus (COVID-19) pandemic by looking into green energy resources, global environmental indexes (ESG), and stock markets. The study employs advanced machine learning, such as the LightGBM, CatBoost, XGBoost, Random Forest (RF), and neural network models. An accurate forecasting framework can effectively capture the trend of the changes in oil prices and reduce the impact of the COVID-19 pandemic on such prices. Additionally, a large dataset with different asset classes was used to investigate the crash period. The research also introduced SHapely Additive exPlanations (SHAP) values for model analysis and interpretability. The empirical results indicate the superiority of the RF and LightGBM over traditional models. Moreover, this new framework provides favorable explanations of the model performance using the efficient SHAP algorithm. It also highlights the core features of predicting oil prices. The study found that high values of GER and ESG lead to lower crude oil prices. Our results are crucial for investors and policymakers in promoting climate change mitigation and sustained economic prosperity through green energy resources.",
        "DOI": "10.1016/j.jenvman.2021.113511",
        "affiliation_name": "ESDES Business School",
        "affiliation_city": "Lyon",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Ambient air pollution and meteorological factors escalate electricity consumption",
        "paper_author": "Sarkodie S.A.",
        "publication": "Science of the Total Environment",
        "citied_by": "24",
        "cover_date": "2021-11-15",
        "Abstract": "The impact of climate change is evident in the variability of weather patterns, hence, affecting electricity generation and consumption. Existing literature examines the effect of humidity and temperature on energy, but suffers from omitted variable bias. Here, we adopt several parameters namely ambient air pollution, precipitation, surface pressure, dew-frost point, relative humidity, wind speed, earth skin temperature, cooling degree days, heating degree days, solar and wind generation, cumulative installed PV power, and wind turbine capacity, solar and wind electricity consumption, and energy price index to investigate the role of climatic and energy-related factors on households, industry sector, commercial and public service attributed electricity consumption in Norway. Our machine learning estimator accounts for climate change heterogeneity, and historical effects while controlling omitted-variable and misspecification bias. The empirical assessment shows the radiative forcing effect of ambient air pollution decreases electricity consumption. In contrast, the scavenging effect of rainfall intensity on ambient air pollution improves both wind and solar electricity consumption. Rising levels of earth skin temperature, and humidity increases solar and wind electricity consumption whereas dew-frost point drops temperature, and humidity to improve human comfort. Our study highlights that energy price index is critical to the adoption of solar and wind energy technologies.",
        "DOI": "10.1016/j.scitotenv.2021.148841",
        "affiliation_name": "Nord Universitet",
        "affiliation_city": "Bodo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Dynamic energy dispatch strategy for integrated energy system based on improved deep reinforcement learning",
        "paper_author": "Yang T.",
        "publication": "Energy",
        "citied_by": "144",
        "cover_date": "2021-11-15",
        "Abstract": "Dynamic energy dispatch is an integral part of the operation optimization of integrated energy systems (IESs). Most existing dynamic dispatch schemes depend heavily on explicit forecast or mathematical models of the future uncertainties. Due to the randomness of renewable energy generation and energy demands, these approaches are limited by the accuracy of forecasting or model. A novel model-free dynamic dispatch strategy for IES based on improved deep reinforcement learning (DRL) is proposed to solve the problem. The IES dynamic dispatch problem is formulated as a Markov decision process (MDP), in which the uncertainties of renewable generation, electric load and heat load are considered. For solving the MDP, an improved deep deterministic policy gradient (DDPG) algorithm using prioritized experience replay mechanism and L2 regularization is developed, so as to improve the policy quality and learning efficiency of the dispatch strategy. The proposed approach does not require any forecast information or distribution knowledge, and can adaptively respond to the stochastic fluctuations of the supply and demands. Simulation results show the proposed dispatch strategy has faster convergence and lower operating costs than original DDPG-based strategy. In addition, the advantages of the proposed approach in terms of cost-effectiveness and stochastic environmental adaptation are validated.",
        "DOI": "10.1016/j.energy.2021.121377",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Clairvoyant prefetching for distributed machine learning i/o",
        "paper_author": "Dryden N.",
        "publication": "International Conference for High Performance Computing, Networking, Storage and Analysis, SC",
        "citied_by": "41",
        "cover_date": "2021-11-14",
        "Abstract": "I/O is emerging as a major bottleneck for machine learning training, especially in distributed environments. Indeed, at large scale, I/O takes as much as 85% of training time. Addressing this I/O bottleneck necessitates careful optimization, as optimal data ingestion pipelines differ between systems, and require a delicate balance between access to local storage, external filesystems, and remote nodes. We introduce NoPFS, a machine learning I/O middleware, which provides a scalable, flexible, and easy-To-use solution to the I/O bottleneck. NoPFS uses clairvoyance: Given the seed generating the random access pattern for training with SGD, it can exactly predict when and where a sample will be accessed. We combine this with an analysis of access patterns and a performance model to provide distributed caching policies that adapt to different datasets and storage hierarchies. NoPFS reduces I/O times and improves endto-end training by up to 5.4× on the ImageNet-1k, ImageNet-22k, and CosmoFlow datasets.",
        "DOI": "10.1145/3458817.3476181",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "City vertical gardening: An ecological approach to urban planning linkages between machine learning, biometric data, climate control, and urban health",
        "paper_author": "Geropanta V.",
        "publication": "Smart Cities and Machine Learning in Urban Health",
        "citied_by": "2",
        "cover_date": "2021-11-12",
        "Abstract": "The countermeasures taken during the COVID-19 pandemic opened discussions regarding their status as temporal or ephemeral as they designated the positive environmental effects of the COVID-19 anthropause. The necessity to think about city transformation in times of environmental and health crises has revealed a number of digital tools and greening practices that might shape new policy and planning models to affront global challenges. Among these tools, a number of 'urban acupuncture' activities have revealed the role of greening and gardening in urban spaces and how they assist in tackling challenges of environmental sustainability and city resilience. The authors investigate the contribution of vertical gardening (VG) as urban health enhancer and its prospects within smart city. They select and assess two case studies that integrate synergies between VG and machine learning (ML) approaches in an effort to showcase the tools' combined effect in realizing environmental control. These experiments imply hints for potential future research and implementation to broaden environments.",
        "DOI": "10.4018/978-1-7998-7176-7.ch002",
        "affiliation_name": "Technical University of Crete",
        "affiliation_city": "Chania",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Methodologies to associate COVID-19 spreading data to space and scale: A report on the first outbreak",
        "paper_author": "Margiori L.I.",
        "publication": "Smart Cities and Machine Learning in Urban Health",
        "citied_by": "0",
        "cover_date": "2021-11-12",
        "Abstract": "Since the onset of the COVID-19 pandemic, the correlation between the spread of the SARS-Cov-2 virus and a number of epidemiological parameters has been a key tool for understanding the dynamics of its flow. This information has assisted local authorities in making policy decisions for the containment of its expansion. Several methods have been used including topographical data, artificial intelligence and machine learning data, and epidemiological tools to analyze factors facilitating the spread of epidemic at a local and global scale. The aim of this study is to use a new tool to assess and categorize the incoming epidemiological data regarding the spread of the disease as per population densities, spatial and topographical morphologies, social and financial activities, population densities and mobility between regions. These data will be appraised as risk factors in the spread of the disease on a local and a global scale.",
        "DOI": "10.4018/978-1-7998-7176-7.ch006",
        "affiliation_name": "Technical University of Crete",
        "affiliation_city": "Chania",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "COVID-19 Vaccine Distribution Policy Design with Reinforcement Learning",
        "paper_author": "Tan P.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-11-12",
        "Abstract": "COVID-19 has become a global crisis and the vaccine has been seen as an effective approach to stop the epidemic spread. However, the resources for distributing and allocating different types of vaccines are limited and we need a better vaccine distribution policy design to prevent the spread of COVID-19 more efficiently. In this study, a pipeline of combing a random forest model and a DQN model is proposed. The random forest model is built to predict the daily new confirmed cases with the vaccine data as the inputs. And the DQN model is built to design the daily allocation ratio of three types of vaccines, with the aim to minimize the new confirmed cases. The experimental results based on the real-world datasets collected in San Diego validate the effectiveness of the proposed pipeline.",
        "DOI": "10.1145/3502827.3502844",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Energy sobriety: A behaviour measurement indicator for fuel poverty using aggregated load readings from smart meters",
        "paper_author": "Fergus P.",
        "publication": "Towards Energy Smart Homes: Algorithms, Technologies, and Applications",
        "citied_by": "3",
        "cover_date": "2021-11-11",
        "Abstract": "Fuel poverty affects between 50 and 125 million households in Europe and is a significant issue for both developed and developing countries globally. This means that fuel-poor residents are unable to adequately warm their home and run the necessary energy services needed for lighting, cooking, hot water, and electrical appliances. The problem is complex but is typically caused by three factors: low income, high energy costs, and energy-inefficient homes. In the United Kingdom (UK), four million families are currently living in fuel poverty. Those in series financial difficulty are either forced to self-disconnect or have their services terminated by energy providers. Fuel poverty contributed to 10,000 reported deaths in England in the winter of 2016-2107 due to homes being cold. While it is recognized by governments as a social, public health, and environmental policy issue, the European Union (EU) has failed to provide a common definition of fuel poverty or a conventional set of indicators to measure it. This chapter discusses current fuel poverty strategies across the EU and proposes a new and foundational behaviour measurement indicator designed to directly assess and monitor fuel poverty risks in households using smart meters, Consumer Access Device (CAD) data, and machine learning. By detecting Activities of Daily Living (ADLS) through household appliance usage, it is possible to spot the early signs of financial difficulty and identify when support packages are required.",
        "DOI": "10.1007/978-3-030-76477-7_2",
        "affiliation_name": "Liverpool John Moores University",
        "affiliation_city": "Liverpool",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Research on low-carbon campus based on ecological footprint evaluation and machine learning: A case study in China",
        "paper_author": "Zheng N.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "21",
        "cover_date": "2021-11-10",
        "Abstract": "Universities, the important locations for scientific research and education, have the responsibility to lead ecological civilization and low carbon transition. Ecological footprint evaluation (EFE) is usually used to measure sustainability of campuses. Although it can provide guidance and reference for overall campus planning, it lacks effective significance for individual behavior, especially when the reduction of carbon emissions is the aim. On the other hand a possible solution can be represented by machine learning. It can identify the key factors that will influence individual's overall carbon emissions caused by students' daily behavior, it can be used to find effective ways to reduce individual carbon emissions. This paper applied EFE and machine learning to comprehensively evaluate campus sustainability and students' carbon emissions. Huazhong University of Science and Technology (HUST), a “University in the Forest”, was used as a study case in China. Even if HUST is endowned with a forest coverage of 72%, here we showed that its Ecological Footprint Index was −12.52, indicating strong unsustainability. This is mainly due to the high energy and food consumption, caused by the large population living in the campus and the lacking of energy saving measures. The per capita ecological footprint was relatively high, compared with other universities in the world, which meant more efforts needed to be done on ecological sustainability. Low carbon emission is a key feature for a sustainable campus. Based on the questionnaire survey delivered to 486 students who live in the campus, their daily active data were collected in terms of students' personal clothing, food, housing, consumption and transportation. And their associated carbon emissions were calculated based on emission intensities of Chinese population. Based on 486 detailed datasets, machine learning was then used to identify the key daily behavior to influence students' total carbon emission. Results showed that making behavior changes in air conditioning, food and electric bicycle were the most effective ways to reduce carbon emissions. Finally, while effective suggestions were proposed based on qualitative and quantitative evaluations, it is concluded that it is imperative for universities in China to formulate effective low-carbon policies, to achieve sustainable development and to confront global climate change.",
        "DOI": "10.1016/j.jclepro.2021.129181",
        "affiliation_name": "Harvard John A. Paulson School of Engineering and Applied Sciences",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Predictive Authorization Approach for IoT Environments",
        "paper_author": "Blower A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2021-11-08",
        "Abstract": "The Internet of Things is increasingly finding application in sensitive and critical domains such as healthcare and safety-critical systems. However, without effective authorization mechanisms, sensitive resources could be accessed by unintended subjects and used maliciously. Current authorization mechanisms are unsuitable for the dynamic and constantly evolving resource-constrained environments that IoT systems operate in. This paper describes RECON, an IoT Edge authorization mechanism based on Microservices that enforces attribute-based access control models. RECON predicts future attribute values to provide reliable policy evaluations that are resilient to failure of attribute sources. Lastly, a RECON based case study is presented, that validates the RECON method.",
        "DOI": "10.1145/3494322.3494333",
        "affiliation_name": "School of Computing and Communications, Lancaster University",
        "affiliation_city": "Lancaster",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Understanding, Explanation, and Active Inference",
        "paper_author": "Parr T.",
        "publication": "Frontiers in Systems Neuroscience",
        "citied_by": "15",
        "cover_date": "2021-11-05",
        "Abstract": "While machine learning techniques have been transformative in solving a range of problems, an important challenge is to understand why they arrive at the decisions they output. Some have argued that this necessitates augmenting machine intelligence with understanding such that, when queried, a machine is able to explain its behaviour (i.e., explainable AI). In this article, we address the issue of machine understanding from the perspective of active inference. This paradigm enables decision making based upon a model of how data are generated. The generative model contains those variables required to explain sensory data, and its inversion may be seen as an attempt to explain the causes of these data. Here we are interested in explanations of one’s own actions. This implies a deep generative model that includes a model of the world, used to infer policies, and a higher-level model that attempts to predict which policies will be selected based upon a space of hypothetical (i.e., counterfactual) explanations—and which can subsequently be used to provide (retrospective) explanations about the policies pursued. We illustrate the construct validity of this notion of understanding in relation to human understanding by highlighting the similarities in computational architecture and the consequences of its dysfunction.",
        "DOI": "10.3389/fnsys.2021.772641",
        "affiliation_name": "UCL Queen Square Institute of Neurology",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Fueling their own climate narrative ; Using techniques from big data to decode Big Oil's climate change propaganda",
        "paper_author": "Supran G.",
        "publication": "Science",
        "citied_by": "8",
        "cover_date": "2021-11-05",
        "Abstract": "NA",
        "DOI": "10.1126/science.abm3434",
        "affiliation_name": "Harvard University",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Virtual infection prevention - The next frontier",
        "paper_author": "Pryor R.J.",
        "publication": "Infection Control and Hospital Epidemiology",
        "citied_by": "6",
        "cover_date": "2021-11-05",
        "Abstract": "The coronavirus disease 2019 (COVID-19) pandemic has resulted in the acceleration of telehealth and remote environments as stakeholders and healthcare systems respond to the threat of this disease. How can infectious diseases and healthcare epidemiology expertise be adapted to support safe care for all?",
        "DOI": "10.1017/ice.2020.1404",
        "affiliation_name": "Duke University School of Medicine",
        "affiliation_city": "Durham",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Efficient and targeted COVID-19 border testing via reinforcement learning",
        "paper_author": "Bastani H.",
        "publication": "Nature",
        "citied_by": "58",
        "cover_date": "2021-11-04",
        "Abstract": "Throughout the coronavirus disease 2019 (COVID-19) pandemic, countries have relied on a variety of ad hoc border control protocols to allow for non-essential travel while safeguarding public health, from quarantining all travellers to restricting entry from select nations on the basis of population-level epidemiological metrics such as cases, deaths or testing positivity rates1,2. Here we report the design and performance of a reinforcement learning system, nicknamed Eva. In the summer of 2020, Eva was deployed across all Greek borders to limit the influx of asymptomatic travellers infected with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), and to inform border policies through real-time estimates of COVID-19 prevalence. In contrast to country-wide protocols, Eva allocated Greece’s limited testing resources on the basis of incoming travellers’ demographic information and testing results from previous travellers. By comparing Eva’s performance against modelled counterfactual scenarios, we show that Eva identified 1.85 times as many asymptomatic, infected travellers as random surveillance testing, with up to 2–4 times as many during peak travel, and 1.25–1.45 times as many asymptomatic, infected travellers as testing policies that utilize only epidemiological metrics. We demonstrate that this latter benefit arises, at least partially, because population-level epidemiological metrics had limited predictive value for the actual prevalence of SARS-CoV-2 among asymptomatic travellers and exhibited strong country-specific idiosyncrasies in the summer of 2020. Our results raise serious concerns on the effectiveness of country-agnostic internationally proposed border control policies3 that are based on population-level epidemiological metrics. Instead, our work represents a successful example of the potential of reinforcement learning and real-time data for safeguarding public health.",
        "DOI": "10.1038/s41586-021-04014-z",
        "affiliation_name": "USC Marshall School of Business",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Active learning for imbalanced data under cold start",
        "paper_author": "Barata R.",
        "publication": "ICAIF 2021 - 2nd ACM International Conference on AI in Finance",
        "citied_by": "7",
        "cover_date": "2021-11-03",
        "Abstract": "Modern systems that rely on Machine Learning (ML) for predictive modelling, may suffer from the cold-start problem: supervised models work well but, initially, there are no labels, which are costly or slow to obtain. This problem is even worse in imbalanced data scenarios, where labels of the positive class take longer to accumulate. We propose an Active Learning (AL) system for datasets with orders of magnitude of class imbalance, in a cold start streaming scenario. We present a computationally efficient Outlier-based Discriminative AL approach (ODAL) and design a novel 3-stage sequence of AL labeling policies where ODAL is used as warm-up. Then, we perform empirical studies in four real world datasets, with various magnitudes of class imbalance. The results show that our method can more quickly reach a high performance model than standard AL policies without ODAL warm-up. Its observed gains over random sampling can reach 80% and be competitive with policies with an unlimited annotation budget or additional historical data (using just 2% to 10% of the labels).",
        "DOI": "10.1145/3490354.3494423",
        "affiliation_name": "Feedzai",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Over-Time Trends in Incivility on Social Media: Evidence From Political, Non-Political, and Mixed Sub-Reddits Over Eleven Years",
        "paper_author": "Sun Q.",
        "publication": "Frontiers in Political Science",
        "citied_by": "16",
        "cover_date": "2021-11-02",
        "Abstract": "Incivility in social media has become a major concern of the public, who perceive uncivil online interactions to be both widespread and increasing. This study provides a descriptive account of incivility dynamics over the past 11 years by examining the trends of incivility in three main categories of social media interactions: political, mixed, and non-political. Using longitudinal data from Reddit that accounts for 95% of the entire Reddit universe across 11 years and relying on the combination of supervised machine learning models and traditional statistical inference, the study found that incivility consistently represents around 10% of total Reddit comments. Additionally, political groups tend to be more uncivil, and discussions in mixed groups that are not overtly political but nevertheless discuss politics are less uncivil than in political groups. We also found that the fluctuations of incivility correspond to offline events and platform-specific policies.",
        "DOI": "10.3389/fpos.2021.741605",
        "affiliation_name": "University of California, Davis",
        "affiliation_city": "Davis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting urban flooding susceptibility of public transit systems using machine learning approaches: A case study of the largest city in Canada",
        "paper_author": "Ahmed N.",
        "publication": "Proceedings of the 4th ACM SIGSPATIAL International Workshop on Advances in Resilient and Intelligent Cities, ARIC 2021",
        "citied_by": "1",
        "cover_date": "2021-11-02",
        "Abstract": "Urban floods often cause the functional disruption of public transit systems, thereby impeding people's mobility and resulting in adverse socio-economic consequences. Climate change, rapid urbanization, and unplanned disaster management further increase trends of urban floods with higher frequency and intensity. This study employs data-driven machine learning (ML) models for predicting the flooding susceptibility of public transit systems in Toronto, ON, Canada. Four ML approaches are employed to evaluate the future risks of public transit systems being inundated by flooding events: 1) Random Forest (RF); 2) eXtreme Gradient Boosting (XGBoost); 3) K Nearest Neighbor (KNN); and 4) Naïve Bayes (NB). We estimate flooding probability based on the relationship between flood inundation events and their contributing factors. Flood-plain maps by Toronto and Region Conservation Authority (TRCA) are used to generate flood and non-flood locations as a basis for training (70% of samples) and validating (30% of samples) ML models. We use the Area-Under Receiver Operating Characteristic (AUROC) curve to evaluate the prediction results of ML models. All four models show a high level of accuracy higher than 95%. Our results demonstrate public transit systems near major river channels are highly susceptible to floods which corroborated with historical flooding incidents in 2013 and 2018. The outcome of the study can be helpful to enhance the resilience of public transit systems in the city of Toronto and can facilitate evidence-based planning and policy to make cities more sustainable, livable, and resilient against flood hazards.",
        "DOI": "10.1145/3486626.3493438",
        "affiliation_name": "Western University",
        "affiliation_city": "London",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Dual-Attention Multi-Scale Graph Convolutional Networks for Highway Accident Delay Time Prediction",
        "paper_author": "Wu I.Y.",
        "publication": "GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems",
        "citied_by": "0",
        "cover_date": "2021-11-02",
        "Abstract": "Traffic-related forecasting plays a critical role in determining transportation policy, unlike traditional approaches, which can only make decisions based on statistical results or historical experience. Through machine learning, we are able to capture the potential interactions between urban dynamics and find their mutual interactions in a spatial context. However, despite a plethora of traffic-related studies, few works have explored predicting the impact of congestion. Therefore, this paper focuses on predicting how a car accident leads to traffic congestion, especially the length of time it takes for the congestion to occur. Accordingly, we propose a novel model named Dual-Attention Multi-Scale Graph Convolutional Networks (DAMGNet) to address this issue. In this proposed model, heterogeneous data such as accident information, urban dynamics, and various highway network characteristics are considered and combined. Next, the context encoder encodes the accident data, and the spatial encoder captures the hidden features between multi-scale Graph Convolutional Networks (GCNs). With our designed dual attention mechanism, the DAMGNet model is able to effectively learn the correlation between features. The evaluations conducted on a real-world dataset prove that our DAMGNet has a significant improvement in RMSE and MAE over other comparative methods.",
        "DOI": "10.1145/3474717.3484259",
        "affiliation_name": "National Cheng Kung University",
        "affiliation_city": "Tainan",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Predicting patient-level new-onset atrial fibrillation from population-based nationwide electronic health records: Protocol of FIND-AF for developing a precision medicine prediction model using artificial intelligence",
        "paper_author": "Nadarajah R.",
        "publication": "BMJ Open",
        "citied_by": "16",
        "cover_date": "2021-11-02",
        "Abstract": "Introduction Atrial fibrillation (AF) is a major cardiovascular health problem: it is common, chronic and incurs substantial healthcare expenditure because of stroke. Oral anticoagulation reduces the risk of thromboembolic stroke in those at higher risk; but for a number of patients, stroke is the first manifestation of undetected AF. There is a rationale for the early diagnosis of AF, before the first complication occurs, but population-based screening is not recommended. Previous prediction models have been limited by their data sources and methodologies. An accurate model that uses existing routinely collected data is needed to inform clinicians of patient-level risk of AF, inform national screening policy and highlight predictors that may be amenable to primary prevention. Methods and analysis We will investigate the application of a range of deep learning techniques, including an adapted convolutional neural network, recurrent neural network and Transformer, on routinely collected primary care data to create a personalised model predicting the risk of new-onset AF over a range of time periods. The Clinical Practice Research Datalink (CPRD)-GOLD dataset will be used for derivation, and the CPRD-AURUM dataset will be used for external geographical validation. Both comprise a sizeable representative population and are linked at patient-level to secondary care databases. The performance of the deep learning models will be compared against classic machine learning and traditional statistical predictive modelling methods. We will only use risk factors accessible in primary care and endow the model with the ability to update risk prediction as it is presented with new data, to make the model more useful in clinical practice. Ethics and dissemination Permissions for CPRD-GOLD and CPRD-AURUM datasets were obtained from CPRD (ref no: 19_076). The CPRD ethical approval committee approved the study. The results will be submitted as a research paper for publication to a peer-reviewed journal and presented at peer-reviewed conferences. Trial registration details A systematic review to incorporate within the overall project was registered on PROSPERO (registration number CRD42021245093). The study was registered on ClinicalTrials.gov (NCT04657900).",
        "DOI": "10.1136/bmjopen-2021-052887",
        "affiliation_name": "Faculty of Medicine and Health",
        "affiliation_city": "Leeds",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Artificial intelligence and its contribution to overcome COVID‑19",
        "paper_author": "Chockalingam A.",
        "publication": "International Journal of Noncommunicable Diseases",
        "citied_by": "0",
        "cover_date": "2021-11-01",
        "Abstract": "Artificial intelligence (AI) has a great impact on our daily living and makes our lives more efficient and productive. Especially during the coronavirus disease (COVID‑19) pandemic, AI has played a key role in response to the global health crisis. There has been a boom in AI innovation and its use since the pandemic. However, despite its widespread adoption and great potential, most people have little knowledge of AI concepts and realization of its potential. The objective of this white paper is to communicate the importance of AI and its benefits to society. The report covers AI applications in six different topics from medicine (AI deployment in clinical settings, imaging and diagnostics, and acceleration of drug discovery) to more social aspects (support older adults in long‑term care homes, and AI in supporting small and medium enterprises. The report ends with nine steps to consider for moving forward with AI implementation during and post pandemic period. These include legal and ethical data collection and storage, greater data access, multidisciplinary collaboration, and policy reform.",
        "DOI": "10.4103/2468-8827.330646",
        "affiliation_name": "KITE Research Institute",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Synthetic Longitudinal Education Database: Linking National Datasets for K-16 Education and College Readiness",
        "paper_author": "Lee J.",
        "publication": "International Journal of Educational Methodology",
        "citied_by": "1",
        "cover_date": "2021-11-01",
        "Abstract": "What are missing in the U.S. education policy of “college for all” are supporting data and indicators on K-16 education pathways, i.e, how well all students get ready and stay on track from kindergarten through college. This study creates synthetic national longitudinal education database that helps track and support students’ educational pathways by combining two nationally-representative U.S. sample datasets: Early Childhood Longitudinal Study- Kindergarten (ECLS-K; Kindergarten through 8th grade) and National Education Longitudinal Study (NELS; 8th grade through age 25). The merge of these national datasets, linked together via statistical matching and imputation techniques, can help bridge the gap between elementary and secondary/postsecondary education data/research silos. Using this synthetic K-16 education longitudinal database, this study applies machine learning data analytics in search of college readiness early indicators among kindergarten students. It shows the utilities and limitations of linking preexisting national datasets to impute education pathways and assess college readiness. It discusses implications for developing more holistic and equitable educational assessment system in support of K-16 education longitudinal database.",
        "DOI": "10.12973/ijem.7.4.683",
        "affiliation_name": "University at Buffalo, The State University of New York",
        "affiliation_city": "Buffalo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances of machine learning in clean energy and the transportation industry",
        "paper_author": "Vasant P.",
        "publication": "Advances of Machine Learning in Clean Energy and the Transportation Industry",
        "citied_by": "3",
        "cover_date": "2021-11-01",
        "Abstract": "This book presents the latest research in the field of machine learning, discussing the real-world application problems associated with new innovative renewable energy methodologies as well as cutting edge technologies in the transport industry. The requirements and demands of problem solving have been increasing exponentially, and new artificial intelligence and machine learning technologies have reduced the scope of data coverage worldwide. Recent advances in data technology (DT) have contributed to reducing the gaps in the coverage of domains around the globe. Attention to clean energy in recent decades has been growing exponentially. This is mainly due to a decrease in the cost of both installed capacity of converters and a decrease in the cost of generated energy. Such successes were achieved thanks to the improvement of modern technologies for the production of converters, an increase in the efficiency of using incoming energy, optimization of the operation of converters and analysis of data obtained during the operation of systems with the possibility of planning production. The use of clean energy plays an important role in the transportation industry, where technologies are also being improved from year to year - the transportation industry is growing, and machinery and systems are becoming more autonomous and robotic, where it is no longer possible to do without complex intelligent computing, machine learning optimization, planning and working with large amounts of data. The book is a valuable reference work for researchers in the fields of renewable energy, computer science and engineering with a particular focus on machine learning and intelligent optimization as well as for postgraduates, managers, economists and decision makers, policy makers, government officials, industrialists and practicing scientists and engineers as well compassionate global decision makers. Topics include: Machine learning, Quantum Optimization, Modern Technology in Transport Industry, Innovative Technologies in Transport Education, Systems Based on Renewable Energy Conversion, Business Process Models and Applications in Renewable Energy, Clean Energy, and Climate Change.",
        "DOI": "10.52305/SJDR3905",
        "affiliation_name": "Federal Scientific Agroengineering Center VIM",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "PIKS: A Technique to Identify Actionable Trends for Policy-Makers Through Open Healthcare Data",
        "paper_author": "Rao A.R.",
        "publication": "SN Computer Science",
        "citied_by": "6",
        "cover_date": "2021-11-01",
        "Abstract": "With calls for increasing transparency, governments are releasing greater amounts of data in multiple domains including finance, education, and healthcare. We focus on healthcare due to its economic importance worldwide. The efficient exploratory analysis of healthcare data constitutes a significant challenge. Key concerns in public health include the quick identification and analysis of trends and the detection of outliers. This allows policies to be rapidly adapted to changing circumstances. We present an efficient outlier detection technique, termed PIKS (Pruned iterative-k means searchlight), which combines an iterative k-means algorithm with a pruned searchlight based scan. We apply this technique to identify outliers in two publicly available healthcare datasets from the New York Statewide Planning and Research Cooperative System, and California’s Office of Statewide Health Planning and Development. We provide a comparison of our technique with three other existing outlier detection techniques, consisting of auto-encoders, isolation forests, and feature bagging. We identified outliers in conditions including suicide rates, immunity disorders, social admissions, cardiomyopathies, and pregnancy in the third trimester. We demonstrate that the PIKS technique produces results consistent with other techniques such as the auto-encoder. However, the auto-encoder needs to be trained, which requires several parameters to be tuned. In comparison, the PIKS technique has far fewer parameters to tune. This makes it advantageous for fast, “out-of-the-box” data exploration. The PIKS technique is scalable and can readily ingest new datasets. Hence, it can provide valuable, up-to-date insights to citizens, patients, and policy-makers. We have made our code open source, and with the availability of open data, other researchers can easily reproduce and extend our work. This will help promote a deeper understanding of healthcare policies and public health issues.",
        "DOI": "10.1007/s42979-021-00871-7",
        "affiliation_name": "Fairleigh Dickinson University",
        "affiliation_city": "Teaneck",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An advanced intelligence system in customer online shopping behavior and satisfaction analysis",
        "paper_author": "Moon N.N.",
        "publication": "Current Research in Behavioral Sciences",
        "citied_by": "22",
        "cover_date": "2021-11-01",
        "Abstract": "Online shopping or internet shopping is increasing day by day. With the advancement of modern technology, the online market is growing in a vast way. People nowadays prefer online shopping because it saves time, energy, and money. Because of the blessing of the internet that online shopping has made its debut which also affects the common citizens for online shopping. So, for the emerging growth of the online market, it is necessary to find out the behavior of online shopping and customer satisfaction. Safety, trust, product quality plays an important role in customer satisfaction. In this study, we examined customer online shopping satisfaction its impact. The quality of the product, the price of the product compared to the local market, the policy of return, timely delivery of the product are also essential elements of online shopping. By analyzing all these factors we have tried to find the customer behavior and satisfaction with online shopping. In our study, we used a machine learning method to search for the result. We used 40 thousand data to find out the accuracy of our work and to analyze customer shopping satisfaction. We use Naïve Bayes, Apiorir, Decision Tree, and Random Forest classification algorithms for this analysis. We have got our best result by using Apiorir algorithm (88% accuracy) and Naïve Bayes algorithm (87% accuracy). We have also focused on customer behavior and interest in online shopping. Our study can help to develop the business intelligence and satisfaction enhancement about E-commerce.",
        "DOI": "10.1016/j.crbeha.2021.100051",
        "affiliation_name": "Daffodil International University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Cautious Nonlinear Covariance Steering using Variational Gaussian Process Predictive Models",
        "paper_author": "Tsolovikos A.",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "1",
        "cover_date": "2021-11-01",
        "Abstract": "In this work, we consider the problem of steering the first two moments of the uncertain state of an unknown discrete-time stochastic nonlinear system to a given terminal distribution in finite time. Toward that goal, first, a non-parametric predictive model is learned from a set of available training data points using stochastic variational Gaussian process regression: a powerful and highly scalable machine learning tool for learning distributions over arbitrary nonlinear functions. Second, we formulate a tractable nonlinear covariance steering algorithm that utilizes the learned Gaussian process predictive model to compute a feedback policy that will drive the distribution of the state of the system close to the goal distribution. In a greedy approach, we linearize the Gaussian process model at each time step around the latest predicted mean and covariance, solve the linear covariance steering problem, and propagate the state statistics to the next time step using the unscented transform. This process is then repeated in a shrinking-horizon model predictive control fashion. The cautiousness of the Gaussian process predictive model, which captures both the process noise and modeling errors, is demonstrated in numerical simulations.",
        "DOI": "10.1016/j.ifacol.2021.11.153",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "With no data, there's no equity: addressing the lack of data on COVID-19 for asian american communities",
        "paper_author": "Yi S.S.",
        "publication": "eClinicalMedicine",
        "citied_by": "13",
        "cover_date": "2021-11-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.eclinm.2021.101165",
        "affiliation_name": "NYU Grossman School of Medicine",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Conversing with Humans and Objects: On Repetition and the Curative Power in Animation Making",
        "paper_author": "Budach G.",
        "publication": "Canadian Modern Language Review",
        "citied_by": "1",
        "cover_date": "2021-11-01",
        "Abstract": "This article explores what happens when humans, objects, and digital technology collaborate in creating a short stop-motion film. It investigates how animation making as a hugely repetitive mechanical process interlinks with language, communication, and learning, and how it can affect our responsiveness and readiness to communicate. The article shows how repetition can push back mental concepts and language ideologies that may hinder communication and language learning. Instead, repetitive action can create a positive affective space permitting access to hidden resources and unconscious knowing. Enabled by an affective flow emerging from all participating parts - human and hon-human - a possibly tedious exercise can be transformed into a task of freedom. Co-authors of this paper draw on autoethnographic experience, collaborative methods, and thinking with new materialist theory. Their research shows that animation making can disrupt existing educational policy and implement more equal educational practice by building on human−object assemblages and their power to stimulate more-than-human communication and learning.",
        "DOI": "10.3138/CMLR-2020-0114",
        "affiliation_name": "University of Luxembourg",
        "affiliation_city": "Esch-sur-Alzette",
        "affiliation_country": "Luxembourg"
    },
    {
        "paper_title": "Mapping the (anti-)corruption field: key topics and changing trends, 1968–2020",
        "paper_author": "Pozsgai-Alvarez J.",
        "publication": "Journal of Computational Social Science",
        "citied_by": "5",
        "cover_date": "2021-11-01",
        "Abstract": "As research on (anti-)corruption continues to accelerate, the heterogeneity of perspectives that have emerged in the field complicates the identification of key topics and trends, limiting our capacity to set meaningful research priorities, risking the waste of time and funds, and potentially broadening the gap between scholarly production and policy necessities. To help elucidate this morass, we use the Latent Dirichlet Allocation (LDA) algorithm to classify a dataset of 5417 publications listed in the Global Anticorruption Blog’s (GAB) Anticorruption Bibliography. The results allow us to recognize eight main topics in the literature, as well as their evolution over the past 2 decades in terms of relative attention (as measured by citation count) and publication rates. The topics and trends found here invite us to reflect on the current structure of the (anti-)corruption field, and to draw attention to persistent—and emerging—gaps.",
        "DOI": "10.1007/s42001-021-00110-2",
        "affiliation_name": "Universidad de Valladolid",
        "affiliation_city": "Valladolid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Application of machine learning and data visualization techniques for decision support in the insurance sector",
        "paper_author": "Rawat S.",
        "publication": "International Journal of Information Management Data Insights",
        "citied_by": "97",
        "cover_date": "2021-11-01",
        "Abstract": "The insurance industry has a giant role in the sustainable economic growth of any country. With an increase in the number of insurance buyers, it has become an absolute necessity for an insurance company to have a detailed claim analysis system in place. Claim Analysis is performed by insurance companies to distinguish between fraudulent and genuine claims. Apart from that, Claim Analysis can also be used to understand the client strata in a much better way and implement the results further during the underwriting and acceptance/denial stage of policy enrollment. The main objective of this research work is to identify meaningful and decisive factors for claim filing and acceptance in a learning context through exploratory data analysis (EDA) and feature selection techniques. Also, machine learning algorithms are applied to the datasets and are evaluated using performance metrics.",
        "DOI": "10.1016/j.jjimei.2021.100012",
        "affiliation_name": "Amity University",
        "affiliation_city": "Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Using artificial intelligence for diabetic retinopathy screening: Policy implications",
        "paper_author": "Raman R.",
        "publication": "Indian Journal of Ophthalmology",
        "citied_by": "17",
        "cover_date": "2021-11-01",
        "Abstract": "Artificial intelligence (AI) has evolved over the last few years; its use in DR screening has been demonstrated in multiple evidences across the globe. However, there are concerns right from the data acquisition, bias in data, difficulty in comparing between different algorithm, challenges in machine learning, its application in different group of population, and human barrier to AI adoption in health care. There are also legal and ethical concerns related to AI. The tension between risks and concerns on one hand versus potential and opportunity on the other have driven a need for authorities to implement policies for AI in DR screening to address these issues. The policy makers should support and facilitate research and development of AI in healthcare, but at the same time, it has to be ensured that the use of AI in healthcare aligns with recognized standards of safety, efficacy, and equity. It is essential to ensure that algorithms, datasets, and decisions are auditable and when applied to medical care (such as screening, diagnosis, or treatment) are clinically validated and explainable. Policy frameworks should require design of AI systems in health care that are informed by real-world workflow and human-centric design. Lastly, it should be ensured that healthcare AI solutions align with all relevant ethical obligations, from design to development to use and to be delivered properly in the real world.",
        "DOI": "10.4103/ijo.IJO_1420_21",
        "affiliation_name": "Sankara Nethralaya",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Energy pricing during the COVID-19 pandemic: Predictive information-based uncertainty indexes with machine learning algorithm",
        "paper_author": "Olubusoye O.E.",
        "publication": "Intelligent Systems with Applications",
        "citied_by": "19",
        "cover_date": "2021-11-01",
        "Abstract": "The study investigates the impact of uncertainties on energy pricing during the COVID-19 pandemic using five uncertainty measures that include the COVID-Induced Uncertainty (CIU), Economic Policy Uncertainty (EPU), Global Fear Index (GFI); Volatility Index (VIX), and the Misinformation Index of Uncertainty (MIU). The data, which span between 2-January, 2020 and 19-January, 2021, corresponding to the period of the COVID-19 pandemic. The study finds energy prices to respond significantly to the examined uncertainty measures, with EPU seen to affect the prices of most energy types during the pandemic. We also find predictive potentials inherent in VIX, CIU, and MIU for global energy sources.",
        "DOI": "10.1016/j.iswa.2021.200050",
        "affiliation_name": "University of Ibadan",
        "affiliation_city": "Ibadan",
        "affiliation_country": "Nigeria"
    },
    {
        "paper_title": "Global research on coronaviruses: Metadata-based analysis for public health policies",
        "paper_author": "Warin T.",
        "publication": "JMIR Medical Informatics",
        "citied_by": "0",
        "cover_date": "2021-11-01",
        "Abstract": "Background: Within the context of the COVID-19 pandemic, this paper suggests a data science strategy for analyzing global research on coronaviruses. The application of reproducible research principles founded on text-as-data information, open science, the dissemination of scientific data, and easy access to scientific production may aid public health in the fight against the virus. Objective: The primary goal of this paper was to use global research on coronaviruses to identify critical elements that can help inform public health policy decisions. We present a data science framework to assist policy makers in implementing cutting-edge data science techniques for the purpose of developing evidence-based public health policies. Methods: We used the EpiBibR (epidemiology-based bibliography for R) package to gain access to coronavirus research documents worldwide (N=121,231) and their associated metadata. To analyze these data, we first employed a theoretical framework to group the findings into three categories: conceptual, intellectual, and social. Second, we mapped the results of our analysis in these three dimensions using machine learning techniques (ie, natural language processing) and social network analysis. Results: Our findings, firstly, were methodological in nature. They demonstrated the potential for the proposed data science framework to be applied to public health policies. Additionally, our findings indicated that the United States and China were the primary contributors to global coronavirus research during the study period. They also demonstrated that India and Europe were significant contributors, albeit in a secondary position. University collaborations in this domain were strong between the United States, Canada, and the United Kingdom, confirming the country-level findings. Conclusions: Our findings argue for a data-driven approach to public health policy, particularly when efficient and relevant research is required. Text mining techniques can assist policy makers in calculating evidence-based indices and informing their decision-making process regarding specific actions necessary for effective health responses.",
        "DOI": "10.2196/31510",
        "affiliation_name": "HEC Montréal",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Application Scenarios for Artificial Intelligence in Nursing Care: Rapid Review",
        "paper_author": "Seibert K.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "82",
        "cover_date": "2021-11-01",
        "Abstract": "Background: Artificial intelligence (AI) holds the promise of supporting nurses’ clinical decision-making in complex care situations or conducting tasks that are remote from direct patient interaction, such as documentation processes. There has been an increase in the research and development of AI applications for nursing care, but there is a persistent lack of an extensive overview covering the evidence base for promising application scenarios. Objective: This study synthesizes literature on application scenarios for AI in nursing care settings as well as highlights adjacent aspects in the ethical, legal, and social discourse surrounding the application of AI in nursing care. Methods: Following a rapid review design, PubMed, CINAHL, Association for Computing Machinery Digital Library, Institute of Electrical and Electronics Engineers Xplore, Digital Bibliography & Library Project, and Association for Information Systems Library, as well as the libraries of leading AI conferences, were searched in June 2020. Publications of original quantitative and qualitative research, systematic reviews, discussion papers, and essays on the ethical, legal, and social implications published in English were included. Eligible studies were analyzed on the basis of predetermined selection criteria. Results: The titles and abstracts of 7016 publications and 704 full texts were screened, and 292 publications were included. Hospitals were the most prominent study setting, followed by independent living at home; fewer application scenarios were identified for nursing homes or home care. Most studies used machine learning algorithms, whereas expert or hybrid systems were entailed in less than every 10th publication. The application context of focusing on image and signal processing with tracking, monitoring, or the classification of activity and health followed by care coordination and communication, as well as fall detection, was the main purpose of AI applications. Few studies have reported the effects of AI applications on clinical or organizational outcomes, lacking particularly in data gathered outside laboratory conditions. In addition to technological requirements, the reporting and inclusion of certain requirements capture more overarching topics, such as data privacy, safety, and technology acceptance. Ethical, legal, and social implications reflect the discourse on technology use in health care but have mostly not been discussed in meaningful and potentially encompassing detail. Conclusions: The results highlight the potential for the application of AI systems in different nursing care settings. Considering the lack of findings on the effectiveness and application of AI systems in real-world scenarios, future research should reflect on a more nursing care–specific perspective toward objectives, outcomes, and benefits. We identify that, crucially, an advancement in technological-societal discourse that surrounds the ethical and legal implications of AI applications in nursing care is a necessary next step. Further, we outline the need for greater participation among all of the stakeholders involved.",
        "DOI": "10.2196/26522",
        "affiliation_name": "Beuth Hochschule für Technik Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Feasibility, usability, and effectiveness of a machine learning-based physical activity chatbot: Quasi-experimental study",
        "paper_author": "To Q.G.",
        "publication": "JMIR mHealth and uHealth",
        "citied_by": "32",
        "cover_date": "2021-11-01",
        "Abstract": "Background: Behavioral eHealth and mobile health interventions have been moderately successful in increasing physical activity, although opportunities for further improvement remain to be discussed. Chatbots equipped with natural language processing can interact and engage with users and help continuously monitor physical activity by using data from wearable sensors and smartphones. However, a limited number of studies have evaluated the effectiveness of chatbot interventions on physical activity. Objective: This study aims to investigate the feasibility, usability, and effectiveness of a machine learning-based physical activity chatbot. Methods: A quasi-experimental design without a control group was conducted with outcomes evaluated at baseline and 6 weeks. Participants wore a Fitbit Flex 1 (Fitbit LLC) and connected to the chatbot via the Messenger app. The chatbot provided daily updates on the physical activity level for self-monitoring, sent out daily motivational messages in relation to goal achievement, and automatically adjusted the daily goals based on physical activity levels in the last 7 days. When requested by the participants, the chatbot also provided sources of information on the benefits of physical activity, sent general motivational messages, and checked participants' activity history (ie, the step counts/min that were achieved on any day). Information about usability and acceptability was self-reported. The main outcomes were daily step counts recorded by the Fitbit and self-reported physical activity. Results: Among 116 participants, 95 (81.9%) were female, 85 (73.3%) were in a relationship, 101 (87.1%) were White, and 82 (70.7%) were full-time workers. Their average age was 49.1 (SD 9.3) years with an average BMI of 32.5 (SD 8.0) kg/m2. Most experienced technical issues were due to an unexpected change in Facebook policy (93/113, 82.3%). Most of the participants scored the usability of the chatbot (101/113, 89.4%) and the Fitbit (99/113, 87.6%) as at least “OK.” About one-third (40/113, 35.4%) would continue to use the chatbot in the future, and 53.1% (60/113) agreed that the chatbot helped them become more active. On average, 6.7 (SD 7.0) messages/week were sent to the chatbot and 5.1 (SD 7.4) min/day were spent using the chatbot. At follow-up, participants recorded more steps (increase of 627, 95% CI 219-1035 steps/day) and total physical activity (increase of 154.2 min/week; 3.58 times higher at follow-up; 95% CI 2.28-5.63). Participants were also more likely to meet the physical activity guidelines (odds ratio 6.37, 95% CI 3.31-12.27) at follow-up. Conclusions: The machine learning-based physical activity chatbot was able to significantly increase participants' physical activity and was moderately accepted by the participants. However, the Facebook policy change undermined the chatbot functionality and indicated the need to use independent platforms for chatbot deployment to ensure successful delivery of this type of intervention.",
        "DOI": "10.2196/28577",
        "affiliation_name": "CQUniversity Australia",
        "affiliation_city": "Rockhampton",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Predictive modeling of vaccination uptake in US counties: A machine learning-based approach",
        "paper_author": "Cheong Q.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "11",
        "cover_date": "2021-11-01",
        "Abstract": "Background: Although the COVID-19 pandemic has left an unprecedented impact worldwide, countries such as the United States have reported the most substantial incidence of COVID-19 cases worldwide. Within the United States, various sociodemographic factors have played a role in the creation of regional disparities. Regional disparities have resulted in the unequal spread of disease between US counties, underscoring the need for efficient and accurate predictive modeling strategies to inform public health officials and reduce the burden on health care systems. Furthermore, despite the widespread accessibility of COVID-19 vaccines across the United States, vaccination rates have become stagnant, necessitating predictive modeling to identify important factors impacting vaccination uptake. Objective: This study aims to determine the association between sociodemographic factors and vaccine uptake across counties in the United States. Methods: Sociodemographic data on fully vaccinated and unvaccinated individuals were sourced from several online databases such as the US Centers for Disease Control and Prevention and the US Census Bureau COVID-19 Site. Machine learning analysis was performed using XGBoost and sociodemographic data. Results: Our model predicted COVID-19 vaccination uptake across US counties with 62% accuracy. In addition, it identified location, education, ethnicity, income, and household access to the internet as the most critical sociodemographic features in predicting vaccination uptake in US counties. Lastly, the model produced a choropleth demonstrating areas of low and high vaccination rates, which can be used by health care authorities in future pandemics to visualize and prioritize areas of low vaccination and design targeted vaccination campaigns. Conclusions: Our study reveals that sociodemographic characteristics are predictors of vaccine uptake rates across counties in the United States and, if leveraged appropriately, can assist policy makers and public health officials to understand vaccine uptake rates and craft policies to improve them.",
        "DOI": "10.2196/33231",
        "affiliation_name": "York University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "I'm alone but not lonely. U-shaped pattern of self-perceived loneliness during the COVID-19 pandemic in the UK and Greece",
        "paper_author": "Carollo A.",
        "publication": "Public Health in Practice",
        "citied_by": "5",
        "cover_date": "2021-11-01",
        "Abstract": "Objectives: In the past months, many countries have adopted varying degrees of lockdown restrictions to control the spread of the COVID-19 virus. According to the existing literature, some consequences of lockdown restrictions on people's lives are beginning to emerge yet the evolution of such consequences in relation to the time spent in lockdown is understudied. To inform policies involving lockdown restrictions, this study adopted a data-driven Machine Learning approach to uncover the short-term time-related effects of lockdown on people's physical and mental health. Study design: An online questionnaire was launched on 17 April 2020, distributed through convenience sampling and was self-completed by 2,276 people from 66 different countries. Methods: Focusing on the UK sample (N = 325), 12 aggregated variables representing the participant's living environment, physical and mental health were used to train a RandomForest model to estimate the week of survey completion. Results: Using an index of importance, Self-Perceived Loneliness was identified as the most influential variable for estimating the time spent in lockdown. A significant U-shaped curve emerged for loneliness levels, with lower scores reported by participants who took part in the study during the 6th lockdown week (p = 0.009). The same pattern was replicated in the Greek sample (N = 137) for week 4 (p = 0.012) and 6 (p = 0.009) of lockdown. Conclusions: From the trained Machine Learning model and the subsequent statistical analysis, Self-Perceived Loneliness varied across time in lockdown in the UK and Greek populations, with lower symptoms reported during the 4th and 6th lockdown weeks. This supports the dissociation between social support and loneliness, and suggests that social support strategies could be effective even in times of social isolation.",
        "DOI": "10.1016/j.puhip.2021.100219",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Lane Changing of Autonomous Vehicle Based on TD3 Algorithm in Human-machine Hybrid Driving Environment",
        "paper_author": "Pei X.F.",
        "publication": "Zhongguo Gonglu Xuebao/China Journal of Highway and Transport",
        "citied_by": "12",
        "cover_date": "2021-11-01",
        "Abstract": "Improving the human acceptance of autonomous vehicles in the future is important, and deep reinforcement learning is a key technology for their acceptance. To solve the lane-changing decision problem in a human-machine hybrid driving traffic flow, this study used the deep reinforcement-learning algorithm Twin Delayed Deep Deterministic Policy Gradient (TD3) to realize the free-lane-changing behavior of an autonomous vehicle. First, the theoretical framework of reinforcement learning based on the Markov decision process was introduced. Then, according to the driving data from actual conditions in the NGSIM dataset, a six-lane moderate traffic-congestion simulation scene was established using the autonomous driving simulator NGSIM-ENV. Other non-autonomous vehicles were controlled according to the recorded data in NGSIM. For lane-changing decision making in a continuous action space, the TD3 algorithm was used to develop a lane-changing model to control the driving behavior of the autonomous vehicle. In the proposed lane-changing model, the state space that contained the self-vehicle and environment information and the action space, which included the vehicle acceleration and heading angle, were established. Simultaneously, a reward function in the reinforcement learning was designed to consider factors such as safety, driving efficiency, and comfort. Finally, in the NGSIM-ENV simulation platform, the lane-changing behavior of the autonomous vehicles based on the TD3 algorithm was compared with that in the driving data of human drivers. The average driving velocity was found to increase by 4.8%, and the driving safety and comfort were improved. The simulation results verify the effectiveness of the lane-changing model after the model training is completed. Furthermore, safe, comfortable, and reasonable lane-changing behavior in a complex traffic environment can be realized.",
        "DOI": "10.19721/j.cnki.1001-7372.2021.11.020",
        "affiliation_name": "Wuhan University of Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Development of dialogue management system for banking services",
        "paper_author": "Rustamov S.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "8",
        "cover_date": "2021-11-01",
        "Abstract": "Rapid increase in conversational AI and user chat data lead to intensive development of dialogue management systems (DMS) for various industries. Yet, for low-resource languages, such as Azerbaijani, very little research has been conducted. The main purpose of this work is to experiment with various DMS pipeline set-ups to decide on the most appropriate natural language understanding and dialogue manager settings. In our project, we designed and evaluated different DMS pipelines with respect to the conversational text data obtained from one of the leading retail banks in Azerbaijan. In the work, the main two components of DMS—Natural language Understanding (NLU) and Dialogue Manager—have been investigated. In the first step of NLU, we utilized a language identification (LI) component for language detection. We investigated both built-in LI methods such as fastText and custom machine learning (ML) models trained on the domain-based dataset. The second step of the work was a comparison of the classic ML classifiers (logistic regression, neural networks, and SVM) and Dual Intent and Entity Transformer (DIET) architecture for user intention detection. In these experiments we used different combinations of feature extractors such as CountVectorizer, Term Frequency-Inverse Document Frequency (TF-IDF) Vectorizer, and word embeddings for both word and character n-gram based tokens. To extract important information from the text messages, Named Entity Extraction (NER) component was added to the pipeline. The best NER model was chosen among conditional random fields (CRF) tagger, deep neural networks (DNN), models and build in entity extraction component inside DIET architecture. Obtained entity tags fed to the Dialogue Management module as features. All NLU set-ups were followed by the Dialogue Management module that contains a Rule-based Policy to handle FAQs and chitchats as well as a Transformer Embedding Dialogue (TED) Policy to handle more complex and unexpected dialogue inputs. As a result, we suggest a DMS pipeline for a financial assistant, which is capable of identifying intentions, named entities, and a language of text followed by policies that allow generating a proper response (based on the designed dialogues) and suggesting the best next action.",
        "DOI": "10.3390/app112210995",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Quantum-enhanced reinforcement learning for control: a preliminary study",
        "paper_author": "Hu Y.",
        "publication": "Control Theory and Technology",
        "citied_by": "2",
        "cover_date": "2021-11-01",
        "Abstract": "Reinforcement learning is one of the fastest growing areas in machine learning, and has obtained great achievements in biomedicine, Internet of Things (IoT), logistics, robotic control, etc. However, there are still many challenges for engineering applications, such as how to speed up the learning process, how to balance the trade-off between exploration and exploitation. Quantum technology, which can solve complex problems faster than classical methods, especially in supercomputers, provides us a new paradigm to overcome these challenges in reinforcement learning. In this paper, a quantum-enhanced reinforcement learning is pictured for optimal control. In this algorithm, the states and actions of reinforcement learning are quantized by quantum technology. And then, a probability amplification method, which can effectively avoid the trade-off between exploration and exploitation via quantized technology, is presented. Finally, the optimal control policy is learnt during the process of reinforcement learning. The performance of this quantized algorithm is demonstrated in both MountainCar reinforcement learning environment and CartPole reinforcement learning environment—one kind of classical control reinforcement learning environment in the OpenAI Gym. The preliminary study results validate that, compared with Q-learning, this quantized reinforcement learning method has better control performance without considering the trade-off between exploration and exploitation. The learning performance of this new algorithm is stable with different learning rates from 0.01 to 0.10, which means it is promising to be employed in unknown dynamics systems.",
        "DOI": "10.1007/s11768-021-00063-x",
        "affiliation_name": "Northwest A&amp;F University",
        "affiliation_city": "Yangling",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A comprehensive review: Machine learning and its application in integrated power system",
        "paper_author": "Kumbhar A.",
        "publication": "Energy Reports",
        "citied_by": "66",
        "cover_date": "2021-11-01",
        "Abstract": "A comprehensive review about machine learning application in power system especially in smart grid, renewable energy sector etc. is summarized in this paper. In the power sector, the power consumption is increased day by day very tremendously. So, it is very important that we have to generate the more power without disturbing the environment and whatever the generated power must be utilize effectively with minimum losses and higher efficiency. This will be possible with effective way of using the modern technology like machine learning (ML), artificial intelligence etc. This paper also describes the different types of machine learning techniques with diagram which will be very useful for many researchers who want to understand the basic fundamentals of machine learnings.",
        "DOI": "10.1016/j.egyr.2021.08.133",
        "affiliation_name": "Sanjay Ghodawat University, Kolhapur",
        "affiliation_city": "Kolhapur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Implications of covid-19 restriction measures in urban air quality of thessaloniki, greece: a machine learning approach",
        "paper_author": "Akritidis D.",
        "publication": "Atmosphere",
        "citied_by": "15",
        "cover_date": "2021-11-01",
        "Abstract": "Following the rapid spread of COVID-19, a lockdown was imposed in Thessaloniki, Greece, resulting in an abrupt reduction of human activities. To unravel the impact of restrictions on the urban air quality of Thessaloniki, NO2 and O3 observations are compared against the business-as-usual (BAU) concentrations for the lockdown period. BAU conditions are modeled, applying the XGBoost (eXtreme Gradient Boosting) machine learning algorithm on air quality and meteorological surface measurements, and reanalysis data. A reduction in NO2 concentrations is found during the lockdown period due to the restriction policies at both AGSOFIA and EGNATIA stations of −24.9 [−26.6, −23.2]% and −18.4 [−19.6, −17.1]%, respectively. A reverse effect is revealed for O3 concentrations at AGSOFIA with an increase of 12.7 [10.8, 14.8]%, reflecting the reduced O3 titration by NOx . The implications of COVID-19 lockdowns in the urban air quality of Thessaloniki are in line with the results of several recent studies for other urban areas around the world, highlighting the necessity of more sophisticated emission control strategies for urban air quality management.",
        "DOI": "10.3390/atmos12111500",
        "affiliation_name": "Aristotle University of Thessaloniki",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "An effective evaluation on fault detection in solar panels",
        "paper_author": "Dhanraj J.A.",
        "publication": "Energies",
        "citied_by": "58",
        "cover_date": "2021-11-01",
        "Abstract": "The world’s energy consumption is outpacing supply due to population growth and technological advancements. For future energy demands, it is critical to progress toward a dependable, cost-effective, and sustainable renewable energy source. Solar energy, along with all other alternative energy sources, is a potential renewable resource to manage these enduring challenges in the energy crisis. Solar power generation is expanding globally as a result of growing energy demands and depleting fossil fuel reserves, which are presently the primary sources of power generation. In the realm of solar power generation, photovoltaic (PV) panels are used to convert solar radiation into energy. They are subjected to the constantly changing state of the environment, resulting in a wide range of defects. These defects should be discovered and remedied as soon as possible so that PV panels efficiency, endurance, and durability are not compromised. This paper focuses on five aspects, namely, (i) the various possible faults that occur in PV panels, (ii) the online/remote supervision of PV panels, (iii) the role of machine learning techniques in the fault diagnosis of PV panels, (iv) the various sensors used for different fault detections in PV panels, and (v) the benefits of fault identification in PV panels. Based on the investigated studies, recommendations for future research directions are suggested.",
        "DOI": "10.3390/en14227770",
        "affiliation_name": "Dayananda Sagar College of Engineering",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Deep reinforcement learning for autonomous water heater control",
        "paper_author": "Amasyali K.",
        "publication": "Buildings",
        "citied_by": "20",
        "cover_date": "2021-11-01",
        "Abstract": "Electric water heaters represent 14% of the electricity consumption in residential buildings. An average household in the United States (U.S.) spends about USD 400–600 (0.45 ¢/L–0.68 ¢/L) on water heating every year. In this context, water heaters are often considered as a valuable asset for Demand Response (DR) and building energy management system (BEMS) applications. To this end, this study proposes a model-free deep reinforcement learning (RL) approach that aims to minimize the electricity cost of a water heater under a time-of-use (TOU) electricity pricing policy by only using standard DR commands. In this approach, a set of RL agents, with different look ahead periods, were trained using the deep Q-networks (DQN) algorithm and their performance was tested on an unseen pair of price and hot water usage profiles. The testing results showed that the RL agents can help save electricity cost in the range of 19% to 35% compared to the baseline operation without causing any discomfort to end users. Additionally, the RL agents outperformed rule-based and model predictive control (MPC)-based controllers and achieved comparable performance to optimization-based control.",
        "DOI": "10.3390/buildings11110548",
        "affiliation_name": "Oak Ridge National Laboratory",
        "affiliation_city": "Oak Ridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using machine learning to predict patterns of employment and day program participation",
        "paper_author": "Broda M.D.",
        "publication": "American Journal on Intellectual and Developmental Disabilities",
        "citied_by": "3",
        "cover_date": "2021-11-01",
        "Abstract": "In this article, we demonstrate the potential of machine learning approaches as inductive analytic tools for expanding our current evidence base for policy making and practice that affects people with intellectual and developmental disabilities (IDD). Using data from the National Core Indicators In-Person Survey (NCI-IPS), a nationally validated annual survey of more than 20,000 nationally representative people with IDD, we fit a series of classification tree and random forest models to predict individuals’ employment status and day activity participation as a function of their responses to all other items on the 2017–2018 NCI-IPS. The most accurate model, a random forest classifier, predicted employment outcomes of adults with IDD with an accuracy of 89 percent on the testing sample, and 80 percent on the holdout sample. The most important variable in this prediction was whether or not community employment was a goal in this person’s service plan. These results suggest the potential machine learning tools to examine other valued outcomes used in evidence-based policy making to support people with IDD.",
        "DOI": "10.1352/1944-7558-126.6.477",
        "affiliation_name": "Virginia Commonwealth University",
        "affiliation_city": "Richmond",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Urban safety: An image-processing and deep-learning-based intelligent traffic management and control system",
        "paper_author": "Reza S.",
        "publication": "Sensors",
        "citied_by": "19",
        "cover_date": "2021-11-01",
        "Abstract": "With the rapid growth and development of cities, Intelligent Traffic Management and Control (ITMC) is becoming a fundamental component to address the challenges of modern urban traffic management, where a wide range of daily problems need to be addressed in a prompt and expedited manner. Issues such as unpredictable traffic dynamics, resource constraints, and abnormal events pose difficulties to city managers. ITMC aims to increase the efficiency of traffic management by minimizing the odds of traffic problems, by providing real-time traffic state forecasts to better schedule the intersection signal controls. Reliable implementations of ITMC improve the safety of inhabitants and the quality of life, leading to economic growth. In recent years, researchers have proposed different solutions to address specific problems concerning traffic management, ranging from image-processing and deep-learning techniques to forecasting the traffic state and deriving policies to control intersection signals. This review article studies the primary public datasets helpful in developing models to address the identified problems, complemented with a deep analysis of the works related to traffic state forecast and intersection-signal-control models. Our analysis found that deep-learning-based approaches for short-term traffic state forecast and multi-intersection signal control showed reasonable results, but lacked robustness for unusual scenarios, particularly during oversaturated situations, which can be resolved by explicitly addressing these cases, potentially leading to significant improvements of the systems overall. However, there is arguably a long path until these models can be used safely and effectively in real-world scenarios.",
        "DOI": "10.3390/s21227705",
        "affiliation_name": "Universidade do Porto",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "George: Learning to place long-lived containers in large clusters with operation constraints",
        "paper_author": "Li S.",
        "publication": "SoCC 2021 - Proceedings of the 2021 ACM Symposium on Cloud Computing",
        "citied_by": "27",
        "cover_date": "2021-11-01",
        "Abstract": "Online cloud services are widely deployed as Long-Running Applications (LRAs) hosted in containers. Placing LRA containers turns out to be particularly challenging due to the complex interference between co-located containers and the operation constraints in production clusters such as fault tolerance, disaster avoidance and incremental deployment. Existing schedulers typically provide APIs for operators to manually specify the container scheduling requirements and offer only qualitative scheduling guidelines for container placement. Such schedulers, do not perform well in terms of both performance and scale, while also requiring manual intervention. In this work, we propose George, an end-to-end generalpurpose LRA scheduler by leveraging the state-of-the-art Reinforcement Learning (RL) techniques to intelligently schedule LRA containers. We present an optimal container placement formulation for the first time with the objective of maximizing container placement performance subject to a set of operation constraints. One fundamental challenge in scheduling is to categorically satisfy different operation constraints in practice; specifically, to guarantee hard constraints and ensure soft constraints violations within a pre-defined threshold. We design a novel projection-based proximal policy optimization (PPPO) algorithm in combination with an Integer Linear optimization technique to intelligently schedule LRA containers under operation constraints. In order to reduce the training time, we apply transfer learning technique by taking advantage of the similarity in different LRA scheduling events. We prove theoretically that our proposed algorithm is effective, stable, and safe. We implement George as a plug-in service in Docker Swarm. Our in-house cluster demonstrates that George can maximize the LRA performance while enforcing the hard constraints and the soft constraints with a pre-defined threshold. The experiments show that George improves LRA performance and scale tremendously by requiring less than 1 hour scheduling time in a large cluster with 2K containers and 700 machines, 16x faster than existing schedulers. Compared with state-of-the-art alternatives, George also achieves 26% higher container performance with up to 70% lower constraint violation.",
        "DOI": "10.1145/3472883.3486971",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Drone-based autonomous motion planning system for outdoor environments under object detection uncertainty",
        "paper_author": "Sandino J.",
        "publication": "Remote Sensing",
        "citied_by": "26",
        "cover_date": "2021-11-01",
        "Abstract": "Recent advances in autonomy of unmanned aerial vehicles (UAVs) have increased their use in remote sensing applications, such as precision agriculture, biosecurity, disaster monitoring, and surveillance. However, onboard UAV cognition capabilities for understanding and interacting in environments with imprecise or partial observations, for objects of interest within complex scenes, are limited, and have not yet been fully investigated. This limitation of onboard decision-making under uncertainty has delegated the motion planning strategy in complex environments to human pilots, which rely on communication subsystems and real-time telemetry from ground control stations. This paper presents a UAV-based autonomous motion planning and object finding system under uncertainty and partial observability in outdoor environments. The proposed system architecture follows a modular design, which allocates most of the computationally intensive tasks to a companion computer onboard the UAV to achieve high-fidelity results in simulated environments. We demonstrate the system with a search and rescue (SAR) case study, where a lost person (victim) in bushland needs to be found using a sub-2 kg quadrotor UAV. The navigation problem is mathematically formulated as a partially observable Markov decision process (POMDP). A motion strategy (or policy) is obtained once a POMDP is solved mid-flight and in real time using augmented belief trees (ABT) and the TAPIR toolkit. The system’s performance was assessed using three flight modes: (1) mission mode, which follows a survey plan and used here as the baseline motion planner; (2) offboard mode, which runs the POMDP-based planner across the flying area; and (3) hybrid mode, which combines mission and offboard modes for improved coverage in outdoor scenarios. Results suggest the increased cognitive power added by the proposed motion planner and flight modes allow UAVs to collect more accurate victim coordinates compared to the baseline planner. Adding the proposed system to UAVs results in improved robustness against potential false positive readings of detected objects caused by data noise, inaccurate detections, and elevated complexity to navigate in time-critical applications, such as SAR.",
        "DOI": "10.3390/rs13214481",
        "affiliation_name": "Griffith University",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Monitoring and forecasting of urban expansion using machine learning-based techniques and remotely sensed data: A case study of gharbia governorate, Egypt",
        "paper_author": "Mostafa E.",
        "publication": "Remote Sensing",
        "citied_by": "20",
        "cover_date": "2021-11-01",
        "Abstract": "Rapid population growth is the main driver of the accelerating urban sprawl into agricultural lands in Egypt. This is particularly obvious in governorates where there is no desert backyard (e.g., Gharbia) for urban expansion. This work presents an overview of machine learning-based and state-of-the-art remote sensing products and methodologies to address the issue of random urban expansion, which negatively impacts environmental sustainability. The study aims (1) to investigate the land-use/land-cover (LULC) changes over the past 27 years, and to simulate the future LULC dynamics over Gharbia; and (2) to produce an Urbanization Risk Map in order for the decision-makers to be informed of the districts with priority for sustainable planning. Time-series Landsat images were utilized to analyze the historical LULC change between 1991 and 2018, and to predict the LULC change by 2033 and 2048 based on a logistic regression–Markov chain model. The results show that there is a rapid urbanization trend corresponding to a diminution of the agricultural land. The agricultural sector represented 91.2% of the total land area in 1991, which was reduced to 83.7% in 2018. The built-up area exhibited a similar (but reversed) pattern. The results further reveal that the observed LULC dynamics will continue in a like manner in the future, confirming a remarkable urban sprawl over the agricultural land from 2018 to 2048. The cultivated land changes have a strong negative correlation with the built-up cover changes (the R2 were 0.73 in 1991–2003, and 0.99 in 2003–2018, respectively). Based on the Fuzzy TOPSIS technique, Mahalla Kubra and Tanta are the districts which were most susceptible to the undesirable environmental and socioeconomic impacts of the persistent urbanization. Such an unplanned loss of the fertile agricultural lands of the Nile Delta could negatively influence the production of premium agricultural crops for the local market and export. This study is substantial for the understanding of future trends of LULC changes, and for the proposal of alternative policies to reduce urban sprawl on fertile agricultural lands.",
        "DOI": "10.3390/rs13224498",
        "affiliation_name": "Faculty of Engineering at Shoubra",
        "affiliation_city": "Cairo",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Machine learning cybersecurity adoption in small and medium enterprises in developed countries",
        "paper_author": "Rawindaran N.",
        "publication": "Computers",
        "citied_by": "34",
        "cover_date": "2021-11-01",
        "Abstract": "In many developed countries, the usage of artificial intelligence (AI) and machine learning (ML) has become important in paving the future path in how data is managed and secured in the small and medium enterprises (SMEs) sector. SMEs in these developed countries have created their own cyber regimes around AI and ML. This knowledge is tested daily in how these countries’ SMEs run their businesses and identify threats and attacks, based on the support structure of the individual country. Based on recent changes to the UK General Data Protection Regulation (GDPR), Brexit, and ISO standards requirements, machine learning cybersecurity (MLCS) adoption in the UK SME market has become prevalent and a good example to lean on, amongst other developed nations. Whilst MLCS has been successfully applied in many applications, including network intrusion detection systems (NIDs) worldwide, there is still a gap in the rate of adoption of MLCS techniques for UK SMEs. Other developed countries such as Spain and Australia also fall into this category, and similarities and differences to MLCS adoptions are discussed. Applications of how MLCS is applied within these SME industries are also explored. The paper investigates, using quantitative and qualitative methods, the challenges to adopting MLCS in the SME ecosystem, and how operations are managed to promote business growth. Much like security guards and policing in the real world, the virtual world is now calling on MLCS techniques to be embedded like secret service covert operations to protect data being distributed by the millions into cyberspace. This paper will use existing global research from multiple disciplines to identify gaps and opportunities for UK SME small business cyber security. This paper will also highlight barriers and reasons for low adoption rates of MLCS in SMEs and compare success stories of larger companies implementing MLCS. The methodology uses structured quantitative and qualitative survey questionnaires, distributed across an extensive participation pool directed to the SMEs’ management and technical and non-technical professionals using stratify methods. Based on the analysis and findings, this study reveals that from the primary data obtained, SMEs have the appropriate cybersecurity packages in place but are not fully aware of their potential. Secondary data collection was run in parallel to better understand how these barriers and challenges emerged, and why the rate of adoption of MLCS was very low. The paper draws the conclusion that help through government policies and processes coupled together with collaboration could minimize cyber threats in combatting hackers and malicious actors in trying to stay ahead of the game. These aspirations can be reached by ensuring that those involved have been well trained and understand the importance of communication when applying appropriate safety processes and procedures. This paper also highlights important funding gaps that could help raise cyber security awareness in the form of grants, subsidies, and financial assistance through various public sector policies and training. Lastly, SMEs’ lack of understanding of risks and impacts of cybercrime could lead to conflicting messages between cross-company IT and cybersecurity rules. Trying to find the right balance between this risk and impact, versus productivity impact and costs, could lead to UK SMES getting over these hurdles in this cyberspace in the quest for promoting the usage of MLCS. UK and Wales governments can use the research conducted in this paper to inform and adapt their policies to help UK SMEs become more secure from cyber-attacks and compare them to other developed countries also on the same future path.",
        "DOI": "10.3390/computers10110150",
        "affiliation_name": "Cardiff Metropolitan University",
        "affiliation_city": "Cardiff",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Examining the utility of social media in covid-19 vaccination: Unsupervised learning of 672,133 twitter posts",
        "paper_author": "Liew T.M.",
        "publication": "JMIR Public Health and Surveillance",
        "citied_by": "38",
        "cover_date": "2021-11-01",
        "Abstract": "Background: Although COVID-19 vaccines have recently become available, efforts in global mass vaccination can be hampered by the widespread issue of vaccine hesitancy. Objective: The aim of this study was to use social media data to capture close-to-real-time public perspectives and sentiments regarding COVID-19 vaccines, with the intention to understand the key issues that have captured public attention, as well as the barriers and facilitators to successful COVID-19 vaccination. Methods: Twitter was searched for tweets related to \"COVID-19\" and \"vaccine\" over an 11-week period after November 18, 2020, following a press release regarding the first effective vaccine. An unsupervised machine learning approach (ie, structural topic modeling) was used to identify topics from tweets, with each topic further grouped into themes using manually conducted thematic analysis as well as guided by the theoretical framework of the COM-B (capability, opportunity, and motivation components of behavior) model. Sentiment analysis of the tweets was also performed using the rule-based machine learning model VADER (Valence Aware Dictionary and Sentiment Reasoner). Results: Tweets related to COVID-19 vaccines were posted by individuals around the world (N=672,133). Six overarching themes were identified: (1) emotional reactions related to COVID-19 vaccines (19.3%), (2) public concerns related to COVID-19 vaccines (19.6%), (3) discussions about news items related to COVID-19 vaccines (13.3%), (4) public health communications about COVID-19 vaccines (10.3%), (5) discussions about approaches to COVID-19 vaccination drives (17.1%), and (6) discussions about the distribution of COVID-19 vaccines (20.3%). Tweets with negative sentiments largely fell within the themes of emotional reactions and public concerns related to COVID-19 vaccines. Tweets related to facilitators of vaccination showed temporal variations over time, while tweets related to barriers remained largely constant throughout the study period. Conclusions: The findings from this study may facilitate the formulation of comprehensive strategies to improve COVID-19 vaccine uptake; they highlight the key processes that require attention in the planning of COVID-19 vaccination and provide feedback on evolving barriers and facilitators in ongoing vaccination drives to allow for further policy tweaks. The findings also illustrate three key roles of social media in COVID-19 vaccination, as follows: Surveillance and monitoring, a communication platform, and evaluation of government responses.",
        "DOI": "10.2196/29789",
        "affiliation_name": "SingHealth Polyclinics, Singapore",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "A virtual community for disability advocacy: Development of a searchable artificial intelligence-supported platform",
        "paper_author": "Morr C.E.",
        "publication": "JMIR Formative Research",
        "citied_by": "10",
        "cover_date": "2021-11-01",
        "Abstract": "Background: The lack of availability of disability data has been identified as a major challenge hindering continuous disability equity monitoring. It is important to develop a platform that enables searching for disability data to expose systemic discrimination and social exclusion, which increase vulnerability to inequitable social conditions. Objective: Our project aims to create an accessible and multilingual pilot disability website that structures and integrates data about people with disabilities and provides data for national and international disability advocacy communities. The platform will be endowed with a document upload function with hybrid (automated and manual) paragraph tagging, while the querying function will involve an intelligent natural language search in the supported languages. Methods: We have designed and implemented a virtual community platform using Wikibase, Semantic Web, machine learning, and web programming tools to enable disability communities to upload and search for disability documents. The platform data model is based on an ontology we have designed following the United Nations Convention on the Rights of Persons with Disabilities (CRPD). The virtual community facilitates the uploading and sharing of validated information, and supports disability rights advocacy by enabling dissemination of knowledge. Results: Using health informatics and artificial intelligence techniques (namely Semantic Web, machine learning, and natural language processing techniques), we were able to develop a pilot virtual community that supports disability rights advocacy by facilitating uploading, sharing, and accessing disability data. The system consists of a website on top of a Wikibase (a Semantic Web-based datastore). The virtual community accepts 4 types of users: Information producers, information consumers, validators, and administrators. The virtual community enables the uploading of documents, semiautomatic tagging of their paragraphs with meaningful keywords, and validation of the process before uploading the data to the disability Wikibase. Once uploaded, public users (information consumers) can perform a semantic search using an intelligent and multilingual search engine (QAnswer). Further enhancements of the platform are planned. Conclusions: The platform ontology is flexible and can accommodate advocacy reports and disability policy and legislation from specific jurisdictions, which can be accessed in relation to the CRPD articles. The platform ontology can be expanded to fit international contexts. The virtual community supports information upload and search. Semiautomatic tagging and intelligent multilingual semantic search using natural language are enabled using artificial intelligence techniques, namely Semantic Web, machine learning, and natural language processing.",
        "DOI": "10.2196/33335",
        "affiliation_name": "Faculty of Health",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "The economic loss prediction of flooding based on machine learning and the input-output model",
        "paper_author": "Chen A.",
        "publication": "Atmosphere",
        "citied_by": "6",
        "cover_date": "2021-11-01",
        "Abstract": "As climate change becomes increasingly widespread, rapid, and intense, the frequency of heavy rainfall and floods continues to increase. This article establishes a prediction system using feature sets with multiple data dimensions, including meteorological data and socio-economic data. Based on data of historical floods in 31 provinces and municipalities in China from 2006 to 2018, five machine learning methods are compared to predict the direct economic losses. Among them, GBR performs the best with a goodness-of-fit of 90%. Combined with the input-output (IO) model, the indirect economic losses of agriculture to other sectors are calculated, and the total economic losses caused by floods can be predicted effectively by using the GBR-IO model. The model has a strong generalization ability with a minimum requirement of 80 pieces of data. The results of the data show that in China, provinces heavily reliant on agriculture suffered the most with the proportion of direct economic losses to provincial GDP exceeding 1‰. Therefore, some policy implications are provided to assist the government to take timely pre-disaster preventive measures and conduct post-disaster risk management, thereby reducing the economic losses caused by floods.",
        "DOI": "10.3390/atmos12111448",
        "affiliation_name": "Faculty of Engineering",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Evaluation of features generated by a high-end low-cost electrical smart meter",
        "paper_author": "Koutroumpina C.",
        "publication": "Algorithms",
        "citied_by": "3",
        "cover_date": "2021-11-01",
        "Abstract": "The problem of energy disaggregation is the separation of an aggregate energy signal into the consumption of individual appliances in a household. This is useful, since the goal of energy efficiency at the household level can be achieved through energy-saving policies towards changing the behavior of the consumers. This requires as a prerequisite to be able to measure the energy consumption at the appliance level. The purpose of this study is to present some initial results towards this goal by making heavy use of the characteristics of a particular din-rail meter, which is provided by Meazon S.A. Our thinking is that meter-specific energy disaggregation solutions may yield better results than general-purpose methods, especially for sophisticated meters. This meter has a 50 Hz sampling rate over 3 different lines and provides a rather rich set of measurements with respect to the extracted features. In this paper we aim at evaluating the set of features generated by the smart meter. To this end, we use well-known supervised machine learning models and test their effectiveness on certain appliances when selecting specific subsets of features. Three algorithms are used for this purpose: the Decision Tree Classifier, the Random Forest Classifier, and the Multilayer Perceptron Classifier. Our experimental study shows that by using a specific set of features one can enhance the classification performance of these algorithms.",
        "DOI": "10.3390/a14110311",
        "affiliation_name": "University of Patras",
        "affiliation_city": "Rio",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "House price forecasting with neural networks",
        "paper_author": "Xu X.",
        "publication": "Intelligent Systems with Applications",
        "citied_by": "89",
        "cover_date": "2021-11-01",
        "Abstract": "The house market has been rapidly growing for the past decade in China, making price forecasting an important issue to the people and policy makers. We approach this problem by exploring neural networks for forecasting of house prices from one hundred major cities for the period of June 2010–May 2019, serving as the first study with such wide coverage for the emerging Chinese market through a machine learning technique. We aim at constructing simple and accurate neural networks as a contribution to pure technical forecasting of house prices. To facilitate the analysis, we investigate different model settings over the algorithm (the Levenberg-Marquardt, scaled conjugate gradient, and Bayesian regularization), delay (from two to six), hidden neuron (two, three, five, and eight), and data spitting ratio (70%–15%–15%, 60%–20%–20%, and 80%–10%–10% for trainingvalidationtesting), and arrive at a rather simple neural network with only four delays and three hidden neurons that leads to stable performance of 1% average relative root mean square error across the one hundred cities for the training, validation, and testing phases. We demonstrate the usefulness of the machine learning approach to the house price forecasting problem in the Chinese market. Our results could be used on a standalone basis or combined with fundamental forecasting in forming perspectives of house price trends and conducting policy analysis. Our empirical framework should not be difficult to deploy, which is an important consideration to many decision makers, and has potential to be generalized for house price forecasting of other cities in China.",
        "DOI": "10.1016/j.iswa.2021.200052",
        "affiliation_name": "NC State University",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Influencing factors evaluation of machine learning-based energy consumption prediction",
        "paper_author": "Khan P.W.",
        "publication": "Energies",
        "citied_by": "23",
        "cover_date": "2021-11-01",
        "Abstract": "Modern computing resources, including machine learning-based techniques, are used to maintain stability between the demand and supply of electricity. Machine learning is widely used for the prediction of energy consumption. The researchers present several artificial intelligence and machine learning-based methods to improve the prediction accuracy of energy consumption. However, the discrepancy between actual energy consumption and predicted energy consumption is still challenging. Various factors, including changes in weather, holidays, and weekends, affect prediction accuracy. This article analyses the overall prediction using error curve learning and a hybrid model. Actual energy consumption data of Jeju island, South Korea, has been used for experimental purposes. We have used a hybrid ML model consisting of Catboost, Xgboost, and Multi-layer perceptron for the prediction. Then we analyze the factors that affect the week-ahead (WA) and 48 h prediction results. Mean error on weekdays is recorded as 2.78%, for weekends 2.79%, and for special days it is recorded as 4.28%. We took into consideration significant predicting errors and looked into the reasons behind those errors. Furthermore, we analyzed whether factors, such as a sudden change in temperature and typhoons, had an effect on energy consumption. Finally, the authors have considered the other factors, such as public holidays and weekends, to analyze the significant errors in the prediction. This study can be helpful for policymakers to make policies according to the error-causing factors.",
        "DOI": "10.3390/en14217167",
        "affiliation_name": "Jeju National University",
        "affiliation_city": "Jeju",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "An evidence-based approach on academic management in a school of public health using smaart model",
        "paper_author": "Joshi A.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "2",
        "cover_date": "2021-11-01",
        "Abstract": "Data-driven modeling, action, and strategies have become popular, and the education community has witnessed increased interest in data-driven decision-making (DDDM). DDDM values and prioritizes decisions supported by high-quality, verifiable data that has been effectively processed and analyzed. The objective of our study is to describe the design, development, and implementation of a data-driven, evidence-based model of academic development in the context of CUNY Graduate School of Public Health and Health Policy (CUNY SPH) utilizing SMAART (Sustainability Multisector Accessible Affordable Reimbursable Tailored) model. The alignment of academic and student affairs within CUNY SPH brought with it several challenges. Defining roles and responsibilities across different student and academic affair units with a goal of collaborative leadership model and lack of meaningfulness were key challenges. It was important to listen to the experiences and recommendations of various individuals performing various functions in different capacities. A unified framework of key data indicators was needed to create a transparent and equitable model. An innovative interactive SMAART SPH dashboard designed, developed, and implemented to guide data-driven, evidence-based decision-making. Institutions can use a large amount of data from various sources to improve students’ learning experience, enhance research initiatives, support effective community outreach, and develop campus infrastructure to bring in sustainability.",
        "DOI": "10.3390/su132112256",
        "affiliation_name": "The City University of New York",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning approach on road accidents analysis in Calabarzon, Philippines: An input to road safety management",
        "paper_author": "Torres K.A.R.",
        "publication": "Indonesian Journal of Electrical Engineering and Computer Science",
        "citied_by": "4",
        "cover_date": "2021-11-01",
        "Abstract": "This research was conducted to help the traffic policy makers and general public in preventing road incidents using the collected traffic accident dataset between the years 2016 and 2019. Data mining using classification algorithm was utilized to develop a predictive model for predicting occurrences of traffic accidents. Classification algorithms such as decision tree, k-nn, naïve bayes and neural network have been compared in identifying better classification capability in classifying stage of felony. Neural network shows a very promising result in classifying road accident with a total accuracy result of 87.63%. Nonetheless, k-nn and naïve bayes both acquired a higher than 80% accuracy which shows that this classification algorithms were also good in predicting road accidents. Moreover, public vehicle is more prone in accident rather than private vehicle in both stage of felony and accident may occur between or on 3:00pm and 6:00pm.",
        "DOI": "10.11591/ijeecs.v24.i2.pp993-1000",
        "affiliation_name": "Laguna State Polytechnic University",
        "affiliation_city": "Santa Cruz",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "A Convolutional Stacked Bidirectional LSTM with a Multiplicative Attention Mechanism for Aspect Category and Sentiment Detection",
        "paper_author": "J A.K.",
        "publication": "Cognitive Computation",
        "citied_by": "48",
        "cover_date": "2021-11-01",
        "Abstract": "Traditionally, sentiment analysis is a binary classification task that aims to categorize a piece of text as positive or negative. This approach, however, can be too simplistic when the text under scrutiny contains more than one opinion target. Hence, aspect-based sentiment analysis provides fine-grained sentiment understanding of the product, service, or policy. Machine learning and deep learning algorithms play an important role in this kind of task. Also, attention mechanism has shown breakthrough in the field of natural language processing. Therefore, we propose a convolutional stacked bidirectional long short-term memory with a multiplicative attention mechanism for aspect category and sentiment polarity detection. More specifically, we treat the proposed model as a multiclass classification problem. The proposed model is evaluated using SemEval-2015 and SemEval-2016 dataset. Our proposed model outperforms state-of-the-art results in aspect-based sentiment analysis.",
        "DOI": "10.1007/s12559-021-09948-0",
        "affiliation_name": "School of Computer Science and Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Predicting regional outbreaks of hepatitis a using 3d lstm and open data in korea",
        "paper_author": "Lee K.",
        "publication": "Electronics (Switzerland)",
        "citied_by": "4",
        "cover_date": "2021-11-01",
        "Abstract": "In 2020 and 2021, humanity lived in fear due to the COVID-19 pandemic. However, with the development of artificial intelligence technology, mankind is attempting to tackle many challenges from currently unpredictable epidemics. Korean society has been exposed to various infectious diseases since the Korean War in 1950, and to overcome them, the six most serious cases in National Notifiable Infectious Diseases (NNIDs) category I were defined. Although most infectious diseases have been overcome, viral hepatitis A has been on the rise in Korean society since 2010. Therefore, in this paper, the prediction of viral hepatitis A, which is rapidly spreading in Korean society, was predicted by region using the deep learning technique and a publicly available dataset. For this study, we gathered information from five organizations based on the open data policy: Korea Centers for Disease Control and Prevention (KCDC), National Institute of Environmental Research (NIER), Korea Meteorological Agency (KMA), Public Open Data Portal, and Korea Environment Corporation (KECO). Patient information, water environment information, weather information, population information, and air pollution information were acquired and correlations were identified. Next, an epidemic outbreak prediction was performed using data preprocessing and 3D LSTM. The experimental results were compared with various machine learning methods through RMSE. In this paper, we attempted to predict regional epidemic outbreaks of hepatitis A by linking the open data environment with deep learning. It is expected that the experimental process and results will be used to present the importance and usefulness of establishing an open data environment.",
        "DOI": "10.3390/electronics10212668",
        "affiliation_name": "Chosun University",
        "affiliation_city": "Gwangju",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Uncovering the nature of urban land use composition using multi-source open big data with ensemble learning",
        "paper_author": "Tu Y.",
        "publication": "Remote Sensing",
        "citied_by": "15",
        "cover_date": "2021-11-01",
        "Abstract": "Detailed information on urban land uses has been an essential requirement for urban land management and policymaking. Recent advances in remote sensing and machine learning technologies have contributed to the mapping and monitoring of multi-scale urban land uses, yet there lacks a holistic mapping framework that is compatible with different end users’ demands. Moreover, land use mix has evolved to be a key component in modern urban settings, but few have explicitly measured the spatial complexity of land use or quantitively uncovered its driving forces. Addressing these challenges, here we developed a novel two-stage bottom-up scheme for mapping essential urban land use categories. In the first stage, we conducted object-based land use classification using crowdsourcing features derived from multi-source open big data and an automated ensemble learning approach. In the second stage, we identified parcel-based land use attributes, including the dominant type and mixture mode, by spatially correlating land parcels with the object-based results. Furthermore, we investigated the potential influencing factors of land use mix using principal components analysis and multiple linear regression. Experimental results in Ningbo, a coastal city in China, showed that the proposed framework could accurately depict the distribution and composition of urban land uses. At the object scale, the highest classification accuracy was as high as 86% and 78% for the major (Level I) and minor (Level II) categories, respectively. At the parcel scale, the generated land use maps were spatially consistent with the object-based maps. We found larger parcels were more likely to be mixed in land use, and industrial lands were characterized as the most complicated category. We also identified multiple factors that had a collective impact on land use mix, including geography, socioeconomy, accessibility, and landscape metrics. Altogether, our proposed framework offered an alternative to investigating urban land use composition, which could be applied in a broad range of implications in future urban studies.",
        "DOI": "10.3390/rs13214241",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Unmasking people’s opinions behind mask‐wearing during covid‐19 pandemic—a twitter stance analysis",
        "paper_author": "Cotfas L.A.",
        "publication": "Symmetry",
        "citied_by": "13",
        "cover_date": "2021-11-01",
        "Abstract": "Wearing a mask by the general public has been a controversial issue from the beginning of the COVID‐19 pandemic as the public authorities have had mixed messages, either advising people not to wear masks if uninfected, to wear as a protective measure, to wear them only when inside a building/room with insufficient air flow or to wear them in all the public places. To date, the governments have had different policies regarding mask‐wearing by the general public depending on the COVID‐19 pandemic evolution. In this context, the paper analyzes the general public’s opinion regarding mask‐wearing for the one‐year period starting from 9 January 2020, when the first tweet regarding mask‐wearing in the COVID‐19 context has been posted. Classical machine learning and deep learning algorithms have been considered in analyzing the 8,795,633 tweets extracted. A random sample of 29,613 tweets has been extracted and annotated. The tweets containing news and information related to mask‐wearing have been included in the neutral category, while the ones containing people’s opinions (for or against) have been marked using a symmetrical approach into in favor and against categories. Based on the analysis, it has been determined that most of the mask tweets are in the area of in favor or neutral, while a smaller percentage of tweets and retweets are in the against category. The evolution of the opinions expressed through tweets can be further monitored for extracting the public perspective on mask‐wearing in times of COVID‐19.",
        "DOI": "10.3390/sym13111995",
        "affiliation_name": "Édition, Langages, Littératures, Informatique, Arts, Didactiques, Discours",
        "affiliation_city": "Besancon",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Modelling the common agricultural policy impact over the eu agricultural and rural environment through a machine learning predictive framework",
        "paper_author": "Cristea D.S.",
        "publication": "Agronomy",
        "citied_by": "3",
        "cover_date": "2021-11-01",
        "Abstract": "This research provides an analytical and predictive framework, based on state‐of‐the‐art machine‐learning (ML) algorithms (random forest (RF) and generalized additive models (GAM)), that can be used to assess and improve the Common Agricultural Policy (CAP) im-pact/performance over the agricultural and rural environments, easing the identification of proper instruments that can be used by EU policy makers in CAP’s financial management. The applied methodology consists of elaborating a custom‐developed analytical framework based on a dataset containing 22 relevant indicators, considering four main dimensions that describe the intricacies of the EU agricultural and rural environment, in the CAP context: rural, emissions, macroeconomic, and financial. The results highlight that an increase of the agricultural research and development funding, as well as the agriculture employment rate, negatively influence the degree of rural pov-erty. The rural GDP per capita is influenced by the size of the employment rate in agriculture. It seems that environmental sustainability, identified by both fertilizers used and emissions from agriculture parameters, significantly influences the GDP per capita. In predicting emissions in agriculture, the direct payment, degree of rural poverty, fertilizer use, employment in agriculture, and agriculture labor productivity are the main independent parameters with the highest future importance. It was found that when predicting direct payments, the rural employment rate, employment in agriculture, and gross value added must be considered the most. The agricultural, entrepreneurial income prediction is mainly influenced by the total factor productivity, while agricultural research and development investments depend on gross value added, direct pay-ments, and gross value added in the agricultural sector. Future research, related to prediction models based on CAP indicators, should also consider the marketing dimension. It is recommended for direct payments to be used to invest in upgrading the fertilizers technologies, since environmental sustainability will influence economic growth.",
        "DOI": "10.3390/agronomy11112105",
        "affiliation_name": "Universitatea Dunarea de Jos din Galati",
        "affiliation_city": "Galati",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "A forecasting and prediction methodology for improving the blue economy resilience to climate change in the romanian lower danube euroregion",
        "paper_author": "Petrea S.M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "13",
        "cover_date": "2021-11-01",
        "Abstract": "European Union (EU) policy encourages the development of a blue economy (BE) by un-locking the full economic potential of oceans, seas, lakes, rivers and other water resources, especially in member countries in which it represents a low contribution to the national economy (under 1%). However, climate change represents a main barrier to fully realizing a BE. Enabling conditions that will support the sustainable development of a BE and increase its climate resiliency must be promoted. Romania has high potential to contribute to the development of the EU BE due to its geo-graphic characteristics, namely the presence of the Danube Delta–Black Sea macrosystem, which is part of the Romanian Lower Danube Euroregion (RLDE). Aquatic living resources represent a sector which can significantly contribute to the growth of the BE in the RLDE, a situation which imposes restrictions for both halting biodiversity loss and maintaining the proper conditions to maximize the benefits of the existing macrosystem. It is known that climate change causes water quality problems, accentuates water level fluctuations and loss of biodiversity and induces the destruction of habitats, which eventually leads to fish stock depletion. This paper aims to develop an analytical framework based on multiple linear predictive and forecast models that offers cost‐efficient tools for the monitoring and control of water quality, fish stock dynamics and biodiversity in order to strengthen the resilience and adaptive capacity of the BE of the RLDE in the context of climate change. The following water‐dependent variables were considered: total nitrogen (TN); total phosphorus (TP); dissolved oxygen (DO); pH; water temperature (wt); and water level, all of which were measured based on a series of 26 physicochemical indicators associated with 4 sampling areas within the RLDE (Brăila, Galați, Tulcea and Sulina counties). Predictive models based on fish species catches associated with the Galati County Danube River Basin segment and the ʺDanube Delta” Biosphere Reserve Administration territory were included in the analytical framework to establish an efficient tool for monitoring fish stock dynamics and structures as well as identify methods of controlling fish biodiversity in the RLDE to enhance the sustainable development and resilience of the already‐existing BE and its expansion (blue growth) in the context of aquatic environment climate variation. The study area reflects the integrated approach of the emerging BE, focused on the ocean, seas, lakes and rivers according to the United Nations Agenda. The results emphasized the vulnerability of the RLDE to climate change, a situation revealed by the water level, air temperature and water quality parameter trend lines and forecast models. Considering the sampling design applied within the RLDE, it can be stated that the Tulcea county Danube sector was less affected by climate change compared with the Galați county sector as confirmed by water TN and TP forecast analysis, which revealed higher increasing trends in Galați compared with Tulcea. The fish stock biodiversity was proven to be affected by global warming within the RLDE, since peaceful species had a higher upward trend compared with predatory species. Water level and air temperature forecasting analysis proved to be an important tool for climate change monitoring in the study area. The resulting analytical framework confirmed that time series methods could be used together with machine learning prediction methods to highlight their synergetic abilities for monitoring and predicting the impact of climate change on the marine living resources of the BE sector within the RLDE. The forecasting models developed in the present study were meant to be used as methods of revealing future information, making it possible for decision makers to adopt proper management solutions to prevent or limit the negative impacts of climate change on the BE. Through the identified independent variables, prediction models offer a solution for managing the dependent variables and the possibility of performing less cost‐demanding aquatic environment monitoring activities.",
        "DOI": "10.3390/su132111563",
        "affiliation_name": "Bucharest University of Economic Studies",
        "affiliation_city": "Bucharest",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "DTaxa: An actor–critic for automatic taxonomy induction",
        "paper_author": "Han Y.",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "6",
        "cover_date": "2021-11-01",
        "Abstract": "Automatic taxonomy induction is a challenging task in the field of natural language understanding (NLU) and information retrieval (IR) because it requires machine learning and understanding the is-a relation (i.e. hypernym relation) between term pairs. Therefore, the deep taxa (DTaxa) based on the actor–critic algorithm framework is designed to deal with the aforementioned problems in this paper. The agent in the DTaxa regards the taxonomy induction process as the sequential decision steps so that the agent can take the operation of a term as an action via the policy network to jointly optimize hypernym detection and hypernym organization. Meanwhile, the DTaxa obtains a stable performance from the experiences buffered in the memory. In order to verify the effectiveness of the DTaxa for the automatic taxonomy induction, two experiments are performed on the all bottomed-out full subtrees extracted from WordNet 3.0 and the English environment and science taxonomies in the SemEval-2016 task 13, respectively. The proposed method outperforms these existing methods and achieves state-of-the-art among most metrics.",
        "DOI": "10.1016/j.engappai.2021.104501",
        "affiliation_name": "Beijing University of Chemical Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A reinforcement learning approach for finding optimal policy of adaptive radiation therapy considering uncertain tumor biological response",
        "paper_author": "Ebrahimi S.",
        "publication": "Artificial Intelligence in Medicine",
        "citied_by": "16",
        "cover_date": "2021-11-01",
        "Abstract": "Recent studies have shown that a tumor's biological response to radiation varies over time and has a dynamic nature. Dynamic biological features of tumor cells underscore the importance of using fractionation and adapting the treatment plan to tumor volume changes in radiation therapy treatment. Adaptive radiation therapy (ART) is an iterative process to adjust the dose of radiation in response to potential changes during the treatment. One of the key challenges in ART is how to determine the optimal timing of adaptations corresponding to tumor response to radiation. This paper aims to develop an automated treatment planning framework incorporating the biological uncertainties to find the optimal adaptation points to achieve a more effective treatment plan. First, a dynamic tumor-response model is proposed to predict weekly tumor volume regression during the period of radiation therapy treatment based on biological factors. Second, a Reinforcement Learning (RL) framework is developed to find the optimal adaptation points for ART considering the uncertainty in biological factors with the goal of achieving maximum final tumor control while minimizing or maintaining the toxicity level of the organs at risk (OARs) per the decision-maker's preference. Third, a beamlet intensity optimization model is solved using the predicted tumor volume at each adaptation point. The performance of the proposed RT treatment planning framework is tested using a clinical non-small cell lung cancer (NSCLC) case. The results are compared with the conventional fractionation schedule (i.e., equal dose fractionation) as a reference plan. The results show that the proposed approach performed well in achieving a robust optimal ART treatment plan under high uncertainty in the biological parameters. The ART plan outperformed the reference plan by increasing the mean biological effective dose (BED) value of the tumor by 2.01%, while maintaining the OAR BED within +0.5% and reducing the variability, in terms of the interquartile range (IQR) of tumor BED, by 25%.",
        "DOI": "10.1016/j.artmed.2021.102193",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Economic stimulus through bank regulation: Government responses to the COVID-19 crisis",
        "paper_author": "Polyzos S.",
        "publication": "Journal of International Financial Markets, Institutions and Money",
        "citied_by": "27",
        "cover_date": "2021-11-01",
        "Abstract": "In this paper, we estimate the effects of the COVID-19 pandemic on the banking system and the real economy and simulate potential policy responses. We combine machine learning algorithms, namely a Random Regression Forest and a Long Short Term Memory neural network, with an agent-based framework to calculate the expected results of the pandemic, according to different scenarios regarding financial stability. We then simulate government responses to this crisis and find that traditional demand and supply stimuli are outperformed by our suggestion of relaxing bank regulation. We examine two alternatives of our suggested policy and find that they result in optimised outcomes for most variables examined. Our findings have important policy implications as authorities are formulating post-crisis recovery plans amidst budgetary constraints.",
        "DOI": "10.1016/j.intfin.2021.101444",
        "affiliation_name": "Abu Dhabi University",
        "affiliation_city": "Abu Dhabi",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Equality of opportunity in travel behavior prediction with deep neural networks and discrete choice models",
        "paper_author": "Zheng Y.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "26",
        "cover_date": "2021-11-01",
        "Abstract": "Although researchers increasingly adopt machine learning to model travel behavior, they predominantly focus on prediction accuracy, ignoring the ethical challenges embedded in machine learning algorithms. This study introduces an important missing dimension - computational fairness - to travel behavior analysis. It highlights the accuracy-fairness tradeoff instead of the single dimensional focus on prediction accuracy in the contexts of deep neural network (DNN) and discrete choice models (DCM). We first operationalize computational fairness by equality of opportunity, then differentiate between the bias inherent in data and the bias introduced by modeling. The models inheriting the inherent biases can risk perpetuating the existing inequality in the data structure, and the biases in modeling can further exacerbate it. We then demonstrate the prediction disparities in travel behavior modeling using the 2017 National Household Travel Survey (NHTS) and the 2018–2019 My Daily Travel Survey in Chicago. Empirically, DNN and DCM reveal consistent prediction disparities across multiple social groups: both over-predict the false negative rate of frequent driving for the ethnic minorities, the low-income and the disabled populations, and falsely predict a higher travel burden of the socially disadvantaged groups and the rural populations than reality. Comparing DNN with DCM, we find that DNN can outperform DCM in prediction disparities because of DNN's smaller misspecification error. To mitigate prediction disparities, this study introduces an absolute correlation regularization method, which is evaluated with synthetic and real-world data. The results demonstrate the prevalence of prediction disparities in travel behavior modeling, and the disparities still persist regarding a variety of model specifics such as the number of DNN layers, batch size and weight initialization. Since these prediction disparities can exacerbate social inequity if prediction results without fairness adjustment are used for transportation policy making, we advocate for careful consideration of the fairness problem in travel behavior modeling, and the use of bias mitigation algorithms for fair transport decisions.",
        "DOI": "10.1016/j.trc.2021.103410",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning in Screening High Performance Electrocatalysts for CO<inf>2</inf> Reduction",
        "paper_author": "Zhang N.",
        "publication": "Small Methods",
        "citied_by": "75",
        "cover_date": "2021-11-01",
        "Abstract": "Converting CO2 into carbon-based fuels is promising for relieving the greenhouse gas effect and the energy crisis. However, the selectivity and efficiency of current electrocatalysts for CO2 reductions are still not satisfactory. In this paper, the development of machine learning methods in screening CO2 reduction electrocatalysts over the recent years is reviewed. Through high-throughput calculation of some key descriptors such as adsorption energies, d-band center, and coordination number by well-constructed machine learning models, the catalytic activity, optimal composition, active sites, and CO2 reduction reaction pathway over various possible materials can be predicted and understood. Machine learning is now realized as a fast and low-cost method to effectively explore high performance electrocatalysts for CO2 reduction.",
        "DOI": "10.1002/smtd.202100987",
        "affiliation_name": "Zhengzhou University",
        "affiliation_city": "Zhengzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "IoT-Agro: A smart farming system to Colombian coffee farms",
        "paper_author": "Rodríguez J.P.",
        "publication": "Computers and Electronics in Agriculture",
        "citied_by": "33",
        "cover_date": "2021-11-01",
        "Abstract": "Currently, the adoption of smart technologies for sustainable farming systems creates a distinct competitive edge for farmers, extension services, agri-business, and policy-makers. However, selecting the most appropriate technologies from a wide range of options is never an easy job. In this context, several authors consider Smart Farming as the best solution. However, they fall short in providing more information to recommend the most appropriate IoT technology, the options to manage the IoT infrastructure, and the services to crop management plans and crop production estimation. This paper implements a Smart Farming System based on a three-layered architecture (Agriculture Perception, Edge Computing, and Data Analytics). In the Agriculture Perception Layer, we evaluated Omicron, Libelium, and Intel technologies under criteria such as the price, the number of inputs for sensor connection, communication protocols, portability, battery life, and harvesting energy system photovoltaic panel. We evaluated edge-based management mechanisms in the Edge Layer to provide data reliability, focusing on outlier detection and treatment using Machine Learning and Interpolation algorithms. We recommend the Isolation Forest algorithm for classifying outliers in the monthly temperature dataset (99% of precision) and the Cubic Spline technique for effectively replacing the data classified as outliers (RMSE lower than 0.085). In the Data Analytics Layer, we evaluated different machine learning algorithms to estimate coffee production. The results show that the measured error values of the XGBOOST algorithm keep the values lower than the other models (RMSE 0.008, MAE 0.032, and RSE 0.585). The www.iot-agro.com platform offers farmer services such as weather variables monitoring, coffee production estimating, and IoT infrastructure setting. Finally, stakeholders, researchers, and engineers validated our Smart Farming Solution through a Colombian coffee farm case study. The test evaluated the usability, the straightforward interpretation of data, and the look feel of the web application.",
        "DOI": "10.1016/j.compag.2021.106442",
        "affiliation_name": "Universidad del Cauca",
        "affiliation_city": "Popayan",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "Energy prediction for CNC machining with machine learning",
        "paper_author": "Brillinger M.",
        "publication": "CIRP Journal of Manufacturing Science and Technology",
        "citied_by": "75",
        "cover_date": "2021-11-01",
        "Abstract": "Nowadays, the reduction of CO2 emissions by moving from fossil to renewable energy sources is on the policy of many governments. At the same time, these governments are forcing the reduction of energy consumption. Since large industries have been in the focus for the last decade, today also small and medium enterprises with production lot size one are increasingly being obliged to reduce their energy requirements in production. Energy-efficient CNC machine tools contribute to this goal. In machining processes, the machining strategy also has a significant influence on energy demand. For manufacturing of lot size one, the prediction of the energy demand of a machining strategy, before a part is manufactured plays a decisive role. In numerous previous studies, analytical models between the energy demand and the machining strategy have been developed. However, their accuracy depends largely on the parameterization of these models by dedicated experiments. In this paper, different machine learning algorithms, especially variations of the decision tree (’DecisionTree’, ’RandomForest’, boosted ’RandomForest’) are investigated for their ability to predict the energy demand of CNC machining operations based on real production data, without the need for dedicated experiments. As shown in this paper, the most accurate energy demand predictions can be achieved with the ’RandomForest’ algorithm.",
        "DOI": "10.1016/j.cirpj.2021.07.014",
        "affiliation_name": "Technische Universitat Graz",
        "affiliation_city": "Graz",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Potential economic impacts of groundwater conservation in the Mississippi River Alluvial Aquifer (MRAA), Louisiana, USA",
        "paper_author": "Bhatta D.",
        "publication": "Natural Resource Modeling",
        "citied_by": "2",
        "cover_date": "2021-11-01",
        "Abstract": "Overextraction of groundwater reduces groundwater height, increases the energy cost, and may threaten an aquifer's economic life. Water-intensive crops, corn, and soybean, dominate the agricultural land in the Mississippi River Alluvial Aquifer (MRAA) region of the United States, thus stressing this confined aquifer. Groundwater conservation policy or the adoption of efficient irrigation technology could save both water and energy. This study aims to estimate the future returns from the irrigated land under the scenarios of 30%, 20%, 10%, 5%, and no groundwater conservation from 2020 to 2022. An accurate model to predict the crop choice decision is important to estimate the impact of groundwater policies. We develop a crop choice model where an individual farmer has a crop planting or land fallowing choice each year. We use the random forest, boosted regression trees, and support vector machine for the crop choice prediction. Boosted regression trees perform the best in our classification problem with 75.5% out of sample accuracy. The prediction model shows that the numbers of corn growers increase in the future. Our results show that the profit of 2572 farmers increased cumulatively by 0.14% when they conserve groundwater by 30% for 3 years. From a policy perspective, providing financial and technical assistant to farmers for making investments to conserve groundwater could save energy costs and sustain the economic life of the MRAA. Recommendations for Resource Managers Land allocations to water-intensive crops such as corn and soybeans will expand in Louisiana. More efficient irrigation technology may reduce the groundwater extraction volume. Groundwater extraction volume using a choice prediction model gives a more accurate account of water use compared to the status quo crop choice decision scenario. Since efficient irrigation measures do not reduce crop yield, profit from the irrigated land is higher as it reduces the extraction cost. Government cost-share to adopt efficient irrigation measures may help conserve groundwater resources.",
        "DOI": "10.1111/nrm.12330",
        "affiliation_name": "Louisiana State University",
        "affiliation_city": "Baton Rouge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Network for AI and AI for Network: Challenges and Opportunities for Learning-Oriented Networks",
        "paper_author": "Pan J.",
        "publication": "IEEE Network",
        "citied_by": "21",
        "cover_date": "2021-11-01",
        "Abstract": "The 'data pipe' model used by the existing Internet protocol stack is no longer ideal for many emerging applications, due to multimedia, multicast, mobility, machine learning, and network management challenges. A new learning-oriented network architecture is required to deal with these challenges and serve learning-centric applications in data centers, around network edges, and on mobile devices. This article focuses on the network for AI and AI for network for learning-oriented network architecture. This is done by leveraging, improving, and creating new learning techniques to determine and optimize protocol mechanisms and control policies. The new network architecture can provide ample research opportunities in network topology control, protocol design, and performance evaluation, aiming to network a truly dependable cyber-infrastructure. The learning-oriented network can also learn from applications and communications automatically and continuously while running on different infrastructures to support diverse requirements. In addition, the network can keep evolving its protocol mechanisms and control policies in an online manner. It does this while maintaining protocol security and preserving user privacy, to learn and perform more effectively and efficiently. Finally, the main challenges and opportunities of learning-oriented network are discussed, encouraging further research.",
        "DOI": "10.1109/MNET.101.2100118",
        "affiliation_name": "Huawei Technologies Co., Ltd.",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep reinforcement learning based multi-AUVs cooperative decision-making for attack–defense confrontation missions",
        "paper_author": "Xu J.",
        "publication": "Ocean Engineering",
        "citied_by": "20",
        "cover_date": "2021-11-01",
        "Abstract": "This paper mainly focuses on using deep reinforcement learning (RL) to deal with the cooperative decision-making problem of multiple Autonomous Underwater Vehicles (multi-AUVs) under limited perception and limited communication in attack–defense confrontation missions. Firstly, a novel Coding-Convolutional Network (CCN) is proposed, which can encode the raw sensor information of AUVs and extract representative features from limited perception. Secondly, utilizing the approximator of the state value function and policy function composed of CCN and fully connected network, we put forward a centralized decision-making architecture for multi-AUVs system based on actor–critic framework and give the corresponding algorithm combined with asynchronous training. Moreover, with respect to multi-AUVs attack–defense confrontation tasks, we develop a simulation platform to train and evaluate the proposed algorithms under different parameters. It can be directly observed from the visualization of the simulation that the algorithm enables multi-AUVs to complete the attack–defense confrontation missions excellently and generate some interesting collaborative behaviors. The average winning probability data of the simulation results also indicate that the designed method is feasible for multi-AUVs to achieve cooperative decision-making in attack–defense confrontation missions.",
        "DOI": "10.1016/j.oceaneng.2021.109794",
        "affiliation_name": "Harbin Engineering University",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The future of labor unions in the age of automation and at the dawn of AI",
        "paper_author": "Nissim G.",
        "publication": "Technology in Society",
        "citied_by": "45",
        "cover_date": "2021-11-01",
        "Abstract": "The COVID-19 crisis has accelerated an already-ongoing process of massive digitalization in economic production and services. AI and robotics are getting, for the first time, autonomous and self-learning, with human-like capabilities. The discussion about digitalization and the future of work has become even more imperative. So far, labor unions were the leading institutions representing employees. However, the rising possibility of human substitution by intelligent machines puts in question the feasibility of labor unions’ policies. This development undermines their traditional power sources, which depend on the membership of masses of paid workers and on their ability to stop production. In this context, this paper aims to discuss the challenges confronting unions in capitalist democracies. Most scholarly literature on labor relations has embraced the assumption that the digital revolution will eventually bring new, better jobs. We suggest considering an alternative scenario, namely, a digital revolution that causes mass replacement of human workers and structural, technological unemployment, which might expand our point of view, particularly for designing public policy. We suggest that unions now have two crucial roles. The first is to safeguard workers' rights and interests in the transition from an economy based on paid labor to an economy based on automated-autonomous production; and second, they should transform their primary calling from representing employees to representing the social rights of all citizens, and particularly the material interests of lay people.",
        "DOI": "10.1016/j.techsoc.2021.101732",
        "affiliation_name": "Ruppin Academic Center",
        "affiliation_city": "Emek Hefer",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Holding out the promise of Lasswell's dream: Big data analytics in public policy research and teaching",
        "paper_author": "El-Taliawi O.G.",
        "publication": "Review of Policy Research",
        "citied_by": "16",
        "cover_date": "2021-11-01",
        "Abstract": "While the emergence of big data raises concerns regarding governance and public policy, it also creates opportunities for diversifying the toolkit for analysis for the policy sciences as a whole, i.e., research concerning policy analysis as well as policy studies. Further, it opens avenues for practice, which together with research requires adaptation in teaching curricula if policy education were to remain relevant. However, it is not clear to what extent this opportunity is being realized in public policy research and teaching. In this study, we examine the prevalence of big data analytics in public policy research and pedagogy using bibliometric analysis and topic modeling for the former, and content analysis of course titles and descriptions for the latter. We find that despite significant scope for application of various big data techniques, the use of these analytic techniques in public policy has been largely limited to select institutions in a few countries. Further, data science has received limited attention in policy pedagogy, once again with significant geographic variation in its prevalence. We conclude that, to stay relevant, the policy sciences need to pay more attention to the integration of big data techniques in policy research, pedagogy, and thereby practice.",
        "DOI": "10.1111/ropr.12448",
        "affiliation_name": "Faculteit Techniek, Bestuur en Management, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Service-Driven Modeling Approach to Managing Water Allocation in Priority Doctrine Regions",
        "paper_author": "Zhao T.",
        "publication": "Journal of Water Resources Planning and Management",
        "citied_by": "2",
        "cover_date": "2021-11-01",
        "Abstract": "This work focuses on developing methods to better manage significant imbalances between water supply and demand during droughts. A service-driven approach (Model as a Service, or MaaS) is used to couple river modeling services with optimization services for determining optimal water allocation strategies under daily drought scenarios. It demonstrates the promise of coupling simulation-optimization model services to improve real-time water management in a service driven framework, which should be beneficial to many other water resource applications. The approach is implemented using the DataWolf workflow tool and AzureML Cloud machine learning services and applied to an April 2015 drought event in the Upper Guadalupe River Basin, Texas. Weather and water demand uncertainty are considered through scenario-based optimization. The optimization objective is to minimize the daily total curtailment hours across all groups of permit holders. The scenario analysis shows that the current permit grouping system has a significant impact on the optimal water allocation strategy. The scenarios also demonstrate that noncompliance of junior water users is predicted to have a much greater effect on the river system than noncompliance of senior water users. The resulting framework can be deployed for water allocation in any area by updating water user information, water allocation policy constraints, and river data that can be obtained from publicly available sources.",
        "DOI": "10.1061/(ASCE)WR.1943-5452.0001463",
        "affiliation_name": "Bobby B. Lyle School of Engineering",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reduced-form factor augmented VAR—Exploiting sparsity to include meaningful factors",
        "paper_author": "Beyeler S.",
        "publication": "Journal of Applied Econometrics",
        "citied_by": "4",
        "cover_date": "2021-11-01",
        "Abstract": "Induced sparsity in the factor loading matrix identifies the factor basis, while rotational identification is obtained ex post by clustering methods closely related to machine learning. We extract meaningful economic concepts from a high-dimensional data set, which together with observed variables follow an unrestricted, reduced-form VAR process. Including a comprehensive set of economic concepts allows reliable, fundamental structural analysis, even of the factor augmented VAR itself. We illustrate this by combining two structural identification methods to further analyze the model. To account for the shift in monetary policy instruments triggered by the Great Recession, we follow separate strategies to identify monetary policy shocks. Comparing ours to other parametric and non-parametric factor estimates uncovers advantages of parametric sparse factor estimation in a high dimensional data environment. Besides meaningful factor extraction, we gain precision in the estimation of factor loadings.",
        "DOI": "10.1002/jae.2852",
        "affiliation_name": "Studienzentrum Gerzensee - Stiftung der Schweizerischen Nationalbank",
        "affiliation_city": "Gerzensee",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Scattered woody vegetation promotes European brown hare population",
        "paper_author": "Johann F.",
        "publication": "Basic and Applied Ecology",
        "citied_by": "8",
        "cover_date": "2021-11-01",
        "Abstract": "European brown hare populations have declined during the last decades. Agricultural intensification has been identified as a relevant driver of this process and agri-environment schemes have been implemented to foster biodiversity in agricultural landscapes. Because species-specific outcomes of measures strongly depend on tailored design of the policy framework and the local management, while changing climate may pose additional challenges, policy and management need science-based information of which landscape composition should be promoted to achieve set biodiversity goals. Here, we used direct observations of European brown hares over 20 years for evaluating the effects of landscape composition and weather conditions on European brown hare density. For the first time, our analysis compared the estimates of machine learning (gradient boosting machine) and linear mixed models in terms of importance of a wide range of explanatory variables for European brown hare densities and effect trends. Scattered woody vegetation, as represented by the two variables transitional woodland-shrub and small woody features, was on top rankings among the predictors and greater proportions of these elements were accompanied by sharp increases of European brown hare density. Also warmer winter temperature had a positive effect. We conclude that promoting scattered woody vegetation in agricultural landscapes is a powerful tool for improving European brown hare habitat quality. Particularly with the increasing dynamic in agriculture due to climate change, incentives and regulations that create a long-lasting heterogeneity in the landscape composition through near-natural elements can support the population of this popular mammal.",
        "DOI": "10.1016/j.baae.2021.08.012",
        "affiliation_name": "Universität Freiburg",
        "affiliation_city": "Freiburg im Breisgau",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Education response to COVID 19 pandemic, a special issue proposed by UNICEF: Editorial review",
        "paper_author": "Reuge N.",
        "publication": "International Journal of Educational Development",
        "citied_by": "73",
        "cover_date": "2021-11-01",
        "Abstract": "This editorial paper presents 11 papers related to the special issue proposed by UNICEF on the Education Response to COVID-19. The COVID-19 pandemic provoked an education emergency of unprecedented scale. At its onset in February 2020, school closures were announced in the worst-hit countries. At the peak of the crisis, 90 per cent of learners worldwide had had their education disrupted. Some learners, especially those from the most marginalised population groups, were put at risk of permanent dropout, provoking long-term and significant negative effects on children's life-long wellbeing and the socio-economic development of their communities and countries. This special issue, which received contributions from UNICEF staff and various researchers, focuses on the impact of school closures, the effectiveness of remote learning solutions, equity implications, the mitigation of learning loss and notions around re-opening better. Different research perspectives and evidence is gathered to help strengthen policy considerations and future planning. The conclusion emphasizes building on the innovative solutions generated by the response to the crisis to make education systems more resilient, whilst also reinforcing the focus on equity and inclusion so that pre-existing disparities are not exacerbated in the future.",
        "DOI": "10.1016/j.ijedudev.2021.102485",
        "affiliation_name": "UNICEF",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reinforcement learning vibration control for a flexible hinged plate",
        "paper_author": "Qiu Z.c.",
        "publication": "Aerospace Science and Technology",
        "citied_by": "20",
        "cover_date": "2021-11-01",
        "Abstract": "A reinforcement learning (RL) vibration control method for a flexible hinged plate is developed, including combined bending and torsional vibrations. The experimental setup is constructed. Two laser displacement sensors are used as detection sensors, and two-channel piezoelectric actuators are used to suppress both bending and torsional vibrations simultaneously. A method combining finite element modeling (FEM) and experimental identification is applied to obtain an accurate model of the system. The obtained model is constructed as an RL environment, and a deep deterministic policy gradient (DDPG) RL algorithm based on the priority experience replay (PER) is designed to train modal controllers. The RL modal controllers were transferred to the real experimental system by using the parameter transfer method, and the vibration control experiments were conducted by combining the bending and torsional vibration control method. Simulation and experimental results demonstrate that the controller trained by the proposed deep RL algorithm has better control effects compared with PD control, especially for small amplitude vibration.",
        "DOI": "10.1016/j.ast.2021.107056",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reinforcement Learning for Compensating Power Excursions in Amplified WDM Systems",
        "paper_author": "Freire-Hermelo M.",
        "publication": "Journal of Lightwave Technology",
        "citied_by": "10",
        "cover_date": "2021-11-01",
        "Abstract": "Wavelength-dependent power excursions in gain-controlled erbium doped fiber amplifiers (EDFA) is a challenging issue in optical networks. We investigate a launch channel power control method using reinforcement learning (RL) to mitigate the power excursions of EDFA systems. A machine learning engine is developed, trained and evaluated with four different policy-gradient RL algorithms that are compared according to two main criteria: achieved power excursion reduction and learning time. Different scenarios are considered with 12-, 24-, 40- active channels at fixed wavelengths and with variable number of active channels (between 12 and 64) assigned randomly at different wavelengths during RL process. We show 62% power excursion reduction in the 40-channel scenario and 28% in the variable scenario, which demonstrates the promising role of online RL approach for controlling power excursion in EDFA systems.",
        "DOI": "10.1109/JLT.2021.3107774",
        "affiliation_name": "Institut Polytechnique de Paris",
        "affiliation_city": "Palaiseau",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Artificial Intelligence: Guidance for clinical imaging and therapeutic radiography professionals, a summary by the Society of Radiographers AI working group",
        "paper_author": "Malamateniou C.",
        "publication": "Radiography",
        "citied_by": "39",
        "cover_date": "2021-11-01",
        "Abstract": "Introduction: Artificial intelligence (AI) has started to be increasingly adopted in medical imaging and radiotherapy clinical practice, however research, education and partnerships have not really caught up yet to facilitate a safe and effective transition. The aim of the document is to provide baseline guidance for radiographers working in the field of AI in education, research, clinical practice and stakeholder partnerships. The guideline is intended for use by the multi-professional clinical imaging and radiotherapy teams, including all staff, volunteers, students and learners. Methods: The format mirrored similar publications from other SCoR working groups in the past. The recommendations have been subject to a rapid period of peer, professional and patient assessment and review. Feedback was sought from a range of SoR members and advisory groups, as well as from the SoR director of professional policy, as well as from external experts. Amendments were then made in line with feedback received and a final consensus was reached. Results: AI is an innovative tool radiographers will need to engage with to ensure a safe and efficient clinical service in imaging and radiotherapy. Educational provisions will need to be proportionately adjusted by Higher Education Institutions (HEIs) to offer the necessary knowledge, skills and competences for diagnostic and therapeutic radiographers, to enable them to navigate a future where AI will be central to patient diagnosis and treatment pathways. Radiography-led research in AI should address key clinical challenges and enable radiographers co-design, implement and validate AI solutions. Partnerships are key in ensuring the contribution of radiographers is integrated into healthcare AI ecosystems for the benefit of the patients and service users. Conclusion: Radiography is starting to work towards a future with AI-enabled healthcare. This guidance offers some recommendations for different areas of radiography practice. There is a need to update our educational curricula, rethink our research priorities, forge new strong clinical-academic-industry partnerships to optimise clinical practice. Specific recommendations in relation to clinical practice, education, research and the forging of partnerships with key stakeholders are discussed, with potential impact on policy and practice in all these domains. These recommendations aim to serve as baseline guidance for UK radiographers. Implications for practice: This review offers the most up-to-date recommendations for clinical practitioners, researchers, academics and service users of clinical imaging and therapeutic radiography services. Radiography practice, education and research must gradually adjust to AI-enabled healthcare systems to ensure gains of AI technologies are maximised and challenges and risks are minimised. This guidance will need to be updated regularly given the fast-changing pace of AI development and innovation.",
        "DOI": "10.1016/j.radi.2021.07.028",
        "affiliation_name": "Oxford University Hospitals NHS Foundation Trust",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Machine Learning for User Partitioning and Phase Shifters Design in RIS-Aided NOMA Networks",
        "paper_author": "Yang Z.",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "51",
        "cover_date": "2021-11-01",
        "Abstract": "A novel reconfigurable intelligent surface (RIS) aided non-orthogonal multiple access (NOMA) downlink transmission framework is proposed. We formulate a long-term stochastic optimization problem that involves a joint optimization of NOMA user partitioning and RIS phase shifting, aiming at maximizing the sum data rate of the mobile users (MUs) in NOMA downlink networks. To solve the challenging joint optimization problem, we invoke a modified object migration automation (MOMA) algorithm to partition the users into equal-size clusters. To optimize the RIS phase shifting matrix, we propose a deep deterministic policy gradient (DDPG) algorithm to collaboratively control multiple reflecting elements (REs) of the RIS. Different from conventional training-then-testing processing, we consider a long-term self-adjusting learning model where the intelligent agent is capable of learning the optimal action for every given state through exploration and exploitation. Extensive numerical results demonstrate that: 1) The proposed RIS-aided NOMA downlink framework achieves enhanced sum data rate compared with the conventional orthogonal multiple access (OMA) framework. 2) The proposed DDPG algorithm is capable of learning a dynamic resource allocation policy in a long-term manner. 3) The performance of the proposed RIS-aided NOMA framework can be improved by increasing the granularity of the RIS phase shifts. The numerical results also show that increasing the number of reflecting elements (REs) is an efficient method to improve the sum data rate of the MUs.",
        "DOI": "10.1109/TCOMM.2021.3100866",
        "affiliation_name": "Erik Jonsson School of Engineering and Computer Science",
        "affiliation_city": "Richardson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using machine learning to improve survival prediction after heart transplantation",
        "paper_author": "Ayers B.",
        "publication": "Journal of Cardiac Surgery",
        "citied_by": "27",
        "cover_date": "2021-11-01",
        "Abstract": "Background: This study investigates the use of modern machine learning (ML) techniques to improve prediction of survival after orthotopic heart transplantation (OHT). Methods: Retrospective study of adult patients undergoing primary, isolated OHT between 2000 and 2019 as identified in the United Network for Organ Sharing (UNOS) registry. The primary outcome was 1-year post-transplant survival. Patients were randomly divided into training (80%) and validation (20%) sets. Dimensionality reduction and data re-sampling were employed during training. Multiple machine learning algorithms were combined into a final ensemble ML model. The discriminatory capability was assessed using the area under receiver-operating-characteristic curve (AUROC), net reclassification index (NRI), and decision curve analysis (DCA). Results: A total of 33,657 OHT patients were evaluated. One-year mortality was 11% (n = 3738). In the validation cohort, the AUROC of singular logistic regression was 0.649 (95% CI, 0.628–0.670) compared to 0.691 (95% CI, 0.671–0.711) with random forest, 0.691 (95% CI, 0.671–0.712) with deep neural network, and 0.653 (95% CI, 0.632–0.674) with Adaboost. A final ensemble ML model was created that demonstrated the greatest improvement in AUROC: 0.764 (95% CI, 0.745–0.782) (p <.001). The ensemble ML model improved predictive performance by 72.9% ±3.8% (p <.001) as assessed by NRI compared to logistic regression. DCA showed the final ensemble method improved risk prediction across the entire spectrum of predicted risk as compared to all other models (p <.001). Conclusions: Modern ML techniques can improve risk prediction in OHT compared to traditional approaches. This may have important implications in patient selection, programmatic evaluation, allocation policy, and patient counseling and prognostication.",
        "DOI": "10.1111/jocs.15917",
        "affiliation_name": "Massachusetts General Hospital",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Animals and AI. The role of animals in AI research and application – An overview and ethical evaluation",
        "paper_author": "Bossert L.",
        "publication": "Technology in Society",
        "citied_by": "21",
        "cover_date": "2021-11-01",
        "Abstract": "Artificial intelligence (AI) technologies and their fields of application are among the most debated developments of recent times. Although being widely discussed academically, publicly and in policy debates, certain aspects of their research, development and application are completely ignored, namely the impact AI has on animals. Animals are affected by the research on and development of this technology since it partially relies on animal testing. In addition, AI is also being applied to improve monitoring and marketing of animals in an agricultural context. We argue that it is insufficient to exclude these aspects from debates around AI. In addition to the surveillance-applications on animals, which can be evaluated as impacting them negatively, AI applications, from which individual animals can benefit, do exist. These can primarily be found in nature and wildlife conservation, as we point out at the end of the paper. By providing an overview on how these technologies are applied to animals and how this affects them, this paper aims to fill a previously existing research gap.",
        "DOI": "10.1016/j.techsoc.2021.101678",
        "affiliation_name": "Eberhard Karls Universität Tübingen",
        "affiliation_city": "Tubingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Exploring the multidimensional effects of human activity and land cover on fire occurrence for territorial planning",
        "paper_author": "Carrasco J.",
        "publication": "Journal of Environmental Management",
        "citied_by": "21",
        "cover_date": "2021-11-01",
        "Abstract": "The strong link between climate change and increased wildfire risk suggests a paradigm change on how humans must co-exist with fire and the environment. Different studies have demonstrated that human-induced fire ignitions can account for more than 90 % of forest fires, so human co-existence with wildfires requires informed decision making via preventive policies in order to minimize risk and adapt to new conditions. In this paper, we address the multidimensional effects of three groups of drivers (human activity, geographic and topographic, and land cover) that can be managed to assist in territorial planning under fire risk. We found critical factors of strong interactions with the potential to increase the likelihood of starting a fire. Our solution approach included the application of a Machine Learning method called Random Undersampling and Boosting (RUSBoost) to assess risk (fire occurrence probability), which was subsequently accompanied by a sensitivity analysis that revealed interactions of various levels of risk. The prediction performance of the proposed model was assessed using several statistical measures such as the Receiver Operating Characteristic curve (ROC) and the Area Under the Curve (AUC). The results confirmed the high accuracy of our model, with an AUC of 0.967 and an overall accuracy over test data of 93.01 % after applying a Bayesian approach for hyper-parameter optimization. The study area to test our solution approach comprised the entire geographical territory of central Chile.",
        "DOI": "10.1016/j.jenvman.2021.113428",
        "affiliation_name": "Instituto Sistemas Complejos de Ingeniería",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile"
    },
    {
        "paper_title": "Automated Identification of Substantial Changes in Construction Projects of Airport Improvement Program: Machine Learning and Natural Language Processing Comparative Analysis",
        "paper_author": "Khalef R.",
        "publication": "Journal of Management in Engineering",
        "citied_by": "40",
        "cover_date": "2021-11-01",
        "Abstract": "Contractual changes - mainly substantial changes - within airport improvement program (AIP) projects represent a critical risk that could result in severe negative time and cost impacts. It is critical for airport projects to have in place efficient procedures to process changes effectively, or otherwise this may create an administrative choke point for their stakeholders. Further, with the current US airport infrastructure scoring a D+ (i.e., lacking behind the general US infrastructure), associated authorities called for rebuilding the US airport infrastructure. Thus, it is expected that contractual changes are going to increase for current as well as future US airport projects. This makes it critical to identify these changes early on to incorporate proper change management strategies. However, analysis of contract documents is a process that is known to be inefficient, tedious, and prone to human error. The goal of this research is to create an automated framework to predict substantial contractual changes effectively and efficiently within AIP construction projects. An independent multistep research methodology was used based on principles of natural language processing (NLP) and machine learning techniques (ML). First, the authors adopted a data set containing 876 contractual changes made to the Federal Aviation Administration (FAA) document of guidelines and policies that govern AIP projects (FAA 5100.38D). Second, the authors used NLP techniques to preprocess the aforementioned data. Third, the authors developed hyperparameter-tuned ML models, including k-nearest neighbor (KNN), support vector machine (SVM), random forest (RF), artificial neural network (ANN), extreme gradient boosting (XGBoost), and logistic regression (LR) to predict substantial changes made to the FAA 5100.38D. Accordingly, results indicate that RF showed the most accurate prediction with an area under curve (AUC) value of 0.928, a testing accuracy of 87.45%, and a mean cross-validation accuracy of 92.67%. As such, this automated framework grants stakeholders associated with AIP construction projects a computational decision support tool to easily recognize substantial changes within contract documents, both efficiently and effectively. Ultimately, this research promotes better change management implementation and supports overall AIP project success.",
        "DOI": "10.1061/(ASCE)ME.1943-5479.0000959",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Rolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A prediction-based model for virtual machine live migration monitoring in a cloud datacenter",
        "paper_author": "Motaki S.E.",
        "publication": "Computing",
        "citied_by": "14",
        "cover_date": "2021-11-01",
        "Abstract": "Live migration of virtual machines proves to be inexorable in providing load balancing among physical devices and allowing scalability and flexibility in resource allocation. The existing approaches exhibit different policies, distinct performance characteristics, and side effects such as power consumption and performance degradation. Therefore, determining the most optimal live migration algorithm in certain situations remains an open challenge. In this work, a new prediction-based model to manage the live migration process of VMs is introduced. Our adaptive model dynamically identifies the optimal live migration algorithm for a given performance metric based on a prior diagnosis of the system. The model is developed by considering the assumption of different workloads alongside certain resource constraints for any of the currently available migration algorithms. The proposed model consists of an ensemble-learning strategy that involves linear and non-parametric regression methods to predict six live migration key metrics, provided by the operator and/or the user, for each live migration algorithm. Our model allows considering the best combination which is constituted of the algorithm-metric pair to migrate a VM. The experimental results show that the proposed model allows to significantly alleviate the service level agreement violation rate by between 31 % and 60 % , along with decreasing the total CPU time required for the prediction process.",
        "DOI": "10.1007/s00607-021-00981-3",
        "affiliation_name": "Université de Caen Normandie",
        "affiliation_city": "Caen",
        "affiliation_country": "France"
    },
    {
        "paper_title": "The story of five MENA cities: Urban growth prediction modeling using remote sensing and video analytics",
        "paper_author": "Jaad A.",
        "publication": "Cities",
        "citied_by": "28",
        "cover_date": "2021-11-01",
        "Abstract": "Most urban areas in the Middle East and North Africa (MENA) region have experienced unprecedented growth rates over the past few decades to absorb population increase and hefty migration from surrounding rural and/or politically unstable areas. Such expedited urbanization presents substantial stresses to these urban areas' ecological and financial resources, as well as to the overall well-being of their residents. This paper studies the urban growth pattern in five major cities in the MENA region including Dubai (United Arab Emirates (UAE)), Cairo (Egypt), Doha (Qatar), Casablanca (Morocco), and Riyadh (Kingdom of Saudi Arabia (KSA)). The study adopts a machine learning (ML)-based modeling framework, which integrates remote sensing and computer vision technologies to generate high-fidelity urban growth prediction with limited data requirements. The framework treats successive satellite images for the urban area under study as a video for which a future frame is constructed to present the predicted growth in a specific target year. The methodology is shown to produce growth prediction results that are consistent with previous studies conducted for these five cities. The obtained results are used to derive several recommendations to assist in developing sustainable growth policies for these cities.",
        "DOI": "10.1016/j.cities.2021.103393",
        "affiliation_name": "Bobby B. Lyle School of Engineering",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Patterns in environmental priorities revealed through government open data portals",
        "paper_author": "Lim T.C.",
        "publication": "Telematics and Informatics",
        "citied_by": "4",
        "cover_date": "2021-11-01",
        "Abstract": "The ways in which environmental priorities are framed are varied and influenced by political forces. One technological advance–the proliferation of government open data portals (ODPs)–has the potential to improve governance through facilitating access to data. Yet it is also known that the data hosted on ODPs may simply reflect the goals and interests of multiple levels of political power. In this article, I use traditional statistical correlation and regression techniques along with newer natural language processing and machine learning algorithms to analyze the corpus of datasets hosted on government ODPs (total: 49,066) to extract patterns that relate scales of governance and political liberalism/conservatism to the priorities and meaning attached to environmental issues. I find that state-level and municipal-level ODPs host different categories of environmental datasets, with municipal-level ODPs generally hosting more datasets pertaining to services and amenities and state-level ODPs hosting more datasets pertaining to resource protection and extraction. Stronger trends were observed for the influences of political conservatism/liberalism among state-level ODPs than for municipal-level ODPs.",
        "DOI": "10.1016/j.tele.2021.101678",
        "affiliation_name": "Virginia Polytechnic Institute and State University",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Basin-wide flood depth and exposure mapping from SAR images and machine learning models",
        "paper_author": "Hao C.",
        "publication": "Journal of Environmental Management",
        "citied_by": "27",
        "cover_date": "2021-11-01",
        "Abstract": "Recent years recorded an increasing number of short duration – high-intensity rainfall events in the Indian subcontinent consequent with urban and riverine flash floods. Rapid assessments of flooded areas are key for effective mitigation strategies and disaster risk plans, as well as to prepare operative policies for future events. Herein, we present an integrated methodology for rapidly mapping the flood extent, and depths based on Synthetic Aperture Radar (SAR) images and a digital elevation model (DEM). Incessant rain during August 2019 brought heavy riverine flooding in southern India, killed at least 280 people, and displaced about one million inhabitants from low-lying areas. We used SAR images by Sentinel-1 before, and during the flooding, and the MERIT DEM which enabled us to map the flood extent and flood depth of the inundation zones. Because the coverage of Sentinel-1 scene was limited to the Kabini river section during the flood period, flood extent and depth maps for the adjacent basin was generated by mapping the susceptibility for flooding using the training set obtained from the flood time Sentinel-1 images, and a set of predictive variables derived from DEM using random forest model. Qualitative analysis and cross-comparison with a numerical flood model proved the proposed approach is highly reliable with an accuracy value of 90% and 86% respectively for training and validation data, thus allowing a precise, simple, and fast flood mapping. The methodology presented here could be applied to other flooded areas having incomplete inventory in the context of flood risk assessment.",
        "DOI": "10.1016/j.jenvman.2021.113367",
        "affiliation_name": "Indian Institute of Technology Gandhinagar",
        "affiliation_city": "Gandhinagar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A novel deep reinforcement learning enabled sparsity promoting adaptive control method to improve the stability of power systems with wind energy penetration",
        "paper_author": "Zhang G.",
        "publication": "Renewable Energy",
        "citied_by": "31",
        "cover_date": "2021-11-01",
        "Abstract": "With increasing proportion of wind energy in power systems, the intermittence of such energy makes the system run a wide range of operating conditions. In this context, ordinary power system stabilizers (PSS) tuned based on the linearized model of the system at one operating condition may not be able to effectively damp low frequency oscillations (LFO), which brings great challenges to the stability of the system. To this end, this paper proposes a novel sparsity promoting adaptive control method for the online self-tuning of the PSS parameter settings. Different from the existing adaptive control methods, the proposed method combines deep deterministic policy gradient (DDPG) algorithm and sensitivity analysis theory to train an agent to learn the sparse coordinated control policy of multi-PSS. After training, the well-trained agent can be employed for online sparse coordinated adaptive control, and the control signal is only applied, when it is required and only to the key PSS parameters that have the maximum influence on the system stability. Simulation results verify that the proposed method can make the PSS achieve the better performance of damping oscillation and robustness against the change of wind energy in comparison with other methods.",
        "DOI": "10.1016/j.renene.2021.06.081",
        "affiliation_name": "Aalborg University",
        "affiliation_city": "Aalborg",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Implementation of solar energy in smart cities using an integration of artificial neural network, photovoltaic system and classical Delphi methods",
        "paper_author": "Ghadami N.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "138",
        "cover_date": "2021-11-01",
        "Abstract": "Energy supply of megacities is considered as an active research topic in the new aspects of urban management, especially in developing countries like Iran. With an introduction to the sustainable development goals, the smart city concept presents a novel idea for providing energy in a city with the use of Artificial Intelligence (AI), renewable energy, such as Photovoltaic (PV) technologies, and Transformational Participation (TP) based on motivational programs for citizens. This study aims to evaluate the electrical energy consumption in Mashhad, Iran, based on machine learning tools and present the dynamic strategies for promoting citizens’ willingness for renewable energy generation based on the experts’ knowledge. The main novelty of this research is simultaneous application of Artificial Neural Network (ANN) and statistical analysis for creating a Decision Support System (DSS). Then, the solar energy potential is appraised by the PV system simulation tool during one year in our case study in Mashhad, Iran. Furthermore, a Classical Delphi (CD) method is applied for motivational strategies and further TP implementation. In particular, the motivational strategies are suggested by 45 experts and then are prioritized in sequential expert meetings. The outcomes of this research indicate that the ANN model can successfully forecast the electrical energy consumption in summer and winter periods with a 99% accuracy. Then, based on the solar energy computations in the PV system, the peak of electrical energy consumption can be controlled in the hottest and coldest months. Last but not least, the superposition of experts’ and citizens’ opinions reveal A4 (sharing benefits of optimized costs with the citizens by solar energy generation), B2 (reducing the electrical energy cost for solar energy generation, especially in peak times) and C1 (creating the energy coin in the city with credits instead of spending money in urban activities fits to solar energy generation) as the main motivational strategies for solar energy generation in short, middle and long-term planning horizons.",
        "DOI": "10.1016/j.scs.2021.103149",
        "affiliation_name": "Islamic Azad University, West Tehran Branch",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "A taxonomical review on recent artificial intelligence applications to PV integration into power grids",
        "paper_author": "Feng C.",
        "publication": "International Journal of Electrical Power and Energy Systems",
        "citied_by": "51",
        "cover_date": "2021-11-01",
        "Abstract": "The exponential growth of solar power has been witnessed in the past decade and is projected by the ambitious policy targets. Nevertheless, the proliferation of solar energy poses challenges to power system operations, mostly due to its uncertainty, locational specificity, and variability. The prevalence of smart grids enables artificial intelligence (AI) techniques to mitigate solar integration problems with massive amounts of solar energy data. Different AI subfields (e.g., machine learning, deep learning, ensemble learning, and metaheuristic learning) have brought breakthroughs in solar energy, especially in its grid integration. However, AI research in solar integration is still at the preliminary stage, and is lagging behind the AI mainstream. Aiming to inspire deep AI involvement in the solar energy domain, this paper presents a taxonomical overview of AI applications in solar photovoltaic (PV) systems. Text mining techniques are first used as an assistive tool to collect, analyze, and categorize a large volume of literature in this field. Then, based on the constructed literature infrastructure, recent advancements in AI applications to solar forecasting, PV array detection, PV system fault detection, design optimization, and maximum power point tracking control problems are comprehensively reviewed. Current challenges and future trends of AI applications in solar integration are also discussed for each application theme.",
        "DOI": "10.1016/j.ijepes.2021.107176",
        "affiliation_name": "Erik Jonsson School of Engineering and Computer Science",
        "affiliation_city": "Richardson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Transmission trend of the COVID-19 pandemic predicted by dendritic neural regression",
        "paper_author": "Dong M.",
        "publication": "Applied Soft Computing",
        "citied_by": "17",
        "cover_date": "2021-11-01",
        "Abstract": "In 2020, a novel coronavirus disease became a global problem. The disease was called COVID-19, as the first patient was diagnosed in December 2019. The disease spread around the world quickly due to its powerful viral ability. To date, the spread of COVID-19 has been relatively mild in China due to timely control measures. However, in other countries, the pandemic remains severe, and COVID-19 protection and control policies are urgently needed, which has motivated this research. Since the outbreak of the pandemic, many researchers have hoped to identify the mechanism of COVID-19 transmission and predict its spread by using machine learning (ML) methods to supply meaningful reference information to decision-makers in various countries. Since the historical data of COVID-19 is time series data, most researchers have adopted recurrent neural networks (RNNs), which can capture time information, for this problem. However, even with a state-of-the-art RNN, it is still difficult to perfectly capture the temporal information and nonlinear characteristics from the historical data of COVID-19. Therefore, in this study, we develop a novel dendritic neural regression (DNR) method to improve prediction performance. In the DNR, the multiplication operator is used to capture the nonlinear relationships between input feature signals in the dendrite layer. Considering the complex and large landscape of DNR's weight space, a new scale-free state-of-matter search (SFSMS) algorithm is proposed to optimize the DNR, which combines the state-of-matter search algorithm with a scale-free local search. The SFSMS achieves a better global search ability and thus can effectively reduce the possibility of falling into local minima. In addition, according to Takens's theorem, phase space reconstruction techniques are used to discover the information hidden in the high-dimensional space of COVID-19 data, which further improves the precision of prediction. The experimental results suggest that the proposed method is more competitive in solving this problem than other prevailing methods.",
        "DOI": "10.1016/j.asoc.2021.107683",
        "affiliation_name": "University of Toyama",
        "affiliation_city": "Toyama",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Contributions of internal emissions to peaks and incremental indoor PM<inf>2.5</inf> in rural coal use households",
        "paper_author": "Men Y.",
        "publication": "Environmental Pollution",
        "citied_by": "39",
        "cover_date": "2021-11-01",
        "Abstract": "Indoor air quality is critically important to the human as people spend most time indoors. Indoor PM2.5 is related to the outdoor levels, but more directly influenced by internal sources. Severe household air pollution from solid fuel use has been recognized as one major risk for human health especailly in rural area, however, the issue is significantly overlooked in most national air quality controls and intervention policies. Here, by using low-cost sensors, indoor PM2.5 in rural homes burning coals was monitored for ~4 months and analyzed for its temporal dynamics, distributions, relationship with outdoor PM2.5, and quantitative contributions of internal sources. A bimodal distribution of indoor PM2.5 was identified and the bimodal characteristic was more significant at the finer time resolution. The bimodal distribution maxima were corresponding to the emissions from strong internal sources and the influence of outdoor PM2.5, respectively. Indoor PM2.5 was found to be correlated with the outdoor PM2.5, even though indoor coal combustion for heating was thought to be predominant source of indoor PM2.5. The indoor-outdoor relationship differed significantly between the heating and non-heating seasons. Impacts of typical indoor sources like cooking, heating associated with coal use, and smoking were quantitatively analyzed based on the highly time-resolved PM2.5. Estimated contribution of outdoor PM2.5 to the indoor PM2.5 was ~48% during the non-heating period, but decreased to about 32% during the heating period. The contribution of indoor heating burning coals comprised up to 47% of the indoor PM2.5 during the heating period, while the other indoor sources contributed to ~20%. The study, based on a relatively long-term timely resolved PM2.5 data from a large number of rural households, provided informative results on temporal dynamics of indoor PM2.5 and quantitative contributions of internal sources, promoting scientific understanding on sources and impacts of household air pollution.",
        "DOI": "10.1016/j.envpol.2021.117753",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Service Research Priorities: Designing Sustainable Service Ecosystems",
        "paper_author": "Field J.M.",
        "publication": "Journal of Service Research",
        "citied_by": "110",
        "cover_date": "2021-11-01",
        "Abstract": "This article utilizes input from service scholars, practitioners, reviews of published literature, and influential policy documents to identify service research priorities that push the boundaries of extant research. In a companion piece, we focused on four service research priorities related to managing and delivering service in turbulent times. Further, we identified a set of stakeholder-wants from the literature and included research questions that tie key stakeholder-wants to each of the three priorities in this article and the four priorities in the companion article. Here, we highlight the critical importance of scholarship and practice related to the design of sustainable service ecosystems and discuss three key service research priorities: large-scale and complex service ecosystems for transformative impact (SRP5), platform ecosystems and marketplaces (SRP6), and services for disadvantaged consumers and communities (SRP7). We call for an engaged service scholarship that considers the interrelationships among consumers, organizations, employees, platforms, and societal institutions and pursues transformative goals.",
        "DOI": "10.1177/10946705211031302",
        "affiliation_name": "Boston College",
        "affiliation_city": "Chestnut Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Are pre-service teachers disinclined to utilise embodied humanoid social robots in the classroom?",
        "paper_author": "Istenic A.",
        "publication": "British Journal of Educational Technology",
        "citied_by": "25",
        "cover_date": "2021-11-01",
        "Abstract": "Teachers' readiness for technology integration depends also on their beliefs about the contribution of technology to teaching and learning, which influence their motivation for its adoption. Initial pre-service teacher education is critical in reducing the attitude-behaviour divide supporting technology acceptability, acceptance and use. Acceptance of interaction between human and robot is more complicated than human-computer interaction acceptance. Social robots are radical innovations, harder for potential users to accept in human social spaces than are incremental innovations. In 2019, a survey using a convenience sample of 121 first-year students was conducted to examine pre-service teachers' beliefs about social robot educational technology. It examined the following factors derived from the Unified Theory of Acceptance and Use of Technology adopted for social robots in education: Perceived social dimension, Intention to use, Perceived usability, Anxiety. Based on our findings, it seems there is a critical disjunction between researchers' efforts to equip social robots with human manners and social intelligence and participants' rejection of this technology precisely because it mimics being human. Further, we report that ICT familiarity as assessed using PISA's Information Communication Technology—ICT familiarity factors is related to robot acceptability. These findings need further examination to inform educational robotics design and Human-Robot Interaction research and teacher education and training. Practitioners notes What is already known about this topic In the age of robotic technology, teachers face requirements to prepare students for work and life with social robots. Social robots are tested for classroom integration. Teachers' readiness to implement robot lessons depends on their beliefs about social robotic technology's contribution to teaching. Research and development in the field of social robotics still tend to focus more frequently on technology applications rather than pedagogical issues and advancing teaching and learning. What this paper adds Participants refuse to accept the idea of social robot-based instruction. The identified belief pattern is based mainly on the perceived social dimension, intention to use, perceived usability and anxiety. Participants critically perceive the robot's social dimension. Some of PISA's ICT familiarity factors are related to robots acceptability factors. Implication for policy and/or practice The policy and practice need to address how social robots could be integrated into current teaching and learning practices and more importantly how could robotic technology facilitate innovative pedagogical models for effective and efficient learning. The introduction of social robots should follow instructional design requirements and not merely technological advancement. Teacher initial education has to provide social robotic learning environments for pre-service teachers to experiment and design.",
        "DOI": "10.1111/bjet.13144",
        "affiliation_name": "Kazan Federal University",
        "affiliation_city": "Kazan",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Disparities and drivers of the water footprint of food consumption in China",
        "paper_author": "Pang Z.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "8",
        "cover_date": "2021-11-01",
        "Abstract": "Food production requires a large amount of water. As a country facing a serious scarcity of per capita water resources and severe water pollution, China must explore the spatial distribution characteristics of its dietary water footprint. China is the world’s largest developing country, and water consumption inevitably has increased with its economic development. It is essential to explore the factors influencing the water footprint and water conservation mechanisms. Based on China Health and Nutrition Survey (CHNS) data, individual-level data of dietary water footprint and residents’ socio-economic characteristics were obtained. The decision tree was applied to classify the dietary water footprint based on socio-economic factors, and multinomial logistic regression was then performed to investigate the influence of each factor. The results showed that all six selected socio-economic factors had a statistically significant impact on the dietary water footprint. Income and education level were positively related to the dietary water footprint; urban residents, males, and residents with a higher body mass index (BMI) consumed more dietary water than rural residents, females, and those with a lower BMI, respectively. Age exhibited an inverted U-shaped influence. Understanding the drivers and disparities of the water footprint of food consumption can support the development of policy for energy conservation, which can ultimately help achieve the goal of reducing water waste.",
        "DOI": "10.1007/s11356-021-15125-5",
        "affiliation_name": "Zhejiang University of Technology",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Advanced extreme learning machines vs. deep learning models for peak wave energy period forecasting: A case study in Queensland, Australia",
        "paper_author": "Ali M.",
        "publication": "Renewable Energy",
        "citied_by": "32",
        "cover_date": "2021-11-01",
        "Abstract": "The peak period of an energy-generating wave is one of the most important parameters that describe the spectral shape of the oceanic wave, as this indicates the duration for which the waves prevail with respect to their maximum extractable energy. In this paper, a half-hourly peak wave energy period (TP) forecast model is constructed using a suite of statistically significant lagged inputs based on the partial auto-correlation function with an extreme learning machine model developed and its predictive utility is benchmarked against deep learning models, i.e., convolutional neural network (CNN/CovNet) and recurrent neural network (RNN) models and other traditional M5tree, Conditional Maximization based Multiple Linear Regression (MLR-ECM) and MLR models. The objective model (ELM) vs. the comparison models (CNN, RNN, M5tree, MLR-ECM, and MLR) were trained and validated independently on the test dataset obtained from coastal zones of eastern Australia that have a high potential for implementation of wave energy generation systems. The outcomes ascertain that the ELM model can generate significantly accurate predictions of the half-hourly peak wave energy period, providing a good level of accuracy relative to deep learning models in selected coastal study zones. The study establishes the practical usefulness of the ELM model as being a noteworthy methodology for the applications in renewable and sustainable energy resource management systems.",
        "DOI": "10.1016/j.renene.2021.06.052",
        "affiliation_name": "Southwest University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Variational policy search using sparse Gaussian process priors for learning multimodal optimal actions",
        "paper_author": "Sasaki H.",
        "publication": "Neural Networks",
        "citied_by": "6",
        "cover_date": "2021-11-01",
        "Abstract": "Policy search reinforcement learning has been drawing much attention as a method of learning a robot control policy. In particular, policy search using such non-parametric policies as Gaussian process regression can learn optimal actions with high-dimensional and redundant sensors as input. However, previous methods implicitly assume that the optimal action becomes unique for each state. This assumption can severely limit such practical applications as robot manipulations since designing a reward function that appears in only one optimal action for complex tasks is difficult. The previous methods might have caused critical performance deterioration because the typical non-parametric policies cannot capture the optimal actions due to their unimodality. We propose novel approaches in non-parametric policy searches with multiple optimal actions and offer two different algorithms commonly based on a sparse Gaussian process prior and variational Bayesian inference. The following are the key ideas: (1) multimodality for capturing multiple optimal actions and (2) mode-seeking for capturing one optimal action by ignoring the others. First, we propose a multimodal sparse Gaussian process policy search that uses multiple overlapped GPs as a prior. Second, we propose a mode-seeking sparse Gaussian process policy search that uses the student-t distribution for a likelihood function. The effectiveness of those algorithms is demonstrated through applications to object manipulation tasks with multiple optimal actions in simulations.",
        "DOI": "10.1016/j.neunet.2021.06.010",
        "affiliation_name": "Nara Institute of Science and Technology",
        "affiliation_city": "Ikoma",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Co-occurrence balanced time series classification for the semi-supervised recognition of surgical smoke",
        "paper_author": "Reiter W.",
        "publication": "International Journal of Computer Assisted Radiology and Surgery",
        "citied_by": "7",
        "cover_date": "2021-11-01",
        "Abstract": "Purpose: Automatic recognition and removal of smoke in surgical procedures can reduce risks to the patient by supporting the surgeon. Surgical smoke changes its visibility over time, impacting the vision depending on its amount and the volume of the body cavity. While modern deep learning algorithms for computer vision require large amounts of data, annotations for training are scarce. This paper investigates the use of unlabeled training data with a modern time-based deep learning algorithm. Methods: We propose to improve the state of the art in smoke recognition by enhancing a image classifier based on convolutional neural networks with a recurrent architecture thereby providing temporal context to the algorithm. We enrich the training with unlabeled recordings from similar procedures. The influence of surgical tools on the smoke recognition task is studied to reduce a possible bias. Results: The evaluations show that smoke recognition benefits from the additional temporal information during training. The use of unlabeled data from the same domain in a semi-supervised training procedure shows additional improvements reaching an accuracy of 86.8%. The proposed balancing policy is shown to have a positive impact on learning the discrimination of co-occurring surgical tools. Conclusions: This study presents, to the best of our knowledge, the first use of a time series algorithm for the recognition of surgical smoke and the first use of this algorithm in the described semi-supervised setting. We show that the performance improvements with unlabeled data can be enhanced by integrating temporal context. We also show that adaption of the data distribution is beneficial to avoid learning biases.",
        "DOI": "10.1007/s11548-021-02411-3",
        "affiliation_name": "Wintegral GmbH",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Advanced learning-based energy policy and management of dispatchable units in smart grids considering uncertainty effects",
        "paper_author": "Han A.",
        "publication": "International Journal of Electrical Power and Energy Systems",
        "citied_by": "7",
        "cover_date": "2021-11-01",
        "Abstract": "In this paper, a new machine learning based framework is developed for the energy policy and operation management of the smart grids, utilizing advanced support vector networks in the renewable smart grids (RSGs), considering storage unit, wind and tidal systems and dispatchable units. The proposed system first develops a support vector regression (SVR) for prediction of the tidal and wind units output power with high accuracy. In the second step, an energy policy system is devised which forces the system operator to support renewable sources by guaranteeing the full purchase of their generation. In the third step, the optimal energy management framework is launched which optimizes the operation costs when considering the practical constraints. In the proposed novel framework, a new optimization method based on fuzzy dragonfly algorithm (FDA) is developed to enhance the search performance by creating adjusting fuzzy version this algorithm. In order to handle the uncertainty effects, a reduced scenario based approach is developed which shows high accuracy of 95% confidence level but with trivial computational time. The system quality is assessed on a test RSG system. The results prove the contributing claims of the research, clearly.",
        "DOI": "10.1016/j.ijepes.2021.107188",
        "affiliation_name": "Universitas Mulawarman",
        "affiliation_city": "Samarinda",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Using social media Reddit data to examine foster families' concerns and needs during COVID-19",
        "paper_author": "Lee J.Y.",
        "publication": "Child Abuse and Neglect",
        "citied_by": "20",
        "cover_date": "2021-11-01",
        "Abstract": "Background: COVID-19 is likely to have negatively impacted foster families but few data sources are available to confirm this. Objective: The current study used Reddit social media data to examine how foster families are faring in the pandemic. Discussion topics were identified and examined for changes before and after COVID-19. Participants and setting: Comments were collected from three Reddit online discussion boards dedicated to foster families (N = 11,830). Methods: We used machine learning techniques, including Latent Dirichlet Allocation, for topic modeling and textual analysis for qualitative coding of the Reddit comments. Results: Results showed that three main topics had both significant quantitative and meaningful qualitative changes before and after COVID-19. There were significant increases in conversation about becoming a foster parent (F = 5.75, p = 0.02) and activities for foster children (F = 10.61, p = 0.001), whereas there was a significant decrease in discussing permanency (F = 9.46, p = 0.003) before and after the onset of COVID-19. Qualitative coding showed that regarding the topic of becoming a parent, excitement over approval of foster care license before COVID-19 shifted to foster families' increased anxieties about delays in their licensing cases after COVID-19. For permanency, content changed from the best interest of the child and reunifications before COVID-19 to concerns over family separations and permanency challenges after COVID-19. Regarding activities for foster children, content related to everyday activities before COVID-19 changed to specific activities foster children and families could do during lockdowns. Results suggest areas child welfare workers may focus on to better support foster families during and after the pandemic.",
        "DOI": "10.1016/j.chiabu.2021.105262",
        "affiliation_name": "School of Communication and Information",
        "affiliation_city": "New Brunswick",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multiple strategies for trading short-term stock index futures based on visual trend bands",
        "paper_author": "Chou H.M.",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "3",
        "cover_date": "2021-11-01",
        "Abstract": "Many day traders focus on forecasts of stock index futures. These securities are suitable for frequent and time-sensitive trading as well as for short-term investments. However, most day traders’ strategies are based on their experiences or news headlines. Combined with a pool trading policy, this may lead to unsatisfactory average monthly profit, particularly when compared to the opportunity cost of the traders’ full-time employment in other non-trading jobs. This paper represents multiple investment strategies for day traders based on visual trend bands on short-term stock index futures. This study uses sequential minimal optimization and other machine learning algorithms to evaluate the performance of visual trend bands and derive strategies for better predictions. This study also applies empirical methods on short-term stock index futures datasets to explore the impact of visual trend bands on short-term stock index trading. The accuracy of our proposed visual trend bands reaches 82%, which is not only an objectively high forecasting accuracy rate but also substantially higher than other visual trend bands. The proposed visual trend bands can support day traders in realizing higher profits in their day trades and short-term investments.",
        "DOI": "10.1007/s11042-020-10496-2",
        "affiliation_name": "Chung Yuan Christian University",
        "affiliation_city": "Taoyuan",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Predicting the energy output of hybrid PV–wind renewable energy system using feature selection technique for smart grids",
        "paper_author": "Qadir Z.",
        "publication": "Energy Reports",
        "citied_by": "98",
        "cover_date": "2021-11-01",
        "Abstract": "In the current technological era, predicting the power and energy output based on the changing weather factors play an important role in the economic growth of the renewable energy sector. Unlike traditional fossil fuel-based resources, renewable energy sources potentially play a pivotal role in sustaining a country's economy and improving the quality of life. As our planet is nowadays facing serious challenges due to climate change and global warming, this research could be effective to achieve good prediction accuracy in smart grids using different weather conditions. In the current study, different machine learning models are compared to estimate power and energy of hybrid photovoltaic (PV)-wind renewable energy systems using seven weather factors that have a significant impact on the output of the PV–wind renewable energy system. This study classified the machine learning model which could be potentially useful and efficient to predict energy and power. The historic hourly data is processed with and without data manipulation. While data manipulations are carried out using recursive feature elimination using cross-validation (RFECV). The data is trained using artificial neural network (ANN) regressors and correlations between different features within the dataset are identified. The main aim is to find meaningful patterns that could help statistical learning models train themselves based on these usage patterns. The results suggest that opting feature selection technique using linear regression model outperforms all the other models in all evaluation metrics having to mean squared error (MSE) of 0.000000104, mean absolute error (MAE) of 0.00083, R2 of 99.6%, and computation time of 0.02 s The results investigated depict that the sustainable computational scheme introduced has vast potential to enhance smart grids efficiency by predicting the energy produced by renewable energy systems.",
        "DOI": "10.1016/j.egyr.2021.01.018",
        "affiliation_name": "UNSW Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Neural Stochastic Contraction Metrics for Learning-Based Control and Estimation",
        "paper_author": "Tsukamoto H.",
        "publication": "IEEE Control Systems Letters",
        "citied_by": "28",
        "cover_date": "2021-11-01",
        "Abstract": "We present Neural Stochastic Contraction Metrics (NSCM), a new design framework for provably-stable learning-based control and estimation for a class of stochastic nonlinear systems. It uses a spectrally-normalized deep neural network to construct a contraction metric and its differential Lyapunov function, sampled via simplified convex optimization in the stochastic setting. Spectral normalization constrains the state-derivatives of the metric to be Lipschitz continuous, thereby ensuring exponential boundedness of the mean squared distance of system trajectories under stochastic disturbances. The trained NSCM model allows autonomous systems to approximate optimal stable control and estimation policies in real-time, and outperforms existing nonlinear control and estimation techniques including the state-dependent Riccati equation, iterative LQR, EKF, and the deterministic NCM, as shown in simulation results.",
        "DOI": "10.1109/LCSYS.2020.3046529",
        "affiliation_name": "California Institute of Technology Division of Engineering and Applied Science",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Novel Bounds on the Probability of Misclassification in Majority Voting: Leveraging the Majority Size",
        "paper_author": "Cobbenhagen A.T.J.R.",
        "publication": "IEEE Control Systems Letters",
        "citied_by": "1",
        "cover_date": "2021-11-01",
        "Abstract": "Majority voting is often employed as a tool to increase the robustness of data-driven decisions and control policies, a fact which calls for rigorous, quantitative evaluations of the limits and the potentials of majority voting schemes. This letter focuses on the case where the voting agents are binary classifiers and introduces novel bounds on the probability of misclassification conditioned on the size of the majority. We show that these bounds can be much smaller than the traditional upper bounds on the probability of misclassification. These bounds can be used in a 'Probably Approximately Correct' (PAC) setting, which allows for a practical implementation.",
        "DOI": "10.1109/LCSYS.2020.3040961",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "On Distributed Model-Free Reinforcement Learning Control with Stability Guarantee",
        "paper_author": "Mukherjee S.",
        "publication": "IEEE Control Systems Letters",
        "citied_by": "2",
        "cover_date": "2021-11-01",
        "Abstract": "Distributed learning can enable scalable and effective decision making in numerous complex cyber-physical systems such as smart transportation, robotics swarm, power systems, etc. However, stability of the system is usually not guaranteed in most existing learning paradigms; and this limitation can hinder the wide deployment of machine learning in decision making of safety-critical systems. This letter presents a stability-guaranteed distributed reinforcement learning (SGDRL) framework for interconnected linear subsystems, without knowing the subsystem models. While the learning process requires data from a peer-to-peer (p2p) communication architecture, the control implementation of each subsystem is only based on its local states. The stability of the interconnected subsystems will be ensured by a diagonally dominant eigenvalue condition, which will then be used in a model-free RL algorithm to learn the stabilizing control gains. The RL algorithm structure follows an off-policy iterative framework, with interleaved policy evaluation and policy update steps. We numerically validate our theoretical results by performing simulations on four interconnected sub-systems.",
        "DOI": "10.1109/LCSYS.2020.3041218",
        "affiliation_name": "Pacific Northwest National Laboratory",
        "affiliation_city": "Richland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Early classification of multivariate data by learning optimal decision rules",
        "paper_author": "Sharma A.",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "5",
        "cover_date": "2021-11-01",
        "Abstract": "Early classification on time series has emerged as an active research area in the field of machine learning. It covers a wide range of applications in agriculture, medical and multimedia systems, including drought prediction, health monitoring, event detection, and many more. The early classification aims to predict the class label of a time series as soon as possible without waiting for the complete series. A critical issue in early classification is the learning of decision policy that determines the adequacy of the collected data required for reliable class prediction. It is more challenging for Multivariate Time Series (MTS) data, where the decision depends on multiple variables to achieve a trade-off between earliness and accuracy. Therefore, this work proposes an optimization-based early classification model for MTS data based on optimal decision rule learning. The proposed model adopts a two-layered approach. The first layer employs the Gaussian process probabilistic classifiers for each variable in MTS that provides the class probabilities at the successive time steps in the series. The second layer defines Early Stopping Rule (ESR) that performs the class prediction task. The ESR learns its parameters through the particle swarm optimization by simultaneously minimizing the misclassification cost and delaying the decision cost. This work has utilized publicly available MTS datasets to validate the proposed early classification model. The experimental results show that the proposed model achieves promising results in terms of accuracy and earliness compared to existing methods.",
        "DOI": "10.1007/s11042-020-09366-8",
        "affiliation_name": "Indian Institute of Technology (BHU) Varanasi",
        "affiliation_city": "Varanasi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "An analysis of environmental big data through the establishment of emotional classification system model based on machine learning: focus on multimedia contents for portal applications",
        "paper_author": "Park S.T.",
        "publication": "Multimedia Tools and Applications",
        "citied_by": "9",
        "cover_date": "2021-11-01",
        "Abstract": "With the advent of the Internet, there have been many changes. As existing means of off-line communication have transferred to the Internet, a wide range of multimedia services are emerging. And unlike in the past, these work as tremendous sources from which people’s opinions and attitudes can be obtained. Particularly, diverse opinions and reviews posted on the web in real time help corporations or the State establish the directions of policies. In this context, this study developed machine learning-based environment issue sentiment classifier in order to find out, from comments posted below news, how people recognize issues about climate change in terms of environment. Based on training data constructed by this study, a sentiment classification algorithm was constructed by applying SVM (support vector machine) and Naive Bayes, which are machine learning techniques, and a sentiment classifier was constructed by applying CNN (convolutional neural networks) and Bi-LSTM (bidirectional long-short term memory) techniques among deep learning techniques recently researched vigorously; and then their performance was compared.",
        "DOI": "10.1007/s11042-020-08818-5",
        "affiliation_name": "Korea Environment Institute",
        "affiliation_city": "Sejong",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Explainable AI within the digital transformation and cyber physical systems: XAI methods and applications",
        "paper_author": "Sayed-Mouchaweh M.",
        "publication": "Explainable AI Within the Digital Transformation and Cyber Physical Systems: XAI Methods and Applications",
        "citied_by": "7",
        "cover_date": "2021-10-30",
        "Abstract": "This book presents Explainable Artificial Intelligence (XAI), which aims at producing explainable models that enable human users to understand and appropriately trust the obtained results. The authors discuss the challenges involved in making machine learning-based AI explainable. Firstly, that the explanations must be adapted to different stakeholders (end-users, policy makers, industries, utilities etc.) with different levels of technical knowledge (managers, engineers, technicians, etc.) in different application domains. Secondly, that it is important to develop an evaluation framework and standards in order to measure the effectiveness of the provided explanations at the human and the technical levels. This book gathers research contributions aiming at the development and/or the use of XAI techniques in order to address the aforementioned challenges in different applications such as healthcare, finance, cybersecurity, and document summarization. It allows highlighting the benefits and requirements of using explainable models in different application domains in order to provide guidance to readers to select the most adapted models to their specified problem and conditions. • Includes recent developments of the use of Explainable Artificial Intelligence (XAI) in order to address the challenges of digital transition and cyber-physical systems; • Provides a textual scientific description of the use of XAI in order to address the challenges of digital transition and cyber-physical systems; • Presents examples and case studies in order to increase transparency and understanding of the methodological concepts.",
        "DOI": "10.1007/978-3-030-76409-8",
        "affiliation_name": "IMT Nord Europe",
        "affiliation_city": "Villeneuve-d'Ascq",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Introduction to privacy enhancing technologies: A classification-based approach to understanding PETs",
        "paper_author": "Adams C.",
        "publication": "Introduction to Privacy Enhancing Technologies: A Classification-Based Approach to Understanding PETs",
        "citied_by": "7",
        "cover_date": "2021-10-30",
        "Abstract": "This textbook provides a unique lens through which the myriad of existing Privacy Enhancing Technologies (PETs) can be easily comprehended and appreciated. It answers key privacy-centered questions with clear and detailed explanations. Why is privacy important? How and why is your privacy being eroded and what risks can this pose for you? What are some tools for protecting your privacy in online environments? How can these tools be understood, compared, and evaluated? What steps can you take to gain more control over your personal data? This book addresses the above questions by focusing on three fundamental elements: It introduces a simple classification of PETs that allows their similarities and differences to be highlighted and analyzed; It describes several specific PETs in each class, including both foundational technologies and important recent additions to the field; It explains how to use this classification to determine which privacy goals are actually achievable in a given real-world environment. Once the goals are known, this allows the most appropriate PETs to be selected in order to add the desired privacy protection to the target environment. To illustrate, the book examines the use of PETs in conjunction with various security technologies, with the legal infrastructure, and with communication and computing technologies such as Software Defined Networking (SDN) and Machine Learning (ML). Designed as an introductory textbook on PETs, this book is essential reading for graduate-level students in computer science and related fields, prospective PETs researchers, privacy advocates, and anyone interested in technologies to protect privacy in online environments.",
        "DOI": "10.1007/978-3-030-81043-6",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "QF-TraderNet: Intraday Trading via Deep Reinforcement With Quantum Price Levels Based Profit-And-Loss Control",
        "paper_author": "Qiu Y.",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "5",
        "cover_date": "2021-10-29",
        "Abstract": "Reinforcement Learning (RL) based machine trading attracts a rich profusion of interest. However, in the existing research, RL in the day-trade task suffers from the noisy financial movement in the short time scale, difficulty in order settlement, and expensive action search in a continuous-value space. This paper introduced an end-to-end RL intraday trading agent, namely QF-TraderNet, based on the quantum finance theory (QFT) and deep reinforcement learning. We proposed a novel design for the intraday RL trader’s action space, inspired by the Quantum Price Levels (QPLs). Our action space design also brings the model a learnable profit-and-loss control strategy. QF-TraderNet composes two neural networks: 1) A long short term memory networks for the feature learning of financial time series; 2) a policy generator network (PGN) for generating the distribution of actions. The profitability and robustness of QF-TraderNet have been verified in multi-type financial datasets, including FOREX, metals, crude oil, and financial indices. The experimental results demonstrate that QF-TraderNet outperforms other baselines in terms of cumulative price returns and Sharpe Ratio, and the robustness in the acceidential market shift.",
        "DOI": "10.3389/frai.2021.749878",
        "affiliation_name": "United International College",
        "affiliation_city": "Zhuhai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Hybrid Electric Vehicle Powertrain Control Based on Reinforcement Learning",
        "paper_author": "Yao Z.",
        "publication": "SAE International Journal of Electrified Vehicles",
        "citied_by": "10",
        "cover_date": "2021-10-27",
        "Abstract": "Hybrid Electric Vehicles (HEVs) achieve better fuel economy than conventional vehicles by employing two different power sources: a mechanical engine and an electrical motor. These power sources have conventionally been controlled by a rule-based algorithm or optimization-based control. Besides these conventional approaches, reinforcement learning-based control algorithms have actively been studied recently. To investigate the benefits of the reinforcement learning-based approach, a model-free control algorithm for an HEV is proposed in this article using a Twin Delayed Deep Deterministic policy gradient (TD3), which is an online, off-policy Deep Reinforcement Learning (DRL) algorithm. The effectiveness of the proposed algorithm is studied by applying the TD3 algorithm to a 48V mild HEV (MHEV) model and the optimal operating strategy is obtained for maximum fuel economy. The simulation results show that the proposed TD3-based algorithm improves the average fuel economy by 1.89% on standard driving cycles and 2.20% on real-world driving cycles when compared to the Deep Deterministic Policy Gradient (DDPG) algorithm.",
        "DOI": "10.4271/14-11-02-0013",
        "affiliation_name": "University of Alabama",
        "affiliation_city": "Florence",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Role of Remote Laboratories on STEM Education and the Digital Economy: An overview for Brazil in the 2020's",
        "paper_author": "Araújo M.M.D.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-10-26",
        "Abstract": "This article provides an overview of the current status of remote laboratories in selected engineering schools in Brazil participating in the VISIR+ project, highlighting the importance of their popularization and expansion to strengthen the countrýs effort to better educate engineers in the context of challenges and opportunities of the digital revolution for the innovation economy of the 21st century. It links this reality with the societal impacts of the digital technological revolution accelerated by Artificial Intelligence, Advanced Robotics, Machine Learning and Ubiquitous Internet. It also presents selected updated key indicators of engineering education in Brazil calling for effective policies to modernize the curricula and practices of engineering courses and training of professional engineers to meet the skills required by these new technologies and market demands. It concludes that remote laboratories are an important tool to support the countrýs efforts to succeed on a track to migrate its commodities-based economy into a more sophisticated knowledge based innovative economy.",
        "DOI": "10.1145/3486011.3486518",
        "affiliation_name": "Universidade Estadual do Rio Grande do Sul",
        "affiliation_city": "Porto Alegre",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Causal-Aware Generative Imputation for Automated Underwriting",
        "paper_author": "Li Q.",
        "publication": "International Conference on Information and Knowledge Management, Proceedings",
        "citied_by": "8",
        "cover_date": "2021-10-26",
        "Abstract": "Underwriting is an important process in insurance and is concerned with accepting individuals into insurance policy with tolerable claim risk. Underwriting is a tedious and labor intensive process relying on underwriters' domain knowledge and experience, thus is labor intensive and prone to error. Machine learning models are recently applied to automate the underwriting process and thus to ease the burden on the underwriters as well as improve underwriting accuracy. However, observational data used for underwriting modelling is high dimensional, sparse and incomplete, due to the dynamic evolving nature (e.g., upgrade) of business information systems. Simply applying traditional supervised learning methods e.g., logistic regression or Gradient boosting on such highly incomplete data usually leads to the unsatisfactory underwriting result, thus requiring practical data imputation for training quality improvement. In this paper, rather than choosing off-the-shelf solutions tackling the complex data missing problem, we propose an innovative Generative Adversarial Nets (GAN) framework that can capture the missing pattern from a causal perspective. Specifically, we design a structural causal model to learn the causal relations underlying the missing pattern of data. Then, we devise a Causality-aware Generative network (CaGen) using the learned causal relationship prior to generating missing values, and correct the imputed values via the adversarial learning. We also show that CaGen significantly improves the underwriting prediction in real-world insurance applications.",
        "DOI": "10.1145/3459637.3481900",
        "affiliation_name": "eBay, Inc.",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Facts and Figures on Materials Science and Nanotechnology Progress and Investment",
        "paper_author": "Talebian S.",
        "publication": "ACS Nano",
        "citied_by": "67",
        "cover_date": "2021-10-26",
        "Abstract": "As the twenty-first century unfolds, nanotechnology is no longer just a buzzword in the field of materials science, but rather a tangible reality. This is evident from the surging number of commercial nanoproducts and their corresponding revenue generated in different industry sectors. However, it is important to recognize that sustainable growth of nanotechnology is heavily dependent on government funding and relevant national incentive programs. Consequently, proper analyses on publicly available nanotechnology data sets comprising information on the past two decades can be illuminating, facilitate development, and amend previous strategies as we move forward. Along these lines, classical statistics and machine learning (ML) allow processing large data sets to scrutinize patterns in materials science and nanotechnology research. Herein, we provide an analysis on nanotechnology progress and investment from an unbiased, computational vantage point and using orthogonal approaches. Our data reveal both well-established and surprising correlations in the nanotechnology field and its actors, including the interplay between the number of research institutes-industry, publications-patents, collaborative research, and top contributors to nanoproducts. Overall, data suggest that, supported by incentive programs set out by stakeholders (researchers, funding agencies, policy makers, and industry), nanotechnology could experience an exponential growth and become a centerpiece for economical welfare. Indeed, the recent success of COVID-19 vaccines is also likely to boost public trust in nanotechnology and its global impact over the coming years.",
        "DOI": "10.1021/acsnano.1c03992",
        "affiliation_name": "i3S - Instituto de Investigação e Inovação em Saúde, Universidade do Porto, Portugal",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Condition-based maintenance: an industrial application on rotary machines",
        "paper_author": "Acernese A.",
        "publication": "Journal of Quality in Maintenance Engineering",
        "citied_by": "13",
        "cover_date": "2021-10-26",
        "Abstract": "Purpose: The purpose of this paper is to describe a model for the design and development of a condition-based maintenance (CBM) strategy for the cutting group of a labeling machine. The CBM aims to ensure the quality of labels' cut and overall machine performances. Design/methodology/approach: In developing a complete CBM strategy, two main difficulties have to be overcome: (1) appropriately dealing with incomplete and low-quality production database and (2) selecting the most promising predictive model. The first issue has been addressed applying data cleansing operations and creating ad hoc methodology to enlarge the training data. The second issue has been handled developing and comparing an empirical model with a machine learning (ML)-based model; the comparison has been performed assessing capabilities thereof in predicting erroneous label cuts on data obtained from an operating plant located in Italy. Findings: Research results showed that both empirical and ML-based approaches exhibit good performances in detecting the operating conditions of the cutting machine. The advantage of adopting an ML-based model is that it can be used not only as a condition indicator (i.e. a model able to continuously provide the health status of an asset) but also in predictive maintenance policies (i.e. a CBM carried out following a forecast of the degradation of the item). Research limitations/implications: The study described in this manuscript has been developed on the practices of a labeling machine developed by an international company manufacturing bottling lines for beverage industry. The proposed approach might need some customization in case it is applied to other industries. Future researches can validate the applicability of such models on different rotary machines in other companies and similar industries. Originality/value: The main contribution of this paper lies in the empirical demonstration of the benefits of CBM and predictive maintenance in manufacturing, through the overcoming of a specific production issue. The large number of variables involved in thin label cutting lines (film thickness between 30 and 38 µm), the high throughput and the high costs due to production interruptions render the prediction of non-conforming labels an economically relevant, albeit challenging, goal. Moreover, despite the large scientific literature on CBM in rolling bearing and face cutting movements, papers dealing with rotary labeling machines are very unusual and unique.",
        "DOI": "10.1108/JQME-10-2019-0101",
        "affiliation_name": "Università degli Studi di Modena e Reggio Emilia",
        "affiliation_city": "Modena",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Computational intelligence and healthcare informatics part III- recent development and advanced methodologies",
        "paper_author": "Perumal S.P.",
        "publication": "Computational Intelligence and Healthcare Informatics",
        "citied_by": "1",
        "cover_date": "2021-10-25",
        "Abstract": "There are different types of healthcare simulations currently available varying from simulation of patient records in hospital emergency wards, specific disease level simulation of patient history to human resource management in clinical environments. Role of Machine Learning (ML)/Deep Learning (DL) models in such simulations is very significant and it produces hybrid results by imbibing advantages of ML and simulation modeling techniques. These models bring out the interdependent relationship between the biomedical and computational factors in complex healthcare simulations leveraged by different practitioners and management authorities. Healthcare simulations can be of two types-Agent-Based Methods (ABM) and Discrete Event Simulations (DES). Such simulations involve study of enormous data generated from various biomedical applications, diagnostic arrays and medical devices which are put into standard analytical procedures to extract logical patterns used for further medical analysis. Various ML algorithms like Random Forest, XG Boosting, and Support Vector Machine used for modeling such simulations and aimed at improved prediction scores are studied. Biomedical feature selection and quality training set labeling processes play important role in stabilizing such ML algorithms. As an advanced level, DL models are deployed by making use of different types of Artificial Neural Networks (ANNs) like Recurrent Neural Networks (RNN) and Convolutional Neural Networks (CNN) to improve the simulation vs. realtime output synchronization. Different DL models leveraged for different biomedical simulations are illustrated. There is an important need to strike a trade-off between handling high dimensional data and improved prediction accuracies. ML/DL models developed for such healthcare simulations will clearly focus on writing suitable healthcare policies for high quality medical care.",
        "DOI": "10.1002/9781119818717.ch9",
        "affiliation_name": "College of Engineering, Guindy",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Prediction and analysis of China s tourism labor force based on univariate model based on ARMA",
        "paper_author": "Yin L.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-10-21",
        "Abstract": "Predicting the tourism labor demand of China is of special importance for tourism and other hospitality industries because it provides basic information for subsequent planning, policy making and scientific market decision of the government and tourism enterprise managers. Since it is difficult to construct an accurate model of tourism labor demand and no sufficient data for machine learning based prediction, this paper used ARMA to predict the future 5-year trend of related tourism labor in China. We conducted the trend prediction on the numbers of direct employees in tourism industry, employees in star hotels, employees in lodging industry and employees in travel agencies, for the guidance of tourism investment and planning.",
        "DOI": "10.1145/3516529.3516565",
        "affiliation_name": "Wuhan Business University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Modeling and Optimization of NOx Emission from a 660 MW Coal-Fired Boiler Based on the Deep Learning Algorithm",
        "paper_author": "Wang Y.",
        "publication": "Journal of Chemical Engineering of Japan",
        "citied_by": "3",
        "cover_date": "2021-10-20",
        "Abstract": "With the increasingly strict environmental protection policies, restrictions on NOx emissions are becoming increasingly stringent. This paper focuses on modeling and optimizing NOx emission for a coal-fired boiler with advanced deep learning approaches. Three types of deep recurrent neural network models, including recurrent neural network (RNN), long short-term memory (LSTM), and gate recurrent unit (GRU), are developed to model the relationship between operational parameters and NOx emission of a 660 MW boiler. The hyperparameters of the models are selected by grid search and the effects of the hyperparameters on the prediction results are analyzed. Compared with the traditional back propagation neural network (BP), support vector machine (SVM) models and deep belief network (DBN), the deep recurrent neural network models have higher prediction accuracy. The experimental results show that the GRU-based NOx prediction model has the best prediction performance among the proposed models. Then, the predicted NOx emission is used as the objective of searching the optimal parameters for the boiler combustion through the grey wolf optimization (GWO) algorithm. The searching process of GWO is convergent. According to the simulation results, the declines in the NOx emissions in the two selected cases were 19.49% and 17.96%, which are reasonable achievements for the boiler combustion process.",
        "DOI": "10.1252/jcej.21we004",
        "affiliation_name": "North China Electric Power University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Cross-sector storage and modeling needed for deep decarbonization",
        "paper_author": "Kittner N.",
        "publication": "Joule",
        "citied_by": "19",
        "cover_date": "2021-10-20",
        "Abstract": "Noah Kittner is an assistant professor in energy in the Department of Environmental Sciences and Engineering, Gillings School of Global Public Health and in the Environment, Ecology, and Energy Program at the University of North Carolina at Chapel Hill. His research examines the role of energy storage in the transition to low-carbon energy systems and deep decarbonization. Sergio Castellanos is an assistant professor in the Department of Civil, Architectural and Environmental Engineering at the University of Texas at Austin, where he leads the Rapid, Equitable & Sustainable Energy Transitions (RESET) Lab focusing on equitable pathways for decarbonized energy systems. Patricia Hidalgo-Gonzalez is an assistant professor in the Jacobs School of Engineering and an affiliate member in the Center for Energy Research at the University of California, San Diego. She is the director of the Renewable Energy and Advanced Mathematics Laboratory. She is one of the academic co-leads of the IEEE Power & Energy Society Task Force “Data-Driven Controls for Distributed Systems.” Her research focuses on high penetration of renewable energy using optimization, control theory, and machine learning with safety guarantees. Daniel M Kammen is the James and Katherine Lau Distinguished Chair in Sustainability, and Chair of the Energy and Resources Group, Professor in the Goldman School of Public Policy, and Professor of Nuclear Engineering at the University of California, Berkeley. He has served as Chief Technical Specialist for Renewable Energy and Energy Efficiency at the World Bank, and Science Envoy in the US Department of State. His work is focused on the science and policy of decarbonization at scales from homes to villages to large utility-scale systems. He has been a Coordinating Lead Author for the IPCC since 1999. Sarah Kurtz is a Professor at the University of California Merced. She spent more than 30 years at the National Renewable Energy Laboratory studying multi-junction III-V solar cells, reliability of photovoltaic modules and systems, and other solar-related projects. She is now leading a study of the value of long-duration storage, funded by the California Energy Commission.",
        "DOI": "10.1016/j.joule.2021.09.003",
        "affiliation_name": "School of Engineering",
        "affiliation_city": "Merced",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Quantifying the impacts of human mobility restriction on the spread of coronavirus disease 2019: An empirical analysis from 344 cities of China",
        "paper_author": "Tan J.",
        "publication": "Chinese Medical Journal",
        "citied_by": "0",
        "cover_date": "2021-10-20",
        "Abstract": "Background:Since the outbreak of coronavirus disease 2019 (COVID-19), human mobility restriction measures have raised controversies, partly because of the inconsistent findings. An empirical study is promptly needed to reliably assess the causal effects of the mobility restriction. The purpose of this study was to quantify the causal effects of human mobility restriction on the spread of COVID-19.Methods:Our study applied the difference-in-difference (DID) model to assess the declines of population mobility at the city level, and used the log-log regression model to examine the effects of population mobility declines on the disease spread measured by cumulative or new cases of COVID-19 over time after adjusting for confounders.Results:The DID model showed that a continual expansion of the relative declines over time in 2020. After 4 weeks, population mobility declined by -54.81% (interquartile range, -65.50% to -43.56%). The accrued population mobility declines were associated with the significant reduction of cumulative COVID-19 cases throughout 6 weeks (ie, 1% decline of population mobility was associated with 0.72% [95% CI: 0.50%-0.93%] reduction of cumulative cases for 1 week, 1.42% 2 weeks, 1.69% 3 weeks, 1.72% 4 weeks, 1.64% 5 weeks, and 1.52% 6 weeks). The impact on the weekly new cases seemed greater in the first 4 weeks but faded thereafter. The effects on cumulative cases differed by cities of different population sizes, with greater effects seen in larger cities.Conclusions:Persistent population mobility restrictions are well deserved. Implementation of mobility restrictions in major cities with large population sizes may be even more important.",
        "DOI": "10.1097/CM9.0000000000001763",
        "affiliation_name": "Centre for Health Economics and Policy Analysis",
        "affiliation_city": "Hamilton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Monitoring Compliance in Pandemic Management with Air Pollution Data: A Lesson from COVID-19",
        "paper_author": "Wang R.",
        "publication": "Environmental Science and Technology",
        "citied_by": "3",
        "cover_date": "2021-10-19",
        "Abstract": "NA",
        "DOI": "10.1021/acs.est.1c03818",
        "affiliation_name": "Centre de Recerca Ecològica i Aplicacions Forestals (CREAF-CERCA)",
        "affiliation_city": "Cerdanyola del Valles",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Retraction notice to “Experimental investigation and comparative machine-learning prediction of strength behavior of optimized recycled rubber concrete” [JCBM 256 (2020) 119478] (Construction and Building Materials (2020) 256, (S0950061820314835), (10.1016/j.conbuildmat.2020.119478))",
        "paper_author": "Jalal M.",
        "publication": "Construction and Building Materials",
        "citied_by": "0",
        "cover_date": "2021-10-18",
        "Abstract": "This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). This article has been retracted at the request of the authors Zachary Grasley and Jeffrey W. Bullard. The authors did not consent to being added as co-authors on this paper, they were not informed of the submission to the journal. We have not received a response from the third author Charles Gurganus. It is the responsibility of the corresponding author to submit the correct authorship list on submission and to gain consent from these authors. As this was not done, the author is in breach of the journal's ethical policy.",
        "DOI": "10.1016/j.conbuildmat.2021.124704",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "College Station",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Adaptive Channel Hopping for IEEE 802.15.4 TSCH-Based Networks: A Dynamic Bernoulli Bandit Approach",
        "paper_author": "Javan N.T.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "9",
        "cover_date": "2021-10-15",
        "Abstract": "In IEEE 802.15.4 standard for low-power low-range wireless communications, only one channel is employed for transmission which can result in increased energy consumption, high network delay and poor packet delivery ratio (PDR). In the subsequent IEEE 802.15.4-2015 standard, a Time-slotted Channel Hopping (TSCH) mechanism has been developed which allows for a periodic yet fixed frequency hopping pattern over 16 different channels. Unfortunately, however, most of these channels are susceptible to high-power coexisting Wi-Fi signal interference and to possibly some other ISM-band transmissions. This interference manifests itself in the form of the presence/absence of other devices with either or both static and dynamic channel selection policies. In order to isolate channels with undesirable conditions, blacklisting mechanisms are defined to adapt the channel hopping process. However, the existing solutions which form blacklists unrealistically assume that the statistical model of the external interference remains fixed, and do not vary over time. In this paper, we realistically assume that the impact of external interferes on 802.15.4 may generally follow a non-stationary pattern, and accordingly formulate the adaptive channel hopping problem as a Dynamic Multi-Armed Bernoulli Bandit (Dynamic MABB) process from the machine learning theory. We then propose an online learning algorithm with track-ability properties for computing an adaptive hopping policy. Simulations confirm that when the statistics of the external interference has a switching regime, the proposed solution outperforms the previous schemes in terms of both energy efficiency as well as two important KPIs for TSCH-based networks, i.e., PDR and latency.",
        "DOI": "10.1109/JSEN.2021.3110720",
        "affiliation_name": "Iran University of Science and Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Fund gap to high air quality in China: A cost evaluation for PM<inf>2.5</inf> abatement based on the Air Pollution Prevention and control Action Plan",
        "paper_author": "Liu Z.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "26",
        "cover_date": "2021-10-15",
        "Abstract": "The Chinese government promulgated a series of policies on air cleaning due to the severe PM 2.5 pollution. Thereinto, the Air Pollution Prevention and Control Action Plan (the Action Plan) numbers among the toughest-ever environmental protection policy in China, which significantly restrained haze pollution with a huge cost. In a policy-making for air cleaning, cost assessment is crucial. However, current main methods have a common shortcoming for which they neglect the cost on industrial restructurings. Thus, in this work, we proposed a novel approach to assess the comprehensive cost on the long-term PM 2.5 control in China under the Action Plan scenario. First, PM 2.5 pollution abatements and 10 precursor variations in China's 31 provinces were quantified via the Cohen's index. Then, provincial expenditures were jointed with their corresponding Cohen's indices of precursors and PM 2.5 mitigation, and patterns of the Action Plan were identified through machine learning. It was found that boiler regulation and industrial restructuring were the driving forces for most precursor decreases. Finally, the overall PM 2.5 pollution abatement was calculated by the fixed-effect model and jointed with the cumulative national expenditure to construct a cost curve, which can estimate the cost on both front- and end-of-pipe sections. Thus, the maximum budgets for several air quality targets were evaluated, which was found that China has to pay 10.24 and 51.55 trillion CNY within the PM 2.5 concentrations limits of 25 and 10 μg/m 3, respectively. Our study provided a new insight of fund gaps between different control targets in China and filled the lack of current cost assessment methodologies.",
        "DOI": "10.1016/j.jclepro.2021.128715",
        "affiliation_name": "College of Environmental and Resource Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Crop yield forecasting and associated optimum lead time analysis based on multi-source environmental data across China",
        "paper_author": "Li L.",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "82",
        "cover_date": "2021-10-15",
        "Abstract": "Accurate and timely crop yield forecasts can provide essential information to make conclusive agricultural policies and to conduct investments. Recent studies have used different machine learning techniques to develop such yield forecast systems for single crops at regional scales. However, no study has used multiple sources of environmental predictors (climate, soil, and vegetation) to forecast yields for three major crops in China. In this study, we adopted 7-year observed crop yield data (2013–2019) for three major grain crops (wheat, maize, and rice) across China, and three major data sets including climate, vegetation indices, and soil properties were used to develop a dynamic yield forecasting system based on the random forest (RF) model. The RF model showed good performance for estimating yields of all three crops with correlation coefficient (r) higher than 0.75 and normalized root means square errors (nRMSE) lower than 18.0%. Our results also showed that crop yields can be satisfactorily forecasted at one to three months prior to harvest. The optimum lead time for yield forecasting depended on crop types. In addition, we found the major predictors influencing crop yield varied between crops. In general, solar radiation and vegetation indices (especially during jointing to milk development stages) were identified as the main predictor for winter wheat; vegetation indices (throughout the growing season) and drought (especially during emergence to tasseling stages) were the most important predictors for spring maize; soil moisture (throughout the growing season) was the dominant predictor for summer maize, late rice, and mid rice; precipitation (especially during booting to heading stages) was the main predictor for early rice. Our study provides insights into practical crop yield forecasting and the understanding of yield response to environmental conditions at a large scale across China. The methods undertaken in this research can be easily implemented in other countries with available information on climate, soil, and vegetation conditions.",
        "DOI": "10.1016/j.agrformet.2021.108558",
        "affiliation_name": "Ministry of Agriculture of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Forecasting residential electricity consumption using a hybrid machine learning model with online search data",
        "paper_author": "Gao F.",
        "publication": "Applied Energy",
        "citied_by": "32",
        "cover_date": "2021-10-15",
        "Abstract": "Accurate forecasting of residential electricity consumption plays an important role in formulating energy plans and ensuring the safety of power system operations. In order to improve forecasting accuracy, we propose a novel hybrid model with online search data for residential electricity consumption forecasting. Two main steps are involved: (1) Time difference correlation analysis, cointegration test, and Granger causality test are employed to investigate the relationship between online search data and residential electricity consumption. Qualified search keywords are selected to serve as predictors. (2) An extreme learning machine model optimized by Jaya algorithm, together with the selected search keywords from the first step, is proposed to predict residential electricity consumption. Furthermore, monthly residential electricity consumption data from China are used to validate the effectiveness of the proposed model. The experimental results show that the incorporation of online search data into the model can significantly improve forecasting accuracy. After incorporating online search data, improvement rates of all the forecasting models exceed 10%. In addition, the proposed model has the best forecasting performance compared with seasonal autoregressive integrated moving average (SARIMA(X)), support vector regression (SVR), back propagation neural network (BPNN) and extreme learning model (ELM). Root mean squared error (RMSE), mean absolute percentage error (MAPE), and mean absolute error (MAE) of the proposed model with online search data decrease by 34%-51.2%, 43.03%-53.92%, and 41.35%-54.85% relative to other benchmark models, respectively.",
        "DOI": "10.1016/j.apenergy.2021.117393",
        "affiliation_name": "Institutes of Science and Development",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Estimation of municipal solid waste amount based on one-dimension convolutional neural network and long short-term memory with attention mechanism model: A case study of Shanghai",
        "paper_author": "Lin K.",
        "publication": "Science of the Total Environment",
        "citied_by": "49",
        "cover_date": "2021-10-15",
        "Abstract": "Municipal solid waste (MSW) amount has direct influence on MSW management, policy-decision making, and MSW treatment methods. Machine learning has great potential for prediction, but few studies apply the approaches of deep learning to forecast the quantity of MSW. Therefore, the aim of this study is to evaluate the feasibility and practicability of employing the methods of supervised learning, including Attention, one-dimension Convolutional Neural Network (1D-CNN) and Long Short-Term Memory (LSTM) to predict the MSW Amount in Shanghai. Integrated 1D-CNN and LSTM with Attention model, the new structure model (1D-CNN-LSTM-Attention, 1D-CLA), is designed to forecast MSW amount. In addition, the influence of socioeconomic factors on MSW amount, the structure and layers distribution of Attention, 1D-CNN, LSTM and 1D-CLA are also discussed. The results indicate that the correlation coefficients of Attention, one-dimension CNN, LSTM, and proposed 1D-CLA model to predict the MSW in Shanghai are 78%, 86.6%, 90%, and 95.3%, respectively, suggesting the feasible and practicable. The values of 24, 0.01, 50 and 25 for the number of neurons, dropout, the value of epoch number and Batch size best fit 1D-CLA to predict the amount of MSW in Shanghai. Furthermore, the performance of 1D-CLA is better than any single model or two model's combination (R2 is 95.3%) and the mechanism of 1D-CLA is contributed by three former models following the order: LSTM>CNN>Attention.",
        "DOI": "10.1016/j.scitotenv.2021.148088",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Russian insurance market investigated by an AI system under growing market uncertainty and risk",
        "paper_author": "Lomakin N.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2021-10-14",
        "Abstract": "Based on the analysis of the insurance market in Russia, the development trends of the domestic insurance market under growing market uncertainty and risk have been considered. The theoretical foundations of the insurance activity have been examined. The analysis showed that the growth was weaker than a year earlier, when the non-life market increased by 8.4%. One of the leaders 2019 was the voluntary health insurance (VHI) that showed an increase of +28.8 billion RUB due to the demand for full packaged products, new VHI options in consumer life insurance policies, annual inflation of medical services, and accident and illness insurance that ensured an increase of +17.8 billion RUB that year. There were found practically no changes in the dynamics of the total volume of the insurance market in 2019 compared to 2018; its volume amounted to 1.48 trillion RUB, which was more by only 0.1% than a year earlier. Factors that determined the current situation in the domestic insurance market in the conditions of growing market uncertainty have been identified. An algorithm for predicting parameters required for the insurance market activity using the Perceptron AI system has been proposed. A hypothesis that the artificial intelligence enables forecasting the volume of the premium income of insurance companies in the Russian Federation was put forward and proved. This determines the relevance and practical significance of this study in the context of the digitalization of the economy. The neural network model used values of the results of domestic insurance companies. An important trend is the study of the theoretical foundations of artificial learning systems, machine learning and convolutional neural networks used to solve the problems of the insurance market.",
        "DOI": "10.1145/3527049.3527067",
        "affiliation_name": "Volgograd State Technical University",
        "affiliation_city": "Volgograd",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Integral reinforcement learning-based optimal output feedback control for linear continuous-time systems with input delay",
        "paper_author": "Wang G.",
        "publication": "Neurocomputing",
        "citied_by": "23",
        "cover_date": "2021-10-14",
        "Abstract": "In this paper, an integral reinforcement learning (IRL)-based model-free optimal output-feedback (OPFB) control scheme is developed for linear continuous-time systems with input delay, where the input and past output data are employed rather than the system dynamic model. First, the equivalence between the delayed optimal control and delay-free case is analyzed. Subsequently, the system state is constructed with output signal and the Bellman equation is written in the form of past outputs. Therefore, the IRL algorithm is developed to learn the OPFB control policy, where the iterative policy is evaluated and improved simultaneously. It is proved that the obtained optimal OPFB controller gives the same solution as the optimal state-feedback. Finally, the presented simulation results illustrate the effectiveness of the developed control method.",
        "DOI": "10.1016/j.neucom.2021.06.073",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Learning high-speed flight in the wild",
        "paper_author": "Loquercio A.",
        "publication": "Science Robotics",
        "citied_by": "206",
        "cover_date": "2021-10-13",
        "Abstract": "Quadrotors are agile. Unlike most other machines, they can traverse extremely complex environments at high speeds. To date, only expert human pilots have been able to fully exploit their capabilities. Autonomous operation with onboard sensing and computation has been limited to low speeds. State-of-the-art methods generally separate the navigation problem into subtasks: sensing, mapping, and planning. Although this approach has proven successful at low speeds, the separation it builds upon can be problematic for high-speed navigation in cluttered environments. The subtasks are executed sequentially, leading to increased processing latency and a compounding of errors through the pipeline. Here, we propose an end-to-end approach that can autonomously fly quadrotors through complex natural and human-made environments at high speeds with purely onboard sensing and computation. The key principle is to directly map noisy sensory observations to collision-free trajectories in a receding-horizon fashion. This direct mapping drastically reduces processing latency and increases robustness to noisy and incomplete perception. The sensorimotor mapping is performed by a convolutional network that is trained exclusively in simulation via privileged learning: imitating an expert with access to privileged information. By simulating realistic sensor noise, our approach achieves zero-shot transfer from simulation to challenging real-world environments that were never experienced during training: dense forests, snow-covered terrain, derailed trains, and collapsed buildings. Our work demonstrates that end-to-end policies trained in simulation enable high-speed autonomous flight through challenging environments, outperforming traditional obstacle avoidance pipelines.",
        "DOI": "10.1126/scirobotics.abg5810",
        "affiliation_name": "Intel Corporation",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Adversarial imitation learning with mixed demonstrations from multiple demonstrators",
        "paper_author": "Zuo G.",
        "publication": "Neurocomputing",
        "citied_by": "9",
        "cover_date": "2021-10-07",
        "Abstract": "The aim of generative adversarial imitation learning (GAIL) is to allow an agent to learn an optimal policy from demonstrations via an adversarial training process. However, previous works have not considered a realistic setting for complex continuous control tasks such as robot manipulation, in which the available demonstrations are imperfect and possibly originate from different policies. Such a setting poses significant challenges for the application of the GAIL-related methods. This paper proposes a novel imitation learning (IL) algorithm, MD2-GAIL, to enable an agent to learn effectively from imperfect demonstrations by multiple demonstrators. Instead of training the policy from scratch, unsupervised pretraining is used to speed up the adversarial learning process. Confidence scores representing the quality of the demonstrations are utilized to reconstruct the objective function for off-policy adversarial training, making the policy match the optimal occupancy measure. Based on the Soft Actor Critic (SAC) algorithm, MD2-GAIL incorporates the idea of maximum entropy into the process of optimizing the objective function. Meanwhile, a reshaped reward function is adopted to update the agent policy to avoid falling into local optima.Experiments were conducted based on robotic simulation tasks, and the results show that our method can efficiently learn from the available demonstrations and achieves better performance than other state-of-the-art methods.",
        "DOI": "10.1016/j.neucom.2021.06.053",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Breaking Taboos in Fair Machine Learning: An Experimental Study",
        "paper_author": "Nyarko J.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "5",
        "cover_date": "2021-10-05",
        "Abstract": "Many scholars, engineers, and policymakers believe that algorithmic fairness requires disregarding information about certain characteristics of individuals, such as their race or gender. Often, the mandate to \"blind\"algorithms in this way is conveyed as an unconditional ethical imperative - a minimal requirement of fair treatment - and any contrary practice is assumed to be morally and politically untenable. However, in some circumstances, prohibiting algorithms from considering information about race or gender can in fact lead to worse outcomes for racial minorities and women, complicating the rationale for blinding. In this paper, we conduct a series of randomized studies to investigate attitudes toward blinding algorithms, both among the general public as well as among computer scientists and professional lawyers. We find, first, that people are generally averse to the use of race and gender in algorithmic determinations of \"pretrial risk\"- the risk that criminal defendants pose to the public if released while awaiting trial. We find, however, that this preference for blinding shifts in response to a relatively mild intervention. In particular, we show that support for the use of race and gender in algorithmic decision-making increases substantially after respondents read a short passage about the possibility that blinding could lead to higher detention rates for Black and female defendants, respectively. Similar effect sizes are observed among the general public, computer scientists, and professional lawyers. These findings suggest that, while many respondents attest that they prefer blind algorithms, their preference is not based on an absolute principle. Rather, blinding is perceived as a way to ensure better outcomes for members of marginalized groups. Accordingly, in circumstances where blinding serves to disadvantage marginalized groups, respondents no longer view the exclusion of protected characteristics as a moral imperative, and the use of such information may become politically viable.",
        "DOI": "10.1145/3465416.3483291",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Accuracy-Efficiency Trade-Offs and Accountability in Distributed ML Systems",
        "paper_author": "Cooper A.F.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "7",
        "cover_date": "2021-10-05",
        "Abstract": "Trade-offs between accuracy and efficiency pervade law, public health, and other non-computing domains, which have developed policies to guide how to balance the two in conditions of uncertainty. While computer science also commonly studies accuracy-efficiency trade-offs, their policy implications remain poorly examined. Drawing on risk assessment practices in the US, we argue that, since examining these trade-offs has been useful for guiding governance in other domains, we need to similarly reckon with these trade-offs in governing computer systems. We focus our analysis on distributed machine learning systems. Understanding the policy implications in this area is particularly urgent because such systems, which include autonomous vehicles, tend to be high-stakes and safety-critical. We 1) describe how the trade-off takes shape for these systems, 2) highlight gaps between existing US risk assessment standards and what these systems require to be properly assessed, and 3) make specific calls to action to facilitate accountability when hypothetical risks concerning the accuracy-efficiency trade-off become realized as accidents in the real world. We close by discussing how such accountability mechanisms encourage more just, transparent governance aligned with public values.",
        "DOI": "10.1145/3465416.3483289",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Current advances and future challenges of AIoT applications in particulate matters (PM) monitoring and control",
        "paper_author": "Yang C.T.",
        "publication": "Journal of Hazardous Materials",
        "citied_by": "51",
        "cover_date": "2021-10-05",
        "Abstract": "Air pollution is at the center of pollution-control discussion due to the significant adverse health effects on individuals and the environment. Research has shown the association between unsafe environments and different sizes of particulate matter (PM), highlighting the importance of pollutant monitoring to mitigate its detrimental effect. By monitoring air quality with low-cost monitoring devices that collect massive observations, such as Air Box, a comprehensive collection of ground-level PM concentration is plausible due to the simplicity and low-cost, propelling applications in agriculture, aquaculture, and air quality, water resources, and disaster prevention. This paper aims to view IoT-based systems with low-cost microsensors at the sensor, network, and application levels, along with machine learning algorithms that improve sensor networks’ precision, providing better resolution. From the analysis at the three levels, we analyze current PM monitoring methods, including the use of sensors when collecting PM concentrations, demonstrate the use of IoT-based systems in PM monitoring and its challenges, and finally present the integration of AI and IoT (AIoT) in PM monitoring, indoor air quality control, and future directions. In addition, the inclusion of Taiwan as a site analysis was illustrated to show an example of AIoT in PM-control policy-making potential directions.",
        "DOI": "10.1016/j.jhazmat.2021.126442",
        "affiliation_name": "Dại học Nguyen Tat Thanh",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "A machine learning analysis of misconduct in the New York Police Department",
        "paper_author": "Cubitt T.I.C.",
        "publication": "Policing",
        "citied_by": "8",
        "cover_date": "2021-10-05",
        "Abstract": "Purpose: There is a paucity of data available relating to the misconduct of police officers in larger policing agencies, typically resulting in case study approaches and limited insight into the factors associated with serious misconduct. This paper seeks to contribute to the emerging knowledge base on police misconduct through analysis of 28,429 complaints among 3,830 officers in the New York Police Department, between 2000 and 2019. Design/methodology/approach: This study utilized a data set consisting of officer and complainant demographics, and officer complaint records. Machine learning analytics were employed, specifically random forest, to consider which variables were most associated with serious misconduct among officers that committed misconduct. Partial dependence plots were employed among variables identified as important to consider the points at which misconduct was most, and least likely to occur. Findings: Prior instances of serious misconduct were particularly associated with further instances of serious misconduct, while remedial action did not appear to have an impact in preventing further misconduct. Inexperience, both in rank and age, was associated with misconduct. Specific prior complaints, such as minor use of force, did not appear to be particularly associated with instances of serious misconduct. The characteristics of the complainant held more importance than the characteristics of the officer. Originality/value: The ability to analyze a data set of this size is unusual and important to progressing the knowledge area regarding police misconduct. This study contributes to the growing use of machine learning in understanding the police misconduct environment, and more accurately tailoring misconduct prevention policy and practice.",
        "DOI": "10.1108/PIJPSM-11-2020-0178",
        "affiliation_name": "Western Sydney University",
        "affiliation_city": "Penrith",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A reinforcement learning algorithm for automated detection of skin lesions",
        "paper_author": "Usmani U.A.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "33",
        "cover_date": "2021-10-02",
        "Abstract": "Skin cancers are increasing at an alarming rate, and detection in the early stages is essential for advanced treatment. The current segmentation methods have limited labeling ability to the ground truth images due to the numerous noisy expert annotations present in the datasets. The precise boundary segmentation is essential to correctly locate and diagnose the various skin lesions. In this work, the lesion segmentation method is proposed as a Markov decision process. It is solved by training an agent to segment the region using a deep reinforcement-learning algorithm. Our method is similar to the delineation of a region of interest by the physicians. The agent follows a set of serial actions for the region delineation, and the action space is defined as a set of continuous action parameters. The segmentation model learns in continuous action space using the deep deterministic policy gradient algorithm. The proposed method enables continuous improvement in performance as we proceed from coarse segmentation results to finer results. Finally, our proposed model is evaluated on the International Skin Imaging Collaboration (ISIC) 2017 image dataset, Human against Machine (HAM10000), and PH2 dataset. On the ISIC 2017 dataset, the algorithm achieves an accuracy of 96.33% for the naevus cases, 95.39% for the melanoma cases, and 94.27% for the seborrheic keratosis cases. The other metrics are evaluated on these datasets and rank higher when compared with the current state-of-the-art lesion segmentation algorithms.",
        "DOI": "10.3390/app11209367",
        "affiliation_name": "Waseda University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Analysis of Medical Ethics Issues Caused by the Application of Artificial Intelligence in Ophthalmic Diseases",
        "paper_author": "He N.",
        "publication": "Chinese Medical Ethics",
        "citied_by": "0",
        "cover_date": "2021-10-01",
        "Abstract": "With the continuous progress of machine learning and deep learning, the application of medical artificial intelligence (MAI) technology in the diagnosis and treatment of ophthalmic diseases is increasing. The screening, diagnosis and treatment of ophthalmic diseases often rely on imaging examination, and the ophthalmic examination image has the characteristics of exquisite, complicated and large amount of informative due to its anatomical characteristics. MAI technology has the advantages of high efficiency, accuracy, consistency and convenience, so it has been paid attention and favored by ophthalmologist. However, it is found that it has ethical problems such as patient information security, fair benefit, privacy protection and so on in the process of application. In view of the above problems, it is proposed that measures such as strengthening legal and policy supervision, strengthening the training of professionals and emphasizing the main responsibility of medical institutions should be taken to protect.",
        "DOI": "10.12026/j.issn.1001-8565.2021.10.13",
        "affiliation_name": "The Second Hospital of Xian Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "More Accurate Causal Inference: A Perspective of Machine Learning",
        "paper_author": "Qian H.",
        "publication": "China Journal of Econometrics",
        "citied_by": "4",
        "cover_date": "2021-10-01",
        "Abstract": "There is an increasing trend towards combining machine learning methods with traditional econometric methodologies. Starting from comparing features and internal relations of two mainstream causal inference frameworks, this paper proposes that causal inference can be significantly improved with the introducing of machine learning methods in two ways, one is sample matching and one is counterfactual prediction. Firstly, machine learning techniques can enhance matching qualities by pairing samples directly or improving the accuracies of propensity score predictions. This can make the matched samples more similar to samples collected from randomized controlled trials. Secondly, machine learning techniques can improve the accuracies of counterfactual predictions by modeling complex relations, using cross-validation, and adopting regularization. This paper then introduces the theoretical foundations of combining machine learning techniques and causal inferences by reviewing four specific methods: Matching, regression discontinuity, difference-in-difference, and synthetic control method. At the meantime, several application cases are provided in each method section for researchers in applied econometrics as references.",
        "DOI": "10.12012/CJoE2021-0027",
        "affiliation_name": "LSE-Fudan Research Centre for Global Public Policy",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning for the educational sciences",
        "paper_author": "Hilbert S.",
        "publication": "Review of Education",
        "citied_by": "37",
        "cover_date": "2021-10-01",
        "Abstract": "Machine learning (ML) provides a powerful framework for the analysis of high-dimensional datasets by modelling complex relationships, often encountered in modern data with many variables, cases and potentially non-linear effects. The impact of ML methods on research and practical applications in the educational sciences is still limited, but continuously grows, as larger and more complex datasets become available through massive open online courses (MOOCs) and large-scale investigations. The educational sciences are at a crucial pivot point, because of the anticipated impact ML methods hold for the field. To provide educational researchers with an elaborate introduction to the topic, we provide an instructional summary of the opportunities and challenges of ML for the educational sciences, show how a look at related disciplines can help learning from their experiences, and argue for a philosophical shift in model evaluation. We demonstrate how the overall quality of data analysis in educational research can benefit from these methods and show how ML can play a decisive role in the validation of empirical models. Specifically, we (1) provide an overview of the types of data suitable for ML and (2) give practical advice for the application of ML methods. In each section, we provide analytical examples and reproducible R code. Also, we provide an extensive Appendix on ML-based applications for education. This instructional summary will help educational scientists and practitioners to prepare for the promises and threats that come with the shift towards digitisation and large-scale assessment in education. Context and implications Rationale for this study In 2020, the worldwide SARS-COV-2 pandemic forced the educational sciences to perform a rapid paradigm shift with classrooms going online around the world—a hardly novel but now strongly catalysed development. In the context of data-driven education, this paper demonstrates that the widespread adoption of machine learning techniques is central for the educational sciences and shows how these methods will become crucial tools in the collection and analysis of data and in concrete educational applications. Helping to leverage the opportunities and to avoid the common pitfalls of machine learning, this paper provides educators with the theoretical, conceptual and practical essentials. Why the new findings matter The process of teaching and learning is complex, multifaceted and dynamic. This paper contributes a seminal resource to highlight the digitisation of the educational sciences by demonstrating how new machine learning methods can be effectively and reliably used in research, education and practical application. Implications for educational researchers and policy makers The progressing digitisation of societies around the globe and the impact of the SARS-COV-2 pandemic have highlighted the vulnerabilities and shortcomings of educational systems. These developments have shown the necessity to provide effective educational processes that can support sometimes overwhelmed teachers to digitally impart knowledge on the plan of many governments and policy makers. Educational scientists, corporate partners and stakeholders can make use of machine learning techniques to develop advanced, scalable educational processes that account for individual needs of learners and that can complement and support existing learning infrastructure. The proper use of machine learning methods can contribute essential applications to the educational sciences, such as (semi-)automated assessments, algorithmic-grading, personalised feedback and adaptive learning approaches. However, these promises are strongly tied to an at least basic understanding of the concepts of machine learning and a degree of data literacy, which has to become the standard in education and the educational sciences. Demonstrating both the promises and the challenges that are inherent to the collection and the analysis of large educational data with machine learning, this paper covers the essential topics that their application requires and provides easy-to-follow resources and code to facilitate the process of adoption.",
        "DOI": "10.1002/rev3.3310",
        "affiliation_name": "Universität Regensburg",
        "affiliation_city": "Regensburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Machine learning-based analysis of COVID-19 pandemic impact on US research networks",
        "paper_author": "Kiran M.",
        "publication": "Computer Communication Review",
        "citied_by": "2",
        "cover_date": "2021-10-01",
        "Abstract": "This study explores how fallout from the changing public health policy around COVID-19 has changed how researchers access and process their science experiments. Using a combination of techniques from statistical analysis and machine learning, we conduct a retrospective analysis of historical network data for a period around the stay-At-home orders that took place in March 2020. Our analysis takes data from the entire ESnet infrastructure to explore DOE high-performance computing (HPC) resources at OLCF, ALCF, and NERSC, as well as User sites such as PNNL and JLAB. We look at detecting and quantifying changes in site activity using a combination of t-Distributed Stochastic Neighbor Embedding (t-SNE) and decision tree analysis. Our findings bring insights into the working patterns and impact on data volume movements, particularly during late-night hours and weekends.",
        "DOI": "10.1145/3503954.3503958",
        "affiliation_name": "ESnet",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Traffic Signal Control Model on Isolated Intersection Using Reinforcement Learning: A Case Study on Algiers City, Algeria",
        "paper_author": "Bouriachi F.",
        "publication": "Revue d'Intelligence Artificielle",
        "citied_by": "3",
        "cover_date": "2021-10-01",
        "Abstract": "Traffic jams and congestion in our cities are a major problem because of the huge increase in the number of cars on the road. To remedy this problem, several control methods are proposed to prevent or reduce traffic congestion based on traffic lights. There are few works using reinforcement learning technique for traffic light control and recent studies have shown promising results. However, existing works have not yet tested the methods on the real-world traffic data and they only focus on studying the rewards without interpreting the policies. In this paper, we proposed a reinforcement learning algorithm to address the traffic signal control problem in real multi-phases isolated intersection. A case study based on Algiers city is conducted the simulation results from the different scenarios show that our proposed scheme reduces the total travel time of the vehicles compared to those obtained with traffic-adaptive control.",
        "DOI": "10.18280/ria.350508",
        "affiliation_name": "Université Djillali Liabes de Sidi Bel Abbes",
        "affiliation_city": "Sidi Bel Abbes",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "Application of machine learning in the prediction of COVID-19 daily new cases: A scoping review",
        "paper_author": "Fard S.G.",
        "publication": "Heliyon",
        "citied_by": "52",
        "cover_date": "2021-10-01",
        "Abstract": "Covid-19 Has Produced A Global Pandemic Affecting All Over Of The World. Prediction Of The Rate Of Covid-19 Spread And Modeling Of Its Course Have Critical Impact On Both Health System And Policy Makers. Indeed, Policy Making Depends On Judgments Formed By The Prediction Models To Propose New Strategies And To Measure The Efficiency Of The Imposed Policies. Based On The Nonlinear And Complex Nature Of This Disorder And Difficulties In Estimation Of Virus Transmission Features Using Traditional Epidemic Models, Artificial Intelligence Methods Have Been Applied For Prediction Of Its Spread. Based On The Importance Of Machine And Deep Learning Approaches In The Estimation Of Covid-19 Spreading Trend, In The Present Study, We Review Studies Which Used These Strategies To Predict The Number Of New Cases Of Covid-19. Adaptive Neuro-Fuzzy Inference System, Long Short-Term Memory, Recurrent Neural Network And Multilayer Perceptron Are Among The Mostly Used Strategies In This Regard. We Compared The Performance Of Several Machine Learning Methods In Prediction Of Covid-19 Spread. Root Means Squared Error (Rmse), Mean Absolute Error (Mae), R2 Coefficient Of Determination (R2), And Mean Absolute Percentage Error (Mape) Parameters Were Selected As Performance Measures For Comparison Of The Accuracy Of Models. R2 Values Have Ranged From 0.64 To 1 For Artificial Neural Network (Ann) And Bidirectional Long Short Term Memory (Lstm), Respectively. Adaptive Neuro-Fuzzy Inference System (Anfis), Autoregressive Integrated Moving Average (Arima) And Multilayer Perceptron (Mlp) Have Also Have R2 Values Near 1. Arima And Lstm Had The Highest Mape Values. Collectively, These Models Are Capable Of Identification Of Learning Parameters That Affect Dissimilarities In Covid-19 Spread Across Various Regions Or Populations, Combining Numerous Intervention Methods And Implementing What-If Scenarios By Integrating Data From Diseases Having Analogous Trends With Covid-19. Therefore, Application Of These Methods Would Help In Precise Policy Making To Design The Most Appropriate Interventions And Avoid Non-Efficient Restrictions",
        "DOI": "10.1016/j.heliyon.2021.e08143",
        "affiliation_name": "SBUMS Research Institute for Dental Sciences",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Multiple Intersection Traffic Control using Reinforcement Learning",
        "paper_author": "Shinde M.",
        "publication": "2021 2nd Global Conference for Advancement in Technology, GCAT 2021",
        "citied_by": "0",
        "cover_date": "2021-10-01",
        "Abstract": "This paper introduces application of Multi Agent Deep Deterministic Policy Gradients algorithm for multiple traffic intersection problems. The problem of decrease in waiting time at traffic intersections is still unsolved. Reinforcement learning is the recent technique which was introduced in past years. This paper is an attempt to apply Reinforcement Learning for multiple intersections.",
        "DOI": "10.1109/GCAT52182.2021.9587482",
        "affiliation_name": "Vivekanand Education Society's Institute of Technology",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "U.K. Car Accident and Insurance Predictor using Machine Learning",
        "paper_author": "Patel A.",
        "publication": "2021 2nd Global Conference for Advancement in Technology, GCAT 2021",
        "citied_by": "1",
        "cover_date": "2021-10-01",
        "Abstract": "The region of the United Kingdom has seen a substantial rise in the number of accidents in recent times. Having car insurance in your arsenal acts as a savior in times of financial crisis. In this paper, car accidents occurring in a specific region are analyzed and the insurance policy which is best suitable for the consumer is recommended. Here the car accidents are categorized into different groups of ages and accidents happening on the different days of the week are shown using matplotlib and seaborn libraries.",
        "DOI": "10.1109/GCAT52182.2021.9587647",
        "affiliation_name": "Mukesh Patel School of Technology Management &amp; Engineering, Shirpur Campus",
        "affiliation_city": "Shirpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Retraction: Flavor-cyber-agriculture: Optimization of plant metabolites in an open-source control environment through surrogate modeling (PLoS ONE (2019) 14:4 (e0213918) DOI: 10.1371/journal.pone.0213918)",
        "paper_author": "NA",
        "publication": "PLoS ONE",
        "citied_by": "0",
        "cover_date": "2021-10-01",
        "Abstract": "After this article [1] was published, concerns were raised about the article’s methods and reporting. PLOS followed up in accordance with COPE guidance and PLOS policies; this process involved a post-publication assessment with input from a statistical review and multiple members of PLOS ONE’s Editorial Board. The following concerns were noted and/or confirmed during the post-publication editorial assessment: 1. The experimental methods and statistical analysis methods and models were not reported in sufficient detail to enable replication efforts and to clarify how potential confounds were addressed. The authors addressed some of the methodological reporting issues by providing additional information in post-publication discussions with PLOS and referring to materials posted on GitHub, but they did not fully address the questions about the statistical analyses. 2. An Editorial Board member raised concerns about the selection of machine learning model used in the study and noted that the article did not adequately discuss query learning literature. 3. Consulted experts advised that the dataset is too limited to address the article’s objectives, and that given the size of the dataset, one would expect issues with overfitting data to nonlinear models. 4. Concerns were raised about the number of independent replicates included in the experiments. The authors provided the following information about replication: There was one treatment replicate per climate condition. For chemical analysis, four biological replicates (four basil plants) were sampled for each treatment replicate, but these were pooled before chemical and GC-MS analysis. For Rounds 1 and 3, one chemical measurement was taken for each treatment (pooled sample). For the Round 2 GC-MS experiments, three technical replicates of each pooled sample preparation were analyzed. An Academic Editor advised that considering known limitations of GC-MS and especially since the data were used for modelling, this study did not include sufficient biological and technical replicates to yield reliable results. Consequently, the Academic Editor advised that the article’s conclusions are not adequately supported. The authors disagreed with points 2 and 3, above. Based on the expert input received, including the issues discussed above about reporting, limitations of the dataset, and insufficient replication, the PLOS ONE Editors concluded that there are concerns about the reliability of the article’s results and conclusions, and overall, the article did not meet the journal’s third and fourth publication criteria. (The third and fourth publication criteria require that experiments must have been conducted rigorously, with appropriate controls and replication; methods must be reported in sufficient detail to allow others to reproduce the study; and conclusions must be supported by the data.) Therefore, the PLOS ONE Editors retract this article. We regret that the issues with this article were not identified during the pre-publication peer review process. AJJ, EM, TLS, RM, and CBH did not agree with retraction and stand by the article’s findings. JdlP did not respond or could not be reached. Note: the computational modelling code used in this study was not provided with the published article but has since been deposited in the GitHub repository. The authors clarified that surrogate-optimization methods used the DEAP framework of Fortin et al. [2].",
        "DOI": "10.1371/journal.pone.0259294",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Long-term remote sensing monitoring on LUCC around Chaohu Lake with new information of algal bloom and flood submerging",
        "paper_author": "Lin Y.",
        "publication": "International Journal of Applied Earth Observation and Geoinformation",
        "citied_by": "17",
        "cover_date": "2021-10-01",
        "Abstract": "Human settlements are guided by the proximity or availability of a natural resource such as river or lake basins containing set of streams. The harmonious development of human activity and natural conditions along watershed areas needs close attention and in-depth study. In this paper, the urban agglomerations and ecological spaces in the Yangtze River Delta, China, the Chao Lake Basin and its surrounding watershed ecosystem is taken as research subject for its serious environmental degradation problems during social and economic development. This paper adopted an effective machine learning algorithm (kernel-ELM) to extract land use and land /cover information, and to analyze the land use/cover pattern evolution rules of the Chao Lake Basin with long term Landsat imagery. Subsequent studies were then carried out to demonstrate the flood-affected area and its ecological impact in the basin in 2020, to reveal the occupation on land cover types. The results indicate Conclusions are drawn from the experiment results: (1) There has been significant change in cultivated land, forest land and construction land out of six key land cover types with dynamic degree of −10.17%, 4.61, 67.04% respectively. (2) Algae bloom pollution was extracted from pattern classification results and it was up to 15% of the total water area by the year 2018. (3) The occupation on land use/cover types of the flood was revealed. The results prove effective application of remote sensing technology in environmental analysis and planning for data-driven evaluation of governing policy. This work serves as a scientific basis for environmental management and regional planning in the Chao Lake Basin and can be served as a basis and a reference for evaluating an ecological policy and its impact for other economic developing watershed human settlements with ecological issues.",
        "DOI": "10.1016/j.jag.2021.102413",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Computer-based decision tools for shared therapeutic decision-making in oncology: Systematic review",
        "paper_author": "Yung A.",
        "publication": "JMIR Cancer",
        "citied_by": "13",
        "cover_date": "2021-10-01",
        "Abstract": "Background: Therapeutic decision-making in oncology is a complex process because physicians must consider many forms of medical data and protocols. Another challenge for physicians is to clearly communicate their decision-making process to patients to ensure informed consent. Computer-based decision tools have the potential to play a valuable role in supporting this process. Objective: This systematic review aims to investigate the extent to which computer-based decision tools have been successfully adopted in oncology consultations to improve patient-physician joint therapeutic decision-making. Methods: This review was conducted in accordance with the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) 2020 checklist and guidelines. A literature search was conducted on February 4, 2021, across the Cochrane Database of Systematic Reviews (from 2005 to January 28, 2021), the Cochrane Central Register of Controlled Trials (December 2020), MEDLINE (from 1946 to February 4, 2021), Embase (from 1947 to February 4, 2021), Web of Science (from 1900 to 2021), Scopus (from 1969 to 2021), and PubMed (from 1991 to 2021). We used a snowball approach to identify additional studies by searching the reference lists of the studies included for full-text review. Additional supplementary searches of relevant journals and gray literature websites were conducted. The reviewers screened the articles eligible for review for quality and inclusion before data extraction. Results: There are relatively few studies looking at the use of computer-based decision tools in oncology consultations. Of the 4431 unique articles obtained from the searches, only 10 (0.22%) satisfied the selection criteria. From the 10 selected studies, 8 computer-based decision tools were identified. Of the 10 studies, 6 (60%) were conducted in the United States. Communication and information-sharing were improved between physicians and patients. However, physicians did not change their habits to take advantage of computer-assisted decision-making tools or the information they provide. On average, the use of these computer-based decision tools added approximately 5 minutes to the total length of consultations. In addition, some physicians felt that the technology increased patients' anxiety. Conclusions: Of the 10 selected studies, 6 (60%) demonstrated positive outcomes, 1 (10%) showed negative results, and 3 (30%) were neutral. Adoption of computer-based decision tools during oncology consultations continues to be low. This review shows that information-sharing and communication between physicians and patients can be improved with the assistance of technology. However, the lack of integration with electronic health records is a barrier. This review provides key requirements for enhancing the chance of success of future computer-based decision tools. However, it does not show the effects of health care policies, regulations, or business administration on physicians' propensity to adopt the technology. Nevertheless, it is important that future research address the influence of these higher-level factors as well.",
        "DOI": "10.2196/31616",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Learning TSP requires rethinking generalization",
        "paper_author": "Joshi C.K.",
        "publication": "Leibniz International Proceedings in Informatics, LIPIcs",
        "citied_by": "20",
        "cover_date": "2021-10-01",
        "Abstract": "End-to-end training of neural network solvers for combinatorial optimization problems such as the Travelling Salesman Problem is intractable and inefficient beyond a few hundreds of nodes. While state-of-the-art Machine Learning approaches perform closely to classical solvers when trained on trivially small sizes, they are unable to generalize the learnt policy to larger instances of practical scales. Towards leveraging transfer learning to solve large-scale TSPs, this paper identifies inductive biases, model architectures and learning algorithms that promote generalization to instances larger than those seen in training. Our controlled experiments provide the first principled investigation into such zero-shot generalization, revealing that extrapolating beyond training data requires rethinking the neural combinatorial optimization pipeline, from network layers and learning paradigms to evaluation protocols.",
        "DOI": "10.4230/LIPIcs.CP.2021.33",
        "affiliation_name": "Polytechnique Montréal",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine learning bias in predicting high school grades: A knowledge perspective",
        "paper_author": "Costa-Mendes R.",
        "publication": "Emerging Science Journal",
        "citied_by": "8",
        "cover_date": "2021-10-01",
        "Abstract": "This study focuses on the machine learning bias when predicting teacher grades. The experimental phase consists of predicting the student grades of 11th and 12th grade Portuguese high school grades and computing the bias and variance decomposition. In the base implementation, only the academic achievement critical factors are considered. In the second implementation, the preceding year’s grade is appended as an input variable. The machine learning algorithms in use are random forest, support vector machine, and extreme boosting machine. The reasons behind the poor performance of the machine learning algorithms are either the input space poor preciseness or the lack of a sound record of student performance. We introduce the new concept of knowledge bias and a new predictive model classification. Precision education would reduce bias by providing low-bias intensive-knowledge models. To avoid bias, it is not necessary to add knowledge to the input space. Low-bias extensive-knowledge models are achievable simply by appending the student’s earlier performance record to the model. The low-bias intensive-knowledge learning models promoted by precision education are suited to designing new policies and actions toward academic attainments. If the aim is solely prediction, deciding for a low bias knowledge-extensive model can be appropriate and correct.",
        "DOI": "10.28991/esj-2021-01298",
        "affiliation_name": "NOVA Information Management School, Universidade Nova de Lisboa",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Revisiting the ODE Method for Recursive Algorithms: Fast Convergence Using Quasi Stochastic Approximation",
        "paper_author": "Chen S.",
        "publication": "Journal of Systems Science and Complexity",
        "citied_by": "2",
        "cover_date": "2021-10-01",
        "Abstract": "Several decades ago, Profs. Sean Meyn and Lei Guo were postdoctoral fellows at ANU, where they shared interest in recursive algorithms. It seems fitting to celebrate Lei Guo’s 60th birthday with a review of the ODE Method and its recent evolution, with focus on the following themes:The method has been regarded as a technique for algorithm analysis. It is argued that this viewpoint is backwards: The original stochastic approximation method was surely motivated by an ODE, and tools for analysis came much later (based on establishing robustness of Euler approximations). The paper presents a brief survey of recent research in machine learning that shows the power of algorithm design in continuous time, following by careful approximation to obtain a practical recursive algorithm.While these methods are usually presented in a stochastic setting, this is not a prerequisite. In fact, recent theory shows that rates of convergence can be dramatically accelerated by applying techniques inspired by quasi Monte-Carlo.Subject to conditions, the optimal rate of convergence can be obtained by applying the averaging technique of Polyak and Ruppert. The conditions are not universal, but theory suggests alternatives to achieve acceleration.The theory is illustrated with applications to gradient-free optimization, and policy gradient algorithms for reinforcement learning.",
        "DOI": "10.1007/s11424-021-1251-5",
        "affiliation_name": "National Renewable Energy Laboratory",
        "affiliation_city": "Golden",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Data anonymization for pervasive health care: Systematic literature mapping study",
        "paper_author": "Zuo Z.",
        "publication": "JMIR Medical Informatics",
        "citied_by": "32",
        "cover_date": "2021-10-01",
        "Abstract": "Background: Data science offers an unparalleled opportunity to identify new insights into many aspects of human life withrecent advances in health care. Using data science in digital health raises significant challenges regarding data privacy, transparency,and trustworthiness. Recent regulations enforce the need for a clear legal basis for collecting, processing, and sharing data, forexample, the European Union's General Data Protection Regulation (2016) and the United Kingdom's Data Protection Act (2018).For health care providers, legal use of the electronic health record (EHR) is permitted only in clinical care cases. Any other useof the data requires thoughtful considerations of the legal context and direct patient consent. Identifiable personal and sensitiveinformation must be sufficiently anonymized. Raw data are commonly anonymized to be used for research purposes, with riskassessment for reidentification and utility. Although health care organizations have internal policies defined for informationgovernance, there is a significant lack of practical tools and intuitive guidance about the use of data for research and modeling.Off-The-shelf data anonymization tools are developed frequently, but privacy-related functionalities are often incomparable withregard to use in different problem domains. In addition, tools to support measuring the risk of the anonymized data with regardto reidentification against the usefulness of the data exist, but there are question marks over their efficacy.Objective: In this systematic literature mapping study, we aim to alleviate the aforementioned issues by reviewing the landscapeof data anonymization for digital health care.Methods: We used Google Scholar, Web of Science, Elsevier Scopus, and PubMed to retrieve academic studies published inEnglish up to June 2020. Noteworthy gray literature was also used to initialize the search. We focused on review questionscovering 5 bottom-up aspects: basic anonymization operations, privacy models, reidentification risk and usability metrics,off-The-shelf anonymization tools, and the lawful basis for EHR data anonymization.Results: We identified 239 eligible studies, of which 60 were chosen for general background information; 16 were selected for7 basic anonymization operations; 104 covered 72 conventional and machine learning-based privacy models; four and 19 papersincluded seven and 15 metrics, respectively, for measuring the reidentification risk and degree of usability; and 36 explored 20data anonymization software tools. In addition, we also evaluated the practical feasibility of performing anonymization on EHRdata with reference to their usability in medical decision-making. Furthermore, we summarized the lawful basis for deliveringguidance on practical EHR data anonymization.Conclusions: This systematic literature mapping study indicates that anonymization of EHR data is theoretically achievable;yet, it requires more research efforts in practical implementations to balance privacy preservation and usability to ensure morereliable health care applications.",
        "DOI": "10.2196/29871",
        "affiliation_name": "Durham University",
        "affiliation_city": "Durham",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "What influences attitudes about artificial intelligence adoption: Evidence from U.S. local officials",
        "paper_author": "Horowitz M.C.",
        "publication": "PLoS ONE",
        "citied_by": "34",
        "cover_date": "2021-10-01",
        "Abstract": "Rapid advances in machine learning and related techniques have increased optimism about self-driving cars, autonomous surgery, and other uses of artificial intelligence (AI). But adoption of these technologies is not simply a matter of breakthroughs in the design and training of algorithms. Regulators around the world will have to make a litany of choices about law and policy surrounding AI. To advance knowledge of how they will make these choices, we draw on a unique survey pool—690 local officials in the United States—a representative sample of U.S. local officials. These officials will make many of the decisions about AI adoption, from government use to regulation, given the decentralized structure of the United States. The results show larger levels of support for autonomous vehicles than autonomous surgery. Moreover, those that used ridesharing apps prior to the COVID-19 pandemic are significantly more supportive of autonomous vehicles. We also find that self-reported familiarity with AI is correlated with increased approval of AI uses in a variety of areas, including facial recognition, natural disaster impact planning, and even military surveillance. Related, those who expressed greater opposition to AI adoption also appear more concerned about trade-offs between privacy and information and bias in algorithms. Finally, the explanatory logic used by respondents varies based on gender and prior experience with AI, which we demonstrate with quantitative text analysis.",
        "DOI": "10.1371/journal.pone.0257732",
        "affiliation_name": "University of Pennsylvania",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multi-Agent RL Enables Decentralized Spectrum Access in Vehicular Networks",
        "paper_author": "Xiang P.",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "35",
        "cover_date": "2021-10-01",
        "Abstract": "In this paper, we investigate the joint sub-channel and power allocation problem for cellular vehicle-to-everything (V2X) communications, where multiple vehicle-to-infrastructure (V2I) users share the spectrum resources with vehicle-to-vehicle (V2V) users. In particular, a novel channel state information (CSI)-independent decentralized algorithm based on multi-agent reinforcement learning (MARL) is proposed to maximize the sum throughput of V2I links while meeting the latency and reliability requirements of V2V links. Specifically, we implement the individual double dueling deep recurrent Q-networks (D3RQN) and the carefully designed common reward to train the implicitly collaborative agents, through which, each agent optimizes the policy individually based solely on local CSI-independent observations. To handle the non-stationarity induced by multi-agent concurrent learning, we incorporate hysteretic Q-learning and concurrent experience replay trajectory (CERT) to stabilize the training process. Besides, we incorporate the approximate regretted reward (ARR) to alleviate the unstable reward estimation problem caused by shifting environment dynamics. Simulation results demonstrate that the proposed algorithm outperforms the baselines and can achieve close performance compared with the centralized Brute-force method. Furthermore, the proposed CSI-independent design exhibits comparable performance as the CSI-involved version, which sheds some light on the potential to further reduce the signalling overhead of machine learning-based vehicular communication systems.",
        "DOI": "10.1109/TVT.2021.3103058",
        "affiliation_name": "College of Information Science and Electronic Engineering, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Empirical observation of negligible fairness–accuracy trade-offs in machine learning for public policy",
        "paper_author": "Rodolfa K.T.",
        "publication": "Nature Machine Intelligence",
        "citied_by": "54",
        "cover_date": "2021-10-01",
        "Abstract": "The growing use of machine learning in policy and social impact settings has raised concerns over fairness implications, especially for racial minorities. These concerns have generated considerable interest among machine learning and artificial intelligence researchers, who have developed new methods and established theoretical bounds for improving fairness, focusing on the source data, regularization and model training, or post-hoc adjustments to model scores. However, few studies have examined the practical trade-offs between fairness and accuracy in real-world settings to understand how these bounds and methods translate into policy choices and impact on society. Our empirical study fills this gap by investigating the impact of mitigating disparities on accuracy, focusing on the common context of using machine learning to inform benefit allocation in resource-constrained programmes across education, mental health, criminal justice and housing safety. Here we describe applied work in which we find fairness–accuracy trade-offs to be negligible in practice. In each setting studied, explicitly focusing on achieving equity and using our proposed post-hoc disparity mitigation methods, fairness was substantially improved without sacrificing accuracy. This observation was robust across policy contexts studied, scale of resources available for intervention, time and the relative size of the protected groups. These empirical results challenge a commonly held assumption that reducing disparities requires either accepting an appreciable drop in accuracy or the development of novel, complex methods, making reducing disparities in these applications more practical.",
        "DOI": "10.1038/s42256-021-00396-x",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting covid‐19 vaccination intention: The determinants of vaccine hesitancy",
        "paper_author": "Fernandes N.",
        "publication": "Vaccines",
        "citied_by": "40",
        "cover_date": "2021-10-01",
        "Abstract": "Do people want to be vaccinated against COVID‐19? Herd immunity is dependent on individuals’ willingness to be vaccinated since vaccination is not mandatory. Our main goal was to investigate people’s intention to be vaccinated and their intentions to vaccinate their children. Moreover, we were interested in understanding the role of the personal characteristics, psychological factors, and the lockdown context on that decision. Therefore, we conducted an online survey during the lockdown in Portugal (15 January 2021 until 14 March 2021). Participants completed a socio‐demographic questionnaire, questions about their intentions of being vaccinated, concerns about the vaccine, a COVID‐19 attitudes and beliefs scale, a COVID‐19 vaccine attitudes and beliefs scale, and the Domain‐Specific Risk‐Taking (DOSPERT) Scale. Our results showed that from the 649 participants, 63% of the participants reported being very likely to have the vaccine, while 60% reported being very likely to vaccinate their children. We conducted two linear regression models, explaining 65% of the variance for personal vaccination and 56% of the variance for children vaccination. We found that the COVID‐19 vaccine general beliefs and attitudes were the main determinants of vaccination intention. Additionally, our proposed artificial neural network model was able to predict with 85% accuracy vaccination intention. Thus, our results suggest that psychological factors are an essential determinant of vaccination intention. Thus, public policy decision makers may use these insights for predicting vaccine hesitancy and designing effective vaccination communication strategies.",
        "DOI": "10.3390/vaccines9101161",
        "affiliation_name": "Universidade de Aveiro",
        "affiliation_city": "Aveiro",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Prediction of viral symptoms using wearable technology and artificial intelligence: A pilot study in healthcare workers",
        "paper_author": "D'Haese P.F.",
        "publication": "PLoS ONE",
        "citied_by": "13",
        "cover_date": "2021-10-01",
        "Abstract": "Conventional testing and diagnostic methods for infections like SARS-CoV-2 have limitations for population health management and public policy. We hypothesize that daily changes in autonomic activity, measured through off-the-shelf technologies together with app-based cognitive assessments, may be used to forecast the onset of symptoms consistent with a viral illness. We describe our strategy using an AI model that can predict, with 82% accuracy (negative predictive value 97%, specificity 83%, sensitivity 79%, precision 34%), the likelihood of developing symptoms consistent with a viral infection three days before symptom onset. The model correctly predicts, almost all of the time (97%), individuals who will not develop viral-like illness symptoms in the next three days. Conversely, the model correctly predicts as positive 34% of the time, individuals who will develop viral-like illness symptoms in the next three days. This model uses a conservative framework, warning potentially pre-symptomatic individuals to socially isolate while minimizing warnings to individuals with a low likelihood of developing viral-like symptoms in the next three days. To our knowledge, this is the first study using wearables and apps with machine learning to predict the occurrence of viral illness-like symptoms. The demonstrated approach to forecasting the onset of viral illness-like symptoms offers a novel, digital decision-making tool for public health safety by potentially limiting viral transmission.",
        "DOI": "10.1371/journal.pone.0257997",
        "affiliation_name": "WVU Health Sciences Center Morgantown",
        "affiliation_city": "Morgantown",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Twin-delayed deep deterministic policy gradient for low-frequency oscillation damping control",
        "paper_author": "Cui Q.",
        "publication": "Energies",
        "citied_by": "7",
        "cover_date": "2021-10-01",
        "Abstract": "Due to the large scale of power systems, latency uncertainty in communications can cause severe problems in wide-area measurement systems. To resolve this issue, a significant amount of past work focuses on using emerging technology, including machine learning methods such as Q-learning, for addressing latency issues in modern controls. Although the method can deal with the stochastic characteristics of communication latency, the Q-values can be overestimated in Q-learning methods, leading to high bias. To address the overestimation bias issue, we redesign the learning structure of the deep deterministic policy gradient (DDPG). Then we develop a damping control twin-delayed deep deterministic policy gradient method to handle the damping control issue under unknown latency in the power network. The purpose is to address the damping control issue under unknown latency in the power network. This paper will create a novel reward algorithm, taking into account the machine speed deviation, the episode termination prevention, and the feedback from action space. In this way, the system optimally damps down frequency oscillations while maintaining the system’s stability and reliable operation within defined limits. The simulation results verify the proposed algorithm in various perspectives, including the latency sensitivity analysis under high renewable energy penetration and the comparison with conventional and machine learning control algorithms. The proposed method shows a fast learning curve and good control performance under varying communication latency.",
        "DOI": "10.3390/en14206695",
        "affiliation_name": "Ira A. Fulton Schools of Engineering",
        "affiliation_city": "Tempe",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Cluster forecasting of corruption using nonlinear autoregressive models with exogenous variables (Narx)—an artificial neural network analysis",
        "paper_author": "Ghahari S.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "6",
        "cover_date": "2021-10-01",
        "Abstract": "Any effort to combat corruption can benefit from an examination of past and projected worldwide trends. In this paper, we forecast the level of corruption in countries by integrating artificial neural network modeling and time series analysis. The data were obtained from 113 countries from 2007 to 2017. The study is carried out at two levels: (a) the global level, where all countries are considered as a monolithic group; and (b) the cluster level, where countries are placed into groups based on their development‐related attributes. For each cluster, we use the findings from our previous study on the cluster analysis of global corruption using machine learning methods that identified the four most influential corruption factors, and we use those as independent variables. Then, using the identified influential factors, we forecast the level of corruption in each cluster using nonlinear autoregressive recurrent neural network models with exogenous inputs (NARX), an artificial neural network technique. The NARX models were developed for each cluster, with an objective function in terms of the Corruption Perceptions Index (CPI). For each model, the optimal neural network is determined by fine‐tuning the hyperparameters. The analysis was repeated for all countries as a single group. The accuracy of the models is assessed by comparing the mean square errors (MSEs) of the time series models. The results suggest that the NARX artificial neural network technique yields reliable future values of CPI globally or for each cluster of countries. This can assist policymakers and organizations in assessing the expected efficacies of their current or future corruption control policies from a global perspective as well as for groups of countries.",
        "DOI": "10.3390/su132011366",
        "affiliation_name": "The World Bank, USA",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Potential role of technology innovation in transformation of sustainable food systems: A review",
        "paper_author": "Khan N.",
        "publication": "Agriculture (Switzerland)",
        "citied_by": "64",
        "cover_date": "2021-10-01",
        "Abstract": "Advanced technologies and innovation are essential for promoting sustainable food systems (SFSs) because these technologies can be used to answer some of the critical questions needed to transform SFSs and help us better understand global food security and nutrition. The main ob-jective of this study is to address the question of whether technological innovations have an impact on the transformation of SFSs. There are certain innovations including agricultural land utilization, food processing, production systems, improvement in diets according to people’s needs, and management of waste products. This study provides an overview of new technologies and innovations being used with potential to transform SFSs. Applications of emerging technologies in digital agri-culture, including the Internet of Things (IoT), artificial intelligence and machine learning, drones, use of new physical systems (e.g., advanced robotics, autonomous vehicles, advanced materials), and gene technology (e.g., biofortified crops, genome-wide selection, genome editing), are dis-cussed in this study. Additionally, we suggest eight action initiatives, which are transforming mind-sets, enabling social licensing, changing policies and regulations, designing market incentives, safe-guarding against undesirable effects, ensuring stable finance, building trust, and developing transition pathways that can hasten the transition to more SFSs. We conclude that appropriate incen-tives, regulations, and social permits play a critical role in enhancing the adoption of modern technologies to promote SFSs.",
        "DOI": "10.3390/agriculture11100984",
        "affiliation_name": "Huazhong Agricultural University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Ml-clock: Efficient page cache algorithm based on perceptron-based neural network",
        "paper_author": "Cho M.",
        "publication": "Electronics (Switzerland)",
        "citied_by": "6",
        "cover_date": "2021-10-01",
        "Abstract": "Today, research trends clearly confirm the fact that machine learning technologies open up new opportunities in various computing environments, such as Internet of Things, mobile, and enterprise. Unfortunately, the prior efforts rarely focused on designing system-level input/output stacks (e.g., page cache, file system, block input/output, and storage devices). In this paper, we propose a new page replacement algorithm, called ML-CLOCK, that embeds single-layer perceptron neural network algorithms to enable an intelligent eviction policy. In addition, ML-CLOCK employs preference rules that consider the features of the underlying storage media (e.g., asymmetric read and write costs and efficient write patterns). For evaluation, we implemented a prototype of ML-CLOCK based on trace-driven simulation and compared it with the traditional four replacement algorithms and one flash-friendly algorithm. Our experimental results on the trace-driven environments clearly confirm that ML-CLOCK can improve the hit ratio by up to 72% and reduces the elapsed time by up to 2.16x compared with least frequently used replacement algorithms.",
        "DOI": "10.3390/electronics10202503",
        "affiliation_name": "Changwon National University",
        "affiliation_city": "Changwon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Dueling double Q-learning based reinforcement learning approach for the flow shop scheduling problem",
        "paper_author": "Kim S.J.",
        "publication": "Transactions of the Korean Institute of Electrical Engineers",
        "citied_by": "1",
        "cover_date": "2021-10-01",
        "Abstract": "Flow shop scheduling is an important optimization problem for operating actual manufacturing facilities. In this paper, we propose a novel flow shop scheduling scheme based on the double Q-learning and the dueling architecture. We designed double Q-learning process using two estimation functions rather than a single estimation function to avoid over-estimation problem. In addition, the adaptation of the dueling architecture, which can provide robust policy estimation performance using both the state function and the advantage function, leading to less-variance and efficient learning process. We conducted extensive simulations of flow shop scheduling using multiple datasets with various scheduling scales. From the simulation result, we observed that the proposed scheme outperforms the existing heuristic and reinforcement learning-based scheduling schemes in terms of the final manufacturing time consumption for various flow shop scales.",
        "DOI": "10.5370/KIEE.2021.70.10.1497",
        "affiliation_name": "Changwon National University",
        "affiliation_city": "Changwon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A novel method for performance measurement of public educational institutions using machine learning models",
        "paper_author": "Alam T.M.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "33",
        "cover_date": "2021-10-01",
        "Abstract": "Lack of education is a major concern in underdeveloped countries because it leads to poor human and economic development. The level of education in public institutions varies across all regions around the globe. Current disparities in access to education worldwide are mostly due to systemic regional differences and the distribution of resources. Previous research focused on evaluating students’ academic performance, but less has been done to measure the performance of educational institutions. Key performance indicators for the evaluation of institutional performance differ from student performance indicators. There is a dire need to evaluate educational institutions’ performance based on their disparities and academic results on a large scale. This study proposes a model to measure institutional performance based on key performance indicators through data mining techniques. Various feature selection methods were used to extract the key performance indicators. Several machine learning models, namely, J48 decision tree, support vector machines, random forest, rotation forest, and artificial neural networks were employed to build an efficient model. The results of the study were based on different factors, i.e., the number of schools in a specific region, teachers, school locations, enrolment, and availability of necessary facilities that contribute to school performance. It was also observed that urban regions performed well compared to rural regions due to the improved availability of educational facilities and resources. The results showed that artificial neural networks outperformed other models and achieved an accuracy of 82.9% when the relief‐F based feature selection method was used. This study will help support efforts in governance for performance monitoring, policy formulation, target‐setting, evaluation, and reform to address the issues and challenges in education worldwide.",
        "DOI": "10.3390/app11199296",
        "affiliation_name": "Virtual University of Pakistan",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "A deep learning framework under attention mechanism for wheat yield estimation using remotely sensed indices in the Guanzhong Plain, PR China",
        "paper_author": "Tian H.",
        "publication": "International Journal of Applied Earth Observation and Geoinformation",
        "citied_by": "76",
        "cover_date": "2021-10-01",
        "Abstract": "The rapid and effective acquisition of crop yield information is critical to the stability of food markets and development and implementation of related policies. It is an important baseline observation that is used for ensuring regional and global food security. In this study, a novel deep learning framework was developed for winter wheat yield estimation using meteorological data and two remotely sensed indices, Vegetation Temperature Condition Index (VTCI) and Leaf Area Index (LAI) at the main growth stages of winter wheat in the Guanzhong Plain. The proposed deep learning model was based on Long Short-Term Memory (LSTM) neural network with an attention mechanism (ALSTM), which the main idea is to assign attention to the key parts of the input sequence that affect the target vectors so that the specific features can be accurately extracted. The ALSTM model provided an improved estimation accuracy (R2 = 0.63, MAPE = 8.20%, RMSE = 502.71 kg/ha, NRMSE = 11.15%) as compared with the LSTM (R2 = 0.55, MAPE = 13.46%, RMSE = 699.92 kg/ha, NRMSE = 15.52%). A validation based on leave-one-year-out-validation further substantiated the robustness of ALSTM with smaller values of NRMSE and MAPE (13.63% and 11.54%). We demonstrated that the ALSTM model provided good generalization ability for sampling sites under different farming systems, including irrigation and rain-fed sampling sites. In addition, we evaluated the relative importance of each input variable in determining yields based on stepwise sensitivity analysis. It was found that LAI at the heading-filling stage and the milk stage as well as VTCI at the jointing stage contributed more than other input feature variables towards the corresponding yield. In conclusion, our findings highlighted that the attention mechanism helped to improve the interpretability of neural networks and the ALSTM model along with remotely sensed biophysical indices can provide a reliable and robust estimation of crop yield. An accurate estimation of wheat yield is not only helping towards informed crop management decisions but it will improve efficiency and sustainability of farming operations.",
        "DOI": "10.1016/j.jag.2021.102375",
        "affiliation_name": "University of Leicester",
        "affiliation_city": "Leicester",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A comprehensive techno-eco-assessment of CO<inf>2</inf> enhanced oil recovery projects using a machine-learning assisted workflow",
        "paper_author": "You J.",
        "publication": "International Journal of Greenhouse Gas Control",
        "citied_by": "7",
        "cover_date": "2021-10-01",
        "Abstract": "Carbon dioxide enhanced oil recovery (CO2-EOR) projects not only extract residual oil but also sequestrate CO2 in the depleted reservoirs. This study develops a machine-learning-based workflow to co-optimize the hydrocarbon recovery, CO2 sequestration volume and project net present value (NPV) simultaneously. Considering the trade-off relationships among the objective functions, support vector regression with Gaussian kernel (Gaussian- SVR) proxies are coupled with multi-objective particle swarm optimization (PSO) protocol and generate Pareto optimal solutions. Taking advantage of the high computational efficacy of the proxy model, economic uncertainties introduced by tax credits, capital costs and oil price are investigated by this study. The results indicate that the tax incentive policy (Section 45Q) plays a vital role in enhancing the economic returns of CO2-EOR projects, especially under the depression of crude oil market. The proposed workflow has been successfully implemented to optimize a water alternative CO2 (CO2-WAG) injection project in a depleted oil sand in the US. The optimization results yield an incremental oil production of 15.8 MM STB and 1.37 MM metric tons of CO2 storage in a 20-year development strategy, with the highest project NPV to be 205.6 MM US dollars.",
        "DOI": "10.1016/j.ijggc.2021.103480",
        "affiliation_name": "Chongqing University of Science and Technology",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Digital technologies and open data sources in marine biotoxins’ risk analysis: The case of ciguatera fish poisoning",
        "paper_author": "Katikou P.",
        "publication": "Toxins",
        "citied_by": "7",
        "cover_date": "2021-10-01",
        "Abstract": "Currently, digital technologies influence information dissemination in all business sectors, with great emphasis put on exploitation strategies. Public administrations often use information systems and establish open data repositories, primarily supporting their operation but also serving as data providers, facilitating decision‐making. As such, risk analysis in the public health sector, including food safety authorities, often relies on digital technologies and open data sources. Global food safety challenges include marine biotoxins (MBs), being contaminants whose mitigation largely depends on risk analysis. Ciguatera Fish Poisoning (CFP), in particular, is a MB‐related seafood intoxication attributed to the consumption of fish species that are prone to accumulate ciguatoxins. Historically, CFP occurred endemically in tropical/subtropical areas, but has gradually emerged in temperate regions, including European waters, necessitating official policy adoption to manage the potential risks. Researchers and policy‐makers highlight scientific data inadequacy, under‐reporting of outbreaks and information source fragmentation as major obstacles in developing CFP mitigation strategies. Although digital technologies and open data sources provide exploitable scientific information for MB risk analysis, their utilization in counteracting CFP‐related hazards has not been addressed to date. This work thus attempts to answer the question, “What is the current extent of digital technologies’ and open data sources’ utilization within risk analysis tasks in the MBs field, particularly on CFP?”, by conducting a systematic literature review of the available scientific and grey literature. Results indicate that the use of digital technologies and open data sources in CFP is not negligible. However, certain gaps are identified regarding discrepancies in terminology, source fragmentation and a redundancy and downplay of social media utilization, in turn constituting a future research agenda for this under‐researched topic.",
        "DOI": "10.3390/toxins13100692",
        "affiliation_name": "Ministry of Rural Development and Food",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Evaluating the dynamics of bluetooth low energy based covid-19 risk estimation for educational institutes",
        "paper_author": "Aljohani A.J.",
        "publication": "Sensors",
        "citied_by": "13",
        "cover_date": "2021-10-01",
        "Abstract": "COVID-19 tracing applications have been launched in several countries to track and control the spread of viruses. Such applications utilize Bluetooth Low Energy (BLE) transmissions, which are short range and can be used to determine infected and susceptible persons near an infected person. The COVID-19 risk estimation depends on an epidemic model for the virus behavior and Machine Learning (ML) model to classify the risk based on time series distance of the nodes that may be infected. The BLE technology enabled smartphones continuously transmit beacons and the distance is inferred from the received signal strength indicators (RSSI). The educational activities have shifted to online teaching modes due to the contagious nature of COVID-19. The government policy makers decide on education mode (online, hybrid, or physical) with little technological insight on actual risk estimates. In this study, we analyze BLE technology to debate the COVID-19 risks in university block and indoor class environments. We utilize a sigmoid based epidemic model with varying thresholds of distance to label contact data with high risk or low risk based on features such as contact duration. Further, we train multiple ML classifiers to classify a person into high risk or low risk based on labeled data of RSSI and distance. We analyze the accuracy of the ML classifiers in terms of F-score, receiver operating characteristic (ROC) curve, and confusion matrix. Lastly, we debate future research directions and limitations of this study. We complement the study with open source code so that it can be validated and further investigated.",
        "DOI": "10.3390/s21196667",
        "affiliation_name": "COMSATS University Islamabad, Abbottabad Campus",
        "affiliation_city": "Abbottabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Dataset of COVID-19 outbreak and potential predictive features in the USA",
        "paper_author": "Haratian A.",
        "publication": "Data in Brief",
        "citied_by": "8",
        "cover_date": "2021-10-01",
        "Abstract": "This dataset provides information related to the outbreak of COVID-19 disease in the United States, including data from each of 3142 US counties from the beginning of the outbreak (January 2020) until June 2021. This data is collected from many public online databases and includes the daily number of COVID-19 confirmed cases and deaths, as well as 46 features that may be relevant to the pandemic dynamics: demographic, geographic, climatic, traffic, public-health, social-distancing-policy adherence, and political characteristics of each county. We anticipate many researchers will use this dataset to train models that can predict the spread of COVID-19 and to identify the key driving factors.",
        "DOI": "10.1016/j.dib.2021.107360",
        "affiliation_name": "Alberta Machine Intelligence Institute",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Predicting fitness centre dropout",
        "paper_author": "Sobreiro P.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "4",
        "cover_date": "2021-10-01",
        "Abstract": "The phenomenon of dropout is often found among customers of sports services. In this study we intend to evaluate the performance of machine learning algorithms in predicting dropout using available data about their historic use of facilities. The data relating to a sample of 5209 members was taken from a Portuguese fitness centre and included the variables registration data, payments and frequency, age, sex, non-attendance days, amount billed, average weekly visits, total number of visits, visits hired per week, number of registration renewals, number of members referrals, total monthly registrations, and total member enrolment time, which may be indicative of members’ commitment. Whilst the Gradient Boosting Classifier had the best performance in predicting dropout (sensitivity = 0.986), the Random Forest Classifier was the best at predicting non-dropout (specificity = 0.790); the overall performance of the Gradient Boosting Classifier was superior to the Random Forest Classifier (accuracy 0.955 against 0.920). The most relevant variables predicting dropout were “non-attendance days”, “total length of stay”, and “total amount billed”. The use of decision trees provides information that can be readily acted upon to identify member profiles of those at risk of dropout, giving also guidelines for measures and policies to reduce it.",
        "DOI": "10.3390/ijerph181910465",
        "affiliation_name": "University Institute of Maia",
        "affiliation_city": "Maia",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Texture is important in improving the accuracy of mapping photovoltaic power plants: A case study of ningxia autonomous region, china",
        "paper_author": "Zhang X.",
        "publication": "Remote Sensing",
        "citied_by": "30",
        "cover_date": "2021-10-01",
        "Abstract": "Photovoltaic (PV) technology is becoming more popular due to climate change because it allows for replacing fossil-fuel power generation to reduce greenhouse gas emissions. Consequently, many countries have been attempting to generate electricity through PV power plants over the last decade. Monitoring PV power plants through satellite imagery, machine learning models, and cloud-based computing systems that may ensure rapid and precise locating with current status on a regional basis are crucial for environmental impact assessment and policy formulation. The effect of fusion of the spectral, textural with different neighbor sizes, and topographic features that may improve machine learning accuracy has not been evaluated yet in PV power plants’ mapping. This study mapped PV power plants using a random forest (RF) model on the Google Earth Engine (GEE) platform. We combined textural features calculated from the Grey Level Co-occurrence Matrix (GLCM), reflectance, thermal spectral features, and Normalized Difference Vegetation Index (NDVI), Normalized Difference Built-up Index (NDBI), and Modified Normalized Difference Water Index (MNDWI) from Landsat-8 imagery and elevation, slope, and aspect from Shuttle Radar Topography Mission (SRTM) as input variables. We found that the textural features from GLCM prominent enhance the accuracy of the random forest model in identifying PV power plants where a neighbor size of 30 pixels showed the best model performance. The addition of texture features can improve model accuracy from a Kappa statistic of 0.904 ± 0.05 to 0.938 ± 0.04 and overall accuracy of 97.45 ± 0.14% to 98.32 ± 0.11%. The topographic and thermal features contribute a slight improvement in modeling. This study extends the knowledge of the effect of various variables in identifying PV power plants from remote sensing data. The texture characteristics of PV power plants at different spatial resolutions deserve attention. The findings of our study have great significance for collecting the geographic information of PV power plants and evaluating their environmental impact.",
        "DOI": "10.3390/rs13193909",
        "affiliation_name": "Henan University",
        "affiliation_city": "Kaifeng",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep reinforcement learning for computation offloading and resource allocation in unmanned-aerial-vehicle assisted edge computing",
        "paper_author": "Li S.",
        "publication": "Sensors",
        "citied_by": "27",
        "cover_date": "2021-10-01",
        "Abstract": "Computation offloading technology extends cloud computing to the edge of the access network close to users, bringing many benefits to terminal devices with limited battery and computational resources. Nevertheless, the existing computation offloading approaches are challenging to apply to specific scenarios, such as the dense distribution of end-users and the sparse distribution of network infrastructure. The technological revolution in the unmanned aerial vehicle (UAV) and chip industry has granted UAVs more computing resources and promoted the emergence of UAV-assisted mobile edge computing (MEC) technology, which could be applied to those scenarios. However, in the MEC system with multiple users and multiple servers, making reasonable offloading decisions and allocating system resources is still a severe challenge. This paper studies the offloading decision and resource allocation problem in the UAV-assisted MEC environment with multiple users and servers. To ensure the quality of service for end-users, we set the weighted total cost of delay, energy consumption, and the size of discarded tasks as our optimization objective. We further formulate the joint optimization problem as a Markov decision process and apply the soft actor–critic (SAC) deep reinforcement learning algorithm to optimize the offloading policy. Numerical simulation results show that the offloading policy optimized by our proposed SAC-based dynamic computing offloading (SACDCO) algorithm effectively reduces the delay, energy consumption, and size of discarded tasks for the UAV-assisted MEC system. Compared with the fixed local-UAV scheme in the specific simulation setting, our proposed approach reduces system delay and energy consumption by approximately 50% and 200%, respectively.",
        "DOI": "10.3390/s21196499",
        "affiliation_name": "Lanzhou Jiaotong University",
        "affiliation_city": "Lanzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "LSTM-DDPG for trading with variable positions",
        "paper_author": "Jia Z.",
        "publication": "Sensors",
        "citied_by": "8",
        "cover_date": "2021-10-01",
        "Abstract": "In recent years, machine learning for trading has been widely studied. The direction and size of position should be determined in trading decisions based on market conditions. However, there is no research so far that considers variable position sizes in models developed for trading purposes. In this paper, we propose a deep reinforcement learning model named LSTM-DDPG to make trading decisions with variable positions. Specifically, we consider the trading process as a Partially Observable Markov Decision Process, in which the long short-term memory (LSTM) network is used to extract market state features and the deep deterministic policy gradient (DDPG) framework is used to make trading decisions concerning the direction and variable size of position. We test the LSTM-DDPG model on IF300 (index futures of China stock market) data and the results show that LSTM-DDPG with variable positions performs better in terms of return and risk than models with fixed or few-level positions. In addition, the investment potential of the model can be better tapped by the reward function of the differential Sharpe ratio than that of profit reward function.",
        "DOI": "10.3390/s21196571",
        "affiliation_name": "Birmingham City University",
        "affiliation_city": "Birmingham",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Nonlinear causality between crude oil prices and exchange rates: Evidence and forecasting",
        "paper_author": "Orzeszko W.",
        "publication": "Energies",
        "citied_by": "12",
        "cover_date": "2021-10-01",
        "Abstract": "The relationships between crude oil prices and exchange rates have always been of interest to academics and policy analysts. There are theoretical transmission channels that justify such links; however, the empirical evidence is not clear. Most of the studies on causal relationships in this area have been restricted to a linear framework, which can omit important properties of the investigated dependencies that could be exploited for forecasting purposes. Based on the nonlinear Granger causality tests, we found strong bidirectional causal relations between crude oil prices and two currency pairs: EUR/USD, GBP/USD, and weaker between crude oil prices and JPY/USD. We showed that the significance of these relations has changed in recent years. We also made an attempt to find an effective strategy to forecast crude oil prices using the investigated exchange rates as regressors and vice versa. To this aim, we applied Support Vector Regression (SVR)—the machine learning method of time series modeling and forecasting.",
        "DOI": "10.3390/en14196043",
        "affiliation_name": "Uniwersytet Mikołaja Kopernika w Toruniu",
        "affiliation_city": "Torun",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "FL instructor beliefs about machine translation: Ecological insights to guide research and practice",
        "paper_author": "Hellmich E.",
        "publication": "International Journal of Computer-Assisted Language Learning and Teaching",
        "citied_by": "18",
        "cover_date": "2021-10-01",
        "Abstract": "Machine translation (MT) platforms have gained increasing attention in the educational linguistics community. The current article extends past research on instructor beliefs about MT by way of an ecological theoretical framework. The study reports on a large-scale survey (n=165) of FL universitylevel instructors in the U.S. Findings indicate strong lines being drawn around acceptable MT use (e.g., in relation to text length and skill, policies), an acknowledgement of widespread student use driven by diverse motivations, and the Janus-faced nature of MT's potential threat to the profession. These findings reveal several salient tensions in how MT mediates relationships in language education (e.g., constructions of students, the nature of language and language learning, goals of the profession) that shed new light on the impact of MT technologies on the field. Implications for future research and the development of pedagogical practices anchored in digital literacies conclude the piece.",
        "DOI": "10.4018/IJCALLT.2021100101",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning deep energy shaping policies for stability-guaranteed manipulation",
        "paper_author": "Khader S.A.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "11",
        "cover_date": "2021-10-01",
        "Abstract": "Deep reinforcement learning (DRL) has been successfully used to solve various robotic manipulation tasks. However, most of the existing works do not address the issue of control stability. This is in sharp contrast to the control theory community where the well-established norm is to prove stability whenever a control law is synthesized. What makes traditional stability analysis difficult for DRL are the uninterpretable nature of the neural network policies and unknown system dynamics. In this work, stability is obtained by deriving an interpretable deep policy structure based on the energy shaping control of Lagrangian systems. Then, stability during physical interaction with an unknown environment is established based on passivity. The result is a stability guaranteeing DRL in a model-free framework that is general enough for contact-rich manipulation tasks. With an experiment on a peg-in-hole task, we demonstrate, to the best of our knowledge, the first DRL with stability guarantee on a real robotic manipulator.",
        "DOI": "10.1109/LRA.2021.3111962",
        "affiliation_name": "ABB Corporate Research, Vasteras",
        "affiliation_city": "Vasteras",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Paving New Roads Towards Biodiversity-Based Drug Development in Brazil: Lessons from the Past and Future Perspectives",
        "paper_author": "Braga F.C.",
        "publication": "Revista Brasileira de Farmacognosia",
        "citied_by": "6",
        "cover_date": "2021-10-01",
        "Abstract": "Although Brazil gathers two fundamental features to occupy a leading position on the development of biodiversity-based medicines, the largest flora on earth and a broad tradition on the use of medicinal plants, the number of products derived from the national genetic heritage is so far modest, either as single drugs or as herbal medicines. This article highlights some aspects that may have contributed to the low rates of success and proposes new insights for innovation. We initially approach the use of medicinal plants in Brazil, molded by its ethnic diversity, and the development of the local pharmaceutical industry. A discussion of some governmental initiatives to support plant-based drug development is then presented. Employing the economic concept of “middle-income trap,” we further propose that Brazil is stuck in a “middle-level science trap,” since the increase in the number of scientific publications that launched the country to an intermediate publishing position has not been translated into drug development. Two new approaches to escape from this trap are presented, which may result in innovative drug development. The first is based on the exploitation of the antifragility properties of herbal products aiming to investigate non-canonical pharmacodynamics mechanisms of action, aligned with the concepts of system biology. The second is the manufacture of herbal products based on the circular economy principles, including the use of byproducts for the development of new therapeutical agents. The adoption of these strategies may result in innovative phytomedicines, with global competitiveness. Graphical abstract: [Figure not available: see fulltext.]",
        "DOI": "10.1007/s43450-021-00181-2",
        "affiliation_name": "Universidade Federal de Minas Gerais",
        "affiliation_city": "Belo Horizonte",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Diversity in Clinical Pharmacology and Therapeutics",
        "paper_author": "van der Graaf P.H.",
        "publication": "Clinical Pharmacology and Therapeutics",
        "citied_by": "4",
        "cover_date": "2021-10-01",
        "Abstract": "NA",
        "DOI": "10.1002/cpt.2391",
        "affiliation_name": "Certara, United Kingdom",
        "affiliation_city": "Canterbury",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Predicting length of stay and mortality among hospitalized patients with type 2 diabetes mellitus and hypertension",
        "paper_author": "Barsasella D.",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "11",
        "cover_date": "2021-10-01",
        "Abstract": "Background: Type 2 diabetes mellitus (T2DM) and hypertension (HTN), both non-communicable diseases, are leading causes of death globally, with more imbalances in lower middle-income countries. Furthermore, poor treatment and management are known to lead to intensified healthcare utilization and increased medical care costs and impose a significant societal burden, in these countries, including Indonesia. Predicting future clinical outcomes can determine the line of treatment and value of healthcare costs, while ensuring effective patient care. In this paper, we present the prediction of length of stay (LoS) and mortality among hospitalized patients at a tertiary referral hospital in Tasikmalaya, Indonesia, between 2016 and 2019. We also aimed to determine how socio-demographic characteristics, and T2DM- or HTN-related comorbidities affect inpatient LoS and mortality. Methods: We analyzed insurance claims data of 4376 patients with T2DM or HTN hospitalized in the referral hospital. We used four prediction models based on machine-learning algorithms for LoS prediction, in relation to disease severity, physician-in-charge, room type, co-morbidities, and types of procedures performed. We used five classifiers based on multilayer perceptron (MLP) to predict inpatient mortality and compared them according to training time, testing time, and Area under Receiver Operative Curve (AUROC). Classifier accuracy measures, which included positive predictive value (PPV), negative predictive value (NPV), F-Measure, and recall, were used as performance evaluation methods. Results: A Random forest best predicted inpatient LoS (R2, 0.70; root mean square error [RMSE], 1.96; mean absolute error [MAE], 0.935), and the gradient boosting regression model also performed similarly (R2, 0.69; RMSE, 1.96; MAE, 0.935). For inpatient mortality, best results were observed using MLP with back propagation (AUROC 0.899; 69.33 and 98.61 for PPV and NPV, respectively). The other classifiers, stochastic gradient descent with regression loss function, Huber, and random forest models all showed an average performance. Conclusions: Linear regression model best predicted LoS and mortality was best predicted using MLP. Patients with primary diseases such as T2DM or HTN may have comorbidities that can prolong inpatient LoS. Physicians play an important role in disseminating health related information. These predictions could assist in the development of health policies and strategies that reduce disease burden in resource-limited settings.",
        "DOI": "10.1016/j.ijmedinf.2021.104569",
        "affiliation_name": "Universitas Indonesia, RSUPN Dr. Cipto Mangunkusumo",
        "affiliation_city": "Central Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Consumer recommendation prediction in online reviews using Cuckoo optimized machine learning models",
        "paper_author": "Jain P.K.",
        "publication": "Computers and Electrical Engineering",
        "citied_by": "39",
        "cover_date": "2021-10-01",
        "Abstract": "Digital technology and social media have delivered many advantages in understanding human psychology, which is essential to industrial growth. Skytrax is an online social media platform for travellers to write reviews on airlines. In online reviews, consumer recommendations are critical indicators for service providers to improve their consumer policies as well as service quality. It is also helpful for future customers to help get information on future purchases prior to making them. Therefore, previous consumer recommendations based on online reviews play a vital role in airline recommendations. Our main goal is to use our proposed cuckoo optimized machine learning model to predict airline recommendations. Experimental analysis was implemented using data scraped from the website https://www.airlinequality.com. Our results show that the proposed eXtreme gradient boosting classifier optimized by Cuckoo Search (CS-XGB) outperforms other state-of-the-art techniques.",
        "DOI": "10.1016/j.compeleceng.2021.107397",
        "affiliation_name": "Mekelle University",
        "affiliation_city": "Makale",
        "affiliation_country": "Ethiopia"
    },
    {
        "paper_title": "Dynamic activity chain pattern estimation under mobility demand changes during COVID-19",
        "paper_author": "Liu Y.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "19",
        "cover_date": "2021-10-01",
        "Abstract": "During the coronavirus disease 2019 pandemic, the activity engagement and travel behavior of city residents have been impacted by government restrictions, such as temporary city-wide lockdowns, the closure of public areas and public transport suspension. Based on multiple heterogeneous data sources, which include aggregated mobility change reports and household survey data, this paper proposes a machine learning approach for dynamic activity chain pattern estimation with improved interpretability for examining behavioral pattern adjustments. Based on historical household survey samples, we first establish a computational graph-based discrete choice model to estimate the baseline travel tour parameters before the pandemic. To further capture structural deviations of activity chain patterns from day-by-day time series, we define the activity-oriented deviation parameters within an interpretable utility-based nested logit model framework, which are further estimated through a constrained optimization problem. By incorporating the long short-term memory method as the explainable module to capture the complex periodic and trend information before and after interventions, we predict day-to-day activity chain patterns with more accuracy. The performance of our model is examined based on publicly available datasets such as the 2017 National Household Travel Survey in the United States and the Google Global Mobility Dataset throughout the epidemic period. Our model could shed more light on transportation planning, policy adaptation and management decisions during the pandemic and post-pandemic phases.",
        "DOI": "10.1016/j.trc.2021.103361",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning on sustainable energy: A review and outlook on renewable energy systems, catalysis, smart grid and energy storage",
        "paper_author": "Rangel-Martinez D.",
        "publication": "Chemical Engineering Research and Design",
        "citied_by": "151",
        "cover_date": "2021-10-01",
        "Abstract": "This study presents a broad view of the current state of the art of ML applications in the manufacturing sectors that have a considerable impact on sustainability and the environment, namely renewable energies (solar, wind, hydropower, and biomass), smart grids, the industry of catalysis and power storage and distribution. Artificial neural networks are the most preferred techniques over other ML algorithms because of their generalization capabilities. Demands for ML techniques in the energy sectors will increase considerably in the coming years, since there is a growing demand of academic programmes related to artificial intelligence in science, math, and engineering. Data generation, management, and safety are expected to play a key role for the successful implementation of ML algorithms that can be shared by major stakeholders in the energy sector, thereby promoting the development of ambitious energy management projects. New algorithms for producing reliable data and the addition of other sources of information (e.g., novel sensors) will enhance flow of information between ML and systems. It is expected that unsupervised and reinforcement learning will take a central role in the energy sector, but this will depend on the expansion of other major fields in data science such as big data analytics. Massive implementations, specialized algorithms, and new technologies like 5G will promote the development of sustainable applications of ML in non-industrial applications for energy management.",
        "DOI": "10.1016/j.cherd.2021.08.013",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Low Discrepancy Sequence on Graphs",
        "paper_author": "Cloninger A.",
        "publication": "Journal of Fourier Analysis and Applications",
        "citied_by": "2",
        "cover_date": "2021-10-01",
        "Abstract": "Many applications such as election forecasting, environmental monitoring, health policy, and graph based machine learning require taking expectation of functions defined on the vertices of a graph. We describe a construction of a sampling scheme analogous to the so called Leja points in complex potential theory that can be proved to give low discrepancy estimates for the approximation of the expected value by the impirical expected value based on these points. In contrast to classical potential theory where the kernel is fixed and the equilibrium distribution depends upon the kernel, we fix a probability distribution and construct a kernel (which represents the graph structure) for which the equilibrium distribution is the given probability distribution. Our estimates do not depend upon the size of the graph.",
        "DOI": "10.1007/s00041-021-09865-8",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Impact of artificial intelligence on clinical radiography practice: Futuristic prospects in a low resource setting",
        "paper_author": "Wuni A.R.",
        "publication": "Radiography",
        "citied_by": "24",
        "cover_date": "2021-10-01",
        "Abstract": "Objectives: Current trends in clinical radiography practice include the integration of artificial intelligence (AI) and related applications to improve patient care and enhance research. However, in low resource countries there are unique barriers to the process of AI integration. Using Ghana as a case study, this paper seeks to discuss the potential impact of AI on future radiographic practice in low-resource settings. The opportunities, challenges and the way forward to optimise the potential benefits of AI in future practice within these settings have been explored. Key findings: Some of the barriers to AI integration into radiographic practice relate to lack of regulatory and legal policy frameworks and limited resource availability including unreliable internet connectivity and low expert skillset. Conclusion: These barriers notwithstanding, AI presents a great potential to the growth of medical imaging and subsequently improving quality of healthcare delivery in the near future. For example, AI-enabled radiographer reporting has a potential to improving quality of healthcare, especially in low-resource settings like Ghana with an acute shortage of radiologists. In addition, futuristic AI-enabled advancements such as synthetic cross-modality transfer where images from one modality are used as a baseline to generate a corresponding image of another modality without the need for additional scanning will be of particular benefit in low-resource settings. Implications for practice: The urgent need for inclusion of AI modules for the training of the radiographer of the future has been suggested. Recommendations for development of AI strategies by national societies and regulatory bodies will harmonise the implementation efforts. Finally, there is need for collaboration between clinical practitioners and academia to ensure that the future radiography workforce is well prepared for the AI-enabled clinical environment.",
        "DOI": "10.1016/j.radi.2021.07.021",
        "affiliation_name": "University of Cape Coast Ghana",
        "affiliation_city": "Cape Coast",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Why low-carbon technological innovation hardly promote energy efficiency of China? – Based on spatial econometric method and machine learning",
        "paper_author": "Li W.",
        "publication": "Computers and Industrial Engineering",
        "citied_by": "54",
        "cover_date": "2021-10-01",
        "Abstract": "Can low-carbon technological innovation improve energy efficiency in China? Despite China's attempts to improve energy efficiency through low-carbon technological innovation for several years, many scholars argue that innovation does not necessarily produce the expected outcomes. This study tests the heterogeneity of energy efficiency in China based on Data Envelopment Analysis (DEA) and machine learning and demonstrates the spatial spillover effect of regional agglomeration of low-carbon technology innovation on energy efficiency using the dynamic spatial Durbin model (DSDM). The results show that: (a) China's energy efficiency is heterogeneous in spatial distribution, and it has the characteristics of spilling over from the east to the central and western regions. (b) The direct effect of low-carbon technological innovation on energy efficiency is positive, but the indirect effect is negative, and the total effect is negative. The low-carbon technological innovation has an agglomeration effect, i.e., innovation resources tend to gather in higher energy efficiency regions. (c) Government influence, industrial structure, and foreign capital are key factors of low-carbon technology innovation. Based on these results, this study suggests the following policy recommendations: Narrow the low-carbon technology innovation gap between the developed and developing regions; promote the utilization efficiency of low-carbon technology innovation resources; open the low-carbon technological innovation to foreign investment and encourage low-carbon enterprises to cooperate with them.",
        "DOI": "10.1016/j.cie.2021.107566",
        "affiliation_name": "Jiangsu University",
        "affiliation_city": "Zhenjiang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Performance comparison of wavelets-based machine learning technique for forecasting agricultural commodity prices",
        "paper_author": "Paul R.K.",
        "publication": "Soft Computing",
        "citied_by": "25",
        "cover_date": "2021-10-01",
        "Abstract": "Accurate forecasting of various phenomenon has got crucial importance in the scenario of Indian agriculture as this helps farmers, policy-makers and government to acquire informed decisions. Agricultural time series datasets are mostly nonlinear, nonstationary, non-normal and heteroscedastic in nature. Though the stochastic model like autoregressive integrated moving average and its component models have gained much popularity in modeling linear dynamics, they fail to capture the nonlinearity present in the series. Machine learning (ML) techniques like artificial neural network (ANN) has rapidly emerged within the area of forecasting to take care of nonlinearity in the dataset. But, the presence of high chaotic nature and sophisticated nonlinear structure of the series sometimes distorts the particular model specification. Therefore, preprocessing of the series is required to extract the actual signal in it. Wavelet transformation may be an efficient tool in this scenario. The decomposed and denoised components through wavelet transformation can be modeled using ANN to make wavelet-based hybrid models and eventually, inverse wavelet transform is carried out to obtain the prediction of original series. The incontrovertible fact is that these hybrid models handle nonstationary, nonlinear and non-normal features of datasets simultaneously. The present study discusses the above approach envisaging monthly wholesale tomato price of three major markets in India, namely Ahmedabad, Burdwan and Madanapalli. The improvement over conventional techniques is obtained to a great extent by using wavelet-based combination approach with ML technique as exhibited through empirical evidence.",
        "DOI": "10.1007/s00500-021-06087-4",
        "affiliation_name": "ICAR - Indian Agricultural Statistics Research Institute, New Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The nexus between information technology and environmental pollution: Application of a new machine learning algorithm to OECD countries",
        "paper_author": "Magazzino C.",
        "publication": "Utilities Policy",
        "citied_by": "85",
        "cover_date": "2021-10-01",
        "Abstract": "This paper examines the linkages among Information and Communication Technologies (ICT) penetration, electricity consumption, economic growth, urbanization, and environmental pollution for 25 OECD countries over the 1990–2017 period. We first conduct several panel data analyses and then write and apply a new Machine Learning (ML) algorithm. Empirical findings show that ICT usage enhances economic growth, and it is also a crucial driver of electricity consumption, which, in turn, translates into polluting emissions. The ML results highlight internet usage emerges as a substantial CO2 emissions-enabler, thus corroborating our panel data findings. Potential policy measures are discussed.",
        "DOI": "10.1016/j.jup.2021.101256",
        "affiliation_name": "Università degli Studi di Teramo",
        "affiliation_city": "Teramo",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Modelling the coupling evolution of the water environment and social economic system using PSO-SVM in the Yangtze River Economic Belt, China",
        "paper_author": "Deng C.",
        "publication": "Ecological Indicators",
        "citied_by": "25",
        "cover_date": "2021-10-01",
        "Abstract": "Being a crucial focal point of China's regional development, green development is a novel concept for the coordinated development of the environment and social economy. Therefore, elucidation of the relationship between the aforementioned factors is scientifically necessary to achieve regional green sustainability. Based on the theory of the gray water footprint and physical and statistical models, this study aims to analyze, evaluate, and predict the spatiotemporal dynamics of the coupling evolution between the water environment and social economy in the Yangtze River Economic Belt to provide a scientific reference for exploring basic laws of coordinated development, identifying influencing factors, and formulating management strategies. The results showed that: (1) from 2003 to 2017, the carrying capacity coefficients of the gray water footprint (i.e., the KCOD, KNH3-N, and KTP, except for KTN) decreased over time, as shown by a decreasing trend in the degree of the coupling coordination, which was observed from the east to the west; (2) the coupling coordination degree showed a decreasing trend from the east to the west at the spatial level and an increasing trend from 2003 to 2017 at the temporal level; and (3) the optimal scenario was green development (Plan IV) and the overall coordination degree improved. In addition, corresponding policy recommendations were proposed. The research results are scientifically significant and present a theoretical reference for the coordinated and sustainable development of the regional ecological environment and social economy.",
        "DOI": "10.1016/j.ecolind.2021.108012",
        "affiliation_name": "Chinese Research Academy of Environmental Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "NDBI Based Prediction of Land Use Land Cover Change",
        "paper_author": "Kulkarni K.",
        "publication": "Journal of the Indian Society of Remote Sensing",
        "citied_by": "18",
        "cover_date": "2021-10-01",
        "Abstract": "Urbanization plays a major role in the governance policies of the civic bodies. Predicting the growth of the cities helps the government to provide the infrastructure facilities. Getting to know the number of built-up areas indirectly points to population increase or decrease. The percentage of the land occupied by built-up areas or non-built-up areas can be found out using the remotely sensed images. Land use and land cover (LULC) of these images point out how the land has been used, whether the land is a water body, vegetation, soil or built-up area. This work explores the combination of the remote sensing images and the use multilayer perceptron (MLP)-based cellular automata (CA) for predicting the changes in the LULC on a later date, using two different initial LULC maps as the input. Four basic classes, namely water, vegetation, built-up and soil, have been considered in this work. Machine learning algorithm (Random Forest Classifier) is used to obtain the LULC map of all the 3 years under consideration, namely 2013, 2016 and 2019. The LULC map of the years 2013 and 2016 acts as the initial rasters for the prediction, whereas the LULC map of the year 2019 is used for validation. The novelty of the work lies in the use of Normalized Difference Built-up index raster along with the roadway map, as the spatial variables in the MLP-based CA. The predicted results show an increase of 12.65% in the built-up areas, decrease of the soil class by 5.23%, decrease of the vegetation by 6.63% and decrease in the water bodies by 0.79% compared the base year considered (2013). The predicted LULC map using the proposed model is then validated against an independently obtained LULC map of 2019. The Jaccard similarity coefficient was found to be 0.93, which indicates the validity of the algorithm for future predictions.",
        "DOI": "10.1007/s12524-021-01411-9",
        "affiliation_name": "B.N.M Institute of Technology",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Agencies in the news? Public agencies' media evaluations in a low-trust context",
        "paper_author": "Peci A.",
        "publication": "Governance",
        "citied_by": "12",
        "cover_date": "2021-10-01",
        "Abstract": "Bureaucratic reputations are largely shaped by the media's evaluations of such agencies. However, the research overlooks how the media evaluates public agencies, particularly in low-trust contexts. Using inductive machine-learning techniques, we uncover the media's evaluations of Brazilian regulatory agencies based on more than 38,000 stories published within the last 20 years with the aim of exploring what drives their media evaluations and which reputational dimensions are privileged in the negative media coverage of regulatory agencies. We find different patterns of media evaluations that reflect a unique interplay of media logic, agency strategizing, and the quality of the policy context in which the agencies operate. However, even in a low-trust context, some agencies are able to build a favorable media reputation. In contrast, agencies with unfavorable media reputations are systematically questioned along many reputational dimensions and are subject to stronger negativity bias.",
        "DOI": "10.1111/gove.12579",
        "affiliation_name": "Fundacao Getulio Vargas",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Aboveground biomass estimation of black locust planted forests with aspect variable using machine learning regression algorithms",
        "paper_author": "Ye Q.",
        "publication": "Ecological Indicators",
        "citied_by": "21",
        "cover_date": "2021-10-01",
        "Abstract": "An accurate estimation of forest aboveground biomass (AGB) is important for carbon accounting and afforestation policy making, and the aspect factors that affect forest stand growth are important to the accuracy of AGB estimation. In this study, aspect was incorporated as a variable into three machine learning algorithms (MLAs) (support vector machine (SVM), artificial neural network (ANN) and random forest (RF)), to estimate the AGB of black locust (Robinia pseudoacacia) planted forests in 96 field plots with four different aspects (sunny slope, semi-sunny slope, semi-shady slope and shady slope). The results showed that in the models incorporating aspect variables, the increase in accuracy varied from 36.72% to 41.23% for 29 validation plots based on R2. The A-RF model (RF with aspect variable), which had the highest R2 (0.8519) and lowest RMSE and rRMSE (12.552 Mg/ha and 0.175) was considered optimal for AGB estimation of black locust planted forests. The overestimation of sunny and shady slopes, and the underestimation of semi-sunny and semi-shady slopes are reduced by incorporating the aspect variable. Areas with lower AGB values mainly occur on sunny and shady slopes, and areas with higher AGB values mainly occur on semi-sunny and semi-shady slopes. Overall, our study demonstrates that the introduction of the aspect variable provided the model with a basis for the effects of different growth conditions of black locust planted forests on different aspects, which can improve the accuracy of AGB estimation.",
        "DOI": "10.1016/j.ecolind.2021.107948",
        "affiliation_name": "Northwest A&amp;F University",
        "affiliation_city": "Yangling",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning based deep job exploration and secure transactions in virtual private cloud systems",
        "paper_author": "Rajasoundaran S.",
        "publication": "Computers and Security",
        "citied_by": "32",
        "cover_date": "2021-10-01",
        "Abstract": "Virtual Private Cloud (VPC) is an emerging cloud environment used to provide more secure data communication. VPC provides authentic communication channel for secure communication between the cloud participants. The cloud jobs and the description of the runtime cloud events must be evaluated to provide flawless VPC service. Although VPC provides security in network services, it has to be enriched with internal and external platform level security features. In this regard, secure job service schemes ensure elimination of attacks, unauthorized jobs, improper accesses and intrusions in VPC. These irrelevant tasks (activities) can be isolated before initiating job scheduling process. Particularly, providing security for zero-trust cloud environment is more challenging task. Zero-trust cloud environment has completely vulnerable trust model on both internal and external circumstances. The proposed Machine Learning Based Secure Cloud Job Services (MLSCS) is implemented to provide multi-level security in this zero-trust cloud job servicing system. The proposed MLSCS develops Multi-Server Queue Management techniques, Reinforcement Learning based deep Q Matrix (RL-Q Matrix) techniques, Authentic VPC configuration and VPC Genetic Algorithm Network (VGAN) for establishing security practices in complex job handling system. MLSCS applies effective techniques for eliminating irrelevant cloud jobs to reduce the scheduler complexity and processor utilization. In this work, irrelevant jobs are considered as the jobs that are not appropriate for particular VPC scheduling policies and security principles (attacks). These jobs are identified through various key validation procedures and VPC policy determination procedures. These jobs are eliminated and prohibited in to job scheduler. Consequently, the legitimate jobs are securely forwarded in to job scheduler through multi-server queues. In the experimental setup, the proposed MLSCS is compared with existing schemes such as Reinforcement Learning Based Distributed Heterogeneous Servicing technique (RLDH), Cat Swarm Optimization Based Job Servicing technique (CSOS) and Fuzzy Based Security-Driven Servicing technique (FSDS). The results show the MLSCS delivers 5% to 8% optimal results than existing schemes.",
        "DOI": "10.1016/j.cose.2021.102379",
        "affiliation_name": "VIT Bhopal University",
        "affiliation_city": "Sehore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "PM<inf>2.5</inf> as a major predictor of COVID-19 basic reproduction number in the USA",
        "paper_author": "Milicevic O.",
        "publication": "Environmental Research",
        "citied_by": "26",
        "cover_date": "2021-10-01",
        "Abstract": "Many studies have proposed a relationship between COVID-19 transmissibility and ambient pollution levels. However, a major limitation in establishing such associations is to adequately account for complex disease dynamics, influenced by e.g. significant differences in control measures and testing policies. Another difficulty is appropriately controlling the effects of other potentially important factors, due to both their mutual correlations and a limited dataset. To overcome these difficulties, we will here use the basic reproduction number (R0) that we estimate for USA states using non-linear dynamics methods. To account for a large number of predictors (many of which are mutually strongly correlated), combined with a limited dataset, we employ machine-learning methods. Specifically, to reduce dimensionality without complicating the variable interpretation, we employ Principal Component Analysis on subsets of mutually related (and correlated) predictors. Methods that allow feature (predictor) selection, and ranking their importance, are then used, including both linear regressions with regularization and feature selection (Lasso and Elastic Net) and non-parametric methods based on ensembles of weak-learners (Random Forest and Gradient Boost). Through these substantially different approaches, we robustly obtain that PM2.5 is a major predictor of R0 in USA states, with corrections from factors such as other pollutants, prosperity measures, population density, chronic disease levels, and possibly racial composition. As a rough magnitude estimate, we obtain that a relative change in R0, with variations in pollution levels observed in the USA, is typically ~30%, which further underscores the importance of pollution in COVID-19 transmissibility.",
        "DOI": "10.1016/j.envres.2021.111526",
        "affiliation_name": "Belgrade University School of Medicine",
        "affiliation_city": "Belgrade",
        "affiliation_country": "Serbia"
    },
    {
        "paper_title": "Staying on convention or leapfrogging to eco-innovation?: Identifying early adopters of hydrogen-powered vehicles",
        "paper_author": "Moon H.B.",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "25",
        "cover_date": "2021-10-01",
        "Abstract": "Hydrogen-powered vehicles or fuel cell electric vehicles (FCEV) are recognized as one of the leading innovations within sustainable technologies. However, to the best of our knowledge, only few studies have been conducted regarding the consumer's perspective of the product. This study focuses on analyzing the consumer's criteria and level behind their behavior regarding these vehicles to identify consumer segments that can be potential innovators and early adopters of FCEV. The K-means clustering method was employed to identify different consumer segments based on their chosen criteria. Next, consumer characteristics and their preferences were analyzed using a multinomial logit model to derive important marketing and policy implications. The result of the analysis indicates that 44.9% of the consumers consider FCEV as a potential alternative. These consumers consist of “Innovative luxury consumer group (6.2%),” “Advanced eco-friendly consumer group (12.6%),” and “Economy-oriented eco-friendly consumer group (26.1%).” Among the three groups, the “innovative and luxurious consumer group,” who considered all traditional gasoline and diesel vehicles with FCEV, had the highest potential to leapfrog to FCEV. These findings can accelerate the diffusion of FCEVs if marketing strategies and policy plans are formulated according to suitable consumer segments.",
        "DOI": "10.1016/j.techfore.2021.120995",
        "affiliation_name": "SNU College of Engineering",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Dynamic multiobjective optimization driven by inverse reinforcement learning",
        "paper_author": "Zou F.",
        "publication": "Information Sciences",
        "citied_by": "23",
        "cover_date": "2021-10-01",
        "Abstract": "Due to the widespread interest in dynamic multiobjective optimization in real-world applications, more and more approaches exploiting machine learning are deployed to tackle this type of problems. Unfortunately, recent works do not make full use of the data obtained during the optimization process, which could be benefit for model training thereby mining the dynamic characteristics of the underlying problem. To address this issue, this paper proposes a dynamic multiobjective evolutionary algorithm driven by inverse reinforcement learning to solve the dynamic multiobjective optimization problems. IRL is widely used to recover the unknown reward function, making it possible to perform at an expert level. The notable features of the proposed algorithm mainly consist of data-driven evolutionary technique, which uses inverse reinforcement learning as a surrogate-assisted model for model training. This design makes full use of the surrogate management strategy based on inverse reinforcement learning to optimize the reward function within a reinforcement learning framework. At the same time, the algorithm can generate a promising policy based on limited training data during the optimization process to achieve better algorithm evolution and guide the search. The experimental results on the benchmark problems validate that the proposed algorithm is effective in dealing with dynamic multiobjective optimization.",
        "DOI": "10.1016/j.ins.2021.06.054",
        "affiliation_name": "College of Engineering, Architecture and Technology",
        "affiliation_city": "Stillwater",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Determinants investigation and peak prediction of CO<inf>2</inf> emissions in China’s transport sector utilizing bio-inspired extreme learning machine",
        "paper_author": "Wang W.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "35",
        "cover_date": "2021-10-01",
        "Abstract": "The transport sector is recognized as one of the largest carbon emitters. To achieve China’s carbon peak commitment in the Paris Agreement on schedule, it is indispensable to explore the peak carbon emissions and mitigation strategies in the transport sector. Many researches in the past have contextualized in China’s total emissions peak, while the study about forecasting China’s transport CO2 emissions peak seldom appeared, especially the application of intelligent prediction model. To further investigate the determinants and forecast the peak of transport CO2 emissions in China accurately, a novel bio-inspired prediction model is proposed in this paper, namely, the extreme learning machine (ELM) optimized by manta rays foraging optimization (MRFO), hereafter referred as MRFO-ELM. Adhering to this hybrid model, the mean impact value (MIV) method is then employed to evaluate and differentiate the importance of thirteen influencing factors. Additionally, three scenarios are set to conduct prediction of China’s transport CO2 emissions. The empirical results indicate that the proposed MRFO-ELM has excellent performance in terms of the optimization searching velocity and prediction accuracy. Simultaneously the level of vehicle electrification is verified to be one of the emerging major factors affecting China’s transport CO2 emissions. The transport CO2 emissions in China would peak in 2039 under the baseline model scenario, while the plateau would occur in 2035 or 2043 under sustainable development mode and high growth mode, respectively. The peak years imply much pressure on China’s transport carbon emissions abatement currently, whereas active policy adjustments can effectively urge the earlier occurrence of the emission peak. These new findings suggest that it is essential for China to improve the energy mix and encourage the electric energy replacement in line with urbanization pace, so as to achieve CO2 emissions mitigation in the transport industry.",
        "DOI": "10.1007/s11356-021-14852-z",
        "affiliation_name": "North China Electric Power University (Baoding)",
        "affiliation_city": "Baoding",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reinforcement learning for combinatorial optimization: A survey",
        "paper_author": "Mazyavkina N.",
        "publication": "Computers and Operations Research",
        "citied_by": "418",
        "cover_date": "2021-10-01",
        "Abstract": "Many traditional algorithms for solving combinatorial optimization problems involve using hand-crafted heuristics that sequentially construct a solution. Such heuristics are designed by domain experts and may often be suboptimal due to the hard nature of the problems. Reinforcement learning (RL) proposes a good alternative to automate the search of these heuristics by training an agent in a supervised or self-supervised manner. In this survey, we explore the recent advancements of applying RL frameworks to hard combinatorial problems. Our survey provides the necessary background for operations research and machine learning communities and showcases the works that are moving the field forward. We juxtapose recently proposed RL methods, laying out the timeline of the improvements for each problem, as well as we make a comparison with traditional algorithms, indicating that RL models can become a promising direction for solving combinatorial problems.",
        "DOI": "10.1016/j.cor.2021.105400",
        "affiliation_name": "Skolkovo Institute of Science and Technology",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Revisiting the dynamic interactions between economic growth and environmental pollution in Italy: evidence from a gradient descent algorithm",
        "paper_author": "Mele M.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "44",
        "cover_date": "2021-10-01",
        "Abstract": "Although the literature on the relationship between economic growth and CO2 emissions is extensive, the use of machine learning (ML) tools remains seminal. In this paper, we assess this nexus for Italy using innovative algorithms, with yearly data for the 1960–2017 period. We develop three distinct models: the batch gradient descent (BGD), the stochastic gradient descent (SGD), and the multilayer perceptron (MLP). Despite the phase of low Italian economic growth, results reveal that CO2 emissions increased in the predicting model. Compared to the observed statistical data, the algorithm shows a correlation between low growth and higher CO2 increase, which contradicts the main strand of literature. Based on this outcome, adequate policy recommendations are provided.",
        "DOI": "10.1007/s11356-021-14264-z",
        "affiliation_name": "Université Paris 1 Panthéon-Sorbonne",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Using Analytics to Gain Insights on U.S. Prescription Drug Prices: An Inductive Analysis",
        "paper_author": "Iacocca K.",
        "publication": "Journal of Public Policy and Marketing",
        "citied_by": "6",
        "cover_date": "2021-10-01",
        "Abstract": "Using data scraping techniques to gather data from a variety of previously disjointed sources—some proprietary and some publicly available—this research applies the analytical techniques of data visualization and machine learning to (1) gain exploratory insights into the drivers of prescription drug list prices and (2) test how well these variables impact prices directly and interact to predict pricing. Specifically, this inductive analysis considers characteristics related to the brand (i.e., manufacturer, brand/generic classification), product attributes (i.e., dosing levels, amount of active ingredient), the condition for which the drug is recommended (i.e., therapeutic class, subclass, and pricing tier), and market factors (i.e., number of drugs in class and approval year). Through these analytic analyses, the authors seek to cut through some of the opacity of pharmaceutical drug list prices to consider the drivers of drug prices, evaluate how these insights might drive marketplace and policy solutions, and spark future research inquiries in this area.",
        "DOI": "10.1177/0743915621993173",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Joint optimization of preventive maintenance and production scheduling for multi-state production systems based on reinforcement learning",
        "paper_author": "Yang H.",
        "publication": "Reliability Engineering and System Safety",
        "citied_by": "75",
        "cover_date": "2021-10-01",
        "Abstract": "Preventive maintenance and production scheduling are two important and interactive activities in production systems. In this work, the integrated optimization problem of production scheduling for multi-state single-machine production systems experiencing degradation processes is investigated. Preventive maintenance tasks and jobs scheduling are jointly considered to find the optimal production policy by considering the processing costs, the maintenance costs, and the completion rewards, simultaneously. We formulate the integrated optimization problem as Markov decision process framework. R-learning algorithm is introduced to maximize the long-run expected average rewards per time unit over infinite horizon. On the basis of the analysis of the optimal stationary policy, the appropriate condition to perform preventive maintenance following optimal stationary policy is presented. This provides the basis for the improvement in R-learning algorithm. Furthermore, a novel heuristic reinforcement learning method is proposed to deal with the integrated model more efficiently. Finally, we present the simulation results and analysis of the proposed algorithm's performance in terms of the number of job types and machine states. The simulation results and analysis show the effectiveness of the proposed approach for solving the integrated problems.",
        "DOI": "10.1016/j.ress.2021.107713",
        "affiliation_name": "Jiangsu University",
        "affiliation_city": "Zhenjiang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predictors of Sickness Absence in a Clinical Population With Chronic Pain",
        "paper_author": "LoMartire R.",
        "publication": "Journal of Pain",
        "citied_by": "17",
        "cover_date": "2021-10-01",
        "Abstract": "Chronic pain-related sickness absence is an enormous socioeconomic burden globally. Optimized interventions are reliant on a lucid understanding of the distribution of social insurance benefits and their predictors. This register-based observational study analyzed data for a 7-year period from a population-representative sample of 44,241 chronic pain patients eligible for interdisciplinary treatment (IDT) at specialist clinics. Sequence analysis was used to describe the sickness absence over the complete period and to separate the patients into subgroups based on their social insurance benefits over the final 2 years. The predictive performance of features from various domains was then explored with machine learning-based modeling in a nested cross-validation procedure. Our results showed that patients on sickness absence increased from 17% 5 years before to 48% at the time of the IDT assessment, and then decreased to 38% at the end of follow-up. Patients were divided into 3 classes characterized by low sickness absence, sick leave, and disability pension, with eight predictors of class membership being identified. Sickness absence history was the strongest predictor of future sickness absence, while other predictors included a 2008 policy, age, confidence in recovery, and geographical location. Information on these features could guide personalized intervention in the specialized healthcare. Perspective: This study describes sickness absence in patients who visited a Swedish pain specialist interdisciplinary treatment clinic during the period 2005 to 2016. Predictors of future sickness absence are also identified that should be considered when adapting IDT programs to the patient's needs.",
        "DOI": "10.1016/j.jpain.2021.03.145",
        "affiliation_name": "Università di Pisa",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Robotic grasping: from wrench space heuristics to deep learning policies",
        "paper_author": "de Souza J.P.C.",
        "publication": "Robotics and Computer-Integrated Manufacturing",
        "citied_by": "35",
        "cover_date": "2021-10-01",
        "Abstract": "The robotic grasping task persists as a modern industry problem that seeks autonomous, fast implementation, and efficient techniques. Domestic robots are also a reality demanding a delicate and accurate human–machine interaction, with precise robotic grasping and handling. From decades ago, with analytical heuristics, to recent days, with the new deep learning policies, grasping in complex scenarios is still the aim of several works’ that propose distinctive approaches. In this context, this paper aims to cover recent methodologies’ development and discuss them, showing state-of-the-art challenges and the gap to industrial applications deployment. Given the complexity of the related issue associated with the elaborated proposed methods, this paper formulates some fair and transparent definitions for results’ assessment to provide researchers with a clear and standardised idea of the comparison between the new proposals.",
        "DOI": "10.1016/j.rcim.2021.102176",
        "affiliation_name": "Institute for Systems and Computer Engineering, Technology and Science",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Speaking social Europe: A paradigmatic shift in the European Commission Presidents’ social policy discourse?",
        "paper_author": "Vesan P.",
        "publication": "Journal of European Social Policy",
        "citied_by": "17",
        "cover_date": "2021-10-01",
        "Abstract": "This article presents an original analysis of the social policy discourse at the European Union level by focusing on the language used by European Commission Presidents when addressing social issues. Through an empirical analysis based on a semi-supervised machine learning approach, we consider the entire corpus of speeches made by Barroso and Juncker from 2010 to 2018 and we classify all sentences according to three possible variants of social policy language: social-retrenchment, social-investment and rights-based language. We argue that the focus on these languages allows us to understand whether the ‘fiscal consolidation discipline’ narrative, which dominated in the aftermath of the Great Recession, has been challenged over the years by the recourse to alternative ‘social policy images’. The results confirm a significant shift in the overall configuration of social policy discourse between Barroso and Juncker. This shift has been mainly characterized by an increase in the use of rights-based language and a decrease in the use of social-retrenchment language, which however has not been completely abandoned. Therefore, the recalibration of EC’s speeches on social policy has not been abrupt but has instead been incremental. The article concludes by discussing preliminary interpretations of the observed trends and their potential implications in terms of ‘discursive legacy’ in the post-pandemic era.",
        "DOI": "10.1177/0958928721999596",
        "affiliation_name": "Università degli Studi di Pavia",
        "affiliation_city": "Pavia",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Mid-term electricity load prediction using CNN and Bi-LSTM",
        "paper_author": "Gul M.J.",
        "publication": "Journal of Supercomputing",
        "citied_by": "41",
        "cover_date": "2021-10-01",
        "Abstract": "Electricity is one of the critical role players to build an economy. Electricity consumption and generation can affect the overall policy of the country. Such importance opens an area for intelligent systems that can provide future insights. Intelligent management for electric power consumption requires future electricity power consumption prediction with less error. These predictions provide insights for making decisions to smooth line the policy and grow the country’s economy. Future prediction can be categorized into three categories, namely (1) Long-Term, (2) Short-Term, and (3) Mid-Term predictions. For our study, we consider the Mid-Term electricity consumption prediction. Dataset provided by Korea Electric power supply to get insights for a metropolitan city like Seoul. Dataset is in time-series, so statistical and machine learning models can be used. This study provides experimental results from the proposed ARIMA and CNN-Bi-LSTM. Hyperparameters are tuned for ARIMA and neural network models to increase the models’ accuracy, which looks promising as RMSE for training is 0.14 and 0.20 RMSE for testing.",
        "DOI": "10.1007/s11227-021-03686-8",
        "affiliation_name": "Sejong University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A scheduling method for multi-robot assembly of aircraft structures with soft task precedence constraints",
        "paper_author": "Tereshchuk V.",
        "publication": "Robotics and Computer-Integrated Manufacturing",
        "citied_by": "21",
        "cover_date": "2021-10-01",
        "Abstract": "The use of multiple cooperating robotic manipulators to assemble large aircraft structures entails the scheduling of many discrete tasks such as drilling holes and installing fasteners. Since the tasks have different tool requirements, it is desirable to minimize tool changes that incur significant time costs. We approach this problem as a multi-robot task allocation problem with precedence constraints, where the constraints are loosely enforced in terms of prioritizing the tasks to avoid unnecessary tool changes. To avoid the computational burden of searching over all possible task prioritization options, our main contribution is to develop a two-step, data-driven approach to automatically select suitable precedence relations. The first step is to adapt an iterative auction-based method to encode the precedence relations using scheduling heuristics. The second step is to develop a robust machine learning method to generate policies for automatically selecting efficient scheduling heuristics based on the problem characteristics. Experimental results show that the top performing heuristics yield schedules that are more efficient than those of a baseline partition-based scheduler by almost 17%–19%, depending on the robot failure profiles. The learned policies are also able to select heuristics that perform better than greedy selection without incurring additional computational costs.",
        "DOI": "10.1016/j.rcim.2021.102154",
        "affiliation_name": "Boeing Corporation",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A visual path-following learning approach for industrial robots using DRL",
        "paper_author": "Maldonado-Ramirez A.",
        "publication": "Robotics and Computer-Integrated Manufacturing",
        "citied_by": "39",
        "cover_date": "2021-10-01",
        "Abstract": "Manufacturing companies are in constant need for improved agility. An adequate combination of speed, responsiveness, and business agility to cope with fluctuating raw material costs is essential for today's increasingly demanding markets. Agility in robots is key in operations requiring on-demand control of a robot's tool position and orientation, reducing or eliminating extra programming efforts. Vision-based perception using full-state or partial-state observations and learning techniques are useful to create truly adaptive industrial robots. We propose using a Deep Reinforcement Learning (DRL) approach to solve path-following tasks using a simplified virtual environment with domain randomisation to provide the agent with enough exploration and observation variability during the training to generate useful policies to be transferred to an industrial robot. We validated our approach using a KUKA KR16HW robot equipped with a Fronius GMAW welding machine. The path was manually drawn on two workpieces so the robot was able to perceive, learn and follow it during welding experiments. It was also found that small processing times due to motion prediction (3.5 ms) did not slow down the process, which resulted in smooth robot operations. The novel approach can be implemented onto different industrial robots to carry out different tasks requiring material deposition.",
        "DOI": "10.1016/j.rcim.2021.102130",
        "affiliation_name": "Centro de Investigacion y de Estudios Avanzados del Instituto Politécnico Nacional",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Boundary-Aware Supervoxel-Level Iteratively Refined Interactive 3D Image Segmentation with Multi-Agent Reinforcement Learning",
        "paper_author": "Ma C.",
        "publication": "IEEE Transactions on Medical Imaging",
        "citied_by": "18",
        "cover_date": "2021-10-01",
        "Abstract": "Interactive segmentation has recently been explored to effectively and efficiently harvest high-quality segmentation masks by iteratively incorporating user hints. While iterative in nature, most existing interactive segmentation methods tend to ignore the dynamics of successive interactions and take each interaction independently. We here propose to model iterative interactive image segmentation with a Markov decision process (MDP) and solve it with reinforcement learning (RL) where each voxel is treated as an agent. Considering the large exploration space for voxel-wise prediction and the dependence among neighboring voxels for the segmentation tasks, multi-agent reinforcement learning is adopted, where the voxel-level policy is shared among agents. Considering that boundary voxels are more important for segmentation, we further introduce a boundary-aware reward, which consists of a global reward in the form of relative cross-entropy gain, to update the policy in a constrained direction, and a boundary reward in the form of relative weight, to emphasize the correctness of boundary predictions. To combine the advantages of different types of interactions, i. e., simple and efficient for point-clicking, and stable and robust for scribbles, we propose a supervoxel-clicking based interaction design. Experimental results on four benchmark datasets have shown that the proposed method significantly outperforms the state-of-the-arts, with the advantage of fewer interactions, higher accuracy, and enhanced robustness.",
        "DOI": "10.1109/TMI.2020.3048477",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Distant Domain Transfer Learning for Medical Imaging",
        "paper_author": "Niu S.",
        "publication": "IEEE Journal of Biomedical and Health Informatics",
        "citied_by": "84",
        "cover_date": "2021-10-01",
        "Abstract": "Medical image processing is one of the most important topics in the Internet of Medical Things (IoMT). Recently, deep learning methods have carried out state-of-the-art performances on medical imaging tasks. In this paper, we propose a novel transfer learning framework for medical image classification. Moreover, we apply our method COVID-19 diagnosis with lung Computed Tomography (CT) images. However, well-labeled training data sets cannot be easily accessed due to the disease's novelty and privacy policies. The proposed method has two components: reduced-size Unet Segmentation model and Distant Feature Fusion (DFF) classification model. This study is related to a not well-investigated but important transfer learning problem, termed Distant Domain Transfer Learning (DDTL). In this study, we develop a DDTL model for COVID-19 diagnosis using unlabeled Office-31, Caltech-256, and chest X-ray image data sets as the source data, and a small set of labeled COVID-19 lung CT as the target data. The main contributions of this study are: 1) the proposed method benefits from unlabeled data in distant domains which can be easily accessed, 2) it can effectively handle the distribution shift between the training data and the testing data, 3) it has achieved 96% classification accuracy, which is 13% higher classification accuracy than 'non-transfer' algorithms, and 8% higher than existing transfer and distant transfer algorithms.",
        "DOI": "10.1109/JBHI.2021.3051470",
        "affiliation_name": "Embry-Riddle Aeronautical University",
        "affiliation_city": "Daytona Beach",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "IntelligentCrowd: Mobile Crowdsensing via Multi-Agent Reinforcement Learning",
        "paper_author": "Chen Y.",
        "publication": "IEEE Transactions on Emerging Topics in Computational Intelligence",
        "citied_by": "18",
        "cover_date": "2021-10-01",
        "Abstract": "The prosperity of smart mobile devices has made mobile crowdsensing (MCS) a promising paradigm for completing complex sensing and computation tasks. In the past, great efforts have been made on the design of incentive mechanisms and task allocation strategies from MCS platform's perspective to motivate mobile users' participation. However, in practice, MCS participants face many uncertainties coming from their sensing environment as well as other participants' strategies, and how do they interact with each other and make sensing decisions is not well understood. In this paper, we take MCS participants' perspectives to derive an online sensing policy to maximize their payoffs via MCS participation. Specifically, we model the interactions of mobile users and sensing environments as a multi-agent Markov decision process. Each participant cannot observe others' decisions, but needs to decide her effort level in sensing tasks only based on local information, e.g., her own record of sensed signals' quality. To cope with the stochastic sensing environment, we develop an intelligent crowdsensing algorithm IntelligentCrowd by leveraging the power of multi-agent reinforcement learning (MARL). Our algorithm leads to the optimal sensing policy for each user to maximize the expected payoff against stochastic sensing environments, and can be implemented at the individual participant's level in a distributed fashion. Numerical simulations demonstrate that IntelligentCrowd significantly improves users' payoffs in sequential MCS tasks under various sensing dynamics.",
        "DOI": "10.1109/TETCI.2020.3042244",
        "affiliation_name": "UW College of Engineering",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep reinforcement learning for multi-objective placement of virtual machines in cloud datacenters",
        "paper_author": "Caviglione L.",
        "publication": "Soft Computing",
        "citied_by": "49",
        "cover_date": "2021-10-01",
        "Abstract": "The ubiquitous diffusion of cloud computing requires suitable management policies to face the workload while guaranteeing quality constraints and mitigating costs. The typical trade-off is between the used power and the adherence to a service-level metric subscribed by customers. To this aim, a possible idea is to use an optimization-based placement mechanism to select the servers where to deploy virtual machines. Unfortunately, high packing factors could lead to performance and security issues, e.g., virtual machines can compete for hardware resources or collude to leak data. Therefore, we introduce a multi-objective approach to compute optimal placement strategies considering different goals, such as the impact of hardware outages, the power required by the datacenter, and the performance perceived by users. Placement strategies are found by using a deep reinforcement learning framework to select the best placement heuristic for each virtual machine composing the workload. Results indicate that our method outperforms bin packing heuristics widely used in the literature when considering either synthetic or real workloads.",
        "DOI": "10.1007/s00500-020-05462-x",
        "affiliation_name": "Università degli Studi di Genova",
        "affiliation_city": "Genoa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "TextSpamDetector: textual content based deep learning framework for social spam detection using conjoint attention mechanism",
        "paper_author": "Elakkiya E.",
        "publication": "Journal of Ambient Intelligence and Humanized Computing",
        "citied_by": "13",
        "cover_date": "2021-10-01",
        "Abstract": "Online Social Networks (OSNs) allow easy membership leading to registration of a huge population and generation of voluminous information. These characteristics attract spammers to spread spam which may cause annoyance, financial loss, or personal information loss to the user and also weaken the reputation of social network sites. Most of the spam detection methods are based on user and content-based features using machine learning techniques. But, these annotated features are difficult to extract in real-time due to the privacy policy of most social network sites. Even for the features that can be extracted, because of their large size, the manual extraction process is complex and time-consuming. So there is a need for text level spam detection that does not require extraction of hard-core features. Existing deep learning based or existing single attention mechanism based text classification methods could not perform well as social network data are sparse with short texts and noises. Moreover, Spammers avoid direct spam words and use indirect words to evade spam filtering techniques and thus resulting in the dynamic and non-stationary nature of the social network spam texts. These indirect words contain hidden context that creates attention drift problem. So conjoint attention mechanism along with two attention mechanisms namely normal attention and context preserving attention are proposed to avoid attention drift problem in this deep learning-based text level spam detection technique (TextSpamDetector). Attention drift problem is solved by one attention mechanism which helps to find the important words while another attention mechanism allows focusing on attention in target context by referring to higher level abstraction of context vector. These attention mechanisms are referring to different context representations of the input text for finding informative words from the structural context representation. This structural context representation containing both local semantic features as well as global semantic dependency features is generated by CNN and BiLSTM. The proposed model is evaluated with the existing spam detection techniques using three datasets and the experimental results have proved that the proposed model performs well in terms of accuracy, F measure, and false-positive rate.",
        "DOI": "10.1007/s12652-020-02640-5",
        "affiliation_name": "Indian Institute of Information Technology Una",
        "affiliation_city": "Una",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A study of financial cycles and the macroeconomy in Taiwan",
        "paper_author": "Cheng H.L.",
        "publication": "Empirical Economics",
        "citied_by": "4",
        "cover_date": "2021-10-01",
        "Abstract": "This paper studies the characteristics of financial cycles (credit and house prices) and their interactions with business cycles in Taiwan. We employ multivariate structural time series model to estimate trend and cyclical components in real bank credit, real house prices, and real GDP. We find that financial cycles are roughly twice the length of the business cycles, and house price cycles lead both credit and business cycles. Nevertheless, the estimated length of business and financial cycles in Taiwan is much shorter than those in industrialized economies. We then use machine learning to evaluate the importance of a macroeconomic variable that predicts downturns of financial cycles, by conducting both in-sample fitting and out-of-sample forecasting. Those macrovariables selected by machine learning reflects Taiwan’s close linkage in trades and financial interdependence with other countries such as China and spillover effects from the Fed’s monetary policy.",
        "DOI": "10.1007/s00181-020-01926-z",
        "affiliation_name": "National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Regulating human control over autonomous systems",
        "paper_author": "Firlej M.",
        "publication": "Regulation and Governance",
        "citied_by": "23",
        "cover_date": "2021-10-01",
        "Abstract": "In recent years, many sectors have experienced significant progress in automation, associated with the growing advances in artificial intelligence and machine learning. There are already automated robotic weapons, which are able to evaluate and engage with targets on their own, and there are already autonomous vehicles that do not need a human driver. It is argued that the use of increasingly autonomous systems (AS) should be guided by the policy of human control, according to which humans should execute a certain significant level of judgment over AS. While in the military sector there is a fear that AS could mean that humans lose control over life and death decisions, in the transportation domain, on the contrary, there is a strongly held view that autonomy could bring significant operational benefits by removing the need for a human driver. This article explores the notion of human control in the United States in the two domains of defense and transportation. The operationalization of emerging policies of human control results in the typology of direct and indirect human controls exercised over the use of AS. The typology helps to steer the debate away from the linguistic complexities of the term “autonomy.” It identifies instead where human factors are undergoing important changes and ultimately informs about more detailed rules and standards formulation, which differ across domains, applications, and sectors.",
        "DOI": "10.1111/rego.12344",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Meet the critics: Analyzing the EU Commission's Regulatory Scrutiny Board through quantitative text analysis",
        "paper_author": "Senninger R.",
        "publication": "Regulation and Governance",
        "citied_by": "11",
        "cover_date": "2021-10-01",
        "Abstract": "As part of the “better regulation” agenda, the European Commission created a semi-independent institution, the Regulatory Scrutiny Board, to monitor the preparation of policy proposals. The position of this Board is potentially wide-ranging. A proposal that is not given the green light by it cannot proceed in the Commission's internal decisionmaking process. But so far, the Board has only received scant scholarly attention. We provide a comprehensive analysis of the impact of the Regulatory Scrutiny Board on the Commission's policy preparation. Using machine learning techniques and quantitative text analysis, we study 673 Board opinions and compare almost 100 draft and final policy proposals. Our findings show that the Board is an active watchdog that is taken seriously by the Commission's departments. A full understanding of policy preparation in the EU therefore requires more scholarly attention to the Regulatory Scrutiny Board.",
        "DOI": "10.1111/rego.12312",
        "affiliation_name": "Aarhus Universitet",
        "affiliation_city": "Aarhus",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Evaluating the impact of curriculum learning on the training process for an intelligent agent in a video game",
        "paper_author": "Sáenz R.",
        "publication": "Inteligencia Artificial",
        "citied_by": "3",
        "cover_date": "2021-09-30",
        "Abstract": "We wanted to measure the impact of the curriculum learning technique on the training times for an agent that is being trained to play a video game using reinforcement learning, so we designed experiments with different training curriculums adapted for the video game chosen as a case study, experiments run on a game simulation platform, using the mean cumulative reward as the performance measure. Results suggest that curriculum learning has a significant impact on the training process, decreasing training times up to 40% percent in some cases.",
        "DOI": "10.4114/intartif.vol24iss68pp1-20",
        "affiliation_name": "Universidad Nacional de Colombia",
        "affiliation_city": "Bogotá, D.C.",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "Time-Series Forecasting of COVID-19 Cases Using Stacked Long Short-Term Memory Networks",
        "paper_author": "Maaliw R.R.",
        "publication": "2021 International Conference on Innovation and Intelligence for Informatics, Computing, and Technologies, 3ICT 2021",
        "citied_by": "8",
        "cover_date": "2021-09-29",
        "Abstract": "The extent of the COVID-19 pandemic has devastated world economies and claimed millions of lives. Timely and accurate information such as time-series forecasting is crucial for government, healthcare systems, decision-makers, and policy-implementers in managing the disease's progression. With the potential value of early knowledge to save countless lives, the research investigated and compared the capabilities and robustness of sophisticated deep learning models to traditional time-series forecasting methods. The results show that the Stacked Long Short-Term Memory Networks (SLSTM) outperforms the Exponential Smoothing (ES) and Autoregressive Integrated Moving Average (ARIMA) models for a 15-day forecast horizon. SLSTM attained a collective mean accuracy of 92.17% (confirmed cases) and 82.31% (death cases) using historical data of 419 days from March 6, 2020 to April 28, 2021 of four countries - the Philippines, United States, India, and Brazil.",
        "DOI": "10.1109/3ICT53449.2021.9581688",
        "affiliation_name": "Southern Luzon State University",
        "affiliation_city": "Quezon City",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "Temperature Control of Proton Exchange Membrane Fuel Cell Based on Machine Learning",
        "paper_author": "Li J.",
        "publication": "Frontiers in Energy Research",
        "citied_by": "14",
        "cover_date": "2021-09-28",
        "Abstract": "In order to improve the proton exchange membrane fuel cell (PEMFC) working efficiency, we propose a deep-reinforcement-learning based PID controller for realizing optimal PEMFC stack temperature. For this purpose, we propose the Improved Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm, a tuner of the PID controller, which can adjust the coefficients of the controller in real time. This algorithm accelerates the learning speed of an agent by continuously changing the soft update parameters during the training process, thereby improving the training efficiency of the agent, and further reducing training costs and obtaining a robust strategy. The effectiveness of the control algorithm is verified through a simulation in which it is compared against a group of existing algorithms.",
        "DOI": "10.3389/fenrg.2021.763099",
        "affiliation_name": "South China University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A comparative analysis of opinions and sentiments on clean India campaign and sustainability goals of 2030",
        "paper_author": "Goswami M.",
        "publication": "AIP Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2021-09-28",
        "Abstract": "Human are blessed with natural intelligence. Artificial Intelligence can help human minds to make a best usage of machines to handle huge amount of data with accuracy and precision. AI has a widespread application in 21st century. Opinion mining is an application of artificial intelligence. The opinions expressed in social media can be extracted using python which can be used as an input for various machine learning algorithms to identify many patterns which can help policy makers to make effective policies. Clean India Campaign started in India with a set of goals to be achieved. Sustainability goals of 2030 given by United Nations puts light on many important aspects which need immediate attention in the next 9 years. Current pandemic Covid-19 has also triggered the necessity behind putting immediate attention for a better tomorrow. Without proper awareness programs, brainstorming knowledge cultivation, orienting minds towards the \"what-why-where\"aspects of sustainable growth in each sphere of life, aligning industrial development and digital era towards sustainable industrial development in digital era, sustainable economy, sustainable care of each natural resource; it is not easy to accomplish the sustainability goals of 2030 given by United Nations.This work emphasizes on the case study conducted as an initiative to motivate future policy makers to be aware of the different dimension of 2030 United Nations Agenda and the clean India campaign to take initiatives as a professional through the skills learned focusing on India. Realizing Individual social Responsibility can make a big difference in the planning and implementation of the goals and missions. Swachch Bharat Abhiyan (Clean India Campaign) started Swachch Bharat Mission-Urban (SBM-U) with a few objectives to make India Clean.This work has proposed two phases for analyzing opinions. This research have provided a methodology to apply AI to improve the opinion mining. The conventional opinion analysis is limited by reachability but the automated opinion analysis can be scaled up using artificial intelligence based applications. The uniqueness of the work lies in its focus on 'one-three verticals' in phase 1 of the methodology. Many prominent regions of India are considered as a part of the study. It helps us to provide a clearer picture across different regions of India. It also provide an avenue to list tasks to be done for each region and a set of ways which could be adopted by the future professionals and current stakeholders of higher education institute. Phase 2 focusses on more number of opinions collected from across the globe through digital platforms.",
        "DOI": "10.1063/5.0066545",
        "affiliation_name": "Amity University Kolkata",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Novel Machine Learning-Assisted Policy Recommendation Method on COVID-19 Vaccination Campaign",
        "paper_author": "Song B.",
        "publication": "Proceedings of the 2021 IEEE/ACM 25th International Symposium on Distributed Simulation and Real Time Applications, DS-RT 2021",
        "citied_by": "0",
        "cover_date": "2021-09-27",
        "Abstract": "As the most serious global infectious disease in the past 100 years, it has caused severe loss of life and property to countries and their people worldwide in the past year. As the most powerful tool in the fight against the epidemic, how to quickly promote the COVID-19 vaccine administration plays a vital role in gradually establishing an immune barrier in the population as soon as possible and blocking the COVID-19 epidemic. In this paper, we provide a machine learning-based policy recommendation method on the vaccination campaign of COVID-19 by minimizing three different cost factors: the duration of the pandemic, the budget of the COVID-19 battle as well as the death toll. To generate a more efficient vaccination policy, we construct an Age-stratified Susceptible-Infected-Recovered (ASSIR) model. We validate our method based on the real-world dataset of India by comparing our simulated results with the government's vaccination plan from machine learning prediction. Our approach shows a 13% decrease in disease control time and government budget. At the same time, we find out that vaccination based on each province's population leads to a 12.4% decrease in the death toll than on infection cases. The model developed in this study has practical implications for COVID-19 vaccination campaigns and the infection control of other infectious diseases.",
        "DOI": "10.1109/DS-RT52167.2021.9576138",
        "affiliation_name": "Duke Kunshan University",
        "affiliation_city": "Kunshan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Influence of social determinants of health and county vaccination rates on machine learning models to predict COVID-19 case growth in Tennessee",
        "paper_author": "Wylezinski L.S.",
        "publication": "BMJ Health and Care Informatics",
        "citied_by": "4",
        "cover_date": "2021-09-27",
        "Abstract": "Introduction The SARS-CoV-2 (COVID-19) pandemic has exposed health disparities throughout the USA, particularly among racial and ethnic minorities. As a result, there is a need for data-driven approaches to pinpoint the unique constellation of clinical and social determinants of health (SDOH) risk factors that give rise to poor patient outcomes following infection in US communities. Methods We combined county-level COVID-19 testing data, COVID-19 vaccination rates and SDOH information in Tennessee. Between February and May 2021, we trained machine learning models on a semimonthly basis using these datasets to predict COVID-19 incidence in Tennessee counties. We then analyzed SDOH data features at each time point to rank the impact of each feature on model performance. Results Our results indicate that COVID-19 vaccination rates play a crucial role in determining future COVID-19 disease risk. Beginning in mid-March 2021, higher vaccination rates significantly correlated with lower COVID-19 case growth predictions. Further, as the relative importance of COVID-19 vaccination data features grew, demographic SDOH features such as age, race and ethnicity decreased while the impact of socioeconomic and environmental factors, including access to healthcare and transportation, increased. Conclusion Incorporating a data framework to track the evolving patterns of community-level SDOH risk factors could provide policy-makers with additional data resources to improve health equity and resilience to future public health emergencies.",
        "DOI": "10.1136/bmjhci-2021-100439",
        "affiliation_name": "Robert F. Wagner Graduate School of Public Service",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A machine learning model to investigate factors contributing to the energy transition of utility and independent power producer sectors internationally",
        "paper_author": "Alova G.",
        "publication": "iScience",
        "citied_by": "1",
        "cover_date": "2021-09-24",
        "Abstract": "There is evidence of independent power producers dominating the electricity sector's uptake of renewable energy, with utilities lagging behind. Here, we build a machine-learning-based model with multiple dependent variables to simultaneously explore environmental policy and market structure contributions to investment patterns in different technologies by utility and independent producer sectors across 33 countries over 20 years. With the analysis enabling the capture of non-linear relationships, our findings suggest substantial resistance of gas capacity to even strict carbon pricing policies, while coal appears more responsive. There is also an indication of policy pricing in effects. The positive link of renewables subsidies and fossil fuel disincentives to renewables expansion, particularly wind, is more prominent for independent power producers than utilities. Regarding market structures, different characteristics tend to matter for renewables growth compared to fossil fuel reductions. The results also suggest considerable differences in policy and market factor contributions to technology choices of Organisation for Economic Co-operation and Development vis-à-vis emerging economies.",
        "DOI": "10.1016/j.isci.2021.102929",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Research on the third party logistics mode of cross border e-commerce based on machine learning algorithm",
        "paper_author": "Zeng X.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "3",
        "cover_date": "2021-09-24",
        "Abstract": "Logistics is an important axis of e-commerce development and plays an important role in promoting the rapid development of e-commerce. The development of third-party logistics not only meets the interests of e-commerce, but also meets the needs of logistics, which is a trend of social division of labor. The development of cross-border e-commerce has created a huge logistics market. As a product of the cross-border e-commerce environment, third-party logistics is not only a necessary condition for the stability of China's international trade and the development of cross-border e-commerce, but also a trend promoted by national policies. This article introduces the third-party logistics model, analyzes the needs of third-party logistics development, and promotes third-party logistics in Korea. This model studies the third-party logistics of cross-border e-commerce based on machine learning algorithms. Further development of the cross-border e-commerce environment. The development of artificial intelligence has promoted the development of platform economy and the construction of cross-border e-commerce logistics system. The application and selection of third-party logistics models in cross-border e-commerce conform to the trend of the times. In order to support the development of cross-border e-commerce business and solve the problems of international import and export trade, it is necessary to make full use of the advantages of the third-party logistics model.",
        "DOI": "10.1145/3482632.3482716",
        "affiliation_name": "Hubei Three Gorges Polytechnic",
        "affiliation_city": "Yichang, Hubei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Research on financial risk measurement model based on support vector machine algorithm",
        "paper_author": "Lyu S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-09-24",
        "Abstract": "Because the actor is rational, and everyone's response to information is the same, investors can only get the average income of the market. The traditional risk measurement model has not achieved ideal results in practical application, and can not explain a large number of anomalies in the financial market, especially the abnormal fluctuations in the market. As a developing country, which is a member of global financial integration, China cannot be exposed to international financial risks. The financial crisis always reflects the lack of financial supervision and the loopholes of economic policies in a country or region in some aspects. If we can do a good job of active prevention and early control, we can avoid the influence and destruction of financial risks. Support vector machine is a classification method based on statistical learning theory, which can be used to analyze financial ratio and non-financial ratio and estimate default probability. In this paper, based on support vector machine algorithm, useful information is extracted or mined from financial data, and a financial risk measurement model is constructed to achieve the purpose of forecasting financial risks.",
        "DOI": "10.1145/3482632.3484008",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Sensitivity Analysis of Reinforcement Learning-Based Hybrid Electric Vehicle Powertrain Control",
        "paper_author": "Yao Z.",
        "publication": "SAE International Journal of Commercial Vehicles",
        "citied_by": "2",
        "cover_date": "2021-09-23",
        "Abstract": "Hybrid Electric Vehicles (HEVs) achieve better fuel economy than conventional vehicles by utilizing two different power sources: an internal combustion engine and an electrical motor. The power distribution between these two components must be controlled using some algorithm, be it rule based, optimization based, or reinforcement learning based. In the design of such control algorithms, it is important to evaluate the impact that variations of certain design parameters will have on the system performance, in this case, fuel economy. Traditional methods of sensitivity analysis have been applied to various power flow control algorithms to determine their robustness to the variations of HEV design parameters. This article presents a sensitivity analysis of three power flow control algorithms: twin delayed deep deterministic policy gradient (TD3), deep deterministic policy gradient (DDPG), and adaptive equivalent consumption minimization strategy (A-ECMS). The overall results show that the deep reinforcement learning (DRL)-based control algorithms have similar robustness, but higher design predictability compared to the conventional A-ECMS algorithm.",
        "DOI": "10.4271/02-14-03-0033",
        "affiliation_name": "University of Alabama",
        "affiliation_city": "not available",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The voices of european law: Legislators, judges and law professors",
        "paper_author": "Dyevre A.",
        "publication": "German Law Journal",
        "citied_by": "7",
        "cover_date": "2021-09-22",
        "Abstract": "European Union legislators, CJEU judges and EU law scholars have produced streams of texts which determine both what EU law is and how it is perceived. We explore what these distinct voices tell us about the EU's legal and policy priorities using a mega corpus compiling more than 200,000 legislative acts, 55,000 court rulings and opinions, and 4,000 articles from a leading EU law journal. Applying an unsupervised machine learning technique known as probabilistic topic modelling, we find that economic integration remains the focus of EU law, but that scholars tend to emphasize rights issues more and ignore certain topics, such as farming regulations, almost entirely. The relationship among these partly interdependent, partly autonomous voices, we suggest, can be conceptualized in terms of co-evolution. Legislation influences issue attention on the CJEU, which, in turn, influences what law professors choose to write about.",
        "DOI": "10.1017/glj.2021.47",
        "affiliation_name": "KU Leuven",
        "affiliation_city": "Leuven",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "2021 International Balkan Conference on Communications and Networking, BalkanCom 2021",
        "paper_author": "NA",
        "publication": "2021 International Balkan Conference on Communications and Networking, BalkanCom 2021",
        "citied_by": "0",
        "cover_date": "2021-09-20",
        "Abstract": "The proceedings contain 35 papers. The topics discussed include: digital transformation in industry 4.0 using vibration sensors and machine learning; an efficient decentralized approach for mmWave MIMO channel estimation; meta distribution-optimal base station deployment for finite-area mobile networks; a refined topology-independent probabilistic TDMA MAC policy for ad hoc networks; a coverage path planning algorithm for self-organizing drone swarms; dynamics of multi-strain malware epidemics over duty-cycled wireless sensor networks; and edge computing: system overview and fusion with wireless power transfer.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A Cyber-Physical System for Freeway Ramp Meter Signal Control Using Deep Reinforcement Learning in a Connected Environment",
        "paper_author": "Hou Y.",
        "publication": "IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC",
        "citied_by": "3",
        "cover_date": "2021-09-19",
        "Abstract": "Freeway bottlenecks such as on-ramp merging areas account for about 40% of recurring freeway congestion. It is generally agreed that building more roads and adding more lanes to existing infrastructure does not solve the congestion problem, and so dynamic traffic control measures offer a more cost-effective alternative. Ramp meters, traffic signal devices that regulate traffic flow entering freeways, are among the most effective measures to mitigate congestion at on-ramp merging areas on freeways. The confluence of deep reinforcement learning (RL) and connectivity provides a possible solution to advance ramp meter signal control. Deep RL is a group of machine-learning methods that enables an agent learning from the environment to improve its performance. In this study, three deep RL methods-proximal policy optimization (PPO), Ape-X deep Q-network (DQN), and asynchronous advantage actor-critic agents (A3C)-are explored for ramp meter signal control to maximize vehicle speed and traffic throughput, as well as to minimize energy consumption and emissions at freeway on-ramp merging areas in a connected environment. The low computational requirement and scalability of deep RL for deployment make it a powerful optimization tool for time-sensitive applications such as ramp meter signal control. The results of this study show that deep RL methods yield superior performance to both a fixed-time controller and ALINE A, a state-of-the-art feedback controller.",
        "DOI": "10.1109/ITSC48978.2021.9564699",
        "affiliation_name": "National Renewable Energy Laboratory",
        "affiliation_city": "Golden",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Hybrid Method Based on Stacking for Sentiment Analysis of Indonesian Tweet Responding to COVID-19 Pandemic",
        "paper_author": "Renaldy R.",
        "publication": "Proceedings - 2021 International Seminar on Application for Technology of Information and Communication: IT Opportunities and Creativities for Digital Innovation and Communication within Global Pandemic, iSemantic 2021",
        "citied_by": "0",
        "cover_date": "2021-09-18",
        "Abstract": "Sentiment analysis is opinion mining that focuses on learning about sentiments, attitudes or emotions in a text. Public opinion regarding COVID-19 can be processed to get a sentiment so that it is useful in making a decision or policy. In this study, sentiment analysis was done using a stacking method on Indonesian-language tweet data related to COVID-19. Sentistrength_id is used for sentiment labeling on tweet data that has been collected so that sentiment labels can be obtained in the form of positive and negative class. The sentiment analysis carried out on the tweet data resulted in a positive opinion class of 1879 and negative opinion of 1706. From these data the classification was done using stacking of naïve bayes, K-Nearest Neighbor, Linear Regression as base learner and Support Vector Machine as meta learner. The classification result produce a value in accuracy, precision and recall of 85.6%, 86% and 86%, respectively..",
        "DOI": "10.1109/iSemantic52711.2021.9573199",
        "affiliation_name": "Universitas Dian Nuswantoro",
        "affiliation_city": "Semarang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Analyze Corporate Anti-Corruption Disclosure with Feature Selection",
        "paper_author": "Utomo V.G.",
        "publication": "Proceedings - 2021 International Seminar on Application for Technology of Information and Communication: IT Opportunities and Creativities for Digital Innovation and Communication within Global Pandemic, iSemantic 2021",
        "citied_by": "2",
        "cover_date": "2021-09-18",
        "Abstract": "Corruption creates problem for a country, including Indonesia. Indonesian government put their effort to eliminate corruption. Not only the government, but companies also have their part in corruption elimination with anti-corruption disclosure policy. For some time, the research tries to find the significant variables that influence the policy. However, most of the studies use a statistical approach only. This study offers an alternative method called feature selection that is part of machine learning. The data set in this research has two sources. The first one is sourced from the annual report of companies listed on the Indonesia Stock Exchange from 2017 to 2019. The second source is the membership data of the companies in the United Nations Global Compact (UNGC). Experiment shows that feature selection methods can offer alternatives variables selection. Based on prediction performance in machine learning, feature selection methods may choose the factors that are important in company anti-corruption disclosure policy better than statistical analysis..",
        "DOI": "10.1109/iSemantic52711.2021.9573198",
        "affiliation_name": "Universitas Semarang",
        "affiliation_city": "Semarang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Public attitudes toward COVID-19 vaccines on English-language Twitter: A sentiment analysis",
        "paper_author": "Liu S.",
        "publication": "Vaccine",
        "citied_by": "90",
        "cover_date": "2021-09-15",
        "Abstract": "Objective: To identify themes and temporal trends in the sentiment of COVID-19 vaccine-related tweets and to explore variations in sentiment at world national and United States state levels. Methods: We collected English-language tweets related to COVID-19 vaccines posted between November 1, 2020, and January 31, 2021. We applied the Valence Aware Dictionary and sEntiment Reasoner tool to calculate the compound score to determine whether the sentiment mentioned in each tweet was positive (compound ≥ 0.05), neutral (-0.05 < compound < 0.05), or negative (compound ≤ -0.05). We applied the latent Dirichlet allocation analysis to extract main topics for tweets with positive and negative sentiment. Then we performed a temporal analysis to identify time trends and a geographic analysis to explore sentiment differences in tweets posted in different locations. Results: Out of a total of 2,678,372 COVID-19 vaccine-related tweets, tweets with positive, neutral, and negative sentiments were 42.8%, 26.9%, and 30.3%, respectively. We identified five themes for positive sentiment tweets (trial results, administration, life, information, and efficacy) and five themes for negative sentiment tweets (trial results, conspiracy, trust, effectiveness, and administration). On November 9, 2020, the sentiment score increased significantly (score = 0.234, p = 0.001), then slowly decreased to a neutral sentiment in late December and was maintained until the end of January. At the country level, tweets posted in Brazil had the lowest sentiment score of −0.002, while tweets posted in the United Arab Emirates had the highest sentiment score of 0.162. The overall average sentiment score for the United States was 0.089, with Washington, DC having the highest sentiment score of 0.144 and Wyoming having the lowest sentiment score of 0.036. Conclusions: Public sentiment on COVID-19 vaccines varied significantly over time and geography. Sentiment analysis can provide timely insights into public sentiment toward the COVID-19 vaccine and guide public health policymakers in designing locally tailored vaccine education programs.",
        "DOI": "10.1016/j.vaccine.2021.08.058",
        "affiliation_name": "West China School of Medicine/West China Hospital of Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Methodological framework for short-and medium-term energy, solar and wind power forecasting with stochastic-based machine learning approach to monetary and energy policy applications",
        "paper_author": "Ahmad T.",
        "publication": "Energy",
        "citied_by": "61",
        "cover_date": "2021-09-15",
        "Abstract": "Anomalous seasons such as low-wind summers and extremely cold winters can seriously disrupt energy reliability and productivity. Better short/medium-term forecasts that provide reliable and strategic planning insights will allow the energy industry to plan for these extremes. In order to efficiently quantify uncertainty, this study proposes a Gaussian stochastic-based machine learning process model (GPR) for short/medium-term energy, solar, and wind (ESW) power forecasts using two different temporal resolutions of data. Four experimental steps (EXMS) were designed. Each EXMS is designed with four distinct fitting and predicting methods, and the GPR model uses seven kernel covariance functions for hyperparameter optimization. Real-time data is used for the forecasting analysis at three different locations. The forecasting results are validated using three existing models. The percent coefficient of variation of CVGPR1 and CVGPR2 of EXMS-1 and EXMS-3 for ESW power forecasts is 0.017%, 0.057%, 0.025%, and 0.223%, 0.225%, 0.170%, respectively. Accuracy has shown that the proposed model can predict ESW power simultaneously at two different temporal resolution data. The GPR accuracy with four EXMS methodologies is promising by addressing ESW power forecasts under the GPR framework of significant utilities, independent power producers, and public interest.",
        "DOI": "10.1016/j.energy.2021.120911",
        "affiliation_name": "State Key Laboratory of Internet of Things for Smart City",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "Stock market index prediction based on reservoir computing models",
        "paper_author": "Wang W.J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "31",
        "cover_date": "2021-09-15",
        "Abstract": "Prediction of the financial market price is critical for financial decision-making and market policy-making. Recently, various machine learning and deep learning methods have been adopted to predict financial markets’ movements using historical time series of prices. However, accurate prediction of financial prices is still a long-standing challenge that always calls for new approaches. In this study, a novel machine learning model of reservoir computing is developed to predict stock market indices. The performance of the proposed new model is systematically evaluated using the time series of daily closing prices of seven major international stock market indices including S&P500 Index, New York Stock Exchange Composite, Dow Jones Industrial Average, Nasdaq Composite Index, Financial Times Stock Exchange 100 Index, Nikkei 225 Index, and Shanghai Stock Exchange Index between January 4, 2010, and December 31, 2018 covering 2,272 trading days. The results show that our model outperforms the widely used deep learning methods of long short-term memory and recurrent neural network in most cases. To further evaluate the predictive capability of our model, we compare our model to the other two newly reported deep learning methods in recent studies. Comparative results also show that our model is competitive to those deep learning methods in predicting stock market indices. Our study contributes to the literature by developing novel reservoir computing models for financial market predictions. Meanwhile, our results also provide practical implications for financial practitioners of potential financial applications of reservoir computing in financial time series analysis and predictions.",
        "DOI": "10.1016/j.eswa.2021.115022",
        "affiliation_name": "University of Fribourg",
        "affiliation_city": "Fribourg",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Combining Neural Gas and Reinforcement Learning for Adaptive Traffic Signal Control",
        "paper_author": "Miletic M.",
        "publication": "Proceedings Elmar - International Symposium Electronics in Marine",
        "citied_by": "3",
        "cover_date": "2021-09-13",
        "Abstract": "Travel time of vehicles in urban traffic networks can be reduced by using Adaptive Traffic Signal Control (ATSC) to change the signal program according to the current traffic situation. Modern ATSC approaches based on Reinforcement Learning (RL) can learn the optimal signal control policy. While there are multiple RL based ATSC implementations available, most suffer from high state-action complexity leading to slow convergence and long training time. In this paper, the state-action complexity of ATSC based RL is reduced by implementing Growing Neural Gas learning structure as an integral part of RL, leading to high convergence rate and system stability. The presented approach is evaluated on a simulated signalized intersection, and compared with self-organizing map RL-based ATSC systems. Obtained results prove that the reduction of state-action complexity in this manner improves the effectiveness of RL based ATSC not needing to have an a priory analysis of needed number of neurons for state representation.",
        "DOI": "10.1109/ELMAR52657.2021.9550948",
        "affiliation_name": "University of Zagreb, Faculty of Transport and Traffic Sciences",
        "affiliation_city": "Zagreb",
        "affiliation_country": "Croatia"
    },
    {
        "paper_title": "Comparing Deep Reinforcement Learning Algorithms’ Ability to Safely Navigate Challenging Waters",
        "paper_author": "Larsen T.N.",
        "publication": "Frontiers in Robotics and AI",
        "citied_by": "25",
        "cover_date": "2021-09-13",
        "Abstract": "Reinforcement Learning (RL) controllers have proved to effectively tackle the dual objectives of path following and collision avoidance. However, finding which RL algorithm setup optimally trades off these two tasks is not necessarily easy. This work proposes a methodology to explore this that leverages analyzing the performance and task-specific behavioral characteristics for a range of RL algorithms applied to path-following and collision-avoidance for underactuated surface vehicles in environments of increasing complexity. Compared to the introduced RL algorithms, the results show that the Proximal Policy Optimization (PPO) algorithm exhibits superior robustness to changes in the environment complexity, the reward function, and when generalized to environments with a considerable domain gap from the training environment. Whereas the proposed reward function significantly improves the competing algorithms’ ability to solve the training environment, an unexpected consequence of the dimensionality reduction in the sensor suite, combined with the domain gap, is identified as the source of their impaired generalization performance.",
        "DOI": "10.3389/frobt.2021.738113",
        "affiliation_name": "SINTEF Digital",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Scaling enterprise recommender systems for decentralization",
        "paper_author": "Van Der Goes M.",
        "publication": "RecSys 2021 - 15th ACM Conference on Recommender Systems",
        "citied_by": "3",
        "cover_date": "2021-09-13",
        "Abstract": "Within decentralized organizations, the local demand for recommender systems to support business processes grows. The diversity in data sources and infrastructure challenges central engineering teams. Achieving a high delivery velocity without technical debt requires a scalable approach in the development and operations of recommender systems. At the HEINEKEN Company, we execute a machine learning operations method with five best practices: pipeline automation, data availability, exchangeable artifacts, observability, and policy-based security. Creating a culture of self-service, automation, and collaboration to scale recommender systems for decentralization. We demonstrate a practical use case of a self-service ML workspace deployment and a recommender system, that scale faster to subsidiaries and with less technical debt. This enables HEINEKEN to globally support applications that generate insights with local business impact.",
        "DOI": "10.1145/3460231.3474616",
        "affiliation_name": "HEINEKEN",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Online learning for recommendations at grubhub",
        "paper_author": "Egg A.",
        "publication": "RecSys 2021 - 15th ACM Conference on Recommender Systems",
        "citied_by": "6",
        "cover_date": "2021-09-13",
        "Abstract": "We propose a method to easily modify existing offline Recommender Systems to run online using Transfer Learning. Online Learning for Recommender Systems has two main advantages: quality and scale. Like many Machine Learning algorithms in production if not regularly retrained will suffer from Concept Drift. A policy that is updated frequently online can adapt to drift faster than a batch system. This is especially true for user-interaction systems like recommenders where the underlying distribution can shift drastically to follow user behaviour. As a platform grows rapidly like Grubhub, the cost of running batch training jobs becomes material. A shift from stateless batch learning offline to stateful incremental learning online can recover, for example, at Grubhub, up to a 45x cost savings and a +20% metrics increase. There are a few challenges to overcome with the transition to online stateful learning, namely convergence, non-stationary embeddings and off-policy evaluation, which we explore from our experiences running this system in production.",
        "DOI": "10.1145/3460231.3474599",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Pessimistic reward models for off-policy learning in recommendation",
        "paper_author": "Jeunen O.",
        "publication": "RecSys 2021 - 15th ACM Conference on Recommender Systems",
        "citied_by": "34",
        "cover_date": "2021-09-13",
        "Abstract": "Methods for bandit learning from user interactions often require a model of the reward a certain context-action pair will yield-for example, the probability of a click on a recommendation. This common machine learning task is highly non-trivial, as the data-generating process for contexts and actions is often skewed by the recommender system itself. Indeed, when the deployed recommendation policy at data collection time does not pick its actions uniformly-at-random, this leads to a selection bias that can impede effective reward modelling. This in turn makes off-policy learning-the typical setup in industry-particularly challenging. In this work, we propose and validate a general pessimistic reward modelling approach for off-policy learning in recommendation. Bayesian uncertainty estimates allow us to express scepticism about our own reward model, which can in turn be used to generate a conservative decision rule. We show how it alleviates a well-known decision making phenomenon known as the Optimiser's Curse, and draw parallels with existing work on pessimistic policy learning. Leveraging the available closed-form expressions for both the posterior mean and variance when a ridge regressor models the reward, we show how to apply pessimism effectively and efficiently to an off-policy recommendation use-case. Empirical observations in a wide range of environments show that being conservative in decision-making leads to a significant and robust increase in recommendation performance. The merits of our approach are most outspoken in realistic settings with limited logging randomisation, limited training samples, and larger action spaces.",
        "DOI": "10.1145/3460231.3474247",
        "affiliation_name": "Universiteit Antwerpen",
        "affiliation_city": "Antwerpen",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "B5G: Intelligent Coexistence Model for Edge Network",
        "paper_author": "Zimmo S.",
        "publication": "Canadian Conference on Electrical and Computer Engineering",
        "citied_by": "0",
        "cover_date": "2021-09-12",
        "Abstract": "While researchers are focusing on the fifth-generation (5G) cellular network, the network operators and standard bodies are discussing specifications for beyond fifth-generation (B5G) and 6G. Attributes of B5G include edge intelligence which involves artificial intelligence or machine learning (ML) in the architecture. Network edge servers, or base stations (BS), use edge computing to make time-critical decisions, especially in IoT devices while the data are being transmitted into the cloud. As the dynamic spectrum sharing continues in B5G, BSs implements the coexistence between Wi-Fi and cellular network. These exciting advances require energy efficiency to be considered as network operators pay the majority of the expenses to energy consumption. In this paper, different prediction models on traffic behaviour are computed to determine the lowest root mean square error. The best prediction model is used in the wake-up policy to consider the communication and computing times of the BS needed to return in service. Furthermore, a wake-up policy for the BS is introduced to maintain Quality of Service (QoS) while minimizing energy consumption. Particularly, a wake-up time threshold is set so that if the duration of the traffic prediction time does not cross this threshold, the decision will not be in favour to put it into sleep mode. This ensures that the QoS of the user is not compromised, as this threshold removes the unnecessary wasted time for BS to go to sleep and wake-up.",
        "DOI": "10.1109/CCECE53047.2021.9569058",
        "affiliation_name": "Manhattan College",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Progress and Prospect of Agent-Based Modeling for Water Resources Management<sup>*</sup>",
        "paper_author": "Shiwei Y.",
        "publication": "Advances in Earth Science",
        "citied_by": "1",
        "cover_date": "2021-09-10",
        "Abstract": "Agent-Based Modeling（ABM）has proved to be an efficient and powerful tool to study coupled human and natural systems. In recent years，the use of ABM to track water resources management issues is increasingly popular. Based on the review at the interface of ABM and water resources management studies，the techniques，progresses，advantages and limitations are summarized. Three topic areas are identified，addressing different research issues in the field： urban water resources management， agricultural water resources management and integrated watershed water resources management. Overall，with ABM，human decisions and behaviors are linked with water systems. The underlying feedback mechanisms between human and water systems can be revealed and used for policy and strategy planning. However，there still exist some limitations that need to be improved through the following ways. Firstly，more realistic human decision rules are certainly needed. Machine learning and big data techniques can be applied for this purpose. Additionally，the validation and evaluation methods suitable for ABM should be developed and enhanced. Furthermore，it is recommended to continuously conduct researches at a representative basin to advance the application of ABM for water resources management. More importantly，multi-disciplines collaborations such as involving more social and psychological sciences in ABM should be promoted. In conclusion，ABM provides a new insight to deal with water resources management issues. Strengthening the application of ABM in water resources management could promote the sustainable management and development of water resources around the world.",
        "DOI": "10.11867/j.issn.1001-8166.2021.089",
        "affiliation_name": "Northwest Institute of Eco-Environment and Resources",
        "affiliation_city": "Lanzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An Intelligent Control Model of Credit Line Computing in Intelligence Health-Care Systems",
        "paper_author": "Jiang R.",
        "publication": "Frontiers in Public Health",
        "citied_by": "2",
        "cover_date": "2021-09-10",
        "Abstract": "Technologies such as machine learning and artificial intelligence have brought about a tremendous change to biomedical computing and intelligence health care. As a principal component of the intelligence healthcare system, the hospital information system (HIS) has provided great convenience to hospitals and patients, but incidents of leaking private information of patients through HIS occasionally occur at times. Therefore, it is necessary to properly control excessive access behavior. To reduce the risk of patient privacy leakage when medical data are accessed, this article proposes a dynamic permission intelligent access control model that introduces credit line calculation. According to the target given by the doctor in HIS and the actual access record, the International Classification of Diseases (ICD)-10 code is used to describe the degree of correlation, and the rationality of the access is formally described by a mathematical formula. The concept of intelligence healthcare credit lines is redefined with relevance and time Windows. The access control policy matches the corresponding credit limit and credit interval according to the authorization rules to achieve the purpose of intelligent control. Finally, with the actual data provided by a Grade-III Level-A hospital in Kunming, the program code is written through machine learning and biomedical computing-related technologies to complete the experimental test. The experiment proves that the intelligent access control model based on credit computing proposed in this study can play a role in protecting the privacy of patients to a certain extent.",
        "DOI": "10.3389/fpubh.2021.718594",
        "affiliation_name": "Yunnan University of Finance and Economics",
        "affiliation_city": "Kunming",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Constructing the machine learning techniques based spatial drought vulnerability index in Karnataka state of India",
        "paper_author": "Saha S.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "36",
        "cover_date": "2021-09-10",
        "Abstract": "The drought induced vulnerability is owed much to rapid modernization, climate extremes, and over exploitation of natural resources. However, a natural phenomenon, the drought is amplified by anthropogenic activities that in its enormity influences water availability, agricultural productivity, ecosystem, groundwater storage. The Karnataka state of India is frequently affected by the drought that causes huge loss in agricultural sector and other allied sectors. Therefore, it is essential to measure the vulnerability status for the better management of natural resources in the state of Karnataka. No advanced models are being used yet to portray the drought vulnerability status. Different advanced machine learning models are effective in predicting various physical vulnerabilities. The aim of this study was to use sophisticated machine learning models to precisely define relative drought vulnerability. In that endeavour, it used two advanced machine-learning algorithms (MLAs), namely, Bagging and Artificial Neural Network (ANN) which are still not used in this field. Twenty-six meteorological and socio-economical parameters were considered to find the most drought vulnerable areas. The predisposing parameters were classified as resilience (7 parameters), sensitivity (9 parameters), and exposure (10 parameters). The researchers have produced drought vulnerability maps for overall condition, resilience, sensitivity, and exposure. The relative drought vulnerability maps (RDVMs) clearly show that 40.87%–52.03% of areas fall under very high vulnerability, which is situated in the central and eastern parts of the state. The prediction capacity of newly built models was judged with efficiency, root mean square error (RMSE), true skill statistics (TSS), Friedman and Wilcoxon rank test, and area under the curve (AUC) of receiver operating characteristic (ROC). All of them showed satisfactory results - the RMSE value of 0.32 and 0.33, TSS values of 0.82 and 0.81, and AUC values of 86.50% and 84.20% as obtained by ANN and bagging models, respectively. The produced RDVMs demonstrate the urgency of policy interventions to minimize vulnerability in prioritized areas.",
        "DOI": "10.1016/j.jclepro.2021.128073",
        "affiliation_name": "University of Gour Banga",
        "affiliation_city": "Malda",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Encouraging users in waste sorting using deep neural networks and gamification",
        "paper_author": "Delnevo G.",
        "publication": "GoodIT 2021 - Proceedings of the 2021 Conference on Information Technology for Social Good",
        "citied_by": "10",
        "cover_date": "2021-09-09",
        "Abstract": "In recent years, the focus on sustainability has grown by everyone, including policymakers, companies, and consumers. In this perspective, recycling plays an important role because it allows to reduce the amount of waste to be disposed of, at the same time reducing the need for raw materials. This paper presents ScanBage, a web application designed and developed to support users in separating waste collection. It exploits two machine learning algorithms to automatically classify garbage categories and it employs Gamification elements with the aim of increasing user involvement.",
        "DOI": "10.1145/3462203.3477056",
        "affiliation_name": "Alma Mater Studiorum Università di Bologna",
        "affiliation_city": "Bologna",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Environmental intelligence for more sustainable infrastructure investment",
        "paper_author": "Mulligan M.",
        "publication": "GoodIT 2021 - Proceedings of the 2021 Conference on Information Technology for Social Good",
        "citied_by": "5",
        "cover_date": "2021-09-09",
        "Abstract": "Intelligence is the ability to learn, understand and thus manage new or trying situations through reasoning (inferences based on facts or premises). Environmental Intelligence brings together multiple data streams (facts) from ground-based, satellite and citizen sources with cutting-edge hardware, software and analytical technology employing human reasoning and machine learning to better understand and manage the environment. The EC H2020 ReSET project (Restarting Economy in Support of Environment through Technology) funded by the European Union's Horizon 2020 FET Proactive Programme under grant agreement No 101017857, brings together environmental scientists, social scientists, informatics specialists and stakeholders from five European countries to develop state of the art investment policy support systems. These combine the best available earth observation, crowdsourced and field-monitored data with sophisticated spatial policy support systems for biophysical and social processes. Harnessing combined machine and human intelligence, we seek to to understand best-bet options for 'build back better' investments that maximise environmental, economic and employment benefits. We are working at a series of demonstration sites in Europe where 'build back better' investments are active: Thames Gateway, OxCam Arc and Strand Aldwych in UK; Carasuhat Wetlands in Romania; Castilla Leon and Rivas VaciaMadrid in Spain and Bologna in Italy. Proposed investments include urban greening and traffic management to reduce air pollution and thermal extremes (Strand Aldwych, Bologna, Rivas Vaciamadrid); Natural Flood Management (Thames Gateway, OxCam Arc, Castilla-Leon), land use zoning for low impact tourism (Carasuhat) and green-grey approaches to flood and drought management (Castilla Leon). We bring together new hardware technologies enabling low-cost, distributed, IoT environmental monitoring using the FreeStation.org platform with further developments of our widely used policy support systems CotingNature and Eco:Actuary and enhanced activity and agent-based modelling in the Metronamica modelling framework. This is to better understand current environmental conditions in the areas proposed for investment and to simulate the impact of investment alternatives (business as usual grey, blended grey-green and fully green) on environment, economy and employment in the ReSET investment policy support system. Through this work, we tackle some key challenges of operationalizing environmental intelligence discussed here: • technology as an enabler of research and innovation rather than the key focus of research • live integration of complex data streams • ensuring usability and ease of use through co-design • scalability and relevance to a range of investment types and settings • reducing costs, enabling local maintenance and ensuring accessibility and legacy",
        "DOI": "10.1145/3462203.3475916",
        "affiliation_name": "National Research and Development Institute for Marine Geology and Geoecology",
        "affiliation_city": "Bucharest",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "Smart energy trend observation",
        "paper_author": "Wei R.",
        "publication": "Advances in Sustainable Energy: Policy, Materials and Devices",
        "citied_by": "0",
        "cover_date": "2021-09-08",
        "Abstract": "Smart energy systems is a process by which energy generators and energy network operators interact and provide a comprehensive and optimized solution using a mix of on-demand fossil fuel, local stored sustainable fuels, and other renewables like photovoltaics and hydrogen in a bidirectional network. An overlay upon the smart network is the inclusion of embedded devices that monitor and report to an enterprise management console using Internet bandwidth for implementation and optimization of energy systems. Here, the load is balanced to provide constant voltage over the day using smart management artificial intelligence algorithms. Through design and operation, every facet in the energy network is optimized are addressable using the Internet of Things approach the prupose is to achieve synergy and complementarity of the subsystems, creating a whole that is greater than the subparts. This is due to the incorporation of embedded objects, business model, and system design. The latter is achieved using artificial intelligence algorithms for swarm design optimization at multiple level of integration. These inculde integration at the level of energy generation, storage, transmission, substation, station, and end user. A top layer of automation and blockchain transactional technology is added for self-correction, fault tolerance, deployment of pig-robots and aerial unmanned surveillance to create and maintain a self-aware network. Such a network would also inculde fault tolerance, machine learning, predictive and corrective of component failure. These features augment human decision-making with smart metering and billing of common tasks to business and end users enabling them to focus on their core missions.",
        "DOI": "10.1007/978-3-030-74406-9_26",
        "affiliation_name": "Emergent BioSolutions Inc.",
        "affiliation_city": "Gaithersburg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Role of Artificial Intelligence in the Management of Food Waste",
        "paper_author": "Anggraeni M.C.",
        "publication": "2021 2nd International Conference on Artificial Intelligence and Data Sciences, AiDAS 2021",
        "citied_by": "6",
        "cover_date": "2021-09-08",
        "Abstract": "Food waste is caused by a complex collection of interconnected behavior at both the supplier and customer levels. Computational and mathematical models provide various methods for simulating, diagnosing, and predicting various aspects of the dynamic food waste generation and prevention system. This paper describes three modeling methods that have been used to analyze food waste in the past. Bayesian networks and machine learning algorithms are applied to help determine how much food is discarded at the household level. Agent-Based Simulation was used to gain insight into how innovation and adoption of a particular technology can help minimize retail food waste. The first BN-ABM integrated model assesses consumer food waste levels affected by particular features and aspects, resulting in the model reaching equilibrium. Proofing that there is a need for policy interventions, including training, economic incentives, and campaigns, to obtain the resulting model transformation. These interventions are ready to be assessed by the model, but further study is needed to understand the effects of enforcing these structures on the accuracy of the BN-ABM predictive model. The second ABM model aims to determine the factors that establish the adoption of food waste reduction technology at the retail level, which is influenced by particular but not limited to economic factors, including a strong network between retailers and consumer's awareness regarding food waste reduction technology. These findings can study the effects of policy intervention regarding food waste reduction at the retail and consumer level. The third ABM model employed a general food chain network model consisting of consumers, traders, and producers to simulate the dynamic change of product flow between agents and to be able to assess the effect of agent's behavioral contrast. Resilience is measured by the ability to deal with shocks, and efficiency is the share of total food manages to be dispatched to consumers. At first glance, the simulation results seem to show a system trade-off between efficiency and resilience. Network chain structures with higher efficiency displayed more sensitivity to shocks, while networks with less efficiency show more resilience. However, there seem to be modifications in the results when applying several trading interactions and shock types. Resiliency and efficiency are affected by social aspects (trust and preference) in trading interaction between agents. An essential aspect of resilience is the agent's ability to switch links (trading partners) which shows the capability of reorganization. Insights regarding the research can be applicable when considering real-life food chain and structural reorganization to increase resilience and efficiency in meeting national food security goals.",
        "DOI": "10.1109/AiDAS53897.2021.9574167",
        "affiliation_name": "Bina Nusantara University",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Human-Centered AI using Ethical Causality and Learning Representation for Multi-Agent Deep Reinforcement Learning",
        "paper_author": "Ho J.",
        "publication": "Proceedings of the 2021 IEEE International Conference on Human-Machine Systems, ICHMS 2021",
        "citied_by": "6",
        "cover_date": "2021-09-08",
        "Abstract": "Human-Centered Computing and AI are two fields devoted to several cross-intersecting interests in the modern AI design. They consider human factors and the machine learning algorithms to enhance compatibility and reliability for human-robot interaction and cooperation. In this work, we propose a novel design concept for the challenging issues that have raised ethical dilemmas; an augmented ethical causality with successor representation for policy gradient models Human-Centered AI with environments. The proposed system leverages Human-Centered AI for using explainable knowledge to construct the ethical causality, and shows it significantly outperformed the statistical approach and baselines alone by further considering meta parametric Human-Centered ethical priorities, when compared to other approaches in the simulated game theory Deep Reinforcement Learning environments. The experimental results aim to efficiently and effectively access the cause, effect and impact of causal inference and multi-agent heterogeneity in the DRL environments for natural, general and significant causal learning representations.",
        "DOI": "10.1109/ICHMS53169.2021.9582667",
        "affiliation_name": "Institute of Information Science, Academia Sinica",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Temporal behavioural analysis of extremists on social media: A machine learning based approach",
        "paper_author": "Lutfi S.",
        "publication": "2021 6th International Conference on Smart and Sustainable Technologies, SpliTech 2021",
        "citied_by": "1",
        "cover_date": "2021-09-08",
        "Abstract": "Public opinion is of critical importance to businesses and governments. It represents the collective opinion and prevalent views about a certain topic, policy, or issue. Extreme public opinion consists of extreme views held by individuals that advocate and spread radical ideas for the purpose of radicalizing others. while the proliferation of social media gives unprecedented reach and visibility and a platform for freely expressing public opinion, social media fora can also be used for spreading extreme views, manipulating public opinions, and radicalizing others. In this work, we leverage data mining and analytics techniques to study extreme public opinion expressed using social medial. A dataset of 259, 904 tweets posted between 21/02/2016 and 01/05/2021 was collected in relation to extreme nationalism, hate speech, and supremacy. The collected data was analyzed using a variety to techniques, including sentiment analysis, named entity recognition, social circle analysis, and opinion leaders' identification, and results related to an American politician and an American right-wing activist were presented. The results obtained are very promising and open the door to the ability to monitor the evolution of extreme views and public opinion online.",
        "DOI": "10.23919/SpliTech52315.2021.9566446",
        "affiliation_name": "Zayed University",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Machine Learning-based Cache Optimization on MEC Platform",
        "paper_author": "Akbar W.",
        "publication": "2021 22nd Asia-Pacific Network Operations and Management Symposium, APNOMS 2021",
        "citied_by": "0",
        "cover_date": "2021-09-08",
        "Abstract": "The amount of data generation is exponentially increasing over the past decade due to the widespread use of multimedia applications and social media platforms. Advanced real-time applications such as virtual reality, augmented reality, automated vehicles, smart homes, and intelligent traffic control systems have increased the demand for low latency. Many of these applications are delay-sensitive and put enormous stress on the core network to respond in real-time. CDN (Content Delivery Network) brings storage service to end-users proximity to provide low latency, high data throughput, and low traffic pressure to handle the problems mentioned above. Due to the limited storage capacity of the edge, only in-demand content should cache. Therefore, to optimally utilized the cache space, an efficient content caching and replacement policy is needed. To this end, in this paper, we propose an optimal content replacement algorithm. In this algorithm, a video request pattern is first generated based on a publicly available dataset. After that, a machine learning model is trained on cache logs data. As a result, the predicted video is deleted from the edge to make space for new videos. A real-time testbed is built on KOREN to check the performance of our model. The results based on MAE, MSE, and R-2 show that our model performs well in real-time scenarios.",
        "DOI": "10.23919/APNOMS52696.2021.9562623",
        "affiliation_name": "Jeju National University",
        "affiliation_city": "Jeju",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A Macrocause Classification Model for Violent Crime Analysis in the Field of Public Safety Based on Machine Learning Techniques",
        "paper_author": "De Vasconcelos Dos Santos Junior R.",
        "publication": "2021 IEEE International Smart Cities Conference, ISC2 2021",
        "citied_by": "2",
        "cover_date": "2021-09-07",
        "Abstract": "In developing effective public security policies, two aspects are essential: intelligence and information. In this context, the classification of Macrocauses can help governments better understand some aspects of public security related to the analysis of violent crimes in a state. In the Brazilian state of Rio Grande do Norte (RN), these analyses are currently done by analyzing raw data done by an expert without any specific auxiliary system, known as traditional approaches. It is a time-consuming task, and different experts may have different views on the same case. With this in mind, in this work, we intend to assist these criminal experts by providing a predictive model that classifies the Macrocauses of crimes into a set of pre-defined types to guide the work of the experts and, as a consequence, to speed up the analysis and management processes. Thus, a feature preprocessing was performed in which three different classification techniques are analyzed. The results show that when using XGBoost, the model accuracy reached 0.932378, which is considered excellent for this application.",
        "DOI": "10.1109/ISC253183.2021.9562842",
        "affiliation_name": "Universidade Federal do Rio Grande do Norte",
        "affiliation_city": "Natal",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Mosaic: Modeling Safety Index in Crowd by Detecting Face Masks against COVID-19 and beyond",
        "paper_author": "Almalki K.J.",
        "publication": "2021 IEEE International Smart Cities Conference, ISC2 2021",
        "citied_by": "0",
        "cover_date": "2021-09-07",
        "Abstract": "In addition to rapid vaccination, predicting possible trajectories of the COVID-19 pandemic is critical to health-care-related policy decisions and infrastructure planning. Growing evidence shows that face masks and social distancing can considerably reduce the spread of respiratory viruses like COVID-19. However, the current pandemic trajectory predictions take overly simplified policy input rather than actual observations of face masks and social distancing practices in a crowd. Thus, it is crucial to monitor and understand the extent of masking practices and assess the safety level in a scalable manner. This paper proposes a novel face masking detection system for Modeling Safety Index in Crowd (Mosaic), a Machine Learning (ML)-based approach for detecting masking in a crowd by building new dense mode crowd mask datasets. Mosaic detects, counts, and classifies the crowd's masking condition and calculates spatiotemporal Safety Index (SI) values for each community instead of detecting individual masking cases. SI data can be shared or published to calculate the area-based SI maps (as opt-in data) for assisting effective policy decisions and relief plans against COVID-19. The experimental results show that Mosaic detects various conditions and types of masking states and calculates SI values of a crowd effectively. This paper proposes a novel face masking detection system for Modeling Safety Index in Crowd (Mosaic), a Machine Learning (ML)-based approach for detecting masking in a crowd by building new dense mode crowd mask datasets. Mosaic detects, counts, and classifies the crowd's masking condition and calculates spatiotemporal Safety Index (SI) values for each community instead of detecting individual masking cases. SI data can be shared or published to calculate the area-based SI maps (as opt-in data) for assisting effective policy decisions and relief plans against COVID-19. The experimental results show that Mosaic detects various conditions and types of masking states and calculates SI values of a crowd effectively.",
        "DOI": "10.1109/ISC253183.2021.9562953",
        "affiliation_name": "Saudi Electronic University",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Recommendations for the Development of Socioeconomically-Situated and Clinically-Relevant Neuroimaging Models of Pain",
        "paper_author": "Reddan M.C.",
        "publication": "Frontiers in Neurology",
        "citied_by": "1",
        "cover_date": "2021-09-07",
        "Abstract": "Pain is a complex, multidimensional experience that emerges from interactions among sensory, affective, and cognitive processes in the brain. Neuroimaging allows us to identify these component processes and model how they combine to instantiate the pain experience. However, the clinical impact of pain neuroimaging models has been limited by inadequate population sampling – young healthy college students are not representative of chronic pain patients. The biopsychosocial approach to pain management situates a person's pain within the diverse socioeconomic environments they live in. To increase the clinical relevance of pain neuroimaging models, a three-fold biopsychosocial approach to neuroimaging biomarker development is recommended. The first level calls for the development of diagnostic biomarkers via the standard population-based (nomothetic) approach with an emphasis on diverse sampling. The second level calls for the development of treatment-relevant models via a constrained person-based (idiographic) approach tailored to unique individuals. The third level calls for the development of prevention-relevant models via a novel society-based (social epidemiologic) approach that combines survey and neuroimaging data to predict chronic pain risk based on one's socioeconomic conditions. The recommendations in this article address how we can leverage pain's complexity in service of the patient and society by modeling not just individuals and populations, but also the socioeconomic structures that shape any individual's expectations of threat, safety, and resource availability.",
        "DOI": "10.3389/fneur.2021.700833",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Tracking Air Pollution in China: Near Real-Time PM<inf>2.5</inf>Retrievals from Multisource Data Fusion",
        "paper_author": "Geng G.",
        "publication": "Environmental Science and Technology",
        "citied_by": "302",
        "cover_date": "2021-09-07",
        "Abstract": "Air pollution has altered the Earth’s radiation balance, disturbed the ecosystem, and increased human morbidity and mortality. Accordingly, a full-coverage high-resolution air pollutant data set with timely updates and historical long-term records is essential to support both research and environmental management. Here, for the first time, we develop a near real-time air pollutant database known as Tracking Air Pollution in China (TAP,http://tapdata.org.cn/) that combines information from multiple data sources, including ground observations, satellite aerosol optical depth (AOD), operational chemical transport model simulations, and other ancillary data such as meteorological fields, land use data, population, and elevation. Daily full-coverage PM2.5data at a spatial resolution of 10 km is our first near real-time product. The TAP PM2.5is estimated based on a two-stage machine learning model coupled with the synthetic minority oversampling technique and a tree-based gap-filling method. Our model has an averaged out-of-bag cross-validationR2of 0.83 for different years, which is comparable to those of other studies, but improves its performance at high pollution levels and fills the gaps in missing AOD on daily scale. The full coverage and near real-time updates of the daily PM2.5data allow us to track the day-to-day variations in PM2.5concentrations over China in a timely manner. The long-term records of PM2.5data since 2000 will also support policy assessments and health impact studies. The TAP PM2.5data are publicly available through our website for sharing with the research and policy communities.",
        "DOI": "10.1021/acs.est.1c01863",
        "affiliation_name": "State Environmental Protection Key Laboratory of Sources and Control of Air Pollution Complex",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning Application in Water Quality Using Satellite Data",
        "paper_author": "Hassan N.",
        "publication": "IOP Conference Series: Earth and Environmental Science",
        "citied_by": "30",
        "cover_date": "2021-09-06",
        "Abstract": "Monitoring water quality is a critical aspect of environmental sustainability. Poor water quality has an impact not just on aquatic life but also on the ecosystem. The purpose of this systematic review is to identify peer-reviewed literature on the effectiveness of applying machine learning (ML) methodologies to estimate water quality parameters with satellite data. The data was gathered using the Scopus, Web of Science, and IEEE citation databases. Related articles were extracted, selected, and evaluated using advanced keyword search and the PRISMA approach. The bibliographic information from publications written in journals during the previous two decades were collected. Publications that applied ML to water quality parameter retrieval with a focus on the application of satellite data were identified for further systematic review. A search query of 1796 papers identified 113 eligible studies. Popular ML models application were artificial neural network (ANN), random forest (RF), support vector machines (SVM), regression, cubist, genetic programming (GP) and decision tree (DT). Common water quality parameters extracted were chlorophyll-a (Chl-a), temperature, salinity, colored dissolved organic matter (CDOM), suspended solids and turbidity. According to the systematic analysis, ML can be successfully extended to water quality monitoring, allowing researchers to forecast and learn from natural processes in the environment, as well as assess human impacts on an ecosystem. These efforts will also help with restoration programs to ensure that environmental policy guidelines are followed.",
        "DOI": "10.1088/1755-1315/842/1/012018",
        "affiliation_name": "Universiti Malaysia Terengganu",
        "affiliation_city": "Kuala Terengganu",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning",
        "paper_author": "Mellia M.",
        "publication": "Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning",
        "citied_by": "2",
        "cover_date": "2021-09-03",
        "Abstract": "Discover the impact that new technologies are having on communication systems with this up-to-date and one-stop resource Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning delivers a comprehensive overview of the impact of artificial intelligence (AI) and machine learning (ML) on service and network management. Beginning with a fulsome description of ML and AI, the book moves on to discuss management models, architectures, and frameworks. The authors also explore how AI and ML can be used in service management functions like the generation of workload profiles, service provisioning, and more. The book includes a handpicked selection of applications and case studies, as well as a treatment of emerging technologies the authors predict could have a significant impact on network and service management in the future. Statistical analysis and data mining are also discussed, particularly with respect to how they allow for an improvement of the management and security of IT systems and networks. Readers will also enjoy topics like: A thorough introduction to network and service management, machine learning, and artificial intelligence An exploration of artificial intelligence and machine learning for management models, including autonomic management, policy-based management, intent based-management, and network virtualization-based management Discussions of AI and ML for architectures and frameworks, including cloud -systems, software defined networks, 5G and 6G networks, and Edge/Fog networks An examination of AI and ML for service management, including the automatic -generation of workload profiles using unsupervised learning Perfect for information and communications technology educators, Communication Networks and Service Management in the Era of Artificial Intelligence and Machine Learning will also earn a place in the libraries of engineers and professionals who seek a structured reference on how the emergence of artificial intelligence and machine learning techniques is affecting service and network management.",
        "DOI": "10.1002/9781119675525",
        "affiliation_name": "Dalhousie University",
        "affiliation_city": "Halifax",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Impacts and Implications of COVID-19: An Analytical and Empirical Study",
        "paper_author": "Sharma A.",
        "publication": "Impacts and Implications of COVID-19: An Analytical and Empirical Study",
        "citied_by": "0",
        "cover_date": "2021-09-03",
        "Abstract": "Impacts and Implications of COVID-19: An Analytical and Empirical Study describes the most recent research developments regarding COVID-19. This book includes a wide range of interdisciplinary submissions that address the latest findings regarding a wide variety of psychological, social, managerial, and technological issues for fighting COVID-19. Chapter One discusses how machine learning applies to prediction, forecasting, screening, contact tracing, treatment, medication and the drug or vaccine invention process in connection with COVID-19. Chapter Two deals with immunomodulatory therapy for clinical management of COVID-19 patients. Chapter Three describes the importance of social distancing and the development of a tool to detect social distancing. Chapter Four discusses the impact of COVID-19 on the education sector, and Chapter Five focuses on the impacts of COVID-19 on employment, e-commerce, and e-pharmacies. Chapter Six gives an insight into the policies regarding COVID-19 in India, and Chapter Seven compares vaccine candidates based on their status in trial phases, route of administration, dosage, efficacy, and safety. Chapter Eight explores how the pandemic has impacted human communication and relationships, as people have been forced to interact in the digital space rather than the physical one. Chapter Nine describes the urgent need to devise sustainable and effective strategies to mitigate the problems relating to shortages of labor and equipment in the agricultural sector due to the pandemic. Finally, Chapter Ten describes the role of physical therapy in the recovery of COVID-19 patients.",
        "DOI": "10.52305/WZTU8416",
        "affiliation_name": "Lovely Professional University",
        "affiliation_city": "Phagwara",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Model-based reinforcement learning for router port queue configurations",
        "paper_author": "Kattepur A.",
        "publication": "Intelligent and Converged Networks",
        "citied_by": "6",
        "cover_date": "2021-09-01",
        "Abstract": "Fifth-generation (5G) systems have brought about new challenges toward ensuring Quality of Service (QoS) in differentiated services. This includes low latency applications, scalable machine-to-machine communication, and enhanced mobile broadband connectivity. In order to satisfy these requirements, the concept of network slicing has been introduced to generate slices of the network with specific characteristics. In order to meet the requirements of network slices, routers and switches must be effectively configured to provide priority queue provisioning, resource contention management and adaptation. Configuring routers from vendors, such as Ericsson, Cisco, and Juniper, have traditionally been an expert-driven process with static rules for individual flows, which are prone to sub optimal configurations with varying traffic conditions. In this paper, we model the internal ingress and egress queues within routers via a queuing model. The effects of changing queue configuration with respect to priority, weights, flow limits, and packet drops are studied in detail. This is used to train a model-based Reinforcement Learning (RL) algorithm to generate optimal policies for flow prioritization, fairness, and congestion control. The efficacy of the RL policy output is demonstrated over scenarios involving ingress queue traffic policing, egress queue traffic shaping, and one-hop router coordinated traffic conditioning. This is evaluated over a real application use case, wherein a statically configured router proved sub optimal toward desired QoS requirements. Such automated configuration of routers and switches will be critical for multiple 5G deployments with varying flow requirements and traffic patterns.",
        "DOI": "10.23919/ICN.2021.0016",
        "affiliation_name": "Telefonaktiebolaget LM Ericsson",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "CULTURAL HERITAGE AND DIGITAL TOOLS: THE ROCK INTEROPERABLE PLATFORM",
        "paper_author": "Turilazzi B.",
        "publication": "International Journal of Environmental Impacts",
        "citied_by": "10",
        "cover_date": "2021-09-01",
        "Abstract": "The digitisation of urban cultural heritage (CH) is recognised within EU (European Union) policies as an opportunity to make CH a driver for urban transformation towards a sustainable and inclusive future. Various digital platforms are emerging as tools not only to store, retrieve, compare and process different kind of data related to CH for the use of urban planners and administrators, but also as participative tools for distributed decision-making. The increasing integration between the physical and digital realm through various digital instruments such as the Internet of things, virtual and augmented reality, machine learning and natural language processing, has led designers to conceptualise the necessity of merging different smart city dashboards and platforms into an integrated system known as the urban digital twin (DW). This task can be made possible only through the construction of a shared ontology of the city, which allows the interoperability of different data systems. The DWs, originally developed in mechanical and process engineering, allow to construct a digital model of a physical object or process, to monitor its real-time performance, to perform maintenance tasks and to test the effects of planned changes. However, when extending the notion of the DW to complex cultural and social entities such as cities, it is important to consider also issues of inclusivity and citizen participation. How can the DW be conceptualised not only as a tool of technological control or narrative, but as an instrument to empower not only institutions but also citizens? The experience gathered in the construction of the ROCK platform and its participatory ontology, developed within the Horizon 2020 (H2020) funded project ROCK (GA 730280), becomes an important precedent in this task.",
        "DOI": "10.2495/EI-V4-N3-276-288",
        "affiliation_name": "Alma Mater Studiorum Università di Bologna",
        "affiliation_city": "Bologna",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Control Systems Cyber Security Reference Architecture (RA) for Critical Infrastructure: Healthcare and Hospital Vertical Example",
        "paper_author": "Scalco A.",
        "publication": "Journal of Critical Infrastructure Policy",
        "citied_by": "1",
        "cover_date": "2021-09-01",
        "Abstract": "A reference architecture (RA) provides a common frame of reference with a common vocabulary, reusable designs, and principles that may be applied to future architectures. It can promote re-use of best practices, improve interoperability, and improve awareness of a system under development of the same mindset. The next version of the Department of Defense (DoD) Chief Information Officer (CIO) Cyber Security Reference Architecture (CSRA) will include an appendix for control systems. It provides a frame of reference for cybersecurity implementations based on generalizations of common principles that can provide a starting point for an or-ganization’s architecture effort, inform decision-making, suggest governance, and help define future policy decisions for control sys-tems. The appendix is based on the outcome of the MOSIACS Joint Capability Technology Demonstration (JCTD), which provides the initial cyber defensive capability framework for integrations of Commercial-Off-The-Shelf (COTS) and Government-Off-The-Shelf (GOTS) components to form a control system cyber defensive solution. The MOSAICS capability was successfully demonstrated in the energy sector critical infrastructure vertical on a power system in August 2021. Its applicability embodied delivery methods for technologies in other essential infrastructure sectors, repeatable playbooks for automated Courses of Action (COA), best practices, and templates for cyber security requirements for control systems. The advantages of the RA are to enable better decision-making and policy-making support about cybersecurity for control systems. This paper demonstrates the RA used in the Healthcare and Public Health sector’s critical infrastructure vertical to evaluate concepts such as Zero Trust (ZT) and Defense-in-Depth (DiD) architecture principles related to policymaking.",
        "DOI": "10.18278/jcip.2.2.7",
        "affiliation_name": "Walter Scott, Jr. College of Engineering",
        "affiliation_city": "Fort Collins",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Welfare effect of international migration on the left-behind in Ghana: Evidence from machine learning",
        "paper_author": "Martey E.",
        "publication": "Migration Studies",
        "citied_by": "1",
        "cover_date": "2021-09-01",
        "Abstract": "This article examines the effect of international migration on household expenditure, labor outcomes, and poverty on the left-behind household members in Ghana using nationally representative data. The study contributes to the literature in terms of the methodology employed to reinforce the welfare effect of international migration in a developing country like Ghana. The results suggest that international migration increases household expenditures, which is largely driven by investments relative to expenditure on consumption goods. In addition, transfer of remittances to left-behind household members by migrants results in a reduction of their weekly working hours in the labor market and modestly reduces household poverty. The findings of the study suggest that the gains from international migration can be consolidated with favorable policy environment that ensures flexible conditions and terms of borrowing from banks to finance the initial expenditure related to migration. In addition, reduction in remittance transfer charges is likely to increase transfer through the formal systems, which can be captured and used for future planning.",
        "DOI": "10.1093/migration/mnaa025",
        "affiliation_name": "College of Humanities, University of Ghana",
        "affiliation_city": "Accra",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Anchoring and Asymmetric Information in the Real Estate Market: A Machine Learning Approach",
        "paper_author": "Cheung K.S.",
        "publication": "Journal of Risk and Financial Management",
        "citied_by": "10",
        "cover_date": "2021-09-01",
        "Abstract": "Conventional wisdom suggests that non-local buyers usually pay a premium for home purchases. While the standard contract theory predicts that non-local buyers may pay such a price premium because of the higher cost of gathering information, behavioral economists argue that the premium is due to buyer anchoring biases in relation to the information. Both theories support such a price premium proposition, but the empirical evidence is mixed. In this study, we revisit this conundrum and put forward a critical test of these two alternative hypotheses using a large-scale housing transaction dataset from Hong Kong. A novel machine-learning algorithm with the latest technique in natural language processing where applicable to multi-languages is developed for identifying non-local Mainland Chinese buyers and sellers. Using the repeat-sales method that avoids omitted variable biases, non-local buyers (sellers) are found to buy (sell) at a higher (lower) price than their local counterparts. Taking advantage of a policy change in transaction tax specific to non-local buyers as a quasi-experiment and utilizing the local buyers as counterfactuals, we found that the non-local price premium switches to a discount after the policy intervention. The result implies that the hypothesis of anchoring biases is dominant.",
        "DOI": "10.3390/jrfm14090423",
        "affiliation_name": "Freddie Mac",
        "affiliation_city": "McLean",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Enhancing skyhook for semi-active suspension control via machine learning",
        "paper_author": "Savaia G.",
        "publication": "IFAC Journal of Systems and Control",
        "citied_by": "17",
        "cover_date": "2021-09-01",
        "Abstract": "Semi-active control is the most employed technology for electronic suspension systems. The damping can be regulated to trade-off comfort and handling. Due to its success in industrial applications, semi-active control design has been extensively investigated in literature mainly from a model-based perspective. In this contribution, the authors propose a novel control strategy derived via a sequential learning framework, which selects the most significant feedback measurements for semi-active control and learns the optimal policy from data. As opposed to most of the contributions based on deep-learning approaches, the output of the proposed methodology is a control algorithm consisting of few parameters, which can be easily ported and calibrated on a real vehicle. Experimental validation on a sports-car shows that the proposed algorithm is superior in damping the body resonance with respect to the state-of-the-art skyhook algorithm. Indeed, the learned control policy consists of an augmentation of skyhook.",
        "DOI": "10.1016/j.ifacsc.2021.100161",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Part 1: The Wider Considerations in Translating Heart Failure Guidelines",
        "paper_author": "Iyngkaran P.",
        "publication": "Current Cardiology Reviews",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "Congestive Heart Failure (CHF) is an emerging epidemic. Within one generation, the medical community has learned much of CHF syndromes. It has two distinct mechanisms, systolic and diastolic abnormalities, to account for the common CHF presentation. It is complex as it challenges the available health care services, resource, and funding models in providing an equitable service across the health continuum. Despite the improvement in many cardiovascular diseases, some CHF outcomes like readmissions and costs have increased. The reinvigoration of evi-dence-based medicine, the development of health services models of care, and standardisation of disease processes with taxonomies have also occurred within the same time span. These processes, however, need to be linked with health policy as presented in white papers. In this paper, we ex-plore achieving optimal CHF guideline-recommended outcomes as the science approaches real-world translation.",
        "DOI": "10.2174/1573403X16666210108104945",
        "affiliation_name": "The University of Sydney School of Medicine",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A QoS Optimization Technique with Deep Reinforcement Learning in SDN-Based IoT",
        "paper_author": "Moslehi M.",
        "publication": "Majlesi Journal of Electrical Engineering",
        "citied_by": "5",
        "cover_date": "2021-09-01",
        "Abstract": "In recent years, exponential growth of communication devices in Internet of Things (IoT) has become an emerging technology which facilitates heterogeneous devices to connect with each other in heterogeneous networks. This communication requires different level of Quality-of-Service (QoS) and policies depending on the device type and location. To provide a specific level of QoS, we can utilize emerging new technological concepts in IoT infrastructure, Software-Defined Network (SDN) and, machine learning algorithms. We use deep reinforcement learning in the process of resource management and allocation in control plane. We present an algorithm that aims to optimize resource allocation. Simulation results show that the proposed algorithm improved network performances in terms of QoS parameters, including delay and throughput compared to Random and Round Robin methods. Compared to similar methods, the performance of the proposed method is also as good as the fuzzy and predictive methods.",
        "DOI": "10.52547/mjee.15.3.105",
        "affiliation_name": "University of Kashan",
        "affiliation_city": "Kashan",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "A Mechanism Design and Learning Approach for Revenue Maximization on Cloud Dynamic Spot Markets",
        "paper_author": "Tsiourvas A.",
        "publication": "IEEE International Conference on Cloud Computing, CLOUD",
        "citied_by": "1",
        "cover_date": "2021-09-01",
        "Abstract": "Modern large-scale computing deployments consist of complex elastic applications running over machine clusters. A current trend adopted by providers is to set unused virtual machines, or else spot instances, in low prices to take advantage of spare capacity. In this paper we present a group of efficient allocation and pricing policies that can be used by vendors for their spot price mechanisms. We model the procedure of acquiring virtual machines as a truthful knapsack auction and we deploy dynamic allocation and pricing rules that achieve near-optimal revenue and social welfare. As the problem is NP-hard our solutions are based on approximate algorithms. First, we propose two solutions that do not use prior knowledge. Then, we enhance them with three learning algorithms. We evaluate them with simulations on the Google Cluster dataset and we benchmark them against the Uniform Price, the Optimal Single Price and the Ex-CORE mechanisms. Our proposed dynamic mechanism is robust, achieves revenue up to 89% of the Optimal Single Price auction, and computes the allocation in polynomial time making our contribution computationally tractable in realtime scenarios.",
        "DOI": "10.1109/CLOUD53861.2021.00057",
        "affiliation_name": "University of Thessaly",
        "affiliation_city": "Volos",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Land use land cover mapping using advanced machine learning classifiers",
        "paper_author": "Jamali A.",
        "publication": "Ekologia Bratislava",
        "citied_by": "7",
        "cover_date": "2021-09-01",
        "Abstract": "Due to the recent climate changes such as floods and droughts, there is a need for Land Use Land Cover (LULC) mapping to monitor environmental changes that have effects on ecology, policy management, health and disaster management. As such, in this study, two well-known machine learning classifiers, namely, Support Vector Machine (SVM) and Random Forest (RF), are used for land cover mapping. In addition, two advanced deep learning algorithms, namely, the GAMLP and FSMLP, that are based on the Multi-layer Perceptron (MLP) function are developed in MATLAB programming language. The GAMLP uses a Genetic Algorithm (GA) to optimise parameters of the MLP function and, on the other hand, the FSMLP uses a derivative-free function for optimisation of the MLP function parameters. Three different scenarios using Landsat-8 imagery with spatial resolutions of 30 and 15 m are defined to investigate the effects of data pre-processing on the final predicted LULC map. Results based on the statistical indices, including overall accuracy (OA) and kappa index, show that the developed MLP-based algorithms have relatively high accuracies with higher than 98% correct classification. Besides the statistical indices, final LULC maps are interpreted visually where the GAMLP and FSMLP give the best results for the pre-processed Landsat-8 imagery with a spatial resolution of 15 m, but they have the worst outcomes for the unprocessed Landsat-8 imagery compared to SVM and RF classifiers visually and statistically.",
        "DOI": "10.2478/eko-2021-0031",
        "affiliation_name": "Karabük Üniversitesi",
        "affiliation_city": "Karabuk",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Design of a Structured Hypercube Network Chip Topology Model for Energy Efficiency in Wireless Sensor Network Using Machine Learning",
        "paper_author": "Gupta N.",
        "publication": "SN Computer Science",
        "citied_by": "12",
        "cover_date": "2021-09-01",
        "Abstract": "Network on chips (NoCs) 3D design expansion is continuously changing to produce energy-efficient NoCs. In this production, the major requirement is to have continuous monitoring with great effort of engineering process and policies which tries to incorporate the machine learning techniques for producing EE-NoCs (energy-efficient NoCs). The learning is a method of neural network system. This thought process of machine learning art in producing EE-NoCs resulted in better production. The internal architecture framed is Power Gate Deployment, voltage instant changeovers, and scaling in the frequenting simultaneous reduction in power. Multiprocessor architecture and platform have been introduced to extend the applicability of Moore’s law. The solution for the multiprocessor system architecture is application-specific NoC architecture which are emerging as a leading technology. NoC can be useful in addressing many requirements such as inter-process communication, bandwidth, deadlock avoidance and routing structure. With power now the first order design constraint early stage estimation of NoC power, performance, and area has become important. The topology, switching and routing techniques are necessary in the NoC architecture design. This paper focuses on the n-dimension hypercube network on chip topological structure. It is used for more efficient performance and reliability for data communication. Therefore, in this paper, we are going to go through a bunch of different concepts, such as routing deadlock, and the router pipeline.",
        "DOI": "10.1007/s42979-021-00766-7",
        "affiliation_name": "Teerthanker Mahaveer University, Moradabad",
        "affiliation_city": "Moradabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Support vector machines and k-means to build implementation areas of bundling hubs",
        "paper_author": "Ouadi J.E.",
        "publication": "European Transport - Trasporti Europei",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "City transportation has three basic components that create the essential environment for its functioning and the social welfare namely infrastructure, operational assets, and management policies. The key focus of this article is on understanding long-term distribution of transport demand in order to build bundling networks. To achieve this aim, we provide a hybrid machine-learning approach using a combination of several clustering and forecasting algorithms that are considered efficient given the key performance indicators obtained. This approach involves combining two types of algorithms: clustering and prediction algorithms. Based on simulated benchmarks, results indicated that the clustering phase is still appropriate using the k-means algorithm. To improve the k-means results, we measured 30 validation indices to estimate the number of clusters. In so doing, not only does it want to validate the clusters but also to identify the optimal. To evaluate forecast accuracy in the demand prediction phase, we used the standard key performance indicators, namely MSE, RMSE, MAPE and R . The SVM algorithm has been judged as the most efficient prediction algorithm based on average values of the obtained metrics.",
        "DOI": "10.48295/ET.2021.83.5",
        "affiliation_name": "Hassan II University of Casablanca",
        "affiliation_city": "Casablanca",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Double/debiased machine learning for logistic partially linear model",
        "paper_author": "Liu M.",
        "publication": "Econometrics Journal",
        "citied_by": "9",
        "cover_date": "2021-09-01",
        "Abstract": "We propose double/debiased machine learning approaches to infer a parametric component of a logistic partially linear model. Our framework is based on a Neyman orthogonal score equation consisting of two nuisance models for the nonparametric component of the logistic model and conditional mean of the exposure with the control group. To estimate the nuisance models, we separately consider the use of high dimensional (HD) sparse regression and (nonparametric) machine learning (ML) methods. In the HD case, we derive certain moment equations to calibrate the first order bias of the nuisance models, which preserves the model double robustness property. In the ML case, we handle the nonlinearity of the logit link through a novel and easy-to-implement 'full model refitting' procedure. We evaluate our methods through simulation and apply them in assessing the effect of the emergency contraceptive pill on early gestation and new births based on a 2008 policy reform in Chile.",
        "DOI": "10.1093/ectj/utab019",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An invitation control policy for proactive service systems: Balancing efficiency, value, and service level",
        "paper_author": "Yom-Tov G.B.",
        "publication": "Manufacturing and Service Operations Management",
        "citied_by": "6",
        "cover_date": "2021-09-01",
        "Abstract": "Problem definition: We study the problem of designing a dynamic invitation policy for proactive service systems with finite customer patience under scarce capacity. In such systems, prior knowledge regarding customer value or importance is used to decide whether the company should offer service or not. Academic/practical relevance: Proactive service systems are becoming more popular, as data availability and machine-learning techniques are developed to forecast customer needs. However, very little is known about the efficient use of such tools to promote and manage service systems. Methodology: We use fluid approximation and the Filippov convex method to analyze system dynamics and develop approximations for important performance measures. Results: We show that whereas prioritizing customers in descending order of their r-μ ranking (as long as there are idle servers in the system) is optimal on the fluid level, refinements are necessary in the presence of abandonment on the stochastic level. We propose an r-μ-N policy to account for customer patience. Managerial implications: Our policy can be used to promote service effectivenes and allow decision makers the means to trade off service level against costs in such systems explicitly. Using a case study of a transportation service provider, we show that such a policy can triple revenue compared with random arrivals (nonproactive policy).",
        "DOI": "10.1287/msom.2019.0852",
        "affiliation_name": "Amazon.com, Inc.",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "American Heart Association Precision Medicine Platform Addresses Challenges in Data Sharing",
        "paper_author": "Stevens L.M.",
        "publication": "Circulation: Cardiovascular Quality and Outcomes",
        "citied_by": "8",
        "cover_date": "2021-09-01",
        "Abstract": "AHA’s PMP has enabled secure delivery of data through agile workspaces that scale with the high-performance compute needs of researchers and allow flexibility in the ready-to-run analysis tools. By listening and partnering with end users, we have overcome many of the hurdles facing researchers today including outdated data governance policies, insufficient data documentation, and inability of cloud-based environments to scale up resources for performance and allow researchers to personalize their workspaces with their own tools and pipelines.",
        "DOI": "10.1161/CIRCOUTCOMES.121.007949",
        "affiliation_name": "Vanderbilt University Medical Center",
        "affiliation_city": "Nashville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Disease control as an optimization problem",
        "paper_author": "Navascués M.",
        "publication": "PLoS ONE",
        "citied_by": "4",
        "cover_date": "2021-09-01",
        "Abstract": "In the context of epidemiology, policies for disease control are often devised through a mixture of intuition and brute-force, whereby the set of logically conceivable policies is narrowed down to a small family described by a few parameters, following which linearization or grid search is used to identify the optimal policy within the set. This scheme runs the risk of leaving out more complex (and perhaps counter-intuitive) policies for disease control that could tackle the disease more efficiently. In this article, we use techniques from convex optimization theory and machine learning to conduct optimizations over disease policies described by hundreds of parameters. In contrast to past approaches for policy optimization based on control theory, our framework can deal with arbitrary uncertainties on the initial conditions and model parameters controlling the spread of the disease, and stochastic models. In addition, our methods allow for optimization over policies which remain constant over weekly periods, specified by either continuous or discrete (e.g.: Lockdown on/off) government measures. We illustrate our approach by minimizing the total time required to eradicate COVID- 19 within the Susceptible-Exposed-Infected-Recovered (SEIR) model proposed by Kissler et al. (March, 2020).",
        "DOI": "10.1371/journal.pone.0257958",
        "affiliation_name": "Universität Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Option-Critic Algorithm Based on Sub-Goal Quantity Optimization",
        "paper_author": "Liu C.H.",
        "publication": "Jisuanji Xuebao/Chinese Journal of Computers",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "Reinforcement learning has been extensively studied as a branch of machine learning, where an agent keeps interacting with the environment with the goal of getting maximal long-term return, making it prominent in areas such as control and optimal scheduling. Deep reinforcement learning (DRL) is designed to handle large-scale high-dimensional data such as video and image by extracting the abstract representation, and learning an optima1l policy through reinforcement learning component. Deep reinforcement learning has become a research hotspot in artificial intelligence and a lot of algorithms have been developed. For example, deep Q Network (DQN) is one of the most famous models in deep reinforcement learning, which is based on convolutional neural network (CNN) and Q-learning algorithm and has been used to learn policy in complex environments with high dimensional inputs. However, the DQN failed to perform well in sparse reward environment or with large-scale state space. Hierarchical reinforcement learning was introduced to solve the aforementioned problems where the initial problem space is decomposed into several sub-problem spaces, and the initial large problem is solving by meaning of dealing with each sub-problem individually. However, hierarchical reinforcement learning tends to be effective in tasks with discrete state/action space. The idea of hierarchical deep reinforcement learning, by combining hierarchical reinforcement learning with deep learning, is similar to that of hierarchical reinforcement learning, where it solves sub-problems through the neural network. Time abstraction is an important concept in hierarchical reinforcement learning, and the sub-goal is the key for producing time abstraction. Time abstraction, as one of the most promising areas of hierarchical reinforcement learning, requires the notion of sub-goal as the prerequisite. At present, however, sub-goals or the number of sub-goals must be manually specified, which is in short of automation and generalization across different scenarios. To solve the problem, we propose Option-Critic algorithm based on Sub-goal Quantity Optimization (OC-SQO) that enables the agent to explore the environment, decide the initial sub-goal number, identify sub-goals, and derive the corresponding abstraction through policy gradient. The abstraction is denoted as a triple consisting of the initial state, the internal policy and the terminate function, by which the agent optimizes the policy. The advantage is that the OC-SQO requires no particular initial state, sub-goals or parameters; moreover, it doesn't require internal reward signal since the abstraction is produced during the learning process as mentioned. Based on the above process, OC-SQO reduces a lot of manual intervention compared with the OC method, and achieves better results with only a small amount of manual intervention. The experiment results indicate the effectiveness of OC-SQO algorithm.",
        "DOI": "10.11897/SP.J.1016.2021.01922",
        "affiliation_name": "Soochow University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A review on cyber security named entity recognition",
        "paper_author": "Gao C.",
        "publication": "Frontiers of Information Technology and Electronic Engineering",
        "citied_by": "23",
        "cover_date": "2021-09-01",
        "Abstract": "With the rapid development of Internet technology and the advent of the era of big data, more and more cyber security texts are provided on the Internet. These texts include not only security concepts, incidents, tools, guidelines, and policies, but also risk management approaches, best practices, assurances, technologies, and more. Through the integration of large-scale, heterogeneous, unstructured cyber security information, the identification and classification of cyber security entities can help handle cyber security issues. Due to the complexity and diversity of texts in the cyber security domain, it is difficult to identify security entities in the cyber security domain using the traditional named entity recognition (NER) methods. This paper describes various approaches and techniques for NER in this domain, including the rule-based approach, dictionary-based approach, and machine learning based approach, and discusses the problems faced by NER research in this domain, such as conjunction and disjunction, non-standardized naming convention, abbreviation, and massive nesting. Three future directions of NER in cyber security are proposed: (1) application of unsupervised or semi-supervised technology; (2) development of a more comprehensive cyber security ontology; (3) development of a more comprehensive deep learning model.",
        "DOI": "10.1631/FITEE.2000286",
        "affiliation_name": "Yunnan University",
        "affiliation_city": "Kunming",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Enabling Machine Learning with Service Function Chaining for Security Enhancement at 5G Edges",
        "paper_author": "Feng B.",
        "publication": "IEEE Network",
        "citied_by": "31",
        "cover_date": "2021-09-01",
        "Abstract": "With massive sorts of terminals, devices, and machines connecting to 5G, a tremendous surge of data makes cyber-security a pressing issue, and conventional countermeasures are facing unprecedented challenges. Recently, with the rise of ML (Machine Learning) and SDN/NFV-based (Software-Defined Networks/Network Functions Virtualization) SFC (Service Function Chaining) techniques, how to leverage them for security enhancement in MEC (Multi-Access/Mobile Edge Computing) has received much attention. Hence, in this article, we first propose an elastic framework to integrate ML with virtualized SFC, aiming at smart and efficient provision of different services at MEC. Then, we propose an ML-based anomaly detection algorithm used as a kind of service policy for SFC classifiers, which guides the latter for quick traffic classification and subsequent redirections of attack flows. Finally, we build a corresponding prototype system and evaluate the performance of the proposed algorithm through extensive experiments. Related results have confirmed the feasibility and advantages of the proposed framework and algorithm.",
        "DOI": "10.1109/MNET.100.2000338",
        "affiliation_name": "Guangzhou University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Assessing patient-perceived hospital service quality and sentiment in malaysian public hospitals using machine learning and facebook reviews",
        "paper_author": "Rahim A.I.A.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "20",
        "cover_date": "2021-09-01",
        "Abstract": "Social media is emerging as a new avenue for hospitals and patients to solicit input on the quality of care. However, social media data is unstructured and enormous in volume. Moreover, no empirical research on the use of social media data and perceived hospital quality of care based on patient online reviews has been performed in Malaysia. The purpose of this study was to investigate the determinants of positive sentiment expressed in hospital Facebook reviews in Malaysia, as well as the association between hospital accreditation and sentiments expressed in Facebook reviews. From 2017 to 2019, we retrieved comments from 48 official public hospitals’ Facebook pages. We used machine learning to build a sentiment analyzer and service quality (SERVQUAL) classifier that automatically classifies the sentiment and SERVQUAL dimensions. We utilized logistic regression analysis to determine our goals. We evaluated a total of 1852 reviews and our machine learning sentiment analyzer detected 72.1% of positive reviews and 27.9% of negative reviews. We classified 240 reviews as tangible, 1257 reviews as trustworthy, 125 reviews as responsive, 356 reviews as assurance, and 1174 reviews as empathy using our machine learning SERVQUAL classifier. After adjusting for hospital characteristics, all SERVQUAL dimensions except Tangible were associated with positive sentiment. However, no significant relationship between hospital accreditation and online sentiment was discovered. Facebook reviews powered by machine learning algorithms pro-vide valuable, real-time data that may be missed by traditional hospital quality assessments. Addi-tionally, online patient reviews offer a hitherto untapped indication of quality that may benefit all healthcare stakeholders. Our results confirm prior studies and support the use of Facebook reviews as an adjunct method for assessing the quality of hospital services in Malaysia.",
        "DOI": "10.3390/ijerph18189912",
        "affiliation_name": "Universiti Sains Malaysia, Health Campus",
        "affiliation_city": "Kubang Kerian",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Exploring and predicting the knowledge development in the field of energy storage: Evidence from the emerging startup landscape",
        "paper_author": "Song C.H.",
        "publication": "Energies",
        "citied_by": "11",
        "cover_date": "2021-09-01",
        "Abstract": "The distribution and deployment of energy storage systems on a larger scale will be a key element of successfully managing the sustainable energy transition by balancing the power generation capability and load demand. In this context, it is crucial for researchers and policy makers to understand the underlying knowledge structure and key interaction dynamics that could shape the future innovation trajectory. A data-driven approach is used to analyze the evolving characteristics of knowledge dynamics from static, dynamic and future-oriented perspective. To this end, a network analysis was performed to determine the influence of individual knowledge areas. Subsequently, an interaction trend analysis based on emergence indicators was conducted to highlight the promising relations. Finally, the formation of new knowledge interactions is predicted using a link prediction technique. The findings show that ensuring the energy efficiency is a key issue that has persisted over time. In future, knowledge areas related to digital technologies are expected to gain relevance and lead the transformative change. The derived insights can assist R&D managers and policy makers to design more targeted and informed strategic initiatives to foster the adoption of energy storage solutions.",
        "DOI": "10.3390/en14185822",
        "affiliation_name": "Woosong University",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Quality analysis of youtube videos presenting pelvic floor exercises after prostatectomy surgery",
        "paper_author": "Rodriguez-Rodriguez A.M.",
        "publication": "Journal of Personalized Medicine",
        "citied_by": "10",
        "cover_date": "2021-09-01",
        "Abstract": "Background: Prostate cancer (PC) is a major cause of disease and mortality among men. Surgical treatment involving the removal of the prostate may result in temporary or permanent erectile dysfunction (ED) and urinary incontinence (UI), with considerable impact on quality of life. Pelvic floor muscle training (PFMT) is one of the recommended techniques for the prevention, treat-ment, and rehabilitation of postoperative complications. The aim of this observational study was to assess the quality of YouTube videos—accessible to any patient—related to exercises after prosta-tectomy surgery. Methods: A systematic search was performed on YouTube on 24 September 2020. One hundred and fifty videos were selected and analyzed. Two statistical analyses were conducted based on machine-learning techniques, and videos were classified as ‘Relevant’ or ‘Non-Relevant’ using Principal Component Analysis (PCA) models. Two reviewers conducted independent anal-yses. Inter-observer agreement and individual correlations of video data were evaluated with the Intraclass Correlation Coefficient (ICC). Information quality, reliability, and accuracy were measured using the DISCERN Scale and Global Quality Score (GQS), while video popularity was evaluated using the Video Power Index (VPI). Results: DISCERN scored a mean of 3.35 and GQS scored 3.38. Average number of views was 124,354, mean duration was 14:42 min, mean days online was 1777, mean view ratio was 138.30, mean Likes was 1082, mean Dislikes was 68.58, and mean VPI was 92.28. Conclusions: The quality of the videos available on YouTube regarding the recommended pelvic floor exercises in PC surgery, according to the scores obtained, is High. Educational and health institutions, health professionals, government health authorities, and policy makers need to be involved in the proper development of policies to improve the information available on the web in order to have a positive impact on the healthy behavior of the population.",
        "DOI": "10.3390/jpm11090920",
        "affiliation_name": "Universidad de Sevilla",
        "affiliation_city": "Sevilla",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "COVID-19 and the flu: Data simulations and computational modelling to guide public health strategies",
        "paper_author": "Tunaligil V.",
        "publication": "Family Practice",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "Background: Pandemics threaten lives and economies. This article addresses the global threat of the anticipated overlap of COVID-19 with seasonal-influenza. Objectives: Scientific evidence based on simulation methodology is presented to reveal the impact of a dual outbreak, with scenarios intended for propagation analysis. This article aims at researchers, clinicians of family medicine, general practice and policy-makers worldwide. The implications for the clinical practice of primary health care are discussed. Current research is an effort to explore new directions in epidemiology and health services delivery. Methods: Projections consisted of machine learning, dynamic modelling algorithms and whole simulations. Input data consisted of global indicators of infectious diseases. Four simulations were run for '20% versus 60% flu-vaccinated populations' and '10 versus 20 personal contacts'. Outputs consisted of numerical values and mathematical graphs. Outputs consisted of numbers for 'never infected', 'vaccinated', 'infected/recovered', 'symptomatic/asymptomatic' and 'deceased' individuals. Peaks, percentages, R0, durations are reported. Results: The best-case scenario was one with a higher flu-vaccination rate and fewer contacts. The reverse generated the worst outcomes, likely to disrupt the provision of vital community services. Both measures were proven effective; however, results demonstrated that 'increasing flu-vaccination rates' is a more powerful strategy than 'limiting social contacts'. Conclusions: Results support two affordable preventive measures: (i) to globally increase influenza-vaccination rates, (ii) to limit the number of personal contacts during outbreaks. The authors endorse changing practices and research incentives towards multidisciplinary collaborations. The urgency of the situation is a call for international health policy to promote interdisciplinary modern technologies in public health engineering.",
        "DOI": "10.1093/fampra/cmab058",
        "affiliation_name": "Turkish Airlines",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "In the September 2021 Issue of the Quarterly",
        "paper_author": "Cohen A.B.",
        "publication": "Milbank Quarterly",
        "citied_by": "1",
        "cover_date": "2021-09-01",
        "Abstract": "NA",
        "DOI": "10.1111/1468-0009.12541",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "The role of citizen science and deep learning in camera trapping",
        "paper_author": "Adam M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "6",
        "cover_date": "2021-09-01",
        "Abstract": "Camera traps are increasingly one of the fundamental pillars of environmental monitoring and management. Even outside the scientific community, thousands of camera traps in the hands of citizens may offer valuable data on terrestrial vertebrate fauna, bycatch data in particular, when guided according to already employed standards. This provides a promising setting for Citizen Science initiatives. Here, we suggest a possible pathway for isolated observations to be aggregated into a single database that respects the existing standards (with a proposed extension). Our approach aims to show a new perspective and to update the recent progress in engaging the enthusiasm of citizen scientists and in including machine learning processes into image classification in camera trap research. This approach (combining machine learning and the input from citizen scientists) may significantly assist in streamlining the processing of camera trap data while simultaneously raising public environmental awareness. We have thus developed a conceptual framework and analytical concept for a web-based camera trap database, incorporating the above-mentioned aspects that respect a combination of the roles of experts’ and citizens’ evaluations, the way of training a neural network and adding a taxon complexity index. This initiative could well serve scientists and the general public, as well as assisting public authorities to efficiently set spatially and temporarily well-targeted conservation policies.",
        "DOI": "10.3390/su131810287",
        "affiliation_name": "Ústav Geoniky, Akademie Ved Ceské Republiky",
        "affiliation_city": "Ostrava-Poruba",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Autonomous drifting using reinforcement learning",
        "paper_author": "Orgován L.",
        "publication": "Periodica Polytechnica Transportation Engineering",
        "citied_by": "9",
        "cover_date": "2021-09-01",
        "Abstract": "Autonomous vehicles or self-driving cars are prevalent nowadays, many vehicle manufacturers, and other tech companies are trying to develop autonomous vehicles. One major goal of the self-driving algorithms is to perform manoeuvres safely, even when some anomaly arises. To solve these kinds of complex issues, Artificial Intelligence and Machine Learning methods are used. One of these motion planning problems is when the tires lose their grip on the road, an autonomous vehicle should handle this situation. Thus the paper provides an Autonomous Drifting algorithm using Reinforcement Learning. The algorithm is based on a model-free learning algorithm, Twin Delayed Deep Deterministic Policy Gradients (TD3). The model is trained on six different tracks in a simulator, which is developed specifically for autonomous driving systems; namely CARLA.",
        "DOI": "10.3311/PPTR.18581",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "Meta-learner for amharic sentiment classification",
        "paper_author": "Neshir G.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "6",
        "cover_date": "2021-09-01",
        "Abstract": "The emergence of the World Wide Web facilitates the growth of user-generated texts in less-resourced languages. Sentiment analysis of these texts may serve as a key performance indicator of the quality of services delivered by companies and government institutions. The presence of user-generated texts is an opportunity for assisting managers and policy-makers. These texts are used to improve performance and increase the level of customers’ satisfaction. Because of this potential, sentiment analysis has been widely researched in the past few years. A plethora of approaches and tools have been developed—albeit predominantly for well-resourced languages such as English. Resources for less-resourced languages such as, in this paper, Amharic, are much less developed. As a result, it requires cost-effective approaches and massive amounts of annotated training data, calling for different approaches to be applied. This research investigates the performance of a combination of heterogeneous machine learning algorithms (base learners such as SVM, RF, and NB). These models in the framework are fused by a meta-learner (in this case, logistic regression) for Amharic sentiment classification. An annotated corpus is provided for evaluation of the classification frame-work. The proposed stacked approach applying SMOTE on TF-IDF characters (1,7) grams features has achieved an accuracy of 90%. The overall results of the meta-learner (i.e., stack ensemble) have revealed performance rise over the base learners with TF-IDF character n-grams.",
        "DOI": "10.3390/app11188489",
        "affiliation_name": "Addis Ababa Science and Technology University",
        "affiliation_city": "Addis Ababa",
        "affiliation_country": "Ethiopia"
    },
    {
        "paper_title": "Reinforcement learning for precision oncology",
        "paper_author": "Eckardt J.N.",
        "publication": "Cancers",
        "citied_by": "38",
        "cover_date": "2021-09-01",
        "Abstract": "Precision oncology is grounded in the increasing understanding of genetic and molecular mechanisms that underly malignant disease and offer different treatment pathways for the indi-vidual patient. The growing complexity of medical data has led to the implementation of machine learning techniques that are vastly applied for risk assessment and outcome prediction using either supervised or unsupervised learning. Still largely overlooked is reinforcement learning (RL) that addresses sequential tasks by exploring the underlying dynamics of an environment and shaping it by taking actions in order to maximize cumulative rewards over time, thereby achieving optimal long-term outcomes. Recent breakthroughs in RL demonstrated remarkable results in gameplay and autonomous driving, often achieving human-like or even superhuman performance. While this type of machine learning holds the potential to become a helpful decision support tool, it comes with a set of distinctive challenges that need to be addressed to ensure applicability, validity and safety. In this review, we highlight recent advances of RL focusing on studies in oncology and point out current challenges and pitfalls that need to be accounted for in future studies in order to successfully develop RL-based decision support systems for precision oncology.",
        "DOI": "10.3390/cancers13184624",
        "affiliation_name": "Universitätsklinikum Carl Gustav Carus Dresden",
        "affiliation_city": "Dresden",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Digital citizen science for responding to covid-19 crisis: Experiences from Iran",
        "paper_author": "Vahidi H.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "13",
        "cover_date": "2021-09-01",
        "Abstract": "The Coronavirus Disease 2019 (COVID-19) pandemic has so far been the most severe global public health emergency in this century. Generally, citizen science can provide a complement to authoritative scientific practices for responding to this highly complex biological threat and its adverse consequences. Several citizen science projects have been designed and operationalized for responding to COVID-19 in Iran since the infection began. However, these projects have mostly been overlooked in the existing literature on citizen science. This research sheds light on the most significant online citizen science projects to respond to the COVID-19 crisis in Iran. Furthermore, it highlights some of the opportunities and challenges associated with the strengths and weaknesses of these projects. Moreover, this study captures and discusses some considerable insights and lessons learned from the failures and successes of these projects and provides solutions to overcome some recognized challenges and weaknesses of these projects. The outcomes of this synthesis provide potentially helpful directions for current and future citizen science projects—particularly those aiming to respond to biological disasters such as the COVID-19 pandemic.",
        "DOI": "10.3390/ijerph18189666",
        "affiliation_name": "Keio University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "An innovative machine learning approach to predict the dietary fiber content of packaged foods",
        "paper_author": "Davies T.",
        "publication": "Nutrients",
        "citied_by": "21",
        "cover_date": "2021-09-01",
        "Abstract": "Underconsumption of dietary fiber is prevalent worldwide and is associated with multiple adverse health conditions. Despite the importance of fiber, the labeling of fiber content on packaged foods and beverages is voluntary in most countries, making it challenging for consumers and policy makers to monitor fiber consumption. Here, we developed a machine learning approach for automated and systematic prediction of fiber content using nutrient information commonly available on packaged products. An Australian packaged food dataset with known fiber content information was divided into training (n = 8986) and test datasets (n = 2455). Utilization of a k-nearest neighbors machine learning algorithm explained a greater proportion of variance in fiber content than an existing manual fiber prediction approach (R2 = 0.84 vs. R2 = 0.68). Our findings highlight the opportunity to use machine learning to efficiently predict the fiber content of packaged products on a large scale.",
        "DOI": "10.3390/nu13093195",
        "affiliation_name": "Institutionen för folkhälso- och vårdvetenskap",
        "affiliation_city": "Uppsala",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Heterogeneous effects of health insurance on rural children’s health in China: A causal machine learning approach",
        "paper_author": "Chen H.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "8",
        "cover_date": "2021-09-01",
        "Abstract": "This paper investigates the impact of Urban and Rural Resident Basic Medical Insurance (URRBMI) on the health of preschool and school-age children in rural China using data from the 2018 wave of the China Family Panel Studies (CFPS). We employ the propensity score matching approach and causal forest to evaluate impacts. Results show that the URRBMI has significantly improved the health status of preschool children. However, the health improvement of school-age children by URRBMI is only limited to obese children, and this effect is not significant. In addition, this paper identifies important variables related to heterogeneity through the causal forest and evaluates the heterogeneity of the impact of URRBMI on the health of two types of children. For preschool children, we find disadvantaged mothers (i.e., with lower wealth, lower educated, or in rural areas) benefit more from the URRBMI. No significant heterogeneity is found for the school-age children. Our study demonstrates the power of causal forest to uncover the heterogeneity in policy evaluation, hence providing policymakers with valuable information for policy design.",
        "DOI": "10.3390/ijerph18189616",
        "affiliation_name": "Central University of Finance and Economics",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Fine-grained large-scale vulnerable communities mapping via satellite imagery and population census using deep learning",
        "paper_author": "Salas J.",
        "publication": "Remote Sensing",
        "citied_by": "6",
        "cover_date": "2021-09-01",
        "Abstract": "One of the challenges in the fight against poverty is the precise localization and assessment of vulnerable communities’ sprawl. The characterization of vulnerability is traditionally accomplished using nationwide census exercises, a burdensome process that requires field visits by trained personnel. Unfortunately, most countrywide censuses exercises are conducted only sporadically, making it difficult to track the short-term effect of policies to reduce poverty. This paper introduces a definition of vulnerability following UN-Habitat criteria, assesses different CNN machine learning architectures, and establishes a mapping between satellite images and survey data. Starting with the information corresponding to the 2,178,508 residential blocks recorded in the 2010 Mexican census and multispectral Landsat-7 images, multiple CNN architectures are explored. The best performance is obtained with EfficientNet-B3 achieving an area under the ROC and Precision-Recall curves of 0.9421 and 0.9457, respectively. This article shows that publicly available information, in the form of census data and satellite images, along with standard CNN architectures, may be employed as a stepping stone for the countrywide characterization of vulnerability at the residential block level.",
        "DOI": "10.3390/rs13183603",
        "affiliation_name": "Instituto Politécnico Nacional",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Limits of compartmental models and new opportunities for machine learning: A case study to forecast the second wave of covid-19 hospitalizations in Lombardy, Italy",
        "paper_author": "Gatto A.",
        "publication": "Informatics",
        "citied_by": "8",
        "cover_date": "2021-09-01",
        "Abstract": "Compartmental models have long been used in epidemiological studies for predicting disease spread. However, a major issue when using compartmental mathematical models concerns the time-invariant formulation of hyper-parameters that prevent the model from following the evolution over time of the epidemiological phenomenon under investigation. In order to cope with this problem, the present work suggests an alternative hybrid approach based on Machine Learning that avoids recalculation of hyper-parameters and only uses an initial set. This study shows that the proposed hybrid approach makes it possible to correct the expected loss of accuracy observed in the compartmental model when the considered time horizon increases. As a case study, a basic compartmental model has been designed and tested to forecast COVID-19 hospitalizations during the first and the second pandemic waves in Lombardy, Italy. The model is based on an extended formulation of the contact function that allows modelling of the trend of personal contacts throughout the reference period. Moreover, the scenario analysis proposed in this work can help policy-makers select the most appropriate containment measures to reduce hospitalizations and relieve pressure on the health system, but also to limit any negative impact on the economic and social systems.",
        "DOI": "10.3390/informatics8030057",
        "affiliation_name": "Fondazione Centro Euro-Mediterraneo sui Cambiamenti Climatici",
        "affiliation_city": "Lecce",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Input use efficiency management for paddy production systems in india: A machine learning approach",
        "paper_author": "Bhoi P.B.",
        "publication": "Agriculture (Switzerland)",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "This research illustrates the technical efficiency of the pan‐India paddy cultivation status obtained through a stochastic frontier approach. The results suggest that the mean technical efficiency varies from 0.64 in Gujarat to 0.95 in Odisha. Inputs like human labor, mechanical labor, fertilizer, irrigation and insecticide were found to determine the yield in paddy cultivation across India (except for Chhattisgarh). Inefficiency in the paddy production in Punjab, Bihar, West Bengal, Andhra Pradesh, Tamil Nadu, Kerala, Assam, Gujarat and Odisha in 2016–2017 was caused by technical inefficiency due to poor input management, as suggested by the significant σ2U and σ2v values of the stochastic frontier model. In addition, most of the farm groups in the study operated in the high‐efficiency group (80–90% technical efficiency). No specific pattern of input use can be visualized through descriptive measures to give any specific policy implication. Thus, machine learning algorithms based on the input parameters were tested on the data in order to predict the farmers’ efficiency class for individual states. The highest mean accuracy of 0.80 for the models of all of the states was achieved in random forest models. Among the various states of India, the best random forest prediction model based on accuracy was fitted to the input data of Bihar (0.91), followed by Uttar Pradesh (0.89), Andhra Pradesh (0.88), Assam (0.88) and West Bengal (0.86). Thus, the study provides a technique for the classification and prediction of a farmer’s efficiency group from the levels of input use in paddy cultivation for each state in the study. The study uses the DES input dataset to classify and predict the efficiency group of the farmer, as other machine learning models in agriculture have used mostly satellite, spectral imaging and soil property data to detect disease, weeds and crops.",
        "DOI": "10.3390/agriculture11090837",
        "affiliation_name": "ICAR - Indian Institute of Millets Research, Hyderabad",
        "affiliation_city": "Hyderabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Personalized dynamic pricing with machine learning: High-dimensional features and heterogeneous elasticity",
        "paper_author": "Ban G.Y.",
        "publication": "Management Science",
        "citied_by": "82",
        "cover_date": "2021-09-01",
        "Abstract": "We consider a seller who can dynamically adjust the price of a product at the individual customer level, by utilizing information about customers’ characteristics encoded as a d-dimensional feature vector. We assume a personalized demand model, parameters of which depend on s out of the d features. The seller initially does not know the relationship between the customer features and the product demand but learns this through sales observations over a selling horizon of T periods. We prove that the seller’s expected regret, that is, the revenue loss against a clairvoyant who knows the underlying demand relationship, is at least of order s√- T under any admissible policy. We then design a near-optimal pricing policy for a semiclairvoyant seller (who knows which s of the d features are in the demand model) who achieves an expected regret of order s√- T log T. We extend this policy to a more realistic setting, where the seller does not know the true demand predictors, and show that this policy has an expected regret of order s√- T (log d + log T), which is also near-optimal. Finally, we test our theory on simulated data and on a data set from an online auto loan company in the United States. On both data sets, our experimentation-based pricing policy is superior to intuitive and/or widely-practiced customized pricing methods, such as myopic pricing and segment-then-optimize policies. Furthermore, our policy improves upon the loan company’s historical pricing decisions by 47% in expected revenue over a six-month period.",
        "DOI": "10.1287/mnsc.2020.3680",
        "affiliation_name": "Fuqua School of Business",
        "affiliation_city": "Durham",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Interdependencies of urban behavioral dynamics whilst covid-19 spread",
        "paper_author": "Ko S.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "0",
        "cover_date": "2021-09-01",
        "Abstract": "The outbreak of novel coronavirus disease 2019 (COVID-19) caused many consequences in almost all aspects of our lives. The pandemic dramatically changes people’s behavior in urban areas and transportation systems. Many studies have attempted to analyze spatial behavior and to present analysis data visually in the process of spreading COVID-19 and provided limited temporal and geographical perspectives. In this article, the behavioral changes in urban areas and transportation systems were analyzed throughout the U.S.A. while the COVID-19 spread over 2020. Specifically, assuming the characteristics are not repetitive over time, temporal phases were proposed where spikes or surges of confirmed cases are noticed. The interdependencies between population, mobility, and additional behavioral data were explored at the county level by adopting the machine learning approaches. As a result, interdependencies with the COVID-19 cases were identified differently by phase. It appeared to have a solid relationship with population size at all phases. Furthermore, it revealed racial characteristics, residential types, and vehicle mile traveled ratio in the urban and rural areas had a relationship with confirmed cases with different importance by phase. Although other short-term analyses were also conducted in terms of the COVID-19, this article is considered more legitimate as it provides dynamic relationships of urban elements by Phase at the county level. Moreover, it is expected to be encouraging and beneficial in terms of phase-driven transportation policy preparedness against a possible forthcoming pandemic crisis.",
        "DOI": "10.3390/su13179910",
        "affiliation_name": "Incheon National University",
        "affiliation_city": "Incheon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Machine learning deployment for arms dynamics pattern recognition in Southeast Asia region",
        "paper_author": "Indra Z.",
        "publication": "Indonesian Journal of Electrical Engineering and Computer Science",
        "citied_by": "0",
        "cover_date": "2021-09-01",
        "Abstract": "Finding the most significant determinant variable of arms dynamic is highly required due to strategic policies formulations and power mapping for academics and policy makers. Machine learning is still new or under-discussed among the study of politics and international relations. Existing literature have much focus on using advanced quantitative methods by applying various types of regression analysis. This study analyzed the arms dynamic in Southeast Asia countries along with its some strategic partners such as United States, China, Russia, South Korea, and Japan by using 'Decision Tree' of machine learning algorithm. This study conducted a machine learning analysis on 55 variable items which is classified into 8 classes of variables videlicet defense budget, arms trade exports, arms trade imports, political posture, economic posture, security posture and defense priority, national capability, and direct contact,. The results suggest three findings: (1) state who perceives maritime as strategic drivers and forces will seek more power for its maritime defense posture which is translated to defense budget, (2) big size countries tend to be an arms exporter country, and (3) state's energy dependence often leads to a higher volume of arms transfers between countries.",
        "DOI": "10.11591/ijeecs.v23.i3.pp1654-1662",
        "affiliation_name": "Universitas Muhammadiyah Yogyakarta",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Effectiveness of green infrastructure location based on a social well-being index",
        "paper_author": "Ko S.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "11",
        "cover_date": "2021-09-01",
        "Abstract": "Urban Green Infrastructure (GI) provides promising opportunities to address today’s pressing issues in cities, mainly resulting from uncurbed urbanization. GI has the potential to make significant contributions to make cities more sustainable by satisfying the growing appetite for higher standards of living as well as helping cities adapt to extreme climate events. To leverage the potentials of GI, this article aims to investigate the effectiveness of GI that can enhance social welfare benefits in the triple-bottom line of urban sustainability. First, publicly available data sets representing social demographic, climate, and built environmental elements are collected and indexed to normalize its different scales by the elements, which is termed as the “Social Well-being Index.” Second, a random forest regressor was applied to identify the impacts of variables on the indexed scores by region. As a result, both the Seoul and Gyeonggi-do models found the most significant relationship with the type of GI to prevent pollutants and disasters, followed by GI types to conserve and improve the environment in Seoul and GI types to serve activity spaces in Gyeonggi-do. Furthermore, variables such as population, number of pollutants, and employment rate in Seoul were found significant and employment rate, population, and air pollution were significant in Gyeonggi-do. Finally, a scenario analysis is conducted to investigate the impacts of the overall index score with additional GI facilitation according to the model’s findings. This article can provide effective strategies for implementing policies about GI by considering regional conditions. The analytical processes in this article can provide useful insights into preparing effective ecological and environmental improvement policies accordingly.",
        "DOI": "10.3390/su13179620",
        "affiliation_name": "Incheon National University",
        "affiliation_city": "Incheon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Diagnosing hospital bacteraemia in the framework of predictive, preventive and personalised medicine using electronic health records and machine learning classifiers",
        "paper_author": "Garnica O.",
        "publication": "EPMA Journal",
        "citied_by": "14",
        "cover_date": "2021-09-01",
        "Abstract": "Background: The bacteraemia prediction is relevant because sepsis is one of the most important causes of morbidity and mortality. Bacteraemia prognosis primarily depends on a rapid diagnosis. The bacteraemia prediction would shorten up to 6 days the diagnosis, and, in conjunction with individual patient variables, should be considered to start the early administration of personalised antibiotic treatment and medical services, the election of specific diagnostic techniques and the determination of additional treatments, such as surgery, that would prevent subsequent complications. Machine learning techniques could help physicians make these informed decisions by predicting bacteraemia using the data already available in electronic hospital records. Objective: This study presents the application of machine learning techniques to these records to predict the blood culture’s outcome, which would reduce the lag in starting a personalised antibiotic treatment and the medical costs associated with erroneous treatments due to conservative assumptions about blood culture outcomes. Methods: Six supervised classifiers were created using three machine learning techniques, Support Vector Machine, Random Forest and K-Nearest Neighbours, on the electronic health records of hospital patients. The best approach to handle missing data was chosen and, for each machine learning technique, two classification models were created: the first uses the features known at the time of blood extraction, whereas the second uses four extra features revealed during the blood culture. Results: The six classifiers were trained and tested using a dataset of 4357 patients with 117 features per patient. The models obtain predictions that, for the best case, are up to a state-of-the-art accuracy of 85.9%, a sensitivity of 87.4% and an AUC of 0.93. Conclusions: Our results provide cutting-edge metrics of interest in predictive medical models with values that exceed the medical practice threshold and previous results in the literature using classical modelling techniques in specific types of bacteraemia. Additionally, the consistency of results is reasserted because the three classifiers’ importance ranking shows similar features that coincide with those that physicians use in their manual heuristics. Therefore, the efficacy of these machine learning techniques confirms their viability to assist in the aims of predictive and personalised medicine once the disease presents bacteraemia-compatible symptoms and to assist in improving the healthcare economy.",
        "DOI": "10.1007/s13167-021-00252-3",
        "affiliation_name": "Universidad Complutense de Madrid",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Applying Machine Learning in Self-adaptive Systems",
        "paper_author": "Gheibi O.",
        "publication": "ACM Transactions on Autonomous and Adaptive Systems",
        "citied_by": "92",
        "cover_date": "2021-09-01",
        "Abstract": "Recently, we have been witnessing a rapid increase in the use of machine learning techniques in self-adaptive systems. Machine learning has been used for a variety of reasons, ranging from learning a model of the environment of a system during operation to filtering large sets of possible configurations before analyzing them. While a body of work on the use of machine learning in self-adaptive systems exists, there is currently no systematic overview of this area. Such an overview is important for researchers to understand the state of the art and direct future research efforts. This article reports the results of a systematic literature review that aims at providing such an overview. We focus on self-adaptive systems that are based on a traditional Monitor-Analyze-Plan-Execute (MAPE)-based feedback loop. The research questions are centered on the problems that motivate the use of machine learning in self-adaptive systems, the key engineering aspects of learning in self-adaptation, and open challenges in this area. The search resulted in 6,709 papers, of which 109 were retained for data collection. Analysis of the collected data shows that machine learning is mostly used for updating adaptation rules and policies to improve system qualities, and managing resources to better balance qualities and resources. These problems are primarily solved using supervised and interactive learning with classification, regression, and reinforcement learning as the dominant methods. Surprisingly, unsupervised learning that naturally fits automation is only applied in a small number of studies. Key open challenges in this area include the performance of learning, managing the effects of learning, and dealing with more complex types of goals. From the insights derived from this systematic literature review, we outline an initial design process for applying machine learning in self-adaptive systems that are based on MAPE feedback loops.",
        "DOI": "10.1145/3469440",
        "affiliation_name": "KU Leuven",
        "affiliation_city": "Leuven",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Ensemble learning based on policy optimization neural networks for capability assessment",
        "paper_author": "Zhang F.",
        "publication": "Sensors",
        "citied_by": "4",
        "cover_date": "2021-09-01",
        "Abstract": "Capability assessment plays a crucial role in the demonstration and construction of equipment. To improve the accuracy and stability of capability assessment, we study the neural network learning algorithms in the field of capability assessment and index sensitivity. Aiming at the problem of overfitting and parameter optimization in neural network learning, the paper proposes an improved machine learning algorithm—the Ensemble Learning Based on Policy Optimization Neural Networks (ELPONN) with the policy optimization and ensemble learning. This algorithm presents an optimized neural network learning algorithm through different strategies evolution, and builds an ensemble learning model of multi-intelligent algorithms to assess the capability and analyze the sensitivity of the indexes. Through the assessment of capabilities, the algorithm effectively avoids parameter optimization from entering the minimum point in performance to improve the accuracy of equipment capability assessment, which is significantly better than previous neural network assessment methods. The experimental results show that the mean relative error is 4.10%, which is better than BP, GABP, and early stopping. The ELPONN algorithm has better accuracy and stability performance, and meets the requirements of capability assessment.",
        "DOI": "10.3390/s21175802",
        "affiliation_name": "Aviation University of Air Force",
        "affiliation_city": "Changchun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Assessing consumer buy and pay preferences for labeled food products with statistical and machine learning methods",
        "paper_author": "Shen Y.",
        "publication": "Journal of Food Protection",
        "citied_by": "7",
        "cover_date": "2021-09-01",
        "Abstract": "Food labeling is one approach to encourage safe, healthy, and sustainable dietary practices. Consumer buy and pay preferences for specially labeled food products (e.g., U.S. Department of Agriculture organic, raised without antibiotics, and locally raised) may promote the adoption of associated production practices by food producers. Thus, it is important to understand how consumer buy and pay preferences for specially labeled products vary with their demographics, food-relevant habits, and foodborne disease perceptions. Using both conventional statistical and novel machine learning models, this study analyzed Michigan State University Environmental Science and Policy Program annual survey data (2019) to characterize consumer buy and pay preferences regarding eight labels related to food production practices. Older consumer age was significantly associated with lower consumer willingness to pay more for labeled products. Participants who prefer to shop in nonconventional grocery stores were more willing to buy and pay more for labeled products. Our machine learning models provide a new approach for analyzing food safety and labeling survey data and produced adequate average prediction accuracy scores for all eight labels. The label \"raised without antibiotics\"had the highest average prediction accuracy for consumer willingness to buy. Thus, the machine learning models may be used to analyze food survey data and help develop strategies for promoting healthy food production practices.",
        "DOI": "10.4315/JFP-20-486",
        "affiliation_name": "College of Agriculture &amp; Natural Resources",
        "affiliation_city": "East Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application of multivariate time series cluster analysis to regional socioeconomic indicators of municipalities",
        "paper_author": "Gružauskas V.",
        "publication": "Real Estate Management and Valuation",
        "citied_by": "5",
        "cover_date": "2021-09-01",
        "Abstract": "The socio-economic development of municipalities is defined by a set of indicators in a period of interest and can be analyzed as a multivariate time series. It is important to know which municipalities have similar socio-economic development trends when recommendations for policy makers are provided or datasets for real estate and insurance price evaluations are expanded. Usually, key indicators are derived from expert experience, however this publication implements a statistical approach to identify key trends. Unsupervised machine learning was performed by employing K-means clusterization and principal component analysis for a dataset of multivariate time series. After 100 runs, the result with minimal summing error was analyzed as the final clusterization. The dataset represented various socio-economic indicators in municipalities of Lithuania in the period from 2006 to 2018. The significant differences were noticed for the indicators of municipalities in the cluster which contained the 4 largest cities of Lithuania, and another one containing 3 districts of the 3 largest cities. A robust approach is proposed in this article, when identifying socio-economic differences between regions where real estate is allocated. For example, the evaluated distance matrix can be used for adjustment coefficients when applying the comparative method for real estate valuation.",
        "DOI": "10.2478/remav-2021-0020",
        "affiliation_name": "Kaunas University of Technology",
        "affiliation_city": "Kaunas",
        "affiliation_country": "Lithuania"
    },
    {
        "paper_title": "The potential of data driven approaches for quantifying hydrological extremes",
        "paper_author": "Hauswirth S.M.",
        "publication": "Advances in Water Resources",
        "citied_by": "35",
        "cover_date": "2021-09-01",
        "Abstract": "Recent droughts in Europe have shown that national water systems are facing increasing challenges when dealing with drought impacts. Especially the Netherlands has seen an increasing need to adapt their water management to improve preparedness for future drought events. Ideally, the necessary information needed for operational water management decisions should be readily available ahead of time and/or computed flexibly and efficiently to ensure sufficient time to evaluate the various management actions. In this study, we show that in addition to physically based hydrological models, the upcoming and promising trend of incorporating machine learning (ML) in hydrology can provide the basis for future efforts in supporting national operational water management by providing the needed information efficiently and with the required accuracy. As a precursor for their use in a forecasting system, we assessed the ability of five different data driven methods to simulate hydrological variables at a national-scale. We developed a unified workflow where we use limited information on hydro-meteorological variables and general water management policies to simulate historic timeseries of discharge, groundwater levels, surface water levels and surface water temperatures. We find that all ML methods, ranging from very simple to more complex ones, showed a generally good performance for stations and target levels which are closely linked to the input data and location (e.g. stations along main river network). For downstream stations and small rivers, the Random Forest method outperforms the other methods both for discharge and surface water levels. For surface water temperature no location dependency was observed and for groundwater levels, all methods were performing comparable with most stations ranging in nRMSE 0.2-0.3. Generally, the best performances were reached by the more advanced Random Forest and LSTM methods, which was also seen when simulating high and low flow events. High flow events were slightly better captured than low flow events but overall simulating extreme events based on a simple input data set remains challenging. Specific training sets, including event related information and additional input variables, could like improve future assessments. Including the feature importance of the methods allowed us to detect how and where water management influence played an important role. The addition of information on water management in the ML routines increases overall performance, although limited. We conclude that ML and other data driven approaches have potential in predicting different hydrological variables. We were able to capture and incorporate water management aspects in our analysis, creating a base for future experiments where scenario analysis might reveal ML based mitigation strategies. The combination of limited input data requirement and short computation times makes this new framework suitable for forecasting purposes.",
        "DOI": "10.1016/j.advwatres.2021.104017",
        "affiliation_name": "Deltares",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "A systematic literature review on obesity: Understanding the causes &amp; consequences of obesity and reviewing various machine learning approaches used to predict obesity",
        "paper_author": "Safaei M.",
        "publication": "Computers in Biology and Medicine",
        "citied_by": "329",
        "cover_date": "2021-09-01",
        "Abstract": "Obesity is considered a principal public health concern and ranked as the fifth foremost reason for death globally. Overweight and obesity are one of the main lifestyle illnesses that leads to further health concerns and contributes to numerous chronic diseases, including cancers, diabetes, metabolic syndrome, and cardiovascular diseases. The World Health Organization also predicted that 30% of death in the world will be initiated with lifestyle diseases in 2030 and can be stopped through the suitable identification and addressing of associated risk factors and behavioral involvement policies. Thus, detecting and diagnosing obesity as early as possible is crucial. Therefore, the machine learning approach is a promising solution to early predictions of obesity and the risk of overweight because it can offer quick, immediate, and accurate identification of risk factors and condition likelihoods. The present study conducted a systematic literature review to examine obesity research and machine learning techniques for the prevention and treatment of obesity from 2010 to 2020. Accordingly, 93 papers are identified from the review articles as primary studies from an initial pool of over 700 papers addressing obesity. Consequently, this study initially recognized the significant potential factors that influence and cause adult obesity. Next, the main diseases and health consequences of obesity and overweight are investigated. Ultimately, this study recognized the machine learning methods that can be used for the prediction of obesity. Finally, this study seeks to support decision-makers looking to understand the impact of obesity on health in the general population and identify outcomes that can be used to guide health authorities and public health to further mitigate threats and effectively guide obese people globally.",
        "DOI": "10.1016/j.compbiomed.2021.104754",
        "affiliation_name": "Ecole Nationale des Sciences de l'Informatique",
        "affiliation_city": "Manouba",
        "affiliation_country": "Tunisia"
    },
    {
        "paper_title": "Modeling and forecasting the COVID-19 pandemic time-series data",
        "paper_author": "Doornik J.A.",
        "publication": "Social Science Quarterly",
        "citied_by": "16",
        "cover_date": "2021-09-01",
        "Abstract": "Objective: We analyze the number of recorded cases and deaths of COVID-19 in many parts of the world, with the aim to understand the complexities of the data, and produce regular forecasts. Methods: The SARS-CoV-2 virus that causes COVID-19 has affected societies in all corners of the globe but with vastly differing experiences across countries. Health-care and economic systems vary significantly across countries, as do policy responses, including testing, intermittent lockdowns, quarantine, contact tracing, mask wearing, and social distancing. Despite these challenges, the reported data can be used in many ways to help inform policy. We describe how to decompose the reported time series of confirmed cases and deaths into a trend, seasonal, and irregular component using machine learning methods. Results: This decomposition enables statistical computation of measures of the mortality ratio and reproduction number for any country, and we conduct a counterfactual exercise assuming that the United States had a summer outcome in 2020 similar to that of the European Union. The decomposition is also used to produce forecasts of cases and deaths, and we undertake a forecast comparison which highlights the importance of seasonality in the data and the difficulties of forecasting too far into the future. Conclusion: Our adaptive data-based methods and purely statistical forecasts provide a useful complement to the output from epidemiological models.",
        "DOI": "10.1111/ssqu.13008",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Covid-19 and tracing methodologies: A lesson for the future society",
        "paper_author": "Scantamburlo T.",
        "publication": "Health and Technology",
        "citied_by": "1",
        "cover_date": "2021-09-01",
        "Abstract": "As the new coronavirus (SARS-CoV-2) surged across the globe, new technical solutions have supported policy makers and health authorities to plan and modulate containment measures. The introduction of these solutions provoked a large debate which has focused on risks for privacy and data protection. In this paper we offer an analysis of the available technical approaches and provide new arguments to move beyond the ongoing discussions. In particular, we argue that the past debate missed the opportunity to highlight the societal aspects of privacy and to stimulate a broader reflection on the actions needed to serve the good of society. With this paper, as well as providing an accessible review of the technical and legal aspects of the proposed solutions, we aim to offer new stimuli to reconsider contact tracing and its role in helping countries navigate the current pandemic.",
        "DOI": "10.1007/s12553-021-00575-1",
        "affiliation_name": "Centro Nacional de Supercomputación",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Personalized stratification of hospitalization risk amidst COVID-19: A machine learning approach",
        "paper_author": "Lam C.",
        "publication": "Health Policy and Technology",
        "citied_by": "9",
        "cover_date": "2021-09-01",
        "Abstract": "Objective: In the wake of COVID-19, the United States (U.S.) developed a three stage plan to outline the parameters to determine when states may reopen businesses and ease travel restrictions. The guidelines also identify subpopulations of Americans deemed to be at high risk for severe disease should they contract COVID-19. These guidelines were based on population level demographics, rather than individual-level risk factors. As such, they may misidentify individuals at high risk for severe illness, and may therefore be of limited use in decisions surrounding resource allocation to vulnerable populations. The objective of this study was to evaluate a machine learning algorithm for prediction of serious illness due to COVID-19 using inpatient data collected from electronic health records. Methods: The algorithm was trained to identify patients for whom a diagnosis of COVID-19 was likely to result in hospitalization, and compared against four U.S. policy-based criteria: age over 65; having a serious underlying health condition; age over 65 or having a serious underlying health condition; and age over 65 and having a serious underlying health condition. Results: This algorithm identified 80% of patients at risk for hospitalization due to COVID-19, versus 62% identified by government guidelines. The algorithm also achieved a high specificity of 95%, outperforming government guidelines. Conclusions: This algorithm may identify individuals likely to require hospitalization should they contract COVID-19. This information may be useful to guide vaccine distribution, anticipate hospital resource needs, and assist health care policymakers to make care decisions in a more principled manner.",
        "DOI": "10.1016/j.hlpt.2021.100554",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Hierarchical Reinforcement Learning Explains Task Interleaving Behavior",
        "paper_author": "Gebhardt C.",
        "publication": "Computational Brain and Behavior",
        "citied_by": "15",
        "cover_date": "2021-09-01",
        "Abstract": "How do people decide how long to continue in a task, when to switch, and to which other task? It is known that task interleaving adapts situationally, showing sensitivity to changes in expected rewards, costs, and task boundaries. However, the mechanisms that underpin the decision to stay in a task versus switch away are not thoroughly understood. Previous work has explained task interleaving by greedy heuristics and a policy that maximizes the marginal rate of return. However, it is unclear how such a strategy would allow for adaptation to environments that offer multiple tasks with complex switch costs and delayed rewards. Here, we develop a hierarchical model of supervisory control driven by reinforcement learning (RL). The core assumption is that the supervisory level learns to switch using task-specific approximate utility estimates, which are computed on the lower level. We show that a hierarchically optimal value function decomposition can be learned from experience, even in conditions with multiple tasks and arbitrary and uncertain reward and cost structures. The model also reproduces well-known key phenomena of task interleaving, such as the sensitivity to costs of resumption and immediate as well as delayed in-task rewards. In a demanding task interleaving study with 211 human participants and realistic tasks (reading, mathematics, question-answering, recognition), the model yielded better predictions of individual-level data than a flat (non-hierarchical) RL model and an omniscient-myopic baseline. Corroborating emerging evidence from cognitive neuroscience, our results suggest hierarchical RL as a plausible model of supervisory control in task interleaving.",
        "DOI": "10.1007/s42113-020-00093-9",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Fair classification via Monte Carlo policy gradient method",
        "paper_author": "Petrović A.",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "9",
        "cover_date": "2021-09-01",
        "Abstract": "Artificial intelligence is steadily increasing its impact on everyday life. Therefore, the societal issues of artificial intelligence have become an important concern in the AI research. The presence of data that reflects human biases towards historically discriminated groups defined by sensitive features such as race and gender, results in machine learning models which discriminate against these groups. In order to tackle the impact of bias in data, researchers developed a variety of specialized machine learning algorithms which are able to satisfy different fairness constraints imposed on the model. Group fairness constraints do not fit standard machine learning formulations easily due to their non-differentiable nature. In this paper we developed a technique for learning a fair classifier by Monte Carlo policy gradient method which naturally deals with such non-differentiable constraints. Our methodology focuses on direct optimization of both group fairness metric and predictive performance of the model. In addition, we propose two different variance reduction techniques of gradient estimation. We compare our models to seven other related and state-of-the-art models and demonstrate that they are able to achieve better trade-off between accuracy and unfairness. To the best of our knowledge, this is the first fair classification algorithm which solves the issue of non-differentiable constraints by reinforcement learning techniques.",
        "DOI": "10.1016/j.engappai.2021.104398",
        "affiliation_name": "Singidunum University",
        "affiliation_city": "Belgrade",
        "affiliation_country": "Serbia"
    },
    {
        "paper_title": "Socio-economic disparities and COVID-19 in the USA",
        "paper_author": "Paul A.",
        "publication": "Journal of Physics: Complexity",
        "citied_by": "38",
        "cover_date": "2021-09-01",
        "Abstract": "COVID-19 is not a universal killer. We study the spread of COVID-19 at the county level for the United States up until the 15th of August, 2020. We show that the prevalence of the disease and the death rate are correlated with the local socio-economic conditions often going beyond local population density distributions, especially in rural areas. We correlate the COVID-19 prevalence and death rate with data from the US Census Bureau and point out how the spreading patterns of the disease show asymmetries in urban and rural areas separately and are preferentially affecting the counties where a large fraction of the population is non-white. Our findings can be used for more targeted policy building and deployment of resources for future occurrence of a pandemic due to SARS-CoV-2. Our methodology, based on interpretable machine learning and game theory, can be extended to study the spread of other diseases.",
        "DOI": "10.1088/2632-072X/ac0fc7",
        "affiliation_name": "Deutsches Elektronen-Synchrotron (DESY)",
        "affiliation_city": "Hamburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A multi-country meta-analysis on the role of behavioural change in reducing energy consumption and CO<inf>2</inf> emissions in residential buildings",
        "paper_author": "Khanna T.M.",
        "publication": "Nature Energy",
        "citied_by": "93",
        "cover_date": "2021-09-01",
        "Abstract": "Despite the importance of evaluating all mitigation options to inform policy decisions addressing climate change, a comprehensive analysis of household-scale interventions and their emissions reduction potential is missing. Here, we address this gap for interventions aimed at changing individual households’ use of existing equipment, such as monetary incentives or feedback. We have performed a machine learning-assisted systematic review and meta-analysis to comparatively assess the effectiveness of these interventions in reducing energy demand in residential buildings. We extracted 360 individual effect sizes from 122 studies representing trials in 25 countries. Our meta-regression confirms that both monetary and non-monetary interventions reduce the energy consumption of households, but monetary incentives, of the sizes reported in the literature, tend to show on average a more pronounced effect. Deploying the right combinations of interventions increases the overall effectiveness. We have estimated a global carbon emissions reduction potential of 0.35 GtCO2 yr−1, although deploying the most effective packages of interventions could result in greater reduction. While modest, this potential should be viewed in conjunction with the need for de-risking mitigation pathways with energy-demand reductions.",
        "DOI": "10.1038/s41560-021-00866-x",
        "affiliation_name": "Mercator Research Institute on Global Commons and Climate Change",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Local incentives and national tax evasion: The response of illegal mining to a tax reform in Colombia",
        "paper_author": "Saavedra S.",
        "publication": "European Economic Review",
        "citied_by": "5",
        "cover_date": "2021-09-01",
        "Abstract": "Achieving a fair distribution of resources is one of the goals of fiscal policy. To this end, governments often transfer tax resources from richer to more marginalized areas. In the context of mining in Colombia, we study whether lower transfers to the locality where the taxed economic activity takes place dampen local authorities’ incentives to curb tax evasion. Using machine learning predictions on satellite imagery to identify mines allows us to overcome the challenge of measuring evasion. Employing difference-in-differences strategies, we find that reducing the share of revenue transferred back to mining municipalities leads to an increase in illegal mining. This result highlights the difficulties inherent in adequately redistributing tax revenues.",
        "DOI": "10.1016/j.euroecorev.2021.103843",
        "affiliation_name": "Universidad del Rosario",
        "affiliation_city": "Bogota",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "International Teledermatology Review",
        "paper_author": "McKoy K.",
        "publication": "Current Dermatology Reports",
        "citied_by": "26",
        "cover_date": "2021-09-01",
        "Abstract": "Purpose of Review: The use of teledermatology has been evolving slowly for the delivery of health care to remote and underserved populations. Improving technology and the recent COVID-19 pandemic have hastened its use internationally. Recent Findings: Some barriers to the use of teledermatology have fallen considerably in the last year. Summary: Teledermatology use has increased significantly in recent years in both government-sponsored and private health care systems and individual practices. There are no recognized international practice guidelines and variable use within countries. Many barriers remain to increasing the use of teledermatology.",
        "DOI": "10.1007/s13671-021-00333-6",
        "affiliation_name": "East Kent Hospitals University NHS Foundation Trust",
        "affiliation_city": "Canterbury",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Deep molecular dreaming: Inverse machine learning for de-novo molecular design and interpretability with surjective representations",
        "paper_author": "Shen C.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "38",
        "cover_date": "2021-09-01",
        "Abstract": "Computer-based de-novo design of functional molecules is one of the most prominent challenges in cheminformatics today. As a result, generative and evolutionary inverse designs from the field of artificial intelligence have emerged at a rapid pace, with aims to optimize molecules for a particular chemical property. These models 'indirectly' explore the chemical space; by learning latent spaces, policies, and distributions, or by applying mutations on populations of molecules. However, the recent development of the SELFIES (Krenn 2020 Mach. Learn.: Sci. Technol. 1 045024) string representation of molecules, a surjective alternative to SMILES, have made possible other potential techniques. Based on SELFIES, we therefore propose PASITHEA, a direct gradient-based molecule optimization that applies inceptionism (Mordvintsev 2015) techniques from computer vision. PASITHEA exploits the use of gradients by directly reversing the learning process of a neural network, which is trained to predict real-valued chemical properties. Effectively, this forms an inverse regression model, which is capable of generating molecular variants optimized for a certain property. Although our results are preliminary, we observe a shift in distribution of a chosen property during inverse-training, a clear indication of PASITHEA's viability. A striking property of inceptionism is that we can directly probe the model's understanding of the chemical space on which it is trained. We expect that extending PASITHEA to larger datasets, molecules and more complex properties will lead to advances in the design of new functional molecules as well as the interpretation and explanation of machine learning models.",
        "DOI": "10.1088/2632-2153/ac09d6",
        "affiliation_name": "Vector Institute",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Big data research in fighting COVID-19: Contributions and techniques",
        "paper_author": "Riswantini D.",
        "publication": "Big Data and Cognitive Computing",
        "citied_by": "16",
        "cover_date": "2021-09-01",
        "Abstract": "The COVID-19 pandemic has induced many problems in various sectors of human life. After more than one year of the pandemic, many studies have been conducted to discover various technological innovations and applications to combat the virus that has claimed many lives. The use of Big Data technology to mitigate the threats of the pandemic has been accelerated. Therefore, this survey aims to explore Big Data technology research in fighting the pandemic. Furthermore, the relevance of Big Data technology was analyzed while technological contributions to five main areas were highlighted. These include healthcare, social life, government policy, business and management, and the environment. The analytical techniques of machine learning, deep learning, statistics, and mathematics were discussed to solve issues regarding the pandemic. The data sources used in previous studies were also presented and they consist of government officials, institutional service, IoT generated, online media, and open data. Therefore, this study presents the role of Big Data technologies in enhancing the research relative to COVID-19 and provides insights into the current state of knowledge within the domain and references for further development or starting new studies are provided.",
        "DOI": "10.3390/bdcc5030030",
        "affiliation_name": "Lembaga Ilmu Pengetahuan Indonesia",
        "affiliation_city": "Central Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "No-Pain No-Gain: DRL Assisted Optimization in Energy-Constrained CR-NOMA Networks",
        "paper_author": "Ding Z.",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "60",
        "cover_date": "2021-09-01",
        "Abstract": "This paper applies machine learning to optimize the transmission policies of cognitive radio inspired non-orthogonal multiple access (CR-NOMA) networks, where time-division multiple access (TDMA) is used to serve multiple primary users and an energy-constrained secondary user is admitted to the primary users' time slots via NOMA. During each time slot, the secondary user performs the two tasks: data transmission and energy harvesting based on the signals received from the primary users. The goal of the paper is to maximize the secondary user's long-term throughput, by optimizing its transmit power and the time-sharing coefficient for its two tasks. The long-term throughput maximization problem is challenging due to the need for making decisions that yield long-term gains but might result in short-term losses. For example, when in a given time slot, a primary user with large channel gains transmits, intuition suggests that the secondary user should not carry out data transmission due to the strong interference from the primary user but perform energy harvesting only, which results in zero data rate for this time slot but yields potential long-term benefits. In this paper, a deep reinforcement learning (DRL) approach is applied to emulate this intuition, where the deep deterministic policy gradient (DDPG) algorithm is employed together with convex optimization. Our simulation results demonstrate that the proposed DRL assisted NOMA transmission scheme can yield significant performance gains over two benchmark schemes.",
        "DOI": "10.1109/TCOMM.2021.3087624",
        "affiliation_name": "School of Engineering",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Social media and predictive analysis regarding dietary approaches to stop hypertension",
        "paper_author": "Krittanawong C.",
        "publication": "Progress in Cardiovascular Diseases",
        "citied_by": "0",
        "cover_date": "2021-09-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.pcad.2021.07.006",
        "affiliation_name": "NYU Grossman Long Island School of Medicine",
        "affiliation_city": "Mineola",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Regulatory Lag, Regulatory Friction and Regulatory Transition as FinTech Disenablers: Calibrating an EU Response to the Regulatory Sandbox Phenomenon",
        "paper_author": "Ahern D.",
        "publication": "European Business Organization Law Review",
        "citied_by": "24",
        "cover_date": "2021-09-01",
        "Abstract": "With transformative evolution involving crypto-assets, machine learning applications and data-driven finance models, complex regulatory and policy issues are emerging. Inadequate frameworks in FinTech markets create regulatory friction and regulatory fragmentation. These limitations continue to feature when piecemeal regulatory transition occurs. The danger of EU Member States being left behind in the FinTech innovation race if the regulatory landscape is cumbersome or incomplete for new business models is real. Regulatory lag and regulatory friction also act as a ‘disenabler’ for ease of cross-border FinTech trade in the EU. This article critically engages with the manner in which the regulatory sandbox has rapidly gained critical mass in Member States as a valuable adaptive measure supporting a route to market for FinTech entrepreneurs. Against the backdrop of the European Commission’s Digital Finance Strategy, the article further advances scholarship on FinTech in the EU by probing the EU’s resulting regulatory dilemma, undertaking a systematic evaluation of the continuum of complex policy options available to the European Union in response to the spreading regulatory sandbox phenomenon.",
        "DOI": "10.1007/s40804-021-00217-z",
        "affiliation_name": "Faculty of Arts, Humanities and Social Sciences",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Machine-specified ground structures for topology optimization of binary trusses using graph embedding policy network",
        "paper_author": "Zhu S.",
        "publication": "Advances in Engineering Software",
        "citied_by": "22",
        "cover_date": "2021-09-01",
        "Abstract": "This paper proposes the concept of machine-specified ground structures for topology optimization of trusses. Unlike general ground structures with dense and regular connectivity, machine-specified ground structures are sparse stable ground structures with a specified number of members designed by machines. Firstly, the generation process of machine-specified ground structures from a given node-set is formulated as a reinforcement learning task. Graph embedding is used to integrate the structural information into a comprehensive feature matrix to describe the state. By establishing the policy network, the probability of each action, i.e., selecting each node in the node-set, is obtained based on the comprehensive feature matrix. The task is solved using a gradient-based algorithm called REINFORCE. A randomized 4 × 4 node-set is used to train the agent. The policy converges with a high average reward, and generates different yet reasonable structures because a stochastic policy is employed. Besides, the agent can handle different-sized node-sets without re-training. Hence, the machine-specified ground structures generated by the trained agent can be utilized to assist the structural topology design. Subsequently, a method for a typical problem with singular optimal solutions, i.e., topology optimization of binary trusses with stress and displacement constraints, is proposed based on machine-specified ground structures. Finally, through different-sized numerical examples, it is demonstrated that the machine-specified ground structures lead to a variety of optimal solutions, and it is more likely to obtain the global optimum than fully-connected ground structures. It is worth noting that machine-specified ground structures can also be applied to other problems without re-training.",
        "DOI": "10.1016/j.advengsoft.2021.103032",
        "affiliation_name": "Department of Architecture and Architectural Engineering",
        "affiliation_city": "Kyoto",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Technology and psychotherapeutic interventions: Bibliometric analysis of the past four decades",
        "paper_author": "Zale A.",
        "publication": "Internet Interventions",
        "citied_by": "13",
        "cover_date": "2021-09-01",
        "Abstract": "Background: Rapid growth of the integration of technology and psychotherapeutic interventions has been noted, but no clear quantification of this growth has been done. Aims: This bibliometric analysis seeks to quantify the growth, trends, and applications of technology in psychotherapeutic interventions over the last 40 years. Methods: Searches were conducted in the Web of Science (WOS) database for all existing technology-psychotherapy-related publications from 1981 to October 2020. Search terms were refined using a systematic screening strategy, based upon Cochrane protocol, generating 52 technology terms. Analyses across 40 years and by decade from 1981 to 2020 were conducted. Results: A total of 13,934 peer-reviewed articles were identified. Yearly publication rate has increased from one in 1981 to 1902 by October 2020. The growth rate of publications across decades consistently tripled in size (762.50% from the 1980s to 1990s, 539.71% from the 1990s to 2000s, and 337.24% from the 2000s to 2010s). The author, country, journal, and institution with the most publications were Andersson, G., USA, Journal of Medical Internet Research, and Karolinska Institute, respectively. The most frequent technology search term across all four decades was “internet*.” The trends in percentages of peer-reviewed publications within each decade showed: 1) a declining trend for the term “computer,” 2) an upward trend for the combined terms, “internet,” “online,” and “web,” 3) and a steady but smaller proportion of publications for other terms (“cell phone,” “phone/telephone,” “technology,” “video,” “virtual reality or VR,” “apps,” “digital,” “machine learning,” “electronic,” “robo,” and “telehealth”). Discussion: The rapid growth and trends identified in technology and psychotherapy publications can inform related policies addressing the role of technology in mental health. Moreover, pattern analyses may provide direction for a standard nomenclature to address terminology usage inconsistencies across the field.",
        "DOI": "10.1016/j.invent.2021.100425",
        "affiliation_name": "Pacific Graduate School of Psychology",
        "affiliation_city": "Palo Alto",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning how to dynamically route autonomous vehicles on shared roads",
        "paper_author": "Lazar D.A.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "29",
        "cover_date": "2021-09-01",
        "Abstract": "Road congestion induces significant costs across the world, and road network disturbances, such as traffic accidents, can cause highly congested traffic patterns. If a planner had control over the routing of all vehicles in the network, they could easily reverse this effect. In a more realistic scenario, we consider a planner that controls autonomous cars, which are a fraction of all present cars. We study a dynamic routing game, in which the route choices of autonomous cars can be controlled and the human drivers react selfishly and dynamically. As the problem is prohibitively large, we use deep reinforcement learning to learn a policy for controlling the autonomous vehicles. This policy indirectly influences human drivers to route themselves in such a way that minimizes congestion on the network. To gauge the effectiveness of our learned policies, we establish theoretical results characterizing equilibria and empirically compare the learned policy results with best possible equilibria. We prove properties of equilibria on parallel roads and provide a polynomial-time optimization for computing the most efficient equilibrium. Moreover, we show that in the absence of these policies, high demand and network perturbations would result in large congestion, whereas using the policy greatly decreases the travel times by minimizing the congestion. To the best of our knowledge, this is the first work that employs deep reinforcement learning to reduce congestion by indirectly influencing humans’ routing decisions in mixed-autonomy traffic.",
        "DOI": "10.1016/j.trc.2021.103258",
        "affiliation_name": "UC Santa Barbara College of Engineering",
        "affiliation_city": "Santa Barbara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Behaviour associated with the presence of a school sports ground: Visual information for policy makers",
        "paper_author": "Vala R.",
        "publication": "Children and Youth Services Review",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "The planning and development of sports infrastructure is a complex process that has a broad and long-term impact on health and well-being in communities. It involves many different stake- holders and usually requires significant public or private investments. Its framework is outlined by policies that define the general social goals of such development. To ensure the maximum alignment between the goals and the development activities, it is important to support the policy making process by high-quality information based on real-world data and presented in a clear and focused way. This work introduces a new pipeline of methods for processing and interpretation of data on physical activity and lifestyle in adolescents. The data is extracted from the Health Behaviour in School-aged Children (HBSC) study and analyzed by modern machine learning methods. We identify behavioural patterns associated with the presence and absence of a school sports ground in different sex and age groups of adolescent in the Czech Republic. The patterns are presented by concise graphical models that ease their use by stake- holders without expert knowledge in sociology, statistics, mathematical modelling, etc. They enable intuitive visual assessment of situation in different regions and highlight the specific similarities and differences among them. Together, the proposed methods contribute towards objective evidence-based policy making in sports management and development.",
        "DOI": "10.1016/j.childyouth.2021.106150",
        "affiliation_name": "VSB – Technical University of Ostrava",
        "affiliation_city": "Ostrava",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Improved prediction of total energy consumption and feature analysis in electric vehicles using machine learning and shapley additive explanations method",
        "paper_author": "Pokharel S.",
        "publication": "World Electric Vehicle Journal",
        "citied_by": "27",
        "cover_date": "2021-09-01",
        "Abstract": "Electric vehicles (EVs) have emerged as the green energy alternative for conventional vehicles. While various governments promote EVs, people feel “range anxiety” because of their limited driving range or charge capacity. A limited number of charging stations are available, which results in a strong demand for predicting energy consumed by EVs. In this paper, machine learning (ML) models such as multiple linear regression (MLR), extreme gradient boosting (XGBoost), and support vector regression (SVR) were used to investigate the total energy consumption (TEC) by the EVs. The independent variables used for the study include changing real-life situations or external parameters, such as trip distance, tire type, driving style, power, odometer reading, EV model, city, motorway, country roads, air conditioning, and park heating. We compared the ML models’ performance along with the error analysis. A pairwise correlation study showed that trip distance has a high correlation coefficient (0.87) with TEC. XGBoost had better prediction accuracy (~92%) or R2 (0.92). Trip distance, power, heating, and odometer reading were the most important features influencing the TEC, identified using the shapley additive explanations method.",
        "DOI": "10.3390/wevj12030094",
        "affiliation_name": "Texas A and M International University",
        "affiliation_city": "Laredo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Dynamic Positioning using Deep Reinforcement Learning",
        "paper_author": "Øvereng S.S.",
        "publication": "Ocean Engineering",
        "citied_by": "26",
        "cover_date": "2021-09-01",
        "Abstract": "This paper demonstrates the implementation and performance testing of a Deep Reinforcement Learning based control scheme used for Dynamic Positioning of a marine surface vessel. The control scheme encapsulated motion control and control allocation by using a neural network, which was trained on a digital twin without having any prior knowledge of the system dynamics, using the Proximal Policy Optimization learning algorithm. By using a multivariate Gaussian reward function for rewarding small errors between the vessel and the various setpoints, while encouraging small actuator outputs, the proposed Deep Reinforcement Learning based control scheme showed good positioning performance while being energy efficient. Both simulations and model scale sea trials were carried out to demonstrate performance compared to traditional methods, and to evaluate the ability of neural networks trained in simulation to perform on real life systems.",
        "DOI": "10.1016/j.oceaneng.2021.109433",
        "affiliation_name": "DNV GL AS",
        "affiliation_city": "Oslo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Development of a Soft Actor Critic deep reinforcement learning approach for harnessing energy flexibility in a Large Office building",
        "paper_author": "Kathirgamanathan A.",
        "publication": "Energy and AI",
        "citied_by": "35",
        "cover_date": "2021-09-01",
        "Abstract": "This research is concerned with the novel application and investigation of ‘Soft Actor Critic’ based deep reinforcement learning to control the cooling setpoint (and hence cooling loads) of a large commercial building to harness energy flexibility. The research is motivated by the challenge associated with the development and application of conventional model-based control approaches at scale to the wider building stock. Soft Actor Critic is a model-free deep reinforcement learning technique that is able to handle continuous action spaces and which has seen limited application to real-life or high-fidelity simulation implementations in the context of automated and intelligent control of building energy systems. Such control techniques are seen as one possible solution to supporting the operation of a smart, sustainable and future electrical grid. This research tests the suitability of the technique through training and deployment of the agent on an EnergyPlus based environment of the office building. The agent was found to learn an optimal control policy that was able to minimise energy costs by 9.7% compared to the default rule-based control scheme and was able to improve or maintain thermal comfort limits over a test period of one week. The algorithm was shown to be robust to the different hyperparameters and this optimal control policy was learnt through the use of a minimal state space consisting of readily available variables. The robustness of the algorithm was tested through investigation of the speed of learning and ability to deploy to different seasons and climates. It was found that the agent requires minimal training sample points and outperforms the baseline after three months of operation and also without disruption to thermal comfort during this period. The agent is transferable to other climates and seasons although further retraining or hyperparameter tuning is recommended.",
        "DOI": "10.1016/j.egyai.2021.100101",
        "affiliation_name": "University College Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Integrating remote sensing with swarm intelligence and artificial intelligence for modelling wetland habitat vulnerability in pursuance of damming",
        "paper_author": "Khatun R.",
        "publication": "Ecological Informatics",
        "citied_by": "22",
        "cover_date": "2021-09-01",
        "Abstract": "The current study aimed to investigate the vulnerability state of wetland habitat as a result of damming. Wetland habitat vulnerability state (WHVS) models for pre and post-dam periods were built to investigate the impact, and the difference was assessed. Sixteen hydrological, land composition and water quality parameters were used for modelling WHVS. Swarm intelligence optimised machine learning algorithms such as SVM (Support Vector Machine), ANN (Artificial Neural Network), bagging, radial basis (RBF) and M5P model tree were developed. The models' efficiency was evaluated using statistical methods such as the Receiver operating characteristics (ROC) curve. According to the machine learning models, 8.13–14.58% of the area in the wetland fringe area, small patches, and edges was under the very high vulnerable wetland habitat status in the pre-dam period. During the post-dam period, the region covered by fringes and small and medium-core wetlands increased to 21.23–50.58%. The PSO-RBF model was found to be the best representative model. This study provides a large database of wetland habitat conditions, which could aid policymakers in developing wetland conservation and restoration plans.",
        "DOI": "10.1016/j.ecoinf.2021.101349",
        "affiliation_name": "University of Gour Banga",
        "affiliation_city": "Malda",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Optimization of fitness data monitoring system based on Internet of Things and cloud computing",
        "paper_author": "Shang X.",
        "publication": "Computer Communications",
        "citied_by": "5",
        "cover_date": "2021-09-01",
        "Abstract": "In the service dimension, the construction of fitness science data supervision service mode is discussed. Based on the stakeholder theory, through the statistical analysis of the stakeholders of fitness science data supervision, three core stakeholders of the government, users and data service personnel are identified. Based on these three dimensions, we find out the core concepts of government policy model, user demand model and service model. At the same time, each dimension is deeply analyzed. Through the relationship analysis between these three dimensions, the user-oriented collaborative supervision service model of fitness scientific data is expected to guide the specific service practice of fitness scientific data supervision through the establishment of this model. In addition, an unsupervised learning method in machine learning, the isolation forest algorithm, is introduced to detect abnormal data; at the same time, using real fitness data sets, through comparative experiments with local anomaly factor algorithms, it is verified that the isolation forest algorithm has a good effect of anomaly detection; this article also uses redis cache to optimize the performance of the fitness data monitoring system, which solves the access pressure of the main database in a multi-user high-concurrency environment; Finally, the usability and stability of the system are verified by functional tests and stress tests.",
        "DOI": "10.1016/j.comcom.2021.06.027",
        "affiliation_name": "Sangmyung University",
        "affiliation_city": "Jongno-gu",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A predictive model, and predictors of under-five child malaria prevalence in Ghana: How do LASSO, Ridge and Elastic net regression approaches compare?",
        "paper_author": "Aheto J.M.K.",
        "publication": "Preventive Medicine Reports",
        "citied_by": "17",
        "cover_date": "2021-09-01",
        "Abstract": "Malaria is among the leading causes of mortality and morbidity among children in Ghana. Therefore, identifying the predictors of malaria prevalence in children under-five is among the priorities of the global health agenda. In Ghana, the paradigm shifts from using traditional statistics to machine learning techniques to identifying predictors of malaria prevalence are scarce. Thus, the present study used machine learning techniques to identify variables to build the best fitting predictive model of malaria prevalence in Ghana. We analysed the data on 2867 under-five children with malaria RDT results from the 2019 Ghana Malaria Indicator Survey. LASSO, Ridge, and Elastic Net regression methods were used to select variables to build predictive models. The R freeware version 4.0.2 was used. One out of four children tested positive for malaria (25.04%). The logit models based on selected features by LASSO, Ridge, and Elastic Net contained eleven, fifteen, and thirteen features, respectively. The LASSO regression model is preferred because it contains the smallest number of predictors and the smallest prediction error. The significant predictors of malaria among children were being older than 24 months, residing in the poorest household, being severely anaemic, residing in households without electricity, and residing in a rural area. The predictors identified in our study deserve policy attention and interventions to strengthen malaria control efforts in Ghana. The machine learning techniques employed in our study, especially the LASSO regression technique could be beneficial for identifying predictors of malaria prevalence in this group of children.",
        "DOI": "10.1016/j.pmedr.2021.101475",
        "affiliation_name": "Kwame Nkrumah University of Science &amp; Technology",
        "affiliation_city": "Kumasi",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Machine learning spatio-temporal epidemiological model to evaluate Germany-county-level COVID-19 risk",
        "paper_author": "Wang L.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "22",
        "cover_date": "2021-09-01",
        "Abstract": "As the COVID-19 pandemic continues to ravage the world, it is critical to assess the COVID-19 risk timely on multi-scale. To implement it and evaluate the public health policies, we develop a machine learning assisted framework to predict epidemic dynamics from the reported infection data. It contains a county-level spatio-temporal epidemiological model, which combines spatial cellular automata (CA) with time sensitive-undiagnosed-infected-removed (SUIR) model, and is compatible with the existing risk prediction models. The CA-SUIR model shows the multi-scale risk to the public and reveals the transmission modes of coronavirus in different scenarios. Through transfer learning, this new toolbox is used to predict the prevalence of multi-scale COVID-19 in all 412 counties in Germany. A t-day-ahead risk forecast as well as assessment of the non-pharmaceutical intervention policies is presented. We analyzed the situation at Christmas of 2020, and found that the most serious death toll could be 34.5. However, effective policy could control it below 21thousand, which provides a quantitative basis for evaluating the public policies implemented by the government. Such intervening evaluation process would help to improve public health policies and restart the economy appropriately in pandemics.",
        "DOI": "10.1088/2632-2153/ac0314",
        "affiliation_name": "Frankfurt Institute for Advanced Studies",
        "affiliation_city": "Frankfurt am Main",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "EMORL: Effective multi-objective reinforcement learning method for hyperparameter optimization",
        "paper_author": "Chen S.P.",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "29",
        "cover_date": "2021-09-01",
        "Abstract": "Hyperparameter optimization is critical for the performance of machine learning algorithms. Significant efforts have been dedicated to improve the final accuracy of algorithm by hyperparameter tuning. However, some indicators (such as latency, cpu utilization) are also very important in the actual environment. In this paper, we propose a novel method EMORL (Effective Multi-Objective Reinforcement Learning) based on multi-objective reinforcement learning for hyperparameter optimization to solve the above limitations. Specifically, we extend hyperparameter optimization problem to the reinforcement learning framework and employ an agent to select hyperparameters sequentially, and design a scalarization function that combines accuracy and latency as a multi-objective reward to guide the policy update. To improve the efficiency of hyperparameter optimization, previously successful configuration is reused for reshaping the advantage function. In the experiment, we apply the proposed method to tune the hyperparameters of the eXtreme Gradient Boosting on 101 tasks and convolutional neural networks on 2 tasks. The experimental results demonstrate that the proposed method is better than other methods in most tasks, especially in terms of latency. In addition, we verify the various components of the proposed method through ablation experiments.",
        "DOI": "10.1016/j.engappai.2021.104315",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Analysing patterns of forest cover change and related land uses in the Tano-Offin forest reserve in Ghana: Implications for forest policy and land management",
        "paper_author": "Oduro Appiah J.",
        "publication": "Trees, Forests and People",
        "citied_by": "21",
        "cover_date": "2021-09-01",
        "Abstract": "Forest cover change is a major contributing factor to global environmental change. Whereas several studies have focused on the general land use and land cover dynamics, we focus on analysing forest cover change patterns in a protected landscape taking into consideration how other land categories are increasing at the expense of the forest. In this study, we analyse forest cover change patterns and associated proximate land use factors between 1987 and 2017 using Landsat images from the Tano-Offin Forest Reserve (TOFR) in Ghana. Using the Random Forest machine learning algorithm, we classified the images into forest, developed land, and agricultural land. The study finds that forest cover losses are 1.9 and 1.4 times the amount of forest cover gains in 1987–2002 and 2002–2017, respectively. We find that even though the forest cover is more likely to recover from the agricultural land, land developers mostly targeted the agricultural land. The focus of Ghana's Forest and Wildlife Policy and the underlying process of forest cover change in the TOFR suggest that a country's forest policy should focus on a combination of diverse and spatially explicit proximate factors that are likely to threaten the integrity of forests.",
        "DOI": "10.1016/j.tfp.2021.100105",
        "affiliation_name": "Kwame Nkrumah University of Science &amp; Technology",
        "affiliation_city": "Kumasi",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Comparing tweet sentiments in megacities using machine learning techniques: In the midst of COVID-19",
        "paper_author": "Yao Z.",
        "publication": "Cities",
        "citied_by": "24",
        "cover_date": "2021-09-01",
        "Abstract": "COVID-19 was announced by the World Health Organization as a pandemic on March 11, 2020. Not only has COVID-19 struck the economy and public health, but it also has deep influences on people's feelings. Twitter, as an active social media, is a great database where we can investigate people's sentiments during this pandemic. By conducting sentiment analysis on Tweets using advanced machine learning techniques, this study aims to investigate how public sentiments respond to the pandemic from March 2 to May 21, 2020 in New York City, Los Angeles, London, and another six global mega-cities. Results showed that across cities, negative and positive Tweet sentiment clustered around mid-March and early May, respectively. Furthermore, positive sentiments of Tweets from New York City and London were positively correlated with stricter quarantine measures, although this correlation was not significant in Los Angeles. Meanwhile, Tweet sentiments of all three cities did not exhibit a strong correlation with new cases and hospitalization. Last but not least, we provide a qualitative analysis of the reasons behind differences in correlations shown above, along with a discussion of the polarizing effect of public policies on Tweet sentiments. Thus, the results of this study imply that Tweet sentiment is more sensitive to quarantine orders than reported statistics of COVID-19, especially in populous megacities where public transportation is heavily relied upon, which calls for prompt and effective quarantine measures during contagious disease outbreaks.",
        "DOI": "10.1016/j.cities.2021.103273",
        "affiliation_name": "NYU Shanghai",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Transportation mode choice behavior with recommender systems: A case study on Beijing",
        "paper_author": "Sun X.",
        "publication": "Transportation Research Interdisciplinary Perspectives",
        "citied_by": "17",
        "cover_date": "2021-09-01",
        "Abstract": "Understanding and predicting mode choice behavior in urban areas is an ongoing challenge, with several factors identified in past studies, e.g. built-environment, household statistics, trip properties, and many models being developed, e.g., regression and nested logit models. Existing research studies are predominantly designed around stated preferences surveys on small subsets of a population. The massive use of smartphones and route recommendation systems, however, offers the possibility of interacting with users, opening the potential to better understand and influence mode choice behavior, compared to sole offline analysis. This study explores the ability to predict travelers’ mode choice behavior in Beijing based on a collection of 300,000 recommended transportation alternatives from Baidu. The unique context of Beijing, with its enormous congestion and excessive penetration of smart phones, provides a unique view on actual transportation mode choice at a large scale; and behavioral changes induced by mobile communication technologies. We use machine learning techniques to identify the effects of driving variables, including transportation mode accessibility, weather conditions, alternative trip costs, and time of day. We find robust evidence supporting the observation that users preferably select the first-ranked alternative provided by the route recommendation system. This observation should be exploited further by transportation policy-makers to guide users towards greener and environmental-friendly transport modes.",
        "DOI": "10.1016/j.trip.2021.100408",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "PolSIRD: Modeling Epidemic Spread Under Intervention Policies: Analyzing the First Wave of COVID-19 in the USA",
        "paper_author": "Kamra N.",
        "publication": "Journal of Healthcare Informatics Research",
        "citied_by": "7",
        "cover_date": "2021-09-01",
        "Abstract": "Epidemic spread in a population is traditionally modeled via compartmentalized models which represent the free evolution of disease in the absence of any intervention policies. In addition, these models assume full observability of disease cases and do not account for under-reporting. We present a mathematical model, namely PolSIRD, which accounts for the under-reporting by introducing an observation mechanism. It also captures the effects of intervention policies on the disease spread parameters by leveraging intervention policy data along with the reported disease cases. Furthermore, we allow our recurrent model to learn the initial hidden state of all compartments end-to-end along with other parameters via gradient-based training. We apply our model to the spread of the recent global outbreak of COVID-19 in the USA, where our model outperforms the methods employed by the CDC in predicting the spread. We also provide counterfactual simulations from our model to analyze the effect of lifting the intervention policies prematurely and our model correctly predicts the second wave of the epidemic.",
        "DOI": "10.1007/s41666-021-00099-3",
        "affiliation_name": "USC Viterbi School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Changes of gold prices in COVID-19 pandemic: Daily evidence from Turkey's monetary policy measures with selected determinants",
        "paper_author": "Depren Ö.",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "21",
        "cover_date": "2021-09-01",
        "Abstract": "The study examines the impacts of monetary policy measures on the gold prices in Turkey by using daily data between January 2, 2020 and August 04, 2020 so that reactions of gold prices to the COVID-19 pandemic can be defined. In this context, the effects of 11 (including 3 global, 3 national, 3 monetary policy, 2 COVID-19) determinants on gold prices are examined by adopting machine learning algorithms. The empirical results reveal that (i) the most significant determinant of gold prices is the foreign exchange rate in the pre-pandemic period whereas securities amount bought by the central bank is important in the pandemic period; (ii) the number of confirmed cases and deaths have an important and intermediate effect on gold prices in the pandemic period; (iii) monetary policy measures are important for gold prices; (iv) global factors have a relatively high impact in both periods.",
        "DOI": "10.1016/j.techfore.2021.120884",
        "affiliation_name": "Yıldız Teknik Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Estimating monthly concentrations of ambient key air pollutants in Japan during 2010–2015 for a national-scale birth cohort",
        "paper_author": "Araki S.",
        "publication": "Environmental Pollution",
        "citied_by": "12",
        "cover_date": "2021-09-01",
        "Abstract": "Exposure to ambient air pollution is associated with maternal and child health. Some air pollutants exhibit similar behavior in the atmosphere, and some interact with each other; thus, comprehensive assessments of individual air pollutants are required. In this study, we developed national-scale monthly models for six air pollutants (NO, NO2, SO2, O3, PM2.5, and suspended particulate matter (SPM)) to obtain accurate estimates of pollutant concentrations at 1 km × 1 km resolution from 2010 through 2015 for application to the Japan Environment and Children's Study (JECS), which is a large-scale birth cohort study. We developed our models in the land use regression framework using random forests in conjunction with kriging. We evaluated the model performance via 5-fold location-based cross-validation. We successfully predicted monthly NO (r2 = 0.65), NO2 (r2 = 0.84), O3 (r2 = 0.86), PM2.5 (r2 = 0.79), and SPM (r2 = 0.64) concentrations. For SO2, a satisfactory model could not be developed (r2 = 0.45) because of the low SO2 concentrations in Japan. The performance of our models is comparable to those reported in previous studies at similar temporal and spatial scales. The model predictions in conjunction with the JECS will reveal the critical windows of prenatal and infancy exposure to ambient air pollutants, thus contributing to the development of environmental policies on air pollution.",
        "DOI": "10.1016/j.envpol.2021.117483",
        "affiliation_name": "Graduate School of Energy Science",
        "affiliation_city": "Kyoto",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "A hybrid recommendation model for successful R&amp;D collaboration: Mixing machine learning and discriminant analysis",
        "paper_author": "Jun S.P.",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "16",
        "cover_date": "2021-09-01",
        "Abstract": "Seeking to stimulate and improve the rate of success of R&D collaboration by SMEs, this study developed a method of recommending types of external collaboration organizations that are optimal partners for SMEs. We began by examining the current data on R&D collaboration by partner type to effectively classify the types of R&D partners engaged with South Korean SMEs. Next, we applied machine learning and discriminant analysis to develop a hybrid model for recommending firms that will likely achieve high satisfaction from collaboration with four representative types of R&D partners (universities, public research institutes, large firms, and SMEs). Lastly, we used new data that had not been included in the model development stage, to perform additional evaluations of the model. In our research results, the hybrid recommendation model, designed to identify SMEs that will achieve high satisfaction by R&D partner type, demonstrated outstanding accuracy exceeding 91%. By applying the model proposed in this paper, firms will be able to select their R&D partner types more efficiently and improve the likelihood of achieving success in R&D collaboration. Meanwhile, those responsible for implementing public policies may use the proposed model to improve the efficiency of public investments that support R&D collaboration.",
        "DOI": "10.1016/j.techfore.2021.120871",
        "affiliation_name": "University of Science and Technology (UST)",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Machine learning fairness notions: Bridging the gap with real-world applications",
        "paper_author": "Makhlouf K.",
        "publication": "Information Processing and Management",
        "citied_by": "43",
        "cover_date": "2021-09-01",
        "Abstract": "Fairness emerged as an important requirement to guarantee that Machine Learning (ML) predictive systems do not discriminate against specific individuals or entire sub-populations, in particular, minorities. Given the inherent subjectivity of viewing the concept of fairness, several notions of fairness have been introduced in the literature. This paper is a survey that illustrates the subtleties between fairness notions through a large number of examples and scenarios. In addition, unlike other surveys in the literature, it addresses the question of “which notion of fairness is most suited to a given real-world scenario and why?”. Our attempt to answer this question consists in (1) identifying the set of fairness-related characteristics of the real-world scenario at hand, (2) analyzing the behavior of each fairness notion, and then (3) fitting these two elements to recommend the most suitable fairness notion in every specific setup. The results are summarized in a decision diagram that can be used by practitioners and policy makers to navigate the relatively large catalog of ML fairness notions.",
        "DOI": "10.1016/j.ipm.2021.102642",
        "affiliation_name": "HCT-Dubai Campuses",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "A fuzzy based hybrid decision framework to circularity in dairy supply chains through big data solutions",
        "paper_author": "Kazancoglu Y.",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "50",
        "cover_date": "2021-09-01",
        "Abstract": "This study determines the potential barriers to achieving circularity in dairy supply chains; it proposes a framework which covers big data driven solutions to deal with the suggested barriers. The main contribution of the study is to propose a framework by making ideal matching and ranking of big data solutions to barriers to circularity in dairy supply chains. This framework further offers a specific roadmap as a practical contribution while investigating companies with restricted resources. In this study the main barriers are classified as ‘economic’, ‘environmental’, ‘social and legal’, ‘technological’, ‘supply chain management’ and ‘strategic’ with twenty-seven sub-barriers. Various big data solutions such as machine learning, optimization, data mining, cloud computing, artificial neural network, statistical techniques and social network analysis have been suggested. Big data solutions are matched with circularity focused barriers to show which solutions succeed in overcoming barriers. A hybrid decision framework based on the fuzzy ANP and the fuzzy VIKOR is developed to find the weights of the barriers and to rank the big data driven solutions. The results indicate that among the main barriers, ‘economic’ was of the highest importance, followed by ‘technological’, ‘environmental’, ‘strategic’, ‘supply chain management’ then ‘social and legal barrier’ in dairy supply chains. In order to overcome circularity focused barriers, ‘optimization’ is determined to be the most important big data solution. The other solutions to overcoming proposed challenges are ‘data mining’, ‘machine learning’, ‘statistical techniques’ and ‘artificial neural network’ respectively. The suggested big data solutions will be useful for policy makers and managers to deal with potential barriers in implementing circularity in the context of dairy supply chains.",
        "DOI": "10.1016/j.techfore.2021.120927",
        "affiliation_name": "Plymouth Business School",
        "affiliation_city": "Plymouth",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Exploring the complex origins of energy poverty in The Netherlands with machine learning",
        "paper_author": "Dalla Longa F.",
        "publication": "Energy Policy",
        "citied_by": "25",
        "cover_date": "2021-09-01",
        "Abstract": "Energy poverty is receiving increased attention in developed countries like the Netherlands. Although it only affects a relatively small share of the population, it constitutes a stern challenge that is hard to quantify and monitor, hence difficult to effectively tackle through adequate policy measures. In this paper we introduce a framework to categorize energy poverty risk based on income and energy expenditure. We propose the use of a machine learning classifier to predict energy poverty risk from a broad set of socio-economic parameters: house value, ownership and age, household size, and average population density. While income remains the single most important predictor, we find that the inclusion of these additional socio-economic features is indispensable in order to achieve high prediction reliability. This result forms an indication of the complex nature of the mechanisms underlying energy poverty. Our findings are valid at different geographical scales, i.e. both for single households and for entire neighborhoods. Extensive sensitivity analysis shows that our results are independent of the precise position of risk category boundaries. The outcomes of our study indicate that machine learning could be used as an effective means to monitor energy poverty, and assist the design and implementation of appropriate policy measures.",
        "DOI": "10.1016/j.enpol.2021.112373",
        "affiliation_name": "Nederlandse Organisatie voor toegepast natuurwetenschappelijk onderzoek- TNO",
        "affiliation_city": "The Hague",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "An Analytics-Driven Approach for Optimal Individualized Diabetes Screening",
        "paper_author": "Kamalzadeh H.",
        "publication": "Production and Operations Management",
        "citied_by": "10",
        "cover_date": "2021-09-01",
        "Abstract": "Type 2 diabetes is a chronic disease that affects millions of Americans and puts a significant burden on the healthcare system. The medical community sees screening patients to identify and treat prediabetes and diabetes early as an important goal; however, universal population screening is operationally not feasible, and screening policies need to take characteristics of the patient population into account. For instance, the screening policy for a population in an affluent neighborhood may differ from that of a safety-net hospital. The problem of optimal diabetes screening—whom to screen and when to screen—is clearly important, and small improvements could have an enormous impact. However, the problem is typically only discussed from a practical viewpoint in the medical literature; a thorough theoretical framework from an operational viewpoint is largely missing. In this study, we propose an approach that builds on multiple methods—partially observable Markov decision process (POMDP), hidden Markov model (HMM), and predictive risk modeling (PRM). It uses available clinical information, in the form of electronic health records (EHRs), on specific patient populations to derive an optimal policy, which is used to generate screening decisions, individualized for each patient. The POMDP model, used for determining optimal decisions, lies at the core of our approach. We use HMM to estimate the cohort-specific progression of diabetes (i.e., transition probability matrix) and the emission matrix. We use PRM to generate observations—in the form of individualized risk scores—for the POMDP. Both HMM and PRM are learned from EHR data. Our approach is unique because (i) it introduces a novel way of incorporating predictive modeling into a formal decision framework to derive an optimal screening policy; and (ii) it is based on real clinical data. We fit our model using data on a cohort of more than 60,000 patients over 5 years from a large safety-net health system and then demonstrate the model's utility by conducting a simulation study. The results indicate that our proposed screening policy outperforms existing guidelines widely used in clinical practice. Our estimates suggest that implementing our policy for the studied cohort would add one quality-adjusted life year for every patient, and at a cost that is 35% lower, compared with existing guidelines. Our proposed framework is generalizable to other chronic diseases, such as cancer and HIV.",
        "DOI": "10.1111/poms.13422",
        "affiliation_name": "Bobby B. Lyle School of Engineering",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Artificial intelligence and the fifth phase of political risk management: An application to regulatory expropriation",
        "paper_author": "Hemphill T.A.",
        "publication": "Thunderbird International Business Review",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "Using the context of regulatory expropriation, this article extends political risk management theories, forecasting methodologies (employing artificial intelligence, machine learning, and data analytics), and human intelligence evaluation tools useful for multinational enterprise executives in their planning and decision-making responsibilities. The article identifies three key areas where artificial intelligence will specifically assist managers in analyzing and mitigating risks: (a) earlier identification of risks, (b) precision in risk assessment, and (c) identification of unknown unknown risk correlations. These three categories also represent how artificial intelligence and its application to political risk assessment will evolve in the fifth phase of political risk management, and why it is of particular relevance to risks such as regulatory expropriation. Using the example of an oil exploration joint venture between Russian TNK and BP, and reflecting political and public policy indicators of regulatory expropriation, this political risk management framework and its hypothetical development are illustrated.",
        "DOI": "10.1002/tie.22222",
        "affiliation_name": "University of Michigan-Flint",
        "affiliation_city": "Flint",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting corporate policies using downside risk: A machine learning approach",
        "paper_author": "Avramov D.",
        "publication": "Journal of Empirical Finance",
        "citied_by": "2",
        "cover_date": "2021-09-01",
        "Abstract": "This paper develops a text-based downside risk measure using corporate annual reports and assesses its ability to forecast future corporate policies. The forward-looking measure dynamically captures adverse firm conditions evolving from economic fundamentals. When the measure is below its sample average, leverage, investment, R&D, employment, and dividends consistently fall. When the measure rises, firms increase cash holdings. The proposed measure also delivers robust and persistent forecasts based on in-sample and out-of-sample LASSO regressions.",
        "DOI": "10.1016/j.jempfin.2021.04.009",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Developing an integrated technology-environment-economics model to simulate food-energy-water systems in Corn Belt watersheds",
        "paper_author": "Li S.",
        "publication": "Environmental Modelling and Software",
        "citied_by": "27",
        "cover_date": "2021-09-01",
        "Abstract": "To facilitate understanding and decision making in the food-energy-water (FEW) nexus context, we develop an integrated technology-environment-economics model (ITEEM) at a watershed scale. ITEEM is built as an integration of various models, including models for grain processing, drinking water treatment, and wastewater treatment (technology); a watershed model for hydrology, water quality, crop production, and nutrient cycling (environment); an economics model assessing total benefit, including non-market valuation of environmental benefits. Different data techniques are applied to develop suitable surrogates for computer-based models, including a response matrix method, artificial neural networks, and lookup tables. Empirical equations are applied to develop models of economics and drinking water treatment. The input-output relationships between the models are formulated in a unified computational framework. ITEEM, a spatially semi-distributed dynamic simulation model, can be used to quantify the environmental and socioeconomic impacts of various management practices, technologies, and policy interventions on FEW systems in the Corn Belt.",
        "DOI": "10.1016/j.envsoft.2021.105083",
        "affiliation_name": "Department of Agricultural and Biological Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Behavioural patterns in aggregated demand response developments for communities targeting renewables",
        "paper_author": "Cruz C.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "22",
        "cover_date": "2021-09-01",
        "Abstract": "Encouraging consumers to embrace renewable energies and energy-efficient technologies is at stake, and so the energy players such as utilities and policy-makers are opening up a range of new value propositions towards more sustainable communities. For instance, developments of turn-key demand response aggregation and optimisation of distributed loads are rapidly emerging across the globe in a variety of business models focused on maximising the inherent flexibility and diversity of the behind-the-meter assets. However, even though these developments’ added value is understood and of wide interest, measurement of the desired levels of consumer engagement is still on demonstration stages and assessment of technology readiness. In this paper, we analyse the characteristics of the loads, the behaviour of parameters, and in a final extent, the behaviour of each kind of consumer participating in aggregated demand scheduling. We apply both non-automatic and machine learning methods to extract the relevant factors and to recognise the potential consumer behaviour on a series of scenarios that are drawn using both synthetic data and living labs datasets. Our experimentation showcases a number of three patterns in which factors like the community's demand volume and the consumer's flexibility dominate and impact the performance of the tested development. The experimentation also makes current limitations arise within the existing electricity consumption datasets and their potential for inference and forecasting demand flexibility analytics.",
        "DOI": "10.1016/j.scs.2021.103001",
        "affiliation_name": "Institute of Science Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Using process data to generate an optimal control policy via apprenticeship and reinforcement learning",
        "paper_author": "Mowbray M.",
        "publication": "AIChE Journal",
        "citied_by": "32",
        "cover_date": "2021-09-01",
        "Abstract": "Reinforcement learning (RL) is a data-driven approach to synthesizing an optimal control policy. A barrier to wide implementation of RL-based controllers is its data-hungry nature during online training and its inability to extract useful information from human operator and historical process operation data. Here, we present a two-step framework to resolve this challenge. First, we employ apprenticeship learning via inverse RL to analyze historical process data for synchronous identification of a reward function and parameterization of the control policy. This is conducted offline. Second, the parameterization is improved online efficiently under the ongoing process via RL within only a few iterations. Significant advantages of this framework include to allow for the hot-start of RL algorithms for process optimal control, and robust abstraction of existing controllers and control knowledge from data. The framework is demonstrated on three case studies, showing its potential for chemical process control.",
        "DOI": "10.1002/aic.17306",
        "affiliation_name": "Department of Chemical Engineering and Analytical Science",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Combining deep neural network and bibliometric indicator for emerging research topic prediction",
        "paper_author": "Liang Z.",
        "publication": "Information Processing and Management",
        "citied_by": "51",
        "cover_date": "2021-09-01",
        "Abstract": "Predicting emerging research topics is important to researchers and policymakers. In this study, we propose a two-step solution to the problem of emerging topic prediction. The first step forecasts the future popularity score, a novel indicator reflecting the impact and growth, of candidate topics in a time-series manner. The second step selects novel topics from the candidates predicted to be popular in the first step. Terms with domain characteristics are used as candidate topics. Deep neural networks, specifically LSTM and NNAR, are applied with nine features of topics to predict popularity score. We evaluated the models and five baselines on two datasets from two perspectives, i.e., the ability to (1) predict the correct indicator value and (2) reconstruct the optimal ranking order. Two types of training strategies were compared, including a global strategy that trains a model with all topics and two local strategies that train separate models with different groups of topics. Our results show that LSTM and NNAR outperform other models in predicting the value of popularity score measured by MAE and RMSE, while LightGBM is a competitive baseline in ranking the topics in terms of NDCG@20. The performance difference of global and local strategies is not significant. Emerging topics predicted by our approach are compared with those by other methods. A qualitative assessment on nominated emerging topics suggests topics nominated by machine learning methods are more alike than those by the rule-based model. Some important topics are nominated according to a preliminary literature analysis. This study exploited the strengths of both machine learning and bibliometric indicator approaches for emerging topic prediction. Deep neural networks are applied where objective optimization target can be defined and measured. Bibliometric indicator offers an efficient way to select novel topics from candidates. The hybrid approach shows promise in considering various characteristics of emerging topics when making predictions.",
        "DOI": "10.1016/j.ipm.2021.102611",
        "affiliation_name": "The University of Oklahoma",
        "affiliation_city": "Norman",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Escalation effect of fossil-based CO<inf>2</inf> emissions improves green energy innovation",
        "paper_author": "Sarkodie S.A.",
        "publication": "Science of the Total Environment",
        "citied_by": "31",
        "cover_date": "2021-09-01",
        "Abstract": "The 21st-century development pathway is facing a challenge between climate change mitigation, sustained economic prosperity, and energy security. While extant literature focuses on drivers of anthropogenic emissions, the role of policy measures including green energy innovation, and energy research and development are limited in scope. Here we develop conceptual tools across IEA member countries with four decades of data that demonstrate the role of green energy innovation, and research and development in reducing emissions. Our assessment reveals that sectoral fossil-based CO2 contributes directly to GHG emissions by 29.7–40.6% from transport, 24.6–32% from industry, 18.6–19.5% from buildings, 15–18.4% from other sectors, and 0.5–1.1% from power. We highlight that industrialized high-income countries converge on green energy innovation but diverge on emissions. The empirical evidence shows that achieving green growth is possible through green energy innovation amidst climate change and its impact.",
        "DOI": "10.1016/j.scitotenv.2021.147257",
        "affiliation_name": "Nord Universitet",
        "affiliation_city": "Bodo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Retraction notice: Fault diagnosis of heating systems using multivariate feature extraction based machine learning classifiers (Journal of Building Engineering (2020) 30, (S2352710219319527), (10.1016/j.jobe.2020.101221))",
        "paper_author": "NA",
        "publication": "Journal of Building Engineering",
        "citied_by": "0",
        "cover_date": "2021-09-01",
        "Abstract": "Retraction notice to <\"Fault diagnosis of heating systems using multivariate feature extraction based machine learning classifiers\"> <[Journal of Building Engineering 30 (2020) 101221]> <SondesGharsellaoui MajdiMansouri MohamedTrabelsi Shady S.Refaat HassaniMessaoud> < Electrical Engineering Department, Laboratory of Automatic Signal and Image Processing, National Higher Engineering School of Tunis, Monfleury, Tunisia. Electrical and Computer Engineering Program, Texas A&M University at Qatar, Doha, Qatar. Electronic and Communications Engineering Department, Kuwait College of Science and Technology, Kuwait. Laboratory of Automatic Signal and Image Processing, National Engineering School of Monastir, Monastir, Tunisia> This article has been retracted: please see Elsevier Policy on Article Withdrawal (https://www.elsevier.com/about/our-business/policies/article-withdrawal). <This article has been retracted at the request of the Editor-in-Chief The article duplicates significant parts of a paper that had already appeared in Gharsellaoui, S.; Mansouri, M.; Refaat, S.S.; Abu-Rub, H.; Messaoud, H. Multivariate Features Extraction and Effective Decision Making Using Machine Learning Approaches. Energies 2020, 13, 609. One of the conditions of submission of a paper for publication is that authors declare explicitly that the paper has not been previously published and is not under consideration for publication elsewhere. Re-use of any data should be appropriately cited. As such this article represents a misuse of the scientific publishing system. The scientific community takes a very strong view on this matter and apologies are offered to readers of the journal that this was not detected during the submission process.>",
        "DOI": "10.1016/j.jobe.2021.102382",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Increased ozone pollution alongside reduced nitrogen dioxide concentrations during Vienna's first COVID-19 lockdown: Significance for air quality management",
        "paper_author": "Brancher M.",
        "publication": "Environmental Pollution",
        "citied_by": "53",
        "cover_date": "2021-09-01",
        "Abstract": "Background: Lockdowns amid the COVID-19 pandemic have offered a real-world opportunity to better understand air quality responses to previously unseen anthropogenic emission reductions. Methods and main objective: This work examines the impact of Vienna's first lockdown on ground-level concentrations of nitrogen dioxide (NO2), ozone (O3) and total oxidant (Ox). The analysis runs over January to September 2020 and considers business as usual scenarios created with machine learning models to provide a baseline for robustly diagnosing lockdown-related air quality changes. Models were also developed to normalise the air pollutant time series, enabling facilitated intervention assessment. Core findings: NO2 concentrations were on average −20.1% [13.7–30.4%] lower during the lockdown. However, this benefit was offset by amplified O3 pollution of +8.5% [3.7–11.0%] in the same period. The consistency in the direction of change indicates that the NO2 reductions and O3 increases were ubiquitous over Vienna. Ox concentrations increased slightly by +4.3% [1.8–6.4%], suggesting that a significant part of the drops in NO2 was compensated by gains in O3. Accordingly, 82% of lockdown days with lowered NO2 were accompanied by 81% of days with amplified O3. The recovery shapes of the pollutant concentrations were depicted and discussed. The business as usual-related outcomes were broadly consistent with the patterns outlined by the normalised time series. These findings allowed to argue further that the detected changes in air quality were of anthropogenic and not of meteorological reason. Pollutant changes on the machine learning baseline revealed that the impact of the lockdown on urban air quality were lower than the raw measurements show. Besides, measured traffic drops in major Austrian roads were more significant for light-duty than for heavy-duty vehicles. It was also noted that the use of mobility reports based on cell phone movement as activity data can overestimate the reduction of emissions for the road transport sector, particularly for heavy-duty vehicles. As heavy-duty vehicles can make up a large fraction of the fleet emissions of nitrogen oxides, the change in the volume of these vehicles on the roads may be the main driver to explain the change in NO2 concentrations. Interpretation and implications: A probable future with emissions of volatile organic compounds (VOCs) dropping slower than emissions of nitrogen oxides could risk worsened urban O3 pollution under a VOC-limited photochemical regime. More holistic policies will be needed to achieve improved air quality levels across different regions and criteria pollutants.",
        "DOI": "10.1016/j.envpol.2021.117153",
        "affiliation_name": "Veterinarmedizinische Universitat Wien",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Synthesis of control Lyapunov functions and stabilizing feedback strategies using exit-time optimal control Part II: Numerical approach",
        "paper_author": "Yegorov I.",
        "publication": "Optimal Control Applications and Methods",
        "citied_by": "3",
        "cover_date": "2021-09-01",
        "Abstract": "This paper continues the study (Yegorov, Dower, and Grüne et al.) and develops a curse-of-dimensionality-free numerical approach to feedback stabilization, whose theoretical foundation was built in Yegorov et al. and involved the characterization of control Lyapunov functions (CLFs) via exit-time optimal control. First, we describe an auxiliary linearization-based technique for the construction of a local CLF and discuss how to determine its appropriate sublevel set that can serve as the terminal set in the exit-time optimal control problem leading to a global or semi-global CLF. Next, the curse of complexity is addressed with regard to the approximation of CLFs and associated feedback strategies in high-dimensional regions. The goal is to enable for efficient model predictive control implementations with essentially faster (though less accurate) online policy updates than in case of solving direct or characteristics-based nonlinear programming problems for each sample instant. We propose a computational approach that combines gradient enhanced modifications of the Kriging and inverse distance weighting frameworks for scattered grid interpolation. It in particular allows for convenient offline inclusion of new data to improve obtained approximations (machine learning can be used to select relevant new sparse grid nodes). Moreover, our method is designed so as to a priori return proper values of the CLF interpolant and its gradient on the entire terminal set of the considered exit-time optimal control problem. Supporting numerical simulation results are also presented.",
        "DOI": "10.1002/oca.2733",
        "affiliation_name": "Department of Electrical and Electronic Engineering",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A robust approach to deriving long-term daily surface NO<inf>2</inf> levels across China: Correction to substantial estimation bias in back-extrapolation",
        "paper_author": "Wu Y.",
        "publication": "Environment International",
        "citied_by": "29",
        "cover_date": "2021-09-01",
        "Abstract": "Background: Long-term surface NO2 data are essential for retrospective policy evaluation and chronic human exposure assessment. In the absence of NO2 observations for Mainland China before 2013, training a model with 2013–2018 data to make predictions for 2005–2012 (back-extrapolation) could cause substantial estimation bias due to concept drift. Objective: This study aims to correct the estimation bias in order to reconstruct the spatiotemporal distribution of daily surface NO2 levels across China during 2005–2018. Methods: On the basis of ground- and satellite-based data, we proposed the robust back-extrapolation with a random forest (RBE-RF) to simulate the surface NO2 through intermediate modeling of the scaling factors. For comparison purposes, we also employed a random forest (Base-RF), as a representative of the commonly used approach, to directly model the surface NO2 levels. Results: The validation against Taiwan's NO2 observations during 2005–2012 showed that RBE-RF adequately corrected the substantial underestimation by Base-RF. The RMSE decreased from 10.1 to 8.2 µg/m3, 7.1 to 4.3 µg/m3, and 6.1 to 2.9 µg/m3 in predicting daily, monthly, and annual levels, respectively. For North China with the most severe pollution, the population-weighted NO2 ([NO2]pw) during 2005–2012 was estimated as 40.2 and 50.9 µg/m3 by Base-RF and RBE-RF, respectively, i.e., 21.0% difference. While both models predicted that the national annual [NO2]pw increased during 2005–2011 and then decreased, the interannual trends were underestimated by >50.2% by Base-RF relative to RBE-RF. During 2005–2018, the nationwide population that lived in the areas with NO2 > 40 µg/m3 were estimated as 259 and 460 million by Base-RF and RBE-RF, respectively. Conclusion: With RBE-RF, we corrected the estimation bias in back-extrapolation and obtained a full-coverage dataset of daily surface NO2 across China during 2005–2018, which is valuable for environmental management and epidemiological research.",
        "DOI": "10.1016/j.envint.2021.106576",
        "affiliation_name": "Zhejiang Academy of Agricultural Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting cell phone adoption metrics using machine learning and satellite imagery",
        "paper_author": "Oughton E.J.",
        "publication": "Telematics and Informatics",
        "citied_by": "8",
        "cover_date": "2021-09-01",
        "Abstract": "Approximately half of the global population does not have access to the internet, even though digital connectivity can reduce poverty by revolutionizing economic development opportunities. Due to a lack of data, Mobile Network Operators and governments struggle to effectively determine if infrastructure investments are viable, especially in greenfield areas where demand is unknown. This leads to a lack of investment in network infrastructure, resulting in a phenomenon commonly referred to as the ‘digital divide’. In this paper we present a machine learning method that uses publicly available satellite imagery to predict telecoms demand metrics, including cell phone adoption and spending on mobile services, and apply the method to Malawi and Ethiopia. Our predictive machine learning approach consistently outperforms baseline models which use population density or nightlight luminosity, with an improvement in data variance prediction of at least 40%. The method is a starting point for developing more sophisticated predictive models of infrastructure demand using machine learning and publicly available satellite imagery. The evidence produced can help to better inform infrastructure investment and policy decisions.",
        "DOI": "10.1016/j.tele.2021.101622",
        "affiliation_name": "Siebel School of Computing and Data Science",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A hybrid econometric–machine learning approach for relative importance analysis: prioritizing food policy",
        "paper_author": "Malhotra A.",
        "publication": "Eurasian Economic Review",
        "citied_by": "7",
        "cover_date": "2021-09-01",
        "Abstract": "A measure of relative importance of variables is often desired by researchers when the explanatory aspects of econometric methods are of interest. To this end, the author briefly reviews the limitations of conventional econometrics in constructing a reliable measure of variable importance. The author highlights the relative stature of explanatory and predictive analysis in economics and the emergence of fruitful collaborations between econometrics and computer science. Learning lessons from both, the author proposes a hybrid approach based on conventional econometrics and advanced machine learning (ML) algorithms, which are otherwise, used in predictive analytics. The purpose of this article is two-fold: to propose a hybrid approach to assess relative importance and demonstrate its applicability in addressing policy priority issues with an example of food inflation in India, followed by a broader aim to introduce the possibility of conflation of ML and conventional econometrics to an audience of researchers in economics and social sciences, in general.",
        "DOI": "10.1007/s40822-021-00170-9",
        "affiliation_name": "Jawaharlal Nehru University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Artificial Intelligence and Liability in Medicine: Balancing Safety and Innovation",
        "paper_author": "Maliha G.",
        "publication": "Milbank Quarterly",
        "citied_by": "74",
        "cover_date": "2021-09-01",
        "Abstract": "Policy Points With increasing integration of artificial intelligence and machine learning in medicine, there are concerns that algorithm inaccuracy could lead to patient injury and medical liability. While prior work has focused on medical malpractice, the artificial intelligence ecosystem consists of multiple stakeholders beyond clinicians. Current liability frameworks are inadequate to encourage both safe clinical implementation and disruptive innovation of artificial intelligence. Several policy options could ensure a more balanced liability system, including altering the standard of care, insurance, indemnification, special/no-fault adjudication systems, and regulation. Such liability frameworks could facilitate safe and expedient implementation of artificial intelligence and machine learning in clinical care.",
        "DOI": "10.1111/1468-0009.12504",
        "affiliation_name": "Harvard Law School",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Performance of linear mixed models and random forests for spatial prediction of soil pH",
        "paper_author": "Makungwe M.",
        "publication": "Geoderma",
        "citied_by": "41",
        "cover_date": "2021-09-01",
        "Abstract": "Digital soil maps describe the spatial variation of soil and provide important information on spatial variation of soil properties which provides policy makers with a synoptic view of the state of the soil. This paper presents a study to tackle the task of how to map the spatial variation of soil pH across Zambia. This was part of a project to assess suitability for rice production across the country. Legacy data on the target variable were available along with additional exhaustive environmental covariates as potential predictor variables. We had the option of undertaking spatial prediction by geostatistical or machine learning methods. We set out to compare the approaches from the selection of predictor variables through to model validation, and to test the predictors on a set of validation observations. We also addressed the problem of how to robustly validate models from legacy data when these have, as is often the case, a strongly clustered spatial distribution. The validation statistics results showed that the empirical best linear unbiased predictor (EBLUP) with the only fixed effect a constant mean (ordinary kriging) performed better than the other methods. Random forests had the largest model-based estimates of the expected squared errors. We also noticed that the random forest algorithm was prone to select as “important” spatially correlated random variables which we had simulated.",
        "DOI": "10.1016/j.geoderma.2021.115079",
        "affiliation_name": "University of Zambia",
        "affiliation_city": "Lusaka",
        "affiliation_country": "Zambia"
    },
    {
        "paper_title": "Machine-Learning-Based Real-Time Economic Dispatch in Islanding Microgrids in a Cloud-Edge Computing Environment",
        "paper_author": "Dong W.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "47",
        "cover_date": "2021-09-01",
        "Abstract": "The paradigm of the Internet of Things (IoT) and cloud-edge computing plays a significant role in future smart grids. The data-driven solution integrating the artificial intelligence functionalities brings novel methods to address the nontrivial task of economic dispatch in microgrids in the presence of uncertainties of renewable generations and loads. This article proposes a learning-based decision-making framework for the economic energy dispatch of an islanding microgrid based on the cloud-edge computing architecture. Cloud resources are utilized to solve the optimal dispatch decision sequences over historical operating patterns. It can be considered as a sample labeling process for the supervised training that can implement the complex mapping of input-output space through an advanced machine learning model. Then, the well-trained model can be adopted locally at edge computing devices keeping the long-term parameters unchanged for implement the real-time microgrid energy dispatch. The key benefit of the proposed solution is that it effectively avoids the prediction of multiple stochastic variables and the design of sophisticated regulation strategies or reward policy functions for real-time dispatch. The solution is extensively assessed through simulation experiments by the use of real data measurements for a set of operational scenarios and the numerical results validate the effectiveness and benefit of the proposed algorithmic solution.",
        "DOI": "10.1109/JIOT.2021.3067951",
        "affiliation_name": "Zhejiang Lab",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A power and thermal-aware virtual machine management framework based on machine learning",
        "paper_author": "Xiao P.",
        "publication": "Cluster Computing",
        "citied_by": "22",
        "cover_date": "2021-09-01",
        "Abstract": "Energy consumption in data centers grows rapidly in recent years. As a widely-applied energy-efficient method, workload consolidation also has its own limitations that may bring some negative effects, such as performance degradation, QoS violation, localized hotspots and so on, which is especially true when optimal objectives are inherently conflict. In this paper, we present a power and thermal-aware VM management framework called PTM-ML, which relies on machine learning technique to find optimal host configuration based on workload characteristics and cooling system’s working state. Based on such an optimal host configuration, it then makes VM migration and consolidation decisions by enforcing an efficient load-balancing policy, with aiming at achieving a better trade-off between energy efficiency and performance. The prototype of PTM-ML framework is deployed and evaluated in a real-world cloud data center. Extensive experiments are conducted by using different workload traces with distinctive characteristics, and the results are compared with four similar approaches in terms of total energy consumption, real-time power consumption, average latency and etc. Experimental results show that the proposed PTM-ML outperforms the existing approaches in terms of multiple metrics, and it also exhibits better robustness and adaptability in presence of dynamic workloads.",
        "DOI": "10.1007/s10586-020-03228-6",
        "affiliation_name": "Hunan Institute of Engineering",
        "affiliation_city": "Xiangtan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Supporting Sustainable Virtual Network Mutations with Mystique",
        "paper_author": "Sacco A.",
        "publication": "IEEE Transactions on Network and Service Management",
        "citied_by": "9",
        "cover_date": "2021-09-01",
        "Abstract": "The abiding attempt of automation has also permeated the networks, with the ability to measure, analyze, and control themselves in an automated manner, by reacting to changes in the environment (e.g., demand). When provided with these features, networks are often labeled as 'self-driving' or 'autonomous'. In this regard, the provision and orchestration of physical or virtual resources are crucial for both Quality of Service (QoS) guarantees and cost management in the edge/cloud computing environment. To effectively manage the lifecycle of these resources, an auto-scaling mechanism is essential. However, traditional threshold-based and recent Machine Learning (ML)-based policies are often unable to address the soaring complexity of networks due to their centralized approach. By relying on multi-agent reinforcement learning, we propose Mystique, a solution that learns from the load on links to establish the minimal set of active network resources. As traffic demands ebb and flow, our adaptive and self-driving solution can scale up and down and also react to failures in a fully automated, flexible, and efficient manner. Our results demonstrate that the presented solution can reduce network energy consumption while providing an adequate service level, outperforming other benchmark auto-scaling approaches.",
        "DOI": "10.1109/TNSM.2021.3059647",
        "affiliation_name": "Saint Louis University School of Science and Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A machine learning-based branch and price algorithm for a sampled vehicle routing problem",
        "paper_author": "Furian N.",
        "publication": "OR Spectrum",
        "citied_by": "25",
        "cover_date": "2021-09-01",
        "Abstract": "Planning of operations, such as routing of vehicles, is often performed repetitively in rea-world settings, either by humans or algorithms solving mathematical problems. While humans build experience over multiple executions of such planning tasks and are able to recognize common patterns in different problem instances, classical optimization algorithms solve every instance independently. Machine learning (ML) can be seen as a computational counterpart to the human ability to recognize patterns based on experience. We consider variants of the classical Vehicle Routing Problem with Time Windows and Capacitated Vehicle Routing Problem, which are based on the assumption that problem instances follow specific common patterns. For this problem, we propose a ML-based branch and price framework which explicitly utilizes those patterns. In this context, the ML models are used in two ways: (a) to predict the value of binary decision variables in the optimal solution and (b) to predict branching scores for fractional variables based on full strong branching. The prediction of decision variables is then integrated in a node selection policy, while a predicted branching score is used within a variable selection policy. These ML-based approaches for node and variable selection are integrated in a reliability-based branching algorithm that assesses their quality and allows for replacing ML approaches by other (classical) better performing approaches at the level of specific variables in each specific instance. Computational results show that our algorithms outperform benchmark branching strategies. Further, we demonstrate that our approach is robust with respect to small changes in instance sizes.",
        "DOI": "10.1007/s00291-020-00615-8",
        "affiliation_name": "Technische Universitat Graz",
        "affiliation_city": "Graz",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Evaluation of the environmental impacts of urbanization from the viewpoint of increased skin temperatures: a case study from Istanbul, Turkey",
        "paper_author": "Khorrami B.",
        "publication": "Applied Geomatics",
        "citied_by": "10",
        "cover_date": "2021-09-01",
        "Abstract": "Urbanization is an inevitable process all around the world especially in developing countries like Turkey. Istanbul has been experiencing rapid urban expansion for the past 60 years. This urban expansion is leading to the replacement of forests by various artificial surfaces. This situation has a critical impact on the natural surfaces due to the alteration of heat energy balance. In this study, the authors tried to investigate the extent of urbanization of Istanbul within the past decades to unearth its impacts on the urban heat island (UHI) severity and the level of its ecological consequences in terms of decreased thermal comfort. To this end, land use/cover (LULC) and land surface temperature (LST) maps were generated using Landsat imageries based on random forest (RF) classifier (as a machine learning tool) and radiometric image processing algorithms, respectively, for four different dates from 1989 to 2019. The statistical and spectral indicators were calculated for the study area to evaluate the association between urban development and UHI. Results indicate that Istanbul has suffered a continuous land transformation from forest to urban and croplands so that the area of forest has diminished by 373.3 km2, and the artificial surfaces have increased by 260 km2. Skin temperatures over all the LULC classes show an increase during the study period with the highest values estimated over artificial surfaces. The statistical analysis of urbanization indicators (ULI, PD, UGSI, NDVI, and NDBI) and UHI indicator (UTFVI) resulted in good correlation coefficients with the best agreement found between NDBI and UTFVI which stresses the strong link between the expansion of built-up areas as a result of urbanization and the severity of UHI and its ecological impacts in Istanbul. Thus, it is a must for policy-makers and officials of the city to take accurate measures regarding the urban planning to mitigate the harsh environmental impacts of growing urbanization of Istanbul in upcoming years.",
        "DOI": "10.1007/s12518-020-00350-3",
        "affiliation_name": "Dokuz Eylül Üniversitesi",
        "affiliation_city": "Izmir",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Learning chordal extensions",
        "paper_author": "Liu D.",
        "publication": "Journal of Global Optimization",
        "citied_by": "6",
        "cover_date": "2021-09-01",
        "Abstract": "A highly influential ingredient of many techniques designed to exploit sparsity in numerical optimization is the so-called chordal extension of a graph representation of the optimization problem. The definitive relation between chordal extension and the performance of the optimization algorithm that uses the extension is not a mathematically understood task. For this reason, we follow the current research trend of looking at Combinatorial Optimization tasks by using a Machine Learning lens, and we devise a framework for learning elimination rules yielding high-quality chordal extensions. As a first building block of the learning framework, we propose an imitation learning scheme that mimics the elimination ordering provided by an expert rule. Results show that our imitation learning approach is effective in learning two classical elimination rules: the minimum degree and minimum fill-in heuristics, using simple Graph Neural Network models with only a handful of parameters. Moreover, the learned policies display remarkable generalization performance, across both graphs of larger size, and graphs from a different distribution.",
        "DOI": "10.1007/s10898-020-00973-1",
        "affiliation_name": "Polytechnique Montréal",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "MLPAM: A Machine Learning and Probabilistic Analysis Based Model for Preserving Security and Privacy in Cloud Environment",
        "paper_author": "Gupta I.",
        "publication": "IEEE Systems Journal",
        "citied_by": "40",
        "cover_date": "2021-09-01",
        "Abstract": "The organizational valuable data needs to be shared with multiple parties and stakeholders in a cloud environment for storage, analysis, and data utilization. However, to ensure the security, preserve privacy while sharing the data effectively among various parties have become formidable challenges. In this article, by utilizing encryption, machine learning, and probabilistic approaches, we propose a novel model that supports multiple participants to securely share their data for distinct purposes. The model defines the access policy and communication protocol among the involved multiple untrusted parties to process the owners' data. The proposedmodel minimizes the risk associated with the leakage by providing a robust mechanism for prevention coupled with detection. The experimental results demonstrate the efficiency of the proposed model for different classifiers over various datasets. The proposed model ensures high accuracy and precision up to97%and 100%relatively and secures a significant improvement up to 0.01%, 103%, 151%, 87%, 96%, 43%, and 186% for average probability, average success rate, detection rate, accuracy, precision, recall, and specificity, respectively, compared to the prior works that prove its effectiveness.",
        "DOI": "10.1109/JSYST.2020.3035666",
        "affiliation_name": "School of Computing and Information Systems",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Public opinion mining using natural language processing technique for improvisation towards smart city",
        "paper_author": "Leelavathy S.",
        "publication": "International Journal of Speech Technology",
        "citied_by": "13",
        "cover_date": "2021-09-01",
        "Abstract": "In this digital world integrating smart city concepts, there is a tremendous scope and need for e-governance applications. Now people analyze the opinion of others before purchasing any product, hotel booking, stepping onto restaurants etc. and the respective user share their experience as a feedback towards the service. But there is no e-governance platform to obtain public opinion grievances towards covid19, government new laws, policies etc. With the growing availability and emergence of opinion rich information’s, new opportunities and challenges might arise in developing a technology for mining the huge set of public messages, opinions and alert the respective departments to take necessary actions and also nearby ambulances if its related to covid-19. To overcome this pandemic situation a natural language processing based efficient e-governance platform is demandful to detect the corona positive patients and provide transparency on the covid count and also alert the respective health ministry and nearby ambulance based on the user voice inputs. To convert the public voice messages into text, we used Hidden Markov Models (HMMs). To identify respective government department responsible for the respective user voice input, we perform pre-processing, part of speech, unigram, bigram, trigram analysis and fuzzy logic (machine learning technique). After identifying the responsible department, we perform 2 methods, (1) Automatic alert e-mail and message to the government departmental officials and nearby ambulance or covid camp if the user input is related to covis19. (2) Ticketing system for public and government officials monitoring. For experimental results, we used Java based web and mobile application to execute the proposed methodology. Integration of HMM, Fuzzy logic provides promising results.",
        "DOI": "10.1007/s10772-020-09766-z",
        "affiliation_name": "Aarupadai Veedu Institute of Technology",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Using deep learning to examine the correlation between transportation planning and perceived safety of the built environment",
        "paper_author": "Hollander J.B.",
        "publication": "Environment and Planning B: Urban Analytics and City Science",
        "citied_by": "8",
        "cover_date": "2021-09-01",
        "Abstract": "In this study, we attempt to estimate the effects of various transportation policies on the perceived safety of the built environment. We train a convolutional neural network on a dataset of safety perception scores for Google Street View images taken in Boston, MA. We then apply the trained neural network to a large set of Google Street View images of coordinates in Montreal and Toronto to generate their respective safety perception scores. We estimate probit, logit, and ordinary least squares regression models using our cross-sectional dataset consisting of safety perception scores, as well as transportation policy variables and a set of control variables, by regressing the safety perception scores on the remaining set of variables. We answer our research question by observing the direction, magnitude, and statistical significance of the coefficient estimates associated with the policy variables across all regression models. We studied and cataloged transportation policies planned for over the past 10 years in both cities. We found that those census tracts with the poorest safety scores were the same places where planners focused their transportation investments. The study makes an important contribution to transportation planning methodologies by drawing on the novel data source of Google Street View images, to understand the safety of an area.",
        "DOI": "10.1177/2399808320959079",
        "affiliation_name": "Tufts University",
        "affiliation_city": "Medford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "On the relationship between transportation infrastructure and economic development in China",
        "paper_author": "Magazzino C.",
        "publication": "Research in Transportation Economics",
        "citied_by": "94",
        "cover_date": "2021-09-01",
        "Abstract": "This paper aims to explore the impact of transportation infrastructure on economic growth in China at different levels: aggregate and regional. Using a time series approach and panel data for 28 regions (where there are provinces also) over the time 1990–2017, the experimental findings confirms the economic theory of development choices. Although other studies have addressed this problem with the same data, our contribution has been to combine the aggregated results with the regional ones for policy analysis. In addition, we combine a Machine Learning technique capable of verifying causality through a supervised and an econometric approach. The results show that the contribution to the growth of transport investments is different from region to region, but we have highlighted how transport affects economic growth at the aggregate level. However, the lack of infrastructure maintenance eliminates the positive effects of investments over time in the medium term.",
        "DOI": "10.1016/j.retrec.2020.100947",
        "affiliation_name": "Università degli Studi di Teramo",
        "affiliation_city": "Teramo",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Demographics as determinants of social security",
        "paper_author": "Chen J.M.",
        "publication": "Debt in Times of Crisis: Does Economic Crisis Really Impact Debt?",
        "citied_by": "0",
        "cover_date": "2021-08-27",
        "Abstract": "Population demographics have been long debated as factors that influence the capacity of countries to manage their debt levels. Drops in fertility and replacement rate can endanger the viability of a country's social security system. Reproductive declines pose a particular threat to pension plans. In some cases, declines in population can increase the burden borne by the state. Employing a series of econometric models and machine learning techniques, we find evidence that population, age dependency ratio, fertility rate, migration and unemployment determine the level of social security benefits. These relationships depend on the model and the proxy used to measure the level of social security or pension benefits. Machine learning models tend to assign more weight to governmental policies. All else being equal, machine learning models find, that countries offering generous health and social benefits also fund pensions generously, and vice versa.",
        "DOI": "10.1007/978-3-030-74162-4_5",
        "affiliation_name": "Michigan State University",
        "affiliation_city": "East Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The impact of demographics on the level of tariffs",
        "paper_author": "Chen J.M.",
        "publication": "Debt in Times of Crisis: Does Economic Crisis Really Impact Debt?",
        "citied_by": "0",
        "cover_date": "2021-08-27",
        "Abstract": "Demography almost surely affects the ability of countries to manage their debt levels as part of their overall macroeconomic policy. By the same token, the demographic attributes of labor influence political decisions among nation-states, including international trade policy. In particular, the free movement of labor is a bedrock principle of the European Union and a reason to join it or withdraw from it. This study investigates the influence of (labor) demographics on tariffs in 45 OECD and non-OECD countries. Through a series of econometric models and machine learning techniques we find evidence that the population and labor force may influence the level of tariffs, depending on the model and the database. By contrast, migration does not. Income per capita and consumption affect the tariff rate as well. Machine learning methods confirm conclusions reached through conventional econometrics and shed further light on the relationship between tariff levels and their hypothesized predictors.",
        "DOI": "10.1007/978-3-030-74162-4_4",
        "affiliation_name": "Michigan State University",
        "affiliation_city": "East Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Medium and Short Term Energy Forecasting using LSTM Neural Network Method for Gujarat State",
        "paper_author": "Doshi R.",
        "publication": "2021 Asian Conference on Innovation in Technology, ASIANCON 2021",
        "citied_by": "4",
        "cover_date": "2021-08-27",
        "Abstract": "A stable power system requires balance between generation and demand. The power system under World Bank initiative has restructured in majority of countries throughout the world. Implementation of Availability based tariff (ABT) and establishment of Energy exchange, congestion in network etc. has made it necessary to forecast the load condition accurately. Load forecasting is required to be performed for different of timespan, i.e. short, medium and long term. Some machine learning based approaches were used in recent past to address this problem, however taking in account of the dependencies of load demands on load density, city and industrial plants, local and global policies there is scope of forecasting precision. This paper proposes a deep learning based neural network architecture, i.e., Long-short memory term (LSTM) neural network for energy forecasting in short and medium term with the collected dataset from State Load Dispatch Centre (SLDC), Amreli, Gujarat. The dataset includes three months (May-July 2014) of energy consumption at hourly basis. Short-term as for the next 24 hours and medium-term forecasting for over 9 days are performed with root mean squared error 88.05 and 87.97 MW, respectively. Furthermore, forecasting is also performed for holidays, preholiday and post-holiday periods which exhibited even less RMSE.",
        "DOI": "10.1109/ASIANCON51346.2021.9544812",
        "affiliation_name": "Marwadi University",
        "affiliation_city": "Rajkot",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Tale of Two Cities: COVID-19 and the Emotional Well-Being of Student-Athletes Using Natural Language Processing",
        "paper_author": "Floyd C.",
        "publication": "Frontiers in Sports and Active Living",
        "citied_by": "7",
        "cover_date": "2021-08-25",
        "Abstract": "Student-athletes at the Division I institutions face a slew of challenges and stressors that can have negative impacts in eliciting different emotional responses during the COVID-19 pandemic. We employed machine-learning-based natural language processing techniques to analyze the user-generated content posted on Twitter of Atlantic Coast Conference (ACC) student-athletes to study changes in their sentiment as it relates to the COVID-19 crisis, major societal events, and policy decisions. Our analysis found that positive sentiment slightly outweighed negative sentiment overall, but that there was a noticeable uptick in negative sentiment in May and June 2020 in conjunction with the Black Lives Matter protests. The most commonly expressed emotions by these athletes were joy, trust, anticipation, and fear, suggesting that they used social media as an outlet to share primarily optimistic sentiments, while still publicly expressing strong negative sentiments like fear and trepidation about the pandemic and other important contemporary events. Athletic administrators, ACC coaches, support staff, and other professionals can use findings like these to guide sound, evidence-based decision-making and to better track and promote the emotional wellness of student-athletes.",
        "DOI": "10.3389/fspor.2021.710289",
        "affiliation_name": "Florida State University",
        "affiliation_city": "Tallahassee",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Intelligent OpenRAN orchestration assisted by a Reinforcement Learning Resource Management policy",
        "paper_author": "Silveira W.",
        "publication": "2021 2nd Sustainable Cities Latin America Conference, SCLA 2021",
        "citied_by": "3",
        "cover_date": "2021-08-25",
        "Abstract": "Efficiently orchestrating resources in a Radio Access Network poses a challenging task, which has been made even more difficult by the addition of vertical slices of operation with very unrelated requirements in 5G and Beyond 5G. The proposal of an open and interoperable standard by the Open Radio Access alliance has paved the path to foment research and development of innovative solutions. As a result, the solution herein presented employs a Machine Learning algorithm of Reinforcement Learning to deal with the multiple slices requirements in a unified approach based on a resource management policy. The simulation results showed a consistent response of the Machine Learning model to wisely administrate the available resources to maximize the potential of the User Equipment requirements attainment.",
        "DOI": "10.1109/SCLA53004.2021.9540164",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Reinforcement Learning to Improve Image-Guidance of Ablation Therapy for Atrial Fibrillation",
        "paper_author": "Muizniece L.",
        "publication": "Frontiers in Physiology",
        "citied_by": "6",
        "cover_date": "2021-08-25",
        "Abstract": "Atrial fibrillation (AF) is the most common cardiac arrhythmia and currently affects more than 650,000 people in the United Kingdom alone. Catheter ablation (CA) is the only AF treatment with a long-term curative effect as it involves destroying arrhythmogenic tissue in the atria. However, its success rate is suboptimal, approximately 50% after a 2-year follow-up, and this high AF recurrence rate warrants significant improvements. Image-guidance of CA procedures have shown clinical promise, enabling the identification of key patient anatomical and pathological (such as fibrosis) features of atrial tissue, which require ablation. However, the latter approach still suffers from a lack of functional information and the need to interpret structures in the images by a clinician. Deep learning plays an increasingly important role in biomedicine, facilitating efficient diagnosis and treatment of clinical problems. This study applies deep reinforcement learning in combination with patient imaging (to provide structural information of the atria) and image-based modelling (to provide functional information) to design patient-specific CA strategies to guide clinicians and improve treatment success rates. To achieve this, patient-specific 2D left atrial (LA) models were derived from late-gadolinium enhancement (LGE) MRI scans of AF patients and were used to simulate patient-specific AF scenarios. Then a reinforcement Q-learning algorithm was created, where an ablating agent moved around the 2D LA, applying CA lesions to terminate AF and learning through feedback imposed by a reward policy. The agent achieved 84% success rate in terminating AF during training and 72% success rate in testing. Finally, AF recurrence rate was measured by attempting to re-initiate AF in the 2D atrial models after CA with 11% recurrence showing a great improvement on the existing therapies. Thus, reinforcement Q-learning algorithms can predict successful CA strategies from patient MRI data and help to improve the patient-specific guidance of CA therapy.",
        "DOI": "10.3389/fphys.2021.733139",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Predicting environmental risk factors in relation to health outcomes among school children from Romania using random forest model - An analysis of data from the SINPHONIE project",
        "paper_author": "Lin Z.",
        "publication": "Science of the Total Environment",
        "citied_by": "12",
        "cover_date": "2021-08-25",
        "Abstract": "Background: Few studies have simultaneously assessed the health impact of school and home environmental factors on children, since handling multiple highly correlated environmental variables is challenging. In this study, we examined indoor home and school environments in relation to health outcomes using machine learning methods and logistic regression. Methods: We used the data collected by the SINPHONIE (Schools Indoor Pollution and Health: Observatory Network in Europe) project in Romania, a multicenter European research study that collected comprehensive information on school and home environments, health symptoms in children, smoking, and school policies. The health outcomes were categorized as: any health symptoms, asthma, allergy and flu-like symptoms. Both logistic regression and random forest (RF) methods were used to predict the four categories of health outcomes, and the methods prediction performance was compared. Results: The RF method we employed for analysis showed that common risk factors for the investigated categories of health outcomes, included: environmental tobacco smoke (ETS), dampness in the indoor school environment, male gender, air freshener use, residence located in proximity of traffic (<200 m), stressful schoolwork, and classroom noise (contributions ranged from 7.91% to 23.12%). Specificity, accuracy and area under the curve (AUC) values for most outcomes were higher when using RF compared to logistic regression, while sensitivity was similar in both methods. Conclusion: This study suggests that ETS, dampness in the indoor school environment, use of air fresheners, living in proximity to traffic (<200 m) and noise are common environmental risk factors for the investigated health outcomes. RF pointed out better predictive values, sensitivity and accuracy compared to logistic regression.",
        "DOI": "10.1016/j.scitotenv.2021.147145",
        "affiliation_name": "School of Public Health",
        "affiliation_city": "Rensselaer",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "SSD model selection method based on machine learning algorithm",
        "paper_author": "Yang B.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "3",
        "cover_date": "2021-08-24",
        "Abstract": "The chemical pollutants produced by human activities often lead to the risk of ecological species diversity destruction by affecting the physiological activities of organisms in nature. Ecological risk assessment (ERA) can be used to evaluate the degree of adverse effects of external factors on the ecological environment, provide the basis for taking effective ecological protection measures and formulating reasonable environmental policies, and also an important means to understand the possible adverse effects of ecological health and pollutants on the ecological environment. The species sensitivity distribution (SSD) method is a widely used evaluation method, and its core step is to select the appropriate species toxicity data for curve fitting. In this paper, the basic concept of ecological risk assessment is briefly introduced, and the basic principle and implementation steps of species sensitivity distribution method are described in detail. Aiming at the problem of SSD model selection in water environment, machine learning algorithm is introduced, and corresponding neural network is constructed. Taking the root mean square (RMSE) and sum of squared error (SSE) were as the index, the optimal SSD model suitable for water environment is determined, The SSD model selection method based on machine learning algorithm is obtained. At last, the application of machine learning algorithm in SSD model selection is prospected, and the shortcomings of the existing research and the future research direction are pointed out.",
        "DOI": "10.1088/1742-6596/2005/1/012082",
        "affiliation_name": "Guizhou Academy of Sciences",
        "affiliation_city": "Guizhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Modern labor economics: Theory and public policy",
        "paper_author": "Ehrenberg R.G.",
        "publication": "Modern Labor Economics: Theory and Public Policy",
        "citied_by": "20",
        "cover_date": "2021-08-23",
        "Abstract": "Modern Labor Economics: Theory and Public Policy, now in its fourteenth edition, continues to be the leading text for one-semester courses in labor economics at the undergraduate and graduate levels. It offers a thorough overview of the modern theory of labor market behavior and reveals how this theory is used to analyze public policy. Designed for students who may not have extensive backgrounds in economics, the text balances theoretical coverage with examples of practical applications that allow students to see concepts in action. The authors believe that showing students the social implications of the concepts discussed in the course will enhance their motivation to learn. Consequently, this text presents numerous examples of policy decisions that have been affected by the ever-shifting labor market. This new edition continues to offer the following: a balance of relevant, contemporary examples coverage of the current economic climate an introduction to basic methodological techniques and problems tools for review and further study This fourteenth edition presents updated data throughout and a wealth of new examples, such as the impact of COVID-19 lockdowns, gig work, nudges, monopsony power in the technology industry, and the effect of machine learning on inequality. Supplementary materials for students and instructors are available on the book's companion website.",
        "DOI": "10.4324/9780429327209",
        "affiliation_name": "University of Richmond",
        "affiliation_city": "Richmond",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Grasp Planning for Flexible Production with Small Lot Sizes based on CAD models using GPIS and Bayesian Optimization",
        "paper_author": "Lin J.",
        "publication": "IEEE International Conference on Automation Science and Engineering",
        "citied_by": "0",
        "cover_date": "2021-08-23",
        "Abstract": "Grasp planning for multi-fingered hands is still challenging due to the high nonlinear quality metrics, the high dimensionality of hand posture configuration, and complex object shapes. Analytical-based grasp planning algorithms formulate the grasping problem as a constraint optimization problem using advanced convex optimization solvers. However, these are not guaranteed to find a globally optimal solution. Data-driven based algorithms utilize machine learning algorithm frameworks to learn the grasp policy using enormous training data sets. This paper presents a new approach for grasp generation by formulating a global optimization problem with Bayesian optimization. Furthermore, we parameterize the object shape utilizing the Gaussian Process Implicit Surface (GPIS) to integrate the object shape information into the optimization process. Moreover, a chart defined on the object surface is used to refine the palm pose locally. We introduced a dual optimization stage to optimize the palm pose and contact points separately. We further extend the Bayesian optimization by utilizing the alternating direction method of multipliers (ADMM) to eliminate contact optimization constraints. We conduct the experiments in the graspit! Simulator that demonstrates the effectiveness of this approach quantitatively and qualitatively. Our approach achieves a 95% success rate on various common objects with diverse shapes, scales, and weights.",
        "DOI": "10.1109/CASE49439.2021.9551451",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Selecting Part Feeding Policies with a Combined Optimization-Machine Learning Approach",
        "paper_author": "Moretti E.",
        "publication": "IEEE International Conference on Automation Science and Engineering",
        "citied_by": "0",
        "cover_date": "2021-08-23",
        "Abstract": "In several industries, increasing attention is being devoted to the design and management of part feeding systems. This paper applies a combined optimization-machine learning (ML) approach for part feeding policies selection to the case of a truck assembly plant. According to this approach, feeding policies are selected through a ML model, trained using the output of an optimization model previously applied to a sample of parts. Results show that this approach leads to results close to the optimal ones, as the developed ML models are able to estimate the optimal policies for most of the parts.",
        "DOI": "10.1109/CASE49439.2021.9551570",
        "affiliation_name": "Universiteit Gent",
        "affiliation_city": "Ghent",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Adversarial Trajectories Generation for Automotive Applications",
        "paper_author": "Turlej W.",
        "publication": "2021 25th International Conference on Methods and Models in Automation and Robotics, MMAR 2021",
        "citied_by": "1",
        "cover_date": "2021-08-23",
        "Abstract": "The development of Advanced Driver Assistance Systems (ADAS) with a high level of autonomy requires immense testing efforts to ensure the safety and robustness of developed algorithms in critical situations. Unfortunately, exploration of difficult situations through test drives in natural traffic is ineffective due to the rarity of such events. While scenario-based testing in a virtual environment is often proposed as an effective method that helps to evaluate system performance in difficult situations, the manual definition of virtual test scenarios poses a significant challenge itself. Performance drops in tested systems, especially ones containing machine learning components, may be related to situations that are not necessarily considered challenging for a human driver and thus are difficult to predict in a test design. In this paper, we propose a method that allows to generate a variety of virtual test scenarios for ADAS through an adversarial trajectories generation. The method generates scenarios by finding trajectories of the road users in the proximity of the vehicle controlled by the tested algorithm that result in safety-critical events, such as collisions. We demonstrate the effectiveness of the presented method on an example of a critical scenario generation for a vehicle control policy based on Reinforcement Learning methods.",
        "DOI": "10.1109/MMAR49549.2021.9528492",
        "affiliation_name": "AGH University of Krakow",
        "affiliation_city": "Krakow",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Driving Factors of CO<inf>2</inf> Emissions: Further Study Based on Machine Learning",
        "paper_author": "Li S.",
        "publication": "Frontiers in Environmental Science",
        "citied_by": "45",
        "cover_date": "2021-08-23",
        "Abstract": "Greenhouse gases, especially carbon dioxide (CO2) emissions, are viewed as one of the core causes of climate change, and it has become one of the most important environmental problems in the world. This paper attempts to investigate the relation between CO2 emissions and economic growth, industry structure, urbanization, research and development (R&D) investment, actual use of foreign capital, and growth rate of energy consumption in China between 2000 and 2018. This study is important for China as it has pledged to peak its carbon dioxide emissions (CO2) by 2030 and achieve carbon neutrality by 2060. We apply a suite of machine learning algorithms on the training set of data, 2000–2015, and predict the levels of CO2 emissions for the testing set, 2016–2018. Employing rmse for model selection, results show that the nonlinear model of k-nearest neighbors (KNN) model performs the best among linear models, nonlinear models, ensemble models, and artificial neural networks for the present dataset. Using KNN model, sensitivity analysis of CO2 emissions around its centroid position was conducted. The findings indicate that not all provinces should develop its industrialization. Some provinces should stay at relatively mild industrialization stage while selected others should develop theirs as quickly as possible. It is because CO2 emissions will eventually decrease after saturation point. In terms of urbanization, there is an optimal range for a province. At the optimal range, the CO2 emissions would be at a minimum, and it is likely a result of technological innovation in energy usage and efficiency. Moreover, China should increase its R&D investment intensity from the present level as it will decrease CO2 emissions. If R&D reinvestment is associated with actual use of foreign capital, policy makers should prioritize the use of foreign capital for R&D investment on green technology. Last, economic growth requires consuming energy. However, policy makers must refrain from consuming energy beyond a certain optimal growth rate. The above findings provide a guide to policy makers to achieve dual-carbon strategy while sustaining economic development.",
        "DOI": "10.3389/fenvs.2021.721517",
        "affiliation_name": "Central University of Finance and Economics",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Federating trust: Network orchestration for cross-boundary zero trust",
        "paper_author": "Olson K.",
        "publication": "Proceedings of the 2021 SIGCOMM 2021 Poster and Demo Sessions, Part of SIGCOMM 2021",
        "citied_by": "4",
        "cover_date": "2021-08-23",
        "Abstract": "Zero Trust is an emerging security paradigm that does away with implicit zones of trust commonly employed within static, defense-in-depth, enterprise architectures. One of the core tenets of Zero Trust is that resource access is determined by dynamic policy- A n intersection of trust in a user, the supporting application or service, the underlying network, and the devices which hold or process data. Establishing this overall assessment of trust serves well for centralized architectures where an administrator can establish and assess each of these trust enablers, such as in an enterprise network. However, shifting workloads to remote access, bring your own device (BYOD), and cloud hosting of collaborative services, to name a few, all challenge the ability of an administrator to effectively establish a complete Zero Trust architecture due to the inability to fully trust each component. This shift away from centrally managed architectures reveal a significant challenge in achieving complete Zero Trust: Security is a function of many interactions, many of which an administer has no control over. Recently the term \"Zero Trust 2.0\"was coined as an evolution to Zero Trust which establishes identity as the new perimeter via an orchestration layer and machine learning capabilities∼\\cite{trust}. However, this functionality still remains tied to centrally controlled architectures where an administrator can link together products and solutions to achieve a desired level of security. We argue that this orchestration needs to expand beyond these common enterprise boundaries in a way that trust can be guaranteed across disparate systems, networks, and servicers. Similar to identity federation, where a user can use credentials from one provider to access another competitors platform, federation of trust should serve as a guarantee for security across networks. In the remaining sections we propose what this trust federation mechanism could potentially look like.",
        "DOI": "10.1145/3472716.3472865",
        "affiliation_name": "University of Colorado Boulder",
        "affiliation_city": "Boulder",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Self-play reinforcement learning with comprehensive critic in computer games",
        "paper_author": "Liu S.",
        "publication": "Neurocomputing",
        "citied_by": "27",
        "cover_date": "2021-08-18",
        "Abstract": "Self-play reinforcement learning, where agents learn by playing with themselves, has been successfully applied in many game scenarios. However, the training procedure for self-play reinforcement learning is unstable and more sample-inefficient than (general) reinforcement learning, especially in imperfect information games. To improve the self-play training process, we incorporate a comprehensive critic into the policy gradient method to form a self-play actor-critic (SPAC) method for training agents to play computer games. We evaluate our method in four different environments in both competitive and cooperative tasks. The results show that the agent trained with our SPAC method outperforms those trained with deep deterministic policy gradient (DDPG) and proximal policy optimization (PPO) algorithms in many different evaluation approaches, which vindicate the effect of our comprehensive critic in the self-play training procedure.",
        "DOI": "10.1016/j.neucom.2021.04.006",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning-Based Extraction of Breast Cancer Receptor Status From Bilingual Free-Text Pathology Reports",
        "paper_author": "Pironet A.",
        "publication": "Frontiers in Digital Health",
        "citied_by": "4",
        "cover_date": "2021-08-17",
        "Abstract": "As part of its core business of gathering population-based information on new cancer diagnoses, the Belgian Cancer Registry receives free-text pathology reports, describing results of (pre-)malignant specimens. These reports are provided by 82 laboratories and written in 2 national languages, Dutch or French. For breast cancer, the reports characterize the status of estrogen receptor, progesterone receptor, and Erb-b2 receptor tyrosine kinase 2. These biomarkers are related with tumor growth and prognosis and are essential to define therapeutic management. The availability of population-scale information about their status in breast cancer patients can therefore be considered crucial to enrich real-world scientific studies and to guide public health policies regarding personalized medicine. The main objective of this study is to expand the data available at the Belgian Cancer Registry by automatically extracting the status of these biomarkers from the pathology reports. Various types of numeric features are computed from over 1,300 manually annotated reports linked to breast tumors diagnosed in 2014. A range of popular machine learning classifiers, such as support vector machines, random forests and logistic regressions, are trained on this data and compared using their F1 scores on a separate validation set. On a held-out test set, the best performing classifiers achieve F1 scores ranging from 0.89 to 0.92 for the four classification tasks. The extraction is thus reliable and allows to significantly increase the availability of this valuable information on breast cancer receptor status at a population level.",
        "DOI": "10.3389/fdgth.2021.692077",
        "affiliation_name": "National Cancer Registry",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "NaturalLanguageProcesing4All - A Constructionist NLP tool for Scaffolding Students' Exploration of Text",
        "paper_author": "Hjorth A.",
        "publication": "ICER 2021 - Proceedings of the 17th ACM Conference on International Computing Education Research",
        "citied_by": "5",
        "cover_date": "2021-08-16",
        "Abstract": "This paper presents a pilot study of NaturalLanguageProcessing4All (NLP4All), a Constructionist, low-threshold, XAI learning tool designed to bring Natural Language Processing methods into high school classrooms. Specifically, NLP4All is designed to let non-programmers explore different corpora of text through classification activities. Together with a high school Social Studies teacher, I developed a 2-week (6-hour) learning unit focusing on analyzing tweets from political parties to explore the differences and similarities between their policy views and communication styles. In the analysis, I find that text classification shows unexplored promise as a learning activity; that students were able to draw on their prior knowledge to classify tweets; that using NLP4All to collaboratively classify tweets led to productive classroom discussions; and that while students were able to build good machine learning models for classifying tweets, their rationales often focused on identifying one party, rather than distinguishing between parties. Finally, I discuss other educational contexts where NLP and ML can be productive for children, and future design features that may be worth exploring.",
        "DOI": "10.1145/3446871.3469749",
        "affiliation_name": "Aarhus Universitet",
        "affiliation_city": "Aarhus",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Typology and literature review on multiple supplier inventory control models",
        "paper_author": "Svoboda J.",
        "publication": "European Journal of Operational Research",
        "citied_by": "56",
        "cover_date": "2021-08-16",
        "Abstract": "This paper reviews the literature on inventory models with multiple sourcing options and presents a typology for classification. By means of the classification, the progression of the literature (policies and modeling assumptions) is illustrated, the main decision trade-offs in multiple sourcing are identified and avenues for future research are pointed out. Multiple sourcing decision models trade off the added costs of backup sourcing against higher inventory or shortage costs under single sourcing. The value of multiple over single sourcing is found to increase in the uncertainty to be buffered, in inventory holding and shortage costs, as well as in the constraints of the primary source. The literature evolved from small, restrictive models to larger problems and more realism. Accordingly, replenishment policies progressed from optimal policies to more heuristic decision rules. Three areas for future research are suggested for moving the field forward and towards more practical applicability. (1) Further integration of model aspects such as the extension of replenishment policies to more than two suppliers and to multi-echelon models. (2) Focusing on supply chain resilience with decision making disruption events or demand spikes under consideration of risk preferences. (3) Utilizing industry data in machine learning and data-driven methodologies.",
        "DOI": "10.1016/j.ejor.2020.11.023",
        "affiliation_name": "TUM School of Management, Munich",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Interactive imitation learning for spacecraft path-planning in binary asteroid systems",
        "paper_author": "Parmar K.",
        "publication": "Advances in Space Research",
        "citied_by": "9",
        "cover_date": "2021-08-15",
        "Abstract": "Exploration of small body systems poses the problem of designing path planning strategies for possibly uncharted environments. Traditional methods aimed at developing rigorous trajectory baselines may suffer inefficiencies, or turn infeasible when confronted with unknown dynamics. In strongly non-linear dynamics, mapping point design solutions from one dynamical regime to another may be hindered by underlying chaotic behavior. Rather than relying on baseline driven approaches, more generalized strategies may be found by observing human pilots controlling spacecraft motion within varying dynamical environments; the resultant data can then be utilized to initialize machine learning agents to provide more autonomous solutions. A previous numerical experiment resulted in a technical dataset comprising of human-based path planning strategies across a range of binary asteroid systems. This dataset is now used to train various imitation learning agents, and initiate the creation of a framework that integrates human–machine cooperation into the early training phases of artificial intelligent agents; the current application is for spacecraft guidance in binary asteroid systems, as a prototype of complex, potentially unknown, orbit dynamics. An interactive training architecture, based on the DAgger algorithm, is designed and employed to train both original and interactively coached agents, the latter stemming from both corrective and evaluative feedback by a real time human interactor. All agents were interactively trained for a predefined time period. The results from this investigation may provide the first, empirical observations of behavioral cloning within multi-body dynamics with largely randomized parameters, with some notable contributions including early characterization of training time, initial evidence of an autonomous agent learning meaningful policy features via imitation, and early identification of challenges in training fully autonomous agents for a multi-body dynamics path planning problem of this complexity and high dimensional state space.",
        "DOI": "10.1016/j.asr.2021.04.023",
        "affiliation_name": "Samuel Ginn College of Engineering",
        "affiliation_city": "Auburn",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A novel approach for estimation of aboveground biomass of a carbon-rich mangrove site in India",
        "paper_author": "Ghosh S.M.",
        "publication": "Journal of Environmental Management",
        "citied_by": "37",
        "cover_date": "2021-08-15",
        "Abstract": "Mangroves can play a crucial part in climate change mitigation policies due to their high carbon-storing capacity. However, the carbon sequestration potential of Indian mangroves generally remained unexplored to date. In this study, multi-temporal Sentinel-1 and 2 data-derived variables were used to estimate the AGB of a tropical carbon-rich mangrove forest of India. Ensemble prediction of multiple machine learning algorithms, including Random Forest (RF), Gradient Boosted Model (GBM), and Extreme Gradient Boosting (XGB), were used for AGB prediction. The multi-temporal dataset was used in two different ways to find the most suitable method of using them. The results of the analysis showed that the modeling field measured AGB with individual date data values results in estimates with root mean square errors (RMSE) ranging from 149.242 t/ha for XGB to 151.149 t/ha for the RF. Modeling AGB with the average and percentile metrics of the multi-temporal image stack improves the prediction accuracy of AGB, with RMSE ranging from 81.882 t/ha for the XGB to 74.493 t/ha for the RF. The AGB modeling using ensemble prediction showed further improvement in accuracy with an RMSE of 72.864 t/ha and normalized RMSE of 11.38%. In this study, the intra-seasonal variation of Sentinel-1 and 2 data for mangrove ecosystems was explored for the first time. The variations in remotely sensed variables could be attributed mainly to soil moisture availability and rainfall in the mangrove ecosystem. The efficiency of Sentinel-1 and 2 data-derived variables and ensemble prediction of machine learning models for Indian mangroves were also explored for the first time. The methodologies established in this study can be used in the future for accurate prediction and repeated monitoring of AGB for mangrove ecosystems.",
        "DOI": "10.1016/j.jenvman.2021.112816",
        "affiliation_name": "Space Applications Centre",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "COVID-19 dynamics across the US: A deep learning study of human mobility and social behavior",
        "paper_author": "Bhouri M.A.",
        "publication": "Computer Methods in Applied Mechanics and Engineering",
        "citied_by": "36",
        "cover_date": "2021-08-15",
        "Abstract": "This paper presents a deep learning framework for epidemiology system identification from noisy and sparse observations with quantified uncertainty. The proposed approach employs an ensemble of deep neural networks to infer the time-dependent reproduction number of an infectious disease by formulating a tensor-based multi-step loss function that allows us to efficiently calibrate the model on multiple observed trajectories. The method is applied to a mobility and social behavior-based SEIR model of COVID-19 spread. The model is trained on Google and Unacast mobility data spanning a period of 66 days, and is able to yield accurate future forecasts of COVID-19 spread in 203 US counties within a time-window of 15 days. Interestingly, a sensitivity analysis that assesses the importance of different mobility and social behavior parameters reveals that attendance of close places, including workplaces, residential, and retail and recreational locations, has the largest impact on the effective reproduction number. The model enables us to rapidly probe and quantify the effects of government interventions, such as lock-down and re-opening strategies. Taken together, the proposed framework provides a robust workflow for data-driven epidemiology model discovery under uncertainty and produces probabilistic forecasts for the evolution of a pandemic that can judiciously provide information for policy and decision making. All codes and data accompanying this manuscript are available at https://github.com/PredictiveIntelligenceLab/DeepCOVID19.",
        "DOI": "10.1016/j.cma.2021.113891",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning for Consumers and Markets",
        "paper_author": "Wang W.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "0",
        "cover_date": "2021-08-14",
        "Abstract": "Consumers leave digital footprints through large volumes of heterogeneous data which is a wealth of commercial value for firms, waiting to be mined. While there are initial success stories, this area is still under-explored. Further research and communication between the ML community and business community are needed to better align the objectives and create more successful applications. While machine learning is equipped to handle a variety of raw data for predictive tasks, without the theoretical insights from economics and consumer behavior to guide ML models, extracting generalizable insights with clear managerial implications and formulating impactful policies remain elusive. This workshop aims to promote further communication between these disciplines to foster synergistic development of impactful research that could benefit one another.",
        "DOI": "10.1145/3447548.3469478",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Causal Inference and Machine Learning in Practice with EconML and CausalML: Industrial Use Cases at Microsoft, TripAdvisor, Uber",
        "paper_author": "Syrgkanis V.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "19",
        "cover_date": "2021-08-14",
        "Abstract": "In recent years, both academic research and industry applications see an increased effort in using machine learning methods to measure granular causal effects and design optimal policies based on these causal estimates. Open source packages such as CausalML and EconML provide a unified interface for applied researchers and industry practitioners with a variety of machine learning methods for causal inference. The tutorial will cover the topics including conditional treatment effect estimators by meta-learners and tree-based algorithms, model validations and sensitivity analysis, optimization algorithms including policy leaner and cost optimization. In addition, the tutorial will demonstrate the production of these algorithms in industry use cases.",
        "DOI": "10.1145/3447548.3470792",
        "affiliation_name": "Microsoft Research Cambridge",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Globally Optimized Matchmaking in Online Games",
        "paper_author": "Deng Q.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "9",
        "cover_date": "2021-08-14",
        "Abstract": "As one of the core components of online games, matchmaking is the process of arranging multiple players into matches, where the quality of matchmaking systems directly determines player satisfaction and further affects the life cycle of game products. With the number of candidate players increases, the number of possible match combinations grows exponentially, which makes the current implementation for multiplayer matchmaking can only obtain locally optimal arrangement in an inefficient fashion. In this paper, we focus on the globally optimized matchmaking problem, in which the objective is to decide an optimal matching sequence for the queuing players. To tackle this challenging problem, we propose a novel data-driven matchmaking framework, called GloMatch, based on machine learning principles. Through transforming the matchmaking problem into a sequential decision problem, we solve it with the help of an effective policy-based deep reinforcement learning algorithm. Quantitative experiments on simulation and online game environments demonstrate the effectiveness of the presented framework.",
        "DOI": "10.1145/3447548.3467074",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "All Models Are Useful: Bayesian Ensembling for Robust High Resolution COVID-19 Forecasting",
        "paper_author": "Adiga A.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "17",
        "cover_date": "2021-08-14",
        "Abstract": "Timely, high-resolution forecasts of infectious disease incidence are useful for policy makers in deciding intervention measures and estimating healthcare resource burden. In this paper, we consider the task of forecasting COVID-19 confirmed cases at the county level for the United States. Although multiple methods have been explored for this task, their performance has varied across space and time due to noisy data and the inherent dynamic nature of the pandemic. We present a forecasting pipeline which incorporates probabilistic forecasts from multiple statistical, machine learning and mechanistic methods through a Bayesian ensembling scheme, and has been operational for nearly 6 months serving local, state and federal policymakers in the United States. While showing that the Bayesian ensemble is at least as good as the individual methods, we also show that each individual method contributes significantly for different spatial regions and time points. We compare our model's performance with other similar models being integrated into CDC-initiated COVID-19 Forecast Hub, and show better performance at longer forecast horizons. Finally, we also describe how such forecasts are used to increase lead time for training mechanistic scenario projections. Our work demonstrates that such a real-time high resolution forecasting pipeline can be developed by integrating multiple methods within a performance-based ensemble to support pandemic response.",
        "DOI": "10.1145/3447548.3467197",
        "affiliation_name": "University of Virginia",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Data-driven Humanitarian Mapping: Harnessing Human-Machine Intelligence for High-Stake Public Policy and Resilience Planning",
        "paper_author": "Gaikwad S.N.S.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "2",
        "cover_date": "2021-08-14",
        "Abstract": "NA",
        "DOI": "10.1145/3447548.3469461",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Fragile Earth: Accelerating Progress towards Equitable Sustainability",
        "paper_author": "Abe N.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "1",
        "cover_date": "2021-08-14",
        "Abstract": "Fragile Earth 2021, our annual workshop is taking place as part of the Earth Day events at ACM's KDD 2021 Conference on research in Machine Learning and its applications. The 5th edition of Fragile Earth will bring together the research community, industry, and policymakers to develop radically new technological foundations for advancing and meeting the Sustainable Development Goals in a way that ensures equitable and inclusive progress.",
        "DOI": "10.1145/3447548.3469484",
        "affiliation_name": "IBM Research",
        "affiliation_city": "Yorktown Heights",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Multi-Graph Attributed Reinforcement Learning based Optimization Algorithm for Large-scale Hybrid Flow Shop Scheduling Problem",
        "paper_author": "Ni F.",
        "publication": "Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining",
        "citied_by": "38",
        "cover_date": "2021-08-14",
        "Abstract": "Hybrid Flow Shop Scheduling Problem (HFSP) is an essential problem in the automated warehouse scheduling, aiming at optimizing the sequence of jobs and the assignment of machines to utilize the makespan or other objectives. Existing algorithms adopt fixed search paradigm based on expert knowledge to seek satisfactory solutions. However, considering the varying data distribution and large scale of the practical HFSP, these methods fail to guarantee the quality of the obtained solution under the real-time requirement, especially facing extremely different data distribution. To address this challenge, we propose a novel Multi-Graph Attributed Reinforcement Learning based Optimization (MGRO) algorithm to better tackle the practical large-scale HFSP and improve the existing algorithm. Owing to incorporating the reinforcement learning-based policy search approach with classic search operators and the powerful multi-graph based representation, MGRO is capable of adjusting the search paradigm according to specific instances and enhancing the search efficiency. Specifically, we formulate the Gantt chart of the instance into the multi-graph-structured data. Then Graph Neural Network (GNN) and attention-based adaptive weighted pooling are employed to represent the state and make MGRO size-agnostic across arbitrary sizes of instances. In addition, a useful reward shaping approach is designed to facilitate model convergence. Extensive numerical experiments on both the publicly available dataset and real industrial dataset from Huawei Supply Chain Business Unit demonstrate the superiority of MGRO over existing baselines.",
        "DOI": "10.1145/3447548.3467135",
        "affiliation_name": "Huawei Noah's Ark Lab",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Modelling the length of hospital stay in medicine and surgical departments",
        "paper_author": "Fiorillo A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2021-08-13",
        "Abstract": "Healthcare Associated Infections are among the world's leading public health problems and the most serious complications for hospitalized patients that can impact length of stay (LOS). In this work, medical record data of 24365 patients admitted to general surgery and clinical medicine wards were used collectively with the aim of creating models capable of predicting overall LOS, measured in days, considering clinical information. Multiple linear regression analysis was performed with IBM SPSS, the coefficient of determination (R2) was equal to 0,288. A regression analysis with ML algorithms was performed with the Knime Analysis Platform. The R2 were quite low for both multiple linear regression and ML regression analyses. The use of these techniques showed that there is a relationship between clinical variables and overall LOS. The results constitute a valid support tool for decision makers to provide the turnover index for the benefit of health policy in the management of departments.",
        "DOI": "10.1145/3502060.3503639",
        "affiliation_name": "Azienda Ospedaliera Universitaria Federico II",
        "affiliation_city": "Naples",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Making machine learning trustworthy",
        "paper_author": "Eshete B.",
        "publication": "Science",
        "citied_by": "31",
        "cover_date": "2021-08-13",
        "Abstract": "NA",
        "DOI": "10.1126/science.abi5052",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Dearborn",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Policy-Driven Approach to Secure Extraction of COVID-19 Data From Research Papers",
        "paper_author": "Elluri L.",
        "publication": "Frontiers in Big Data",
        "citied_by": "11",
        "cover_date": "2021-08-12",
        "Abstract": "The entire scientific and academic community has been mobilized to gain a better understanding of the COVID-19 disease and its impact on humanity. Most research related to COVID-19 needs to analyze large amounts of data in very little time. This urgency has made Big Data Analysis, and related questions around the privacy and security of the data, an extremely important part of research in the COVID-19 era. The White House OSTP has, for example, released a large dataset of papers related to COVID research from which the research community can extract knowledge and information. We show an example system with a machine learning-based knowledge extractor which draws out key medical information from COVID-19 related academic research papers. We represent this knowledge in a Knowledge Graph that uses the Unified Medical Language System (UMLS). However, publicly available studies rely on dataset that might have sensitive data. Extracting information from academic papers can potentially leak sensitive data, and protecting the security and privacy of this data is equally important. In this paper, we address the key challenges around the privacy and security of such information extraction and analysis systems. Policy regulations like HIPAA have updated the guidelines to access data, specifically, data related to COVID-19, securely. In the US, healthcare providers must also comply with the Office of Civil Rights (OCR) rules to protect data integrity in matters like plasma donation, media access to health care data, telehealth communications, etc. Privacy policies are typically short and unstructured HTML or PDF documents. We have created a framework to extract relevant knowledge from the health centers’ policy documents and also represent these as a knowledge graph. Our framework helps to understand the extent to which individual provider policies comply with regulations and define access control policies that enforce the regulation rules on data in the knowledge graph extracted from COVID-related papers. Along with being compliant, privacy policies must also be transparent and easily understood by the clients. We analyze the relative readability of healthcare privacy policies and discuss the impact. In this paper, we develop a framework for access control decisions that uses policy compliance information to securely retrieve COVID data. We show how policy compliance information can be used to restrict access to COVID-19 data and information extracted from research papers.",
        "DOI": "10.3389/fdata.2021.701966",
        "affiliation_name": "University of Maryland, Baltimore County (UMBC)",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using reinforcement learning to forecast the spread of COVID-19 in France",
        "paper_author": "Khalilpourazari S.",
        "publication": "ICAS 2021 - 2021 IEEE International Conference on Autonomous Systems, Proceedings",
        "citied_by": "7",
        "cover_date": "2021-08-11",
        "Abstract": "In December 2020, a new strain of coronavirus was found in Wuhan, China. The virus causes COVID-19, a severe respiratory illness. Up to date, the virus has spread rapidly to many countries, and more than 103 million cases and 2 million death has been reported worldwide. France is one of the European Union countries that has reported more than 3 million cases and 76 thousand death. Prediction of the COVID-19 pandemic growth is essential to enable governments to put new measures to slow down the spread of the virus. Due to the virus's novelty, providing an efficient method to predict pandemic growth is a challenging task. This research applies a recent reinforcement learning-based algorithm to a recently developed model to simulate the COVID-19 pandemic in France. We provide essential information about the pandemic growth in the country in every period in which the government of France has taken action to limit the pandemic or relaxed existing restrictions. We derive the values of the pandemic parameters, including reproduction rate, which gives us essential information about the pandemic. This information will help policymakers and healthcare professionals to plan for future measures limiting community transmission. Besides, we performed sensitivity analyses to determine the most critical parameters that accelerate the pandemic.",
        "DOI": "10.1109/ICAS49788.2021.9551174",
        "affiliation_name": "Concordia University",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A Birds-Eye (Re)View of Acid-Suppression Drugs, COVID-19, and the Highly Variable Literature",
        "paper_author": "Mura C.",
        "publication": "Frontiers in Pharmacology",
        "citied_by": "2",
        "cover_date": "2021-08-11",
        "Abstract": "This Perspective examines a recent surge of information regarding the potential benefits of acid-suppression drugs in the context of COVID-19, with a particular eye on the great variability (and, thus, confusion) that has arisen across the reported findings, at least as regards the popular antacid famotidine. The degree of inconsistency and discordance reflects contradictory conclusions from independent, clinical-based studies that took roughly similar approaches, in terms of both experimental design (retrospective, observational, cohort-based, etc.) and statistical analysis workflows (propensity-score matching and stratification into sub-cohorts, etc.). The contradictions and potential confusion have ramifications for clinicians faced with choosing therapeutically optimal courses of intervention: e.g., do any potential benefits of famotidine suggest its use in a particular COVID-19 case? (If so, what administration route, dosage regimen, duration, etc. are likely optimal?) As succinctly put this March in Freedberg et al. (2021), “…several retrospective studies show relationships between famotidine and outcomes in COVID-19 and several do not.” Beyond the pressing issue of possible therapeutic indications, the conflicting data and conclusions related to famotidine must be resolved before its inclusion/integration in ontological and knowledge graph (KG)–based frameworks, which in turn are useful for drug discovery and repurposing. As a broader methodological issue, note that reconciling inconsistencies would bolster the validity of meta-analyses which draw upon the relevant data-sources. And, perhaps most broadly, developing a system for treating inconsistencies would stand to improve the qualities of both 1) real world evidence-based studies (retrospective), on the one hand, and 2) placebo-controlled, randomized multi-center clinical trials (prospective), on the other hand. In other words, a systematic approach to reconciling the two types of studies would inherently improve the quality and utility of each type of study individually.",
        "DOI": "10.3389/fphar.2021.700703",
        "affiliation_name": "Department of Biomedical Engineering",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A State-of-Art Review of Digital Technologies for the Next Generation of Tinnitus Therapeutics",
        "paper_author": "Searchfield G.D.",
        "publication": "Frontiers in Digital Health",
        "citied_by": "13",
        "cover_date": "2021-08-10",
        "Abstract": "Background: Digital processing has enabled the development of several generations of technology for tinnitus therapy. The first digital generation was comprised of digital Hearing Aids (HAs) and personal digital music players implementing already established sound-based therapies, as well as text based information on the internet. In the second generation Smart-phone applications (apps) alone or in conjunction with HAs resulted in more therapy options for users to select from. The 3rd generation of digital tinnitus technologies began with the emergence of many novel, largely neurophysiologically-inspired, treatment theories that drove development of processing; enabled through HAs, apps, the internet and stand-alone devices. We are now of the cusp of a 4th generation that will incorporate physiological sensors, multiple transducers and AI to personalize therapies. Aim: To review technologies that will enable the next generations of digital therapies for tinnitus. Methods: A “state-of-the-art” review was undertaken to answer the question: what digital technology could be applied to tinnitus therapy in the next 10 years? Google Scholar and PubMed were searched for the 10-year period 2011–2021. The search strategy used the following key words: “tinnitus” and [“HA,” “personalized therapy,” “AI” (and “methods” or “applications”), “Virtual reality,” “Games,” “Sensors” and “Transducers”], and “Hearables.” Snowballing was used to expand the search from the identified papers. The results of the review were cataloged and organized into themes. Results: This paper identified digital technologies and research on the development of smart therapies for tinnitus. AI methods that could have tinnitus applications are identified and discussed. The potential of personalized treatments and the benefits of being able to gather data in ecologically valid settings are outlined. Conclusions: There is a huge scope for the application of digital technology to tinnitus therapy, but the uncertain mechanisms underpinning tinnitus present a challenge and many posited therapeutic approaches may not be successful. Personalized AI modeling based on biometric measures obtained through various sensor types, and assessments of individual psychology and lifestyles should result in the development of smart therapy platforms for tinnitus.",
        "DOI": "10.3389/fdgth.2021.724370",
        "affiliation_name": "Auckland Bioengineering Institute",
        "affiliation_city": "Auckland",
        "affiliation_country": "New Zealand"
    },
    {
        "paper_title": "Using Machine Learning Algorithms to Predict Efficiency of US's States Mask Policy during COVID-19",
        "paper_author": "Cui J.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "1",
        "cover_date": "2021-08-10",
        "Abstract": "Over the past year, the COVID-19 outbreak deeply and thoroughly changed the way the world is. However, the control policy's efficiency is still in dispute. Through the way of machine learning, now we are able to find and to probe into the data about corona-virus spreading patterns in a short period of time, suiting the remedy to the case, to launch targeted prevention policies, and minimize the economic loss under the premise of control the spread of the virus on a large scale. We directly use the LES algorithm and K-means clustering to make a comparison about the data feature. Therefore, the results are much more convincing than using any other recursive analyzing method alone. It is precise because of the ID3 algorithm, which we use for further analysis, to find the reason why those policies work.",
        "DOI": "10.1088/1742-6596/1994/1/012011",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Design of an assistive robot for infant mobility interventions",
        "paper_author": "Vinoo A.",
        "publication": "2021 30th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2021",
        "citied_by": "9",
        "cover_date": "2021-08-08",
        "Abstract": "Childhood ambulatory disabilities detract from not only the physical development, but also the social engagement of young children. Commercial mobility aids can help improve the autonomy of children with disabilities, but affordability issues, policy challenges, and uncertainty about training standards limit early use of these devices. In this paper, we build on affordable research-grade mobility aids for young children and consider how to design and evaluate an assistive robot that can support the use of these devices. With young children's contingency learning abilities in mind, we designed an assistive mobile robot capable of supplying age-appropriate light, sound, and bubble rewards. We conducted a first evaluation of the robot's ability to support driving practice with N = 5 typically developing infants. The results indicate mixed success of the robot rewards; driving distances uniformly tended to fall over the course of the study, but children did tend to look at the robot. In a second exploratory study involving N = 6 children in free ambulatory play, we see clearer differences in gaze and behavior from the introduction of an assistive robot. Generally, this research can inform others interested in assistive robotic interventions for young children.",
        "DOI": "10.1109/RO-MAN50785.2021.9515415",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Corvallis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Competitive physical interaction by reinforcement learning agents using intention estimation",
        "paper_author": "Noda H.",
        "publication": "2021 30th IEEE International Conference on Robot and Human Interactive Communication, RO-MAN 2021",
        "citied_by": "0",
        "cover_date": "2021-08-08",
        "Abstract": "The physical human-robot interaction (pHRI) research field is expected to contribute to competitive and cooperative human-robot tasks that involve force interactions. However, compared with human-human interactions, current pHRI approaches lack tactical considerations. Current approaches do not estimate intentions from human behavior and do not select policies that are appropriate for the opponent's changing policy. For this reason, we propose a reinforcement learning model that estimates the opponent's changing policy using time-series observations and expresses the agent's policy in a common latent space, referring to descriptions of tactics in open-skill sports. We verify the performance of the reinforcement learning agent using two novel physical and competitive environments, push-hand game and air-hockey. From this, we confirm that the latent space works properly for policy information because each latent variable that represents the machine agent's own policy and that of the opponent affects the behavior of the agent. Two latent variables can clearly express how the agent estimates the opponent's policy and decides its own policy.",
        "DOI": "10.1109/RO-MAN50785.2021.9515411",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Machine Learning-Aided Management of Motorway Facilities Using Single-Vehicle Accident Data",
        "paper_author": "Kaewunruen S.",
        "publication": "SAE International Journal of Transportation Safety",
        "citied_by": "1",
        "cover_date": "2021-08-06",
        "Abstract": "Management of expressway networks has been mainly focused on defect management without looking at the correlations with accidental risks. This causes unsustainability in expressway infrastructure maintenance since such defects may not be a contributing factor toward public safety. Thus it is necessary to incorporate accidental events for decision-making in infrastructure management. This study has developed a novel approach to machine learning (ML) that incorporates actual primary data from the last 10 years of single-vehicle accidents (SVA) by collisions with motorway facilities, or so-called single-vehicle collisions with fixed objects. The ML is firstly aimed at identifying the influential factors of SVA in relation to finding effective countermeasures for accidents by integrating the correlation analysis, multiple regression analysis, and ML techniques. The study reveals that wet pavement conditions have a significant effect on SVA. The results show that improvement of the skid resistance is the most effective method to reduce SVA when the average vehicle speed (AVS) is less than 60 km/h. At the locations with gentle curve radii, ML indicates that it is crucial to redesign the speed-through management. Interestingly, the real data over 10 years indicate no relationship between equivalent single axle load (ESAL) and skid resistance, although many other studies have demonstrated the inverse relationship. In this study, the novel ML mean demonstrates excellent capability in providing suitable countermeasures for a reduction of SVA under a variety of uncertain and road quantitative aspects. The ML-based mitigation policies can also be applicable to other motorways and can contribute to their road safety, underpinning sustainable transport systems.",
        "DOI": "10.4271/09-09-02-0007",
        "affiliation_name": "Metropolitan Expressway Company Limited",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "A Framework for Analyzing Road Accidents Using Machine Learning Paradigms",
        "paper_author": "Shweta ",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "9",
        "cover_date": "2021-08-06",
        "Abstract": "Road Safety is a matter of great concern throughout the world. As number of casualties is increasing more than 4% annually in all age groups. It has been predicted that due to road accidents causality rate will grow around 8% till 2030. It's entirely admissible and saddening to let citizens get killed in road accidents. As a result, to handle this sort of situation, an in-depth analysis is required. The Data of Road accidents are very heterogeneous in nature so analysis of such type of data is tricky. Segmentation is the main task for analyzing such data. So, K-means clustering method is mainly used for it as proposed in the research work. Second task of this model is to extract the data, images and hidden patterns by using Supervised Machine Learning algorithm that will help to form the policies for the prevention from road accidents. The combination of segmentation machine learning algorithm produces meaning full information.",
        "DOI": "10.1088/1742-6596/1950/1/012072",
        "affiliation_name": "Galgotias University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Using Reinforcement Learning Algorithms to Explore COVID-19 Spread in South Africa",
        "paper_author": "Hanie R.L.",
        "publication": "icABCD 2021 - 4th International Conference on Artificial Intelligence, Big Data, Computing and Data Communication Systems, Proceedings",
        "citied_by": "1",
        "cover_date": "2021-08-05",
        "Abstract": "Many learning opportunities for machine learning (ML) exist within the context of how viruses and their spread can be combatted. If the agents can be trained to demonstrate optimal behaviour in a pandemic, their actions can possibly be replicated to improve spread in a real-life scenario. The aim of this research is to train reinforcement learning (RL) agents to survive in a rule-based AI environment that simulates the spread of COVID-19 in South Africa. The RL agents used in the training environment were created using Unity's ML agent SDK. The ML agent SDK supports the usage of two RL-specific algorithms, Proximal Policy Optimization (PPO), and Soft Actor-Critic (SAC). This study contributes to the AI space by providing insight into how a virus and its interaction with a population can be modelled using Unity and machine learning. The agents were able to combat COVID-19 effectively and did so by self-Training how to maintain social distance and have regular check-ups at the hospital. It was also observed that susceptible agents pay frequent visits to the hospital without ever being rewarded for doing so. The code will be open-sourced to the Unity machine learning agent's SDK community and discords.",
        "DOI": "10.1109/icABCD51485.2021.9519325",
        "affiliation_name": "North-West University",
        "affiliation_city": "Potchefstroom",
        "affiliation_country": "South Africa"
    },
    {
        "paper_title": "Analyzing the Behaviour of Java-Based Movie Recommendation System using Machine Learning",
        "paper_author": "Govil N.",
        "publication": "Proceedings of the 2nd International Conference on Electronics and Sustainable Communication Systems, ICESC 2021",
        "citied_by": "2",
        "cover_date": "2021-08-04",
        "Abstract": "Everyone like and enjoy watching movies. Movies have tremendous glamour and unique magic to educate, entertain, and influence the spectators to a great extent. The need is to take positive aspects from movies instead of the negative sides that may harm our society. In the current scenario, the people are more considerate on the rating points of any particular item that is available online or offline before investing money in it. Movies are also not unaffected by this fact of rating and recommendation policies. So, there is a need to implement a recommender system that can recommend a suitable movie to the viewers. In this perspective, this research work has implemented a movie recommendation system by considering the latent factor. This system is coded in Java programming language. The implemented application can be commercially used since it helps the viewers to select the movies of their own choice.",
        "DOI": "10.1109/ICESC51422.2021.9532868",
        "affiliation_name": "GLA University, Mathura",
        "affiliation_city": "Mathura",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine Learning Based Data Security Model Using Blockchain for Secure Data Transmission in IoT",
        "paper_author": "Ch S.C.",
        "publication": "Proceedings of the 2nd International Conference on Electronics and Sustainable Communication Systems, ICESC 2021",
        "citied_by": "0",
        "cover_date": "2021-08-04",
        "Abstract": "The Internet of Things (IoT) Internet typically provides information on all Internet properties. Without human interference, it monitors and handles the functions remotely. It can immediately or through its experiences adapt to the conditions. Because of the participation of IoT devices in many applications, security and privacy of the users have become a matter of major concern. The current security and privacy policies are being undermined by cyber-attacks at an explosive pace. Blockchain technology recently became one of the most advanced technique in IOT. Blockchain has been developed to facilitate digital transactions and to provide safe and reliable access to the distributed ledger. Blockchain is able to provide safe transactions among users without the need for reliable third parties or intermediaries with intelligent contracts. Each node data transmission packets rate will be recorded using the blockchain. Consequently, Machine Learning (ML) algorithms are employed to produce precise outputs from large and complex databases that enable produced outputs to predict and detect IoT-based systems' vulnerabilities. Data from heterogeneous sensors can be collected by translating the differing types of values for various sensor types. In addition to fast IoT system expansion via global protection, it is not expected to reach its highest level. As a result of the omnipresent existence of IoT, most users have no experience or ability to protect devices alone. In IoT world, machine learning can be extremely successful in addressing safety challenges. In this research work, a Machine Learning based Data Security Model with Blockchain (MLDSMB) for IoT secure data transmission is proposed. The proposed model is contrasted with the traditional models and the proposed technique shows that the secure data transmission levels are high than existing models.",
        "DOI": "10.1109/ICESC51422.2021.9532659",
        "affiliation_name": "Pragati Engineering College",
        "affiliation_city": "Kakinada",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A multi-layer model for the early detection of COVID-19",
        "paper_author": "Shmueli E.",
        "publication": "Journal of the Royal Society Interface",
        "citied_by": "3",
        "cover_date": "2021-08-04",
        "Abstract": "Current COVID-19 screening efforts mainly rely on reported symptoms and the potential exposure to infected individuals. Here, we developed a machine-learning model for COVID-19 detection that uses four layers of information: (i) sociodemographic characteristics of the individual, (ii) spatio-temporal patterns of the disease, (iii) medical condition and general health consumption of the individual and (iv) information reported by the individual during the testing episode. We evaluated our model on 140 682 members of Maccabi Health Services who were tested for COVID-19 at least once between February and October 2020. These individuals underwent, in total, 264 516 COVID-19 PCR tests, out of which 16 512 were positive. Our multi-layer model obtained an area under the curve (AUC) of 81.6% when evaluated over all the individuals in the dataset, and an AUC of 72.8% when only individuals who did not report any symptom were included. Furthermore, considering only information collected before the testing episode - i.e. before the individual had the chance to report on any symptom - our model could reach a considerably high AUC of 79.5%. Our ability to predict early on the outcomes of COVID-19 tests is pivotal for breaking transmission chains, and can be used for a more efficient testing policy.",
        "DOI": "10.1098/rsif.2021.0284",
        "affiliation_name": "Maccabi Healthcare Services",
        "affiliation_city": "Tel Aviv-Yafo",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Interpretable Ranking with Generalized Additive Models",
        "paper_author": "Zhuang H.",
        "publication": "WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining",
        "citied_by": "21",
        "cover_date": "2021-08-03",
        "Abstract": "Interpretability of ranking models is a crucial yet relatively under-examined research area. Recent progress on this area largely focuses on generating post-hoc explanations for existing black-box ranking models. Though promising, such post-hoc methods cannot provide sufficiently accurate explanations in general, which makes them infeasible in many high-stakes scenarios, especially the ones with legal or policy constraints. Thus, building an intrinsically interpretable ranking model with transparent, self-explainable structure becomes necessary, but this remains less explored in the learning-to-rank setting. In this paper, we lay the groundwork for intrinsically interpretable learning-to-rank by introducing generalized additive models (GAMs) into ranking tasks. Generalized additive models (GAMs) are intrinsically interpretable machine learning models and have been extensively studied on regression and classification tasks. We study how to extend GAMs into ranking models which can handle both item-level and list-level features and propose a novel formulation of ranking GAMs. To instantiate ranking GAMs, we employ neural networks instead of traditional splines or regression trees. We also show that our neural ranking GAMs can be distilled into a set of simple and compact piece-wise linear functions that are much more efficient to evaluate with little accuracy loss. We conduct experiments on three data sets and show that our proposed neural ranking GAMs can outperform other traditional GAM baselines while maintaining similar interpretability.",
        "DOI": "10.1145/3437963.3441796",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Online Post-Processing in Rankings for Fair Utility Maximization",
        "paper_author": "Gupta A.",
        "publication": "WSDM 2021 - Proceedings of the 14th ACM International Conference on Web Search and Data Mining",
        "citied_by": "11",
        "cover_date": "2021-08-03",
        "Abstract": "We consider the problem of utility maximization in online ranking applications while also satisfying a pre-defined fairness constraint. We consider batches of items which arrive over time, already ranked using an existing ranking model. We propose online post-processing for re-ranking these batches to enforce adherence to the pre-defined fairness constraint, while maximizing a specific notion of utility. To achieve this goal, we propose two deterministic re-ranking policies. In addition, we learn a re-ranking policy based on a novel variation of learning to search. Extensive experiments on real world and synthetic datasets demonstrate the effectiveness of our proposed policies both in terms of adherence to the fairness constraint and utility maximization. Furthermore, our analysis shows that the performance of the proposed policies depends on the original data distribution w.r.t the fairness constraint and the notion of utility.",
        "DOI": "10.1145/3437963.3441724",
        "affiliation_name": "University of Massachusetts Amherst",
        "affiliation_city": "Amherst",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Energy consumption and spatial assessment of renewable energy penetration and building energy efficiency in malaysia: A review",
        "paper_author": "Aldhshan S.R.S.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "54",
        "cover_date": "2021-08-02",
        "Abstract": "The development of sustainable energy systems is very important to addressing the economic, environmental, and social pressures of the energy sector. Globally, buildings consume up to 40% of the world’s total energy. By 2030, it is expected to increase to 50%. Therefore, the world is facing a great challenge to overcome these problems related to global energy production. Malaysia is one of the top consumers of primary energy in Asia. In 2018, primary energy consumption for Malaysia was 3.79 quadrillion btu at an average annual rate of 4.58%. In this paper, we have carried out a detailed literature review on several previous studies of energy consumption in the world, especially in Malaysia, and how geographical information system (GIS) methods have been used for the spatial assessment of energy efficiency. Indeed, strategies of energy efficiency are essential in energy policy that could be created using various approaches used for energy savings in buildings. The findings of this review reveal that, for estimating energy consumption, exploring renewable energy sources, and investigating solar radiation, several geographic information system techniques such as multiple criteria decision analysis (MCDA), machine learning (ML), and deep learning (DL) are mainly utilized. The result indicates that the fuzzy DS method can more reliably determine the optimal PV farm locations. The 3D models are also regarded as an effective tool for estimating solar radiation, since this method generates a 3D model exportable to software tools. In addition, GIS and 3D can contribute to several purposes, such as sunlight access to buildings in urban areas, city growth prediction models and analysis of the habitability of public places.",
        "DOI": "10.3390/su13169244",
        "affiliation_name": "University of Technology Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Using Machine Learning to Analyze Merger Activity",
        "paper_author": "Jiang T.",
        "publication": "Frontiers in Applied Mathematics and Statistics",
        "citied_by": "6",
        "cover_date": "2021-08-02",
        "Abstract": "An unprecedented amount of access to data, “big data (or high dimensional data),” cloud computing, and innovative technology have increased applications of artificial intelligence in finance and numerous other industries. Machine learning is used in process automation, security, underwriting and credit scoring, algorithmic trading and robo-advisory. In fact, machine learning AI applications are purported to save banks an estimated $447 billion by 2023. Given the advantages that AI brings to finance, we focused on applying supervised machine learning to an investment problem. 10-K SEC filings are routinely used by investors to determine the worth and status of a company–Warren Buffett is frequently cited to read a 10-K a day. We sought to answer–“Can machine learning analyze more than thousands of companies and spot patterns? Can machine learning automate the process of human analysis in predicting whether a company is fit to merge? Can machine learning spot something that humans cannot?” In the advent of rising antitrust discussion of growing market concentrations and the concern for decrease in competition, we analyzed merger activity using text as a data set. Merger activity has been traditionally hard to predict in the past. We took advantage of the large amount of publicly available filings through the Securities Exchange Commission that give a comprehensive summary of a company, and used text, and an innovative way to analyze a company. In order to verify existing theory and measure harder to observe variables, we look to use a text document and examined a firm’s 10-K SEC filing. To minimize over-fitting, the L2 LASSO regularization technique is used. We came up with a model that has 85% accuracy compared to a 35% accuracy using the “bag-of-words” method to predict a company’s likelihood of merging from words alone on the same period’s test data set. These steps are the beginnings of tackling more complicated questions, such as “Which section or topic of words is the most predictive?” and “What is the difference between being acquired and acquiring?” Using product descriptions to characterize mergers further into horizontal and vertical mergers could eventually assist with the causal estimates that are of interest to economists. More importantly, using language and words to categorize companies could be useful in predicting counterfactual scenarios and answering policy questions, and could have different applications ranging from detecting fraud to better trading.",
        "DOI": "10.3389/fams.2021.649501",
        "affiliation_name": "University of California, Davis",
        "affiliation_city": "Davis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Optimal operation of a photovoltaic integrated captive cogeneration plant with a utility grid using optimization and machine learning prediction methods",
        "paper_author": "Reddy B.K.",
        "publication": "Energies",
        "citied_by": "15",
        "cover_date": "2021-08-02",
        "Abstract": "The World Energy Council, in its 2019 World Energy Scenarios Report, advised policy-makers to identify innovative opportunities for the integration of renewable energy resources into existing electrical power systems to achieve a fast and affordable solution. However, large‐scale industries with cogeneration units are facing problems in handling the higher penetration levels of intermittent renewable energies. This paper addresses large‐size photovoltaic power integration problems and their optimal operation. This work considers the case of a chemical industry having both cogeneration power and solar photovoltaics. Here, a modified firefly algorithm and a hybrid power resource optimization solver are proposed. The results of the proposed method are compared with other benchmark techniques, to confirm its advantages. The proposed techniques can be used in industries having cogeneration power plants with photovoltaics for better optimization and to meet the guidelines specified in IEEE 1547. The voltage ramp index is proposed to determine the voltage ramp up and down with intermittent solar irradiance. Additionally, a machine learning technique is used to predict the cogeneration plant efficiency at different loads and the solar irradiance under varying weather conditions. Finally, this paper proposes the effectiveness of the modified heuristic technique and certain guidelines, including solvers for industrial use.",
        "DOI": "10.3390/en14164935",
        "affiliation_name": "Lovely Professional University",
        "affiliation_city": "Phagwara",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Information System Construction and Research on Preference of Model by Multi-Class Decision Tree Regression",
        "paper_author": "Mao Z.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "5",
        "cover_date": "2021-08-02",
        "Abstract": "Through the construction of customer asset allocation decision preference model based on machine learning, the input variables are set as demographic variables, family economic conditions, personality psychological characteristics and risk attitude, and the output variables are customer asset allocation decision preference choices. machine learning algorithms such as decision tree and support vector machine are used to predict customers' asset allocation decision preference, and compared with traditional prediction methods. The results show that the machine learning algorithm can predict customers' asset allocation decision preference to a certain extent, and its performance is more effective than the traditional prediction method. Combined with the sample data, this paper analyzes the impact of venture capital on the growth ability of small and medium-sized enterprises, uses entropy method to evaluate corporate growth ability and corporate governance respectively, and further establishes a regression model to verify the intermediary role of corporate governance. The structured macro-prudential monetary policy rules with different response coefficients to the leverage ratio of different enterprises can effectively improve the level of social welfare, and the combination of optimal response coefficients is different under different kinds of shocks. Venture capital involvement in small and medium-sized enterprises can significantly improve the growth ability of small and medium-sized enterprises, and the support of venture capital can help enterprises improve the level of corporate governance. The experimental results show that the scorecard model constructed by the proposed method has good stability. The more obvious the improvement of the level of social welfare caused by the structural macroprudential monetary policy rules. The accurate prediction of asset allocation decision preference helps to improve customer decision-making efficiency and satisfaction, and reduce the labor costs of financial institutions..",
        "DOI": "10.1088/1742-6596/1982/1/012153",
        "affiliation_name": "Changchun University of Technology",
        "affiliation_city": "Changchun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A forest monitoring system for tanzania",
        "paper_author": "John E.",
        "publication": "Remote Sensing",
        "citied_by": "14",
        "cover_date": "2021-08-02",
        "Abstract": "Tropical forests provide essential ecosystem services related to human livelihoods. How-ever, the distribution and condition of tropical forests are under significant pressure, causing shrink-age and risking biodiversity loss across the tropics. Tanzania is currently undergoing significant forest cover changes, but monitoring is limited, in part due to a lack of remote sensing knowledge, tools and methods. This study has demonstrated a comprehensive approach to creating a national-scale forest monitoring system using Earth Observation data to inform decision making, policy formulation, and combat biodiversity loss. A systematically wall-to-wall forest baseline was created for 2018 through the application of Landsat 8 imagery. The classification was developed using the extreme gradient boosting (XGBoost) machine-learning algorithm, and achieved an accuracy of 89% and identified 45.76% of the country’s area to be covered with forest. Of those forested areas, 45% was found within nationally protected areas. Utilising an innovative methodology based on a forest habitat suitability analysis, the forest baseline was classified into forest types, with an overall accuracy of 85%. Woodlands (open and closed) were found to make up 79% of Tanzania’s forests. To map changes in forest extent, an automated system for downloading and processing of the Landsat imagery was used along with the XGBoost classifiers trained to define the national forest extent, where Landsat 8 scenes were individually downloaded and processed and the identified changes summarised on an annual basis. Forest loss identified for 2019 was found to be 157,204 hectares, with an overall accuracy of 82%. These forest losses within Tanzania have already triggered ecological problems and alterations in ecosystem types and species loss. Therefore, a forest monitoring system, such as the one presented in this study, will enhance conservation programmes and support efforts to save the last remnants of Tanzania’s pristine forests.",
        "DOI": "10.3390/rs13163081",
        "affiliation_name": "Aberystwyth University",
        "affiliation_city": "Aberystwyth",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Poverty mapping in the dian-gui-qian contiguous extremely poor area of southwest china based on multi-source geospatial data",
        "paper_author": "Xu Y.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "14",
        "cover_date": "2021-08-02",
        "Abstract": "Accurate information on the spatial distribution of poverty is of great significance to the formulation and implementation of the government’s targeted poverty alleviation policy. Traditional poverty mapping is mainly based on household survey data and statistical data, which cannot describe the spatial distribution of poverty well. This paper presents a study of mapping the integrated poverty index (IPI) in the Dian-Gui-Qian contiguous extremely poor area of southwest China. Based on multiple independent spatial variables extracted from NPP/VIIRS nighttime light (NTL) remote sensing data, digital elevation model (DEM), land cover information, open street map, and city accessibility data, eight algorithms were employed and compared to determine the optimal model for IPI estimation. Among these machine learning algorithms, traditional multiple linear regression had the lowest accuracy compared with the other seven machine learning algorithms and XGBoost showed the best performance. Feature selection was performed to reduce overfitting and five variables were finally selected. The final developed XGBoost model achieved an MAE of 0.0454 and an R2 of 0.68. The IPI map derived from the developed XGBoost model characterized the spatial pattern of poverty in the Dian-Gui-Qian contiguous extremely poor area well, which provided a good reference for the poverty alleviation work and public resources allocation in the study area. This study can also serve as a template for poverty mapping in other areas using remote sensing data.",
        "DOI": "10.3390/su13168717",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Estimation of urban land-use efficiency for sustainable development by integrating over 30-year landsat imagery with population data: A case study of ha long, Vietnam",
        "paper_author": "Jalilov S.M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "23",
        "cover_date": "2021-08-02",
        "Abstract": "Humans are moving into urban areas at an accelerated pace. An increasing urban population fuels urban expansion and reduces nearby agricultural lands and natural environments such as forests, swamps, other water-pervious areas. Unsustainable development creates a disproportion between the growth of urban areas and the growth in urban population. The UN SDG indicator 11.3.1 specifically addresses the issue of the measurement of land-use efficiency. While the metric and methodology to estimate the indicator are straightforward, it faces problems of data unavaila-bility and inconsistency. Vietnam has a record of tremendous economic growth that has translated into more urban settlements of size. Consequently, rural population movement into urban areas has led to many urban sustainable planning and development challenges. In the absence of previous work on estimating land-use efficiency in Vietnamese cities, this study makes the first attempt to examine land-use efficiency in Ha Long, one of the country’s fast-growing cities in recent decades. We mapped land use from high-resolution Landsat imagery (30 m) spanning multi-decadal obser-vations from 1986 to 2020. An advanced machine learning approach, the Support Vector Machine algorithm, was applied to estimate the built-up area, which, by integration with census data, is es-sential for calculating SDG indicator 11.3.1. This study shows that the land-use efficiency metric was positive but small at the beginning of the considered period but increased in 2000–2020. These results suggest that before 2000, the urban land consumption rate in Ha Long was lower than the population growth rate, implying denser urban land use. The situation changed to the opposite when the urban land consumption rate exceeded the population growth rate in the past two dec-ades. The study’s approach is applicable to regional and district levels to provide comparative analyses between cities or parts of a region or districts of the city. These analyses are valuable tools for assessing the impact of local urban and municipal planning policies on urban development.",
        "DOI": "10.3390/su13168848",
        "affiliation_name": "Vietnam Academy of Science and Technology",
        "affiliation_city": "Hanoi",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Comparison of machine-learning and casa models for predicting apple fruit yields from time-series planet imageries",
        "paper_author": "Bai X.",
        "publication": "Remote Sensing",
        "citied_by": "32",
        "cover_date": "2021-08-02",
        "Abstract": "Apple (Malus domestica Borkh. cv. “Fuji”), an important cash crop, is widely consumed around the world. Accurately predicting preharvest apple fruit yields is critical for planting policy making and agricultural management. This study attempted to explore an effective approach for predicting apple fruit yields based on time-series remote sensing data. In this study, time-series vegetation indices (VIs) were derived from Planet images and analyzed to further construct an accumulated VI (∑ VIs)-based random forest (RF∑ VI) model and a Carnegie–Ames–Stanford approach (CASA) model for predicting apple fruit yields. The results showed that (1) ∑ NDVI was the optimal predictor to construct an RF model for apple fruit yield, and the R2, RMSE, and RPD values of the RF∑ NDVI model reached 0.71, 16.40 kg/tree, and 1.83, respectively. (2) The maximum light use efficiency was determined to be 0.499 g C/MJ, and the CASASR model (R2 = 0.57, RMSE = 19.61 kg/tree, and RPD = 1.53) performed better than the CASANDVI model and the CASAAverage model (R2, RMSE, and RPD = 0.56, 24.47 kg/tree, 1.22 and 0.57, 20.82 kg/tree, 1.44, respectively). (3) This study compared the yield prediction accuracies obtained by the models using the same dataset, and the RF∑ NDVI model (RPD = 1.83) showed a better performance in predicting apple fruit yields than the CASASR model (RPD = 1.53). The results obtained from this study indicated the potential of the RF∑ NDVI model based on time-series Planet images to accurately predict apple fruit yields. The models could provide spatial and quantitative information of apple fruit yield, which would be valuable for agronomists to predict regional apple production to inform and develop national planting policies, agricultural management, and export strategies.",
        "DOI": "10.3390/rs13163073",
        "affiliation_name": "National Engineering Research Center for Information Technology in Agriculture Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Analogy-based crop yield forecasts based on temporal similarity of leaf area index",
        "paper_author": "Liu Y.",
        "publication": "Remote Sensing",
        "citied_by": "3",
        "cover_date": "2021-08-02",
        "Abstract": "Seasonal forecasts of crop yield are important components for agricultural policy decisions and farmer planning. A wide range of input data are often needed to forecast crop yield in a region where sophisticated approaches such as machine learning and process-based models are used. This requires considerable effort for data preparation in addition to identifying data sources. Here, we propose a simpler approach called the Analogy Based Crop-yield (ABC) forecast scheme to make timely and accurate prediction of regional crop yield using a minimum set of inputs. In the ABC method, a growing season from a prior long-term period, e.g., 10 years, is first identified as analogous to the current season by the use of a similarity index based on the time series leaf area index (LAI) patterns. Crop yield in the given growing season is then forecasted using the weighted yield average reported in the analogous seasons for the area of interest. The ABC approach was used to predict corn and soybean yields in the Midwestern U.S. at the county level for the period of 2017–2019. The MOD15A2H, which is a satellite data product for LAI, was used to compile inputs. The mean absolute percentage error (MAPE) of crop yield forecasts was <10% for corn and soybean in each growing season when the time series of LAI from the day of year 89 to 209 was used as inputs to the ABC approach. The prediction error for the ABC approach was comparable to results from a deep neural network model that relied on soil and weather data as well as satellite data in a previous study. These results indicate that the ABC approach allowed for crop yield forecast with a lead-time of at least two months before harvest. In particular, the ABC scheme would be useful for regions where crop yield forecasts are limited by availability of reliable environmental data.",
        "DOI": "10.3390/rs13163069",
        "affiliation_name": "Research Institute of Agricultural and Life Science",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "The Interactive Management of the SARS-CoV-2 Virus: The Social Cohesion Index, a Methodological-Operational Proposal",
        "paper_author": "Turchi G.P.",
        "publication": "Frontiers in Psychology",
        "citied_by": "17",
        "cover_date": "2021-08-02",
        "Abstract": "This contribution places itself within the emergency context of the COVID-19 spread. Until medical research identifies a cure acting at an organic level, it is necessary to manage what the emergency generates among the members of the Community in interactive terms in a scientific and methodologically well-founded way. This is in order to promote, among the members of the Community, the pursuit of the common aim of reducing the spread of infection, with a view to community health as a whole. In addition, being at the level of interactions enables us to move towards a change of these interactions in response to the COVID-19 emergency, in order to manage what will happen in the future, in terms of changes in the interactive arrangements after the emergency itself. This becomes possible by shifting away from the use of deterministic-causal references to the use of the uncertainty of interaction as an epistemological foundation principle. Managing the interactive (and non-organic) fallout of the emergency in the Community is made possible by the formalisation of the interactive modalities (the Discursive Repertories) offered by Dialogical Science. To place oneself within this scientific panorama enables interaction measurements: so, the interaction measurement indexes offers a range of generative possibilities of realities built by the speeches of the Community members. Moreover, the Social Cohesion measurement index, in the area of Dialogical Science, makes available to public policies the shared measure of how and by how much the Community is moving towards the common purpose of reducing the contagion spread, rather than moving towards other personal and not shared goals (for instance, having a walk in spite of the lockdown). In this index, the interaction between the Discursive Repertories and the “cohesion weight” associated with them offers a Cohesion output: the data allow to manage operationally what happens in the Community in a shared way and in anticipation, without leaving the interactions between its members to chance. In this way, they can be directed towards the common purpose through appropriate interventions relevant to the interactive set-up described in the data. The Cohesion measure makes it possible to operate effectively and efficiently, thanks to the possibility of monitoring the progress of the interventions implemented and evaluating their effectiveness. In addition, the use of predictive Machine Learning models, applied to interactive cohesion data, allows for immediate and efficient availability of the measure itself, optimising time and resources.",
        "DOI": "10.3389/fpsyg.2021.559842",
        "affiliation_name": "Università degli Studi di Padova",
        "affiliation_city": "Padua",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Analysing Impact of Price Ceiling System on Housing Market using Machine Learning",
        "paper_author": "Yoon K.S.",
        "publication": "Journal of the Architectural Institute of Korea",
        "citied_by": "3",
        "cover_date": "2021-08-01",
        "Abstract": "Housing prices in Korea continued to rise with the consumer’s desire for asset increase and suppliers’ desire for profit, and the government introduced a price ceiling system in 1972 to stabilize housing prices. The government expected that housing stability would be achieved by introducing the price ceiling system, but there was a constant controversy over the effect of it. Some experts argued that the price ceiling system does not affect existing housing prices, but rather reduces housing supply, which increases price in the long run. In this study, we intend to analyze the impact of the price ceiling system on housing market forecast by predicting housing market based on the presence or absence of the price ceiling system and comparing the accuracy. Several previous research have studied the factors affecting housing price, but this only identified the correlation, and there was insufficient of research on housing price prediction according to actual policy. To overcome such statistical limitations, this paper predicts housing price using machine learning that can be interpreted with high accuracy even if input variables are incomplete, wide, or irregular. As a result of analysis, the difference between RMSE(Root Mean Error), error rate mean, and error rate standard deviation was insignificant even if the price ceiling system was applied or not. This means that the housing market is more affected by other factors than the price ceiling system.",
        "DOI": "10.5659/JAIK.2021.37.8.221",
        "affiliation_name": "Hanyang University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Moving Forward in the Next Decade: Radiation Oncology Sciences for Patient-Centered Cancer Care",
        "paper_author": "Coleman C.N.",
        "publication": "JNCI Cancer Spectrum",
        "citied_by": "9",
        "cover_date": "2021-08-01",
        "Abstract": "In a time of rapid advances in science and technology, the opportunities for radiation oncology are undergoing transformational change. The linkage between and understanding of the physical dose and induced biological perturbations are opening entirely new areas of application. The ability to define anatomic extent of disease and the elucidation of the biology of metastases has brought a key role for radiation oncology for treating metastatic disease. That radiation can stimulate and suppress subpopulations of the immune response makes radiation a key participant in cancer immunotherapy. Targeted radiopharmaceutical therapy delivers radiation systemically with radionuclides and carrier molecules selected for their physical, chemical, and biochemical properties. Radiation oncology usage of \"big data\" and machine learning and artificial intelligence adds the opportunity to markedly change the workflow for clinical practice while physically targeting and adapting radiation fields in real time. Future precision targeting requires multidimensional understanding of the imaging, underlying biology, and anatomical relationship among tissues for radiation as spatial and temporal \"focused biology.\" Other means of energy delivery are available as are agents that can be activated by radiation with increasing ability to target treatments. With broad applicability of radiation in cancer treatment, radiation therapy is a necessity for effective cancer care, opening a career path for global health serving the medically underserved in geographically isolated populations as a substantial societal contribution addressing health disparities. Understanding risk and mitigation of radiation injury make it an important discipline for and beyond cancer care including energy policy, space exploration, national security, and global partnerships.",
        "DOI": "10.1093/jncics/pkab046",
        "affiliation_name": "National Cancer Institute (NCI)",
        "affiliation_city": "Rockville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Transfer learning applied to DRL-Based heat pump control to leverage microgrid energy efficiency",
        "paper_author": "Lissa P.",
        "publication": "Smart Energy",
        "citied_by": "28",
        "cover_date": "2021-08-01",
        "Abstract": "Domestic hot water accounts for approximately 15% of the total residential energy consumption in Europe, and most of this usage happens during specific periods of the day, resulting in undesirable peak loads. The increase in energy production from renewables adds additional complexity in energy balancing. Machine learning techniques for heat pump control have demonstrated efficacy in this regard. However, reducing the amount of time and data required to train effective policies can be challenging. This paper investigates the application of transfer learning applied to a deep reinforcement learning-based heat pump control to leverage energy efficiency in a microgrid. First, we propose an algorithm for domestic hot water temperature control and PV self-consumption optimisation. Secondly, we perform transfer learning to speed-up the convergence process. The experiments were deployed in a simulated environment using real data from two residential demand response projects. The results show that the proposed algorithm achieved up to 10% of savings after transfer learning was applied, also contributing to load-shifting. Moreover, the learning time to train near-optimal control policies was reduced by more than a factor of 5.",
        "DOI": "10.1016/j.segy.2021.100044",
        "affiliation_name": "University of Galway",
        "affiliation_city": "Galway",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Towards automated privacy compliance checking of applications in Cloud and Fog environments",
        "paper_author": "Farhadi M.",
        "publication": "Proceedings - 2021 International Conference on Future Internet of Things and Cloud, FiCloud 2021",
        "citied_by": "6",
        "cover_date": "2021-08-01",
        "Abstract": "Internet application users are increasingly concerned about the way applications handle their personal data. However, manually checking whether applications actually respect the claims made in their privacy policy is both error-prone and time-consuming. This paper claims that the privacy compliance of applications hosted in cloud or fog computing platforms can and should be automatically carried by the platform itself. We discuss the feasibility of unintrusive and application-agnostic monitoring in the platform layer to check the privacy compliance of applications. First, the platform may monitor an application's privacy-oriented behavior through signals such as its network traffic characteristics. Second, these signals can be analyzed and compared with the principles found in the application's privacy policy. We present a procedure based on machine-learning techniques to identify the type of data being shared by applications with external third-parties even if the application uses encrypted communications. Our classifiers identify traffic samples of applications with 86 % accuracy.",
        "DOI": "10.1109/FiCloud49777.2021.00010",
        "affiliation_name": "Institut de Recherche en Informatique et Systèmes Aléatoires",
        "affiliation_city": "Rennes",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Statistical Analytics and Regional Representation Learning for COVID-19 Pandemic Understanding",
        "paper_author": "Fazeli S.",
        "publication": "Proceedings - 2021 IEEE 9th International Conference on Healthcare Informatics, ISCHI 2021",
        "citied_by": "0",
        "cover_date": "2021-08-01",
        "Abstract": "The rapid spread of the novel coronavirus (COVID-19) has severely impacted almost all countries around the world. It not only has caused a tremendous burden on health-care providers to bear, but it has also brought severe impacts on the economy and social life. The presence of reliable data and the results of in-depth statistical analyses provide researchers and policymakers with invaluable information to understand this pandemic and its growth pattern more clearly. This paper combines and processes an extensive collection of publicly available datasets to provide a unified information source for representing geographical regions with regards to their pandemic-related behavior. The features are grouped into various categories to account for their impact based on the higher-level concepts associated with them. This work uses several correlation analysis techniques to observe value and order relationships between features, feature groups, and COVID-19 occurrences. Dimensionality reduction techniques and projection methodologies are used to elaborate on individual and group importance of these representative features. A specific RNN-based inference pipeline called DoubleWindowLSTM-CP is proposed in this work for predictive event modeling. It utilizes sequential patterns and enables concise record representation while using but a minimal amount of historical data. The quantitative results of our statistical analytics indicated critical patterns reflecting on many of the expected collective behavior and their associated outcomes. Predictive modeling with DoubleWindowLSTM-CP instance exhibits efficient performance in quantitative and qualitative assessments while reducing the need for extended and reliable historical information on the pandemic.",
        "DOI": "10.1109/ICHI52183.2021.00047",
        "affiliation_name": "University of California, Los Angeles",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The Research on the forecast of tourism demand based on Baidu search index-Taking Beijing as an example",
        "paper_author": "Huang Y.",
        "publication": "Proceedings - 2021 13th International Conference on Intelligent Human-Machine Systems and Cybernetics, IHMSC 2021",
        "citied_by": "2",
        "cover_date": "2021-08-01",
        "Abstract": "The accurate analysis of tourist volume plays an important role in the scientific management of tourism resources and the formulation of policies by tourism decision makers. The data generated by tourists' online search behavior provide a new perspective for tourism prediction. Based on the six elements of tourism, combined with text analysis, the conceptual framework of Baidu index keywords related to tourist volume is established. The statistical test and correlation analysis of Baidu index keywords were carried out, and the keyword sequences with predictive ability were selected. Then several prediction models are established to predict the number of visitors and optimize the model. Finally, the prediction accuracy of different models is analyzed by using goodness of fit (R2) and mean absolute percentage error (MAPE). It is found that the variable weight combination prediction model based on GBDT has the best effect, \\mathrm{R}^{2} and MAPE are 0.9943 and 1.78%, respectively.",
        "DOI": "10.1109/IHMSC52134.2021.00029",
        "affiliation_name": "Business School of Sichuan University",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Probabilistic approach to predict landslide susceptibility based on dynamic parameters for Uttarkashi, Uttarakhand (India)",
        "paper_author": "Kainthura P.",
        "publication": "Journal of Scientific and Industrial Research",
        "citied_by": "3",
        "cover_date": "2021-08-01",
        "Abstract": "The changing climate and global warming affect the stability of slopes, resulting in landslides. Landslides are frequent in hilly regions all over the world. The present work compares three GIS-based machine learning techniques to predict the changes in landslide susceptibility patterns classified as low, moderate, and high from observed records. The state-of-the-art methods include Random Forest (RF), Support Vector Machine (SVM), and Multinomial Logistic Regression (MLR). The landslide inventory contains a total of 1239 locations, which are divided into three subsets for training, testing, and validation purposes. A total of seven influencing factors were selected to understand the relationship between selected factors and observed landslides. The models were compared using the Receiver Operating Characteristics (ROC) curve and other statistical measures, including accuracy, precision, recall, sensitivity, and specificity. The RF model outperformed with the highest training (RFAccuracy=91%), testing (RFAccuracy=88%), and validation (RFAccuracy=86%) accuracy. The ROC values computed for the validation dataset for three models are 0.749, 0.734, and 0.874 for the MLR, SVM, and RF models respectively. The outcome of the present study could be instrumental for policy and decision-makers concerning risk planning and mitigation.",
        "DOI": "NA",
        "affiliation_name": "University of Petroleum and Energy Studies",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The Clinical Information Systems Response to the COVID-19 Pandemic",
        "paper_author": "Reeves J.J.",
        "publication": "Yearbook of medical informatics",
        "citied_by": "20",
        "cover_date": "2021-08-01",
        "Abstract": "OBJECTIVE: The year 2020 was predominated by the coronavirus disease 2019 (COVID-19) pandemic. The objective of this article is to review the areas in which clinical information systems (CIS) can be and have been utilized to support and enhance the response of healthcare systems to pandemics, focusing on COVID-19. METHODS: PubMed/MEDLINE, Google Scholar, the tables of contents of major informatics journals, and the bibliographies of articles were searched for studies pertaining to CIS, pandemics, and COVID-19 through October 2020. The most informative and detailed studies were highlighted, while many others were referenced. RESULTS: CIS were heavily relied upon by health systems and governmental agencies worldwide in response to COVID-19. Technology-based screening tools were developed to assist rapid case identification and appropriate triaging. Clinical care was supported by utilizing the electronic health record (EHR) to onboard frontline providers to new protocols, offer clinical decision support, and improve systems for diagnostic testing. Telehealth became the most rapidly adopted medical trend in recent history and an essential strategy for allowing safe and effective access to medical care. Artificial intelligence and machine learning algorithms were developed to enhance screening, diagnostic imaging, and predictive analytics - though evidence of improved outcomes remains limited. Geographic information systems and big data enabled real-time dashboards vital for epidemic monitoring, hospital preparedness strategies, and health policy decision making. Digital contact tracing systems were implemented to assist a labor-intensive task with the aim of curbing transmission. Large scale data sharing, effective health information exchange, and interoperability of EHRs remain challenges for the informatics community with immense clinical and academic potential. CIS must be used in combination with engaged stakeholders and operational change management in order to meaningfully improve patient outcomes. CONCLUSION: Managing a pandemic requires widespread, timely, and effective distribution of reliable information. In the past year, CIS and informaticists made prominent and influential contributions in the global response to the COVID-19 pandemic.",
        "DOI": "10.1055/s-0041-1726513",
        "affiliation_name": "Department of Surgery",
        "affiliation_city": "San Diego",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Key Contributions in Clinical Research Informatics",
        "paper_author": "Daniel C.",
        "publication": "Yearbook of medical informatics",
        "citied_by": "1",
        "cover_date": "2021-08-01",
        "Abstract": "OBJECTIVES: To summarize key contributions to current research in the field of Clinical Research Informatics (CRI) and to select best papers published in 2020. METHOD: A bibliographic search using a combination of Medical Subject Headings (MeSH) descriptors and free-text terms on CRI was performed using PubMed, followed by a double-blind review in order to select a list of candidate best papers to be then peer-reviewed by external reviewers. After peer-review ranking, a consensus meeting between two section editors and the editorial team was organized to finally conclude on the selected four best papers. RESULTS: Among the 877 papers published in 2020 and returned by the search, there were four best papers selected. The first best paper describes a method for mining temporal sequences from clinical documents to infer disease trajectories and enhancing high-throughput phenotyping. The authors of the second best paper demonstrate that the generation of synthetic Electronic Health Record (EHR) data through Generative Adversarial Networks (GANs) could be substantially improved by more appropriate training and evaluation criteria. The third best paper offers an efficient advance on methods to detect adverse drug events by computer-assisting expert reviewers with annotated candidate mentions in clinical documents. The large-scale data quality assessment study reported by the fourth best paper has clinical research informatics implications, in terms of the trustworthiness of inferences made from analysing electronic health records. CONCLUSIONS: The most significant research efforts in the CRI field are currently focusing on data science with active research in the development and evaluation of Artificial Intelligence/Machine Learning (AI/ML) algorithms based on ever more intensive use of real-world data and especially EHR real or synthetic data. A major lesson that the coronavirus disease 2019 (COVID-19) pandemic has already taught the scientific CRI community is that timely international high-quality data-sharing and collaborative data analysis is absolutely vital to inform policy decisions.",
        "DOI": "10.1055/s-0041-1726514",
        "affiliation_name": "Laboratoire d'Informatique Médicale et d'Ingénieurie des Connaissances en e-Santé",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "A systematic review on artificial intelligence/deep learning applications and challenges to battle against covid-19 pandemic",
        "paper_author": "Manoj A.",
        "publication": "Disaster Advances",
        "citied_by": "10",
        "cover_date": "2021-08-01",
        "Abstract": "The eruption of COVID-19 Corona Virus, namely SARS-CoV-2, has created a disastrous condition throughout the world. The cumulative incidence of COVID-19 is increasing rapidly day by day all over the world. Technologies like Artificial Intelligence (AI), Internet of Things (IoT), Big Data and Deep Learning can support healthcare system to fight and look ahead against fast spreading of new disease COVID-19. These technologies can significantly improve treatment consistency and decision making by developing useful algorithms. These technologies can be deployed very effectively to track the disease, to predict growth of the epidemic, design strategies and policy to manage its spread and drug and vaccine development. Motivated by recent advances and applications of artificial intelligence (AI) and big data in various areas, this study aims at emphasizing their importance in responding to the COVID-19 outbreak and preventing the severe effects of the COVID-19 pandemic. This study first presents an overview of AI and big data along with their applications in fighting against COVID-19 and then an attempt is made to standardize ongoing AI and deep learning activities in this area. Finally, this study highlighted challenges and issues associated with State-of-the-Art solutions to effectively control the COVID-19 situation.",
        "DOI": "10.25303/148da9021",
        "affiliation_name": "Sage University Indore",
        "affiliation_city": "Indore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Image processing for public health surveillance of tobacco point-of-sale advertising: Machine learning-based methodology",
        "paper_author": "English N.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "5",
        "cover_date": "2021-08-01",
        "Abstract": "Background: With a rapidly evolving tobacco retail environment, it is increasingly necessary to understand the point-of-sale (POS) advertising environment as part of tobacco surveillance and control. Advances in machine learning and image processing suggest the ability for more efficient and nuanced data capture than previously available. Objective: The study aims to use machine learning algorithms to discover the presence of tobacco advertising in photographs of tobacco POS advertising and their location in the photograph. Methods: We first collected images of the interiors of tobacco retailers in West Virginia and the District of Columbia during 2016 and 2018. The clearest photographs were selected and used to create a training and test data set. We then used a pretrained image classification network model, Inception V3, to discover the presence of tobacco logos and a unified object detection system, You Only Look Once V3, to identify logo locations. Results: Our model was successful in identifying the presence of advertising within images, with a classification accuracy of over 75% for 8 of the 42 brands. Discovering the location of logos within a given photograph was more challenging because of the relatively small training data set, resulting in a mean average precision score of 0.72 and an intersection over union score of 0.62. Conclusions: Our research provides preliminary evidence for a novel methodological approach that tobacco researchers and other public health practitioners can apply in the collection and processing of data for tobacco or other POS surveillance efforts. The resulting surveillance information can inform policy adoption, implementation, and enforcement. Limitations notwithstanding, our analysis shows the promise of using machine learning as part of a suite of tools to understand the tobacco retail environment, make policy recommendations, and design public health interventions at the municipal or other jurisdictional scale.",
        "DOI": "10.2196/24408",
        "affiliation_name": "Center for Tobacco Products (CTP)",
        "affiliation_city": "Silver Spring",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Analyzing COVID-19 Using Multisource Data: An Integrated Approach of Visualization, Spatial Regression, and Machine Learning",
        "paper_author": "Wu C.",
        "publication": "GeoHealth",
        "citied_by": "8",
        "cover_date": "2021-08-01",
        "Abstract": "Coronavirus disease 2019 (COVID-19), caused by severe acute respiratory syndrome coronavirus 2, was first identified in Wuhan, China, in December 2019. As the number of COVID-19 infections and deaths worldwide continues to increase rapidly, the prevention and control of COVID-19 remains urgent. This article aims to analyze COVID-19 from a geographical perspective, and this information can provide useful insights for rapid visualization of spatial-temporal epidemic information and identification of the factors important to the spread of COVID-19. A new type of vitalization method, called the point grid map, is integrated with calendar-based visualization to show the spatial-temporal variations in COVID-19. The combination of mixed geographically weighted regression (mixed GWR) and extreme gradient boosting (XGBoost) is used to identify the potential factors and the corresponding importance. The visualization results clearly reflect the spatial-temporal patterns of COVID-19. The quantified results reveal that the impact of population outflow from Wuhan is the most important factor and indicate statistically significant spatial heterogeneity. Our results provide insights into how multisource big geodata can be employed within the framework of integrating visualization and analytical methods to characterize COVID-19 trends. In addition, this work can help understand the influential factors for controlling and preventing epidemics, which is important for policy design and effective decision-making for controlling COVID-19. The results reveal that one of the most effective ways to control COVID-19 include controlling the source of infection, cutting off the transmission route, and protecting vulnerable groups.",
        "DOI": "10.1029/2021GH000439",
        "affiliation_name": "Hunan Normal University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Higher-order probabilistic adversarial computations: categorical semantics and program logics",
        "paper_author": "Aguirre A.",
        "publication": "Proceedings of the ACM on Programming Languages",
        "citied_by": "10",
        "cover_date": "2021-08-01",
        "Abstract": "Adversarial computations are a widely studied class of computations where resource-bounded probabilistic adversaries have access to oracles, i.e., probabilistic procedures with private state. These computations arise routinely in several domains, including security, privacy and machine learning. In this paper, we develop program logics for reasoning about adversarial computations in a higher-order setting. Our logics are built on top of a simply typed λ-calculus extended with a graded monad for probabilities and state. The grading is used to model and restrict the memory footprint and the cost (in terms of oracle calls) of computations. Under this view, an adversary is a higher-order expression that expects as arguments the code of its oracles. We develop unary program logics for reasoning about error probabilities and expected values, and a relational logic for reasoning about coupling-based properties. All logics feature rules for adversarial computations, and yield guarantees that are valid for all adversaries that satisfy a fixed resource policy. We prove the soundness of the logics in the category of quasi-Borel spaces, using a general notion of graded predicate liftings, and we use logical relations over graded predicate liftings to establish the soundness of proof rules for adversaries. We illustrate the working of our logics with simple but illustrative examples.",
        "DOI": "10.1145/3473598",
        "affiliation_name": "Institute of Science Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Climate data for the European forestry sector: From end-user needs to opportunities for climate resilience",
        "paper_author": "Fraccaroli C.",
        "publication": "Climate Services",
        "citied_by": "6",
        "cover_date": "2021-08-01",
        "Abstract": "The aim of this study is to assess the potential of Earth Observation and climate data for the forestry sector focusing on the Copernicus Climate Change Service (C3S). Although forestry researchers recognize the importance of Earth Observation and climate data, forestry practitioners currently work mainly with land cover information, largely neglecting climate data. Understanding its potential for the forestry sector becomes thus important, as to align the vast offer of climate services in Europe to different forestry users and stakeholders’ necessities. Interviews, surveys, and dedicated workshops were used to collect a series of forestry end-users’ needs and requirements regarding climate data. End-user's requirements were categorized through a SWOT analysis, which allowed to identify perceived internal strengths and weaknesses, external opportunities and threats to the increased use of the C3S. Results indicate that improved climate services for the forestry sector based on C3S data would benefit from enhanced training on the use of climate data, improved provision of services integrating climate with non-climate data, the provision of new variables and indicators, and the integration of machine learning techniques for developing data and information in support of the deployment of climate services. These findings are relevant to close the gap between demand and supply of climate services for the forestry sector and provide a basis for further exploring the value of climate data in serving a wide array of forestry stakeholders. Going forward, increased knowledge on user requirements from both forest practitioners and policy-makers can be beneficial to develop accessible tailored services.",
        "DOI": "10.1016/j.cliser.2021.100247",
        "affiliation_name": "Basque Research and Technology Alliance (BRTA)",
        "affiliation_city": "Mendaro",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Adaptive Predictive Power Management for Mobile LTE Devices",
        "paper_author": "Brand P.",
        "publication": "IEEE Transactions on Mobile Computing",
        "citied_by": "6",
        "cover_date": "2021-08-01",
        "Abstract": "Reducing the energy consumption of mobile phones is a crucial design goal for cellular modem solutions for LTE and 5G NR standards. Most dynamic power management techniques targeting mobile devices proposed so far, however, are purely reactive in powering down and up system components. Promising approaches extend this, by predicting information from the cell and the communication protocol to take decisions proactively. In this paper, we present a complete proactive power management approach for the modem based on on-line grant prediction. In this context, we define proactive policies that allow a mobile device to go to sleep states more often compared to reactive power management systems, e.g., in time slots of predicted transmission inactivity in a cell. Furthermore, we propose and compare two algorithmic solutions to this proactive grant prediction problem, one a feed-forward neural network and one a SARSA-\\lambdaλ reinforcement agent. As the implementation of these machine learning techniques also creates additional energy and resource costs, both approaches are carefully designed, optimized, and evaluated not only in terms of prediction accuracy, but also in terms of overall energy savings. Notably, our predictor implementations are able to achieve up to 17 percent in overall energy savings on real-world traces.",
        "DOI": "10.1109/TMC.2020.2988651",
        "affiliation_name": "Intel Deutschland GmbH",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Predicting success of outbound telemarketing in insurance policy loans using an explainable multiple-filter convolutional neural network",
        "paper_author": "Gu J.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "5",
        "cover_date": "2021-08-01",
        "Abstract": "Outbound telemarketing is an efficient direct marketing method wherein telemarketers solicit potential customers by phone to purchase or subscribe to products or services. However, those who are not interested in the information or offers provided by outbound telemarketing gen-erally experience such interactions negatively because they perceive telemarketing as spam. In this study, therefore, we investigate the use of deep learning models to predict the success of outbound telemarketing for insurance policy loans. We propose an explainable multiple-filter convolutional neural network model called XmCNN that can alleviate overfitting and extract various high-level features using hundreds of input variables. To enable the practical application of the proposed method, we also examine ensemble models to further improve its performance. We experimentally demonstrate that the proposed XmCNN significantly outperformed conventional deep neural network models and machine learning models. Furthermore, a deep learning ensemble model con-structed using the XmCNN architecture achieved the lowest false positive rate (4.92%) and the highest F1-score (87.47%). We identified important variables influencing insurance policy loan prediction through the proposed model, suggesting that these factors should be considered in practice. The proposed method may increase the efficiency of outbound telemarketing and reduce the spam problems caused by calling non-potential customers.",
        "DOI": "10.3390/app11157147",
        "affiliation_name": "Kyobo Life Insurance Co.,Ltd.",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Food for thought: A natural language processing analysis of the 2020 Dietary Guidelines publice comments",
        "paper_author": "Lindquist J.",
        "publication": "American Journal of Clinical Nutrition",
        "citied_by": "7",
        "cover_date": "2021-08-01",
        "Abstract": "Background: The Administrative Procedure Act of 1946 guarantees the public an opportunity to view and comment on the 2020 Dietary Guidelines as part of the policymaking process. In the past, public comments were submitted by postal mail or public hearings. The convenience of public comment through the Internet has generated increased comment volume, making manual analysis challenging. Objectives: To apply natural language processing (NLP NLP is natural language processing.) to identify sentiment, emotion, and themes in the 2020 Dietary Guidelines public comments. Methods: Written comments to the Scientific Report of the 2020 Dietary Guidelines Advisory Committee that were uploaded and visible at https://beta.regulations.gov/docket/FNS-2020-0015 were extracted using a computer program and retained for analysis. All comments were filtered, and duplicates were removed. A 2-round latent Dirichlet analysis (LDA) was used to identify 3 overarching topics as well as subtopics addressed in the comments. Sentiment analysis was applied to categorize emotion and overall positive and negative sentiment within each topic. Results: Three different topics were identified by LDA. The first topic involved negative sentiment surrounding removing dairy from the guidelines because the commenters felt dairy is unnecessary. The second topic focused on positive sentiment involved in restricting added sugars. The third topic was too diverse to characterize under 1 theme. A second LDA within the third topic had 3 subtopics containing positive sentiment. The first subtopic valued the inclusion of dairy in the recommendations, the second involved the health benefits of consuming beef, and the third indicated that the recommendations lead to overall good health outcomes. Conclusions: Public comments were diverse, held conflicting viewpoints, and often did not base comments on personal anecdotes or opinions without citing scientific evidence. Because the volume of public comments has grown dramatically, NLP has promise to assist in objective analysis of public comment input.",
        "DOI": "10.1093/ajcn/nqab119",
        "affiliation_name": "United States Army Center for Army Analysis",
        "affiliation_city": "Fort Belvoir",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mapping forward-looking mitigation studies at country level",
        "paper_author": "Lepault C.",
        "publication": "Environmental Research Letters",
        "citied_by": "3",
        "cover_date": "2021-08-01",
        "Abstract": "We provide the first survey of the rapidly expanding literature on country-level mitigation pathways using systematic mapping techniques. We build a database of 4691 relevant papers from the Web of Science and Scopus. We analyze their abstracts and metadata using text mining and natural language processing techniques. To discover common topics within the abstracts, we use an innovative and fully reproducible topic modeling approach based on two machine learning models. We find that the number of papers per country is well correlated with current levels of greenhouse gas (GHG) emissions, with few papers for (current) low emitters, notably in Africa. Time horizons of 2030 and 2050 each account for one-third of the papers, with the former actually more frequent in recent years, spurred by interest in the (Intended) Nationally Determined Contributions. Topic modeling analysis of the data set reveals that forward-looking mitigation papers encompass all dimensions of mitigation, save for financial issues, that are lacking. However, energy and to a lesser degree land use, land use change and forestry are very dominant relative to other sectors. Topics are unevenly addressed across countries, reflecting national circumstances and priorities, but also pointing to gaps in the literature. The limited number of forward-looking papers in (currently) low-emitting countries raises questions about the lack of research capacity in support of the construction of domestic climate policies.",
        "DOI": "10.1088/1748-9326/ac0ac8",
        "affiliation_name": "Université Paris-Saclay",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Nearshore benthic mapping in the great lakes: A multi-agency data integration approach in southwest lake Michigan",
        "paper_author": "Reif M.K.",
        "publication": "Remote Sensing",
        "citied_by": "4",
        "cover_date": "2021-08-01",
        "Abstract": "The Laurentian Great Lakes comprise the largest assemblage of inland waterbodies in North America, with vast geographic, environmentally complex nearshore benthic substrate and associated habitat. The Great Lakes Water Quality Agreement, originally signed in 1972, aims to help restore and protect the basin, and ecosystem monitoring is a primary objective to support adaptive management, environmental policy, and decision making. Yet, monitoring ecosystem trends remains challenging, potentially hindering progress in lake management and restoration. Consistent, high-resolution maps of nearshore substrate and associated habitat are fundamental to support management needs, and the nexus of high-quality remotely sensed data with improvements to analytical methods are increasing opportunities for large-scale nearshore benthic mapping at project-relevant spatial resolutions. This study attempts to advance the integration of high-fidelity data (airborne imagery and lidar, satellite imagery, in situ observations, etc.) and machine learning to identify and classify nearshore benthic substrate and associated habitat using a case study in southwest Lake Michigan along Illinois Beach State Park, Illinois, USA. Data inputs and analytical methods were evaluated to better understand their implications with respect to the Coastal and Marine Ecological Classification Standard (CMECS) classification hierarchy, resulting in an approach that could be easily applied to other shallow coastal environments. Classification of substrate and biotic components were iteratively classified in two Tiers in which classes with increasing specificity were identified using different combinations of airborne and satellite data inputs. Classification accuracy assessments revealed that for the Tier 1 substrate component (3 classes), average overall accuracy was 90.10 ± 0.60% for 24 airborne data combinations and 89.77 ± 1.02% for 12 satellite data combinations, whereas the Tier 1 biotic component (2 classes) average overall accuracy was 93.58 ± 0.91% for 24 airborne data combinations and 92.67 ± 0.71% for 11 satellite data combinations. The Tier 2 result for the substrate component (2 classes) was 93.28% for 2 airborne data combinations and 95.25% for the biotic component (2 classes). The study builds on foundational efforts to move towards a more integrated data approach, whereby data strengths and limitations for mapping nearshore benthic substrate and associated habitat, expressed through classification accuracy, were evaluated within the context of the CMECS classification hierarchy, and has direct applicability to critical monitoring needs in the Great Lakes.",
        "DOI": "10.3390/rs13153026",
        "affiliation_name": "Michigan State University",
        "affiliation_city": "East Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Urban vegetation coverage based on multi-core learning characteristics and regional economic law planning",
        "paper_author": "Wang D.",
        "publication": "Arabian Journal of Geosciences",
        "citied_by": "1",
        "cover_date": "2021-08-01",
        "Abstract": "The development of urbanization has caused many ecological and environmental problems. The green space in the city has important ecological significance. It can reduce the urban climate effect through photosynthesis and improve the quality of urban ecological environment. Therefore, the study of urban vegetation is of great significance. Based on the Landsat TM/OLI remote sensing image as the data source, according to the characteristic curve of soil characteristic spectrum in the study area, TNDVI, RVI, and other 11 vegetation indexes were used to process the Landsat data, and the comparison and analysis were carried out. Based on the vegetation coverage index, the image of the study area is processed to obtain the change of urban forest coverage in the study area. This paper also proposes an image classification algorithm with intermediate functions and tests the performance of the algorithm through experiments. However, in the process of experiment, only fast and simple sequential merging is used, and some problems that may appear in the merging process are not considered, such as redundancy or crosslinks between items after sequential merging. In order to avoid potential problems and further improve the resolution of merging function, this paper is planning regional quotient method based on multi-core learning features. This paper analyzes the current situation of China’s existing regional commercial law system, explains the necessity of regional coordination in the field of commercial law, and draws lessons from some useful experience of coordinating regional commercial law in foreign countries. Combined with China’s specific national conditions, it proposes to improve the coordinated development of regional commercial legal system, so as to provide theoretical guidance for the practice of coordinating China’s regional economic legal system.",
        "DOI": "10.1007/s12517-021-07941-3",
        "affiliation_name": "Hunan University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Long-term evolution of the SUHI footprint and urban expansion based on a temperature attenuation curve in the yangtze river delta urban agglomeration",
        "paper_author": "Tao F.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "6",
        "cover_date": "2021-08-01",
        "Abstract": "The rapid growth of urbanization and population has aggravated the urban heat island (UHI) effect in urban agglomerations. However, because scholars have so far focused mainly on the magnitude of the UHI effect, there is still a lack of research on the quantitative evaluation of the relationship between urban expansion and the degree of the UHI effect from the urban agglomeration perspective. This paper analyzed the spatiotemporal characteristics and the interactive mechanism of the surface urban heat island footprint (SUHI FP) in the Yangtze River Delta urban agglomeration (YRDUA). The summer footprints (FPs) of 27 cities were extracted using a logistics model, and the temporal trend was estimated by a standard deviation ellipse (SDE). Furthermore, the authors used the classical machine-learning k-means algorithm to cluster the temperature attenuation curves to reveal development patterns in different cities. The results showed that the degree of FP expansion during the daytime was more apparent than at night, the area of urban growth positively correlated with a city’s population level, and from 2005 to 2018 (the period of the study), the spatial evolution for all cities showed an overall trend from east to west. These cities were divided roughly into three development patterns by clustering their 2018 temperature attenuation curves. These findings can provide a scientific basis for formulating effective land-use policies by giving a deeper understanding of the spatiotemporal changes in the SUHI FPs and their relationship with land cover in the YRDUA.",
        "DOI": "10.3390/su13158530",
        "affiliation_name": "Nantong University",
        "affiliation_city": "Nantong",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Development and application of earth observation based machine learning methods for characterizing forest and land cover change in dilijan national park of armenia between 1991 and 2019",
        "paper_author": "Morin N.",
        "publication": "Remote Sensing",
        "citied_by": "6",
        "cover_date": "2021-08-01",
        "Abstract": "Dilijan National Park is one of the most important national parks of Armenia, established in 2002 to protect its rich biodiversity of flora and fauna and to prevent illegal logging. The aim of this study is to provide first, a mapping of forest degradation and deforestation, and second, of land cover/land use changes every 5 years over a 28-year monitoring cycle from 1991 to 2019, using Sentinel-2 and Landsat time series and Machine Learning methods. Very High Spatial Resolution imagery was used for calibration and validation purposes of forest density modelling and related changes. Correlation coefficient R2 between forest density map and reference values ranges from 0.70 for the earliest epoch to 0.90 for the latest one. Land cover/land use classification yield good results with most classes showing high users’ and producers’ accuracies above 80%. Although forest degradation and deforestation which initiated about 30 years ago was restrained thanks to protection measures, anthropogenic pressure remains a threat with the increase in settlements, tourism, or agriculture. This case study can be used as a decision-support tool for the Armenian Government for sustainable forest management and policies and serve as a model for a future nationwide forest monitoring system.",
        "DOI": "10.3390/rs13152942",
        "affiliation_name": "Collecte Localisation Satellites",
        "affiliation_city": "Ramonville",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Big data value chain: Multiple perspectives for the built environment",
        "paper_author": "Hernández-Moral G.",
        "publication": "Energies",
        "citied_by": "17",
        "cover_date": "2021-08-01",
        "Abstract": "Current climate change threats and increasing CO2 emissions, especially from the building stock, represent a context where action is required. It is necessary to provide efficient manners to manage energy demand in buildings and contribute to a decarbonised future. By combining new technologies, such as artificial intelligence, Internet of things, blockchain, and the exploitation of big data towards solving real life problems, the way could be paved towards smart and energy-aware buildings. In this context, the aim of this paper is to present a critical review and an in-detail definition of the big data value chain for the built environment in Europe, covering multiple needs and perspectives: “policy”, “technology” and “business”, in order to explore the main challenges and opportunities in this area.",
        "DOI": "10.3390/en14154624",
        "affiliation_name": "Eurac Research",
        "affiliation_city": "Bolzano",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Pandemic analytics by advanced machine learning for improved decision making of COVID-19 crisis",
        "paper_author": "Demertzis K.",
        "publication": "Processes",
        "citied_by": "12",
        "cover_date": "2021-08-01",
        "Abstract": "With the advent of the first pandemic wave of Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2), the question arises as to whether the spread of the virus will be controlled by the application of preventive measures or will follow a different course, regardless of the pattern of spread already recorded. These conditions caused by the unprecedented pandemic have highlighted the importance of reliable data from official sources, their complete recording and analysis, and accurate investigation of epidemiological indicators in almost real time. There is an ongoing research demand for reliable and effective modeling of the disease but also the formulation of substantiated views to make optimal decisions for the design of preventive or repressive measures by those responsible for the implementation of policy in favor of the protection of public health. The main objective of the study is to present an innovative data-analysis system of COVID-19 disease progression in Greece and her border countries by real-time statistics about the epidemiological indicators. This system utilizes visualized data produced by an automated information system developed during the study, which is based on the analysis of large pandemic-related datasets, making extensive use of advanced machine learning methods. Finally, the aim is to support with up-to-date technological means optimal decisions in almost real time as well as the development of medium-term forecast of disease progression, thus assisting the competent bodies in taking appropriate measures for the effective management of the available health resources.",
        "DOI": "10.3390/pr9081267",
        "affiliation_name": "International Hellenic University",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Large-scale river mapping using contrastive learning and multi-source satellite imagery",
        "paper_author": "Wei Z.",
        "publication": "Remote Sensing",
        "citied_by": "16",
        "cover_date": "2021-08-01",
        "Abstract": "River system is critical for the future sustainability of our planet but is always under the pressure of food, water and energy demands. Recent advances in machine learning bring a great potential for automatic river mapping using satellite imagery. Surface river mapping can provide accurate and timely water extent information that is highly valuable for solid policy and management decisions. However, accurate large-scale river mapping remains challenging given limited labels, spatial heterogeneity and noise in satellite imagery (e.g., clouds and aerosols). In this paper, we propose a new multi-source data-driven method for large-scale river mapping by combining multispectral imagery and synthetic aperture radar data. In particular, we build a multi-source data segmentation model, which uses contrastive learning to extract the common information between multiple data sources while also preserving distinct knowledge from each data source. Moreover, we create the first large-scale multi-source river imagery dataset based on Sentinel-1 and Sentinel-2 satellite data, along with 1013 handmade accurate river segmentation mask (which will be released to the public). In this dataset, our method has been shown to produce superior performance (F1score is 91.53%) over multiple state-of-the-art segmentation algorithms. We also demonstrate the effectiveness of the proposed contrastive learning model in mapping river extent when we have limited and noisy data.",
        "DOI": "10.3390/rs13152893",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reprint of: Automated stem cell production by bio-inspired control",
        "paper_author": "Monostori L.",
        "publication": "CIRP Journal of Manufacturing Science and Technology",
        "citied_by": "0",
        "cover_date": "2021-08-01",
        "Abstract": "The potential in treating chronic and life-threatening diseases by stem cell therapies can greatly be exploited via the efficient automation of stem cell production. Working with living material though poses severe challenges to automation. Recently, production platforms has been developed and tested worldwide with the aim to increase the reproducibility, quality and throughput of the process, to minimize human errors, and to reduce costs of production. A distinctive feature of this domain is the symbiotic co-existence and co-evolution of the technical, information and communication, as well as biological ingredients in production structures. A challenging way to overcome the issues of automated production is the use of biologically inspired control algorithms. In the paper an approach is described which combines digital, agent-based simulation and reinforcement learning for this purpose. The modelling of the cell growth behaviour, which is an important prerequisite of the simulation, is also introduced, together with an appropriate model fitting procedure. The applicability of the proposed approach is demonstrated by the results of a comprehensive investigation.",
        "DOI": "10.1016/j.cirpj.2021.06.010",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "The COVID-19 Pandemic and the Need for an Integrated and Equitable Approach: An International Expert Consensus Paper",
        "paper_author": "Gerotziafas G.T.",
        "publication": "Thrombosis and Haemostasis",
        "citied_by": "17",
        "cover_date": "2021-08-01",
        "Abstract": "Background One year after the declaration of the coronavirus disease 2019 (COVID-19) pandemic by the World Health Organization (WHO) and despite the implementation of mandatory physical barriers and social distancing, humanity remains challenged by a long-lasting and devastating public health crisis. Management Non-pharmacological interventions (NPIs) are efficient mitigation strategies. The success of these NPIs is dependent on the approval and commitment of the population. The launch of a mass vaccination program in many countries in late December 2020 with mRNA vaccines, adenovirus-based vaccines, and inactivated virus vaccines has generated hope for the end of the pandemic. Current Issues The continuous appearance of new pathogenic viral strains and the ability of vaccines to prevent infection and transmission raise important concerns as we try to achieve community immunity against severe acute respiratory syndrome coronavirus type 2 (SARS-CoV-2) and its variants. The need of a second and even third generation of vaccines has already been acknowledged by the WHO and governments. Perspectives There is a critical and urgent need for a balanced and integrated strategy for the management of the COVID-19 outbreaks organized on three axes: (1) P revention of the SARS-CoV-2 infection, (2) Detection and early diagnosis of patients at risk of disease worsening, and (3) Anticipation of medical care (PDA). Conclusion The PDA strategy integrated into state policy for the support and expansion of health systems and introduction of digital organizations (i.e., telemedicine, e-Health, artificial intelligence, and machine-learning technology) is of major importance for the preservation of citizens' health and life world-wide.",
        "DOI": "10.1055/a-1535-8807",
        "affiliation_name": "Hippokration General Hospital of Thessaloniki",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Leveraging artificial intelligence and big data to optimize covid-19 clinical public health and vaccination roll-out strategies in Africa",
        "paper_author": "Mellado B.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "16",
        "cover_date": "2021-08-01",
        "Abstract": "COVID-19 is imposing massive health, social and economic costs. While many developed countries have started vaccinating, most African nations are waiting for vaccine stocks to be allocated and are using clinical public health (CPH) strategies to control the pandemic. The emergence of variants of concern (VOC), unequal access to the vaccine supply and locally specific logistical and vaccine delivery parameters, add complexity to national CPH strategies and amplify the urgent need for effective CPH policies. Big data and artificial intelligence machine learning techniques and collaborations can be instrumental in an accurate, timely, locally nuanced analysis of multiple data sources to inform CPH decision-making, vaccination strategies and their staged roll-out. The AfricaCanada Artificial Intelligence and Data Innovation Consortium (ACADIC) has been established to develop and employ machine learning techniques to design CPH strategies in Africa, which requires ongoing collaboration, testing and development to maximize the equity and effectiveness of COVID-19-related CPH interventions.",
        "DOI": "10.3390/ijerph18157890",
        "affiliation_name": "Dahdaleh Institute for Global Health Research",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Do gender wage differences within households influence women's empowerment and welfare? Evidence from Ghana",
        "paper_author": "Danquah M.",
        "publication": "Journal of Economic Behavior and Organization",
        "citied_by": "11",
        "cover_date": "2021-08-01",
        "Abstract": "Using household data from the latest wave of the Ghana Living Standards Survey, this paper utilizes machine learning techniques – IV LASSO – that allows for the treatment of unconfoundedness in the selection of observables and unobservables to examine the structural effect of gender wage differences within households on women's empowerment and welfare in Ghana. The structural parameters of the IV LASSO estimations show that a reduction in household gender wage gap significantly enhances women's empowerment. Also, a decline in household gender wage gap results meaningfully in improving household and women's welfare. Particularly, the increasing effect on women's welfare resulting from decreases in household gender wage differences is much higher than for the household welfare. The findings showcase the need to vigorously adopt policies that both increase the quantity and quality of jobs for women and address gender barriers that inhibit women from accessing these jobs opportunities in sub-Saharan Africa.",
        "DOI": "10.1016/j.jebo.2021.06.014",
        "affiliation_name": "Jyväskylä University School of Business and Economics",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Rebirth of distributed AI—A review of ehealth research",
        "paper_author": "Khan M.A.",
        "publication": "Sensors",
        "citied_by": "8",
        "cover_date": "2021-08-01",
        "Abstract": "The envisioned smart city domains are expected to rely heavily on artificial intelligence and machine learning (ML) approaches for their operations, where the basic ingredient is data. Privacy of the data and training time have been major roadblocks to achieving the specific goals of each application domain. Policy makers, the research community, and the industrial sector have been putting their efforts into addressing these issues. Federated learning, with its distributed and local training approach, stands out as a potential solution to these challenges. In this article, we discuss the potential interplay of different technologies and AI for achieving the required features of future smart city services. Having discussed a few use-cases for future eHealth, we list design goals and technical requirements of the enabling technologies. The paper confines its focus on federated learning. After providing the tutorial on federated learning, we analyze the Federated Learning research literature. We also highlight the challenges. A solution sketch and high-level research directions may be instrumental in addressing the challenges.",
        "DOI": "10.3390/s21154999",
        "affiliation_name": "United Arab Emirates University",
        "affiliation_city": "Al Ain",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Deep reinforcement learning-based safe interaction for industrial human-robot collaboration using intrinsic reward function",
        "paper_author": "Liu Q.",
        "publication": "Advanced Engineering Informatics",
        "citied_by": "80",
        "cover_date": "2021-08-01",
        "Abstract": "Aiming at human-robot collaboration in manufacturing, the operator's safety is the primary issue during the manufacturing operations. This paper presents a deep reinforcement learning approach to realize the real-time collision-free motion planning of an industrial robot for human-robot collaboration. Firstly, the safe human-robot collaboration manufacturing problem is formulated into a Markov decision process, and the mathematical expression of the reward function design problem is given. The goal is that the robot can autonomously learn a policy to reduce the accumulated risk and assure the task completion time during human-robot collaboration. To transform our optimization object into a reward function to guide the robot to learn the expected behaviour, a reward function optimizing approach based on the deterministic policy gradient is proposed to learn a parameterized intrinsic reward function. The reward function for the agent to learn the policy is the sum of the intrinsic reward function and the extrinsic reward function. Then, a deep reinforcement learning algorithm intrinsic reward-deep deterministic policy gradient (IRDDPG), which is the combination of the DDPG algorithm and the reward function optimizing approach, is proposed to learn the expected collision avoidance policy. Finally, the proposed algorithm is tested in a simulation environment, and the results show that the industrial robot can learn the expected policy to achieve the safety assurance for industrial human-robot collaboration without missing the original target. Moreover, the reward function optimizing approach can help make up for the designed reward function and improve policy performance.",
        "DOI": "10.1016/j.aei.2021.101360",
        "affiliation_name": "Wuhan University of Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Pedagogical leaders and the teaching—learning processes in covid-19 times",
        "paper_author": "Álvarez-Arregui E.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "7",
        "cover_date": "2021-08-01",
        "Abstract": "This study aimed to identify the main decisions made by pedagogical leaders, comprising institutional management teams, heads of departments, and teachers in general, in order to improve teaching–learning processes and promote the comprehensive education of students—in particular, secondary school students during the pandemic period, located in the regions of Andalusia and Madrid (Spain). An integrated mixed methodology was applied, composed of the contributions of discussion groups and content analysis of the corresponding open questions presented in each of the constitutive dimensions of the questionnaire. Such analyses were expanded by applying an ad-hoc designed questionnaire, which indicates the main actions developed by leaders and their implications in the educational community, when working on communication facilitation processes, using program planning through the support of technologies and decision making regarding the training of teachers, didactic resources, and the emergence of competences to be trained by the leaders participating in the research. The results highlight the dedication, commitment, and implication of pedagogical leaders during the COVID-19 period.",
        "DOI": "10.3390/ijerph18157731",
        "affiliation_name": "Universidad Nacional de Educacion a Distancia",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Artificial Intelligence and the radiologist’s role",
        "paper_author": "Ratnayake M.",
        "publication": "Journal of Medical Imaging and Radiation Oncology",
        "citied_by": "0",
        "cover_date": "2021-08-01",
        "Abstract": "NA",
        "DOI": "10.1111/1754-9485.13282",
        "affiliation_name": "Royal Adelaide Hospital",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Investment in science can mitigate the negative impacts of land use on declining primate populations",
        "paper_author": "Zhao X.",
        "publication": "American Journal of Primatology",
        "citied_by": "7",
        "cover_date": "2021-08-01",
        "Abstract": "Changes in land use and the conversion of natural forests to agricultural fields and cattle pastures are threatening the survival of many species of wild animals, including nonhuman primates. Given its almost 1.4 billion people, China faces a difficult challenge in balancing economic development, human well-being, environmental protection, and animal conservation. We examined the effects of poverty, anthropogenic land use (cropland and pasture/grazing), human population growth, government investment in science and public attention to primates during the period from the 1980s to 2015 on primate population persistence in China. We analyzed these data using generalized mixed-effects models, structural equation models (SEM) and random forests (a machine learning technique). We found that 16 of 21 (76%) primate species in China, for which data are available, have experienced a population decline over the past 35 years. Factors contributing most to primate population decline included human poverty and the conversion of natural habitat to cropland. In contrast, the five species of primates that were characterized by recent population increases were the subjects of substantial government research funding and their remaining distribution occurs principally in protected areas (PAs). We argue that increased funding for research, the establishment and expansion of PAs, a national policy focused on reducing poverty, and educational programs designed to inform and encourage local people to participate in scientific investigation and wildlife protection, can mitigate the negative impacts of historical patterns of land conversion on primate population survival in China.",
        "DOI": "10.1002/ajp.23302",
        "affiliation_name": "Dali University",
        "affiliation_city": "Dali",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning-based method for forecasting water levels in irrigation and drainage systems",
        "paper_author": "Truong V.H.",
        "publication": "Environmental Technology and Innovation",
        "citied_by": "15",
        "cover_date": "2021-08-01",
        "Abstract": "This study presents possible applications of machine learning (ML) methods for estimating water levels without a throughout understanding of hydrological processes and complex databases of irrigation systems. The Bac-Hung-Hai catchment, the biggest irrigation and drainage area in Vietnam, is selected as a case study due to the large database on this case consisting of 3348 samples drawn over a 21-year monitoring period. The state-of-the-art Gradient tree boosting (GTB)-based model was developed and is compared with eight other common ML methods. The proposed GTB-based model consistently showed the best performance, with the lowest value of mean-squares-error and the greatest values for R2 and adjusted R2 in all case studies. Moreover, over 91% of the total samples had an error rate of below 10% between the predicted and the observed values. The results suggested that the GTB model can predict water level with high accuracy, thus helping researchers and policy-makers devise proactive strategies for hydraulic regulation and sustainable water management.",
        "DOI": "10.1016/j.eti.2021.101762",
        "affiliation_name": "Thuyloi University",
        "affiliation_city": "Hanoi",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Adaptive signal control for bus service reliability with connected vehicle technology via reinforcement learning",
        "paper_author": "Chow A.H.F.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "31",
        "cover_date": "2021-08-01",
        "Abstract": "This paper presents an adaptive signal controller for managing traffic delays and urban bus service reliability with fully adaptable acyclic timing plans. The signal controller is built upon a reinforcement learning framework that consists of a model-based and a data-driven component. The model-based component is represented by a hybrid kinematic wave traffic model that integrates macroscopic flow-based and microscopic vehicle-based state variables subject to stochastic demands and bus service status. To cope with the high dimensional solution space, the data-driven component is incorporated as a multi-layer artificial neural network and is used to approximate future traffic states and system performances with respect to prevailing control settings. Before the controller can be used, the neural network is to be trained through a series of realised dynamic state transitions via an on-policy temporal difference learning algorithm. The proposed control framework is tested over a real world corridor scenario in London, UK. The proposed controller is able to reduce both traffic delays and bus service variabilities subject to stochastic demands with acyclic timing plans that can be derived in short computational time. This study contributes to the design of adaptive network traffic control for multi-modal networks with connected vehicle technology and advanced learning-based optimisation techniques.",
        "DOI": "10.1016/j.trc.2021.103264",
        "affiliation_name": "Sun Yat-Sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Impact of land cover changes on carbon stock trends in Kenya for spatial implementation of REDD+ policy",
        "paper_author": "Nyamari N.",
        "publication": "Applied Geography",
        "citied_by": "29",
        "cover_date": "2021-08-01",
        "Abstract": "Terrestrial carbon stock estimates information has significant importance in planning decisions for global warming and climate change mitigation. This study aimed to estimate and analyze carbon stock changes in Kenya as consequence of land cover change (LCC) using free open data to provide affordable and timely information. Using Random Forest (RF) decision trees, the land cover for 2028 was modelled based on 2004 and 2016 land cover under a Business as Usual (BAU) and an alternative Reducing of Emissions from Forest Degradation and Deforestation (REDD+) scenarios. The InVEST carbon model was used for estimation and valuation of carbon stock between 2004 and 2028. Results show a 16% decline in carbon stock with a loss of 21 billion US$ under the BAU scenario. On a regional scale, results show a gradual decline in carbon stock in the Coastal and Central regions while other regions exhibited mixed results. This trend can be reversed by the implementation of a REDD + scenario with a possible increase of 1.6% between 2016 and 2028, translating to a gain of 1 billion US$. This study contributes to the understanding of spatiotemporal carbon stock changes under different scenarios for effective spatial planning aiming to a balanced natural resource utilization.",
        "DOI": "10.1016/j.apgeog.2021.102479",
        "affiliation_name": "NOVA Information Management School, Universidade Nova de Lisboa",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Optimizing matching time intervals for ride-hailing services using reinforcement learning",
        "paper_author": "Qin G.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "48",
        "cover_date": "2021-08-01",
        "Abstract": "Matching trip requests and available drivers efficiently is considered a central operational problem for ride-hailing services. A widely adopted matching strategy is to accumulate a batch of potential passenger-driver matches and solve bipartite matching problems repeatedly. The efficiency of matching can be improved substantially if the matching is delayed by adaptively adjusting the matching time interval. The optimal delayed matching is subject to the trade-off between the delay penalty and the reduced wait cost and is dependent on the system's supply and demand states. Searching for the optimal delayed matching policy is challenging, as the current policy is compounded with past actions. To this end, we tailor a family of reinforcement learning-based methods to overcome the curse of dimensionality and sparse reward issues. In addition, this work provides a solution to spatial partitioning balance between the state representation error and the optimality gap of asynchronous matching. Lastly, we examine the proposed methods with real-world taxi trajectory data and garner managerial insights into the general delayed matching policies. The focus of this work is single-ride service due to limited access to shared ride data, while the general framework can be extended to the setting with a ride-pooling component.",
        "DOI": "10.1016/j.trc.2021.103239",
        "affiliation_name": "DiDi Chuxing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Bayesian Surrogate Learning for Uncertainty Analysis of Coupled Multidisciplinary Systems",
        "paper_author": "Ghoreishi S.F.",
        "publication": "Journal of Computing and Information Science in Engineering",
        "citied_by": "14",
        "cover_date": "2021-08-01",
        "Abstract": "Engineering systems are often composed of many subsystems that interact with each other. These subsystems, referred to as disciplines, contain many types of uncertainty and in many cases are feedback-coupled with each other. In designing these complex systems, one needs to assess the stationary behavior of these systems for the sake of stability and reliability. This requires the system level uncertainty analysis of the multidisciplinary systems, which is often computationally intractable. To overcome this issue, techniques have been developed for capturing the stationary behavior of the coupled multidisciplinary systems through available data of individual disciplines. The accuracy and convergence of the existing techniques depend on a large amount of data from all disciplines, which are not available in many practical problems. Toward this, we have developed an adaptive methodology that adds the minimum possible number of samples from individual disciplines to achieve an accurate and reliable uncertainty propagation in coupled multidisciplinary systems. The proposed method models each discipline function via Gaussian process (GP) regression to derive a closed-form policy. This policy sequentially selects a new sample point that results in the highest uncertainty reduction over the distribution of the coupling design variables. The effectiveness of the proposed method is demonstrated in the uncertainty analysis of an aerostructural system and a coupled numerical example.",
        "DOI": "10.1115/1.4049994",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "How are network centrality metrics related to interest rates in the Mexican secured and unsecured interbank markets?",
        "paper_author": "Téllez-León I.E.",
        "publication": "Journal of Financial Stability",
        "citied_by": "5",
        "cover_date": "2021-08-01",
        "Abstract": "In financial stability, it is essential to know the determinants of interest rates in interbank markets because they are important vehicles for liquidity allocation among banks and are relevant for monetary policy transmission. Recent research indicates that banks with excess liquidity exercise their market power by rationing liquidity during periods of financial stress. This confirms the value of knowing the banks connections and identifying liquidity spreaders in such markets to manage contagion risk, liquidity hoarding and to preserve financial stability. In addition to well studied bank features such as size, liquidity and credit risk, we study which network metrics relate to interest rates during different periods. Using transaction level data on unsecured and secured lending, we apply an approach that employs network theory, econometric models and machine learning to analyze the structural properties of the secured and unsecured interbank markets in Mexico. Our findings support the “too-interconnected-to-fail” hypothesis. In the secured interbank market, PageRank shows a relationship with interest rates, while metrics associated with the notion of influence and systemic risk (Katz and DebtRank) are relevant in the unsecured interbank market. In general, a bank with high centrality lends at higher rates and gets funding at lower rates.",
        "DOI": "10.1016/j.jfs.2021.100893",
        "affiliation_name": "Banco de Mexico",
        "affiliation_city": "Mexico City",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "A time series clustering based approach for construction of real-world drive cycles",
        "paper_author": "Ganesh Sundarkumar G.",
        "publication": "Transportation Research Part D: Transport and Environment",
        "citied_by": "9",
        "cover_date": "2021-08-01",
        "Abstract": "Building representative real world drive cycles is an important component in the modelling of emissions, battery health of electric vehicles and autonomous vehicles. All these applications are sensitive to the transients and diversity present in real world driving patterns, which are not adequately captured by current approaches. To address this lacuna, we use clustering techniques involving time-series (shape) based distances on the raw data directly to obtain representative sets of real world drive cycles. We demonstrate the efficacy of our approach using experimental data from a fleet of eight motorcycles run across five locations in India. Dynamic Time Warping (DTW) distance based clustering gives optimal results. We give theoretical and experimental justification for our constructions. We believe that the constructed drive cycles using the proposed approach would help in assessing the impact of various policies aimed at building eco-friendly transportation systems.",
        "DOI": "10.1016/j.trd.2021.102896",
        "affiliation_name": "Robert Bosch Engineering and Business Solutions Private Limited",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Personalized vital signs control based on continuous action-space reinforcement learning with supervised experience",
        "paper_author": "Sun C.",
        "publication": "Biomedical Signal Processing and Control",
        "citied_by": "10",
        "cover_date": "2021-08-01",
        "Abstract": "Vital signs reflect patients’ current health status. Different patients are suitable for distinct references of vital signs due to the disease type and individual physique. Personalized Vital Signs Control (PVSC) helps clinicians with the recommendation of the optimal references for real-time treatment. However, a data-driven approach needs to overcome the unclear ground truth problem, requires complex feature integration and continuous value space, and is expected to ensure the safety of fragile patients. But none of the existing approaches can overcome all of these challenges simultaneously. This work emphasizes PVSC as a sequence decision-making problem and applies multiple reinforcement learning methods to it. We propose a novel adaptive medical control model. The model combines the deep deterministic policy gradient reinforcement learning algorithm, supervised experience knowledge, and recurrent neural network module, named PVSC-RL. We test the model on a real medical database, MIMIC-III, with 15,232 sepsis and 13,608 heart failure records. Experimental results show that using the policy of PVSC-RL, the survival rate of sepsis and heart failure patients by blood glucose control and blood pressure control can be increased by 3.45%, 15.21%, 4.19%, 12.13%. Meanwhile, the safety rate is also be increased by 3.09%, 1.02%, 3.54%, 4.04%.",
        "DOI": "10.1016/j.bspc.2021.102847",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Adaptable automation with modular deep reinforcement learning and policy transfer",
        "paper_author": "Raziei Z.",
        "publication": "Engineering Applications of Artificial Intelligence",
        "citied_by": "24",
        "cover_date": "2021-08-01",
        "Abstract": "Future industrial automation systems are anticipated to be shaped by intelligent technologies that allow for the adaptability of machines to the variations and uncertainties in processes and work environments. This paper is motivated by the need for devising new intelligent methods that enable efficient and scalable training of collaborative robots on a variety of tasks that foster their adaptability to new tasks and environments. Recent advances in deep Reinforcement Learning (RL) provide new possibilities to realize this vision. The state-of-the-art in deep RL offers proven algorithms that enable autonomous learning and mastery of a variety of robotic manipulation tasks with minimal human intervention. However, current deep RL algorithms predominantly specialize in a narrow range of tasks, are sample inefficient, and lack sufficient stability, which hinders their adoption in real-life, industrial settings. This paper develops and tests a Hyper-Actor Soft Actor–Critic (HASAC) deep RL framework based on the notions of task modularization and transfer learning to tackle this limitation. The goal of the proposed HASAC is to enhance an agent's adaptability to new tasks by transferring the learned policies of former tasks to the new task through a ”hyper-actor”. The HASAC framework is tested on the virtual robotic manipulation benchmark, Meta-World. Numerical experiments indicate superior performance by HASAC over state-of-the-art deep RL algorithms in terms of reward value, success rate, and task completion time.",
        "DOI": "10.1016/j.engappai.2021.104296",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Biologically meaningful distribution models highlight the benefits of the Paris Agreement for demersal fishing targets in the North Atlantic Ocean",
        "paper_author": "Ramos Martins M.",
        "publication": "Global Ecology and Biogeography",
        "citied_by": "18",
        "cover_date": "2021-08-01",
        "Abstract": "Aim: With climate change challenging marine biodiversity and resource management, it is crucial to anticipate future latitudinal and depth shifts under contrasting global change scenarios to support policy-relevant biodiversity impact assessments [e.g., Intergovernmental Panel on Climate Change (IPCC)]. We aim to demonstrate the benefits of complying with the Paris Agreement (United Nations Framework Convention on Climate Change) and limiting environmental changes, by assessing future distributional shifts of 10 commercially important demersal fish species. Location: Northern Atlantic Ocean. Time period: Analyses of distributional shifts compared near present-day conditions (2000–2017) with two Representative Concentration Pathway (RCP) scenarios of future climate changes (2090–2100): one following the Paris Agreement climate forcing (RCP2.6) and another without stringent mitigation measures (RCP8.5). Major taxa studied: Demersal fish. Methods: We use machine learning distribution models coupled with biologically meaningful predictors to project future latitudinal and depth shifts. Structuring projections with information beyond temperature-based predictors allowed us to encompass the physiological limitations of species better. Results: Our models highlighted the additional roles of temperature, primary productivity and dissolved oxygen in shaping fish distributions (average relative contribution to the models of 32.12 ± 10.24, 15.6 ± 7.5 and 12.1 ± 6.1%, respectively). We anticipated a generalized trend of poleward shifts in both future scenarios, with aggravated changes in suitable area with RCP8.5 (average area loss with RCP2.6 = 13.3 ± 4.1%; RCP8.5 = 40.9 ± 13.3%). Shifts to deeper waters were also predicted to be of greater magnitude with RCP8.5 (average depth gain = 25.4 ± 21.5 m) than with RCP2.6 (average depth gain = 10.4 ± 7.9 m). Habitat losses were projected mostly in the Mediterranean, Celtic and Irish Seas, the southern areas of the North Sea and along the NE coast of North America. Main conclusions: Inclusion of biologically meaningful predictors beyond temperature in species distribution modelling can improve predictive performances. Limiting future climate changes by complying with the Paris Agreement can translate into reduced distributional shifts, supporting biodiversity conservation and resource management.",
        "DOI": "10.1111/geb.13327",
        "affiliation_name": "Universidade do Algarve",
        "affiliation_city": "Faro",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Sudden cardiac death: We are doing well ... But we need to do better!",
        "paper_author": "Tzeis S.",
        "publication": "Heart",
        "citied_by": "2",
        "cover_date": "2021-08-01",
        "Abstract": "NA",
        "DOI": "10.1136/heartjnl-2021-319344",
        "affiliation_name": "Mitera Maternity Hospital",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Federated Learning in Unreliable and Resource-Constrained Cellular Wireless Networks",
        "paper_author": "Salehi M.",
        "publication": "IEEE Transactions on Communications",
        "citied_by": "70",
        "cover_date": "2021-08-01",
        "Abstract": "With growth in the number of smart devices and advancements in their hardware, in recent years, data-driven machine learning techniques have drawn significant attention. However, due to privacy and communication issues, it is not possible to collect this data at a centralized location. Federated learning is a machine learning setting where the centralized location trains a learning model over remote devices. Federated learning algorithms cannot be employed in the real world scenarios unless they consider unreliable and resource-constrained nature of the wireless medium. In this paper, we propose a federated learning algorithm that is suitable for cellular wireless networks. We prove its convergence, and provide a sub-optimal scheduling policy that improves the convergence rate. We also study the effect of local computation steps and communication steps on the convergence of the proposed algorithm. We prove, in practice, federated learning algorithms may solve a different problem than the one that they have been employed for if the unreliability of wireless channels is neglected. Finally, through numerous experiments on real and synthetic datasets, we demonstrate the convergence of our proposed algorithm.",
        "DOI": "10.1109/TCOMM.2021.3081746",
        "affiliation_name": "University of Manitoba",
        "affiliation_city": "Winnipeg",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "COVID-19 highlights the need to optimize critical care resource use: The role of a respiratory-led multidisciplinary team",
        "paper_author": "Balu A.",
        "publication": "Respirology",
        "citied_by": "3",
        "cover_date": "2021-08-01",
        "Abstract": "NA",
        "DOI": "10.1111/resp.14090",
        "affiliation_name": "University of Southampton, Faculty of Medicine",
        "affiliation_city": "Southampton",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Cost-sensitive learning for semi-supervised hit-and-run analysis",
        "paper_author": "Zhu S.",
        "publication": "Accident Analysis and Prevention",
        "citied_by": "13",
        "cover_date": "2021-08-01",
        "Abstract": "Hit-and-run crashes not only degrade the morality, but also result in delays of medical services provided to victims. However, class imbalance problem exists as the number of hit-and-run crashes is much smaller than that of non-hit-and-run crashes. The missing label problem also exists in the crash analysis due to reasons like data barrier such that the information hidden in the unlabelled samples has not been effectively utilised. In this paper, a cost-sensitive semi-supervised logistic regression (CS3LR) model is proposed for hit-and-run analysis, in order to tackle class-imbalanced data distribution and missing label problem, based on the crash dataset of Victorian, Australia (2013–2019). By performing label estimation with logistic regression jointly utilising both labelled and unlabelled data with pseudo labels in a well-designed cost-sensitive semi-supervised maximum likelihood framework, the proposed model can obtain an unbiased likelihood parameter for hit-and-run prediction and analysis. Comparing the experimental results of CS3LR model with two logistic regression models and seven machine learning methods, better performance of CS3LR model is demonstrated. The most significant contributing factors to hit-and-run crashes extracted by CS3LR with only 10% labelled data show a high degree of consistency with the true contributing factors obtained by the supervised cost-sensitive logistic regression with complete hit-and-run labels. The effects of class-weighted ratio and hyper-parameter λ on the performance of hit-and-run crash prediction model have also been analysed. The results can further provide recommendations and implications on the policies and counter-measures for preventing hit-and-run collisions and crimes. The methodology proposed in this paper can also be employed to analyse crash data with other types of missing labels, such as crash severity.",
        "DOI": "10.1016/j.aap.2021.106199",
        "affiliation_name": "School of Civil and Environmental Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Improved nutrient management in cereals using Nutrient Expert and machine learning tools: Productivity, profitability and nutrient use efficiency",
        "paper_author": "Timsina J.",
        "publication": "Agricultural Systems",
        "citied_by": "39",
        "cover_date": "2021-08-01",
        "Abstract": "CONTEXT: Smallholder farmers of the Eastern Indo-Gangetic Plains (EIGP) of South Asia rely mainly on cereal-based cropping systems to meet the food and nutritional demand and support their livelihood. Yet the productivity of the major cereals - rice, wheat, and maize - in the region are far lower than their potential. Nutrient management plays a crucial role in improving cereal yields and economic return, and continued improvement in nutrient management practices and their on-farm implementation is required to develop locally relevant solutions that are site-specific, easy-to-develop and geared towards system resilience. OBJECTIVES: The objective of the study was to conduct the comparative assessment of three nutrient management strategies for the three major cereals considering productivity, profitability and nutrient use efficiencies (NUE); estimate their potential yields and yield gaps; and explain the causes of yield variability across farmer-participatory on-farm trials in the EIGP of Nepal. METHODS: We compared three nutrient management strategies (farmer's fertilizer practice- FP, government recommendation -GR, and Nutrient Expert®- NE-based recommendation), in 600 on-farm trials. We used the NE DSS tool, APSIM – a cropping system simulation model, and machine learning (ML) approaches (Linear Mixed Effect model -LME; and Random Forest model - RF) for the three cereals using data from those trials. The NE and APSIM were chosen due to simplicity in use and their wider evaluation and application in fertilizer recommendation yield prediction; RF was chosen due to its robustness in predictive ability and identifying and ranking factors determining yield or other variables of interest. RESULTS: The NE-based fertilizer recommendations for maize, wheat and rice increased yield by about 3.5, 1.4, and 1.3 t ha−1 respectively, increased profits, and improved NUE over FP or GR. The risk analysis showed that at a given probability level, NE always resulted in higher yields of all cereals than GR or FP. APSIM identified 25th June as optimum transplanting date for rice and 10th December as optimum sowing date for maize and wheat and simulated long-term average potential yield of 7–7.5, 5–5.5 and 13–13.3 t ha−1 respectively for rice, wheat and maize. There were larger yield gaps between PY and FP (2.6–8.5 t ha−1) than PY and NE (2.0–3.7 t ha−1) across crops and villages. The LME model showed highly significant treatment and location effects for grain yield of all cereals. The point estimate of the difference for grain yield as estimated by Tukey's HSD test was highest for NE-FP and lowest for GR-FP for all crops. The RF model identified grain N uptake for rice and grain P and K uptakes for wheat and maize as most influential factors contributing to their grain yield under each nutrient management strategy. CONCLUSIONS: The NE-based nutrient management had significant effects over FP and GR leading to positive changes on yield and economic performance under varied growing environments. SIGNIFICANCE: These findings based on novel tools and approaches have important policy implications for increasing food security and profits from the major cereals by refining or improving the GR or FP and increasing their NUE in Nepal. Studies with larger sample size across varied agro-climatic zones in the EIGP and much of South Asia would help policy makers consider DSS tools and ML approaches suitable for upscaling and large-scale adoption by smallholder farmers.",
        "DOI": "10.1016/j.agsy.2021.103181",
        "affiliation_name": "Mohammed VI Polytechnic University",
        "affiliation_city": "Ben Guerir",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Predictive modelling as a tool for effective municipal waste management policy at different territorial levels",
        "paper_author": "Rosecký M.",
        "publication": "Journal of Environmental Management",
        "citied_by": "50",
        "cover_date": "2021-08-01",
        "Abstract": "Nowadays, the European municipal waste management policy based on the circular economy paradigm demands the closing of material and financial loops at all territorial levels of public administration. The effective planning of treatment capacities (especially sorting plants, recycling, and energy recovery facilities) and municipal waste management policy requires an accurate prognosis of municipal waste generation, and therefore, the knowledge of behavioral, socio-economic, and demographic factors influencing the waste management (and recycling) behavior of households, and other municipal waste producers. To enable public bodies at different territorial levels to undertake an effective action resulting in circular economy we evaluated various factors influencing the generation of municipal waste fractions at regional, micro-regional and municipal level in the Czech Republic. Principal components were used as input for traditional models (multivariable linear regression, generalized linear model) as well as tree-based machine learning models (regression trees, random forest, gradient boosted regression trees). Study results suggest that the linear regression model usually offers a good trade-off between model accuracy and interpretability. When the most important goal of the prediction is supposed to be accuracy, the random forest is generally the best choice. The quality of developed models depends mostly on the chosen territorial level and municipal waste fraction. The performance of these models deteriorates significantly for lower territorial levels because of worse data quality and bigger variability. Only the age structure seems to be important across territorial levels and municipal waste fractions. Nevertheless, also other factors are of high significance in explaining the generation of municipal waste fractions at different territorial levels (e.g. number of economic subjects, expenditures, population density and the level of education). Therefore, there is not one single effective public policy dealing with circular economy strategy that fits all territorial levels. Public representatives should focus on policies effective at specific territorial level. However, performance of the models is poor for lower territorial levels (municipality and micro-regions). Thus, results for municipalities and micro-regions are weak and should be treated as such.",
        "DOI": "10.1016/j.jenvman.2021.112584",
        "affiliation_name": "Brno University of Technology, Faculty of Mechanical Engineering",
        "affiliation_city": "Brno",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Using causal forests to assess heterogeneity in cost-effectiveness analysis",
        "paper_author": "Bonander C.",
        "publication": "Health Economics (United Kingdom)",
        "citied_by": "14",
        "cover_date": "2021-08-01",
        "Abstract": "We develop a method for data-driven estimation and analysis of heterogeneity in cost-effectiveness analyses (CEA) with experimental or observational individual-level data. Our implementation uses causal forests and cross-fitted augmented inverse probability weighted learning to estimate heterogeneity in incremental outcomes, costs and net monetary benefits, as well as other parameters relevant to CEA. We also show how the results can be visualized in relevant ways for the analysis of heterogeneity in CEA, such as using individual-level cost effectiveness planes. Using a simulated dataset and an R package implementing our methods, we show how the approach can be used to estimate the average cost-effectiveness in the entire sample or in subpopulations, explore and analyze the heterogeneity in incremental outcomes, costs and net monetary benefits (and their determinants), and learn policy rules from the data.",
        "DOI": "10.1002/hec.4263",
        "affiliation_name": "Göteborgs Universitet",
        "affiliation_city": "Gothenburg",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Incorporating Climate Change in Pavement Maintenance Policies: Application to Temperature Rise in the Isfahan County, Iran",
        "paper_author": "Mahpour A.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "23",
        "cover_date": "2021-08-01",
        "Abstract": "Although temperature rise is imminent in Iran and could damage asphalt pavements, no national guide exists to adapt them. To ensure the sustainability of pavements against temperature rise, a county-level methodology based on machine-learning algorithms was developed. To show the applicability of the framework, the Isfahan County was studied. The county's climate was found to change from cold-semi-desert to relatively-warm-semi-desert in future decades. Then, optimal maintenance policies before and after climate change were identified. It was concluded that optimal policies of arterial roads before and after climate change were more intense than those of local roads. Furthermore, optimal policies after climate change were more intense than those before climate change at additional costs of 1379.57 MR/KM and 632.49 MR/KM respectively for arterial and local roads. The same methodology could be applied to sustainably adapt asphalt pavements of other counties. To validate the research, a questionnaire survey of pavement management and climate change experts was done. The experts confirmed that the methodology facilitates achieving sustainable development goals #9, #11, and #13 by improving maintenance budget allocation, enhancing policy-makers communication with authorities, maintaining adequate technical and end-user levels of service, and adapting pavements to climate change through cost-effective and performance-effective maintenance policies.",
        "DOI": "10.1016/j.scs.2021.102960",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Novel methodology for developing a safety standard based on clustering of experts’ assessments of safety requirements",
        "paper_author": "Aly S.",
        "publication": "Safety Science",
        "citied_by": "8",
        "cover_date": "2021-08-01",
        "Abstract": "The practice of developing product or system safety standards is currently conducted with high level of subjectivity, which affects the reliability of development outcomes. The decision to adopt specific safety requirements into the standard is usually based on the knowledge, intuition and experience of the technical expert involved in developing the body of the safety standard made up of those requirements or specifications. This is usually carried out without analyzing risk attributes or factors addressed by each safety requirement constituting a safety standard. This can lead to inaccuracy and lack of reliability due to either under-estimation or over-estimation of risks involved. This research presents unprecedented, novel, structured and objective methodology, that aims to improve the practice of developing safety standards. In order to accomplish the above end, the proposed methodology acts to prioritize the system’ safety requirements of each system's design elements based on a set of commonly identified risk factors they address. We have investigated the currently existing risk prioritization and multi-criterion decision making techniques, and found that machine learning data clustering approaches can be adequate especially in case of relatively large number of assessed decision alternatives (i.e., the assessed safety requirements). We have elaborated the merits of the proposed clustering-based methodology over existing prominent ones. The proposed methodology starts with analyzing product or system safety to identify common risk factors. A numerical scale is used to enable objective quantification of risk factors’ values for each safety requirement by multiple experts. The obtained experts’ numerical assessments of each safety requirement are then averaged to represent the raw data set containing risk profiles of each safety requirement assessed. This risk factors data set is then used by fuzzy c-means clustering algorithm, to organize them into groups of different level of priorities, so as to prioritize their corresponding safety requirements. We have applied the proposed methodology on a real case study of developing school bus safety standard. The main benefit of the proposed methodology includes its capability to support the safety standards development practitioners and policy makers, as well as technical experts in objectively and systematically carry out the critical decision of adoption, exclusion and update of the safety requirements into the developed safety standard. Additionally, it can efficiently guide safety engineers and inspectors to undertake more reliable and structured risk assessment process. Over and above, the implementation of the proposed methodology is guaranteed to result in more reliable, accurate and risk-informed safety standard.",
        "DOI": "10.1016/j.ssci.2021.105292",
        "affiliation_name": "Faculty of Engineering Helwan",
        "affiliation_city": "Helwan",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Smart cities: Understanding policies, standards, applications and case studies",
        "paper_author": "Salkuti S.R.",
        "publication": "International Journal of Electrical and Computer Engineering",
        "citied_by": "15",
        "cover_date": "2021-08-01",
        "Abstract": "This paper presents the integration of required basic facilities of living such as healthcare, education, and infrastructure for building the smart cities. The administrations of smart cities should have the smart governance, safety measures with cultural and social stimulus. Four building blocks of smart cities, i.e., people and environment, smart utilities, smart technology and smart administration are described in the present paper. The aim of this paper is to give a clearer perspective of the key decisions with spatial reference that may assume a key part in the plan of a smart city technique. Application of various technologies, for examples big data, artificial intelligence, machine learning, internet of things (IoT), cloud computing, block chain technology to the smart cities are discussed in this paper. Various challenges of smart cities such as information technology (IT) infrastructure, cost, privacy, security, efficiency, fossil fuel dependency and congested commutes with proposed solutions are also presented in this paper.",
        "DOI": "10.11591/ijece.v11i4.pp3137-3144",
        "affiliation_name": "Woosong University",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Multi-Parallel Adaptive Grasshopper Optimization Technique for Detecting Anonymous Attacks in Wireless Networks",
        "paper_author": "Dwivedi S.",
        "publication": "Wireless Personal Communications",
        "citied_by": "5",
        "cover_date": "2021-08-01",
        "Abstract": "For a number of years, due to exponential increase in the demand for sustainable environment, suspicious activities have recently been identified as over-serious threats that are continually processing and growing. Identifying suspicious activities in the domain of cyber security is considered as a growing concern of research. To deal with suspicious threats, network requires traffic surveillance accompanied by beardown security policies. In order to handle data outflow, spoofing, disruption of service, energy exploiting, and insecure gateways range of attacks issues, the existing intrusion detection systems (IDSs) have observed to be less efficient as many of them are not able to detect anomalies with the change in the definition of the attack. To build a protected system against various cyber-attacks in computer networks, in this study, we introduce a multi-parallel adaptive evolutionary technique to utilize adaptation mechanism in the group of swarms for network intrusion detection. After that, simulated annealing is incorporated into multi-parallel adaptive grasshopper optimization technique to further improve the agent quality of individual after each iteration. It has revolutionized in the recent era for efficient threat detection with great performance in a certain time limit. The simulations are performed on three IDS datasets such as NSL-KDD, AWID-ATK-R, and NGIDS-DS. The proposed technique is compared with various existing techniques using different evaluation metrics. The comparative analysis demonstrates that the applicability of proposed technique concerning its merits outperforms the others algorithms.",
        "DOI": "10.1007/s11277-021-08368-5",
        "affiliation_name": "National Institute of Technology Raipur",
        "affiliation_city": "Raipur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A survey of inverse reinforcement learning: Challenges, methods and progress",
        "paper_author": "Arora S.",
        "publication": "Artificial Intelligence",
        "citied_by": "359",
        "cover_date": "2021-08-01",
        "Abstract": "Inverse reinforcement learning (IRL) is the problem of inferring the reward function of an agent, given its policy or observed behavior. Analogous to RL, IRL is perceived both as a problem and as a class of methods. By categorically surveying the extant literature in IRL, this article serves as a comprehensive reference for researchers and practitioners of machine learning as well as those new to it to understand the challenges of IRL and select the approaches best suited for the problem on hand. The survey formally introduces the IRL problem along with its central challenges such as the difficulty in performing accurate inference and its generalizability, its sensitivity to prior knowledge, and the disproportionate growth in solution complexity with problem size. The article surveys a vast collection of foundational methods grouped together by the commonality of their objectives, and elaborates how these methods mitigate the challenges. We further discuss extensions to the traditional IRL methods for handling imperfect perception, an incomplete model, learning multiple reward functions and nonlinear reward functions. The article concludes the survey with a discussion of some broad advances in the research area and currently open research questions.",
        "DOI": "10.1016/j.artint.2021.103500",
        "affiliation_name": "University of Georgia School of Computing",
        "affiliation_city": "Athens",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Soil predictors are crucial for modelling vegetation distribution and its responses to climate change",
        "paper_author": "Oliveira G.d.C.",
        "publication": "Science of the Total Environment",
        "citied_by": "25",
        "cover_date": "2021-08-01",
        "Abstract": "Bioclimatic envelope models have been extensively used to predict the vegetation dynamics in response to climate changes. However, they are prone to the uncertainties arising from General Circulation Models (GCMs), classification algorithms and predictors, with low-resolution results and little detail at the regional level. Novel research has focused on the improvement of these models through a combination of climate and soil predictors to enhance ecological consistency. In this framework, we aimed to apply a joint edaphoclimatic envelope to predict the current and future vegetation distribution in the semiarid region of Brazil, which encompasses several classes of vegetation in response to the significant environmental heterogeneity. We employed a variety of machine learning algorithms and GCMs under RCP 4.5 and 8.5 scenarios of Coupled Model Intercomparison Project Phase 5 (CMIP5), in 1 km resolution. The combination of climate and soil predictors resulted in higher detail at landscape-scale and better distinction of vegetations with overlapping climatic niches. In forecasts, soil predictors imposed a buffer effect on vegetation dynamics as they reduced shifts driven solely by climatic drift. Our results with the edaphoclimatic approach pointed to an expansion of the dry Caatinga vegetation, ranging from an average of 16% to 24% on RCP 4.5 and RCP8.5 scenarios, respectively. The shift in environmental suitability from forest to open and dry vegetation implies a major loss to biodiversity, as well as compromising the provision of ecosystem services important for maintaining the economy and livelihoods of the world's largest semiarid population. Predicting the most susceptible regions to future climate change is the first step in developing strategies to mitigate impacts in these areas.",
        "DOI": "10.1016/j.scitotenv.2021.146680",
        "affiliation_name": "Universidade Federal de Minas Gerais",
        "affiliation_city": "Belo Horizonte",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Living with arsenic in the environment: An examination of current awareness of farmers in the Bengal basin using hybrid feature selection and machine learning",
        "paper_author": "Mishra D.",
        "publication": "Environment International",
        "citied_by": "13",
        "cover_date": "2021-08-01",
        "Abstract": "High levels of arsenic in drinking water and food materials continue to pose a global health challenge. Over 127 million people alone in Bangladesh (BD) and West Bengal (WB) state of India are exposed to elevated levels of arsenic in drinking water. Despite decades of research and outreach, arsenic awareness in communities continue to be low. Specifically, very few studies reported arsenic awareness among low-income farming communities. A comprehensive approach to assess arsenic awareness is a key step in identifying research and development priorities so that appropriate stakeholder engagement may be designed to tackle arsenic menace. In this study, we developed a comprehensive arsenic awareness index (CAAI) and identified key awareness drivers (KADs) of arsenic to help evaluate farmers’ preferences in dealing with arsenic in the environment. The CAAI and KADs were developed using a questionnaire survey in conjunction with ten machine learning (ML) models coupled with a hybrid feature selection approach. Two questionnaire surveys comprising of 73 questions covering health, water and community, and food were conducted in arsenic-affected areas of WB and BD. Comparison of CAAIs showed that the BD farmers were generally more arsenic-aware (CAAI = 7.7) than WB farmers (CAAI = 6.8). Interestingly, the reverse was true for the awareness linked to arsenic in the food chain. Application of hybrid feature selection identified 15 KADs, which included factors related to stakeholder interventions and cropping practices instead of commonly perceived factors such as age, gender and income. Among ML algorithms, classification and regression trees and single C5.0 tree could estimate CAAIs with an average accuracy of 84%. Both communities agreed on policy changes on water testing and clean water supply. The CAAI and KADs combination revealed a contrasting arsenic awareness between the two farming communities, albeit their cultural similarities. Specifically, our study shows the need for increasing awareness of risks through the food chain in BD, whereas awareness campaigns should be strengthened to raise overall awareness in WB possibly through media channels as deemed effective in BD.",
        "DOI": "10.1016/j.envint.2021.106529",
        "affiliation_name": "University of South Australia",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Gradient Statistics Aware Power Control for Over-the-Air Federated Learning",
        "paper_author": "Zhang N.",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "121",
        "cover_date": "2021-08-01",
        "Abstract": "Federated learning (FL) is a promising technique that enables many edge devices to train a machine learning model collaboratively in wireless networks. By exploiting the superposition nature of wireless waveforms, over-the-air computation (AirComp) can accelerate model aggregation and hence facilitate communication-efficient FL. Due to channel fading, power control is crucial in AirComp. Prior works assume that the signals to be aggregated from each device, i.e., local gradients have identical statistics. In FL, however, gradient statistics vary over both training iterations and feature dimensions, and are unknown in advance. This paper studies the power control problem for over-the-air FL by taking gradient statistics into account. The goal is to minimize the aggregation error by optimizing the transmit power at each device subject to average power constraints. We obtain the optimal policy in closed form when gradient statistics are given. Notably, we show that the optimal transmit power is continuous and monotonically decreases with the squared multivariate coefficient of variation (SMCV) of gradient vectors. We then propose a method to estimate gradient statistics with negligible communication cost. Experimental results demonstrate that the proposed gradient-statistics-aware power control achieves higher test accuracy than the existing schemes for a wide range of scenarios.",
        "DOI": "10.1109/TWC.2021.3065748",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Access Control Policy Maintenance in IoT Based on Machine Learning",
        "paper_author": "Zhao Y.",
        "publication": "Journal of Circuits, Systems and Computers",
        "citied_by": "2",
        "cover_date": "2021-08-01",
        "Abstract": "The rapid growth of communication networking, ubiquitous sensing, and signal processing, has promoted the development of the Internet of Things (IoT). However, the IoT is essentially dynamic and has no clearly defined network boundary, unauthorized access and data leakage may be much easier. Attribute-based access control (ABAC) can solve the problem of fine-grained access control and large-scale user dynamic expansion in complex information systems, and provides an ideal access control solution for an open network environment, which is more suitable for the dynamic access environment of IoT. However, the dynamic nature of IoT brings new challenges to access control. On the one hand, as new devices and services are continuously deployed, administrators need to manually formulate new rules, which is time-consuming and error-prone. On the other hand, as the IoT environment is continuously changing, the access policy easily becomes unsuitable for the current environment. In order to solve the above two problems, we propose a new scheme named Policy Maintenance-based machine learning (PMML), which includes two modules named Policy Generalization (PG) and Policy Evaluation (PE). After the access control model is deployed, automated PG and PE are carried out to maintain the rule set. In the PG module, we define a novel measure, resource similarity, and integrate it into policy mining so that policies could generalize among related resources. In the PE module, we introduce a quantitative method to assess rules and prune rules of low-quality. We conduct our experiments on real-world enterprise access logs from Amazon, and thoroughly analyzed the effects of different hyper-parameters on the experimental results. The experimental results have qualitatively and quantitatively shown the effectiveness of our proposed scheme.",
        "DOI": "10.1142/S0218126621501899",
        "affiliation_name": "Nanjing University of Science and Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A model free controller based on reinforcement learning for active steering system with uncertainties",
        "paper_author": "Zhao J.",
        "publication": "Proceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering",
        "citied_by": "3",
        "cover_date": "2021-08-01",
        "Abstract": "Vehicle steering control is crucial to autonomous vehicles. However, unknown parameters and uncertainties of vehicle steering systems bring a great challenge to its control performance, which needs to be tackled urgently. Therefore, this paper proposes a novel model free controller based on reinforcement learning for active steering system with unknown parameters. The model of the active steering system and the Brushless Direct Current (BLDC) motor is built to construct a virtual object in simulations. The agent based on Deep Deterministic Policy Gradient (DDPG) algorithm is built, including actor network and critic network. The rewards from environment are designed to improve the effectiveness of agent. Simulations and testbench experiments are implemented to train the agent and verify the effectiveness of the controller. Results show that the proposed algorithm can acquire the network parameters and achieve effective control performance without any prior knowledges or models. The proposed agent can adapt to different vehicles or active steering systems easily and effectively with only retraining of the network parameters.",
        "DOI": "10.1177/0954407021994416",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Spatial modeling of susceptibility to subsidence using machine learning techniques",
        "paper_author": "Mohammady M.",
        "publication": "Stochastic Environmental Research and Risk Assessment",
        "citied_by": "23",
        "cover_date": "2021-08-01",
        "Abstract": "Land subsidence is a hazard that results from conditioning factors that cause environmental change and generate social and economic impacts. Some of these factors may increase dissolution of calcareous stones, change groundwater storage, or stem from mining, faulting, and seismic activity. Semnan Plain, Iran is experiencing land subsidence that, along with secondary impacts like surface fissures, is becoming increasingly troublesome. This study modeled land subsidence and created a susceptibility map using multivariate adaptive regression spline (MARS), mixture discriminant analysis (MDA), and boosted regression tree (BRT) machine-learning methods. Analysis of satellite imagery, documents reporting past subsidence, and a contemporary field survey identified 65 sinkholes on Semnan Plain. Twelve conditioning factors were selected for analysis from a review of the scholarly literature, field investigation, and data availability. The three methods were used to model subsidence from a training subset of the known sites. The models were validated with the remaining subset of subsidence locations. Finally, susceptibility maps were used to predict other sites that are highly likely to see subsidence. Receiver operating characteristic curves and the area under the curves (AUC) were applied to assess the accuracies of the maps. AUC values (0.637, 0.783, and 0.712 for the BRT, MARS, and MDA models respectively) showed that MARS generated the most accurate model, MDA generated the second most accurate, and BRT’s was the least accurate model. Subsidence susceptibility maps as produced here can be useful, meaningful, and functional tools for local and regional planners and policy makers involved in land use planning, resource management, and hazard mitigation.",
        "DOI": "10.1007/s00477-020-01967-x",
        "affiliation_name": "Texas State University",
        "affiliation_city": "San Marcos",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An Edge Computing Framework for Powertrain Control System Optimization of Intelligent and Connected Vehicles Based on Curiosity-Driven Deep Reinforcement Learning",
        "paper_author": "Hu B.",
        "publication": "IEEE Transactions on Industrial Electronics",
        "citied_by": "35",
        "cover_date": "2021-08-01",
        "Abstract": "For the ongoing revolution in developing intelligent and connected vehicles (ICVs), there is a lack of research for powertrain control systems using the latest artificial intelligence and vehicle-to-everything technology that have already been widely adopted in the autonomous driving systems. In this context, recent development of deep reinforcement learning (DRL) and one of the latest computing frameworks are coupled to facilitate an onboard-based intelligent powertrain control. Taking the boost control of a diesel engine equipped with variable geometry turbocharger as an example, the results show that the final control behavior indicated by the cumulated rewards is improved by 50.43% and the learning efficiency is improved by 74.29% for the proposed curiosity-driven DRL algorithm, compared with the same structure DRL algorithm with classic random exploration policy. In addition, unlike most of the DRL-based powertrain optimization algorithms, which have only been applied to single-machine architecture, this work manages the proposed DRL algorithm in parallel and, more importantly, from an edge computing perspective. This, in addition to greatly speeding up the algorithm training, can also realize a good balance of control accuracy and generality depending upon the selected training scenario. Moreover, unlike most of the cloud computing frameworks, which require low network latency, the proposed architecture can achieve a similar final control performance even if good network communication is not allowed. Compared with other existing powertrain control methods, the proposed algorithm is able to approximate a global powertrain control optimization autonomously in a connected manner, making it attractive to current ICVs with advanced automated driving and traditional powertrain control.",
        "DOI": "10.1109/TIE.2020.3007100",
        "affiliation_name": "Chongqing University of Technology",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "AC-SUM-GAN: Connecting Actor-Critic and Generative Adversarial Networks for Unsupervised Video Summarization",
        "paper_author": "Apostolidis E.",
        "publication": "IEEE Transactions on Circuits and Systems for Video Technology",
        "citied_by": "62",
        "cover_date": "2021-08-01",
        "Abstract": "This paper presents a new method for unsupervised video summarization. The proposed architecture embeds an Actor-Critic model into a Generative Adversarial Network and formulates the selection of important video fragments (that will be used to form the summary) as a sequence generation task. The Actor and the Critic take part in a game that incrementally leads to the selection of the video key-fragments, and their choices at each step of the game result in a set of rewards from the Discriminator. The designed training workflow allows the Actor and Critic to discover a space of actions and automatically learn a policy for key-fragment selection. Moreover, the introduced criterion for choosing the best model after the training ends, enables the automatic selection of proper values for parameters of the training process that are not learned from the data (such as the regularization factor $\\sigma $ ). Experimental evaluation on two benchmark datasets (SumMe and TVSum) demonstrates that the proposed AC-SUM-GAN model performs consistently well and gives SoA results in comparison to unsupervised methods, that are also competitive with respect to supervised methods.",
        "DOI": "10.1109/TCSVT.2020.3037883",
        "affiliation_name": "Centre for Research and Technology-Hellas",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Robust Android Malware Detection System Against Adversarial Attacks Using Q-Learning",
        "paper_author": "Rathore H.",
        "publication": "Information Systems Frontiers",
        "citied_by": "49",
        "cover_date": "2021-08-01",
        "Abstract": "Since the inception of Andoroid OS, smartphones sales have been growing exponentially, and today it enjoys the monopoly in the smartphone marketplace. The widespread adoption of Android smartphones has drawn the attention of malware designers, which threatens the Android ecosystem. The current state-of-the-art Android malware detection systems are based on machine learning and deep learning models. Despite having superior performance, these models are susceptible to adversarial attack. Therefore in this paper, we developed eight Android malware detection models based on machine learning and deep neural network and investigated their robustness against the adversarial attacks. For the purpose, we created new variants of malware using Reinforcement Learning, which will be misclassified as benign by the existing Android malware detection models. We propose two novel attack strategies, namely single policy attack and multiple policy attack using reinforcement learning for white-box and grey-box scenario respectively. Putting ourselves in adversary’ shoes, we designed adversarial attacks on the detection models with the goal of maximising fooling rate, while making minimum modifications to the Android application and ensuring that the app’s functionality and behaviour does not change. We achieved an average fooling rate of 44.21% and 53.20% across all the eight detection models with maximum five modifications using a single policy attack and multiple policy attack, respectively. The highest fooling rate of 86.09% with five changes was attained against the decision tree based model using the multiple policy approach. Finally, we propose an adversarial defence strategy which reduces the average fooling rate by threefold to 15.22% against a single policy attack, thereby increasing the robustness of the detection models i.e. the proposed model can effectively detect variants (metamorphic) of malware. The experimental analysis shows that our proposed Android malware detection system using reinforcement learning is more robust against adversarial attacks.",
        "DOI": "10.1007/s10796-020-10083-8",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Explaining Deep Learning Models through Rule-Based Approximation and Visualization",
        "paper_author": "Soares E.",
        "publication": "IEEE Transactions on Fuzzy Systems",
        "citied_by": "24",
        "cover_date": "2021-08-01",
        "Abstract": "This article describes a novel approach to the problem of developing explainable machine learning models. We consider a deep reinforcement learning (DRL) model representing a highway path planning policy for autonomous highway driving [1]. The model constitutes a mapping from the continuous multidimensional state space characterizing vehicle positions and velocities to a discrete set of actions in longitudinal and lateral direction. It is obtained by applying a customized version of the double deep Q-network learning algorithm [2]. The main idea is to approximate the DRL model with a set of IF-THEN rules that provide an alternative interpretable model, which is further enhanced by visualizing the rules. This concept is rationalized by the universal approximation properties of the rule-based models with fuzzy predicates. The proposed approach includes a learning engine composed of zero-order fuzzy rules, which generalize locally around the prototypes by using multivariate function models. The adjacent (in the data space) prototypes, which correspond to the same action, are further grouped and merged into the so-called MegaClouds reducing significantly the number of fuzzy rules. The input selection method is based on ranking the density of the individual inputs. Experimental results show that the specific DRL agent can be interpreted by approximating with families of rules of different granularity. The method is computationally efficient and can be potentially extended to addressing the explainability of the broader set of fully connected deep neural network models.",
        "DOI": "10.1109/TFUZZ.2020.2999776",
        "affiliation_name": "School of Computing and Communications, Lancaster University",
        "affiliation_city": "Lancaster",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Method of physical inventory checking on cigarette stereoscopic warehouse based on UAV",
        "paper_author": "Zhao Z.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-07-28",
        "Abstract": "The elevated warehouse is the initial place of the cigarette end-product. It is an important link between the workshop and the delivery of cigarette. It undertakes large storage tasks of cigarette end-product in the limited space. The traditional manual inventory is difficult because of the large tunnel depth, high building height and dense distribution of goods. Based on the actual situation of the elevated warehouse of cigarette products, by learning the inventory management technology of advanced enterprises outside the tobacco industry, combined with the guidelines and policies of the tobacco industry, applying artificial intelligence technology, this paper puts forward a scheme of UAV inventory of cigarette end-product.",
        "DOI": "10.1145/3480651.3480655",
        "affiliation_name": "Hongta tobacco (group) co. LTD",
        "affiliation_city": null,
        "affiliation_country": "China"
    },
    {
        "paper_title": "Efficient real-time earliest deadline first based scheduling for apache spark",
        "paper_author": "Neciu L.F.",
        "publication": "Proceedings - 2021 20th International Symposium on Parallel and Distributed Computing, ISPDC 2021",
        "citied_by": "4",
        "cover_date": "2021-07-28",
        "Abstract": "Apache Spark is a distributed computing framework for fast in-memory data analysis, Machine Learning jobs, and SQL queries that employs Resilient Distributed Dataset for distributing data and Directed Acyclic Graph for scheduling computations. Currently, Spark provides two scheduling policies for tasks pending execution: a First In First Out policy and a FAIR policy, providing no support for deadline-based real-time scheduling. In this paper, we present a new system designed to accept deadlines for heterogeneous Spark Jobs and perform a real-time scheduling policy based on Earliest Deadline First (EDF). To showcase the efficiency of our scheduling policy, we compare and analyze the performance of our solution with the current Spark execution policies in terms of job lateness. We empirically prove that our real-time policy provides much lower lateness given suitable constraints.",
        "DOI": "10.1109/ISPDC52870.2021.9521640",
        "affiliation_name": "Institutul Naţional de Cercetare-Dezvoltare in Informatica",
        "affiliation_city": "Bucharest",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "Dynamic Changes in Community Deprivation of Access to Urban Green Spaces by Multiple Transport Modes",
        "paper_author": "Cheng S.",
        "publication": "Frontiers in Public Health",
        "citied_by": "12",
        "cover_date": "2021-07-27",
        "Abstract": "Urban green spaces (UGSs) improve the quality of life of urban inhabitants. With the acceleration of urbanization and changes in traffic networks, it remains unclear whether changes in the distribution of UGSs can satisfy the needs of all inhabitants and offer equal services to inhabitants from different socioeconomic backgrounds. This study addresses this issue by analyzing dynamic changes in UGS accessibility in 2012, 2016, and 2020 for inhabitants of the central urban area of Fuzhou in China at the community level. The study introduces multiple transportation modes for an accessibility estimation based on a framework using the two-step floating catchment area method and examines the dynamic changes in community deprivation of UGS accessibility using Kernel regularized least squares, a machine learning algorithm. The results demonstrate that spatial disparities of UGS accessibility exist among the multi-transport modes and vary with time. Communities with high accessibility to UGSs by walking are scattered around the urban area; for accessibility by cycling, the high accessibility regions expand and surround the regions with low accessibility in the core urban areas, forming a semi-enclosed spatial pattern. However, the core urban spatial orientation of UGS accessibility by public transit demonstrates a reverse trend to the above two modes. The spatial pattern of UGS accessibility also varies over time, and the growth rate of accessibility slightly declined during the study period. Furthermore, the increase in UGS accessibility tended to slow from 2016–2020 compared with 2012–2016, and the trend toward equality was also erratic. The degree of deprivation for communities first weakened and was then aggravated, corresponding to the slowdown in the growth rate of accessibility, leading to the persistence existence of social inequality. Moreover, significant deprivation mainly exists among less educated people or those using the cycling and integrated travel modes. Although public transport is developing, deprived communities, such as communities with large proportion of older people, have experienced a decline in access to UGSs by public transport. Based on these findings, the study proposes a policy framework for the balanced distribution of UGSs as part of urbanization.",
        "DOI": "10.3389/fpubh.2021.615432",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Preparing the Next Generation Advanced Manufacturing Workforce Using Collaborative Robots and Experiential Learning (Work in Progress)",
        "paper_author": "Mbanisi K.C.",
        "publication": "ASEE Annual Conference and Exposition, Conference Proceedings",
        "citied_by": "0",
        "cover_date": "2021-07-26",
        "Abstract": "The widening skills gap and shrinking workforce in advanced manufacturing is a critical national problem. One solution is to open the minds of schoolchildren to the joy of robotics in manufacturing to stir their enthusiasm, with a larger goal of generating future career interest. This paper describes the application and assessment of a 7-week long after-school experiential learning program using collaborative robots that introduced 16 middle school students from underrepresented and underserved groups to robotics and advanced manufacturing. Through pre- and post-surveys, students reported feeling better informed about collaborative robots, how they are used in manufacturing, how to program them, as well as how to operate industry standard machine tools. This work in progress study may serve as a valuable guide for K-12 STEM educators and policy makers interested in developing programs which inspire and equip pre-college students to pursue engineering careers. Future work will enlarge the sample size of participants through additional offerings and include quantitative evaluations of instructional effectiveness in addition to the student surveys.",
        "DOI": "NA",
        "affiliation_name": "Worcester Polytechnic Institute",
        "affiliation_city": "Worcester",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep deterministic policy gradient-based combustion optimization method for coal-fired boiler",
        "paper_author": "Bao X.",
        "publication": "Chinese Control Conference, CCC",
        "citied_by": "3",
        "cover_date": "2021-07-26",
        "Abstract": "Boiler combustion optimization technology aims to improve boiler efficiency while reducing NOx emissions. However, the combustion optimization methods commonly used lack the self-learning capability and have low utilization of historical data. In this paper, a combustion optimization method based on the deep deterministic policy gradient (DDPG) algorithm is proposed. Firstly, dynamic modeling is realized based on online least squares support vector machine and multi-kernel learning, and the optimal kernel function weight coefficient and related kernel parameters are selected by an improved particle swarm optimization algorithm. Secondly, the DDPG algorithm is introduced to optimize the control variables. The simulation results demonstrate that the multi-kernel least squares support vector machine (MKLSSVM) model has better local fitting performance and global generalization performance. The DDPG optimizer and MKLSSVM predictor can effectively improve the boiler efficiency and reduce pollutant emissions while maintaining the stable reheat steam temperature.",
        "DOI": "10.23919/CCC52363.2021.9549318",
        "affiliation_name": "Key Lab of Energy Thermal Conversion and Control, Ministry of Education",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Zero-shot policy generation in lifelong reinforcement learning",
        "paper_author": "Qian Y.M.",
        "publication": "Neurocomputing",
        "citied_by": "5",
        "cover_date": "2021-07-25",
        "Abstract": "Lifelong reinforcement learning (LRL) is an important approach to achieve continual lifelong learning of multiple reinforcement learning tasks. The two major methods used in LRL are task decomposition and policy knowledge extraction. Policy knowledge extraction method in LRL can share knowledge for tasks in different task domains and for tasks in the same task domain with different system environmental coefficients. However, the generalization ability of policy knowledge extraction method is limited on learned tasks rather than learned task domains. In this paper, we propose a cross-domain lifelong reinforcement learning algorithm with zero-shot policy generation ability (CDLRL-ZPG) to improve generalization ability of policy knowledge extraction method from learned tasks to learned task domains. In experiments, we evaluated CDLRL-ZPG performance on four task domains. And our results show that the proposed algorithm can directly generate satisfactory results without needing a trial and error learning process to achieve zero-shot learning in general.",
        "DOI": "10.1016/j.neucom.2021.02.058",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Situated Accountability: Ethical Principles, Certification Standards, and Explanation Methods in Applied AI",
        "paper_author": "Henriksen A.",
        "publication": "AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "15",
        "cover_date": "2021-07-21",
        "Abstract": "Artificial intelligence (AI) has the potential to benefit humans and society by its employment in important sectors. However, the risks of negative consequences have underscored the importance of accountability for AI systems, their outcomes, and the users of such systems. In recent years, various accountability mechanisms have been put forward in pursuit of the responsible design, development, and use of AI. In this article, we provide an in-depth study of three such mechanisms, as we analyze Scandinavian AI developers' encounter with (1) ethical principles, (2) certification standards, and (3) explanation methods. By doing so, we contribute to closing a gap in the literature between discussions of accountability on the research and policy level, and accountability as a responsibility put on the shoulders of developers in practice. Our study illustrates important flaws in the current enactment of accountability as an ethical and social value which, if left unchecked, risks undermining the pursuit of responsible AI. By bringing attention to these flaws, the article signals where further work is needed in order to build effective accountability systems for AI.",
        "DOI": "10.1145/3461702.3462564",
        "affiliation_name": "Aarhus Universitet",
        "affiliation_city": "Aarhus",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Skilled and Mobile: Survey Evidence of AI Researchers' Immigration Preferences",
        "paper_author": "Zwetsloot R.",
        "publication": "AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "3",
        "cover_date": "2021-07-21",
        "Abstract": "Countries, companies, and universities are increasingly competing over top-tier artificial intelligence (AI) researchers. Where are these researchers likely to immigrate and what affects their immigration decisions? We conducted a survey (n = 524) of the immigration preferences and motivations of researchers that had papers accepted at one of two prestigious AI conferences: the Conference on Neural Information Processing Systems (NeurIPS) and the International Conference on Machine Learning (ICML). We find that the U.S. is the most popular destination for AI researchers, followed by the U.K., Canada, Switzerland, and France. A country's professional opportunities stood out as the most common factor that influences immigration decisions of AI researchers, followed by lifestyle and culture, the political climate, and personal relations. The destination country's immigration policies were important to just under half of the researchers surveyed, while around a quarter noted current immigration difficulties to be a deciding factor. Visa and immigration difficulties were perceived to be a particular impediment to conducting AI research in the U.S., the U.K., and Canada. Implications of the findings for the future of AI talent policies and governance are discussed.",
        "DOI": "10.1145/3461702.3462617",
        "affiliation_name": "Georgetown University",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Face Mis-ID: An Interactive Pedagogical Tool Demonstrating Disparate Accuracy Rates in Facial Recognition",
        "paper_author": "Raz D.",
        "publication": "AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "10",
        "cover_date": "2021-07-21",
        "Abstract": "This paper reports on the making of an interactive demo to illustrate algorithmic bias in facial recognition. Facial recognition technology has been demonstrated to be more likely to misidentify women and minoritized people. This risk, among others, has elevated facial recognition into policy discussions across the country, where many jurisdictions have already passed bans on its use. Whereas scholarship on the disparate impacts of algorithmic systems is growing, general public awareness of this set of problems is limited in part by the illegibility of machine learning systems to non-specialists. Inspired by discussions with community organizers advocating for tech fairness issues, we created the Face Mis-ID Demo to reveal the algorithmic functions behind facial recognition technology and to demonstrate its risks to policymakers and members of the community. In this paper, we share the design process behind this interactive demo, its form and function, and the design decisions that honed its accessibility, toward its use for improving legibility of algorithmic systems and awareness of the sources of their disparate impacts.",
        "DOI": "10.1145/3461702.3462627",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Machine Learning and the Meaning of Equal Treatment",
        "paper_author": "Simons J.",
        "publication": "AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "9",
        "cover_date": "2021-07-21",
        "Abstract": "Approaches to non-discrimination are generally informed by two principles: striving for equality of treatment, and advancing various notions of equality of outcome. We consider when and why there are trade-offs in machine learning between respecting formalistic interpretations of equal treatment and advancing equality of outcome. Exploring a hypothetical discrimination suit against Facebook, we argue that interpretations of equal treatment which require blindness to difference may constrain how machine learning can be deployed to advance equality of outcome. When machine learning models predict outcomes that are unevenly distributed across racial groups, using those models to advance racial justice will often require deliberately taking race into account. We then explore the normative stakes of this tension. We describe three pragmatic policy options underpinned by distinct interpretations and applications of equal treatment. A status quo approach insists on blindness to difference, permitting the design of machine learning models that compound existing patterns of disadvantage. An industry-led approach would specify a narrow set of domains in which institutions were permitted to use protected characteristics to actively reduce inequalities of outcome. A government-led approach would impose positive duties that require institutions to consider how best to advance equality of outcomes and permit the use of protected characteristics to achieve that goal. We argue that while machine learning offers significant possibilities for advancing racial justice and outcome-based equality, harnessing those possibilities will require a shift in the normative commitments that underpin the interpretation and application of equal treatment in non-discrimination law and the governance of machine learning.",
        "DOI": "10.1145/3461702.3462556",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Who Gets What, According to Whom? An Analysis of Fairness Perceptions in Service Allocation",
        "paper_author": "Hannan J.",
        "publication": "AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "9",
        "cover_date": "2021-07-21",
        "Abstract": "Algorithmic fairness research has traditionally been linked to the disciplines of philosophy, ethics, and economics, where notions of fairness are prescriptive and seek objectivity. Increasingly, however, scholars are turning to the study of what different people perceive to be fair, and how these perceptions can or should help to shape the design of machine learning, particularly in the policy realm. The present work experimentally explores five novel research questions at the intersection of the \"Who,\"\"What,\"and \"How\"of fairness perceptions. Specifically, we present the results of a multi-factor conjoint analysis study that quantifies the effects of the specific context in which a question is asked, the framing of the given question, and who is answering it. Our results broadly suggest that the \"Who\"and \"What,\"at least, matter in ways that are 1) not easily explained by any one theoretical perspective, 2) have critical implications for how perceptions of fairness should be measured and/or integrated into algorithmic decision-making systems.",
        "DOI": "10.1145/3461702.3462568",
        "affiliation_name": "University at Buffalo, The State University of New York",
        "affiliation_city": "Buffalo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Fair Machine Learning under Partial Compliance",
        "paper_author": "Dai J.",
        "publication": "AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society",
        "citied_by": "4",
        "cover_date": "2021-07-21",
        "Abstract": "Typically, fair machine learning research focuses on a single decision maker and assumes that the underlying population is stationary. However, many of the critical domains motivating this work are characterized by competitive marketplaces with many decision makers. Realistically, we might expect only a subset of them to adopt any non-compulsory fairness-conscious policy, a situation that political philosophers call partial compliance. This possibility raises important questions: how does partial compliance and the consequent strategic behavior of decision subjects affect the allocation outcomes? If k% of employers were to voluntarily adopt a fairness-promoting intervention, should we expect k% progress (in aggregate) towards the benefits of universal adoption, or will the dynamics of partial compliance wash out the hoped-for benefits? How might adopting a global (versus local) perspective impact the conclusions of an auditor? In this paper, we propose a simple model of an employment market, leveraging simulation as a tool to explore the impact of both interaction effects and incentive effects on outcomes and auditing metrics. Our key findings are that at equilibrium: (1) partial compliance by k% of employers can result in far less than proportional (k%) progress towards the full compliance outcomes; (2) the gap is more severe when fair employers match global (vs local) statistics; (3) choices of local vs global statistics can paint dramatically different pictures of the performance vis-a-vis fairness desiderata of compliant versus non-compliant employers; (4) partial compliance based on local parity measures can induce extreme segregation. Finally, we discuss implications for auditors and insights concerning the design of regulatory frameworks.",
        "DOI": "10.1145/3461702.3462521",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modeling of Landscape Change and Tele-Coupling in Local Socio-Ecological Systems: A Simulation of Land Use Change and Recreational Activities in Southern Idaho, United States",
        "paper_author": "Huang L.",
        "publication": "Proceedings of the 2021 Annual Modeling and Simulation Conference, ANNSIM 2021",
        "citied_by": "1",
        "cover_date": "2021-07-19",
        "Abstract": "The modeling of landscape change and socio-ecological systems (SES) tends to ignore the interactions across distance and boundaries. To fill the gap, this research analyzes landscape change by considering the tele-coupling effects at the local scale between Owyhee county and Treasure Valley in Idaho, United States. The spatial distribution of recreational activities in Owyhee county are modeled by Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST). Land use and cover change (LUCC) are simulated using Multi-Layer Perceptron Neural Network (MLPNN). Results show that the tele-coupling effects have significant impacts on the nature-based recreation in Owyhee county. With the tele-coupling effects, MLPNN has achieved a high overall accuracy and kappa coefficient in LUCC. The findings suggest that the tele-coupling effects should be incorporated into the modeling of landscape change and SES. This study also provides policy implications for land management and stakeholder involvement in accommodating landscape change.",
        "DOI": "10.23919/ANNSIM52504.2021.9552108",
        "affiliation_name": "University of Idaho",
        "affiliation_city": "Moscow",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "ADVERSARIALuscator: An Adversarial-DRL based Obfuscator and Metamorphic Malware Swarm Generator",
        "paper_author": "Sewak M.",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "6",
        "cover_date": "2021-07-18",
        "Abstract": "Advanced metamorphic malware and ransomware, by using obfuscation, could alter their internal structure with every attack. If such malware could intrude even into any of the IoT network, then even if the original malware instance get detected, by that time it can still infect the entire network. The IoT era also required Industry 4.0 grade AI based defense against such advanced malware. But AI algorithm need a lot of training data, and it is challenging to obtain training data for such evasive malware. Therefore, in this paper, we present ADVERSARIALuscator, a novel system that uses specialized (adversarial) deep reinforcement learning to obfuscate malware at the opcode level and create multiple metamorphic instances of the same. To the best of our knowledge, is the first-ever system that adopts the Markov Decision Process based approach to convert and find a solution to the problem of creating individual obfuscations at the opcode level. This is important as the machine language level is the least at which functionality could be preserved so as to mimic an actual attack effectively. is also the first-ever system to use efficient continuous action control capable deep reinforcement learning agents like the Proximal Policy Optimization in the area of cyber security. Experimental results indicate that could raise the metamorphic probability of a corpus of malware by ≥ 0.45. Additionally, more than 33% of metamorphic instances generated by were able to evade even the most potent IDS and penetrate the target system, even when the defending IDS could detect the original malware instance. Hence could be used to generate data representative of a swarm of very potent and coordinated AI based metamorphic malware attack. The so generated data and simulations could be used to bolster the defenses of an IDS against an actual AI based metamorphic attack from advanced malware and ransomware.",
        "DOI": "10.1109/IJCNN52387.2021.9534016",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Policy Optimization for Berth Allocation Problems",
        "paper_author": "Cervellera C.",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "6",
        "cover_date": "2021-07-18",
        "Abstract": "This paper investigates the policy optimization paradigm, where a learning model is trained to find the solution of complex Markov decision problems, as a tool to address the berth allocation problem in multimodal terminals. To this purpose, we drop the typical formulation of the latter as a mixed-integer static scheduling one, and we model it instead as an evolving scenario in which berths are assigned to ships according to a parameterized policy function that drives the temporal evolution of the environment. We adopt a cross-entropy optimization scheme to optimize the policy parameters, which is a simple and highly parallelizable gradient-free technique. As compared to the static mixed-integer formulation, the proposed approach relies on a much lighter optimization problem in the continuous space of the policy parameters, thus making it feasible to replan in real time when needed. Furthermore, the generality of the policy optimization approach allows to take into account any performance metric and specific feature of the scenario straightforwardly, without the need to devise ad hoc heuristics. Simulation tests showcase the good performance of the policy approach under various conditions.",
        "DOI": "10.1109/IJCNN52387.2021.9533891",
        "affiliation_name": "Consiglio Nazionale delle Ricerche",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Distributed Emergent Agreements with Deep Reinforcement Learning",
        "paper_author": "Schmid K.",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "1",
        "cover_date": "2021-07-18",
        "Abstract": "Building autonomous agents that are capable to cooperate with other machines is an essential step towards large scale application of AI systems. Especially systems comprised of multiple self-interested agents with general sum returns can profit from cooperative behavior as cooperation can help to increase the return from all agents simultaneously. A critical aspect that might undermine cooperation is given if agents cannot make credible threats or promises (called commitment problems). Inspired by this idea in this work we augment deep reinforcement learning agents with the capability to build agreements with one another, thereby enabling agents to autonomously learn at which time to cooperate with other agents. This approach, called distributed emergent agreement learning (DEAL), enables agents to commit to specific policies defined by the agreement. We evaluate DEAL with up to 16 agents, represented as Deep Q-Networks or instances of Proximal Policy Optimization in a factory domain and empirically show that agreements increase cooperation by improving both overall and agent individual returns.",
        "DOI": "10.1109/IJCNN52387.2021.9533333",
        "affiliation_name": "Ludwig-Maximilians-Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Low-Resource Neural Machine Translation with Neural Episodic Control",
        "paper_author": "Wu N.",
        "publication": "Proceedings of the International Joint Conference on Neural Networks",
        "citied_by": "0",
        "cover_date": "2021-07-18",
        "Abstract": "Reinforcement Learning (RL) has been proved to alleviate metric inconsistency and exposure deviation in training-evaluation of neural machine translation (NMT), but the sample efficiency is limited by sampling methods (Temporal-Difference (TD) or Monte-Carlo (MC)), and still cannot compensate for the inefficient non-zero rewards caused by insufficient data sets. In addition, RL rewards can only be effective when the model parameters are basically determined. Therefore, we proposed episodic control reinforcement learning method, which obtains the model with basically determined parameters through the knowledge transfer, and records the historical action trajectory by introducing semi-tabular differentiable neural dictionary (DND), the model can quickly approximate the real state-value according to samples reward when updating policy. We verified on CCMT2019 Mongolian-Chinese (Mo-Zh), Tibetan-Chinese (Ti-Zh), and Uyghur-Chinese (Ug-Zh) tasks, and the results showed that the quality was significantly improved, which fully demonstrated the effectiveness of the method.",
        "DOI": "10.1109/IJCNN52387.2021.9533677",
        "affiliation_name": "Inner Mongolia University China",
        "affiliation_city": "Hohhot",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Secretaries with Advice",
        "paper_author": "Dütting P.",
        "publication": "EC 2021 - Proceedings of the 22nd ACM Conference on Economics and Computation",
        "citied_by": "40",
        "cover_date": "2021-07-18",
        "Abstract": "The secretary problem is probably the purest model of decision making under uncertainty. In this paper we ask which advice can we give the algorithm to improve its success probability We propose a general model that unifies a broad range of problems: from the classic secretary problem with no advice, to the variant where the quality of a secretary is drawn from a known distribution and the algorithm learns each candidate's quality on arrival, to more modern versions of advice in the form of samples, to an ML-inspired model where a classifier gives us noisy signal about whether or not the current secretary is the best on the market. Our main technique is a factor revealing LP that captures all of the problems above. We use this LP formulation to gain structural insight into the optimal policy. Using tools from linear programming, we present a tight analysis of optimal algorithms for secretaries with samples, optimal algorithms when secretaries' qualities are drawn from a known distribution, and a new noisy binary advice model.",
        "DOI": "10.1145/3465456.3467623",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using Network Analysis and Machine Learning to Identify Virus Spread Trends in COVID-19",
        "paper_author": "Reis Pinheiro C.A.",
        "publication": "Big Data Research",
        "citied_by": "12",
        "cover_date": "2021-07-15",
        "Abstract": "The outbreak of Coronavirus Disease 2019 (COVID-19) has infected and killed millions of people globally, resulting in a pandemic with enormous global impact. This disease affects the respiratory system, and the viral agent that causes it, SARS-CoV-2, spreads through droplets of saliva, as well as through coughing and sneezing. As an extremely transmissible viral infection, COVID-19 is causing significant damage to the economies of both developed and lower- and middle-income countries because of its direct impact on the health of citizens and the containment measures taken to curtail the virus. Methods to reduce or control the spread of the virus and protect the global population are needed to avoid further deaths, long-term health issues, and prolonged economic impact. The most effective approach to reduce viral spread and avoid a substantial collapse of the health system, in the absence of vaccines, is nonpharmaceutical interventions (NPI) such as enforcing social containment restrictions, monitoring overall population mobility, implementing widespread viral testing, and increasing hygiene measures. Our approach consists of combining network analytics with machine learning models by using a combination of anonymized health and telecommunications data to better understand the correlation between population movements and virus spread. This approach, called location network analysis (LNA), allows for accurate prediction of possible new outbreaks. It gives governments and health authorities a crucial tool that can help define more accurate public health metrics and can be used either to intensify social containment policies to avoid further spread or to ease them to reopen the economy. LNA can also help to retrospectively evaluate the effectiveness of policy responses to COVID-19.",
        "DOI": "10.1016/j.bdr.2021.100242",
        "affiliation_name": "SAS Institute, Inc.",
        "affiliation_city": "Cary",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "DeepComp: Deep reinforcement learning based renewable energy error compensable forecasting",
        "paper_author": "Jeong J.",
        "publication": "Applied Energy",
        "citied_by": "20",
        "cover_date": "2021-07-15",
        "Abstract": "Recently, renewable energy is rapidly integrated into the power grid to prevent climate change, and accurate forecasting of renewable generation becomes critical for reliable power system operation. However, existing forecasting algorithms only focused on reducing forecasting errors without considering error compensability by using a large-scale battery. In this paper, we propose a novel strategy called error compensable forecasting. We switch the objective of forecasting from reducing errors to making errors compensable by leveraging a battery, which in turn reduces the dispatched error, the difference between forecasted value and dispatched value. The challenging part of the proposed objective lies in that the stored energy at current time is affected by the previous forecasting result. In this regard, we propose a deep reinforcement learning based error compensable forecasting framework, called DeepComp, having forecasting in the loop of control. This makes an action as a continuous forecasted value, which requires a continuous action space. We leverage proximal policy optimization, which is simple to implement with outstanding performance for continuous control. Extensive experiments with solar and wind power generations show that DeepComp outperforms the conventional forecasting methods by up to 90% and achieves accurate forecasting, e.g., 0.58–1.22% of the mean absolute percentage error.",
        "DOI": "10.1016/j.apenergy.2021.116970",
        "affiliation_name": "Sogang University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A Machine Learning-based DSS for mid and long-term company crisis prediction",
        "paper_author": "Perboli G.",
        "publication": "Expert Systems with Applications",
        "citied_by": "37",
        "cover_date": "2021-07-15",
        "Abstract": "In the field of detection and prediction of company defaults and bankruptcy, significant effort has been devoted to evaluating financial ratios as predictors using statistical models and machine learning techniques. This problem becomes crucially important when financial decision-makers are provided with predictions on which to act, based on the output of prediction models. However, research has shown that such predictors are sufficiently accurate in the short-term, with the focus mainly directed towards large and medium-large companies. In contrast, in this paper, we focus on mid- and long-term bankruptcy prediction (up to 60 months) targeting small and/or medium enterprises. The key contribution of this study is a substantial improvement of the prediction accuracy in the short-term (12 months) using machine learning techniques, compared to the state-of-the-art, while also making accurate mid- and long-term predictions (measure of the area under the ROC curve of 0.88 with a 60 month prediction horizon). Extensive computational tests on the entire set of companies in Italy highlight the efficiency and accuracy of the developed method, as well as demonstrating the possibility of using it as a tool for the development of strategies and policies for entire economic systems. Considering the recent COVID-19 pandemic, we show how our method can be used as a viable tool for large-scale policy-making.",
        "DOI": "10.1016/j.eswa.2021.114758",
        "affiliation_name": "Politecnico di Torino",
        "affiliation_city": "Turin",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Long-term exposure to ambient PM<inf>2.5</inf> increase obesity risk in Chinese adults: A cross-sectional study based on a nationwide survey in China",
        "paper_author": "Cao S.",
        "publication": "Science of the Total Environment",
        "citied_by": "22",
        "cover_date": "2021-07-15",
        "Abstract": "Certain studies suggest that air pollution could be a risk factor for obesity, but the evidence on the association between air pollution exposure and obesity in adults is limited. This study aims to examine the association between long-term exposure to fine particulate matter (PM2.5) and obesity-related traits in Chinese adults. Thus, a cross-sectional study was conducted based on a nationally representative sample of 91, 121 adults from 31 provinces in China. Integrated the data from satellites, chemical transport model, and ground observations, annual average concentrations of PM2.5 was obtained at the township level using a machine learning method. The information on body weight, height, and waist circumference (WC) were obtained from a questionnaire survey. The general obesity and abdominal obesity status were classified based on body mass index (BMI) and WC, respectively. Logistic and multivariate linear regression models were used to examine the association between PM2.5 and obesity-related traits, along with the examination of potential effect modifications. After adjustment for covariates, a 10 μg/m3 increase in PM2.5 concentration was associated with 8.0% [95% confidence interval (CI): 1.0%, 10.0%] and 10% (95% CI: 9.0%, 11.0%) increases in odds for general obesity and abdominal obesity, respectively. The odds ratios associated with per 10 μg/m3 PM2.5 increase were significantly greater in individuals of older age (≥60 years), of Han ethnicity, with lower socioeconomic status (SES), cooking without using a ventilation device, using unclean household fuels, having near-home pollution sources, and doing no physical exercise. These findings suggest that long-term exposure to ambient PM2.5 increase obesity risk in Chinese adults. It has significant significance to reduce air pollution to reducing the burden of obesity, particularly for the susceptible populations.",
        "DOI": "10.1016/j.scitotenv.2021.145812",
        "affiliation_name": "Duke Kunshan University",
        "affiliation_city": "Kunshan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sentimental Analysis Applications and Approaches during COVID-19: A Survey",
        "paper_author": "Umair A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "13",
        "cover_date": "2021-07-14",
        "Abstract": "The social media and electronic media has a vast amount of user-generated data such as people' comment and reviews about different product, diseases, government policies etc. Sentimental analysis is the emerging field in text mining where people's feeling and emotions are extracted using different techniques. COVID-19 has declared as pandemic and effected people's lives all over the globe. It caused the feelings of fear, anxiety, anger, depression and many other psychological issues. In this survey paper, the sentimental analysis applications and methods which are used for COVID-19 research are briefly presented. The comparison of thirty primary studies shows that Naive Bayes and SVM are the widely used algorithms of sentimental analysis for COVID-19 research. The applications of sentimental analysis during COVID includes the analysis of people's sentiments specially students, reopening sentiments, analysis of restaurants reviews and analysis of vaccine sentiments.",
        "DOI": "10.1145/3472163.3472274",
        "affiliation_name": "Consiglio Nazionale delle Ricerche",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Predicting Accounts Receivable with Machine Learning: A Case in Malaysia",
        "paper_author": "Ramanei T.A.P.",
        "publication": "2021 International Conference on Information Technology, ICIT 2021 - Proceedings",
        "citied_by": "2",
        "cover_date": "2021-07-14",
        "Abstract": "Accounts receivable plays a major role in credit to cash conversion cycle which involves collection management, payment management and debtors aging. Lack of visibility on accounts receivable management limits efficiency in collection management leading to long aging debtors. Aging payments eventually turns into bad debts leaving a negative impact on the cash flow. The case study company, PangCo Jaya is a wholesale consumer goods distributer located in Malaysia. The objective of this study is to predict payment timing of PangCo Jaya's customers. The outcome of this case study enables collection team to plan for proactive debt collection. This study applies Machine Learning techniques to address accounts receivable challenges faced by PangCo Jaya. The tools used in this study is Python in Jupyter Notebook. A supervised Machine Learning classification model for predicting invoice payment prediction has been developed. This solution enables proficient payment collection by reaching out to targeted customer with potential payment delay prediction. In future, these trends can be applied to evaluate if there is a necessity in revising customers' credit policies and estimate potential receivables that are under risk of turning into bad debts.",
        "DOI": "10.1109/ICIT52682.2021.9491773",
        "affiliation_name": "Universiti Sains Malaysia",
        "affiliation_city": "Minden",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "A Call to Action for New Global Approaches to Cardiovascular Disease Drug Solutions",
        "paper_author": "Figtree G.A.",
        "publication": "Circulation",
        "citied_by": "20",
        "cover_date": "2021-07-13",
        "Abstract": "While we continue to wrestle with the immense challenge of implementing equitable access to established evidence-based treatments, substantial gaps remain in our pharmacotherapy armament for common forms of cardiovascular disease including coronary and peripheral arterial disease, heart failure, hypertension, and arrhythmia. We need to continue to invest in the development of new approaches for the discovery, rigorous assessment, and implementation of new therapies. Currently, the time and cost to progress from lead compound/product identification to the clinic, and the success rate in getting there reduces the incentive for industry to invest, despite the enormous burden of disease and potential size of market. There are tremendous opportunities with improved phenotyping of patients currently batched together in syndromic \"buckets.\" Use of advanced imaging and molecular markers may allow stratification of patients in a manner more aligned to biological mechanisms that can, in turn, be targeted by specific approaches developed using high-throughput molecular technologies. Unbiased \"omic\" approaches enhance the possibility of discovering completely new mechanisms in such groups. Furthermore, advances in drug discovery platforms, and models to study efficacy and toxicity more relevant to the human disease, are valuable. Re-imagining the relationships among discovery, translation, evaluation, and implementation will help reverse the trend away from investment in the cardiovascular space, establishing innovative platforms and approaches across the full spectrum of therapeutic development.",
        "DOI": "10.1161/CIR.0000000000000981",
        "affiliation_name": "NIHR Oxford Biomedical Research Centre",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Clinical Characterization and Prediction of Clinical Severity of SARS-CoV-2 Infection among US Adults Using Data from the US National COVID Cohort Collaborative",
        "paper_author": "Bennett T.D.",
        "publication": "JAMA Network Open",
        "citied_by": "177",
        "cover_date": "2021-07-13",
        "Abstract": "IMPORTANCE The National COVID Cohort Collaborative (N3C) is a centralized, harmonized, highgranularity electronic health record repository that is the largest, most representative COVID-19 cohort to date. This multicenter data set can support robust evidence-based development of predictive and diagnostic tools and inform clinical care and policy. OBJECTIVES To evaluate COVID-19 severity and risk factors over time and assess the use of machine learning to predict clinical severity. DESIGN, SETTING, AND PARTICIPANTS In a retrospective cohort study of 1 926 526 US adults with SARS-CoV-2 infection (polymerase chain reaction >99% or antigen >1%) and adult patients without SARS-CoV-2 infection who served as controls from 34 medical centers nationwide between January 1, 2020, and December 7, 2020, patientswere stratified using aWorld Health Organization COVID-19 severity scale and demographic characteristics. Differences between groups over time were evaluated using multivariable logistic regression. Random forest and XGBoost models were used to predict severe clinical course (death, discharge to hospice, invasive ventilatory support, or extracorporeal membrane oxygenation). MAIN OUTCOMES AND MEASURES Patient demographic characteristics and COVID-19 severity using theWorld Health Organization COVID-19 severity scale and differences between groups over time using multivariable logistic regression. RESULTS The cohort included 174 568 adults who tested positive for SARS-CoV-2 (mean [SD] age, 44.4 [18.6] years; 53.2%female) and 1 133 848 adult controls who tested negative for SARS-CoV-2 (mean [SD] age, 49.5 [19.2] years; 57.1% female). Of the 174 568 adults with SARS-CoV-2, 32 472 (18.6%) were hospitalized, and 6565 (20.2%) of those had a severe clinical course (invasive ventilatory support, extracorporeal membrane oxygenation, death, or discharge to hospice). Of the hospitalized patients, mortality was 11.6%overall and decreased from 16.4%in March to April 2020 to 8.6%in September to October 2020 (P = .002 for monthly trend). Using 64 inputs available on the first hospital day, this study predicted a severe clinical course using random forest and XGBoost models (area under the receiver operating curve = 0.87 for both) that were stable over time. The factor most strongly associated with clinical severity was pH; this result was consistent across machine learning methods. In a separate multivariable logistic regression model built for inference, age (odds ratio [OR], 1.03 per year; 95%CI, 1.03-1.04), male sex (OR, 1.60; 95%CI, 1.51-1.69), liver disease (OR, 1.20; 95%CI, 1.08-1.34), dementia (OR, 1.26; 95%CI, 1.13-1.41), African American (OR, 1.12; 95%CI, 1.05-1.20) and Asian (OR, 1.33; 95%CI, 1.12-1.57) race, and obesity (OR, 1.36; 95%CI, 1.27-1.46) were independently associated with higher clinical severity. CONCLUSIONS AND RELEVANCE This cohort study found that COVID-19 mortality decreased over time during 2020 and that patient demographic characteristics and comorbidities were associated with higher clinical severity. The machine learning models accurately predicted ultimate clinical severity using commonly collected clinical data from the first 24 hours of a hospital admission.",
        "DOI": "10.1001/jamanetworkopen.2021.16901",
        "affiliation_name": "Department of Biomedical Informatics",
        "affiliation_city": "Stony Brook",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "CNN-based stress and emotion recognition in ambulatory settings",
        "paper_author": "Liakopoulos L.",
        "publication": "IISA 2021 - 12th International Conference on Information, Intelligence, Systems and Applications",
        "citied_by": "13",
        "cover_date": "2021-07-12",
        "Abstract": "Stress has been recognized as a major contributor in a number of mental, psychological or physical conditions which reduce the quality of human life. The monitoring of affective states through readily available wearables and unobtrusive sensors can allow to recognize early signs of stress and burn-out, thereby develop prevention policies to combat psychosocial risks. This study analyzes data from diverse sensing modalities with signal processing techniques and advanced machine learning approaches in order to unobtrusively recognize stress and negative emotions. We investigate the performance of - easy to obtain in ambulatory settings - heart rate signal and juxtapose it against multi-modal information from electrophysiological signals, facial expression features and body posture. For the former, we introduce 2D spectrograms into a convolutional neural network (CNN) and use the obtained activation maps as frequency patterns differentiating stressful conditions. For the rest of the sensors, we compare different classifiers (SVM, KNN, Random Forest, Neural Networks) and data fusion schemes. In addition, a second phase assessment is conceptualized for emotion recognition reflected in facial expressions using images from a smartphone's camera. Our CNN implementation in Android platform enables near real-time estimation of the instantaneous emotional expressions, which, when combined with stress-indicators, can help elucidating the relationship between stress and negative affective states.",
        "DOI": "10.1109/IISA52424.2021.9555508",
        "affiliation_name": "University of Patras",
        "affiliation_city": "Rio",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Learning with Little Data: Industry Challenges and Innovations",
        "paper_author": "Rao N.",
        "publication": "SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citied_by": "0",
        "cover_date": "2021-07-11",
        "Abstract": "In e-commerce applications, customers search and discover one or more products using queries. Some of these queries are broad and diverse, with multiple intents. Therefore, relying purely on the anonymized and aggregated customer historical behavioral data is not sufficient to train machine learned models. For example, customers may click and purchase a galaxy charger for a \"samsung galaxy s9\"query. The item is not an exact match for the customer query. However, it serves as a complement to the original query and may be purchased. To address these potential mismatches from surfacing in search results, e-commerce systems rely on machine learned models trained on human- annotated data. There are two challenges in collecting human annotated data. First, the human annotation process does not scale and it is hard to obtain large volumes of annotations in multiple languages. Second, annotators must query existing systems to obtain samples for auditing, resulting in very few mismatched examples (data skewness) and counterfactual biases. In this talk, we address these challenges using two recent advances in deep learning. To address the data skewness, we generate hard negative examples using positive examples. The key idea here is to generate synthetic data using a Variational Encoder Decoder (VED) architecture. We show how a modified loss function with a novel combiner (to combine VED with the classifier) can avoid policy-based gradients and other heuristics. To address the sparsity of data in less popular languages, we combine data across all languages using language-agnostic representation learning. The side information we use aligns the items across languages in the same latent space. We show that our approaches significantly improve upon state of the art baselines, by over 25% in F1 score for the variational model, and over 20% in F1 score for the multilingual model.",
        "DOI": "10.1145/3404835.3464925",
        "affiliation_name": "Amazon.com, Inc.",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Interactive Information Retrieval with Bandit Feedback",
        "paper_author": "Wang H.",
        "publication": "SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citied_by": "5",
        "cover_date": "2021-07-11",
        "Abstract": "Information retrieval (IR) in nature is a process of sequential decision making. The system repeatedly interacts with the users to refine its understanding of the users' information needs, improve its estimation of result relevance, and thus increase the utility of its returned results (e.g., the result rankings). Distinct from traditional IR solutions that rigidly execute an offline trained policy, interactive information retrieval emphasizes online policy learning. This, however, is fundamentally difficult for at least three reasons. First, the system only collects user feedback on the presented results, aka, the bandit feedback. Second, users' feedback is known to be noisy and biased. Third, as a result, the system always faces the conflicting goals of improving its policy by presenting currently underestimated results to users versus satisfying the users by ranking the currently estimated best results on top. In this tutorial, we will first motivate the need for online policy learning in interactive IR, by highlighting its importance in several real-world IR problems where online sequential decision making is necessary, such as web search and recommendations. We will carefully address the new challenges that arose in such a solution paradigm, including sample complexity, costly and even outdated feedback, and ethical considerations in online learning (such as fairness and privacy) in interactive IR. We will prepare the technical discussions by first introducing several classical interactive learning strategies from machine learning literature, and then fully dive into the recent research developments for addressing the aforementioned fundamental challenges in interactive IR. Note that the tutorial on \"Interactive Information Retrieval: Models, Algorithms, and Evaluation\"will provide a broad overview on the general conceptual framework and formal models in interactive IR, while this tutorial covers the online policy learning solutions for interactive IR with bandit feedback.",
        "DOI": "10.1145/3404835.3462810",
        "affiliation_name": "University of Virginia School of Engineering and Applied Science",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "FedNLP: An Interpretable NLP System to Decode Federal Reserve Communications",
        "paper_author": "Lee J.",
        "publication": "SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval",
        "citied_by": "6",
        "cover_date": "2021-07-11",
        "Abstract": "The Federal Reserve System (the Fed) plays a significant role in affecting monetary policy and financial conditions worldwide. Although it is important to analyse the Fed's communications to extract useful information, it is generally long-form and complex due to the ambiguous and esoteric nature of content. In this paper, we present FedNLP, an interpretable multi-component Natural Language Processing (NLP) system to decode Federal Reserve communications. This system is designed for end-users to explore how NLP techniques can assist their holistic understanding of the Fed's communications with NO coding. Behind the scenes, FedNLP uses multiple NLP models from traditional machine learning algorithms to deep neural network architectures in each downstream task. The demonstration shows multiple results at once including sentiment analysis, summary of the document, prediction of the Federal Funds Rate movement and visualization for interpreting the prediction model's result. Our application system and demonstration are available at https://fednlp.net.",
        "DOI": "10.1145/3404835.3462785",
        "affiliation_name": "The University of Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Trustworthy AI for process automation on a Chylla-Haase polymerization reactor",
        "paper_author": "Hein D.",
        "publication": "GECCO 2021 Companion - Proceedings of the 2021 Genetic and Evolutionary Computation Conference Companion",
        "citied_by": "0",
        "cover_date": "2021-07-07",
        "Abstract": "In this paper, genetic programming reinforcement learning (GPRL) is utilized to generate human-interpretable control policies for a Chylla-Haase polymerization reactor. Such continuously stirred tank reactors (CSTRs) with jacket cooling are widely used in the chemical industry, in the production of fine chemicals, pigments, polymers, and medical products. Despite appearing rather simple, controlling CSTRs in real-world applications is quite a challenging problem to tackle. GPRL utilizes already existing data from the reactor and generates fully automatically a set of optimized simplistic control strategies, so-called policies, the domain expert can choose from. Note that these policies are white-box models of low complexity, which makes them easy to validate and implement in the target control system, e.g., SIMATIC PCS 7. However, despite its low complexity the automatically-generated policy yields a high performance in terms of reactor temperature control deviation, which we empirically evaluate on the original reactor template.",
        "DOI": "10.1145/3449726.3463131",
        "affiliation_name": "Siemens AG",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Explainability and performance of anticipatory learning classifier systems in non-deterministic environments",
        "paper_author": "Orhand R.",
        "publication": "GECCO 2021 Companion - Proceedings of the 2021 Genetic and Evolutionary Computation Conference Companion",
        "citied_by": "2",
        "cover_date": "2021-07-07",
        "Abstract": "In the field of Reinforcement Learning, models based on neural networks are highly performing, but explaining their decisions is very challenging. Instead of seeking to open these \"black boxes\"to meet the increasing demand for explainability, another approach is to used rule-based machine learning models that are explainable by design, such as the Anticipatory Learning Classifier Systems (ALCS). ALCS are able to develop simultaneously a complete representation of their environment and a decision policy based on this representation to solve their learning tasks. This paper focuses on the ability of ALCS to deal with non-deterministic environments used in reinforcement learning problems, while discussing their explainability. Directions for future research are thus highlighted to improve both the performance and the explainability of the ALCS to meet the needs of critical real-world applications.",
        "DOI": "10.1145/3449726.3459510",
        "affiliation_name": "Université de Strasbourg",
        "affiliation_city": "Strasbourg",
        "affiliation_country": "France"
    },
    {
        "paper_title": "New Technologies Can Cost Effectively Reduce Oil and Gas Methane Emissions, but Policies Will Require Careful Design to Establish Mitigation Equivalence",
        "paper_author": "Kemp C.E.",
        "publication": "Environmental Science and Technology",
        "citied_by": "26",
        "cover_date": "2021-07-06",
        "Abstract": "Reducing methane emissions from oil and gas systems is a central component of US and international climate policy. Leak detection and repair (LDAR) programs using optical gas imaging (OGI)-based surveys are routinely used to mitigate fugitive emissions or leaks. Recently, new technologies and platforms such as planes, drones, and satellites promise more cost-effective mitigation than existing approaches. To be approved for use in LDAR programs, new technologies must demonstrate emissions mitigation equivalent to existing approaches. In this work, we use the FEAST modeling tool to (a) identify cost vs mitigation trade-offs that arise from using new technologies and (b) provide a framework for effective design of alternative LDAR programs. We identify several critical insights. First, LDAR programs can trade sensitivity for speed without sacrificing mitigation outcomes. Second, low sensitivity or high detection threshold technologies have an effective upper bound on achievable mitigation that is independent of the survey frequency. Third, the cost effectiveness of tiered LDAR programs using site-level detection technologies depends on their ability to distinguish leaks from routine venting. Finally, \"technology equivalence\"based on mitigation outcomes differs across basins and should be evaluated independently. The FEAST model will enable operators and regulators to systematically evaluate new technologies in next-generation LDAR programs.",
        "DOI": "10.1021/acs.est.1c03071",
        "affiliation_name": "Harrisburg University of Science and Technology",
        "affiliation_city": "Harrisburg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The accuracy versus interpretability trade-off in fraud detection model",
        "paper_author": "Nesvijevskaia A.",
        "publication": "Data and Policy",
        "citied_by": "17",
        "cover_date": "2021-07-05",
        "Abstract": "Like a hydra, fraudsters adapt and circumvent increasingly sophisticated barriers erected by public or private institutions. Among these institutions, banks must quickly take measures to avoid losses while guaranteeing the satisfaction of law-abiding customers. Facing an expanding flow of operations, effective banking relies on data analytics to support established risk control processes, but also on a better understanding of the underlying fraud mechanism. In addition, fraud being a criminal offence, the evidential aspect of the process must also be considered. These legal, operational, and strategic constraints lead to compromises on the means to be implemented for fraud management. This paper first focuses on the translation of practical questions raised in the banking industry at each step of the fraud management process into performance evaluation required to design a fraud detection model. Secondly, it considers a range of machine learning approaches that address these specificities: the imbalance between fraudulent and nonfraudulent operations, the lack of fully trusted labels, the concept-drift phenomenon, and the unavoidable trade-off between accuracy and interpretability of detection. This state-of-the-art review sheds some light on a technology race between black box machine learning models improved by post-hoc interpretation and intrinsic interpretable models boosted to gain accuracy. Finally, it discusses how concrete and promising hybrid approaches can provide pragmatic, short-term answers to banks and policy makers without swallowing up stakeholders with economical and ethical stakes in this technological race.",
        "DOI": "10.1017/dap.2021.3",
        "affiliation_name": "Conservatoire National des Arts et Metiers",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "A gis methodology to determine the critical regions for mitigating eutrophication in large territories: The case of jalisco, mexico",
        "paper_author": "Cervantes-Astorga E.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "2",
        "cover_date": "2021-07-02",
        "Abstract": "Inadequate management practices for solid waste and wastewater are some of the main causes of eutrophication globally, especially in regions where intensive livestock, agricultural, and industrial activities are coupled with inexistent or ineffective waste and wastewater treatment infrastructure. In this study, a methodological approach is presented to spatially assess the trophic state of large territories based on public water quality databases. The trophic state index (TSI) includes total nitrogen, total phosphorus, chlorophyll A, chemical oxygen demand, and Secchi disk depth values as water quality indicators. A geographical information system (GIS) was used to manage the spatiotemporal attributes of the water quality data, in addition to spatially displaying the results of TSI calculations. As a case study, this methodological approach was applied to determine the critical regions for mitigating eutrophication in the state of Jalisco, Mexico. Although a decreasing trend was observed for the TSI values over time for most subbasins (2012–2019), a tendency for extreme hypereutrophication was observed in some regions, such as the Guadalajara metropolitan area and the Altos region, which are of high economic relevance at the state level. A correlation analysis was performed between the TSI parameters and rainfall measurements for all subbasins under analysis, which suggested a tendency for nutrient wash-off during the rainy seasons for most subbasins; however, further research is needed to quantify the real impacts of rainfall by including other variables such as elevation and slope. The relationships between the water quality indicators and land cover were also explored. The GIS methodology proposed in this study can be used to spatially assess the trophic state of large regions over time, taking advantage of available water quality databases. This will enable the efficient development and implementation of public policies to assess and mitigate the eutrophication of water sources, as well as the efficient allocation of resources for critical regions. Further studies should focus on applying integrated approaches combining on-site monitoring data, remote sensing data, and machine learning algorithms to spatially evaluate the trophic state of territories.",
        "DOI": "10.3390/su13148029",
        "affiliation_name": "Centro de Investigación y Asistencia en Tecnologia y Diseño del Estado de Jalisco",
        "affiliation_city": "Guadalajara",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Using machine learning to predict retrofit effects for a commercial building portfolio",
        "paper_author": "Xu Y.",
        "publication": "Energies",
        "citied_by": "14",
        "cover_date": "2021-07-02",
        "Abstract": "Buildings account for 40% of the energy consumption and 31% of the CO2 emissions in the United States. Energy retrofits of existing buildings provide an effective means to reduce building consumption and carbon footprints. A key step in retrofit planning is to predict the effect of various potential retrofits on energy consumption. Decision-makers currently look to simulation-based tools for detailed assessments of a large range of retrofit options. However, simulations often require detailed building characteristic inputs, high expertise, and extensive computational power, presenting challenges for considering portfolios of buildings or evaluating large-scale policy proposals. Data-driven methods offer an alternative approach to retrofit analysis that could be more easily applied to portfolio-wide retrofit plans. However, current applications focus heavily on evaluating past retrofits, providing little decision support for future retrofits. This paper uses data from a portfolio of 550 federal buildings and demonstrates a data-driven approach to generalizing the heterogeneous treatment effect of past retrofits to predict future savings potential for assisting retrofit planning. The main findings include the following: (1) There is high variation in the predicted savings across retrofitted buildings, (2) GSALink, a dashboard tool and fault detection system, commissioning, and HVAC investments had the highest average savings among the six actions analyzed; and (3) by targeting high savers, there is a 110–300 billion Btu improvement potential for the portfolio in site energy savings (the equivalent of 12–32% of the portfolio-total site energy consumption).",
        "DOI": "10.3390/en14144334",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Assessment of the spatial and temporal patterns of cover crops using remote sensing",
        "paper_author": "Kc K.",
        "publication": "Remote Sensing",
        "citied_by": "23",
        "cover_date": "2021-07-02",
        "Abstract": "Cover cropping is a conservation practice that helps to alleviate soil health problems and reduce nutrient losses. Understanding the spatial variability in historic and current adoption of cover cropping practices and their impacts on soil, water, and nutrient dynamics at a landscape scale is an important step in determining and prioritizing areas in a watershed to effectively utilize this practice. However, such data are lacking. Our objective was to develop a spatial and temporal inventory of winter cover cropping practices in the Maumee River watershed using images collected by Landsat satellites (Landsat 5, 7 and 8) from 2008 to 2019 in Google Earth Engine (GEE) platform. Each year, satellite images collected during cover crop growing season (i.e., between October and April) were converted into two seasonal composites based on cover crop phenology. Using these composites, various image-based covariates were extracted for 628 ground-truth (field) data. By integrating ground-truth and image-based covariates, a cover crop classification model based on a random forest (RF) algorithm was developed, trained and validated in GEE platform. Our classification scheme differentiated four cover crop categories: Winter Hardy, Winter Kill, Spring Emergent, and No Cover. The overall classification accuracy was 75%, with a kappa coefficient of 0.63. The results showed that more than 50% of the corn-soybean areas in the Maumee River watershed were without winter crops during 2008–2019 period. It was found that 2019/2020 and 2009/2010 were the years with the largest and lowest cover crop areas, with 34% and 10% in the watershed, respectively. The total cover cropping area was then assessed in relation to fall precipitation and cumulative growing degree days (GDD). There was no apparent increasing trend in cover crop areas between 2008 and 2019, but the variability in cover crops areas was found to be related to higher accumulated GDD and fall precipitation. A detailed understanding of the spatial and temporal distribution of cover crops using GEE could help in promoting site-specific management practices to enhance their environmental benefits. This also has significance to policy makers and funding agencies as they could use the information to localize areas in need of interventions for supporting adoption of cover cropping practice.",
        "DOI": "10.3390/rs13142689",
        "affiliation_name": "Department of Food, Agricultural and Biological Engineering",
        "affiliation_city": "Columbus",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Applying machine learning to develop lane control principles for mixed traffic",
        "paper_author": "Hsu T.P.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "0",
        "cover_date": "2021-07-02",
        "Abstract": "The mixed traffic environment often has high accident rates. Therefore, many motorcycle-related traffic improvements or control methods are employed in countries with mixed traffic, including slow-traffic lanes, motorcycle two-stage left turn areas, and motorcycle waiting zones. In Taiwan, motorcycles can ride in only the two outermost lanes, including the curb lane and a mixed traffic lane. This study analyzed the new motorcycle-riding space control policy on 27 major arterial roads containing 248 road segments in Taipei by analyzing before-and-after accident data from the years 2012–2018. In this study, the equivalent-property-damage-only (EPDO) method was used to evaluate the severity of crashes before and after the cancelation of the third lane prohibition of motorcycles (TLPM) policy. After EPDO analysis, the random forest analysis method was used to screen the crucial factors in accidents for specific road segments. Finally, a classification and regression tree (CART) was created to predict the accident improvement effects of the road segments with discontinued TLPM in different situations. Furthermore, to provide practical applications, this study integrated the CART results and the needs of traffic authorities to determine four rules for canceling TLPM. In the future, on the accident-prone road segment with TLPM, the inspection of the four rules can provide the authority to decide whether to cancel TLPM to improve the accident or not.",
        "DOI": "10.3390/su13147656",
        "affiliation_name": "College of Engineering, National Taiwan University",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "State-aware stochastic optimal power flow",
        "paper_author": "Pareek P.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "2",
        "cover_date": "2021-07-02",
        "Abstract": "The increase in distributed generation (DG) and variable load mandates system operators to perform decision-making considering uncertainties. This paper introduces a novel state-aware stochastic optimal power flow (SA-SOPF) problem formulation. The proposed SA-SOPF has objective to find a day-ahead base-solution that minimizes the generation cost and expectation of deviations in generation and node voltage set-points during real-time operation. We formulate SA-SOPF for a given affine policy and employ Gaussian process learning to obtain a distributionally robust (DR) affine policy for generation and voltage set-point change in real-time. In simulations, the GP-based affine policy has shown distributional robustness over three different uncertainty distributions for IEEE 14-bus system. The results also depict that the proposed SA-OPF formulation can reduce the expectation in voltage and generation deviation more than 60% in real-time operation with an additional day-ahead scheduling cost of 4.68% only for 14-bus system. For, in a 30-bus system, the reduction in generation and voltage deviation, the expectation is achieved to be greater than 90% for 1.195% extra generation cost. These results are strong indicators of possibility of achieving the day-ahead solution which lead to lower real-time deviation with minimal cost increase.",
        "DOI": "10.3390/su13147577",
        "affiliation_name": "School of Electrical and Electronic Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Exploring factors for predicting anxiety disorders of the elderly living alone in south korea using interpretable machine learning: A population-based study",
        "paper_author": "Byeon H.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "29",
        "cover_date": "2021-07-02",
        "Abstract": "This epidemiological study aimed to develop an X-AI that could explain groups with a high anxiety disorder risk in old age. To achieve this objective, (1) this study explored the predictors of senile anxiety using base models and meta models. (2) This study presented decision tree visualization that could help psychiatric consultants and primary physicians easily interpret the path of predicting high-risk groups based on major predictors derived from final machine learning models with the best performance. This study analyzed 1558 elderly (695 males and 863 females) who were 60 years or older and completed the Zung’s Self-Rating Anxiety Scale (SAS). We used support vector machine (SVM), random forest, LightGBM, and Adaboost for the base model, a single predictive model, while using XGBoost algorithm for the meta model. The analysis results confirmed that the predictive performance of the “SVM + Random forest + LightGBM + AdaBoost + XGBoost model (stacking ensemble: accuracy 87.4%, precision 85.1%, recall 87.4%, and F1-score 85.5%)” was the best. Also, the results of this study showed that the elderly who often (or mostly) felt subjective loneliness, had a Self Esteem Scale score of 26 or less, and had a subjective communication with their family of 4 or less (on a 10-point scale) were the group with the highest risk anxiety disorder. The results of this study imply that it is necessary to establish a community-based mental health policy that can identify elderly groups with high anxiety risks based on multiple risk factors and manage them constantly.",
        "DOI": "10.3390/ijerph18147625",
        "affiliation_name": "Inje University",
        "affiliation_city": "Gimhae",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Big data-enabled solutions framework to overcoming the barriers to circular economy initiatives in healthcare sector",
        "paper_author": "Kazançoğlu Y.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "32",
        "cover_date": "2021-07-02",
        "Abstract": "Ever-changing conditions and emerging new challenges affect the ability of the healthcare sector to survive with the current system, and to maintain its processes effectively. In the healthcare sector, the conservation of the natural resources is being obstructed by insufficient infrastructure for managing residual waste resulting from single-use medical materials, increased energy use, and its environmental burden. In this context, circularity and sustainability concepts have become essential in healthcare to meliorate the sector’s negative impacts on the environment. The main aim of this study is to identify the barriers related to circular economy (CE) in the healthcare sector, apply big data analytics in healthcare, and provide solutions to these barriers. The contribution of this research is the detailed examination of the current healthcare literature about CE adaptation, and a proposal for a big data-enabled solutions framework to barriers to circularity, using fuzzy bestworst Method (BWM) and fuzzy VIKOR. Based on the findings, managerial, policy, and theoretical implementations are recommended to support sustainable development initiatives in the healthcare sector.",
        "DOI": "10.3390/ijerph18147513",
        "affiliation_name": "Ch. Ranbir Singh State Institute of Engineering and Technology",
        "affiliation_city": "Jhajjar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Prediction of covid-19 risk in public areas using iot and machine learning",
        "paper_author": "Elbasi E.",
        "publication": "Electronics (Switzerland)",
        "citied_by": "23",
        "cover_date": "2021-07-02",
        "Abstract": "COVID-19 is a community-acquired infection with symptoms that resemble those of in-fluenza and bacterial pneumonia. Creating an infection control policy involving isolation, disinfection of surfaces, and identification of contagions is crucial in eradicating such pandemics. Incorporating social distancing could also help stop the spread of community-acquired infections like COVID-19. Social distancing entails maintaining certain distances between people and reducing the frequency of contact between people. Meanwhile, a significant increase in the development of different Internet of Things (IoT) devices has been seen together with cyber-physical systems that connect with physical environments. Machine learning is strengthening current technologies by adding new approaches to quickly and correctly solve problems utilizing this surge of available IoT devices. We propose a new approach using machine learning algorithms for monitoring the risk of COVID-19 in public areas. Extracted features from IoT sensors are used as input for several machine learning algorithms such as decision tree, neural network, naïve Bayes classifier, support vector machine, and random forest to predict the risks of the COVID-19 pandemic and calculate the risk probability of public places. This research aims to find vulnerable populations and reduce the impact of the disease on certain groups using machine learning models. We build a model to calculate and predict the risk factors of populated areas. This model generates automated alerts for security authorities in the case of any abnormal detection. Experimental results show that we have high accuracy with random forest of 97.32%, with decision tree of 94.50%, and with the naïve Bayes classifier of 99.37%. These algorithms indicate great potential for crowd risk prediction in public areas.",
        "DOI": "10.3390/electronics10141677",
        "affiliation_name": "American University of the Middle East",
        "affiliation_city": "Al Ahmadi",
        "affiliation_country": "Kuwait"
    },
    {
        "paper_title": "Predictive modeling approach for surface water quality: Development and comparison of machine learning models",
        "paper_author": "Izhar Shah M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "37",
        "cover_date": "2021-07-02",
        "Abstract": "Water pollution is an increasing global issue that societies are facing and is threating human health, ecosystem functions and agriculture production. The distinguished features of artificial intelligence (AI) based modeling can deliver a deep insight pertaining to rising water quality concerns. The current study investigates the predictive performance of gene expression programming (GEP), artificial neural network (ANN) and linear regression model (LRM) for modeling monthly total dissolved solids (TDS) and specific conductivity (EC) in the upper Indus River at two outlet stations. In total, 30 years of historical water quality data, comprising 360 TDS and EC monthly records, were used for models training and testing. Based on a significant correlation, the TDS and EC modeling were correlated with seven input parameters. Results were evaluated using various performance measure indicators, error assessment and external criteria. The simulated outcome of the models indicated a strong association with actual data where the correlation coefficient above 0.9 was observed for both TDS and EC. Both the GEP and ANN models remained the reliable techniques in predicting TDS and EC. The formulated GEP mathematical equations depict its novelty as compared to ANN and LRM. The results of sensitivity analysis indicated the increasing trend of input variables affecting TDS as HCO3− (22.33%) > Cl− (21.66%) > Mg2+ (16.98%) > Na+ (14.55%) > Ca2+ (12.92%) > SO42− (11.55%) > pH (0%), while, in the case of EC, it followed the trend as HCO3− (42.36%) > SO42−(25.63%) > Ca2+ (13.59%) > Cl− (12.8%) > Na+ (5.01%) > pH (0.61%) > Mg2+ (0%). The parametric analysis revealed that models have incorporated the effect of all the input parameters in the modeling process. The external assessment criteria confirmed the generalized outcome and robustness of the proposed approaches. Conclusively, the outcomes of this study demonstrated that the formulation of AI based models are cost effective and helpful for river water quality assessment, management and policy making.",
        "DOI": "10.3390/su13147515",
        "affiliation_name": "COMSATS University Islamabad, Abbottabad Campus",
        "affiliation_city": "Abbottabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Managing sars-cov-2 testing in schools with an artificial intelligence model and application developed by simulation data",
        "paper_author": "Valtchev S.Z.",
        "publication": "Electronics (Switzerland)",
        "citied_by": "9",
        "cover_date": "2021-07-02",
        "Abstract": "Research on SARS-CoV-2 and its social implications have become a major focus to interdisciplinary teams worldwide. As interest in more direct solutions, such as mass testing and vaccination grows, several studies appear to be dedicated to the operationalization of those solutions, leveraging both traditional and new methodologies, and, increasingly, the combination of both. This research examines the challenges anticipated for preventative testing of SARS-CoV-2 in schools and proposes an artificial intelligence (AI)-powered agent-based model crafted specifically for school scenarios. This research shows that in the absence of real data, simulation-based data can be used to develop an artificial intelligence model for the application of rapid assessment of school testing policies.",
        "DOI": "10.3390/electronics10141626",
        "affiliation_name": "York University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Energy Consumption and Price Forecasting Through Data-Driven Analysis Methods: A Review",
        "paper_author": "Patel H.",
        "publication": "SN Computer Science",
        "citied_by": "17",
        "cover_date": "2021-07-01",
        "Abstract": "Prediction of energy consumption and price is crucial in formatting policies related to the global energy market, demand, and supply. Data-driven analysis methods are giving rise to innovations in the world energy sector, including energy finance and economics. This paper has critically evaluated expand writings committed to Energy finance and economics applications of data-driven analysis. This paper comes up with an extensive view of state of the art in the area, which is already discussed with a different procedure. This review recognizes the applications of data-driven analysis methods in various areas such as forecasting domestic, nationwide, and transport energy consumption and price forecasting of multiple commodities, including crude oil, natural gas, and electricity. We have investigated certain research papers and given conclusion based on their researched and proposed model’s prediction results and accuracies in respective areas. Our study suggests that Artificial Neural Network (ANN), Support Vector Machine (SVM), and other proposed neural network models are the most effective methods among other statistical and machine learning methods.",
        "DOI": "10.1007/s42979-021-00698-2",
        "affiliation_name": "Pandit Deendayal Energy University",
        "affiliation_city": "Gandhinagar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Vpn-nonvpn traffic classification using deep reinforced naive bayes and fuzzy k-means clustering",
        "paper_author": "Gupta A.",
        "publication": "Proceedings - 2021 IEEE 41st International Conference on Distributed Computing Systems Workshops, ICDCSW 2021",
        "citied_by": "7",
        "cover_date": "2021-07-01",
        "Abstract": "This paper addresses one of the attack methods where threat actors break into secure networks through virtual private networks (VPN) to launch tunneling based encrypted attacks, obfuscated advanced persistent threats and malware. The paper proposes Naive Bayes augmented with deep reinforcement learning (DRL) and fuzzy k-means clustering to classify VPN and non-VPN data. The proposed method is validated on the publicly available UNB-CIC VPN non-VPN dataset and shows an accuracy comparable to other state-of-the-art machine learning algorithms for traffic characterization. The proposed approach for traffic characterization of traffic classes (e.g., FTP and P2P) and application identification (e.g., Netflix and Amazon Prime) is analyzed for traffic-class detection efficiency and accuracy, and the ability to distinguish between VPN and non-VPN network traffic. The experimental results reveal that an optimum network traffic classification is achieved for 'NB+DRL' approach, where DRL is used to reinforce the NB classification model through iterative policy evaluation and improvement and achieves recall of 0.96 in traffic categorization and 0.95 in application identification. This is further improved with fuzzy k-means clustering to reduce computational costs for encrypted network traffic classification using 'NB+DRL+fuzzy k-means clustering', where the class partitions based on k-means converge to a local minimum based on dissimilarity measures for given packet features. The test set F1 scores of 0.973 and 0.965 are achieved for traffic characterization and application identification, respectively.",
        "DOI": "10.1109/ICDCSW53096.2021.00008",
        "affiliation_name": "Toronto Metropolitan University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "An overview of inverse reinforcement learning techniques",
        "paper_author": "Shah S.I.H.",
        "publication": "Intelligent Environments 2021: Workshop Proceedings of the 17th International Conference on Intelligent Environments",
        "citied_by": "6",
        "cover_date": "2021-07-01",
        "Abstract": "In decision-making problems reward function plays an important role in finding the best policy. Reinforcement Learning (RL) provides a solution for decision-making problems under uncertainty in an Intelligent Environment (IE). However, it is difficult to specify the reward function for RL agents in large and complex problems. To counter these problems an extension of RL problem named Inverse Reinforcement Learning (IRL) is introduced, where reward function is learned from expert demonstrations. IRL is appealing for its potential use to build autonomous agents, capable of modeling others, deprived of compromising in performance of the task. This approach of learning by demonstrations relies on the framework of Markov Decision Process (MDP). This article elaborates original IRL algorithms along with their close variants to mitigate challenges. The purpose of this paper is to highlight an overview and theoretical background of IRL in the field of Machine Learning (ML) and Artificial Intelligence (AI). We presented a brief comparison between different variants of IRL in this article.",
        "DOI": "10.3233/AISE210097",
        "affiliation_name": "Consiglio Nazionale delle Ricerche",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Online calculation of coal-fired boiler combustion efficiency based on machine learning",
        "paper_author": "Bo C.",
        "publication": "Clean Coal Technology",
        "citied_by": "2",
        "cover_date": "2021-07-01",
        "Abstract": "The direction of economic development and policy orientation has promoted the upgrading of coal-fired boilers in thermal power plants towards the direction of intelligence. The combustion efficiency of coal-fired boiler is an important indicator to measure the operating status of boiler. In order to meet the requirements of real-time calculation of boiler thermal efficiency, the following methods are used to calculate the boiler efficiency with the help of the daily measurement data of the power plant j Firstly, the corresponding combustion and operation characteristics of the boiler were analyzed; Secondly, according to the extracted features, the preprocessing methods of eliminating outliers,steady state discrimination,and similarity processing were carried out to generate better training samples. Finally,the neural net¬work algorithm improved by genetic algorithm was used to establish the calculation model among the boiler exhaust temperature, fly ash car¬bon content and coal ash content. The calorific value of the coal into the furnace was calculated by using the proportional relationship be¬tween the calorific value of coal and the theoretical air volume,and the calculated value was used in the inverse balance calculation model of the boiler thermal efficiency. The calculation results show that the predicted value of the neural network model can meet the require¬ments of engineering calculation. The calculated exhaust gas temperature, fly ash carbon content and coal ash content can be used in the calculation of boiler efficiency to realize real-time dynamic boiler efficiency calculation. The change of the calculated boiler efficiency is approximately the same as that of the actual evaporation change. When the actual evaporation capacity of the boiler decreases, the effi-ciency of the boiler will decrease. When the actual evaporation capacity of the boiler is maintained above 60% of the rated evaporation ca¬pacity, the boiler efficiency is easily maintained at a high level.",
        "DOI": "10.13226/j.issn.1006-6772.CE21042501",
        "affiliation_name": "Key Lab of Energy Thermal Conversion and Control, Ministry of Education",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Application of Machine Learning and Statistics in Banking Customer Churn Prediction",
        "paper_author": "Shukla A.",
        "publication": "2021 8th International Conference on Smart Computing and Communications: Artificial Intelligence, AI Driven Applications for a Smart World, ICSCC 2021",
        "citied_by": "7",
        "cover_date": "2021-07-01",
        "Abstract": "Application of the core concepts of Machine Learning and Statistics for predicting whether the customer would leave the services of the bank in future or not. Machine learning model is trained by considering the data of 10,000 customers of the bank. Statistical Techniques are applied so as to investigate the data in depth and infer the relationships between different features or variables of data. The web application uses the trained model in the backend to predict the probability of the customer leaving the bank. Hence, the website can prove to be extremely useful for the bank managers and decision makers of the bank to get an idea of those customers who are likely to leave the services of the bank in future and can retain them by formulating some new policies.",
        "DOI": "10.1109/ICSCC51209.2021.9528258",
        "affiliation_name": "Bharati Vidyapeeth (Deemed to be University) College of Engineering",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Citizen Participation and Machine Learning for a Better Democracy",
        "paper_author": "Arana-Catania M.",
        "publication": "Digital Government: Research and Practice",
        "citied_by": "53",
        "cover_date": "2021-07-01",
        "Abstract": "The development of democratic systems is a crucial task as confirmed by its selection as one of the Millennium Sustainable Development Goals by the United Nations. In this article, we report on the progress of a project that aims to address barriers, one of which is information overload, to achieving effective direct citizen participation in democratic decision-making processes. The main objectives are to explore if the application of Natural Language Processing (NLP) and machine learning can improve citizens' experience of digital citizen participation platforms. Taking as a case study the \"Decide Madrid\"Consul platform, which enables citizens to post proposals for policies they would like to see adopted by the city council, we used NLP and machine learning to provide new ways to (a) suggest to citizens proposals they might wish to support; (b) group citizens by interests so that they can more easily interact with each other; (c) summarise comments posted in response to proposals; and (d) assist citizens in aggregating and developing proposals. Evaluation of the results confirms that NLP and machine learning have a role to play in addressing some of the barriers users of platforms such as Consul currently experience. CCS concepts: •Human-centred computing→Collaborative and social computing •Computing methodologies→Artificial intelligence→Natural language processing",
        "DOI": "10.1145/3452118",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Optimizing Computation Offloading in Satellite-UAV-Served 6G IoT: A Deep Learning Approach",
        "paper_author": "Mao B.",
        "publication": "IEEE Network",
        "citied_by": "141",
        "cover_date": "2021-07-01",
        "Abstract": "Satellite networks can provide Internet of Things (IoT) devices in remote areas with seamless coverage and downlink multicast transmissions. However, the large transmission latency, serious path loss, as well as the energy and resource constraints of IoT terminals challenge the stringent service requirements for throughput and latency in the 6G era. To address these problems, technologies including space-air-ground integrated networks (SAGINs), machine learning, edge computing, and energy harvesting are highly expected in 6G IoT. In this article, we consider the unmanned aerial vehicles (UAVs) and satellites to offer wireless-powered IoT devices edge computing and cloud computing services, respectively. To accelerate the communications, Terahertz frequency bands are utilized for communications between UAVs and IoT devices. Since the tasks generated by terrestrial IoT devices can be conducted locally, offloaded to the UAV-based edge servers or remote cloud servers through satellites, we focus on the computation offloading problem and consider deep learning techniques to optimize the task success rate considering the energy dynamics and channel conditions. A deep-learning-based offloading policy optimization strategy is given where the long short-term memory model is considered to address the dynamics of energy harvesting performance. Through the theoretical explanation and performance analysis, we discover the importance of emerging technologies including SAGIN, energy harvesting, and artificial intelligence techniques for 6G IoT.",
        "DOI": "10.1109/MNET.011.2100097",
        "affiliation_name": "Tohoku University",
        "affiliation_city": "Sendai",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Reinforcement Learning in Reproducing Kernel Hilbert Spaces: Enabling Continuous Brain?Machine Interface Adaptation",
        "paper_author": "Wang Y.",
        "publication": "IEEE Signal Processing Magazine",
        "citied_by": "4",
        "cover_date": "2021-07-01",
        "Abstract": "This tutorial reviews a series of reinforcement learning (RL) methods implemented in a reproducing kernel Hilbert space (RKHS) developed to address the challenges imposed on decoder design. RL-based decoders enable the user to learn the prosthesis control through interactions without desired signals and better represent the subject's goal to complete the task. The numerous actions in complex tasks and nonstationary neural states form a vast and dynamic state-action space, imposing a computational challenge in the decoder to detect the emerging neural patterns as well as quickly establish and adjust the globally optimal policy.",
        "DOI": "10.1109/MSP.2021.3076309",
        "affiliation_name": "University of Florida",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using conditional random fields to optimize a self-adaptive bell-lapadula model in control systems",
        "paper_author": "Yang L.",
        "publication": "IEEE Transactions on Systems, Man, and Cybernetics: Systems",
        "citied_by": "5",
        "cover_date": "2021-07-01",
        "Abstract": "Once defined, the access control policies and regulations would never be changed in a running and state transition process. However, it will give attackers the possibility of discovering vulnerabilities in the system, and the control systems lack the ability of dynamic perception of security state and risk, causing the systems to be exposed to risks. In this article, a dynamic Bell-LaPadula (BLP) model is proposed. The conditional random field (CRF) is introduced into the BLP model to optimize the rules. First, the model formalizes the security attributes, states of system, transition rules, and constraint models on the basis of the state transition of CRFs. After the historical system access logs are processed as the original dataset, a feature selection method is proposed to extract the requests and current states as feature vectors. Second, this article presents a rules training algorithm based on L-BFGS to implement the study and training of datasets, and then marks the logs in the test set through Viterbi algorithm automatically. On the base of these, a rule generation algorithm is proposed to dynamically adjust the access control rules based on the current security status and events of the system. Third, the security of CRFs-BLP is proved by theoretical analysis. Finally, the validity and accuracy of the model are verified by estimating the value of the precision, recall, and F1-score. As the system threats are shown to be decreased obviously from these experiments, this dynamic model can decrease the vulnerabilities and risk effectively.",
        "DOI": "10.1109/TSMC.2019.2937551",
        "affiliation_name": "Hunan University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Pricing through health apps generated data- Digital dividend as a game changer: Discrete choice experiment",
        "paper_author": "Heidel A.",
        "publication": "PLoS ONE",
        "citied_by": "10",
        "cover_date": "2021-07-01",
        "Abstract": "Objectives The objective of this paper is to study under which circumstances wearable and health app users would accept a compensation payment, namely a digital dividend, to share their selftracked health data. Methods We conducted a discrete choice experiment alternative, a separated adaptive dual response. We chose this approach to reduce extreme response behavior, considering the emotionally-charged topic of health data sales, and to measure willingness to accept. Previous experiments in lab settings led to demands for high monetary compensation. After a first online survey and two pre-studies, we validated four attributes for the final online study: monthly bonus payment, stakeholder handling the data (e.g., health insurer, pharmaceutical or medical device companies, universities), type of data, and data sales to third parties. We used a random utility framework to evaluate individual choice preferences. To test the expected prices of the main study for robustness, we assigned respondents randomly to one of two identical questionnaires with varying price ranges.",
        "DOI": "10.1371/journal.pone.0254786",
        "affiliation_name": "WHU - Otto Beisheim School of Management",
        "affiliation_city": "Vallendar",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A NEAT quantum error decoder",
        "paper_author": "Théveniaut H.",
        "publication": "SciPost Physics",
        "citied_by": "1",
        "cover_date": "2021-07-01",
        "Abstract": "We investigate the use of the evolutionary NEAT algorithm for the optimization of a policy network that performs quantum error decoding on the toric code, with bitflip and depolarizing noise, one qubit at a time. We find that these NEAT-optimized network decoders have similar performance to previously reported machine-learning based decoders, but use roughly three to four orders of magnitude fewer parameters to do so.",
        "DOI": "10.21468/SCIPOSTPHYS.11.1.005",
        "affiliation_name": "Université Toulouse III - Paul Sabatier",
        "affiliation_city": "Toulouse",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Improving Healthcare Cost, Quality, and Access Through Artificial Intelligence and Machine Learning Applications",
        "paper_author": "Ball H.C.",
        "publication": "Journal of Healthcare Management",
        "citied_by": "8",
        "cover_date": "2021-07-01",
        "Abstract": "Since the early 1970s, technology has increasingly become integrated into the healthcare field. Today, artificial intelligence (AI) and machine learning (ML, a set of learning techniques used by AI) have the capacity to revolutionize the delivery of patient care. This essay examines the mechanics and processes of machine learning through discussion of deep learning and natural language processing and then discusses the application of these learning techniques in pattern recognition of malignant tumors in comparison to present methods of diagnostic imaging assessment. The discussion also covers the implications of AI assistive technology more broadly regarding ethical policy making, patient autonomy, and the healthcare Iron Triangle of cost, quality, and access. It concludes with the idea that failure to incorporate AI and ML techniques in healthcare may be malpractice.",
        "DOI": "10.1097/JHM-D-21-00149",
        "affiliation_name": "Texas State University",
        "affiliation_city": "San Marcos",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Two degree-of-freedom robotic eye: Design, modeling, and learning-based control in foveation and smooth pursuit",
        "paper_author": "Rajendran S.K.",
        "publication": "Bioinspiration and Biomimetics",
        "citied_by": "10",
        "cover_date": "2021-07-01",
        "Abstract": "With increasing ocular motility disorders affecting human eye movement, the need to understand the biomechanics of the human eye rises constantly. A robotic eye system that physically mimics the human eye can serve as a useful tool for biomedical researchers to obtain an intuitive understanding of the functions and defects of the extraocular muscles and the eye. This paper presents the design, modeling, and control of a two degree-of-freedom (2-DOF) robotic eye, driven by artificial muscles, in particular, made of super-coiled polymers (SCPs). Considering the highly nonlinear dynamics of the robotic eye system, this paper applies deep deterministic policy gradient (DDPG), a machine learning algorithm to solve the control design problem in foveation and smooth pursuit of the robotic eye. To the best of our knowledge, this paper presents the first modeling effort to establish the dynamics of a robotic eye driven by SCP actuators, as well as the first control design effort for robotic eyes using a DDPG-based control strategy. A linear quadratic regulator-type reward function is proposed to achieve a balance between system performances (convergence speed and tracking accuracy) and control efforts. Simulation results are presented to demonstrate the effectiveness of the proposed control strategy for the 2-DOF robotic eye.",
        "DOI": "10.1088/1748-3190/abfe40",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Knowledge generation via social-knowledge network co-evolution: 30 years (1990–2019) of adaptation, mitigation and transformation related to climate change",
        "paper_author": "Baggio J.A.",
        "publication": "Climatic Change",
        "citied_by": "5",
        "cover_date": "2021-07-01",
        "Abstract": "Knowledge production is a co-evolutionary process where scientific topics and concepts are debated, discussed and assessed between scientists. We assess, we analyze, we “interpret” the world, and, at the same time, we communicate with one another, and we value certain knowledge more than other knowledge, based on some measure of prestige, conformism or past events. Here we analyze the evolution of research topics over the past 30 years (from 1990 to 2019) and assess how research topics have evolved by jointly analyzing topic evolution and the citation network related to climate change adaptation, mitigation or transformation. We found that (1) the research focus has evolved from emissions and modelling to social impacts (i.e. local policies), (2) research on climate change (and possibly research in general) is often confined within specific research areas, hinting that interdisciplinary and convergent work may open opportunities for integrative research able to foster innovative thinking in climate science, and (3) the climate change literature is increasing in overall complexity, requiring novel tools to make sense of the literature such as the implementation of more refined machine learning and natural language process algorithms to identify causal mechanisms and synthesize the body of work to generate new knowledge.",
        "DOI": "10.1007/s10584-021-03146-5",
        "affiliation_name": "University of Central Florida",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "What determines the effectiveness of national protected area networks?",
        "paper_author": "Shah P.",
        "publication": "Environmental Research Letters",
        "citied_by": "23",
        "cover_date": "2021-07-01",
        "Abstract": "More than 15% of global terrestrial area is under some form of protection and there is a growing impetus to increase this coverage to 30% by 2030. But not all protection is effective and the reasons some countries' protected areas (PAs) are more effective than others' are poorly understood. We evaluate the effectiveness of national PA networks established between 2000 and 2012 globally in avoiding forest loss, taking into account underlying deforestation threats using a combination of matching methods and cross-sectional regressions. We then assess which demographic, agricultural, economic, and governance factors are most strongly associated with national PA effectiveness using machine learning methods. We estimate that national PAs established between 2000 and 2012 reduced deforestation in those areas by 72%, avoiding 86 062 km2 of forest loss. The effectiveness of national PAs varied by strictness of protection based on International Union for Conservation of Nature category. Strictly PAs reduced forest loss by 81% compared to what would have occurred without protection, while less strictly PAs reduced forest loss by 67%. Thus, the 26% of new PAs that were strictly protected contributed 39% of the total forest loss avoided within PAs between 2000 and 2012. If every country's PAs were as effective as the country with the most effective PAs within the same region, they would have increased the area of deforestation avoided by 38%, saving a further 119 082 km2 of forest. Part of the variation in PA effectiveness across countries is explained by the placement of PA in areas facing higher deforestation threat. Countries with lower agricultural activity, higher economic growth and better governance are most strongly associated with greater country-level PA effectiveness.",
        "DOI": "10.1088/1748-9326/ac05ed",
        "affiliation_name": "Okinawa Institute of Science and Technology Graduate University",
        "affiliation_city": "Okinawa",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "The innovative state",
        "paper_author": "Noveck B.S.",
        "publication": "Daedalus",
        "citied_by": "5",
        "cover_date": "2021-07-01",
        "Abstract": "To create government that is neither bigger nor smaller but better at solving problems more effectively and legitimately, agencies need to use big data and the associated technologies of machine learning and predictive analytics. Such data-analytical approaches will help agencies understand the problems they are addressing more empirically and devise more responsive policies and services. Such data-processing tools can also be used to make citizen engagement more efficient, helping agencies to make sense of large quantities of information and invite meaningful participation from more diverse audiences who have never participated in our democracy. To take advantage of the power of new technologies for governing, however, the federal government needs, first and foremost, to invest in training public servants to work differently and prepare them for the future of work in a new technological age.",
        "DOI": "10.1162/DAED_a_01863",
        "affiliation_name": "New York University",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Anatomy into the battle of supporting or opposing reopening amid the COVID-19 pandemic on Twitter: A temporal and spatial analysis",
        "paper_author": "Li L.",
        "publication": "PLoS ONE",
        "citied_by": "13",
        "cover_date": "2021-07-01",
        "Abstract": "Reopening amid the COVID-19 pandemic has triggered a battle on social media. The supporters perceived that the lockdown policy could damage the economy and exacerbate social inequality. By contrast, the opponents believed it was necessary to contain the spread and ensure a safe environment for recovery. Anatomy into the battle is of importance to address public concerns, beliefs, and values, thereby enabling policymakers to determine the appropriate solutions to implement reopening policy. To this end, we investigated over 1.5 million related Twitter postings from April 17 to May 30, 2020. With the aid of natural language processing (NLP) techniques and machine learning classifiers, we classified each tweet into either a \"supporting\"or \"opposing\"class and then investigated the public perception from temporal and spatial perspectives. From the temporal dimension, we found that both political and scientific news that were extensively discussed on Twitter led to the perception of opposing reopening. Further, being the first mover with full reopen adversely affected the public reaction to reopening policy, while being the follower or late mover resulted in positive responses. From the spatial dimension, the correlation and regression analyses suggest that the state-level perception was very likely to be associated with political affiliation and health value.",
        "DOI": "10.1371/journal.pone.0254359",
        "affiliation_name": "A. James Clark School of Engineering",
        "affiliation_city": "College Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Comparison of random forest, support vector machines, and neural networks for post-disaster forest species mapping of the krkonoše/karkonosze transboundary biosphere reserve",
        "paper_author": "Zagajewski B.",
        "publication": "Remote Sensing",
        "citied_by": "51",
        "cover_date": "2021-07-01",
        "Abstract": "Mountain forests are exposed to extreme conditions (e.g., strong winds and intense solar radiation) and various types of damage by insects such as bark beetles, which makes them very sensitive to climatic changes. Therefore, continuous monitoring is crucial, and remote-sensing techniques allow the monitoring of transboundary areas where a common policy is needed to protect and monitor the environment. In this study, we used Sentinel-2 and Landsat 8 open data to assess the forest stands classification of the UNESCO Krkonoše/Karkonosze Transboundary Biosphere Reserve, which is undergoing dynamic changes in recovering woodland vegetation due to an ecological disaster that led to damage and death of a large portion of the forests. Currently, in this protected area, dry big trunks and branches coexist with naturally occurring young forests. This heterogeneity generates mixes, which hinders the automation of classification. Thus, we used three machine learning algorithms—Random Forest (RF), Support Vector Machine (SVM), and Artificial Neural Network (ANN)—to classify dominant tree species (birch, beech, larch and spruce). The best results were obtained for the SVM RBF classifier, which offered an average median F1-score that oscillated around 67.2–91.5% depending on the species. The obtained maps, which were based on multispectral satellite images, were also compared with classifications made for the same area on the basis of hyperspectral APEX imagery (288 spectral bands with three-meter resolution), indicating high convergence in the recognition of woody species.",
        "DOI": "10.3390/rs13132581",
        "affiliation_name": "University of Warsaw",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Prevention is better than cure: Machine learning approach to conflict prediction in sub-saharan africa",
        "paper_author": "Musumba M.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "8",
        "cover_date": "2021-07-01",
        "Abstract": "This article offers policymakers and researchers pragmatic and sustainable approaches to identify and mitigate conflict threats by looking beyond p-values and plausible instruments. We argue that predicting conflict successfully depends on the choice of algorithms, which, if chosen accurately, can reduce economic and social instabilities caused by post-conflict reconstruction. After collating data with variables linked to conflict, we used a grid level dataset of 5928 observations spanning 48 countries across sub-Saharan Africa to predict civil conflict. The goals of the study were to assess the performance of supervised classification machine learning (ML) algorithms in comparison with logistic model, assess the implication of selecting a specific performance metric on policy initiatives, and evaluate the value of interpretability of the selected model. After comparing class imbalance resampling methods, the synthetic minority over-sampling technique (SMOTE) was employed to improve out-of-sample prediction for the trained model. The results indicate that if our selected performance metric is recall, gradient tree boosting is the best algorithm; however, if precision or F1 score is the selected metric, then the multilayer perceptron algorithm produces the best model.",
        "DOI": "10.3390/su13137366",
        "affiliation_name": "Texas A&amp;M University",
        "affiliation_city": "College Station",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Teleworking and online shopping: Socio-economic factors affecting their impact on transport demand",
        "paper_author": "Soler J.R.L.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "25",
        "cover_date": "2021-07-01",
        "Abstract": "Teleworking and online shopping became commonplace during the COVID-19 pandemic and can be expected to maintain a strong presence in the foreseeable future. They can lead to significant changes in mobility patterns and transport demand. It is still unclear, however, how extensive their adoption can be, since each individual has different preferences or constraints. The overall impact on transport depends on which segments of the population will modify their behaviour and on what the substitutes to the current patterns will be. The purpose of this work is to identify the user profiles and spatial aspects that affect the adoption of teleworking and online shopping, and to explore the potential impact on transport demand. To that end, data from an EU-wide survey on mobility were analysed using a Machine Learning methodology. The results suggest that while the take up of the new work and consumption patterns is high on average, there are significant differences among countries and across different socio-economic profiles. Teleworking appears to have a high potential mainly in certain services sectors, affecting commuting patterns predominantly in large urban areas. Online shopping activity is more uniform across the population, although differences among countries and age groups may still be relevant. The findings of this work can be useful for the analysis of policies to encourage the uptake of new technologies in transport and mobility. They can be also a good reference point for future studies on the ex-post analysis of the impacts of the pandemic on mobility.",
        "DOI": "10.3390/su13137211",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Creative approaches for assessing long-term outcomes in children",
        "paper_author": "Wu A.C.",
        "publication": "Pediatrics",
        "citied_by": "1",
        "cover_date": "2021-07-01",
        "Abstract": "Advances in new technologies, when incorporated into routine health screening, have tremendous promise to benefit children. The number of health screening tests, many of which have been developed with machine learning or genomics, has exploded. To assess efficacy of health screening, ideally, randomized trials of screening in youth would be conducted; however, these can take years to conduct and may not be feasible. Thus, innovative methods to evaluate the long-term outcomes of screening are needed to help clinicians and policymakers make informed decisions. These methods include using longitudinal and linked-data systems to evaluate screening in clinical and community settings, school data, simulation modeling approaches, and methods that take advantage of data available in the digital and genomic age. Future research is needed to evaluate how longitudinal and linked-data systems drawing on community and clinical settings can enable robust evaluations of the effects of screening on changes in health status. Additionally, future studies are needed to benchmark participating individuals and communities against similar counterparts and to link big data with natural experiments related to variation in screening policies. These novel approaches have great potential for identifying and addressing differences in access to screening and effectiveness of screening across population groups and communities.",
        "DOI": "10.1542/peds.2021-050693F",
        "affiliation_name": "Friends Research Institute, Inc.",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Trade and innovation policies: Coexistence and spillovers",
        "paper_author": "Auboin M.",
        "publication": "Journal of Policy Modeling",
        "citied_by": "15",
        "cover_date": "2021-07-01",
        "Abstract": "The debate over trade's role in growth and inequality in recent years seems to center on the question of whether the gains from trade are worth the disruption from necessary adjustments. In particular static gains from trade for advanced economies are generally estimated to be small, while empirical evidence around growing employment and inequality challenges suggest trade's role may be larger than previously thought, though still only one of many contributing factors. The focus on static gains though likely understates substantially the dynamic gains, as trade's role in spurring faster economic growth, in both developed and developing countries through competitive and innovative forces. The dynamic, competition and innovation angle suggests a need for industrial policies to be revisited and examine how spillovers play out in the global economy. At the same time significant technological disruption is occurring through digital technology, big data, and machine learning/AI techniques that often require advanced capabilities and have significant competition implications. In recent COVID-19 pandemic policy responses governments have dramatically increased spending and liquidity to support stressed firms and households and encouraged many countries to consider strategic efforts to build certain domestic capabilities with the aim of reducing dependence on trade for emergency related goods and services. This paper provides insights on the specific role of innovation policies, and they differ from and are similar to traditional industrial policies, and what that might mean for future trade rules.",
        "DOI": "10.1016/j.jpolmod.2021.02.010",
        "affiliation_name": "World Trade Organization",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "A review on the integration of deep learning and service-oriented architecture",
        "paper_author": "Fantinato M.",
        "publication": "Journal of Database Management",
        "citied_by": "5",
        "cover_date": "2021-07-01",
        "Abstract": "In recent years, machine learning has been used for data processing and analysis, providing insights to businesses and policymakers. Deep learning technology is promising to further revolutionize this processing leading to better and more accurate results. Current trends in information and communication technology are accelerating widespread use of web services in supporting a service-oriented architecture (SOA) consisting of services, their compositions, interactions, and management. Deep learning approaches can be applied to support the development of SOA-based solutions, leveraging the vast amount of data on web services currently available. On the other hand, SOA has mechanisms that can support the development of distributed, flexible, and reusable infrastructures for the use of deep learning. This paper presents a literature survey and discusses how SOA can be enabled by as well as facilitate the use of deep learning approaches in different types of environments for different levels of users.",
        "DOI": "10.4018/JDM.2021070105",
        "affiliation_name": "Zayed University",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Land-use conflict identification from the perspective of construction space expansion: An evaluation method based on ‘likelihood-exposure-consequence’",
        "paper_author": "Zhou H.",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "11",
        "cover_date": "2021-07-01",
        "Abstract": "Land-use conflict (LUC) is a major problem of land management in the context of rapid urbanization. Conflict identification plays an important role in the development and protection of land space. Considering the possibility of, exposure to, and negative impacts of LUC, we explore the probability of land-use cover change (LUCC), policy constraints, and ecosystem service value (ESV) and build a conflict identification model based on the LEC concept of risk assessment. Taking Daye City as an example, we classify the conflict intensity and delimit the key conflict areas. At the same time, a composite classification system is constructed to analyze the spatial characteristics and internal mechanism of conflict. We find that the conflict between construction and ecological space is the main conflict in Daye City (P.R. China), which is widely distributed. However, the conflict between construction and agricultural space, which is mainly distributed near the center of Daye City, cannot be ignored.",
        "DOI": "10.3390/ijgi10070433",
        "affiliation_name": "Wuhan University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "SDN enabled DDoS attack detection and mitigation for 5G networks",
        "paper_author": "Aryal B.",
        "publication": "Journal of Communications",
        "citied_by": "7",
        "cover_date": "2021-07-01",
        "Abstract": "This paper proposes a hybrid technique for distributed denial-of-service (DDoS) attack detection that combines statistical analysis and machine learning, with software defined networking (SDN) security. Data sets are analyzed in an iterative approach and compared to a dynamic threshold. Sixteen features are extracted, and machine learning is used to examine correlation measures between the features. A dynamically configured SDN is employed with software defined security (SDS), to provide a robust policy framework to protect the availability and integrity, and to maintain privacy of all the networks with quick response remediation. Machine learning is further employed to increase the precision of detection. This increases the accuracy from 87/88% to 99.86%, with reduced false positive ratio (FPR). The results obtained based on experimental data-sets outperformed existing techniques.",
        "DOI": "10.12720/jcm.16.7.267-275",
        "affiliation_name": "Macquarie University",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Population stratification enables modeling effects of reopening policies on mortality and hospitalization rates",
        "paper_author": "Huang T.",
        "publication": "Journal of Biomedical Informatics",
        "citied_by": "4",
        "cover_date": "2021-07-01",
        "Abstract": "Objective: Study the impact of local policies on near-future hospitalization and mortality rates. Materials and Methods: We introduce a novel risk-stratified SIR-HCD model that introduces new variables to model the dynamics of low-contact (e.g., work from home) and high-contact (e.g., work on-site) subpopulations while sharing parameters to control their respective R0(t) over time. We test our model on data of daily reported hospitalizations and cumulative mortality of COVID-19 in Harris County, Texas, from May 1, 2020, until October 4, 2020, collected from multiple sources (USA FACTS, U.S. Bureau of Labor Statistics, Southeast Texas Regional Advisory Council COVID-19 report, TMC daily news, and Johns Hopkins University county-level mortality reporting). Results: We evaluated our model's forecasting accuracy in Harris County, TX (the most populated county in the Greater Houston area) during Phase-I and Phase-II reopening. Not only does our model outperform other competing models, but it also supports counterfactual analysis to simulate the impact of future policies in a local setting, which is unique among existing approaches. Discussion: Mortality and hospitalization rates are significantly impacted by local quarantine and reopening policies. Existing models do not directly account for the effect of these policies on infection, hospitalization, and death rates in an explicit and explainable manner. Our work is an attempt to improve prediction of these trends by incorporating this information into the model, thus supporting decision-making. Conclusion: Our work is a timely effort to attempt to model the dynamics of pandemics under the influence of local policies.",
        "DOI": "10.1016/j.jbi.2021.103818",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Dual dynamic scheduling for hierarchical qos in uplink-noma: A reinforcement learning approach",
        "paper_author": "Li X.",
        "publication": "Sensors",
        "citied_by": "2",
        "cover_date": "2021-07-01",
        "Abstract": "The demand for bandwidth-intensive and delay-sensitive services is surging daily with the development of 5G technology, resulting in fierce competition for scarce radio resources. Power domain Nonorthogonal Multiple Access (NOMA) technologies can dramatically improve system capacity and spectrum efficiency. Unlike existing NOMA scheduling that mainly focuses on fairness, this paper proposes a power control solution for uplink hybrid OMA and PD-NOMA in dual dynamic environments: dynamic and imperfect channel information together with the random user-specific hierarchical quality of service (QoS). This paper models the power control problem as a nonconvex stochastic, which aims to maximize system energy efficiency while guaranteeing hierarchical user QoS requirements. Then, the problem is formulated as a partially observable Markov decision process (POMDP). Owing to the difficulty of modeling time-varying scenes, the urgency of fast convergency, the adaptability in a dynamic environment, and the continuity of the variables, a Deep Reinforcement Learning (DRL)-based method is proposed. This paper also transforms the hierarchical QoS constraint under the NOMA serial interference cancellation (SIC) scene to fit DRL. The simulation results verify the effectiveness and robustness of the proposed algorithm under a dual uncertain environment. As compared with the baseline Particle Swarm Optimization algorithm (PSO), the proposed DRL-based method has demonstrated satisfying performance.",
        "DOI": "10.3390/s21134404",
        "affiliation_name": "New York Institute of Technology",
        "affiliation_city": "Old Westbury",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Optimal Feedback Control of Pedestrian Flow in Heterogeneous Corridors",
        "paper_author": "Zhu Y.",
        "publication": "IEEE Transactions on Automation Science and Engineering",
        "citied_by": "15",
        "cover_date": "2021-07-01",
        "Abstract": "Maintaining the orderliness and efficiency of pedestrian flow through an architectural area is critical for the evacuation process. Especially, clogs and jams are easily triggered in width-changing areas. In this article, we consider pedestrian movement in heterogeneous corridors and design an optimal feedback control to regulate pedestrian flow. Flow characteristics are first studied based on microscopic social-force simulations. A Gaussian process describes the relationship between flow variables with the observation data. The macroscopic model for flow in heterogeneous corridors is developed. To avoid jams, discharges among these corridors are balanced with the narrowest corridor as the primary concern. At the equilibrium, a continuous-time nonlinear control system is formulated, and the adaptive dynamic programming learns the optimal feedback controller. Policy iteration (PI) and neural networks are combined together, and the convergence of neural-network-based PI is demonstrated by analyzing its equivalence to the Gauss-Newton method. Batch normalization is introduced to stabilize the learning process. Simulated experiments demonstrate that the control design can effectively regulate pedestrian flow for both macroscopic and microscopic models. Note to Practitioners - The development of video-processing techniques provides a powerful tool to detect human behavior in real time. In crowd events, the pedestrian movement must be regulated; otherwise, it is easy to fall into the faster-is-slower effect. It is especially important for evacuation routes with different widths. In this article, the optimal feedback control is studied to regulate pedestrian flow in heterogeneous corridors. It takes flow densities as state and produces commands that are composed of entrance influx and free-flow velocities. These commands can be executed with the support of speakers, displays, or the recently developed interactive robots. To avoid congestion, discharges of different corridors are balanced, and the system is optimally stabilized at equilibrium. Based on our work, engineers are able to design pedestrian flow control and achieve optimal evacuation in arbitrary heterogeneous corridors.",
        "DOI": "10.1109/TASE.2020.2996018",
        "affiliation_name": "University of Rhode Island’s College of Engineering",
        "affiliation_city": "Kingston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Fault-Tolerant control of programmable logic controller-based production systems with deep reinforcement learning",
        "paper_author": "Zinn J.",
        "publication": "Journal of Mechanical Design",
        "citied_by": "6",
        "cover_date": "2021-07-01",
        "Abstract": "Fault-tolerant control policies that automatically restart programable logic controller-based automated production system during fault recovery can increase system availability. This article provides a proof of concept that such policies can be synthesized with deep reinforcement learning. The authors specifically focus on systems with multiple end-effectors that are actuated in only one or two axes, commonly used for assembly and logistics tasks. Due to the large number of actuators in multi-end-effector systems and the limited possibilities to track workpieces in a single coordinate system, these systems are especially challenging to learn. This article demonstrates that a hierarchical multi-agent deep reinforcement learning approach together with a separate coordinate prediction module per agent can overcome these challenges. The evaluation of the suggested approach on the simulation of a small laboratory demonstrator shows that it is capable of restarting the system and completing open tasks as part of fault recovery.",
        "DOI": "10.1115/1.4050624",
        "affiliation_name": "Technische Universität München",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "POCASUM: policy categorizer and summarizer based on text mining and machine learning",
        "paper_author": "Deotale R.",
        "publication": "Soft Computing",
        "citied_by": "4",
        "cover_date": "2021-07-01",
        "Abstract": "Having control over your data is a right and a duty that every citizen has in our digital society. It is often that users skip entire policies of applications or websites to save time and energy without realizing the potential sticky points in these policies. Due to obscure language and verbose explanations majority of users of hypermedia do not bother to read them. Further, sometimes digital media companies do not spend enough effort in stating their policies clearly which often time can also be incomplete. A summarized version of these privacy policies that can be categorized into the useful information can help the users. To solve this problem, in this work we propose to use machine learning-based models for policy categorizer that classifies the policy paragraphs under the attributes proposed like security, contact, etc. By benchmarking different machine learning-based classifier models, we show that artificial neural network model performs with higher accuracy on a challenging dataset of textual privacy policies. We thus show that machine learning can help summarize the relevant paragraphs under the various attributes so that the user can get the gist of that topic within a few lines.",
        "DOI": "10.1007/s00500-021-05916-w",
        "affiliation_name": "Cincinnati Children's Hospital Medical Center",
        "affiliation_city": "Cincinnati",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Cancer matters: Now more than ever!",
        "paper_author": "Ramalingam S.S.",
        "publication": "Cancer",
        "citied_by": "0",
        "cover_date": "2021-07-01",
        "Abstract": "NA",
        "DOI": "10.1002/cncr.33669",
        "affiliation_name": "Emory University",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Federated deep learning architecture for personalized healthcare",
        "paper_author": "Chen H.",
        "publication": "Public Health and Informatics: Proceedings of MIE 2021",
        "citied_by": "3",
        "cover_date": "2021-07-01",
        "Abstract": "Using deep learning to advance personalized healthcare requires data about patients to be collected and aggregated from disparate sources that often span institutions and geographies. Researchers regularly come face-to-face with legitimate security and privacy policies that constrain access to these data. In this work, we present a vision for privacy-preserving federated neural network architectures that permit data to remain at a custodian's institution while enabling the data to be discovered and used in neural network modeling. Using a diabetes dataset, we demonstrate that accuracy and processing efficiencies using federated deep learning architectures are equivalent to the models built on centralized datasets. © 2021 European Federation for Medical Informatics (EFMI) and IOS Press.",
        "DOI": "10.3233/SHTI210147",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Data-driven Optimal Control Strategy for Virtual Synchronous Generator via Deep Reinforcement Learning Approach",
        "paper_author": "Li Y.",
        "publication": "Journal of Modern Power Systems and Clean Energy",
        "citied_by": "93",
        "cover_date": "2021-07-01",
        "Abstract": "This paper aims at developing a data-driven optimal control strategy for virtual synchronous generator (VSG) in the scenario where no expert knowledge or requirement for system model is available. Firstly, the optimal and adaptive control problem for VSG is transformed into a reinforcement learning task. Specifically, the control variables, i.e., virtual inertia and damping factor, are defined as the actions. Meanwhile, the active power output, angular frequency and its derivative are considered as the observations. Moreover, the reward mechanism is designed based on three preset characteristic functions to quantify the control targets: (1) maintaining the deviation of angular frequency within special limits; (2) preserving well-damped oscillations for both the angular frequency and active power output; (3) obtaining slow frequency drop in the transient process. Next, to maximize the cumulative rewards, a decentralized deep policy gradient algorithm, which features model-free and faster convergence, is developed and employed to find the optimal control policy. With this effort, a data-driven adaptive VSG controller can be obtained. By using the proposed controller, the inverter-based distributed generator can adaptively adjust its control variables based on current observations to fulfill the expected targets in model-free fashion. Finally, simulation results validate the feasibility and effectiveness of the proposed approach.",
        "DOI": "10.35833/MPCE.2020.000267",
        "affiliation_name": "Daniel Felix Ritchie School of Engineering &amp; Computer Science",
        "affiliation_city": "Denver",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Parameterized reinforcement learning for optical system optimization",
        "paper_author": "Wankerl H.",
        "publication": "Journal of Physics D: Applied Physics",
        "citied_by": "19",
        "cover_date": "2021-07-01",
        "Abstract": "Engineering a physical system to feature designated characteristics states an inverse design problem, which is often determined by several discrete and continuous parameters. If such a system must feature a particular behavior, the mentioned combination of both, discrete and continuous, parameters results in a challenging optimization problem that requires an extensive search for an optimal system design. However, if the corresponding inverse design problem can be reformulated as a parameterized Markov decision process, reinforcement learning (RL) provides a heuristic framework to solve it. In this work, we use multi-layer thin films as an example of the aforementioned optimization problems and consider three design parameters: Each of the thin film layer's dielectric material (discrete) and thickness (continuous), as well as the total number of layers (discrete). While recent methods merely determine the optimal thicknesses and-less commonly-the layers' materials, our approach optimizes the total number of stacked layers as well. In summary, we further develop a Q-learning variant to solve inverse design optimization and thereby outperform human experts and current approaches like needle-point optimization or naive RL. For this purpose, we propose an exponentially transformed reward signal that eases policy search and enables constrained optimization. Moreover, the learned Q-values contain information about the optical properties of multi-layer thin films, which allows us a physical interpretation or what-if analysis and thus enables explainability.",
        "DOI": "10.1088/1361-6463/abfddb",
        "affiliation_name": "OSRAM Opto Semiconductors",
        "affiliation_city": "Regensburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Shipping Domain Knowledge Informed Prediction and Optimization in Port State Control",
        "paper_author": "Yan R.",
        "publication": "Transportation Research Part B: Methodological",
        "citied_by": "53",
        "cover_date": "2021-07-01",
        "Abstract": "Maritime transportation is the backbone of global supply chain. To improve maritime safety, protect the marine environment, and set out seafarers’ rights, port state control (PSC) empowers ports to inspect foreign visiting ships to verify them comply with various international conventions. One critical issue faced by the port states is how to optimally allocate the limited inspection resources for inspecting the visiting ships. To address this issue, this study first develops a state-of-the-art XGBoost model to accurately predict ship deficiency number considering ship generic factors, dynamic factors, and inspection historical factors. Particularly, the XGBoost model takes shipping domain knowledge regarding ship flag, recognized organization, and company performance into account to improve model performance and prediction fairness (e.g., for two ships that are different only in their flag performances, the one with a better flag performance should be predicted to have a better condition than the other). Based on the predictions, a PSC officer (PSCO) scheduling model is proposed to help the maritime authorities optimally allocate inspection resources. Considering that a PSCO can inspect at most four ships in a day, we further propose and incorporate the concepts of inspection template and un-dominated inspection template in the optimization models to reduce problem size as well as improve computation efficiency and model flexibility. Numerical experiments show that the proposed PSCO scheduling model with the predictions of XGBoost as the input is more than 20% better than the current inspection scheme at ports regarding the number of deficiencies detected. In addition, the gap between the proposed model and the model under perfect-forecast policy is only about 8% regarding the number of deficiencies detected. Extensive sensitivity experiments show that the proposed PSCO scheduling model has stable performance and is always better than the current model adopted at ports.",
        "DOI": "10.1016/j.trb.2021.05.003",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "A data-driven operational model for traffic at the Dallas Fort Worth International Airport",
        "paper_author": "Lunacek M.",
        "publication": "Journal of Air Transport Management",
        "citied_by": "10",
        "cover_date": "2021-07-01",
        "Abstract": "Airports are on the front line of significant innovations, allowing the movement of more people and goods faster, cheaper, and with greater convenience. As air travel continues to grow, airports will face challenges in responding to increasing passenger vehicle traffic, which leads to lower operational efficiency, poor air quality, and security concerns. This paper evaluates methods for traffic demand forecasting combined with traffic microsimulation, which will allow airport operations staff to accurately predict traffic and congestion. Using two years of detailed data describing individual vehicle arrivals and departures, aircraft movements, and weather at Dallas-Fort Worth (DFW) International Airport, we evaluate multiple prediction methods including the Auto Regressive Integrated Moving Average (ARIMA) family of models, traditional machine learning models, and DeepAR, a modern recurrent neural network (RNN). We find that these algorithms are able to capture the diurnal trends in the surface traffic, and all do very well when predicting the next 30 minutes of demand. Longer forecast horizons are moderately effective, demonstrating the challenge of this problem and highlighting promising techniques as well as potential areas for improvement. Traffic demand is not the only factor that contributes to terminal congestion, because temporary changes to the road network, such as a lane closure, can make benign traffic demand highly congested. Combining a demand forecast with a traffic microsimulation framework provides a complete picture of traffic and its consequences. The result is an operational intelligence platform for exploring policy changes, as well as infrastructure expansion and disruption scenarios. To demonstrate the value of this approach, we present results from a case study at DFW Airport assessing the impact of a policy change for vehicle routing in high demand scenarios. This framework can assist airports like DFW as they tackle daily operational challenges, as well as explore the integration of emerging technology and expansion of their services into long term plans.",
        "DOI": "10.1016/j.jairtraman.2021.102061",
        "affiliation_name": "National Renewable Energy Laboratory",
        "affiliation_city": "Golden",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "How has Science Education changed over the last 100 years? An analysis using natural language processing",
        "paper_author": "Odden T.O.B.",
        "publication": "Science Education",
        "citied_by": "42",
        "cover_date": "2021-07-01",
        "Abstract": "For well over a century, the journal Science Education has been publishing articles about the teaching and learning of science. These articles represent more than just a repository of past work: they have the potential to offer insights into both the history of science education as well as well as the dynamics of field-specific change. It can be difficult, however, for educators, researchers, reformers, and policymakers to grasp the nuances of over 100 years of scholarship given the overwhelming amount of textual material. To address this problem, we have used latent Dirichlet allocation, an automated machine-learning algorithm from the field of natural language processing, to perform an automated literature review and classification of the corpus of work in Science Education. Using this technique, we have classified research in the journal into 21 distinct topics, falling into three thematic groups: science content topics, teaching-focused topics, and student-focused topics. We have also quantified the rise and fall of these topics and groups over time, and used them to begin to extract insight into the development of the field, including the effects of national policy changes on topics of interest to the research community, the interrelationships between different research topics, and the effects of intellectual cross-pollination. Based on this analysis, we argue that this technique shows great promise for even larger-scale analyses of educational literature and other textual data.",
        "DOI": "10.1002/sce.21623",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Changes in air pollutants during the COVID-19 lockdown in Beijing: Insights from a machine-learning technique and implications for future control policy",
        "paper_author": "Hu J.",
        "publication": "Atmospheric and Oceanic Science Letters",
        "citied_by": "16",
        "cover_date": "2021-07-01",
        "Abstract": "The COVID-19 lockdowns led to abrupt reductions in human-related emissions worldwide and had an unintended impact on air quality improvement. However, quantifying this impact is difficult as meteorological conditions may mask the real effect of changes in emissions on the observed concentrations of pollutants. Based on the air quality and meteorological data at 35 sites in Beijing from 2015 to 2020, a machine learning technique was applied to decouple the impacts of meteorology and emissions on the concentrations of air pollutants. The results showed that the real (“deweathered”) concentrations of air pollutants (expect for O3) dropped significantly due to lockdown measures. Compared with the scenario without lockdowns (predicted concentrations), the observed values of PM2.5, PM10, SO2, NO2, and CO during lockdowns decreased by 39.4%, 50.1%, 51.8%, 43.1%, and 35.1%, respectively. In addition, a significant decline for NO2 and CO was found at the background sites (51% and 37.8%) rather than the traffic sites (37.1% and 35.5%), which is different from the common belief. While the primary emissions reduced during the lockdown period, episodic haze events still occurred due to unfavorable meteorological conditions. Thus, developing an optimized strategy to tackle air pollution in Beijing is essential in the future. 摘要 基于2015–2020年北京35个环境空气站和20个气象站观测资料, 应用机器学习方法 (随机森林算法) 分离了气象条件和源排放对大气污染物浓度的影响. 结果发现, 为应对疫情采取的隔离措施使北京2020年春节期间大气污染物浓度降低了35.1%–51.8%; 其中, 背景站氮氧化物和一氧化碳浓度的降幅最大, 超过了以往报道较多的交通站点. 同时, 2020年春节期间的气象条件不利于污染物扩散, 导致多次霾污染事件发生.为进一步改善北京空气质量, 未来需要优化减排策略.",
        "DOI": "10.1016/j.aosl.2021.100060",
        "affiliation_name": "National Satellite Meteorological Center Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Developing capabilities: Lifelong learning in the age of AI",
        "paper_author": "Poquet O.",
        "publication": "British Journal of Educational Technology",
        "citied_by": "62",
        "cover_date": "2021-07-01",
        "Abstract": "Due to the ongoing digitalisation of workplaces and educational settings, human activity underpinning learning and work is increasingly mediated by technology. The advancement of artificial intelligence (AI) and its integration into everyday technologies influences how people are exposed to information, interact, learn and make decisions. We argue that technology, data and evolving AI applications affect how humans enact and experience life and work, changing the context for learning. Hence, as this paper argues, the current notion of lifelong learning needs a revisit to embrace technology at its foundation. To bring freely chosen goals and ownership in one's learning to the fore, in the context of the coming AI age, we argue for the telos of learning to shift from human capital to human development, with the spotlight on capabilities. The paper draws on the capability approach to inform individuals and organisations of how they can support human development throughout lifelong learning. We then move to provide examples of how technologies underpinning workplace practices can be seen with the focus on capabilities as individuals learn to create value. Practitioner notes What is known about the topic? The primary notion of lifelong learning refers to adult learning processes. The policy perspective that dominates organisation of lifelong learning opportunities focuses on human capital development. Technologies mediate learning and work. What this paper adds Technology is not explicitly addressed in meanings associated with lifelong learning. AI-based technologies dynamically interact with human cognitive and social practices. The paper argues for a stronger focus on human development instead of human capital in the telos of lifelong learning opportunities. Capability approach is a viable alternative to human capital perspective on LLL. Data used to support learning can focus on learner agency and systemic factors that enable and constrain lifelong learning. Implications for practice and/or policy LLL interventions should promote systemic support for learner agency and ownership. LLL interventions should focus on negotiated value creation. Workplaces should embrace human-machine integration but in ways that support capability and human development, not human capital.",
        "DOI": "10.1111/bjet.13123",
        "affiliation_name": "University of South Australia",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Generational differences in automobility: Comparing America's Millennials and Gen Xers using gradient boosting decision trees",
        "paper_author": "Wang K.",
        "publication": "Cities",
        "citied_by": "21",
        "cover_date": "2021-07-01",
        "Abstract": "Whether the Millennials are less auto-centric than the previous generations has been widely discussed in the literature. Most existing studies use regression models and assume that all factors are linear-additive in contributing to the young adults' driving behaviors. This study relaxes this assumption by applying a non-parametric statistical learning method, namely the gradient boosting decision trees (GBDT). Using U.S. nationwide travel surveys for 2001 and 2017, this study examines the non-linear dose-response effects of lifecycle, socio-demographic and residential factors on daily driving distances of Millennial and Gen-X young adults. Holding all other factors constant, Millennial young adults had shorter predicted daily driving distances than their Gen-X counterparts. Besides, residential and economic factors explain around 50% of young adults' daily driving distances, while the collective contributions for life course events and demographics are about 33%. This study also identifies the density ranges for formulating effective land use policies aiming at reducing automobile travel demand.",
        "DOI": "10.1016/j.cities.2021.103204",
        "affiliation_name": "Cullen College of Engineering",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Combining liquid biopsy and radiomics for personalized treatment of lung cancer patients. State of the art and new perspectives",
        "paper_author": "Cucchiara F.",
        "publication": "Pharmacological Research",
        "citied_by": "17",
        "cover_date": "2021-07-01",
        "Abstract": "Lung cancer has become a paradigm for precision medicine in oncology, and liquid biopsy (LB) together with radiomics may have a great potential in this scenario. They are both minimally invasive, easy to perform, and can be repeated during patient's follow-up. Also, increasing evidence suggest that LB and radiomics may provide an efficient way to screen and diagnose tumors at an early stage, including the monitoring of any change in the tumor molecular profile. This could allow treatment optimization, improvement of patients' quality of life, and healthcare-related costs reduction. Latest reports on lung cancer patients suggest a combination of these two strategies, along with cutting-edge data analysis, to decode valuable information regarding tumor type, aggressiveness, progression, and response to treatment. The approach seems more compatible with clinical practice than the current standard, and provides new diagnostic companions being able to suggest the best treatment strategy compared to conventional methods. To implement radiomics and liquid biopsy directly into clinical practice, an artificial intelligence (AI)-based system could help to link patients' clinical data together with tumor molecular profiles and imaging characteristics. AI could also solve problems and limitations related to LB and radiomics methodologies. Further work is needed, including new health policies and the access to large amounts of high-quality and well-organized data, allowing a complementary and synergistic combination of LB and imaging, to provide an attractive choice e in the personalized treatment of lung cancer.",
        "DOI": "10.1016/j.phrs.2021.105643",
        "affiliation_name": "Azienda Ospedaliero Universitaria Pisana",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Large-scale winter catch crop monitoring with Sentinel-2 time series and machine learning–An alternative to on-site controls?",
        "paper_author": "Schulz C.",
        "publication": "Computers and Electronics in Agriculture",
        "citied_by": "19",
        "cover_date": "2021-07-01",
        "Abstract": "The European legislative guidelines on the Common Agricultural Policy (CAP) lead to an obligation of area-wide information about cross-compliant Greening measures in EU countries. But by on-site controlling, agricultural authorities can monitor only a small portion of all registered parcels. With the Copernicus Programme, the freely available Sentinel-1 and Sentinel-2 imagery increasingly supports remote sensing-based agricultural monitoring on a large-scale. However, most prototypes lack the topic of winter catch cropping. Therefore, we developed a new machine learning method for catch crop monitoring and detection at the parcel-level. To gain training and test data for supervised machine learning, we collected winter catch crop parcel data from different years (2016–2019) and four federal states in Germany. Normalized Difference Vegetation Index (NDVI) time series were calculated for each parcel from Sentinel-2 data within the typical winter catch crop cultivation season (July-April). We revealed distinctive temporal patterns of catch cropping and developed nineteen descriptive features for automatized prediction. Then, we trained fifteen Random Forest classifiers comprising different regions and years and conducted a multi-level validation to identify the model with the highest robustness on new data. The Random Forest classifier trained with the input data from all federal states and years outperformed the other models. It reached a mean prediction accuracy of 84% for both classes (catch crop and non-catch crop) across eleven different spatio-temporal domains. Under optimal annual weather conditions it reached accuracies close to 90%. Anomalies caused by heat waves and early frost events were found to have a high influence on the phenology of catch crops and thus lead to reduced prediction accuracies. From the set of predictors, those features with the highest importance measured the correlation between the observed time series and a simulated NDVI phenological profile. We concluded that catch cropping parcels are automatically separable from parcels with other winter cultivations (e.g., winter cereals, grasslands, fallow) with Sentinel-2 NDVI time series data. Different catch crop subgroups (i.e., seed mixes) could not be differentiated by our approach due to very similar phenological profiles. Nonetheless, the used approach allows for large-scale winter catch crop monitoring and supports authorities in the selection of parcels with high demand for on-site controlling. By merging the training datasets from different federal states and years, we could overcome the typical spatial and temporal overfitting problem in machine learning. Therefore, the study's final classifier can be reliably transferred to new datasets in Germany and other regions with similar bio-geographical conditions.",
        "DOI": "10.1016/j.compag.2021.106173",
        "affiliation_name": "Johann Heinrich von Thünen Institute",
        "affiliation_city": "Braunschweig",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "An artificial intelligent framework for prediction of wildlife vehicle collision hotspots based on geographic information systems and multispectral imagery",
        "paper_author": "González-Vélez J.C.",
        "publication": "Ecological Informatics",
        "citied_by": "8",
        "cover_date": "2021-07-01",
        "Abstract": "Wildlife-vehicle collision - WVC is a phenomenon that arises from the fragmentation of ecosystems by roads, limiting the mobility of individuals and putting at risk the stability of populations by increasing mortality. Colombia is not unaware of the problem of the WVC, evidenced in different scientific publications that describe the WVC in the roads of the country. Although the rise of artificial intelligence has significant advances in the prediction of spatial phenomena in recent years, it has not yet been sufficiently explored by Road Ecology. For this reason, this research aimed to develop a methodology to predict the sites of accumulation of WVC in eastern Antioquia, Colombia, based on artificial intelligence algorithms, geographic information systems - GIS, and multispectral image processing. During the development of this research, it was identified that the features most related to the WVC in the study area are: Distance to Forest, Distance to Biological Corridor, Ground Resistance to Movement, Cost of Movement, the bands of the Landsat 8 satellite: 9, 10, 11 and the normalized burning index (NBRI). Different machine learning algorithms were compared (k-nearest neighbours, support vector machines (SVM), random forests (RF), and artificial neural networks). SMOTE and ADASYN balancing techniques were applied. The results allowed to identify that the RF algorithm with ADASYN yielded the best performance when subjected to spatial-wise cross-validation (AUC-ROC 0.78 ± 0.12), surpassing the results of current state-of-the-art. Finally, the methodology was validated through a transfer learning experiment, training the RF-ADASYN algorithm with three zones of the eastern Antioquia region and validating on a different section (AUC-ROC = 0.87 ± 0.09), retraining the initial model with 5% of data from the validation database.",
        "DOI": "10.1016/j.ecoinf.2021.101291",
        "affiliation_name": "Instituto Tecnológico Metropolitano",
        "affiliation_city": "Medellin",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "InsertionNet - A Scalable Solution for Insertion",
        "paper_author": "Spector O.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "33",
        "cover_date": "2021-07-01",
        "Abstract": "Complicated assembly processes can be described as a sequence of two main activities: grasping and insertion. While general grasping solutions are common in industry, insertion is still only applicable to small subsets of problems, mainly ones involving simple shapes in fixed locations and in which the variations are not taken into consideration. Recently, RL approaches with prior knowledge (e.g., LfD or residual policy) have been adopted. However, these approaches might be problematic in contact-rich tasks since interaction might endanger the robot and its equipment. In this letter, we tackled this challenge by formulating the problem as a regression problem. By combining visual and force inputs, we demonstrate that our method can scale to 16 different insertion tasks in less than 10 minutes. The resulting policies are robust to changes in the socket position, orientation or peg color, as well as to small differences in peg shape. Finally, we demonstrate an end-to-end solution for 2 complex assembly tasks with multi-insertion objectives when the assembly board is randomly placed on a table.",
        "DOI": "10.1109/LRA.2021.3076971",
        "affiliation_name": "Bosch Center for Artificial Intelligence",
        "affiliation_city": "Haifa",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "A performance analysis of prediction techniques for impacting vehicles in hit-and-run road accidents",
        "paper_author": "Jha A.N.",
        "publication": "Accident Analysis and Prevention",
        "citied_by": "32",
        "cover_date": "2021-07-01",
        "Abstract": "Road accidents are globally accepted challenges. They are one of the significant causes of deaths and injuries besides other direct and indirect losses. Countries and international organizations have designed technologies, systems, and policies to prevent accidents. However, hit-and-run accidents remain one of the most dangerous types of road accidents as the information about the vehicle responsible for the accident remain unknown. Therefore, any mechanism which can provide information about the impacting vehicle in hit-and-run accidents will be useful in planning and executing preventive measures to address this road menace. Since there exist several models to predict the impacting unknown vehicle, it becomes important to find which is the most accurate amongst those available. This research applies a process-based approach that identifies the most accurate model out of six supervised learning classification models viz. Logistic Reasoning, Linear Discriminant Analysis, Naïve Bayes, Classification and Regression Trees, k-Nearest Neighbor and Support Vector Machine. These models are implemented using five-fold and ten-fold cross validation, on road accident data collected from five mid-sized Indian cities: Agra, Amritsar, Bhopal, Ludhiana, and Vizag (Vishakhapatnam).This study investigates the possible input factors that may have effect on the performance of applied models. Based on the results of the experiment conducted in this study, Support Vector Machine has been found to have the maximum potentiality to predict unknown impacting vehicle type in hit-and-run accidents for all the cities except Amritsar. The result indicates that, Classification and Regression Trees have maximum accuracy, for Amritsar. Naïve Bayes performed very poorly for the five cities. These recommendations will help in predicting unknown impacting vehicles in hit-and-run accidents. The outcome is useful for transportation authorities and policymakers to implement effective road safety measures for the safety of road users.",
        "DOI": "10.1016/j.aap.2021.106164",
        "affiliation_name": "Indian Institute of Technology Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Liquidity costs on intraday power markets: Continuous trading versus auctions",
        "paper_author": "Kuppelwieser T.",
        "publication": "Energy Policy",
        "citied_by": "5",
        "cover_date": "2021-07-01",
        "Abstract": "We analyze liquidity costs on continuous and auction-based intraday power markets using a cost-of-round-trip measure that works for both market designs. We use data from the Italian auction-based intraday market and the German continuous market and present descriptive statistics as well as multivariate regression models to analyze determinants of liquidity costs in both markets. To test for differences in liquidity due to market design, we employ a double machine learning technique controlling for several confounding variables. We show that weekly patterns, yearly seasonality, electricity demand, as well as the influence of temperatures significantly affect liquidity costs. Comparing liquidity costs in both market, we find that, overall, liquidity costs are lower on the Italian market. However, Italian costs increase towards later auctions, while the costs on the German continuous intraday market decrease and reach their low close to physical delivery, where costs are lower than on the last Italian market trading the corresponding products.",
        "DOI": "10.1016/j.enpol.2021.112299",
        "affiliation_name": "TUM School of Management, Munich",
        "affiliation_city": "Munich",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A deep learning based secured energy management framework within a smart island",
        "paper_author": "Chang Q.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "31",
        "cover_date": "2021-07-01",
        "Abstract": "This study proposes a novel secured management method for renewable microgrids considering the policies required for diagnosing cyber-attacks happening in the communication networks, usually applied in the secondary control layer of microgrids (MGs). Due to the so long stochastic and bad information entering the systems in order to make malicious attacks, their location and time data links have the ability of straying of those acting in normal conditions that attempt to have an effect on the precise voltage regulation and current dividing via influencing sensors of current and voltage. The ability to extract high-level features due to the usage of fast fourier transform (FFT) and deep learning (DL) for attack detection in cyberspace has made them to be considered as a strong technique in the face of small mutations or new attacks. These self-educated and compaction abilities of DL architectures have been considered as basic techniques for hidden scheme detection from the training datum for this reason attacks have been distinguished from benign traffic. A novel method, deep learning and FFT, for cyber-security has been used in the following paper with the aim of enabling the attacks detection in DC smart MG. The deep model and traditional machine learning way are evaluated in terms of performance, and distributed attack detection has been compared to the centralized diagnosing procedure. The tests proved that the distributed attack detection system studied can be more advanced in comparison with centralized detection systems applying FFT in the role of the input index of the DL model. This suggested distributed method enables for scalable monitoring of a MG and has the ability of detecting the existence of cyber-attacks in the communications between distributed generation agents (DGAs) controlled via a control on the basis of consensus and isolating the communication link over that the attack has been injected. Any local attack detection needs restricted information about its neighbor's dynamics. The most important factor of the proposed detection plan can be that has the ability of detecting cyber-attacks with great precision and distinguishing cyber-attack from load changes.in addition, this has been shown that the suggested model can be further useful in the detection of the attack.",
        "DOI": "10.1016/j.scs.2021.102938",
        "affiliation_name": "China University of Petroleum (East China)",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reinforcement learning based process optimization and strategy development in conventional tunneling",
        "paper_author": "Erharter G.H.",
        "publication": "Automation in Construction",
        "citied_by": "24",
        "cover_date": "2021-07-01",
        "Abstract": "Reinforcement learning (RL) - a branch of machine learning - refers to the process of an agent learning to achieve a certain goal by interaction with its environment. The process of conventional tunneling shows many similarities, where a geotechnician (agent) tries to achieve a breakthrough (goal) by excavating the rockmass (environment) in an optimum way. In this paper we present a novel RL based framework for strategy development for conventional tunneling. We developed a virtual environment with the goal of a tunnel breakthrough and with a deep Q-network as the agent's architecture. It can choose from different excavation sequences to reach that goal and learns to do so in an economical and safe way by getting feedback from a specially designed reward system. Result analyses show that the optimal policies have great similarities to current practices of sequential tunneling and the framework has the potential to discover new tunneling strategies.",
        "DOI": "10.1016/j.autcon.2021.103701",
        "affiliation_name": "Technische Universitat Graz",
        "affiliation_city": "Graz",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Design matters: New insights on optimizing energy consumption for residential buildings",
        "paper_author": "Sheng W.",
        "publication": "Energy and Buildings",
        "citied_by": "8",
        "cover_date": "2021-07-01",
        "Abstract": "In this paper, we construct a unique database for 1228 residential buildings in Hong Kong to investigate how the spatial features of these residential buildings affect the electricity consumption in the communal area. We choose Hong Kong for this analysis as the city owns a large number of standard-type residential buildings managed by the public institution, which could be affected strongly by environmental policies. Both the machine learning method, based on the Least Absolute Shrinkage and Selection Operator (LASSO), and econometric regressions are adopted to analyse the data. We first utilize the machine learning LASSO technique to identify the most relevant factors for the subsequent econometric analysis. Our results show that the electricity demand for relatively low consumption building types, such as Twin Tower, is 6% lower than that of the high consumption building types. Newly constructed buildings usually belong to the medium consumption types, with the estimated monthly electricity consumption per apartment in communal areas to be around 50.2 kWh on average in 2020. These findings shed light on the nexus between spatial features and energy use for complex buildings, potentially contributing to the better crafting of energy-saving policy and the improvement of residential building programmes.",
        "DOI": "10.1016/j.enbuild.2021.110976",
        "affiliation_name": "City University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Peeking inside the black-box: Explainable machine learning applied to household transportation energy consumption",
        "paper_author": "Shams Amiri S.",
        "publication": "Computers, Environment and Urban Systems",
        "citied_by": "53",
        "cover_date": "2021-07-01",
        "Abstract": "Sustainability policies to mitigate transportation energy impacts on the urban environment are urgently needed. Energy prediction models provide critical information to decision-makers who develop sustainability policies to reduce energy use and emissions. We present a transportation energy model (TEM) that uses Explainable Artificial Intelligence (XAI) methods to predict household transportation energy consumption in this study. The TEM model uses data-driven approaches for household transportation energy prediction. Machine learning techniques in artificial intelligence (AI) predictive modeling have become popular due to their ability to capture nonlinear and complex relationships. On the other hand, developing comprehensive understanding the inference mechanisms in AI models and ensuring trust in their predictions is challenging. This is because AI models are mostly of high complexity and low interpretability; in other words, they are black-box models. This study presents a case study of how model transparency and explanation can be generated using the Local Interpretable Model-Agnostic Explanation (LIME) to support advanced machine learning techniques in the transportation energy field. The methodology has been implemented based on the Household Travel Survey (HTS) data, which is used to train the artificial neural network with a relatively high degree of accuracy. The importance and effect (local explanation) of HTS inputs (such as household travel, demographics, and neighborhood data) on transportation energy consumption for specific traffic analysis zones (TAZs) are analyzed. The results are valuable to promote intelligent and user-friendly transportation energy planning models in urban regions across the world.",
        "DOI": "10.1016/j.compenvurbsys.2021.101647",
        "affiliation_name": "University of Delaware",
        "affiliation_city": "Newark",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reduced renewable energy stability in India following COVID-19: Insights and key policy recommendations",
        "paper_author": "Shekhar J.",
        "publication": "Renewable and Sustainable Energy Reviews",
        "citied_by": "32",
        "cover_date": "2021-07-01",
        "Abstract": "The COVID-19 pandemic has dramatically altered global energy consumption, particularly affecting investment in renewable energy projects. In India, strict shelter-in-place orders enforced during March 2020 have since led to a considerable change in public and private sector investments in planned renewable energy installations. In this paper, we attempt to highlight trends in energy consumption and installed renewable energy capacity noted in India during a period concurrent with the shelter-in-place orders. We discuss recent policy measures and additions to installed renewable energy capacity, and propose key policy recommendations that may help the sector adopt a growth trajectory similar to one noted pre-pandemic. This paper is organized into four main parts. In the first section, we draw focus to India's renewable energy policies and pay special emphasis on recent interventions and campaigns targeted towards achieving high growth rates in the sector. We briefly discuss the need for effective public-private partnerships in order to meet these targets. In the second part, we quantitatively characterise the growth of renewables in India. We present an overview of several mechanisms and missions the government has launched in line with their policy to mitigate the environmental impact of India's energy mix. In the third part, we analyse the decrease in electricity demand in India from 24 March to 30 June 2020, a period concurrent with shelter-at-home orders issued by the Government. We also characterise changes in installed renewable energy capacity between March to December 2016–2020 to provide causal evidence of the effect of the pandemic on the growth of renewables. In this section, we also compile and analyse data on state-wise stressed assets across renewable energy generators in the country. Lastly, in the fourth and final portion of this paper, we highlight policy recommendations that may help the sector overcome logistical and financial bottlenecks in the short-term. We do this with the hope of outlining key measures that decision makers may employ to achieve pre-COVID sectoral growth in the long term. Our recommendations cover three different policy instruments: investment subsidies, operational subsidies, and recommendations for DISCOMs.",
        "DOI": "10.1016/j.rser.2021.111015",
        "affiliation_name": "Symbiosis School for Liberal Arts",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Planning-augmented hierarchical reinforcement learning",
        "paper_author": "Gieselmann R.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "21",
        "cover_date": "2021-07-01",
        "Abstract": "Planning algorithms are powerful at solving long-horizon decision-making problems but require that environment dynamics are known. Model-free reinforcement learning has recently been merged with graph-based planning to increase the robustness of trained policies in state-space navigation problems. Recent ideas suggest to use planning in order to provide intermediate waypoints guiding the policy in long-horizon tasks. Yet, it is not always practical to describe a problem in the setting of state-to-state navigation. Often, the goal is defined by one or multiple disjoint sets of valid states or implicitly using an abstract task description. Building upon previous efforts, we introduce a novel algorithm called Planning-Augmented Hierarchical Reinforcement Learning (PAHRL) which translates the concept of hybrid planning/RL to such problems with implicitly defined goal. Using a hierarchical framework, we divide the original task, formulated as a Markov Decision Process (MDP), into a hierarchy of shorter horizon MDPs. Actor-critic agents are trained in parallel for each level of the hierarchy. During testing, a planner then determines useful subgoals on a state graph constructed at the bottom level of the hierarchy. The effectiveness of our approach is demonstrated for a set of continuous control problems in simulation including robot arm reaching tasks and the manipulation of a deformable object.",
        "DOI": "10.1109/LRA.2021.3071062",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "A spatially based quantile regression forest model for mapping rural land values",
        "paper_author": "Córdoba M.",
        "publication": "Journal of Environmental Management",
        "citied_by": "21",
        "cover_date": "2021-07-01",
        "Abstract": "Rural land valuation plays an important role in the development of land use policies for agricultural purposes. The advance of computational software and machine learning methods has enhanced mass appraisal methodologies for modeling and predicting economic values. New machine learning methods, like tree-based regression models, have been proposed as an alternative to linear regression to predict economic values from ancillary variables, since these algorithms are able to handle non-normality and non-linearity in the data. However, regression trees are commonly estimated assuming independent rather than spatially correlated data. This study aims to build a tree-based regression model that will help to tackle methodological problems related to the determination of prices of rural lands. The Quantile Regression Forest (QRF) algorithm was used to provide a regression model to predict and assess the uncertainty associated with model-derived predictions. However, the classical QRF ignores the autocorrelation underlying spatialized land values. The objective of this work was to develop, implement, and evaluate a spatial version of QRF, named sQRF, for computer-assisted mass appraisal of rural land values accounting for information from neighboring sites. We compared predictions of land values from sQRF with those obtained from spatial random forest, kriging regression, and linear regression models. sQRF performed well in predicting rural land values; indeed, it performed better than multiple linear regression. An important feature of sQRF is its ability to produce a direct uncertainty measure to assess the goodness of the predictions. Land values reﬂect a complex mix of agricultural returns, localization, and access to markets, which can be predicted from ancillary environmental variables. Good predictive models are essential to determine land values for multiple purposes including territorial taxation.",
        "DOI": "10.1016/j.jenvman.2021.112509",
        "affiliation_name": "Consejo Nacional de Investigaciones Científicas y Técnicas",
        "affiliation_city": "Buenos Aires",
        "affiliation_country": "Argentina"
    },
    {
        "paper_title": "IHG-MA: Inductive heterogeneous graph multi-agent reinforcement learning for multi-intersection traffic signal control",
        "paper_author": "Yang S.",
        "publication": "Neural Networks",
        "citied_by": "45",
        "cover_date": "2021-07-01",
        "Abstract": "Multi-agent deep reinforcement learning (MDRL) has been widely applied in multi-intersection traffic signal control. The MDRL algorithms produce the decentralized cooperative traffic-signal policies via specialized multi-agent settings in certain traffic networks. However, the state-of-the-art MDRL algorithms seem to have some drawbacks. (1) It is desirable that the traffic-signal policies can be smoothly transferred to diverse traffic networks, however, the adopted specialized multi-agent settings hinder the traffic-signal policies to transfer and generalize to new traffic networks. (2) Existing MDRL algorithms which are based on deep neural networks cannot flexibly tackle a time-varying number of vehicles traversing the traffic networks. (3) Existing MDRL algorithms which are based on homogeneous graph neural networks fail to capture the heterogeneous features of objects in traffic networks. Motivated by the above observations, in this paper, we propose an algorithm, referred to as Inductive Heterogeneous Graph Multi-agent Actor–critic (IHG-MA) algorithm, for multi-intersection traffic signal control. The proposed IHG-MA algorithm has two features: (1) It conducts representation learning using a proposed inductive heterogeneous graph neural network (IHG), which is an inductive algorithm. The proposed IHG algorithm can generate embeddings for previously unseen nodes (e.g., new entry vehicles) and new graphs (e.g., new traffic networks). But unlike the algorithms based on the homogeneous graph neural network, IHG algorithm not only encodes heterogeneous features of each node, but also encodes heterogeneous structural (graph) information. (2) It also conducts policy learning using a proposed multi-agent actor–critic(MA), which is a decentralized cooperative framework. The proposed MA framework employs the final embeddings to compute the Q-value and policy, and then optimizes the whole algorithm via the Q-value and policy loss. Experimental results on different traffic datasets illustrate that IHG-MA algorithm outperforms the state-of-the-art algorithms in terms of multiple traffic metrics, which seems to be a new promising algorithm for multi-intersection traffic signal control.",
        "DOI": "10.1016/j.neunet.2021.03.015",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Planning with Learned Dynamics: Probabilistic Guarantees on Safety and Reachability via Lipschitz Constants",
        "paper_author": "Knuth C.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "24",
        "cover_date": "2021-07-01",
        "Abstract": "We present a method for feedback motion planning of systems with unknown dynamics which provides probabilistic guarantees on safety, reachability, and goal stability. To find a domain in which a learned control-affine approximation of the true dynamics can be trusted, we estimate the Lipschitz constant of the difference between the true and learned dynamics, and ensure the estimate is valid with a given probability. Provided the system has at least as many controls as states, we also derive existence conditions for a one-step feedback law which can keep the real system within a small bound of a nominal trajectory planned with the learned dynamics. Our method imposes the feedback law existence as a constraint in a sampling-based planner, which returns a feedback policy around a nominal plan ensuring that, if the Lipschitz constant estimate is valid, the true system is safe during plan execution, reaches the goal, and is ultimately invariant in a small set about the goal. We demonstrate our approach by planning using learned models of a 6D quadrotor and a 7DOF Kuka arm. We show that a baseline which plans using the same learned dynamics without considering the error bound or the existence of the feedback law can fail to stabilize around the plan and become unsafe.",
        "DOI": "10.1109/LRA.2021.3068889",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The impact of COVID-19 on the electricity demand: a case study for Turkey",
        "paper_author": "Ceylan Z.",
        "publication": "International Journal of Energy Research",
        "citied_by": "35",
        "cover_date": "2021-07-01",
        "Abstract": "Due to the extraordinary impact of the Coronavirus Disease 2019 (COVID-19) and the resulting lockdown measures, the demand for energy in business and industry has dropped significantly. This change in demand makes it difficult to manage energy generation, especially electricity production and delivery. Thus, reliable models are needed to continue safe, secure, and reliable power. An accurate forecast of electricity demand is essential for making a reliable decision in strategic planning and investments in the future. This study presents the extensive effects of COVID-19 on the electricity sector and aims to predict electricity demand accurately during the lockdown period in Turkey. For this purpose, well-known machine learning algorithms such as Gaussian process regression (GPR), sequential minimal optimization regression (SMOReg), correlated Nyström views (XNV), linear regression (LR), reduced error pruning tree (REPTree), and M5P model tree (M5P) were used. The SMOReg algorithm performed best with the lowest mean absolute percentage error (3.6851%), mean absolute error (21.9590), root mean square error (29.7358), and root relative squared error (36.5556%) values in the test dataset. This study can help policy-makers develop appropriate policies to control the harms of not only the current pandemic crisis but also an unforeseeable crisis.",
        "DOI": "10.1002/er.6631",
        "affiliation_name": "Samsun University",
        "affiliation_city": "Samsun",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Integrating remote sensing and machine learning into environmental monitoring and assessment of land use change",
        "paper_author": "Nguyen H.A.T.",
        "publication": "Sustainable Production and Consumption",
        "citied_by": "28",
        "cover_date": "2021-07-01",
        "Abstract": "Addressing the increasing burden on land use requires effective policy for sustainable land use along with economic development. Analysis of local and global indicators based on land use maps could reveal information on the progress of sustainable development. This study proposes a method that reduces the time and cost of creating land use maps applicable for many purposes of environmental protection. Freely accessible existing data, Sentinel-2 satellite images, together with a machine learning algorithm, Random Forest, are integrated to generate an annual map, sufficient to meet the intended needs. The method is illustrated by a case study of Phuket in Thailand. An annual map for Phuket created using the proposed method was compared to the official map released by the Thai government for the year 2018. The two maps did not differ significantly, validating the efficacy of the proposed method. Annual maps were then produced for several years to assess the effect of land use change in the past 19 years on the environmental and sustainable management in Phuket. Although there was evidence of the efforts to develop Phuket island as a sustainable province such as the government policy to conserve green areas, land use change based analytical results indicated Phuket's urban development was not going in an environmentally sustainable direction.",
        "DOI": "10.1016/j.spc.2021.02.025",
        "affiliation_name": "Mahidol University",
        "affiliation_city": "Nakhon Pathom",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Learning to Be Proactive: Self-Regulation of UAV Based Networks with UAV and User Dynamics",
        "paper_author": "Zhang R.",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "24",
        "cover_date": "2021-07-01",
        "Abstract": "Multi-Unmanned Aerial Vehicle (UAV) control is one of the major research interests in UAV-based networks. Yet few existing works focus on how the network should optimally react when the UAV lineup and user distribution change. In this work, proactive self-regulation (PSR) of UAV-based networks is investigated when one or more UAVs are about to quit or join the network, with considering dynamic user distribution. We target at an optimal UAV trajectory control policy which proactively relocates the UAVs whenever the UAV lineup is about to change, rather than passively dispatches the UAVs after the change. Specifically, a deep reinforcement learning (DRL)-based self-regulation approach is developed to maximize the accumulated user satisfaction (US) score for a certain period within which at least one UAV will quit or join the network. To handle the changed dimension of the state-action space before and after the lineup changes, the state transition is deliberately designed. To accommodate continuous state and action space, an actor-critic based DRL, i.e., deep deterministic policy gradient (DDPG), is applied with better convergence stability. To effectively promote learning exploration around the timing of lineup change, an asynchronous parallel computing (APC) learning structure is proposed. Referred to as PSR-APC, the developed approach is then extended to the case of dynamic user distribution by incorporating time as one of the agent states. Finally, numerical results are presented to demonstrate the convergence and superiority of PSR-APC over a passive reaction method, and its capability in jointly handling the dynamics of both UAV lineup and user distribution.",
        "DOI": "10.1109/TWC.2021.3058533",
        "affiliation_name": "Armour College of Engineering",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Fine-grained assessment of greenspace satisfaction at regional scale using content analysis of social media and machine learning",
        "paper_author": "Wang Z.",
        "publication": "Science of the Total Environment",
        "citied_by": "56",
        "cover_date": "2021-07-01",
        "Abstract": "Assessing perceptions of green spaces is of considerable interest to developers aiming for sustainable urbanization. However, there are numerous challenges facing the development of a rapid, effective, and fine-grained method to assess large-scale greenspace perception. Survey-based studies of perception yielded detailed assessments of green spaces but lacked regional comparisons. The few big-data-based studies of greenspace perception lacked fine-grained explorations. Therefore, we used content analysis to interpret perception in two ways: perceived frequency and perceived satisfaction, including overall park satisfaction and satisfaction with individual landscape features. We analyzed social media posts about urban parks in Beijing, China. A structured lexicon was developed to capture detailed landscape features, and machine learning was employed to assess satisfaction levels. Both of these techniques performed well in interpreting greenspace satisfaction from volunteered textual comments. A detailed study of 50 parks demonstrated that overall park satisfaction was positive. Additionally, individual landscape features were more influential than frequency of landscape features in affecting satisfaction. Our framework confirmed the potential of online comments as complementary to traditional surveys in assessing greenspace perception, while enhancing our understanding of this perception on a regional scale. Practically, this study can facilitate sustainable policy-making regarding urban green spaces, specifically through offering a structured landscape-feature lexicon, rapid regional comparison of various parks, and an emphasis on quality rather than quantity of landscape features.",
        "DOI": "10.1016/j.scitotenv.2021.145908",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "On kernel machine learning for propensity score estimation under complex confounding structures",
        "paper_author": "Zou B.",
        "publication": "Pharmaceutical Statistics",
        "citied_by": "2",
        "cover_date": "2021-07-01",
        "Abstract": "Post marketing data offer rich information and cost-effective resources for physicians and policy-makers to address some critical scientific questions in clinical practice. However, the complex confounding structures (e.g., nonlinear and nonadditive interactions) embedded in these observational data often pose major analytical challenges for proper analysis to draw valid conclusions. Furthermore, often made available as electronic health records (EHRs), these data are usually massive with hundreds of thousands observational records, which introduce additional computational challenges. In this paper, for comparative effectiveness analysis, we propose a statistically robust yet computationally efficient propensity score (PS) approach to adjust for the complex confounding structures. Specifically, we propose a kernel-based machine learning method for flexibly and robustly PS modeling to obtain valid PS estimation from observational data with complex confounding structures. The estimated propensity score is then used in the second stage analysis to obtain the consistent average treatment effect estimate. An empirical variance estimator based on the bootstrap is adopted. A split-and-merge algorithm is further developed to reduce the computational workload of the proposed method for big data, and to obtain a valid variance estimator of the average treatment effect estimate as a by-product. As shown by extensive numerical studies and an application to postoperative pain EHR data comparative effectiveness analysis, the proposed approach consistently outperforms other competing methods, demonstrating its practical utility.",
        "DOI": "10.1002/pst.2105",
        "affiliation_name": "UNC Gillings School of Global Public Health",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Bullying discourse on Twitter: An examination of bully-related tweets using supervised machine learning",
        "paper_author": "Dhungana Sainju K.",
        "publication": "Computers in Human Behavior",
        "citied_by": "14",
        "cover_date": "2021-07-01",
        "Abstract": "Prior research shows that combining social science with big data can advance our understanding of key social issues like bullying. The current study examines the sharing and disclosure of bullying experiences through the use of Twitter data by including keywords that capture both face-to-face and cyberbullying experiences. Using human coded tweets and supervised machine learning, the study considers the role of the author in bullying-related tweets, identifies different types of bullying, analyzes why someone would share a bullying episode on Twitter, and examines the temporal patterns of bullying-related tweets. The study analyzed 847,548 tweets collected between August 7, 2019, and March 31, 2020. The results revealed that most of the tweets were shared from the perspective of the victim, included both general and online bullying, and the most common reason for posting was to report or to self-disclose. Bullying-related tweets were significantly longer than the average tweet and high profile incidents prompted an increase in posts. The results suggest that while Twitter may be a venue for bullying, it is also a space where users can find cathartic discussion and support. This study highlights ways that researchers, educators, and policymakers can utilize Twitter as a medium for positive change and harness machine learning to inform policy and anti-bullying initiatives.",
        "DOI": "10.1016/j.chb.2021.106735",
        "affiliation_name": "Rotman School of Management",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Leveraging task modularity in reinforcement learning for adaptable industry 4.0 automation",
        "paper_author": "Chen Q.",
        "publication": "Journal of Mechanical Design",
        "citied_by": "22",
        "cover_date": "2021-07-01",
        "Abstract": "The vision of Industry 4.0 is to materialize the notion of a lot-size of one through enhanced adaptability and resilience of manufacturing and logistics operations to dynamic changes or deviations on the shop floor. This article is motivated by the lack of formal methods for efficient transfer of knowledge across different yet interrelated tasks, with special reference to collaborative robotic operations such as material handling, machine tending, assembly, and inspection. We propose a meta reinforcement learning framework to enhance the adaptability of collaborative robots to new tasks through task modularization and efficient transfer of policies from previously learned task modules. Our experiments on the OpenAI Gym Robotics environments Reach, Push, and Pick-and-Place indicate an average 75% reduction in the number of iterations to achieve a 60% success rate as well as a 50%-80% improvement in task completion efficiency, compared to the deep deterministic policy gradient (DDPG) algorithm as a baseline. The significant improvements achieved in the jumpstart and asymptotic performance of the robot create new opportunities for investigating the current limitations of learning robots in industrial settings, associated with sample inefficiency and specialization on one task through modularization and transfer learning.",
        "DOI": "10.1115/1.4049531",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Professionalization of online gaming? Theoretical and empirical analysis for a monopoly-holding platform",
        "paper_author": "Ribeiro V.M.",
        "publication": "Journal of Theoretical and Applied Electronic Commerce Research",
        "citied_by": "4",
        "cover_date": "2021-07-01",
        "Abstract": "We analyze the private equilibrium of a two-sided market representing the online gaming industry under a principal-agent model. A monopoly-holding platform hires a manager to attract new members from both sides of the market while considering uncertainty on the adhesion of viewers and online gamers. First, we mathematically demonstrate that increasing cross-group network externalities can decrease the platform’s profit, which contradicts a canonical result from the field of two-sided markets. Moreover, knowing that the intermediary’s goal is aligned with the private interest of online gamers, machine learning models empirically show that the main theoretical outcome is observed in reality due to the presence of heterogeneous indirect network effects in online gaming activities. Second, we conclude that social welfare can be either harmed or improved for increasing cross-group network externalities, which means that the professionalization of online gaming may or may not be legitimized depending on the value taken by exogenous parameters related to the platform’s uncertainty on the number of agents that get on board, risk aversion of viewers, and royalty rate applied to online gamers. Finally, a discussion based on 2020 facts is provided and several policy recommendations are formulated to ensure the persistence of best regulatory practices.",
        "DOI": "10.3390/jtaer16040040",
        "affiliation_name": "Huaiyin Teachers University",
        "affiliation_city": "Huainan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sustainable development scale of housing estates: An economic assessment using machine learning approach",
        "paper_author": "Tang B.s.",
        "publication": "Sustainable Development",
        "citied_by": "6",
        "cover_date": "2021-07-01",
        "Abstract": "Economic sustainability is often addressed from the perspective of economic growth and at the national level. In contrast, this research attempts to examine the question of economic sustainability of human settlement at a local project level. Urban planners need to strike a balance between dispersal and over-concentration of population in cities. The existing theories suggest that either excessively low or extremely high levels of household concentration is undesirable to a neighborhood. In this study, an economic assessment using machine learning (ML) techniques is used to identify the threshold scale of a housing estate, which comprises many privately owned residential units (like condos) with shared amenities. Using two decades of property transaction data in Hong Kong as our evidence, this study has found that a tipping point exists in the development scale of these housing estates. Housing values initially rise with the number of residential units in a housing estate but gradually fall when it increases beyond a critical limit. This nonlinear economic relationship is attributed to the per household share of common facilities, which does not increase sufficiently to match with the growing population density of the housing estates. The policy implication is that, to optimize housing supply, urban planning should not just focus on increasing the development bulk of housing but should also pay attention to the possible bottlenecks in the provision of shared amenities in the neighborhood.",
        "DOI": "10.1002/sd.2168",
        "affiliation_name": "The Hong Kong Polytechnic University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Reinforcement learning in surgery",
        "paper_author": "Datta S.",
        "publication": "Surgery (United States)",
        "citied_by": "26",
        "cover_date": "2021-07-01",
        "Abstract": "Patients and physicians make essential decisions regarding diagnostic and therapeutic interventions. These actions should be performed or deferred under time constraints and uncertainty regarding patients’ diagnoses and predicted response to treatment. This may lead to cognitive and judgment errors. Reinforcement learning is a subfield of machine learning that identifies a sequence of actions to increase the probability of achieving a predetermined goal. Reinforcement learning has the potential to assist in surgical decision making by recommending actions at predefined intervals and its ability to utilize complex input data, including text, image, and temporal data, in the decision-making process. The algorithm mimics a human trial-and-error learning process to calculate optimum recommendation policies. The article provides insight regarding challenges in the development and application of reinforcement learning in the medical field, with an emphasis on surgical decision making. The review focuses on challenges in formulating reward function describing the ultimate goal and determination of patient states derived from electronic health records, along with the lack of resources to simulate the potential benefits of suggested actions in response to changing physiological states during and after surgery. Although clinical implementation would require secure, interoperable, livestreaming electronic health record data for use by virtual model, development and validation of personalized reinforcement learning models in surgery can contribute to improving care by helping patients and clinicians make better decisions.",
        "DOI": "10.1016/j.surg.2020.11.040",
        "affiliation_name": "Herbert Wertheim College of Engineering",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Empowered Trajectory and Passive Beamforming Design in UAV-RIS Wireless Networks",
        "paper_author": "Liu X.",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "202",
        "cover_date": "2021-07-01",
        "Abstract": "A novel framework is proposed for integrating reconfigurable intelligent surfaces (RIS) in unmanned aerial vehicle (UAV) enabled wireless networks, where an RIS is deployed for enhancing the service quality of the UAV. Non-orthogonal multiple access (NOMA) technique is invoked to further improve the spectrum efficiency of the network, while mobile users (MUs) are considered as roaming continuously. The energy consumption minimizing problem is formulated by jointly designing the movement of the UAV, phase shifts of the RIS, power allocation policy from the UAV to MUs, as well as determining the dynamic decoding order. A decaying deep Q-network (D-DQN) based algorithm is proposed for tackling this pertinent problem. In the proposed D-DQN based algorithm, the central controller is selected as an agent for periodically observing the state of UAV-enabled wireless network and for carrying out actions to adapt to the dynamic environment. In contrast to the conventional DQN algorithm, the decaying learning rate is leveraged in the proposed D-DQN based algorithm for attaining a tradeoff between accelerating training speed and converging to the local optimal. Numerical results demonstrate that: 1) In contrast to the conventional Q-learning algorithm, which cannot converge when being adopted for solving the formulated problem, the proposed D-DQN based algorithm is capable of converging with minor constraints; 2) The energy dissipation of the UAV can be significantly reduced by integrating RISs in UAV-enabled wireless networks; 3) By designing the dynamic decoding order and power allocation policy, the RIS-NOMA case consumes 11.7% less energy than the RIS-OMA case.",
        "DOI": "10.1109/JSAC.2020.3041401",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A spatial machine learning model for analysing customers' lapse behaviour in life insurance",
        "paper_author": "Hu S.",
        "publication": "Annals of Actuarial Science",
        "citied_by": "15",
        "cover_date": "2021-07-01",
        "Abstract": "Spatial analysis ranges from simple univariate descriptive statistics to complex multivariate analyses and is typically used to investigate spatial patterns or to identify spatially linked consumer behaviours in insurance. This paper investigates if the incorporation of publicly available spatially linked demographic census data at population level is useful in modelling customers' lapse behaviour (i.e. stopping payment of premiums) in life insurance policies, based on data provided by an insurance company in Ireland. From the insurance company's perspective, identifying and assessing such lapsing risks in advance permit engagement to prevent such incidents, saving money by re-evaluating customer acquisition channels and improving capital reserve calculation and preparation. Incorporating spatial analysis in lapse modelling is expected to improve lapse prediction. Therefore, a hybrid approach to lapse prediction is proposed - spatial clustering using census data is used to reveal the underlying spatial structure of customers of the Irish life insurer, in conjunction with traditional statistical models for lapse prediction based on the company data. The primary contribution of this work is to consider the spatial characteristics of customers for life insurance lapse behaviour, via the integration of reliable government provided census demographics, which has not been considered previously in actuarial literature. Company decision-makers can use the insights gleaned from this analysis to identify customer subsets to target with personalized promotions to reduce lapse rates, and to reduce overall company risk.",
        "DOI": "10.1017/S1748499520000329",
        "affiliation_name": "University of Limerick",
        "affiliation_city": "Limerick",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Challenges and opportunities for using national animal datasets to support foot-and-mouth disease control",
        "paper_author": "van Andel M.",
        "publication": "Transboundary and Emerging Diseases",
        "citied_by": "9",
        "cover_date": "2021-07-01",
        "Abstract": "National level databases of animal numbers, locations and movements provide the essential foundations for disease preparedness, outbreak investigations and control activities. These activities are particularly important for managing and mitigating the risks of high-impact transboundary animal disease outbreaks such as foot-and-mouth disease (FMD), which can significantly affect international trade access and domestic food security. In countries where livestock production systems are heavily subsidized by the government, producers are often required to provide detailed animal movement and demographic data as a condition of business. In the remaining countries, it can be difficult to maintain these types of databases and impossible to estimate the extent of missing or inaccurate information due to the absence of gold standard datasets for comparison. Consequently, competent authorities are often required to make decisions about disease preparedness and control based on available data, which may result in suboptimal outcomes for their livestock industries. It is important to understand the limitations of poor data quality as well as the range of methods that have been developed to compensate in both disease-free and endemic situations. Using FMD as a case example, this review first discusses the different activities that competent authorities use farm-level animal population data for to support (1) preparedness activities in disease-free countries, (2) response activities during an acute outbreak in a disease-free country, and (3) eradication and control activities in an endemic country. We then discuss (4) data requirements needed to support epidemiological investigations, surveillance, and disease spread modelling both in disease-free and endemic countries.",
        "DOI": "10.1111/tbed.13858",
        "affiliation_name": "Ministry for Primary Industries",
        "affiliation_city": "Wellington",
        "affiliation_country": "New Zealand"
    },
    {
        "paper_title": "Human-in-the-Loop Low-Shot Learning",
        "paper_author": "Wan S.",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "9",
        "cover_date": "2021-07-01",
        "Abstract": "We consider a human-in-the-loop scenario in the context of low-shot learning. Our approach was inspired by the fact that the viability of samples in novel categories cannot be sufficiently reflected by those limited observations. Some heterogeneous samples that are quite different from existing labeled novel data can inevitably emerge in the testing phase. To this end, we consider augmenting an uncertainty assessment module into low-shot learning system to account into the disturbance of those out-of-distribution (OOD) samples. Once detected, these OOD samples are passed to human beings for active labeling. Due to the discrete nature of this uncertainty assessment process, the whole Human-In-the-Loop Low-shot (HILL) learning framework is not end-to-end trainable. We hence revisited the learning system from the aspect of reinforcement learning and introduced the REINFORCE algorithm to optimize model parameters via policy gradient. The whole system gains noticeable improvements over existing low-shot learning approaches.",
        "DOI": "10.1109/TNNLS.2020.3011559",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting irregularities in arrival times for transit buses with recurrent neural networks using GPS coordinates and weather data",
        "paper_author": "Alam O.",
        "publication": "Journal of Ambient Intelligence and Humanized Computing",
        "citied_by": "24",
        "cover_date": "2021-07-01",
        "Abstract": "Intelligent transportation systems (ITS) play an important role in the quality of life of citizens in any metropolitan city. Despite various policies and strategies incorporated to increase the reliability and quality of service, public transportation authorities continue to face criticism from commuters largely due to irregularities in bus arrival times, most notably manifested in early or late arrivals. Due to these irregularities, commuters may miss important appointments, wait for too long at the bus stop, or arrive late for work. Therefore, accurate prediction models are needed to build better customer service solutions for transit systems, e.g. building accurate mobile apps for trip planning or sending bus delay/cancel notifications. Prediction models will also help in developing better appointment scheduling systems for doctors, dentists, and other businesses to take into account transit bus delays for their clients. In this paper, we seek to predict the occurrence of arrival time irregularities by mining GPS coordinates of transit buses provided by the Toronto Transit Commission (TTC) along with hourly weather data and using this data in machine learning models that we have developed. In our study, we compared the performance of a Long Short Term Memory Recurrent Neural Network (LSTM) model against four baseline models, an Artificial Neural Network (ANN), Support Vector Regression (SVR), Autoregressive Integrated Moving Average (ARIMA) and historical averages. We found that our LSTM model demonstrates the best prediction accuracy. The improved accuracy achieved by the LSTM model may lend itself to its ability to adjust and update the weights of neurons while accounting for long-term dependencies. In addition, we found that weather conditions play a significant role in improving the accuracy of our models. Therefore, we built a prediction model that combines an LSTM model with a Recurrent Neural Network Model (RNN) that focuses on the weather condition. Our findings also reveal that in nearly 37% of scheduled arrival times, buses either arrive early or late by a margin of more than 5 min, suggesting room for improvement in the current strategies employed by transit authorities.",
        "DOI": "10.1007/s12652-020-02507-9",
        "affiliation_name": "Trent University",
        "affiliation_city": "Peterborough",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Constrained cross-entropy method for safe reinforcement learning",
        "paper_author": "Wen M.",
        "publication": "IEEE Transactions on Automatic Control",
        "citied_by": "12",
        "cover_date": "2021-07-01",
        "Abstract": "We study a safe reinforcement learning problem, in which the constraints are defined as the expected cost over finite-length trajectories. We propose a constrained cross-entropy-based method to solve this problem. The key idea is to transform the original constrained optimization problem into an unconstrained one with a surrogate objective. The method explicitly tracks its performance with respect to constraint satisfaction and thus is well suited for safety-critical applications. We show that the asymptotic behavior of the proposed algorithm can be almost-surely described by that of an ordinary differential equation. Then, we give sufficient conditions on the properties of this differential equation for the convergence of the proposed algorithm. At last, we show the performance of the proposed algorithm in two simulation examples. In a constrained linear-quadratic regulator example, we observe that the algorithm converges to the global optimum with high probability. In a 2-D navigation example, we find that the algorithm effectively learns feasible policies without assumptions on the feasibility of initial policies, even with non-Markovian objective functions and constraint functions.",
        "DOI": "10.1109/TAC.2020.3015931",
        "affiliation_name": "Cockrell School of Engineering",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reinforcement learning-based bird-view automated vehicle control to avoid crossing traffic",
        "paper_author": "Wang Y.",
        "publication": "Computer-Aided Civil and Infrastructure Engineering",
        "citied_by": "32",
        "cover_date": "2021-07-01",
        "Abstract": "This paper presents an innovative bird-view control framework for connected automated vehicles (CAV). Most recently tested automated vehicles are based on sensing systems equipped on the car body, which require the self-driving policy to be robust and adaptive to various environmental uncertainties. Inspired by the vehicle to infrastructure technologies, the self-driving technology can also be achieved through the communication between road infrastructure and the vehicle, where sensors are mainly installed on the road in a high position, which can collect traffic information from a bird-view. To this end, we developed a fusion-based Q-learning method to yield an optimal bird-view control policy for a CAV on a multi-lane road. With our control policy, the CAV can drive smartly under complicated traffic environment, interacting with leading vehicles and crossing traffic simultaneously. A series of case studies show our CAV control policy is string stable and can avoid collisions under various scenarios.",
        "DOI": "10.1111/mice.12572",
        "affiliation_name": "UW-Madison College of Engineering",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning in space and time for modelling soil organic carbon change",
        "paper_author": "Heuvelink G.B.M.",
        "publication": "European Journal of Soil Science",
        "citied_by": "99",
        "cover_date": "2021-07-01",
        "Abstract": "Spatially resolved estimates of change in soil organic carbon (SOC) stocks are necessary for supporting national and international policies aimed at achieving land degradation neutrality and climate change mitigation. In this work we report on the development, implementation and application of a data-driven, statistical method for mapping SOC stocks in space and time, using Argentina as a pilot. We used quantile regression forest machine learning to predict annual SOC stock at 0–30 cm depth at 250 m resolution for Argentina between 1982 and 2017. The model was calibrated using over 5,000 SOC stock values from the 36-year time period and 35 environmental covariates. We preprocessed normalized difference vegetation index (NDVI) dynamic covariates using a temporal low-pass filter to allow the SOC stock for a given year to depend on the NDVI of the current as well as preceding years. Predictions had modest temporal variation, with an average decrease for the entire country from 2.55 to 2.48 kg C m−2 over the 36-year period (equivalent to a decline of 211 Gg C, 3.0% of the total 0–30 cm SOC stock in Argentina). The Pampa region had a larger estimated SOC stock decrease from 4.62 to 4.34 kg C m−2 (5.9%) during the same period. For the 2001–2015 period, predicted temporal variation was seven-fold larger than that obtained using the Tier 1 approach of the Intergovernmental Panel on Climate Change and United Nations Convention to Combat Desertification. Prediction uncertainties turned out to be substantial, mainly due to the limited number and poor spatial and temporal distribution of the calibration data, and the limited explanatory power of the covariates. Cross-validation confirmed that SOC stock prediction accuracy was limited, with a mean error of 0.03 kg C m−2 and a root mean squared error of 2.04 kg C m−2. In spite of the large uncertainties, this work showed that machine learning methods can be used for space–time SOC mapping and may yield valuable information to land managers and policymakers, provided that SOC observation density in space and time is sufficiently large. Highlights: We tested the use of machine learning for space–time mapping of soil organic carbon (SOC) stock. Predictions for Argentina from 1982 to 2017 showed a 3% decrease of the topsoil SOC stock over time. The machine learning model predicted a greater temporal variation than the IPCC Tier 1 approach. Accurate machine learning SOC stock prediction requires dense soil sampling in space and time.",
        "DOI": "10.1111/ejss.12998",
        "affiliation_name": "Woods Hole Research Center",
        "affiliation_city": "Falmouth",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Teaching for Human Inverse Reinforcement Learning",
        "paper_author": "Lee M.S.",
        "publication": "Frontiers in Robotics and AI",
        "citied_by": "11",
        "cover_date": "2021-06-30",
        "Abstract": "As robots continue to acquire useful skills, their ability to teach their expertise will provide humans the two-fold benefit of learning from robots and collaborating fluently with them. For example, robot tutors could teach handwriting to individual students and delivery robots could convey their navigation conventions to better coordinate with nearby human workers. Because humans naturally communicate their behaviors through selective demonstrations, and comprehend others’ through reasoning that resembles inverse reinforcement learning (IRL), we propose a method of teaching humans based on demonstrations that are informative for IRL. But unlike prior work that optimizes solely for IRL, this paper incorporates various human teaching strategies (e.g. scaffolding, simplicity, pattern discovery, and testing) to better accommodate human learners. We assess our method with user studies and find that our measure of test difficulty corresponds well with human performance and confidence, and also find that favoring simplicity and pattern discovery increases human performance on difficult tests. However, we did not find a strong effect for our method of scaffolding, revealing shortcomings that indicate clear directions for future work.",
        "DOI": "10.3389/frobt.2021.693050",
        "affiliation_name": "The Robotics Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Exploiting Multilingual Neural Linguistic Representation for Sentiment Classification of Political Tweets in Code-mix Language",
        "paper_author": "Kannan R.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "2",
        "cover_date": "2021-06-29",
        "Abstract": "Social media is more and more utilized by people around the world to express their feelings and opinions in the kind of short text messages. Twitter has been a rapidly growing microblogging social networking website where people express their opinions in a precise and simple manner of expressions. It has also become a platform for governmental, non-governmental and individual opinions and policy announcements. Detecting sentiments from tweets has a wide range of applications including identifying the anxiety or depression of individuals and measuring the well-being or mood of a community. In addition, the sentiment classification becomes complex when the tweet is written in codemix language which is a mix of two different languages. The main objective of this paper is to classify tweets written in mix of Tamil and English language into positive, negative, or neutral. This is achieved by fine tuning a pretrained multilingual text representation model as well as deep learning transformers. The proposed approach is experimented with large scale of tweets collected for societal issues in India. We also provide a comparative study of different machine learning and deep learning models. The proposed architecture based on neural linguistic representation provides significant accuracy in classifying both Tamil and codemix tweets.",
        "DOI": "10.1145/3468784.3470787",
        "affiliation_name": "Bishop Heber College, Tiruchirappalli",
        "affiliation_city": "Tiruchirappalli",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Multi-agent Reinforcement Learning Approaches to RF Fingerprint Enhancement",
        "paper_author": "Carmack J.",
        "publication": "WiseML 2021 - Proceedings of the 3rd ACM Workshop on Wireless Security and Machine Learning",
        "citied_by": "3",
        "cover_date": "2021-06-28",
        "Abstract": "Deep learning based RF Fingerprinting has shown great promise for IoT device security. This work explores various multi-agent reinforcement learning approaches to enable RF Fingerprint enhancement for an ensemble of transmitters. A RiftNet™ Reconstruction Model (RRM) is used to learn a latent Wi-Fi signal representation and how to reconstruct from that latent representation at the transmitter such that the reconstruction uniquely excites parts of the front-end to enhance the fingerprint. Deep reinforcement learning is then employed to learn the RRM control policy. Details on the design of the control interface, state representation, and rewards structure are presented for four different policy approaches. The resulting computational and security characteristics are discussed..",
        "DOI": "10.1145/3468218.3469037",
        "affiliation_name": "BAE Systems plc",
        "affiliation_city": "Farnborough",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Proceedings of the 2021 IEEE Conference on Network Softwarization: Accelerating Network Softwarization in the Cognitive Age, NetSoft 2021",
        "paper_author": "NA",
        "publication": "Proceedings of the 2021 IEEE Conference on Network Softwarization: Accelerating Network Softwarization in the Cognitive Age, NetSoft 2021",
        "citied_by": "0",
        "cover_date": "2021-06-28",
        "Abstract": "The proceedings contain 74 papers. The topics discussed include: mitigating evasion attacks on machine learning based NIDS systems in SDN; elastic slicing in programmable networks; providing in-network support to coflow scheduling; revisiting heavy-hitter detection on commodity programmable switches; Alviu: an intent-based SD-WAN orchestrator of network slices for enterprise networks; tenant-oriented resource optimization for cloud network slicing with performance guarantees; a dynamic recommendation-based trust scheme for the smart grid; leveraging the 5G architecture to mitigate amplification attacks; on slice isolation options in the transport network and associated feasibility indicators; design and manufacture of narrow-band BPF for local 5G network slicing; and mind the semantic gap: policy intent inference from network metadata.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A Distributed Consensus Protocol for Sustainable Federated Learning",
        "paper_author": "Alfauri H.",
        "publication": "Proceedings of the 2021 IEEE Conference on Network Softwarization: Accelerating Network Softwarization in the Cognitive Age, NetSoft 2021",
        "citied_by": "1",
        "cover_date": "2021-06-28",
        "Abstract": "The most significant challenge of our time is global warming, it impacts every area of our lives. This study was motivated by the observation that to train Artificial Intelligence and Machine learning (AI/ML) algorithms result in staggering carbon footprints. Moreover, centralized implementations are becoming a bottleneck of several AI/ML applications that needs frequent retraining and low latency responses. To overcome the limitations of a centralized ML research community has proposed Federated Learning, a technique used to train AI/ML algorithms in a distributed fashion. There has been significant previous work to reduce power consumption by adopting efficient hardware techniques; while such techniques yield large savings, they are not focusing on distributed learning. We propose an Energy-efficient Consensus Protocol (EECP) for sustainable Federated Learning. Our protocol iterates over the bidding phase and agreement (or consensus) phase by only exchanging bids and a few other policy-driven information with neighbor workers. Our simulations show significant energy savings of up to 22.7% with respect to our benchmark.",
        "DOI": "10.1109/NetSoft51509.2021.9492565",
        "affiliation_name": "Saint Louis University School of Science and Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting the future research gaps using hybrid approach: Machine learning and ontology - A case study on biodiversity",
        "paper_author": "Premananthan P.",
        "publication": "Handbook of Research on Knowledge and Organization Systems in Library and Information Science",
        "citied_by": "0",
        "cover_date": "2021-06-25",
        "Abstract": "Sri Lanka is one of the global biodiversity hotspots that contain a large variety of fauna and flora. But nowadays Sri Lankan wildlife has faced many issues because of poor management and policies to protect wildlife. The lack of technical and research support leads many researchers to retreat to select wildlife as their domain of study. This study demonstrates a novel approach to data mining to find hidden keywords and automated labeling for past research work in this area. Then use those results to predict the trending topics of researches in the field of biodiversity. To model topics and extract the main keywords, the authors used the latent dirichlet allocation (LDA) algorithms. Using the topic modeling performance, an ontology model was also developed to describe the relationships between each keyword. They classified the research papers using the artificial neural network (ANN) using ontology instances to predict the future gaps for wildlife research papers. The automatic classification and labeling will lead many researchers to find their desired research papers accurately and quickly.",
        "DOI": "10.4018/978-1-7998-7258-0.ch009",
        "affiliation_name": "Sabaragamuwa University",
        "affiliation_city": "Belihuloya",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Examining the evolution of E-government development of nations through machine learning techniques",
        "paper_author": "Mengesha N.",
        "publication": "Handbook of Research on Applied Data Science and Artificial Intelligence in Business and Industry",
        "citied_by": "1",
        "cover_date": "2021-06-25",
        "Abstract": "Several initiatives have tried to measure the efforts nations have made towards developing e-government. The UN E-Government Development Index (EGDI) is the only global report that ranks and classifies the UN Member States into four categories based on a weighted average of normalized scores on online service, telecom infrastructure, and human capital. The authors argue that the EGDI fails in showing the efforts of nations over time and in informing nations and policymakers as to what and from whom to draw policy lessons. Using the UN EGDI data from 2008 to 2020, they profile the UN Member States and show the relevance of machine learning techniques in addressing these issues. They examine the resulting cluster profiles in terms of theoretical perspectives in the literature and derive policy insights from the different groupings of nations and their evolution over time. Finally, they discuss the policy implications of the proposed methodology and the insights obtained.",
        "DOI": "10.4018/978-1-7998-6985-6.ch004",
        "affiliation_name": "Goodman School of Business",
        "affiliation_city": "St. Catharines",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "The Mobile Robot for Garbage Sorting and Handling Based on Machine Vision",
        "paper_author": "Zhou Q.",
        "publication": "2021 IEEE International Conference on Artificial Intelligence, Robotics, and Communication, ICAIRC 2021",
        "citied_by": "6",
        "cover_date": "2021-06-25",
        "Abstract": "Recent years, garbage sorting has attracted wide attention from all aspects of society. Various methods and policies for garbage sorting have been put forward, which started from cultivating people's active awareness of garbage sorting. With the development of machine vision and deep learning, applying these techniques to intelligent garbage sorting will be a worthy direction. A mobile robot for garbage sorting and handling based on machine vision and GPS auto-drive technology was designed in this paper. The scheme was elaborated from three aspects of mechanical structure, hardware system, and software system. The test results showed that the PID speed regulation response of the mobile robot was fast, and the accuracy rates for recyclable garbage and hazardous garbage were respectively 100% and 80%.",
        "DOI": "10.1109/ICAIRC52191.2021.9544768",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Vehicle Insurance Fraud Detection System Using Robotic Process Automation and Machine Learning",
        "paper_author": "S.patil N.",
        "publication": "2021 International Conference on Intelligent Technologies, CONIT 2021",
        "citied_by": "11",
        "cover_date": "2021-06-25",
        "Abstract": "Vehicle owners purchase insurance policy for their vehicles to adjust the expenditure incurred in getting into an auto accident. Annual premiums need to be paid by owners to an auto insurance company on regular basis. The insurance company pays all or most of the costs associated with vehicle damage. The insurance sector is a highly regulated industry, and with this increasing competition, it is not at all easy to keep up with the latest technologies. Robotic Process Automation (RPA) is a promising approach that automates recurring human tasks using software bots. Many organizations use RPA to allay their employees from repetitive and tedious tasks which contributes to achieve many benefits including better business efficiency, larger productivity, data security, reduced cycle time, and improved accuracy. The client's satisfaction, enhanced and efficient production can be achieved in the organizations with the use of computers for doing repetitive tasks which run in background along with the production processes. These background automation systems are referred as Robotic Process Automation (RPA). It automates the repeating tasks thereby reducing human intervention. RPA is known as a catalyst for the bot revolution. Implementing RPA is a challenge for any organization that is willing to adapt it and must learn to deal with RPA to reach maximum results. Usage of Robotic Process Automation (RPA) in the insurance sector facilitates the easy collection of policyholder's details, essential information from previous years' claims documents, therefore allowing the insurers to settle insurance claims seamlessly. This paper aims to perform Vehicle Fraud Detection by efficiently adopting Robotic Process Automation in the insurance sector to automate the task of by integrating with Machine Learning (ML) techniques that make the system more intelligent to classify an insurance claim as a fraud or legitimate. The authors found that Linear Discriminant Analysis (LDA) shown prominent results with an accuracy of 90% compared to other techniques. Finally, future directions are presented.",
        "DOI": "10.1109/CONIT51480.2021.9498507",
        "affiliation_name": "KLE Technological University",
        "affiliation_city": "Hubli",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Deep Learning for Vision and Decision Making in Self Driving Cars-Challenges with Ethical Decision Making",
        "paper_author": "Asmika B.",
        "publication": "2021 International Conference on Intelligent Technologies, CONIT 2021",
        "citied_by": "10",
        "cover_date": "2021-06-25",
        "Abstract": "In recent times self-driving vehicle is a revolutionary Idea. Self-Driving cars are the driver less cars where the car runs by itself called as Autonomous cars. There are lot of underlying Technologies like Machine Learning and Deep Learning. This paper focuses on vision and decision making capabilities of self-driving cars using Deep Learning and also ethical challenges while making sudden decisions. Deep Learning is a sub part of Machine Learning which is inspired by the working process and functionality of biological neurons. Vision is the important and strong aspect of self-driving car that contribute a lot i.e., sensing the environment to identify obstacles, reading traffic signs, understanding traffic signal light status, traffic light count down time recognition and finally making appropriate decision on what it sees. Decision making is a complex task when it comes to real time scenarios, where the autonomous driving agent need to make decisions based on the data generated in real world. There is huge amount of data generated by various sensors, radars and LIDAR's. Every time it is like a new experience for the autonomous driving agent, it is difficult to make different policies for different driving scenarios because of existing rules and amount of previous data available. Decision making depends on different technologies like computer vision and deep learning. Ethical decision making, sacrificial decision making is really a tough job for autonomous driving agent in unavoidable accident situations where people lives are at stake.",
        "DOI": "10.1109/CONIT51480.2021.9498342",
        "affiliation_name": "GITAM University",
        "affiliation_city": "Visakhapatnam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Electrical Load Forecasting",
        "paper_author": "Singh U.",
        "publication": "2021 International Conference on Intelligent Technologies, CONIT 2021",
        "citied_by": "0",
        "cover_date": "2021-06-25",
        "Abstract": "Since the electricity demand is increasing globally, load forecasting techniques have become immensely important in forecasting the electricity demands and it also helps the policy makers. The aim of our project is to perform short-term load forecasting, i.e. up to a week ahead. Household owners can estimate the upcoming load and power distribution organization would know the demand and could be prepared henceforth. Our attempt is to generate useful insights and forecast as accurately as possible. We are using different techniques starting from Naive Bayes, Classical Linear Methods (like ARIMA), and some Machine Learning Algorithms (like LinearRegression, Ridge, Lasso, HuberRegressor, ElasticNet, Lars, LassoLars, PassiveAggressiveRegressor, RANSAC Regressor, SGD Regressor) to make predictions. And we are also using Deep Learning algorithms like CNN, LSTM and combining CNN-LSTM to get more accurate predictions. In the end we will compare all the predictions from all the models that we have used and determine which model makes the best prediction.",
        "DOI": "10.1109/CONIT51480.2021.9498349",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "LCTES 2021 - Proceedings of the 22nd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems, co-located with PLDI 2021",
        "paper_author": "NA",
        "publication": "Proceedings of the ACM SIGPLAN Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES)",
        "citied_by": "0",
        "cover_date": "2021-06-22",
        "Abstract": "The proceedings contain 15 papers. The topics discussed include: robust I/O-compute concurrency for machine learning pipelines in constrained cyber-physical devices; better atomic writes by exposing the flash out-of-band area to file systems; MaPHeA: a lightweight memory hierarchy-aware profile-guided heap allocation framework; automatic mapping and code optimization for OpenCL Kernels on FT-matrix architecture; CHaNAS: coordinated search for network architecture and scheduling policy; annotate once – analyze anywhere: context-aware WCET analysis by user-defined abstractions; Optimus: towards optimal layer-fusion on deep learning processors; WasmAndroid: a cross-platform runtime for native programming languages on android; and simple, light, yet formally verified, global common subexpression elimination and loop-invariant code motion.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Hybrid Approach for Digital Twins in the Built Environment",
        "paper_author": "Lin Y.W.",
        "publication": "e-Energy 2021 - Proceedings of the 2021 12th ACM International Conference on Future Energy Systems",
        "citied_by": "14",
        "cover_date": "2021-06-22",
        "Abstract": "In recent years, several countries have created policies to enforce Zero Energy Building (ZEB) standards for new building construction. Achieving this for new buildings is feasible, but it may be difficult to transform existing buildings to ZEBs. Digital twins provide a promising approach to monitor existing buildings and further increase their energy efficiency. A digital twin (DT) is a virtual representation of a physical entity. It has several applications in product design, product cycle, and fault detection. This paper presents a hybrid approach that combines physics-based and machine learning methods to create a DT for the built environment. A case study for a digital twin of a single room is also discussed. The initial comparison of cooling energy between the physical testbed and the DT model shows promising results for future development. The limitations, challenges, and future development of the approach are also addressed in the paper.",
        "DOI": "10.1145/3447555.3466585",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Solving the Dynamics-Aware Economic Dispatch Problem with the Koopman Operator",
        "paper_author": "King E.",
        "publication": "e-Energy 2021 - Proceedings of the 2021 12th ACM International Conference on Future Energy Systems",
        "citied_by": "8",
        "cover_date": "2021-06-22",
        "Abstract": "The dynamics-aware economic dispatch (DED) problem embeds low-level generator dynamics and operational constraints to enable near real-time scheduling of generation units in a power network. DED produces a more dynamic supervisory control policy than traditional economic dispatch (T-ED) that reduces overall generation costs. However, in contrast to T-ED, DED is a nonlinear, non-convex optimization problem that is computationally prohibitive to solve. We introduce a machine learning-based operator-theoretic approach for solving the DED problem efficiently. Specifically, we develop a novel discrete-time Koopman Operator (KO) formulation that embeds domain information into the structure of the KO to learn high-fidelity approximations of the generator dynamics. Using the KO approximation, the DED problem can be reformulated as a computationally tractable linear program (abbreviated DED-KO). We demonstrate the high solution quality and computational-time savings of the DED-KO model over the original DED formulation on a 9-bus test system.",
        "DOI": "10.1145/3447555.3464864",
        "affiliation_name": "Pacific Northwest National Laboratory",
        "affiliation_city": "Richland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "MemOReL: A &lt;u&gt;Mem&lt;/u&gt;ory-oriented &lt;u&gt;O&lt;/u&gt;ptimization Approach to &lt;u&gt;Re&lt;/u&gt;inforcement &lt;u&gt;L&lt;/u&gt;earning on FPGA-based Embedded Systems",
        "paper_author": "Sahoo S.S.",
        "publication": "Proceedings of the ACM Great Lakes Symposium on VLSI, GLSVLSI",
        "citied_by": "6",
        "cover_date": "2021-06-22",
        "Abstract": "Reinforcement Learning (RL) represents the machine learning method that has come closest to showing human-like learning. While Deep RL is becoming increasingly popular for complex applications such as AI-based gaming, it has a high implementation cost in terms of both power and latency. Q-Learning, on the other hand, is a much simpler method that makes it more feasible for implementation on resource-constrained embedded systems for control and navigation. However, the optimal policy search in Q-Learning is a compute-intensive and inherently sequential process and a software-only implementation may not be able to satisfy the latency and throughput constraints of such applications. To this end, we propose a novel accelerator design with multiple design trade-offs for implementing Q-Learning on FPGA-based SoCs. Specifically, we analyze the various stages of the Epsilon-Greedy algorithm for RL and propose a novel microarchitecture that reduces the latency by optimizing the memory access during each iteration. Consequently, we present multiple designs that provide varying trade-offs between performance, power dissipation, and resource utilization of the accelerator. With the proposed approach, we report considerable improvement in throughput with lower resource utilization over state-of-The-Art design implementations.",
        "DOI": "10.1145/3453688.3461533",
        "affiliation_name": "Center for Advancing Electronics Dresden",
        "affiliation_city": "Dresden",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Network Automation for Path Selection: A New Knowledge Transfer Approach",
        "paper_author": "Lin G.",
        "publication": "2021 IFIP Networking Conference, IFIP Networking 2021",
        "citied_by": "1",
        "cover_date": "2021-06-21",
        "Abstract": "Due to the ever-increasing complexity of modern communication networks, network operators are making tremendous efforts on achieving objectives for the network to meet the diversified requirements of many real-world applications. However, network operators are repeatedly taking a lot of time on some common tasks shared by different networks. In order to reduce repetitive human efforts on network management, advanced machine learning paradigms, such as deep reinforcement learning, has received numerous attention in the networking community. Nevertheless, it encounters great difficulty in transferring learned policies to new environments, resulting in new model training and testing for each changed environment setting. To tackle this important issue, in this paper we propose a new framework that is the first of its kind to enable an agent to have transferable knowledge for network management, specifically, for network path selection tasks. Through this framework, an agent can efficiently learn and express the transferable network knowledge for achieving task objectives. Extensive experimental results show that the learned knowledge through the proposed framework can realize some common objectives of path selection tasks across different network environments. In addition, the knowledge learned from one network task can significantly improve the learning performance of another similar but different task.",
        "DOI": "10.23919/IFIPNetworking52078.2021.9472841",
        "affiliation_name": "Institute of Information Engineering",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A combined rule-based and machine learning approach for automated GDPR compliance checking",
        "paper_author": "Hamdani R.E.",
        "publication": "Proceedings of the 18th International Conference on Artificial Intelligence and Law, ICAIL 2021",
        "citied_by": "36",
        "cover_date": "2021-06-21",
        "Abstract": "The General Data Protection Regulation (GDPR) requires data controllers to implement end-to-end compliance. Controllers must therefore ensure that the terms agreed with the data subject and their own obligations under GDPR are respected in the data flows from data subject to controllers, processors and sub processors (i.e. data supply chain). This paper seeks to contribute to bridge both ends of compliance checking through a two-pronged study. First, we conceptualize a framework to implement a document-centric approach to compliance checking in the data supply chain. Second, we develop specific methods to automate compliance checking of privacy policies. We test a two-modules system, where the first module relies on NLP to extract data practices from privacy policies. The second module encodes GDPR rules to check the presence of mandatory information. The results show that the text-to-text approach outperforms local classifiers and enables the extraction of both coarse-grained and fine-grained information with only one model. We implement full evaluation of our system on a dataset of 30 privacy policies annotated by legal experts. We conclude that this approach could be generalized to other documents in the data supply as a means to improve end-to-end compliance.",
        "DOI": "10.1145/3462757.3466081",
        "affiliation_name": "École des hautes études commerciales de Paris",
        "affiliation_city": "Jouy-en-Josas",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Predicting Obesity in Adults Using Machine Learning Techniques: An Analysis of Indonesian Basic Health Research 2018",
        "paper_author": "Thamrin S.A.",
        "publication": "Frontiers in Nutrition",
        "citied_by": "50",
        "cover_date": "2021-06-21",
        "Abstract": "Obesity is strongly associated with multiple risk factors. It is significantly contributing to an increased risk of chronic disease morbidity and mortality worldwide. There are various challenges to better understand the association between risk factors and the occurrence of obesity. The traditional regression approach limits analysis to a small number of predictors and imposes assumptions of independence and linearity. Machine Learning (ML) methods are an alternative that provide information with a unique approach to the application stage of data analysis on obesity. This study aims to assess the ability of ML methods, namely Logistic Regression, Classification and Regression Trees (CART), and Naïve Bayes to identify the presence of obesity using publicly available health data, using a novel approach with sophisticated ML methods to predict obesity as an attempt to go beyond traditional prediction models, and to compare the performance of three different methods. Meanwhile, the main objective of this study is to establish a set of risk factors for obesity in adults among the available study variables. Furthermore, we address data imbalance using Synthetic Minority Oversampling Technique (SMOTE) to predict obesity status based on risk factors available in the dataset. This study indicates that the Logistic Regression method shows the highest performance. Nevertheless, kappa coefficients show only moderate concordance between predicted and measured obesity. Location, marital status, age groups, education, sweet drinks, fatty/oily foods, grilled foods, preserved foods, seasoning powders, soft/carbonated drinks, alcoholic drinks, mental emotional disorders, diagnosed hypertension, physical activity, smoking, and fruit and vegetables consumptions are significant in predicting obesity status in adults. Identifying these risk factors could inform health authorities in designing or modifying existing policies for better controlling chronic diseases especially in relation to risk factors associated with obesity. Moreover, applying ML methods on publicly available health data, such as Indonesian Basic Health Research (RISKESDAS) is a promising strategy to fill the gap for a more robust understanding of the associations of multiple risk factors in predicting health outcomes.",
        "DOI": "10.3389/fnut.2021.669155",
        "affiliation_name": "Hasanuddin University",
        "affiliation_city": "Makassar",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Automatic control of simulated moving bed process with deep Q-network",
        "paper_author": "Oh T.H.",
        "publication": "Journal of Chromatography A",
        "citied_by": "24",
        "cover_date": "2021-06-21",
        "Abstract": "Optimal control of a simulated moving bed (SMB) process is challenging because the system dynamics is represented as nonlinear partial differential-algebraic equations combined with discrete events. In addition, product purity constraints are active at the optimal operating condition, which implies that these constraints can be easily violated by disturbance. Recently, artificial intelligence techniques have received significant attention for their ability to address complex problems, involving a large number of state variables. In this study, a data-based deep Q-network, which is a model-free reinforcement learning method, is applied to the SMB process to train a near-optimal control policy. Using a deep Q-network, the control policy of a complex dynamic system can be trained off-line as long as a sufficient number of data is provided. These data can be efficiently generated by performing numerical simulations in parallel on multiple machines. The on-line computation of the control input using a trained Q-network is fast enough to satisfy the computational time limit for the SMB process. However, because the Q-network does not predict the future state, it is not possible to explicitly impose state constraints. Instead, the state constraints are indirectly imposed by providing a relatively large penalty (negative reward) when the constraints are violate. Furthermore, logic-based switching control is utilized to limit the ranges of the extract and raffinate purities, which helps to satisfy the state constraints and reduce the regions in the state space for reinforcement learning to explore. The simulation results demonstrate the advantages of applying deep reinforcement learning to control the SMB process.",
        "DOI": "10.1016/j.chroma.2021.462073",
        "affiliation_name": "LG Life Sciences, Ltd.",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Learning Optimal Power Flow Solutions using Linearized Models in Power Distribution Systems",
        "paper_author": "Sadnan R.",
        "publication": "Conference Record of the IEEE Photovoltaic Specialists Conference",
        "citied_by": "3",
        "cover_date": "2021-06-20",
        "Abstract": "Solving nonlinear optimal power flow (OPF) problem is computationally expensive, and poses scalability challenges for power distribution networks. An alternative to solving the original nonlinear OPF is the linear approximated OPF models. Although, these linear approximated OPF models are fast, the resulting solutions may result in significant optimality gap. Lately, the application of machine learning (ML) methods in successfully solving the nonlinear OPF has been reported. These methods learn and estimate the nonlinear control policies using a purely data-driven approach. In this paper, we propose an approach to complements the ML based approach to solving OPF using solutions from known linearized OPF model. Specifically, we use supervised learning to map the solutions of linear OPF to nonlinear control variables. Unlike, the traditional ML based methods for OPF that approximate the full distribution feeder model using function approximation, our approach uses a two-node approximation of radial networks. The proposed approach is validated using IEEE 123 bus test system for OPF solutions obtained using the nonlinear OPF models.",
        "DOI": "10.1109/PVSC43889.2021.9518472",
        "affiliation_name": "Voiland College of Engineering and Architecture",
        "affiliation_city": "Pullman",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Naives Bayes Algorithm for Twitter Sentiment Analysis",
        "paper_author": "Samsir ",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "19",
        "cover_date": "2021-06-18",
        "Abstract": "On 2 March 2020, the Indonesian government, through President Joko 'Jokowi' Widodo, announced the first two cases of COVID-19 in Indonesia. This is the first case of COVID-19 officially confirmed in that country. Several cases have continued to increase since then. President Jokowi began issuing policies on the spread of this virus. This is different from other countries, such as Malaysia and Singapore, which responded from the previous month when the Indonesian government still stated that coronavirus does not exist in Indonesia. Our case study is to find a public opinion through social network analysis of Indonesian public policy during the beginning of the Indonesian COVID-19 pandemic in March 2020. This research implements text mining and document-based sentiments on Twitter data that is reprocessed through machine learning techniques using the Naïve Bayes method. We found negative opinions in the period more dominant by 46%, while that was 35% positive sentiment and 20% neutral. This research shows that anticipation, sadness, and anger are very dominant in the emotional analysis.",
        "DOI": "10.1088/1742-6596/1933/1/012019",
        "affiliation_name": "Institut Teknologi Batam",
        "affiliation_city": "Batam",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Heterogenous Treatment Effect in Microcredit on Those Who Take It Up: Evidence from a Randomized Experiment in Morocco Based on the Casual Forest Model",
        "paper_author": "Qing A.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2021-06-18",
        "Abstract": "Randomized experiments are now widely used in analyzing policy implementation or evaluation because researchers can estimate the average treatment effect between the control and treated groups. While, treatment effects are variable in different subgroups, which is interesting for us to explore. The paper applies novel machine learning technology that detects heterogeneous treatment effect through a data-driven approach. Specifically, the paper applies causal forest to a dataset derived from a random experiment did in Morocco by discussing how each different variables contribute to the final result of borrowing.",
        "DOI": "10.1145/3473714.3473791",
        "affiliation_name": "Shanghai Starriver Bilingual School",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "David F. Hendry (1944-)",
        "paper_author": "Ericsson N.R.",
        "publication": "The Palgrave Companion to Oxford Economics",
        "citied_by": "1",
        "cover_date": "2021-06-16",
        "Abstract": "David Hendry has made-and continues to make-major contributions to the econometrics of empirical economic modelling, economic forecasting, econometrics software, and economic policy. This chapter reviews his contributions by topic, emphasizing the overlaps between different strands in his research and the importance of real-world problems in motivating and benefiting from that research.",
        "DOI": "10.1007/978-3-030-58471-9_24",
        "affiliation_name": "Federal Reserve System",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Gender Bias in the News: A Scalable Topic Modelling and Visualization Framework",
        "paper_author": "Rao P.",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "21",
        "cover_date": "2021-06-16",
        "Abstract": "We present a topic modelling and data visualization methodology to examine gender-based disparities in news articles by topic. Existing research in topic modelling is largely focused on the text mining of closed corpora, i.e., those that include a fixed collection of composite texts. We showcase a methodology to discover topics via Latent Dirichlet Allocation, which can reliably produce human-interpretable topics over an open news corpus that continually grows with time. Our system generates topics, or distributions of keywords, for news articles on a monthly basis, to consistently detect key events and trends aligned with events in the real world. Findings from 2 years worth of news articles in mainstream English-language Canadian media indicate that certain topics feature either women or men more prominently and exhibit different types of language. Perhaps unsurprisingly, topics such as lifestyle, entertainment, and healthcare tend to be prominent in articles that quote more women than men. Topics such as sports, politics, and business are characteristic of articles that quote more men than women. The data shows a self-reinforcing gendered division of duties and representation in society. Quoting female sources more frequently in a caregiving role and quoting male sources more frequently in political and business roles enshrines women’s status as caregivers and men’s status as leaders and breadwinners. Our results can help journalists and policy makers better understand the unequal gender representation of those quoted in the news and facilitate news organizations’ efforts to achieve gender parity in their sources. The proposed methodology is robust, reproducible, and scalable to very large corpora, and can be used for similar studies involving unsupervised topic modelling and language analyses.",
        "DOI": "10.3389/frai.2021.664737",
        "affiliation_name": "Simon Fraser University",
        "affiliation_city": "Burnaby",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A Classification Model for Predicting Suitable Cache Level in a Multi-core Architecture",
        "paper_author": "Thasneema V.T.",
        "publication": "ICCISc 2021 - 2021 International Conference on Communication, Control and Information Sciences, Proceedings",
        "citied_by": "3",
        "cover_date": "2021-06-16",
        "Abstract": "Cache memory has an important role in achieving system performance in multi-core architecture. Finding the best suitable cache configuration for an application is a very important step while designing a computer system to improve the performance. The commonly considered cache memory design parameters are the size of the cache, line size, associativity, type of cache, replacement policy, writes policy and levels of cache. Selecting these parameters decides the design goals such as system performance, energy consumption, area, scalability and programmability of an application. Cache design space is a time consuming and complex process as it involves studies on the impact of all possible cache parameter configurations on system performance. This project mainly aims at creating a model that can predict an efficient cache configuration-cache level-that is best suitable for an application in terms of energy consumption and performance in a multi-core environment using machine learning techniques such as classification. The design goal here is to predict the optimum cache levels for an application by considering the design parameters such as cache sizes, associativity, block size etc. This method will be carried out in a multi-core environment for the studies on advancements in computer architecture. The required data set is generated using two simulators such as Gem5 and CACTI. The entire process of data collection is automated via shell scripting in Unix OS and applications from different domains will be considered here with different cache parameter combinations. The performance of the classifier is measured based on the evaluation metrics such as Precision, Recall, and F-measure. Performance measurement concerning power consumption and execution time would be the figure of merits of this project.",
        "DOI": "10.1109/ICCISc52257.2021.9484900",
        "affiliation_name": "Amrita Vishwa Vidyapeetham University, Bangalore",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Dimensions of cybersecurity risk management",
        "paper_author": "Nygard K.E.",
        "publication": "Advances in Cybersecurity Management",
        "citied_by": "12",
        "cover_date": "2021-06-15",
        "Abstract": "Risk analysis and management are of fundamental importance in cybersecurity. The core elements of risk are threat, vulnerability, and impact. Risk management has a basis in cybersecurity technical policies, procedures, and practices. Dimensions of risk are also at higher levels, with major interconnections in issues of international relations and trade, safety, economic vitality, health, and human life. The work of this paper is focused on risk and closely related concepts. Details and analyses that pertain to security of cyber-physical systems and the role of intrusion detection and machine learning methodologies are included.",
        "DOI": "10.1007/978-3-030-71381-2_17",
        "affiliation_name": "North Dakota State University",
        "affiliation_city": "Fargo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An Approach to Mapping Deforestation in Permanent Forest Reserve Using the Convolutional Neural Network and Sentinel-1 Synthetic Aperture Radar",
        "paper_author": "Wahab M.A.A.",
        "publication": "Proceedings - CAMP 2021: 2021 5th International Conference on Information Retrieval and Knowledge Management: Digital Technology for IR 4.0 and Beyond",
        "citied_by": "3",
        "cover_date": "2021-06-15",
        "Abstract": "Forests are essential for the protection of biodiversity and provide essential ecosystem services to humankind. Globally, 1.6 billion people depend on forests as fuel sources, construction materials, medicine, food, and freshwater sources. However, according to the monitoring service Global Forest Watch, our world lost 12 million hectares (30 million acres) of tropical tree cover in 2018, equal to 30 football pitches a minute. Surprisingly, Malaysia was among the top six countries that year with tremendous losses. Therefore, stern action is needed to increase public knowledge of ecosystem threats, improve strategic forest management decisions, and enforce land-use policies. This study aims to map deforestation in Permanent Forest Reserve (HSK) Yong in Pahang between 2017 and 2020 using satellite images of Sentinel-1 SAR. We further automate the classification of forest and non-forest by using a small and straightforward Convolutional Neural Network (CNN) model architecture. Our model used an open-source machine learning framework, namely Orfeo ToolBox TensorFlow (OTBTF). As well as machine learning, deep learning can be applied by OTBTF without image size restrictions and is computationally efficient, regardless of hardware configuration. The methodology includes data pre-processing, RGB composition, patches sampling, TensorFlow model train, TensorFlow model serve, and verification. Results show that the CNN approach with the Sentinel-1 Synthetic Aperture Radar (SAR) was 81.57 percent of the overall accuracy and the Kappa index was 0.6313. In brief, the approach mentioned in this study provides an alternative and reasonable approach for the HSK deforestation mapping in Peninsular Malaysia.",
        "DOI": "10.1109/CAMP51653.2021.9498144",
        "affiliation_name": "Universiti Kebangsaan Malaysia",
        "affiliation_city": "Bangi",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Intracounty modeling of COVID-19 infection with human mobility: Assessing spatial heterogeneity with business traffic, age, and race",
        "paper_author": "Hou X.",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "103",
        "cover_date": "2021-06-15",
        "Abstract": "The COVID-19 pandemic is a global threat presenting health, economic, and social challenges that continue to escalate. Metapopulation epidemic modeling studies in the susceptible–exposed–infectious–removed (SEIR) style have played important roles in informing public health policy making to mitigate the spread of COVID-19. These models typically rely on a key assumption on the homogeneity of the population. This assumption certainly cannot be expected to hold true in real situations; various geographic, socioeconomic, and cultural environments affect the behaviors that drive the spread of COVID-19 in different communities. What’s more, variation of intracounty environments creates spatial heterogeneity of transmission in different regions. To address this issue, we develop a human mobility flow-augmented stochastic SEIR-style epidemic modeling framework with the ability to distinguish different regions and their corresponding behaviors. This modeling framework is then combined with data assimilation and machine learning techniques to reconstruct the historical growth trajectories of COVID-19 confirmed cases in two counties in Wisconsin. The associations between the spread of COVID-19 and business foot traffic, race and ethnicity, and age structure are then investigated. The results reveal that, in a college town (Dane County), the most important heterogeneity is age structure, while, in a large city area (Milwaukee County), racial and ethnic heterogeneity becomes more apparent. Scenario studies further indicate a strong response of the spread rate to various reopening policies, which suggests that policy makers may need to take these heterogeneities into account very carefully when designing policies for mitigating the ongoing spread of COVID-19 and reopening.",
        "DOI": "10.1073/pnas.2020524118",
        "affiliation_name": "University of Wisconsin-Madison",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Agent-based modelling of post-disaster recovery with remote sensing data",
        "paper_author": "Ghaffarian S.",
        "publication": "International Journal of Disaster Risk Reduction",
        "citied_by": "55",
        "cover_date": "2021-06-15",
        "Abstract": "Disaster risk management, and post-disaster recovery (PDR) in particular, become increasingly important to assure resilient development. Yet, PDR is the most poorly understood phase of the disaster management cycle and can take years or even decades. The physical aspects of the recovery are relatively easy to monitor and evaluate using, e.g. geospatial remote sensing data compared to functional assessments that include social and economic processes. Therefore, there is a need to explore the impacts of different dimensions of the recovery, including individual behaviour and their interactions with socio-economic institutions. In this study, we develop an agent-based model to simulate and explore the PDR process in urban areas of Tacloban, the Philippines devastated by Typhoon Haiyan in 2013. Formal and informal (slum) sector households are differentiated in the model to explore their resilience and different recovery patterns. Machine learning-derived land use maps are extracted from remote sensing images for pre- and post-disaster and are used to provide information on physical recovery. We use the empirical model to evaluate two realistic policy scenarios: the construction of relocation sites after a disaster and the investments in improving employment options. We find that the speed of the recovery of the slum dwellers is higher than formal sector households due to the quick reconstruction of slums and the availability of low-income jobs in the first months after the disaster. Finally, the results reveal that the households' commuting distance to their workplaces is one of the critical factors in households’ decision to relocate after a disaster.",
        "DOI": "10.1016/j.ijdrr.2021.102285",
        "affiliation_name": "University of Technology Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Scalable coordinated management of peer-to-peer energy trading: A multi-cluster deep reinforcement learning approach",
        "paper_author": "Qiu D.",
        "publication": "Applied Energy",
        "citied_by": "113",
        "cover_date": "2021-06-15",
        "Abstract": "The increasing penetration of small-scale distributed energy resources (DER) has the potential to support cost-efficient energy balancing in emerging electricity systems, but is also fundamentally affecting the conventional operation paradigm of the latter. In this context, innovative market mechanisms need to be devised to better coordinate and provide incentives for DER to utilize their flexibility. Peer-to-Peer (P2P) energy trading has emerged as an alternative approach to facilitate direct trading between consumers and prosumers interacting in an energy collective and fosters more efficient local demand–supply balancing. While previous research has primarily focused on the technical and economic benefits of P2P trading, little effort has been made towards the incorporation of prosumers’ heterogeneous characteristics in the P2P trading problem. Here, we address this research gap by classifying the participating prosumers into multiple clusters with regard to their portfolio of DER, and analyzing their trading decisions in a simulated P2P trading platform. The latter employs the mid-market rate (MMR) local pricing mechanism to enable energy trading among prosumers and penalizes the contribution to the system demand peak of each prosumer. We formulate the P2P trading problem as a multi-agent coordination problem and propose a novel multi-agent deep reinforcement learning (MADRL) method to address it. The proposed method is founded on the combination of the multi-agent deep deterministic policy gradient (MADDPG) algorithm and the technique of parameter sharing (PS), which not only enables accelerating the training speed by sharing experiences and learned policies between all agents in each cluster, but also sustains the policies’ diversity between multiple clusters. To address the non-stationarity and computational complexity of MADRL as well as persevering the privacy of prosumers, the P2P trading platform acts as a trusted third party which augments the market collective trading information to help training of prosumer agents. Experiments with a large-scale real-world data-set involving 300 residential households demonstrate that the proposed MADRL method exhibits a strong generalization capability in the test data-set and outperforms the state-of-the-art MADRL methods with regard to the system operation cost, demand peak as well as computational time.",
        "DOI": "10.1016/j.apenergy.2021.116940",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A machine-learning prediction method of lithium-ion battery life based on charge process for different applications",
        "paper_author": "Yang Y.",
        "publication": "Applied Energy",
        "citied_by": "166",
        "cover_date": "2021-06-15",
        "Abstract": "For accelerating the technology development and facilitating the reliable operation of lithium-ion batteries, accurate prediction for battery cycle life and remaining useful life (RUL) are both critical. However, diverse aging mechanisms, significant device variability and random working conditions have remained challenges. A reasonable description and an effective prediction algorithm are indispensable for achieving accurate prediction results. In this paper, battery terminal voltage, current and temperature curves from several charge cycles and especially their difference between these cycles are first utilized for description of battery cycle life and RUL. Moreover, a hybrid convolutional neural network (CNN), which is based on a fusion of three-dimensional CNN and two-dimensional CNN, is designed for their predictions. The battery charge voltage, current and temperature and their curves are first fused for considering the strong relationships between them. And the features hidden in the curves are extracted and modelled automatically. Furthermore, a feature attention algorithm and a multi-scale cycle attention algorithm are proposed to estimate the relationships between different features and cycles respectively for further heightening the prediction performance. Experiments and comparisons are conducted. The results show that the proposed method is an accurate method for different applications. It achieved 1.1% test error for battery cycle life early prediction of different batteries under different charge policies, and 3.6% for RUL prediction.",
        "DOI": "10.1016/j.apenergy.2021.116897",
        "affiliation_name": "Xi'an Jiaotong University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Advanced household profiling using digital water meters",
        "paper_author": "Rahim M.S.",
        "publication": "Journal of Environmental Management",
        "citied_by": "11",
        "cover_date": "2021-06-15",
        "Abstract": "Advanced householder profiling using digital water metering data analytics has been acknowledged as a core strategy for promoting water conservation because of its ability to provide near real-time feedback to customers and instil long-term conservation behaviours. Customer profiling based on household water consumption data collected through digital water meters helps to identify the water consumption patterns and habits of customers. This study employed advanced customer profiling techniques adapted from the machine learning research domain to analyse high-resolution data collected from residential digital water meters. Data analytics techniques were applied on already disaggregated end-use water consumption data (e.g., shower and taps) for creating in-depth customer profiling at various intervals (e.g., 15, 30, and 60 min). The developed user profiling approach has some learning functionality as it can ascertain and accommodate changing behaviours of residential customers. The developed advanced user profiling technique was shown to be beneficial since it identified residential customer behaviours that were previously unseen. Furthermore, the technique can identify and address novel changes in behaviours, which is an important feature for promoting and sustaining long-term water conservation behaviours. The research has implications for researchers in data analytics and water demand management, and also for practitioners and government policy advisors seeking to conserve valuable potable-water resources.",
        "DOI": "10.1016/j.jenvman.2021.112377",
        "affiliation_name": "Griffith University",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A machine learning approach for modelling parking duration in urban land-use",
        "paper_author": "Parmar J.",
        "publication": "Physica A: Statistical Mechanics and its Applications",
        "citied_by": "19",
        "cover_date": "2021-06-15",
        "Abstract": "Parking is an inevitable issue in the fast-growing developing countries. Increasing number of vehicles require more and more urban land to be allocated for parking. However, a little attention has been conferred to the parking issues in developing countries like India. This study proposes a model for analysing the influence of car user's socioeconomic and travel characteristics on parking duration. Specifically, artificial neural network (ANN) is deployed to capture the interrelationship between driver's characteristics and parking duration. ANNs are highly efficient in learning and recognizing connections between parameters for best prediction of an outcome. Since, utility of ANNs has been critically limited due to its ‘Black Box’ nature, the study involves the use of Garson's algorithm and Local interpretable model-agnostic explanations (LIME) for model interpretations. LIME shows the prediction for any classification, by approximating it locally with the developed interpretable model. This study is based on microdata collected on-site through interview surveys considering two land-uses: office-business and market/shopping. Results revealed the higher probability of prediction through LIME and therefore, the methodology can be adopted ubiquitously. Further, the policy implications are discussed based on the results for both land-uses. This unique study could lead to enhanced parking policy and management to achieve the sustainability goals.",
        "DOI": "10.1016/j.physa.2021.125873",
        "affiliation_name": "S. V. National Institute of Technology",
        "affiliation_city": "Surat",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Characterizing Emergent Behaviors in Twitter Telehealth Communication during the COVID-19 Pandemic",
        "paper_author": "Lit C.L.",
        "publication": "2021 16th International System of Systems Engineering Conference, SoSE 2021",
        "citied_by": "0",
        "cover_date": "2021-06-14",
        "Abstract": "Telehealth has played a critical role in supporting healthcare delivery during the COVID-19 pandemic. Mitigation practices of physical distancing and sheltering-in-place continue to impose a significant burden on face-to-face healthcare visits. As a result, telehealth adoption and utilization have increased significantly after the U.S. Department of Health and Human Services waived telehealth payment requirements. These changes have been rapid and affect both individuals and organizations, ranging from healthcare and technology to news and policy. We turn to Twitter, as a broad-reaching communication platform, to elucidate and characterize Telehealth communication patterns. While different aspects of tweeting about telehealth have been used to answer specific questions, we sought to understand the collective telehealth tweeting behavior as a system of different types of users tweeting with various intent and sentiment. Such an approach combines the typically independent analysis of structure, using social network analysis, and purpose or function of communication, with topic analysis and sentiment analysis. In this paper, we apply a systems-based approach-called hetero-functional graph theory-to comprehensively describe the structure and function of the Twitter Telehealth communication system. We modeled 13 different types of telehealth users and 15 combinations of tweet intent and sentiment, which together describe 195 system capabilities. We applied machine learning to classify individual user tweeting behavior for different classes of telehealth stakeholders. We identified several patterns of longitudinal tweeting behaviors that varied by system form and function. By applying an interdependent methodology to understand both form and function, we provide deeper insights into tweeting behaviors between different classes of stakeholders. In doing so, we achieve a greater understanding of the various needs of different stakeholders, which can be leveraged as a valuable resource in informing more equitable policies as telehealth becomes a more permanent and scaled healthcare delivery service.",
        "DOI": "10.1109/SOSE52739.2021.9497466",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Hanover",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Full-Actuation Rolling Locomotion with Tensegrity Robot via Deep Reinforcement Learning",
        "paper_author": "Guo Y.",
        "publication": "2021 5th International Conference on Robotics and Automation Sciences, ICRAS 2021",
        "citied_by": "3",
        "cover_date": "2021-06-11",
        "Abstract": "Tensegrity robots, entirely composed of elastic cables and rigid rods, have many excellent properties which have a wide application from complex co-robotics to planetary. Nevertheless, it is still difficult to control tensegrity robots because of their unconventional designs and highly coupled dynamics. Deep reinforcement learning algorithms have been used in a lot of robotic tasks due to their strong perception and decision-making capabilities. However, it often needs to collect a lot of samples, which limits its application. Model-based algorithms can learn with fewer samples but have a sub-optimal result because of the model error. In the paper, we proposed a hybrid method to achieve effective control of tensegrity robots. Firstly, we established the simulation platform via the framework of the positional formulation finite element method. And thens, we use a medium-sized neural network to fit the dynamic model and control the tensegrity robot via model prediction control (MPC). The controlled trajectories are used to initialize the parameters and memory of deep deterministic policy gradient (DDPG). We demonstrated that the hybrid algorithm can achieve efficient control of the tensegrity robot. In this work, we have realized full-Actuation rolling with a tensegrity robot on a plane and 5° slope surface.",
        "DOI": "10.1109/ICRAS52289.2021.9476651",
        "affiliation_name": "Dalian University of Technology",
        "affiliation_city": "Dalian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "How to apply O<inf>3</inf> and PM<inf>2.5</inf> collaborative control to practical management in China: A study based on meta-analysis and machine learning",
        "paper_author": "Liu Z.",
        "publication": "Science of the Total Environment",
        "citied_by": "48",
        "cover_date": "2021-06-10",
        "Abstract": "Constant increase of atmospheric O3 concentration is a barrier for the further air quality improvement in China. Given that PM2.5 is still controlled as a key pollutant, managements for the collaborative reduction of O3 and PM2.5 are urgently required in China. In the current work, monitoring data of O3 and PM2.5 from 2015 to 2016 in 1464 monitoring sites (MS) was collected and cleaned. Additionally, 7 anthropogenic emission reductions were jointed with the corresponding monitoring data. According to the O3 and PM2.5 variation, a meta-analysis was conducted and divided regions into 4 categories via the effect size, region I: O3 and PM2.5 collaborative reduction, region II: PM2.5 decreased and O3 increased, region III: O3 decreased and PM2.5 increased, regions IV: both O3 and PM2.5 increased. Then, based on the region labels, machine learning was used to identify the pattern between region label and its precursor reductions. The findings were as follows: (1) Principal component analysis showed that NH3 was not focused on. (2) Random forest had a well performance on region classification with the accuracy of 80.40% and the importance of the 7 precursors was in the sequence of VOCs>NH3 > PM2.5 > OC > SO2 > NOX > Coarse PM. (3) Polytomous logistic regression evaluated the critical factors that influenced the region label, which showed that the reductions of VOCs, NH3 and PM2.5 could achieve the collaborative reduction in a short time in most of cities in China. Based on the statistical results above, a kinetic management system including evaluation and policy-making sections was finally established, which filled the gap of the collaborative reduction in environmental management in China.",
        "DOI": "10.1016/j.scitotenv.2021.145392",
        "affiliation_name": "College of Environmental and Resource Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Supervised learning for the prediction of firm dynamics",
        "paper_author": "Bargagli-Stoffi F.J.",
        "publication": "Data Science for Economics and Finance: Methodologies and Applications",
        "citied_by": "15",
        "cover_date": "2021-06-09",
        "Abstract": "Thanks to the increasing availability of granular, yet high-dimensional, firm level data, machine learning (ML) algorithms have been successfully applied to address multiple research questions related to firm dynamics. Especially supervised learning (SL), the branch of ML dealing with the prediction of labelled outcomes, has been used to better predict firms' performance. In this chapter, we will illustrate a series of SL approaches to be used for prediction tasks, relevant at different stages of the company life cycle. The stages we will focus on are (1) startup and innovation, (2) growth and performance of companies, and (3) firms' exit from the market. First, we review SL implementations to predict successful startups and R&D projects. Next, we describe how SL tools can be used to analyze company growth and performance. Finally, we review SL applications to better forecast financial distress and company failure. In the concluding section, we extend the discussion of SL methods in the light of targeted policies, result interpretability, and causality.",
        "DOI": "10.1007/978-3-030-66891-4_2",
        "affiliation_name": "Scuola IMT Alti Studi Lucca",
        "affiliation_city": "Lucca",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "What Matters in Maintaining Effective Open Government Data Systems?: The Role of Government Managerial Capacity, and Political and Legal Environment",
        "paper_author": "Ahn M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "3",
        "cover_date": "2021-06-09",
        "Abstract": "This paper aims to identify key institutional factors that contribute to effective open data systems. Rapid advancement in new technologies such as machine learning, algorithms, IoT, and Cloud Computing has amplified the importance of national open data systems. The availability of relevant public data has become a crucial factor in creating sophisticated machine learning platforms or algorithms that will have a considerable impact on national competitiveness. Effective national open data strategies will matter in shaping an environment that will facilitate data production, dissemination, and utilization. Using multiple sources of data that measure the qualities of open data systems and various political, governmental, and legal attributes at the national level, we seek to identify key institutional factors that contribute to robust open data policies and outcomes. Our findings point to the importance of the existence of a national open data strategy and support (especially \"open by default\"strategy), pre-existing e-government capability, and countries operating under full democracy with its guarantees to civil liberties and political freedom. In addition, the nature of the open data matters as different managerial, political, and demographic conditions affected the quality of different open data systems. Policy implications of our findings are discussed.",
        "DOI": "10.1145/3463677.3463732",
        "affiliation_name": "University of Massachusetts Boston",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The Right Tool for the Job? Assessing the Use of Artificial Intelligence for Identifying Administrative Errors",
        "paper_author": "Young M.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "5",
        "cover_date": "2021-06-09",
        "Abstract": "This article explores the extent to which machine learning can be used to detect administrative errors. It concentrates on administrative errors in unemployment insurance (UI) decisions, which give rise to a public values conflict between efficiency and effectiveness. This conflict is first described and then highlighted in the history of the US UI regime. Machine learning may not only mitigate this conflict but it may also help to combat fraud and reduce the backlog of claims associated with economic crises such as the COVID-19 pandemic. The article uses data about improper UI payments throughout the US from 2002 through 2018 to analyze the accuracy of random forests and deep learning models. We find that a random forest model using gradient descent boosting is more accurate, along several measures, than every deep learning model tested. This finding could be explained by the goodness-of-fit between the machine learning method and the available data. Alternatively, deep learning performance could be attenuated by necessary limits to publicly-accessible claims data.",
        "DOI": "10.1145/3463677.3463714",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Syracuse",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Approach to Detect Fake News, Misinformation in COVID-19 Pandemic",
        "paper_author": "Bojjireddy S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "12",
        "cover_date": "2021-06-09",
        "Abstract": "Fake news is false information about current events, intentionally created to mislead readers. The spread of such fake news has the potential to create a negative impact on individuals and society. With today's straightforward creation of social media posts, there has been an increasing amount of fake news, compared to traditional media in the past. We present one of the most serious societal issue of misinformation, specifically using Presidential Election and COVID-19 health related fake news. We present multi-dimensional approaches that organizations and individuals could utilize for detecting fake news, ranging from human/social approaches, to technical approaches to organizational trust/policy approaches. The Machine Learning approach as a technical solution is presented for automating the detection of fake news and misleading contents. A fake news detection web application is presented to make it easy for end users to determine whether an article is legitimate or fake.",
        "DOI": "10.1145/3463677.3463762",
        "affiliation_name": "New Jersey Institute of Technology",
        "affiliation_city": "Newark",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neighbourhood management in sloppy mountain areas",
        "paper_author": "Aliyah I.",
        "publication": "IOP Conference Series: Earth and Environmental Science",
        "citied_by": "0",
        "cover_date": "2021-06-08",
        "Abstract": "Special character of slope areas demands more efforts from the inhabitants to live. The way people live and organize their living space is the learning process products in adapting to the unique conditions of slope areas. Using collaborative model, this study aims to develop a management strategy for mountainous rural slope area. Interactive and Internal-External Environmental Analysis were used to understand human-nature interactions in mountainous slope area of Mount Lawu located in Karanganyar Regency, Central Java, Indonesia. The results signify that the management strategy of the sloppy mountain areas is dependent factor of the behaviour and perceptions of the community and government programs. Community knowledge, their participation and commitments, synergized actions and policies, and the existence of supervision and control system are the key factors that can be accommodated through collaborative model in neighbourhood management.",
        "DOI": "10.1088/1755-1315/780/1/012045",
        "affiliation_name": "Universitas Sebelas Maret",
        "affiliation_city": "Surakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Identity Management with Hybrid Blockchain Approach: A Deliberate Extension with Federated-Inverse-Reinforcement Learning",
        "paper_author": "Banerjee S.",
        "publication": "IEEE International Conference on High Performance Switching and Routing, HPSR",
        "citied_by": "4",
        "cover_date": "2021-06-07",
        "Abstract": "The widespread decentralized applications and Blockchain components significantly boost the security frameworks in many vertical applications and use-cases including different secured payment methods and smart contracts. The integral part of any smart contract is the validation of the stake-holder identity, in general, while ideally being achieved without the third-party involvement. Recent industrial research works introduce the sovereign-identity system, where Blockchain becomes a decentralized component to establish a self-certified identity and to avoid a centralized trust third party. Hence, the classification of distributed transactions with respect to identity validation across several users becomes more challenging, especially because of the massive and sensitive identities that are issued through many users and IoT devices and that are used to validate transactions. In this context, it is important to identify and classify the malicious and non-malicious types of transactions. Our proposed method achieves the target of identity classifications from variety of transaction data. Since different users may have different device usage patterns, the data samples and labels located on any individual device may follow a different distribution, which cannot represent the global data distribution. Therefore, the solution could be bi-focal to compensate the gap. This paper coins the approach of hybridizing the consensus where as to initiate a machine learning mechanism to collect the local data globally through a permission driven and a federated approach. We introduce here a Federated Reinforcement learning to be improvised for distributed independent data as a policy of consortium while binding the proof of consensus more centrally authenticated.",
        "DOI": "10.1109/HPSR52026.2021.9481851",
        "affiliation_name": "CNAM Laboratoire Cédric",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Living up to the Hype of Hyperspectral Aquatic Remote Sensing: Science, Resources and Outlook",
        "paper_author": "Dierssen H.M.",
        "publication": "Frontiers in Environmental Science",
        "citied_by": "61",
        "cover_date": "2021-06-07",
        "Abstract": "Intensifying pressure on global aquatic resources and services due to population growth and climate change is inspiring new surveying technologies to provide science-based information in support of management and policy strategies. One area of rapid development is hyperspectral remote sensing: imaging across the full spectrum of visible and infrared light. Hyperspectral imagery contains more environmentally meaningful information than panchromatic or multispectral imagery and is poised to provide new applications relevant to society, including assessments of aquatic biodiversity, habitats, water quality, and natural and anthropogenic hazards. To aid in these advances, we provide resources relevant to hyperspectral remote sensing in terms of providing the latest reviews, databases, and software available for practitioners in the field. We highlight recent advances in sensor design, modes of deployment, and image analysis techniques that are becoming more widely available to environmental researchers and resource managers alike. Systems recently deployed on space- and airborne platforms are presented, as well as future missions and advances in unoccupied aerial systems (UAS) and autonomous in-water survey methods. These systems will greatly enhance the ability to collect interdisciplinary observations on-demand and in previously inaccessible environments. Looking forward, advances in sensor miniaturization are discussed alongside the incorporation of citizen science, moving toward open and FAIR (findable, accessible, interoperable, and reusable) data. Advances in machine learning and cloud computing allow for exploitation of the full electromagnetic spectrum, and better bridging across the larger scientific community that also includes biogeochemical modelers and climate scientists. These advances will place sophisticated remote sensing capabilities into the hands of individual users and provide on-demand imagery tailored to research and management requirements, as well as provide critical input to marine and climate forecasting systems. The next decade of hyperspectral aquatic remote sensing is on the cusp of revolutionizing the way we assess and monitor aquatic environments and detect changes relevant to global communities.",
        "DOI": "10.3389/fenvs.2021.649528",
        "affiliation_name": "School of Engineering",
        "affiliation_city": "Merced",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predicting energy cost of public buildings by artificial neural networks, CART, and random forest",
        "paper_author": "Zekić-Sušac M.",
        "publication": "Neurocomputing",
        "citied_by": "69",
        "cover_date": "2021-06-07",
        "Abstract": "The paper deals with modeling the cost of energy consumed in public buildings by leveraging three machine learning methods: artificial neural networks, CART, and random forest regression trees. Energy consumption is one of the major issues in global and national policies, therefore scientific efforts in creating prediction models of energy consumption and cost are highly important. One of the largest energy consumers in every state is its public sector, consisting of educational, health, public administration, military, and other types of public buildings. Recent technologies based on sensor networks and Big data platforms enable collection of large amounts of data that could be used to analyze energy consumption and cost. A real data from Croatian public sector is used in this paper including a large number of constructional, energetic, occupational, climate and other attributes. The algorithms for data pre-processing and modeling by optimizing parameters are suggested. Three strategies were tested: (1) with all available variables, (2) with a filter-based variable selection, and (3) with a wrapper-based variable selection which integrates Boruta algorithm and random forest. Prediction models of energy cost are created using two approaches: (a) comparative usage of artificial neural networks and two types of regression trees, CART and random forest, and (b) integration of RF-Boruta variable selection and machine learning methods for prediction. A cross-validation procedure was used to optimize the artificial neural network and regression tree topology, as well to select the most appropriate activation function. Along with creating a prediction model, the aim of the paper was also to extract the relevant predictors of energy cost in public buildings which are important in planning the construction or renovation of buildings. The results have shown that the second approach which integrates machine learning with Boruta method, where the random forest algorithm is used for both variable reduction and prediction modeling, has produced a higher accuracy of prediction than the individual usage of three machine learning methods. Such findings confirm the potential of hybrid machine learning methods which are suggested in previous research, but in favor of random forest method over CART and artificial neural networks. Regarding the variable selection, the model has extracted heating and occupational data as the most important, followed by constructional, cooling, electricity, and lighting attributes. The model could be implemented in public buildings information systems and their IoT networks within the concept of smart buildings and smart cities.",
        "DOI": "10.1016/j.neucom.2020.01.124",
        "affiliation_name": "Sveučilište Josipa Jurja Strossmayera u Osijeku",
        "affiliation_city": "Osijek",
        "affiliation_country": "Croatia"
    },
    {
        "paper_title": "Deep Reinforcement Learning Based Optimization for Charging of Aggregated Electric Vehicles",
        "paper_author": "Zhao X.",
        "publication": "Dianwang Jishu/Power System Technology",
        "citied_by": "21",
        "cover_date": "2021-06-05",
        "Abstract": "With the popularization of electricity data acquisition systems, the application of data-driven machine learning methods has played a significant role on optimal decision-making in demand response. In this paper, based on the real-time feedback data from the charging monitoring system and TOU tariff, a deep reinforcement learning (DRL) method is proposed to optimize the charging strategy of the electric vehicles (EVs) from the perspective of aggregator. A twin delay deep deterministic policy gradient (TD3) algorithm is implemented to model the charging process of a single vehicle. By adding randomly the noises in the states of the trained agent, our model attained generalized abilities to control EV charging strategies under divergent states. With the distributed deployment of the well-trained agents, this method realizes the real-time optimization of aggregated EVs' charging strategy, which is proved with examples.",
        "DOI": "10.13335/j.1000-3673.pst.2020.1418",
        "affiliation_name": "North China Electric Power University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "MULTICLASS CLASSIFICATION WITH IMBALANCED DATASETS FOR CAR OWNERSHIP DEMAND MODEL – COST-SENSITIVE LEARNING",
        "paper_author": "Kaewwichian P.",
        "publication": "Promet - Traffic and Transportation",
        "citied_by": "5",
        "cover_date": "2021-06-04",
        "Abstract": "In terms of the travel demand prediction from the household car ownership model, if the imbalanced data were used to support the transportation policy via a machine learning model, it would negatively affect the algorithm training process. The data on household car ownership obtained from the study project for the expressway preparation in the Khon Kaen Province (2015) was an unbalanced dataset. In other words, the number of members of the minority class is lower than the rest of the answer classes. The result is a bias in data classification. Consequently, this research suggested balancing the datasets with cost-sensitive learning methods, including decision trees, k-nearest neighbors (kNN), and naive Bayes algorithms. Before creating the 3-class model, a k-folds cross-validation method was applied to classify the datasets to define true positive rate (TPR) for the model’s performance validation. The outcome indicated that the kNN algorithm demonstrated the best performance for the minority class data prediction compared to other algorithms. It provides TPR for rural and suburban area types, which are region types with very different imbalance ratios, before balancing the data of 46.9% and 46.4%. After balancing the data (MCN1), TPR values were 84.4% and 81.4%, respectively.",
        "DOI": "10.7307/ptt.v33i3.3728",
        "affiliation_name": "Rajamangala University of Technology Isan",
        "affiliation_city": "Nakhon Ratchasima",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Sentiment Analysis and Classification of COVID-19 Tweets",
        "paper_author": "Rakshana S.B.",
        "publication": "Proceedings of the 5th International Conference on Trends in Electronics and Informatics, ICOEI 2021",
        "citied_by": "4",
        "cover_date": "2021-06-03",
        "Abstract": "The ruinous COVID-19 (Coronavirus disease) pandemic is the paramount issue prevalent in our world today. Social media serves as a common platform, where thoughts, experiences and essential information pertaining to COVID-19 could be shared. The primary objective of this project is to analyze using NLP (Natural Language Processing) techniques, the sentiments of users across various countries based on tweets posted during the pandemic, which could be beneficial for healthcare and government organizations to assess and address the needs of individuals and formulate policies accordingly. The sentiments of tweets are determined to be positive or negative based on analysis results obtained. Unlike existing research, a proper comparative sentiment analysis of COVID-19 related tweets has been performed to obtain conclusions regarding suitability of sentiment classification models and their respective accuracies. According to the proposed approach in this paper, a convolutional neural network and recurrent neural network is constructed for sentiment analysis based on text, which will help identify the growth in fear sentiment and negative sentiment with assured higher accuracy.",
        "DOI": "10.1109/ICOEI51242.2021.9453062",
        "affiliation_name": "Vellore Institute of Technology, Chennai",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Analyzing barriers of circular food supply chains and proposing industry 4.0 solutions",
        "paper_author": "Ada N.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "103",
        "cover_date": "2021-06-02",
        "Abstract": "The concept of the circular economy (CE) has gained importance worldwide recently since it offers a wider perspective in terms of promoting sustainable production and consumption with limited resources. However, few studies have investigated the barriers to CE in circular food supply chains. Accordingly, this paper presents a systematic literature review of 136 papers from 2010 to 2020 from WOS and Scopus databases regarding these barriers to understand CE implementation in food supply chains. The barriers are classified under seven categories: “cultural”, “business and business finance”, “regulatory and governmental”, “technological, “managerial”, “supply-chain management”, “knowledge and skills”. The findings show the need to identify barriers preventing the transition to CE. The findings also indicate that these challenges to CE can be overcome through Industry 4.0, which includes a variety of technologies, such as the Internet of Things (IoT), cloud technologies, machine learning, and blockchain. Specifically, machine learning can offer support by making workflows more efficient through the forecasting and analytical capabilities of food supply chains. Blockchain and big data analytics can provide the necessary support to establish legal systems and improve environmental regulations since transparency is a crucial issue for taxation and incentives systems. Thus, CE can be promoted via adequate laws, policies, and innovative technologies.",
        "DOI": "10.3390/su13126812",
        "affiliation_name": "Graphic Era Deemed to be University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Development of an intelligent decision support system for attaining sustainable growth within a life insurance company",
        "paper_author": "Khan M.F.",
        "publication": "Mathematics",
        "citied_by": "1",
        "cover_date": "2021-06-02",
        "Abstract": "Consumer behaviour is one of the most important and complex areas of research. It acknowledges the buying behaviour of consumer clusters towards any product, such as life insurance policies. Among various factors, the three most well-known determinants on which human conjecture depends for preferring a product are demographic, economic and psychographic factors, which can help in developing an accurate market design and strategy for the sustainable growth of a company. In this paper, the study of customer satisfaction with regard to a life insurance company is presented, which focused on comparing artificial intelligence-based, data-driven approaches to classical market segmentation approaches. In this work, an artificial intelligence-based decision support system was developed which utilises the aforementioned factors for the accurate classification of potential buyers. The novelty of this paper lies in developing supervised machine learning models that have a tendency to accurately identify the cluster of potential buyers with the help of demographic, economic and psychographic factors. By considering a combination of the factors that are related to the demographic, economic and psychographic elements, the proposed support vector machine model and logistic regression model-based decision support systems were able to identify the cluster of potential buyers with collective accuracies of 98.82% and 89.20%, respectively. The substantial accuracy of a support vector machine model would be helpful for a life insurance company which needs a decision support system for targeting potential customers and sustaining its share within the market.",
        "DOI": "10.3390/math9121369",
        "affiliation_name": "Middle East University Jordan",
        "affiliation_city": "Amman",
        "affiliation_country": "Jordan"
    },
    {
        "paper_title": "Machine learning-based prediction models for patients no-show in online outpatient appointments",
        "paper_author": "Fan G.",
        "publication": "Data Science and Management",
        "citied_by": "28",
        "cover_date": "2021-06-01",
        "Abstract": "With the development of information and communication technologies, all public tertiary hospitals in China began to use online outpatient appointment systems. However, the phenomenon of patient no-shows in online outpatient appointments is becoming more serious. The objective of this study is to design a prediction model for patient no-shows, thereby assisting hospitals in making relevant decisions, and reducing the probability of patient no-show behavior. We used 382,004 original online outpatient appointment records, and divided the data set into a training set (N1 ​= ​286,503), and a validation set (N2 ​= ​95,501). We used machine learning algorithms such as logistic regression, k-nearest neighbor (KNN), boosting, decision tree (DT), random forest (RF) and bagging to design prediction models for patient no-show in online outpatient appointments. The patient no-show rate of online outpatient appointment was 11.1% (N ​= ​42,224). From the validation set, bagging had the highest area under the ROC curve and AUC value, which was 0.990, followed by random forest and boosting models, which were 0.987 and 0.976, respectively. In contrast, compared with the previous prediction models, the area under ROC and AUC values of the logistic regression, decision tree, and k-nearest neighbors were lower at 0.597, 0.499 and 0.843, respectively. This study demonstrates the possibility of using data from multiple sources to predict patient no-shows. The prediction model results can provide decision basis for hospitals to reduce medical resource waste, develop effective outpatient appointment policies, and optimize operations.",
        "DOI": "10.1016/j.dsm.2021.06.002",
        "affiliation_name": "The University of Texas Rio Grande Valley",
        "affiliation_city": "Brownsville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Optimal Load Balancing with Locality Constraints",
        "paper_author": "Weng W.",
        "publication": "Performance Evaluation Review",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "Applications in cloud platforms motivate the study of efficient load balancing under job-server constraints and server heterogeneity. In this paper, we study load balancing on a bipartite graph where left nodes correspond to job types and right nodes correspond to servers, with each edge indicating that a job type can be served by a server. Thus edges represent locality constraints, i.e., an arbitrary job can only be served at servers which contain certain data and/or machine learning (ML) models. Servers in this system can have heterogeneous service rates. In this setting, we investigate the performance of two policies named Join-The-Fastest-of-The-Shortest-Queue (JFSQ) and Join-The-Fastest-of-The-Idle-Queue (JFIQ), which are simple variants of Join-The-Shortest-Queue and Join-The-Idle-Queue, where ties are broken in favor of the fastest servers. Under a \"well-connected'' graph condition, we show that JFSQ and JFIQ are asymptotically optimal in the mean response time when the number of servers goes to infinity. In addition to asymptotic optimality, we also obtain upper bounds on the mean response time for finite-size systems. We further show that the well-connectedness condition can be satisfied by a random bipartite graph construction with relatively sparse connectivity.",
        "DOI": "10.1145/3410220.3456279",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Context, Language Modeling, and Multimodal Data in Finance",
        "paper_author": "Das S.",
        "publication": "Journal of Financial Data Science",
        "citied_by": "3",
        "cover_date": "2021-06-01",
        "Abstract": "The authors enhance pretrained language models with Securities and Exchange Commission filings data to create better language representations for features used in a predictive model. Specifically, they train RoBERTa class models with additional financial regulatory text, which they denote as a class of RoBERTa-Fin models. Using different datasets, the authors assess whether there is material improvement over models that use only text-based numerical features (e.g., sentiment, readability, polarity), which is the traditional approach adopted in academia and practice. The RoBERTa-Fin models also outperform generic bidirectional encoder representations from transformers (BERT) class models that are not trained with financial text. The improvement in classification accuracy is material, suggesting that full text and context are important in classifying financial documents and that the benefits from the use of mixed data, (i.e., enhancing numerical tabular data with text) are feasible and fruitful in machine learning models in finance.",
        "DOI": "10.3905/jfds.2021.1.063",
        "affiliation_name": "The University of Chicago",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "PP-PG: Combining parameter perturbation with policy gradient methods for effective and efficient explorations in deep reinforcement learning",
        "paper_author": "Li S.",
        "publication": "ACM Transactions on Intelligent Systems and Technology",
        "citied_by": "4",
        "cover_date": "2021-06-01",
        "Abstract": "Efficient and stable exploration remains a key challenge for deep reinforcement learning (DRL) operating in high-dimensional action and state spaces. Recently, a more promising approach by combining the exploration in the action space with the exploration in the parameters space has been proposed to get the best of both methods. In this article, we propose a new iterative and close-loop framework by combining the evolutionary algorithm (EA), which does explorations in a gradient-free manner directly in the parameters space with an actor-critic, and the deep deterministic policy gradient (DDPG) reinforcement learning algorithm, which does explorations in a gradient-based manner in the action space to make these two methods cooperate in a more balanced and efficient way. In our framework, the policies represented by the EA population (the parametric perturbation part) can evolve in a guided manner by utilizing the gradient information provided by the DDPG and the policy gradient part (DDPG) is used only as a fine-tuning tool for the best individual in the EA population to improve the sample efficiency. In particular, we propose a criterion to determine the training steps required for the DDPG to ensure that useful gradient information can be generated from the EA generated samples and the DDPG and EA part can work together in a more balanced way during each generation. Furthermore, within the DDPG part, our algorithm can flexibly switch between fine-tuning the same previous RL-Actor and fine-tuning a new one generated by the EA according to different situations to further improve the efficiency. Experiments on a range of challenging continuous control benchmarks demonstrate that our algorithm outperforms related works and offers a satisfactory trade-off between stability and sample efficiency.",
        "DOI": "10.1145/3452008",
        "affiliation_name": "Naval University of Engineering",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Short-Term Traffic Forecasting: An LSTM Network for Spatial-Temporal Speed Prediction",
        "paper_author": "Abduljabbar R.L.",
        "publication": "Future Transportation",
        "citied_by": "23",
        "cover_date": "2021-06-01",
        "Abstract": "Traffic forecasting remains an active area of research in the transport and data science fields. Decision-makers rely on traffic forecasting models for both policy-making and operational management of transport facilities. The wealth of spatial and temporal real-time data increasingly available from traffic sensors on roads provides a valuable source of information for policymakers. This paper adopts the Long Short-Term Memory (LSTM) recurrent neural network to predict speed by considering both the spatial and temporal characteristics of real-time sensor data. A total of 288,653 real-life traffic measurements were collected from detector stations on the Eastern Freeway in Melbourne/Australia. A comparative performance analysis among different models such as the Recurrent Neural Network (RNN) that has an internal memory that is able to remember its inputs and Deep Learning Backpropagation (DLBP) neural network approaches are also reported. The LSTM results showed average accuracies in the outbound direction ranging between 88 and 99 percent over prediction horizons between 5 and 60 min, and average accuracies between 96 and 98 percent in the inbound direction. The models also showed resilience in accuracies as the prediction horizons increased spatially for distances up to 15 km, providing a remarkable performance compared to other models tested. These results demonstrate the superior performance of LSTM models in capturing the spatial and temporal traffic dynamics, providing decision-makers with robust models to plan and manage transport facilities more effectively.",
        "DOI": "10.3390/futuretransp1010003",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Deep Reinforcement Learning Control of White-Light Continuum Generation",
        "paper_author": "Valensise C.M.",
        "publication": "2021 Conference on Lasers and Electro-Optics Europe and European Quantum Electronics Conference, CLEO/Europe-EQEC 2021",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "Deep Reinforcement Learning (deep RL) is a branch of Machine Learning dealing with the solution of optimization problems, usually formalized as Markov Decision Processes [1]. At discrete temporal steps, an agent takes an action on the system receiving back a reward that depends on the state reached by the system. The goal of the agent is to determine an optimal policy, i.e. a map between states and actions, to maximise the future rewards, by directly experiencing and sampling the environment without any a-priori knowledge of the system. Among the various optimization algorithms, deep RL is particularly versatile thanks to the underlying neural networks [2] , a powerful universal approximator.",
        "DOI": "10.1109/CLEO/Europe-EQEC52157.2021.9592637",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Digital Trade And Artificial Intelligence: Role Of Intellectual Property",
        "paper_author": "Singh V.",
        "publication": "NTUT Journal of Intellectual Property Law and Management",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "In the era of globalization, the Artificial Intelligence has emerged as the most accepted technology with its application in various fields throughout the globe. The companies developing these Programmes endeavour to make their presence more known by carrying out more innovation and automation in technological and digital business. The present research proposal is aimed to study the intellectual property (IP) issues in relation to AI in digital medium. As an incentive to technological innovation and to reap the benefits of investment, it is essential to own and protect the Intellectual Property in all innovations. The ownership of intangible aspects of software innovation and protection of the data that forms part thereof, is a difficult question, the answer to which still remains behind a smokescreen. Different IP protection mechanisms recognized under various international documents are examined in this research for exploring the better and effective protection for AI and AI-based inventions. Protection of data is an important aspect and critical component of AI as its functioning mechanism is based upon machine learning techniques that use data for training and validation. With this research the authors paint a picture of the various difficulties encountered while looking for effective data protection measures. This research is an attempt to assess the efficiency of IP laws for protection of the data which forms part of AI technology, when the same is made the ‘subject’ of digital trade. It also aims to check whether any new policy measures are required under existing IP system for effective protection, due to revolution in digital world. The present study focuses on the aspect that any new or existing policy in IP should encourage the free flow of data for uninterrupted functioning of AI without affecting the right to privacy or security",
        "DOI": "NA",
        "affiliation_name": "Guru Gobind Singh Indraprastha University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Solving two-stage stochastic route-planning problem in milliseconds via end-to-end deep learning",
        "paper_author": "Zheng J.",
        "publication": "Complex and Intelligent Systems",
        "citied_by": "19",
        "cover_date": "2021-06-01",
        "Abstract": "With the rapid development of e-economy, ordering via online food delivery platforms has become prevalent in recent years. Nevertheless, the platforms are facing lots of challenges such as time-limitation and uncertainty. This paper addresses a complex stochastic online route-planning problem (SORPP) which is mathematically formulated as a two-stage stochastic programming model. To meet the immediacy requirement of online fashion, an end-to-end deep learning model is designed which is composed of an encoder and a decoder. To embed different problem-specific features, different network layers are adopted in the encoder; to extract the implicit relationship, the probability mass functions of stochastic food preparation time is processed by a convolution neural network layer; to provide global information, the location map and rider features are handled by the factorization-machine (FM) and deep FM layers, respectively; to screen out valuable information, the order features are embedded by attention layers. In the decoder, the permutation sequence is predicted by long-short term memory cells with attention and masking mechanism. To learn the policy for finding optimal permutation under complex constraints of the SORPP, the model is trained in a supervised learning way with the labels obtained by iterated greedy search algorithm. Extensive experiments are conducted based on real-world data sets. The comparative results show that the proposed model is more efficient than meta-heuristics and is able to yield higher quality solutions than heuristics. This work provides an intelligent optimization technique for complex online food delivery system.",
        "DOI": "10.1007/s40747-021-00288-y",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A bayesian approach to insider threat detection",
        "paper_author": "Wall A.",
        "publication": "Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications",
        "citied_by": "9",
        "cover_date": "2021-06-01",
        "Abstract": "Insider attacks are an ever-increasing threat for organizations, with dire consequences. Rogue employees who possess legitimate access to systems, and knowledge of security policies and monitoring practices of organizations, can evade detection. Organizations remain ill-equipped in detecting, deterring and mitigating sophisticated insider attacks, as traditional security controls and detection systems are tailored to external threats. Literature on insider threat detection provides the theoretical foundation to understand the motives, behavior and patterns of insider attacks. The majority of proposed models for insider threat anomaly detection, mainly focus on processing network data. In this paper, we propose and evaluate a Bayesian Network architecture that can consider behavioral aspects in tandem with network data. Our system utilizes machine learning to understand the structure of the data, inputs specially crafted features based on theoretical foundations of insider threat and enables analysts to consider behavioral features, if such data is available. We applied our system on CMU’s synthetic dataset and our results provide justified and informed decisions on selecting parameters for Bayesian Networks and suggest that such an approach is highly effective. All attacks in the dataset were identified, with a very low number of false positives.",
        "DOI": "10.22667/JOWUA.2021.06.30.048",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Control of a polyol process using reinforcement learning",
        "paper_author": "Zhu W.",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "6",
        "cover_date": "2021-06-01",
        "Abstract": "Reinforcement learning is a branch of machine learning, where an agent gradually learns a control policy via a combination of exploration and interactions with a system. Recent successes of model-free reinforcement learning (RL) has attracted tremendous attention from the process control community. For instance, RL has been successfully applied in very complex control tasks (e.g., games such as chess or Go that contain large state spaces) and is shown to be robust to uncertainties. These findings indicate that there is a significant potential to leverage RL methods to improve the control of chemical processes. In this work, RL was applied to a detailed and accurate simulation of an industrial polyol process. To manufacture the desired product, the RL controller is required to achieve the target ending conditions determined by four key parameters; meanwhile, economic factors are also considered in this process, including batch reaction time and total feed amounts. The obtained results show a high consistency between RL and the current optimal operating conditions. Additionally, an improvement opportunity was identified by extending current control bounds of the manipulated variables. This work illustrates that RL is capable of handling complicated industrial systems, even under realistic operating constraints.",
        "DOI": "10.1016/j.ifacol.2021.08.291",
        "affiliation_name": "Cain Department of Chemical Engineering",
        "affiliation_city": "Baton Rouge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Adversarial Attacks on CFO-Based Continuous Physical Layer Authentication: A Game Theoretic Study",
        "paper_author": "Saritas S.",
        "publication": "IEEE International Conference on Communications",
        "citied_by": "4",
        "cover_date": "2021-06-01",
        "Abstract": "5G and beyond 5G low power wireless networks make Internet of Things (IoT) and Cyber-Physical Systems (CPS) applications capable of serving massive amounts of devices and machines. Due to the broadcast nature of wireless networks, it is crucial to secure the communication between these devices and machines from spoofing and interception attacks. This paper is concerned with the security of carrier frequency offset (CFO) based continuous physical layer authentication. The interaction between an attacker and a defender is modeled as a dynamic discrete leader-follower game with imperfect information. In the considered model, a legitimate user (Alice) communicates with the defender/operator (Bob) and is authorized by her CFO continuously. The attacker (Eve), by listening/eavesdropping the communication between Alice and Bob, tries to learn the CFO characteristics of Alice and aims to inject malicious packets to Bob by impersonating Alice. First, by showing that the optimal attacker strategy is a threshold policy, an optimization problem of the attacker with exponentially growing action space is reduced to a tractable integer optimization problem with a single parameter, then the corresponding defender cost is derived. Extensive simulations illustrate the characteristics of optimal strategies/utilities of the players depending on the actions, and show that the defender's optimal false positive rate causes attack success probabilities to be in the order of 0.99. The results show the importance of the parameters while finding the balance between system security and efficiency.",
        "DOI": "10.1109/ICC42927.2021.9500824",
        "affiliation_name": "The Royal Institute of Technology (KTH)",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Collaborative Partially-Observable Reinforcement Learning Using Wireless Communications",
        "paper_author": "Ko E.",
        "publication": "IEEE International Conference on Communications",
        "citied_by": "3",
        "cover_date": "2021-06-01",
        "Abstract": "Each robot utilizes the reinforcement learning (RL) to control its maneuver and these robots can collaborate to accomplish a common goal to form a collaborative multi-agent system (MAS). Due to the constraints of distributive locations and different poses of robots, in practice, each agent (robot) in such a collaborative MAS can only partially observe the environment and other agents (such as competitive agents), and consequently operate based on its belief of the state(s). The alignment of the beliefs of collaborative agents can be therefore enhanced by adopting wireless communications, but is rarely studied in literature. To explore wireless communications applied to collaborative partially-observable reinforcement learning (PORL), we propose that each collaborative agent predicts the environment dynamics, including the behavior of those agents outside the collaborative MAS, and then constructs the learning-based belief of the world (i.e. global state). To assist such prediction and learning, we modify the RL assisted by the wireless communication functionality into two stages: prediction of the state and local actor-and-critic on global value(s). In other words, while one agent predicts and learns its own policy, another agent can updates critics on the sequence of history to update global value(s) that can further assist to validate the prediction. From numerical experiments, we find that the timing of communication or information exchange among collaborative agents has critical impact on the duration of learning and prediction, and thus the performance of MAS, which suggests the desirable communication for distributed PORL among collaborative agents toward an efficient MAS.",
        "DOI": "10.1109/ICC42927.2021.9500922",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Tampa",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Security-Constrained Reinforcement Learning Framework for Software Defined Networks",
        "paper_author": "Mudgerikar A.",
        "publication": "IEEE International Conference on Communications",
        "citied_by": "6",
        "cover_date": "2021-06-01",
        "Abstract": "Reinforcement Learning (RL) is an effective technique for building 'smart' SDN controllers because of its model-free nature and ability to learn policies online without requiring extensive training data. However, as RL agents are geared to maximize functionality and explore the environment without constraints, security can be breached. In this paper, we propose Jarvis-SDN, a RL framework that constrains explorations by taking security into account. In Jarvis-SDN, the RL agent learns 'intelligent policies' which maximize functionality but not at the cost of security. Standard network flow based attack sig-natures obtained from intrusion detection system (IDS) datasets cannot be used as policies because they do not conform to the state model of the RL framework and thus have poor accuracy and high false positives. To address such issue, the security policies for constraining explorations in Jarvis-SDN are learnt in a semi-supervised manner in the form of 'partial attack signatures' from packet captures of IDS datasets that are then encoded in the objective function of the RL based optimization framework. These signatures are learnt using Deep Q-Networks (DQN). Our analysis shows that DQN based attack signatures perform better than classical machine learning techniques, like decision trees, random forests and deep neural networks (DNN), for common network attacks. We instantiate our framework for a SDN controller with the goal of intelligent rate control to further analyze the effectiveness of the attack signatures.",
        "DOI": "10.1109/ICC42927.2021.9500763",
        "affiliation_name": "Purdue University",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Achieving Robust Performance for Traffic Classification Using Ensemble Learning in SDN Networks",
        "paper_author": "Yang T.",
        "publication": "IEEE International Conference on Communications",
        "citied_by": "7",
        "cover_date": "2021-06-01",
        "Abstract": "Software-defined networking (SDN) enables centralized control of a network of programmable switches by dynamically updating flow rules. This paves the way for dynamic and autonomous control of the network. In order to be able to apply a suitable set of policies to the correct set of traffic flows, SDN needs input from traffic classification mechanisms. Today, there is a variety of classification algorithms in machine learning. However, recent studies have found that using an arbitrary algorithm does not necessarily provide the best classification outcome on a dataset, and therefore a framework called ensemble which combines individual algorithms to improve classification results has gained attraction. In this paper, we propose the application of the ensemble algorithm as a machine learning pre-processing tool, which classifies ingress network traffic for SDN to pick the right set of traffic policies. Performance evaluation results show that this ensemble classifier can achieve robust performance in all tested traffic types.",
        "DOI": "10.1109/ICC42927.2021.9500571",
        "affiliation_name": "University of Surrey",
        "affiliation_city": "Guildford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Designing Adversarial Attack and Defence for Robust Android Malware Detection Models",
        "paper_author": "Rathore H.",
        "publication": "Proceedings - 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume, DSN-S 2021",
        "citied_by": "3",
        "cover_date": "2021-06-01",
        "Abstract": "The last decade witnessed an exponential rise of Android smartphones and malware attacks on them. Researchers have investigated and proposed many promising malware detection models based on machine learning. However, these malware detection models are susceptible to adversarial attacks which threaten the Android security ecosystem. In this article, we propose to develop malware detection models which are more robust against adversarial attacks. We first designed an i-bit adversarial attack policy which achieved an average fooling rate of 51% with maximum ten modifications across twelve different malware detection models. Later we also propose an adversarial defence mechanism which enhanced the robustness of the malware detection models by reducing the fooling rate to one-Third against the same adversarial attack.",
        "DOI": "10.1109/DSN-S52858.2021.00025",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India"
    },
    {
        "paper_title": "iCovidCare: Intelligent health monitoring framework for COVID-19 using ensemble random forest in edge networks",
        "paper_author": "Adhikari M.",
        "publication": "Internet of Things (Netherlands)",
        "citied_by": "19",
        "cover_date": "2021-06-01",
        "Abstract": "The COVID-19 outbreak is in its growing stage due to the lack of standard diagnosis for the patients. In recent times, various models with machine learning have been developed to predict and diagnose novel coronavirus. However, the existing models fail to take an instant decision for detecting the COVID-19 patient immediately and cannot handle multiple medical sensor data for disease prediction. To handle such challenges, we propose an intelligent health monitoring and prediction framework, namely the iCovidCare model for predicting the health status of COVID-19 patients using the ensemble Random Forest (eRF) technique in edge networks. In the proposed framework, a rule-based policy is designed on the local edge devices to detect the risk factor of a patient immediately using monitoring Temperature sensor values. The real-time health monitoring parameters of different medical sensors are transmitted to the centralized cloud servers for future health prediction of the patients. The standard eRF technique is used to predict the health status of the patients using the proposed data fusion and feature selection strategy by selecting the most significant features for disease prediction. The proposed iCovidCare model is evaluated with a synthetic COVID-19 dataset and compared with the standard classification models based on various performance matrices to show its effectiveness. The proposed model has achieved 95.13% accuracy, which is higher than the standard classification models.",
        "DOI": "10.1016/j.iot.2021.100385",
        "affiliation_name": "Tartu Ülikool",
        "affiliation_city": "Tartu",
        "affiliation_country": "Estonia"
    },
    {
        "paper_title": "NN-Baton: DNN workload orchestration and chiplet granularity exploration for multichip accelerators",
        "paper_author": "Tan Z.",
        "publication": "Proceedings - International Symposium on Computer Architecture",
        "citied_by": "39",
        "cover_date": "2021-06-01",
        "Abstract": "The revolution of machine learning poses an unprecedented demand for computation resources, urging more transistors on a single monolithic chip, which is not sustainable in the Post-Moore era. The multichip integration with small functional dies, called chiplets, can reduce the manufacturing cost, improve the fabrication yield, and achieve die-level reuse for different system scales. DNN workload mapping and hardware design space exploration on such multichip systems are critical, but missing in the current stage.This work provides a hierarchical and analytical framework to describe the DNN mapping on a multichip accelerator and analyze the communication overhead. Based on this framework, we propose an automatic tool called NN-Baton with a pre-design flow and a post-design flow. The pre-design flow aims to guide the chiplet granularity exploration with given area and performance budgets for the target workload. The post-design flow focuses on the workload orchestration on different computation levels -package, chiplet, and core - in the hierarchy. Compared to Simba, NN-Baton generates mapping strategies that save 22.5%∼44% energy under the same computation and memory configurations.The architecture exploration demonstrates that area is a decisive factor for the chiplet granularity. For a 2048-MAC system under a 2 mm2 chiplet area constraint, the 4-chiplet implementation with 4 cores and 16 lanes of 8-size vector-MAC is always the top-pick computation allocation across several benchmarks. In contrast, the optimal memory allocation policy in the hierarchy typically depends on the neural network models.",
        "DOI": "10.1109/ISCA52012.2021.00083",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Hetero-ViTAL: A virtualization stack for heterogeneous FPGA clusters",
        "paper_author": "Zha Y.",
        "publication": "Proceedings - International Symposium on Computer Architecture",
        "citied_by": "16",
        "cover_date": "2021-06-01",
        "Abstract": "With field-programmable gate arrays (FPGAs) being widely deployed into data centers, an efficient virtualization support is required to fully unleash the potential of cloud FPGAs. Nevertheless, existing FPGA virtualization solutions only support a homogeneous FPGA cluster comprising identical FPGA devices. Representative work such as ViTAL provides sufficient system support for scale-out acceleration and improves the overall resource utilization through a fine-grained spatial sharing. While these existing solutions (including ViTAL) can efficiently virtualize a homogeneous cluster, it is hard to extend them to virtualizing a heterogeneous cluster which comprises multiple types of FPGAs. We expect the future cloud FPGAs are likely to be more heterogeneous due to hardware rolling upgrade.In this paper, we rethink FPGA virtualization from ground up and propose Hetero-ViTAL to virtualize heterogeneous FPGA clusters. We identify the conflicting requirements of runtime management and offline compilation when designing the abstraction for a heterogeneous cluster, which is also the fundamental reason why the single-level abstraction as proposed in ViTAL (and other prior works) cannot be trivially extended to the heterogeneous case. To decouple these conflicting requirements, we provide a two-level system abstraction in Hetero-ViTAL. Specifically, the high-level abstraction is FPGA-agnostic and provides a simple and homogeneous view of the FPGA resources to simplify the runtime management. On the contrary, the low-level abstraction is FPGA-specific and exposes sufficient spatial resource constraints to the compilation framework to ensure the mapping quality. Rather than simply adding a layer on top of the single-level abstraction as proposed in ViTAL and other prior work, we judiciously determine how much hardware details should be exposed at each level to balance the management complexity, mapping quality and compilation cost. We then develop a compilation framework to map applications onto this two-level abstraction with several optimization techniques to further improve the mapping quality. We also provide a runtime management policy to alleviate the fragmentation issue, which becomes more severe in a heterogeneous cluster due to the distinct resource capacities of diverse FPGAs.We evaluate Hetero-ViTAL on a custom-built FPGA cluster and demonstrate its effectiveness using machine learning and image processing applications. Results show that Hetero-ViTAL reduces the average response time (a critical metric for QoS) by 79.2% for a heterogeneous cluster compared to the non-virtualized baseline. When virtualizing a homogeneous cluster, Hetero-ViTAL also reduces the average response time by 42.0% compared with ViTAL due to a better system design.",
        "DOI": "10.1109/ISCA52012.2021.00044",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using Control Theory and Bayesian Reinforcement Learning for Policy Management in Pandemic Situations",
        "paper_author": "Rathore H.",
        "publication": "2021 IEEE International Conference on Communications Workshops, ICC Workshops 2021 - Proceedings",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "As engineers and scientists, it is our responsibility to learn lessons from the recent pandemic outbreak and see how public health policies can be effectively managed to reduce the severe loss of lives and minimize the impact on people's livelihood. Non-pharmaceutical interventions, such as in-place sheltering and social distancing, are typically introduced to slow the spread (flatten the curve) and reverse the growth of the virus. However, such approaches have the unintended consequences of causing economic activities to plummet and bringing local businesses to a standstill, thereby putting millions of jobs at risk. City administrators have generally resorted to an open loop, belief-based decision-making process, thereby struggling to manage (identify and enforce) timely and optimal policies. To overcome this challenge, this position paper explores a systematically designed, feedback-based strategy, to modulate parameters that control suppression and mitigation. Our work leverages advances in Bayesian Reinforcement Learning algorithms and known techniques in control theory, to stabilize and diminish the rate of propagation in pandemic situations. This paper discusses how offline exploitation using pre-trigger data, online exploration using observations from the environment, and a careful orchestration between the two using granular control of multiple on-off control signals can be used to modulate policy enforcement based on established metrics, such as reproduction number.",
        "DOI": "10.1109/ICCWorkshops50388.2021.9473604",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Decentralized Federated Learning for Road User Classification in Enhanced V2X Networks",
        "paper_author": "Barbieri L.",
        "publication": "2021 IEEE International Conference on Communications Workshops, ICC Workshops 2021 - Proceedings",
        "citied_by": "19",
        "cover_date": "2021-06-01",
        "Abstract": "Federated Learning (FL) techniques are emerging in the automotive context to support connected automated driving services. Yet, when applied to vehicular use cases, conventional centralized FL policies show some drawbacks in terms of latency and scalability. This paper focuses on decentralized FL solutions, which attempt to overcome such limitations, by introducing a distributed computing architecture: vehicles exchange the parameters of a shared Machine Learning (ML) model via V2V links, without the need of a central orchestrator. Sharing all ML parameters, however, might not be feasible when minimal V2X bandwidth usage is required or the model is highly complex (e.g., extremely deep networks) as in advanced scenarios for high levels of automation. We thus propose a modular decentralized FL solution and we discuss its application to road user classification in a cooperative vehicular sensing use case. The proposed FL solution performs the point cloud processing of Lidar sensor inputs using a PointNet compliant architecture. It enables the exchange of a subset of the model parameters, namely selected ML model layers, optimized for communication efficiency, convergence and accuracy. We use real sensor data extracted from a publicly available dataset to validate the method, focusing on non-uniform scenarios where sensor data are highly unbalanced across the connected vehicles. For all cases, FL is shown to outperform the ego-sensing approach with minimal bandwidth usage.",
        "DOI": "10.1109/ICCWorkshops50388.2021.9473581",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Path Design for NOMA-Enhanced Robots: A Machine Learning Approach with Radio Map",
        "paper_author": "Zhong R.",
        "publication": "2021 IEEE International Conference on Communications Workshops, ICC Workshops 2021 - Proceedings",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "A communication enabled indoor intelligent robots (IRs) service framework is proposed, where the non-orthogonal multiple access (NOMA) technique is adopted to enhance the data rate and user fairness. Build on the proposed communication model, motions of IRs and the down-link power allocation policy are jointly optimized to maximize the mission efficiency and communication reliability of IRs. In an effort to find the optimal path for IRs from the initial point to their mission destinations, a novel reinforcement learning approach named deep transfer deterministic policy gradient (DT-DPG) algorithm is proposed. In order to save the training time and hardware costs, the radio map is investigated and provided to the agent as a virtual training environment. Our simulation demonstrates that 1) The participation of the NOMA technique effectively improves the communication reliability of IRs; 2) The radio map is qualified to be a virtual training environment, and its statistical channel state information improves training efficiency by about 30%; 3) The proposed algorithm is superior to the deep deterministic policy gradient (DDPG) algorithm in terms of the optimization performance, training time, and anti-local optimum ability.",
        "DOI": "10.1109/ICCWorkshops50388.2021.9473594",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Benefit-Cost analysis of social media facilitated bystander programs",
        "paper_author": "Ebers A.",
        "publication": "Journal of Benefit-Cost Analysis",
        "citied_by": "2",
        "cover_date": "2021-06-01",
        "Abstract": "Bystander programs contribute to crime prevention by motivating people to intervene in violent situations. Social media allow addressing very specific target groups, and provide valuable information for program evaluation. This paper provides a conceptual framework for conducting benefit-cost analysis of bystander programs and puts a particular focus on the use of social media for program dissemination and data collection. The benefit-cost model treats publicly funded programs as investment projects and calculates the benefit-cost ratio. Program benefit arises from the damages avoided by preventing violent crime. We provide systematic instructions for estimating this benefit. The explained estimation techniques draw on social media data, machine-learning technology, randomized controlled trials and discrete choice experiments. In addition, we introduce a complementary approach with benefits calculated from the public attention generated by the program. To estimate the value of public attention, the approach uses the bid landscaping method, which originates from display advertising. The presented approaches offer the tools to implement a benefit-costs analysis in practice. The growing importance of social media for the dissemination of policy programs requires new evaluation methods. By providing two such methods, this paper contributes to evidence-based decisionmaking in a growing policy area.",
        "DOI": "10.1017/bca.2020.34",
        "affiliation_name": "Gottfried Wilhelm Leibniz Universität Hannover",
        "affiliation_city": "Hannover",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "A Study of Learning Search Approximation in Mixed Integer Branch and Bound: Node Selection in SCIP",
        "paper_author": "Yilmaz K.",
        "publication": "AI (Switzerland)",
        "citied_by": "19",
        "cover_date": "2021-06-01",
        "Abstract": "In line with the growing trend of using machine learning to help solve combinatorial optimisation problems, one promising idea is to improve node selection within a mixed integer programming (MIP) branch-and-bound tree by using a learned policy. Previous work using imitation learning indicates the feasibility of acquiring a node selection policy, by learning an adaptive node searching order. In contrast, our imitation learning policy is focused solely on learning which of a node’s children to select. We present an offline method to learn such a policy in two settings: one that comprises a heuristic by committing to pruning of nodes; one that is exact and backtracks from a leaf to guarantee finding the optimal integer solution. The former setting corresponds to a child selector during plunging, while the latter is akin to a diving heuristic. We apply the policy within the popular open-source solver SCIP, in both heuristic and exact settings. Empirical results on five MIP datasets indicate that our node selection policy leads to solutions significantly more quickly than the state-of-the-art precedent in the literature. While we do not beat the highly-optimised SCIP state-of-practice baseline node selector in terms of solving time on exact solutions, our heuristic policies have a consistently better optimality gap than all baselines, if the accuracy of the predictive model is sufficient. Further, the results also indicate that, when a time limit is applied, our heuristic method finds better solutions than all baselines in the majority of problems tested. We explain the results by showing that the learned policies have imitated the SCIP baseline, but without the latter’s early plunge abort. Our recommendation is that, despite the clear improvements over the literature, this kind of MIP child selector is better seen in a broader approach to using learning in MIP branch-and-bound tree decisions.",
        "DOI": "10.3390/ai2020010",
        "affiliation_name": "Faculteit Elektrotechniek, Wiskunde en Informatica, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Modelling of activity-travel pattern with support vector machine",
        "paper_author": "Alex A.P.",
        "publication": "European Transport - Trasporti Europei",
        "citied_by": "1",
        "cover_date": "2021-06-01",
        "Abstract": "Activity based travel demand modelling involves lot of uncertainty due to the complex and varying decision making behaviour of each individual. This study contributes to the literature by assessing the suitability of Support Vector Machine (SVM) in modelling the activity pattern and travel behaviour of workers. Activity and travel behaviour of workers consists of decision outcomes, which can be modelled as classification and regression problems. SVM is a good classifier and regressor with good testing and learning capability, hence the present study used SVM for modelling. It was found that support vector machine models are well performing to predict the activity pattern and travel behaviour of workers. The SVM models developed in the study predicts the temporal variation of mode wise work activity generation. Prediction of temporal mode share of commuters is advantageous to policy makers to experiment the implementation of temporary Travel Demand Management (TDM) actions effectively.",
        "DOI": "10.48295/ET.2021.82.2",
        "affiliation_name": "Hindustan Institute of Technology and Science",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Strengthening biopharma's resilience",
        "paper_author": "Van Parys F.",
        "publication": "Pharmaceutical Outsourcing",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "NA",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Automatic first-arrival picking method via intelligent Markov optimal decision processes",
        "paper_author": "Luo F.",
        "publication": "Journal of Geophysics and Engineering",
        "citied_by": "7",
        "cover_date": "2021-06-01",
        "Abstract": "Picking the first arrival is an important step in seismic processing. The large volume of the seismic data calls for automatic and objective picking. In this paper, we formulate first-arrival picking as an intelligent Markov decision process in the multi-dimensional feature attribute space. By designing a reasonable model, the global optimization is carried out in the reward function space to obtain the path with the largest cumulative reward value, to achieve the purpose of automatically picking up the first arrival. The state-value function contains a distance-related discount factor γ, which enables the Markov decision process to pick up the first-arrival continuity to consider the lateral continuity of the seismic data and avoid the bad trace information in the seismic data. On this basis, the method of this paper further introduces the optimized model that is a fuzzy clustering-based multi-dimensional attribute reward function and structure-based Gaussian stochastic policy, thereby reducing the difficulty of model design, and making the seismic data pick up more accurately and automatically. Testing this approach in the field seismic data reveals its properties and shows it can automatically pick up more reasonable first arrivals and has a certain quality control ability, especially the first-arrival energy is weak (the signal-to-noise ratio is low) or there are adjacent complex waveforms in the shallow layer.",
        "DOI": "10.1093/jge/gxab026",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Proximal policy optimization-based join order optimization with spark SQL",
        "paper_author": "Lee K.M.",
        "publication": "IEIE Transactions on Smart Processing and Computing",
        "citied_by": "0",
        "cover_date": "2021-06-01",
        "Abstract": "In a smart grid, massive amounts of data are generated during the production, transmission, and consumption of electricity. Often, complex and varied queries with multiple join and selection operations need to be run on such data. Several studies have focused on improving the performance of query evaluation by applying machine learning techniques to query optimization problems. However, these studies are limited to processing queries for data in a single environment. In this paper, we propose a Proximal Policy Optimization (PPO)-based join order optimization model for use on Spark SQL to improve the retrieval performance for large amounts of data. The model uses the cost computation method of Spark SQL for training with the costs of the join plans generated by the model as rewards. The model can find more join plans with lower costs than the plans that Spark SQL finds because Spark SQL is limited to a low search space. We demonstrate that the proposed model generates join plans with similar or lower costs than Spark SQL without executing the optimization algorithm of Spark SQL.",
        "DOI": "10.5573/IEIESPC.2021.10.3.227",
        "affiliation_name": "Chungnam National University",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A unified schedule policy of distributed machine learning framework for CPU-GPU cluster",
        "paper_author": "Zhu Z.",
        "publication": "Xibei Gongye Daxue Xuebao/Journal of Northwestern Polytechnical University",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "With the widespread using of GPU hardware facilities, more and more distributed machine learning applications have begun to use CPU-GPU hybrid cluster resources to improve the efficiency of algorithms. However, the existing distributed machine learning scheduling framework either only considers task scheduling on CPU resources or only considers task scheduling on GPU resources. Even considering the difference between CPU and GPU resources, it is difficult to improve the resource usage of the entire system. In other words, the key challenge in using CPU-GPU clusters for distributed machine learning jobs is how to efficiently schedule tasks in the job. In the full paper, we propose a CPU-GPU hybrid cluster schedule framework in detail. First, according to the different characteristics of the computing power of the CPU and the computing power of the GPU, the data is divided into data fragments of different sizes to adapt to CPU and GPU computing resources. Second, the paper introduces the task scheduling method under the CPU-GPU hybrid. Finally, the proposed method is verified at the end of the paper. After our verification for K-Means, using the CPU-GPU hybrid computing framework can increase the performance of K-Means by about 1.5 times. As the number of GPUs increases, the performance of K-Means can be significantly improved.",
        "DOI": "10.1051/jnwpu/20213930529",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "MABWISER: Parallelizable Contextual Multi-armed Bandits",
        "paper_author": "Strong E.",
        "publication": "International Journal on Artificial Intelligence Tools",
        "citied_by": "6",
        "cover_date": "2021-06-01",
        "Abstract": "Contextual multi-armed bandit algorithms are an effective approach for online sequential decision-making problems. However, there are limited tools available to support their adoption in the community. To fill this gap, we present an open-source Python library with context-free, parametric and non-parametric contextual multi-armed bandit algorithms. The MABWiser library is designed to be user-friendly and supports custom bandit algorithms for specific applications. Our design provides built-in parallelization to speed up training and testing for scalability with special attention given to ensuring the reproducibility of results. The API makes hybrid strategies possible that combine non-parametric policies with parametric ones, an area that is not explored in the literature. As a practical application, we demonstrate using the library in both batch and online simulations for context-free, parametric and non-parametric contextual policies with the well-known MovieLens data set. Finally, we quantify the performance benefits of built-in parallelization.",
        "DOI": "10.1142/S0218213021500214",
        "affiliation_name": "Fidelity Investments",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Survey on Causal Inference",
        "paper_author": "Yao L.",
        "publication": "ACM Transactions on Knowledge Discovery from Data",
        "citied_by": "320",
        "cover_date": "2021-06-01",
        "Abstract": "Causal inference is a critical research topic across many domains, such as statistics, computer science, education, public policy, and economics, for decades. Nowadays, estimating causal effect from observational data has become an appealing research direction owing to the large amount of available data and low budget requirement, compared with randomized controlled trials. Embraced with the rapidly developed machine learning area, various causal effect estimation methods for observational data have sprung up. In this survey, we provide a comprehensive review of causal inference methods under the potential outcome framework, one of the well-known causal inference frameworks. The methods are divided into two categories depending on whether they require all three assumptions of the potential outcome framework or not. For each category, both the traditional statistical methods and the recent machine learning enhanced methods are discussed and compared. The plausible applications of these methods are also presented, including the applications in advertising, recommendation, medicine, and so on. Moreover, the commonly used benchmark datasets as well as the open-source codes are also summarized, which facilitate researchers and practitioners to explore, evaluate and apply the causal inference methods.",
        "DOI": "10.1145/3444944",
        "affiliation_name": "Alibaba Group Holding Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Host-Based Virtual Machine Workload Characterization Using Hypervisor Trace Mining",
        "paper_author": "Nemati H.",
        "publication": "ACM Transactions on Modeling and Performance Evaluation of Computing Systems",
        "citied_by": "3",
        "cover_date": "2021-06-01",
        "Abstract": "Cloud computing is a fast-growing technology that provides on-demand access to a pool of shared resources. This type of distributed and complex environment requires advanced resource management solutions that could model virtual machine (VM) behavior. Different workload measurements, such as CPU, memory, disk, and network usage, are usually derived from each VM to model resource utilization and group similar VMs. However, these course workload metrics require internal access to each VM with the available performance analysis toolkit, which is not feasible with many cloud environments privacy policies. In this article, we propose a non-intrusive host-based virtual machine workload characterization using hypervisor tracing. VM blockings duration, along with virtual interrupt injection rates, are derived as features to reveal multiple levels of resource intensiveness. In addition, the VM exit reason is considered, as well as the resource contention rate due to the host and other VMs. Moreover, the processes and threads preemption rates in each VM are extracted using the collected tracing logs. Our proposed approach further improves the selected features by exploiting a page ranking based algorithm to filter non-important processes running on each VM. Once the metric features are defined, a two-stage VM clustering technique is employed to perform both coarse- and fine-grain workload characterization. The inter-cluster and intra-cluster similarity metrics of the silhouette score is used to reveal distinct VM workload groups, as well as the ones with significant overlap. The proposed framework can provide a detailed vision of the underlying behavior of the running VMs. This can assist infrastructure administrators in efficient resource management, as well as root cause analysis.",
        "DOI": "10.1145/3460197",
        "affiliation_name": "Polytechnique Montréal",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A Virtual Network Embedding Algorithm Based on Double-Layer Reinforcement Learning",
        "paper_author": "Li M.",
        "publication": "Computer Journal",
        "citied_by": "7",
        "cover_date": "2021-06-01",
        "Abstract": "Virtual network embedding (VNE) algorithms dominate the effectiveness of resource sharing in network virtualization. Heuristic embedding algorithms generally make embedding decisions by artificially specified strategies, in which the node importance is measured by simply summing or multiplying several node attributes. However, the contributions of different attributes may be combined through complex functional relationships. The reinforcement learning-based VNE algorithms can optimize node embedding. However, the existing algorithms only consider the local node attributes, and only simple shortest path-based embedding policy is adopted for link embedding, resulting limited embedding effects. To overcome the above defects, we propose a double-layer reinforcement learning-based VNE algorithm (DRL-VNE). In DRL-VNE, both the global and local node attributes are extracted to represent the status of network nodes, then a policy network is constructed to optimize node embedding, and the other policy network is designed to optimize link embedding. The performance of DRL-VNE is evaluated under different network scenarios and is compared with that of heuristic and machine learning-based VNE algorithms. Simulation results show that in hierarchical network scenario, the request acceptance ratio and the resource utilization of DRL-VNE are respectively improved by 14% and by 27% compared with the best performance comparison algorithm.",
        "DOI": "10.1093/comjnl/bxab040",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Identifying urban poverty using high-resolution satellite imagery and machine learning approaches: Implications for housing inequality",
        "paper_author": "Li G.",
        "publication": "Land",
        "citied_by": "18",
        "cover_date": "2021-06-01",
        "Abstract": "Enriching Asian perspectives on the rapid identification of urban poverty and its implications for housing inequality, this paper contributes empirical evidence about the utility of image features derived from high-resolution satellite imagery and machine learning approaches for identifying urban poverty in China at the community level. For the case of the Jiangxia District and Huangpi District of Wuhan, image features, including perimeter, line segment detector (LSD), Hough transform, gray-level cooccurrence matrix (GLCM), histogram of oriented gradients (HoG), and local binary patterns (LBP), are calculated, and four machine learning approaches and 25 variables are applied to identify urban poverty and relatively important variables. The results show that image features and machine learning approaches can be used to identify urban poverty with the best model performance with a coefficient of determination, R2, of 0.5341 and 0.5324 for Jiangxia and Huangpi, respectively, although some differences exist among the approaches and study areas. The importance of each variable differs for each approach and study area; however, the relatively important variables are similar. In particular, four variables achieved relatively satisfactory prediction results for all models and presented obvious differences in varying communities with different poverty levels. Housing inequality within low-income neighborhoods, which is a response to gaps in wealth, income, and housing affordability among social groups, is an important manifestation of urban poverty. Policy makers can implement these findings to rapidly identify urban poverty, and the findings have potential applications for addressing housing inequality and proving the rationality of urban planning for building a sustainable society.",
        "DOI": "10.3390/land10060648",
        "affiliation_name": "China University of Mining and Technology",
        "affiliation_city": "Xuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A typology of existing machine learning-based predictive analytic tools focused on reducing costs and improving quality in health care: Systematic search and content analysis",
        "paper_author": "Nichol A.A.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "14",
        "cover_date": "2021-06-01",
        "Abstract": "Background: Considerable effort has been devoted to the development of artificial intelligence, including machine learning-based predictive analytics (MLPA) for use in health care settings. The growth of MLPA could be fueled by payment reforms that hold health care organizations responsible for providing high-quality, cost-effective care. Policy analysts, ethicists, and computer scientists have identified unique ethical and regulatory challenges from the use of MLPA in health care. However, little is known about the types of MLPA health care products available on the market today or their stated goals. Objective: This study aims to better characterize available MLPA health care products, identifying and characterizing claims about products recently or currently in use in US health care settings that are marketed as tools to improve health care efficiency by improving quality of care while reducing costs. Methods: We conducted systematic database searches of relevant business news and academic research to identify MLPA products for health care efficiency meeting our inclusion and exclusion criteria. We used content analysis to generate MLPA product categories and characterize the organizations marketing the products. Results: We identified 106 products and characterized them based on publicly available information in terms of the types of predictions made and the size, type, and clinical training of the leadership of the companies marketing them. We identified 5 categories of predictions made by MLPA products based on publicly available product marketing materials: disease onset and progression, treatment, cost and utilization, admissions and readmissions, and decompensation and adverse events. Conclusions: Our findings provide a foundational reference to inform the analysis of specific ethical and regulatory challenges arising from the use of MLPA to improve health care efficiency.",
        "DOI": "10.2196/26391",
        "affiliation_name": "Stanford University School of Medicine",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning-based outcome prediction and novel hypotheses generation for substance use disorder treatment",
        "paper_author": "Nasir M.",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "14",
        "cover_date": "2021-06-01",
        "Abstract": "Objective: Substance use disorder is a critical public health issue. Discovering the synergies among factors impacting treatment program success can help governments and treatment facilities develop effective policies. In this work, we propose a novel data analytics approach using machine learning models to discover interaction effects that might be neglected by traditional hypothesis-generating approaches. Materials and Methods: A patient-episode-level substance use treatment discharge dataset and a Federal Bureau of Investigation crime dataset were joined using core-based statistical area codes. Random forests, artificial neural networks, and extreme gradient boosting were applied with a nested cross-validation methodology. Interaction effects were identified based on the machine learning model with the best performance. These interaction effects were analyzed and tested using traditional logistic regression models on unseen data. Results: In predicting patient completion of a treatment program, extreme gradient boosting performed the best with an area under the curve of 89.31%. Based on our procedure, 73 interaction effects were identified. Among these, 14 were tested using traditional logistic regression models where 12 were statistically significant (P<.05). Conclusions: We identified new interaction effects among the length of stay, frequency of substance use, changes in self-help group attendance frequency, and other factors. This work provides insights into the interactions between factors impacting treatment completion. Further traditional statistical analysis can be employed by practitioners and policy makers to test the effects discovered by our novel machine learning approach.",
        "DOI": "10.1093/jamia/ocaa350",
        "affiliation_name": "University of Massachusetts Lowell",
        "affiliation_city": "Lowell",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Real-time prediction of the daily incidence of COVID-19 in 215 countries and territories using machine learning: Model development and validation",
        "paper_author": "Peng Y.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "17",
        "cover_date": "2021-06-01",
        "Abstract": "Background: Advanced prediction of the daily incidence of COVID-19 can aid policy making on the prevention of disease spread, which can profoundly affect people's livelihood. In previous studies, predictions were investigated for single or several countries and territories. Objective: We aimed to develop models that can be applied for real-time prediction of COVID-19 activity in all individual countries and territories worldwide. Methods: Data of the previous daily incidence and infoveillance data (search volume data via Google Trends) from 215 individual countries and territories were collected. A random forest regression algorithm was used to train models to predict the daily new confirmed cases 7 days ahead. Several methods were used to optimize the models, including clustering the countries and territories, selecting features according to the importance scores, performing multiple-step forecasting, and upgrading the models at regular intervals. The performance of the models was assessed using the mean absolute error (MAE), root mean square error (RMSE), Pearson correlation coefficient, and Spearman correlation coefficient. Results: Our models can accurately predict the daily new confirmed cases of COVID-19 in most countries and territories. Of the 215 countries and territories under study, 198 (92.1%) had MAEs <10 and 187 (87.0%) had Pearson correlation coefficients >0.8. For the 215 countries and territories, the mean MAE was 5.42 (range 0.26-15.32), the mean RMSE was 9.27 (range 1.81-24.40), the mean Pearson correlation coefficient was 0.89 (range 0.08-0.99), and the mean Spearman correlation coefficient was 0.84 (range 0.2-1.00). Conclusions: By integrating previous incidence and Google Trends data, our machine learning algorithm was able to predict the incidence of COVID-19 in most individual countries and territories accurately 7 days ahead.",
        "DOI": "10.2196/24285",
        "affiliation_name": "Shantou University",
        "affiliation_city": "Shantou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predictors of tooth loss: A machine learning approach",
        "paper_author": "Elani H.W.",
        "publication": "PLoS ONE",
        "citied_by": "29",
        "cover_date": "2021-06-01",
        "Abstract": "Introduction Little is understood about the socioeconomic predictors of tooth loss, a condition that can negatively impact individual’s quality of life. The goal of this study is to develop a machine-learning algorithm to predict complete and incremental tooth loss among adults and to compare the predictive performance of these models. Methods We used data from the National Health and Nutrition Examination Survey from 2011 to 2014. We developed multiple machine-learning algorithms and assessed their predictive performances by examining the area under the receiver operating characteristic curve (AUC), accuracy, sensitivity, specificity, and positive and negative predictive values. Results The extreme gradient boosting trees presented the highest performance in the prediction of edentulism (AUC = 88.7%; 95%CI: 87.1, 90.2), the absence of a functional dentition (AUC = 88.3% 95%CI: 87.3,89.3) and for predicting missing any tooth (AUC = 83.2%; 95%CI, 82.0, 84.4). Although, as expected, age and routine dental care emerged as strong predictors of tooth loss, the machine learning approach identified additional predictors, including socioeconomic conditions. Indeed, the performance of models incorporating socioeconomic characteristics was better at predicting tooth loss than those relying on clinical dental indicators alone. Conclusions Future application of machine-learning algorithm, with longitudinal cohorts, for identification of individuals at risk for tooth loss could assist clinicians to prioritize interventions directed toward the prevention of tooth loss.",
        "DOI": "10.1371/journal.pone.0252873",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mechanical rotation at low Reynolds number via reinforcement learning",
        "paper_author": "Liu Y.",
        "publication": "Physics of Fluids",
        "citied_by": "17",
        "cover_date": "2021-06-01",
        "Abstract": "There is growing interest in the development of artificial microscopic machines that can perform complex maneuvers like swimming microorganisms for potential biomedical applications. At the microscopic scales, the dominance of viscous over inertial forces imposes stringent constraints on locomotion. In the absence of inertia, Purcell first proposed an elegant way to generate net translation using kinematically irreversible motions [E. M. Purcell, “Life at low Reynolds number,” Am. J. Phys. 45, 3-11 (1977)]. In addition to net translation, a more recent prototype known as Purcell's “rotator” has been proposed in Dreyfus et al. [“Purcell's “rotator”: Mechanical rotation at low Reynolds number,” Eur. Phys. J. B 47, 161-164 (2005)] as a mechanical implementation of net rotation at low Reynolds numbers. These ingenious designs rely on knowledge of the surrounding environment and the physics of locomotion within the environment, which may be incomplete or unclear in more complex scenarios. More recently, reinforcement learning has been used as an alternative approach to enable a machine to learn effective locomotory gaits for net translation based on its interaction with the surroundings. In this work, we demonstrate the use of reinforcement learning to generate net mechanical rotation at low Reynolds numbers without requiring prior knowledge of locomotion. For a three-sphere configuration, the reinforcement learning recovers the strategy proposed by Dreyfus et al. As the number of spheres increases, multiple effective rotational strategies emerge from the learning process. However, given sufficiently long learning processes, all machines considered in this work converge to a single type of rotational policies that consist of traveling waves of actuation, suggesting its optimality of the strategy in generating net rotation at low Reynolds numbers.",
        "DOI": "10.1063/5.0053563",
        "affiliation_name": "School of Engineering",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Urban sub‐center design framework based on the walkability evaluation method: Taking coomera town sub‐center as an example",
        "paper_author": "Shao J.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "9",
        "cover_date": "2021-06-01",
        "Abstract": "As current society’s reflection on the rapid development of motorization and increasing emphasis on the ecological environment, the study of walkable cities has become one of the key points of urban sustainable design. Creating a walkable city is an effective way to build a low‐carbon and healthy city. With the development of cities, walkability concepts and theories are constantly being given new life, and research methods and design strategies continue to be updated. A city’s walkability and walkability index have become current research hotspots. Based on prior research on walkability and related urban policies, this study selects Coomera Town on the Gold Coast of Queensland, Australia, as the research area because of Coomera Town policy regulations and environmental requirements. This study utilizes traditional qualitative and quantitative research methods, machine mining technology, and the deep learning big data analysis technology to conduct thematic design research in a real place. Its combines walkability evaluation with walkability design to construct a walkable city in a targeted manner. This provides a reference for related city design in the future.",
        "DOI": "10.3390/su13116259",
        "affiliation_name": "Huazhong Agricultural University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Improving Autonomous Robotic Navigation Using Imitation Learning",
        "paper_author": "Cèsar-Tondreau B.",
        "publication": "Frontiers in Robotics and AI",
        "citied_by": "15",
        "cover_date": "2021-06-01",
        "Abstract": "Autonomous navigation to a specified waypoint is traditionally accomplished with a layered stack of global path planning and local motion planning modules that generate feasible and obstacle-free trajectories. While these modules can be modified to meet task-specific constraints and user preferences, current modification procedures require substantial effort on the part of an expert roboticist with a great deal of technical training. In this paper, we simplify this process by inserting a Machine Learning module between the global path planning and local motion planning modules of an off-the shelf navigation stack. This model can be trained with human demonstrations of the preferred navigation behavior, using a training procedure based on Behavioral Cloning, allowing for an intuitive modification of the navigation policy by non-technical users to suit task-specific constraints. We find that our approach can successfully adapt a robot’s navigation behavior to become more like that of a demonstrator. Moreover, for a fixed amount of demonstration data, we find that the proposed technique compares favorably to recent baselines with respect to both navigation success rate and trajectory similarity to the demonstrator.",
        "DOI": "10.3389/frobt.2021.627730",
        "affiliation_name": "U.S. Army Research Laboratory",
        "affiliation_city": "Adelphi",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Data-driven analysis on inter-city commuting decisions in germany",
        "paper_author": "Chen H.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "8",
        "cover_date": "2021-06-01",
        "Abstract": "Understanding commuters’ behavior and influencing factors becomes more and more important every day. With the steady increase of the number of commuters, commuter traffic becomes a major bottleneck for many cities. Commuter behavior consequently plays an increasingly important role in city and transport planning and policy making. Although prior studies investigated a variety of potential factors influencing commuting decisions, most of them are constrained by the data scale in terms of limited time duration, space and number of commuters under investigation, largely owing to their dependence on questionnaires or survey panel data; as such only small sets of features can be explored and no predictions of commuter numbers have been made, to the best of our knowledge. To fill this gap, we collected inter-city commuting data in Germany between 1994 and 2018, and, along with other data sources, analyzed the influence of GDP, housing and the labor market on the decision to commute. Our analysis suggests that the access to employment opportunities, housing price, income and the distribution of the location’s industry sectors are important factors in commuting decisions. In addition, different age, gender and income groups have different commuting patterns. We employed several machine learning algorithms to predict the commuter number using the identified related features with reasonably good accuracy.",
        "DOI": "10.3390/su13116320",
        "affiliation_name": "Georg-August-Universität Göttingen",
        "affiliation_city": "Gottingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Validating and forecasting carbon emissions in the framework of the environmental kuznets curve: The case of Vietnam",
        "paper_author": "Nguyen A.T.",
        "publication": "Energies",
        "citied_by": "9",
        "cover_date": "2021-06-01",
        "Abstract": "This paper examines the environmental Kuznets curve (EKC) in Vietnam between 1977 and 2019. Using the autoregressive distributed lag (ARDL) approach, we find an inverted N‐shaped relation between economic growth and carbon dioxide emissions in both the long‐ and short‐run. The econometric results also reveal that energy consumption and urbanization statistically positively impact pollution. The long‐run Granger causality test shows a unidirectional causality from energy consumption and economic growth to pollution while there is no causal relationship between energy consumption and economic growth. These suggest some crucial policies for curtailing emissions without harming economic development. In the second step, we also employed the back‐propagation neural networks (BPN) to compare the work of econometrics in carbon dioxide emissions forecasting. A 5‐4‐1 multi‐layer perceptron with BPN and learning rate was set at 0.1, which outperforms the ARDL’s outputs. Our findings suggest the potential application of machine learning to notably improve the econometric method’s forecasting results in the literature.",
        "DOI": "10.3390/en14113144",
        "affiliation_name": "National Taiwan University of Science and Technology",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Optimizing hyperparameters of deep reinforcement learning for autonomous driving based on whale optimization algorithm",
        "paper_author": "Ashraf N.M.",
        "publication": "PLoS ONE",
        "citied_by": "60",
        "cover_date": "2021-06-01",
        "Abstract": "Deep Reinforcement Learning (DRL) enables agents to make decisions based on a well-designed reward function that suites a particular environment without any prior knowledge related to a given environment. The adaptation of hyperparameters has a great impact on the overall learning process and the learning processing times. Hyperparameters should be accurately estimated while training DRL algorithms, which is one of the key challenges that we attempt to address. This paper employs a swarm-based optimization algorithm, namely the Whale Optimization Algorithm (WOA), for optimizing the hyperparameters of the Deep Deterministic Policy Gradient (DDPG) algorithm to achieve the optimum control strategy in an autonomous driving control problem. DDPG is capable of handling complex environments, which contain continuous spaces for actions. To evaluate the proposed algorithm, the Open Racing Car Simulator (TORCS), a realistic autonomous driving simulation environment, was chosen to its ease of design and implementation. Using TORCS, the DDPG agent with optimized hyperparameters was compared with a DDPG agent with reference hyperparameters. The experimental results showed that the DDPG’s hyperparameters optimization leads to maximizing the total rewards, along with testing episodes and maintaining a stable driving policy.",
        "DOI": "10.1371/journal.pone.0252754",
        "affiliation_name": "Mansoura University",
        "affiliation_city": "Mansoura",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Making a complex dental care tailored to the person: population health in focus of predictive, preventive and personalised (3P) medical approach",
        "paper_author": "Tachalov V.V.",
        "publication": "EPMA Journal",
        "citied_by": "20",
        "cover_date": "2021-06-01",
        "Abstract": "An evident underestimation of the targeted prevention of dental diseases is strongly supported by alarming epidemiologic statistics globally. For example, epidemiologists demonstrated 100% prevalence of dental caries in the Russian population followed by clinical manifestation of periodontal diseases. Inadequately provided oral health services in populations are caused by multi-factorial deficits including but not limited to low socio-economic status of affected individuals, lack of insurance in sub-populations, insufficient density of dedicated medical units. Another important aspect is the “participatory” medicine based on the active participation of population in maintaining oral health: healthcare will remain insufficient as long as the patient is not motivated and does not feel responsible for their oral health. To this end, nearly half of chronically diseased people do not comply with adequate medical services suffering from severely progressing pathologies. Noteworthy, the prominent risk factors and comorbidities linked to the severe disease course and poor outcomes in COVID-19-infected individuals, such as elderly, diabetes mellitus, hypertension and cardiovascular disease, are frequently associated with significantly altered oral microbiome profiles, systemic inflammatory processes and poor oral health. Suggested pathomechanisms consider potential preferences in the interaction between the viral particles and the host microbiota including oral cavity, the respiratory and gastrointestinal tracts. Since an aspiration of periodontopathic bacteria induces the expression of angiotensin-converting enzyme 2, the receptor for SARS-CoV-2, and production of inflammatory cytokines in the lower respiratory tract, poor oral hygiene and periodontal disease have been proposed as leading to COVID-19 aggravation. Consequently, the issue-dedicated expert recommendations are focused on the optimal oral hygiene as being crucial for improved individual outcomes and reduced morbidity under the COVID-19 pandemic condition. Current study demonstrated that age, gender, socio-economic status, quality of environment and life-style, oral hygiene quality, regularity of dental services requested, level of motivation and responsibility for own health status and corresponding behavioural patterns are the key parameters for the patient stratification considering person-tailored approach in a complex dental care in the population. Consequently, innovative screening programmes and adapted treatment schemes are crucial for the complex person-tailored dental care to improve individual outcomes and healthcare provided to the population.",
        "DOI": "10.1007/s13167-021-00240-7",
        "affiliation_name": "Universitätsklinikum Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "TAM: Targeted Analysis Model with Reinforcement Learning on Short Texts",
        "paper_author": "Chen J.",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "Mining topics on social media (e.g., Twitter and Facebook) is an important task for various applications, such as hot topic discovery, advertising, and promotion activities. Topic modeling techniques are helpful to find out topics that people are talking about. However, current full-analysis models cannot perform well on a focused analysis task-find out all topics related to one particular area in short documents. One reason is that the targeted topic is usually sparse in the corpus of short texts. Another one is, during clustering, even minor errors may compound and render the model useless. This article studies these problems and proposes a targeted analysis model (TAM) with reinforcement learning (RL) to extract any specific topic in a given corpus and perform fine-grained topic generation. In this work, we design a reward function of RL to prevent the false propagation problem induced by Gibbs sampling during the clustering. We amend the targeted topic modeling techniques to the case of RL and use policy search combined with the Gibbs EM algorithm for parameter estimation. Metrics of F1 score and the proposed normalized mutual information-F1 are exploited for the evaluation of clustering and topic generation, respectively. Our experiments have demonstrated that TAM can outperform state-of-the-art models-specifically achieving 25.7% improvement on the F1 score for binary clustering on average.",
        "DOI": "10.1109/TNNLS.2020.3009247",
        "affiliation_name": "State Key Laboratory of Internet of Things for Smart City",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "The classification of profiles of financial catastrophe caused by out-of-pocket payments: A methodological approach",
        "paper_author": "García-Centeno M.C.",
        "publication": "Mathematics",
        "citied_by": "1",
        "cover_date": "2021-06-01",
        "Abstract": "The financial catastrophe resulting from the out-of-pocket payments necessary to access and use healthcare systems has been widely studied in the literature. The aim of this work is to predict the impact of the financial catastrophe a household will face as a result of out-of-pocket payments in long-term care in Spain. These predictions were made using machine learning techniques such as LASSO (Least Absolute Shrinkage and Selection Operator) penalized regression and elastic-net, as well as algorithms like k-nearest neighbors (KNN), MARS (Multivariate Adaptive Regression Splines), random forest, boosted trees and SVM (Support Vector Machine). The results reveal that all the classification methods performed well, with the complex models performing better than the simpler ones and showing no evidence of overfitting. Detecting and defining the profiles of individuals and families most likely to suffer from financial catastrophe is crucial in enabling the design of financial policies aimed at protecting vulnerable groups.",
        "DOI": "10.3390/math9111170",
        "affiliation_name": "Universidad CEU San Pablo",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Environmental conservation policy can bend the trend of future forest losses in the oriental Amazon",
        "paper_author": "Zeferino L.B.",
        "publication": "Regional Environmental Change",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "Scenarios of land use and land cover (LULC) are essential to orient public policies and improve future landscape, but scenarios of LULC at high resolution aiming to guide government actions are still scarce in the frontiers of deforestation in the tropics. This study aimed to explore the historical LULC changes (1985 to 2015) and anticipate how the implementation of the Brazilian New Forest Code could affect the LULC trends for 2050 in a region between Amazon and Cerrado biomes. We classified satellite images from the years 1986, 1990, 1993, 1999, 2004, 2010, and 2015 using a machine learning algorithm and environmental covariates. We projected two scenarios for 2050: scenario 1 representing the future trend based on the past LULC changes using a predictive model, and scenario 2 representing the full implementation of the Forest Code in the region from 2015 to 2050. We found that the forest cover decreased from 29.1 to 21.7% between 1986 and 2015, being converted mainly to pasture areas. In scenario 1, there are expected intense conversions of natural vegetation areas to pastures, resulting in 80% of the basin covered by pasture, 11.3% by forest and 5.1% by cerrado up to 2050. On the other hand, the implementation of Legal Reserves according to Forest Code in scenario 2 can restore the forest cover up to 29.5% by 2050. Although forest area is expected to increase in scenario 2, about 3.7 kha of cerrado still is expected to be converted into pastures. Therefore, the compliance and full adoption of the New Forest Code can help to promote forest protection in this region.",
        "DOI": "10.1007/s10113-021-01787-x",
        "affiliation_name": "Universidade Federal de Vicosa",
        "affiliation_city": "Vicosa",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "One-year lesson: Machine learning prediction of COVID-19 positive cases with meteorological data and mobility estimate in japan",
        "paper_author": "Rashed E.A.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "25",
        "cover_date": "2021-06-01",
        "Abstract": "With the wide spread of COVID-19 and the corresponding negative impact on different life aspects, it becomes important to understand ways to deal with the pandemic as a part of daily rou-tine. After a year of the COVID-19 pandemic, it has become obvious that different factors, including meteorological factors, influence the speed at which the disease is spread and the potential fatalities. However, the impact of each factor on the speed at which COVID-19 is spreading remains controversial. Accurate forecasting of potential positive cases may lead to better management of healthcare resources and provide guidelines for government policies in terms of the action required within an effective timeframe. Recently, Google Cloud has provided online COVID-19 forecasting data for the United States and Japan, which would help in predicting future situations on a state/prefecture scale and are updated on a day-by-day basis. In this study, we propose a deep learning architecture to predict the spread of COVID-19 considering various factors, such as meteorological data and public mobility estimates, and applied it to data collected in Japan to demonstrate its effectiveness. The proposed model was constructed using a neural network architecture based on a long short-term memory (LSTM) network. The model consists of multi-path LSTM layers that are trained using time-series meteorological data and public mobility data obtained from open-source data. The model was tested using different time frames, and the results were compared to Google Cloud forecasts. Public mobility is a dominant factor in estimating new positive cases, whereas meteorological data improve their accuracy. The average relative error of the proposed model ranged from 16.1% to 22.6% in major regions, which is a significant improvement compared with Google Cloud forecasting. This model can be used to provide public awareness regarding the morbidity risk of the COVID-19 pandemic in a feasible manner.",
        "DOI": "10.3390/ijerph18115736",
        "affiliation_name": "Faculty of Science",
        "affiliation_city": "Ismailia",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Analysis of severe injuries in crashes involving large trucks using K-prototypes clustering-based GBDT model",
        "paper_author": "Tahfim S.A.S.",
        "publication": "Safety",
        "citied_by": "8",
        "cover_date": "2021-06-01",
        "Abstract": "The unobserved heterogeneity in traffic crash data hides certain relationships between the contributory factors and injury severity. The literature has been limited in exploring different types of clustering methods for the analysis of the injury severity in crashes involving large trucks. Additionally, the variability of data type in traffic crash data has rarely been addressed. This study explored the application of the k-prototypes clustering method to countermeasure the unobserved heterogeneity in large truck-involved crashes that had occurred in the United States between the period of 2016 to 2019. The study segmented the entire dataset (EDS) into three homogeneous clusters. Four gradient boosted decision trees (GBDT) models were developed on the EDS and individual clusters to predict the injury severity in crashes involving large trucks. The list of input features included crash characteristics, truck characteristics, roadway attributes, time and location of the crash, and environmental factors. Each cluster-based GBDT model was compared with the EDS-based model. Two of the three cluster-based models showed significant improvement in their predicting performances. Additionally, feature analysis using the SHAP (Shapley additive explanations) method identified few new important features in each cluster and showed that some features have a different degree of effects on severe injuries in the individual clusters. The current study concluded that the k-prototypes clustering-based GBDT model is a promising approach to reveal hidden insights, which can be used to improve safety measures, roadway conditions and policies for the prevention of severe injuries in crashes involving large trucks.",
        "DOI": "10.3390/safety7020032",
        "affiliation_name": "Dalian Maritime University",
        "affiliation_city": "Dalian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The impact of covid 19 on university staff and students from iberoamerica: Online learning and teaching experience",
        "paper_author": "Jojoa M.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "29",
        "cover_date": "2021-06-01",
        "Abstract": "(1) Background: The COVID-19 pandemic has created a great impact on mental health in society. Considering the little attention paid by scientific studies to either students or university staff during lockdown, the current study has two aims: (a) to analyze the evolution of mental health and (b) to identify predictors of educational/professional experience and online learning/teaching expe-rience. (2) Methods: 1084 university students and 554 staff in total from four different countries (Spain, Colombia, Chile and Nicaragua) participated in the study, affiliated with nine different uni-versities, four of them Spanish and one of which was online. We used an online survey known as LockedDown, which consists of 82 items, analyzed with classical multiple regression analyses and machine learning techniques. (3) Results: Stress level and feelings of anxiety and depression of students and staff either increased or remained over the weeks. A better online learning experience for university students was associated with the age, perception of the experience as beneficial and support of the university. (4) Conclusions: The study has shown evidence of the emotional impact and quality of life for both students and staff. For students, the evolution of feelings of anxiety and de-pression, as well as the support offered by the university affected the educational experience and online learning. For staff who experienced a positive professional experience, with access to services and products, the quality-of-life levels were maintained.",
        "DOI": "10.3390/ijerph18115820",
        "affiliation_name": "Universidad Internacional de Valencia",
        "affiliation_city": "Valencia",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Discrete-Time Non-Zero-Sum Games with Completely Unknown Dynamics",
        "paper_author": "Song R.",
        "publication": "IEEE Transactions on Cybernetics",
        "citied_by": "64",
        "cover_date": "2021-06-01",
        "Abstract": "In this article, off-policy reinforcement learning (RL) algorithm is established to solve the discrete-time N -player nonzero-sum (NZS) games with completely unknown dynamics. The N -coupled generalized algebraic Riccati equations (GARE) are derived, and then policy iteration (PI) algorithm is used to obtain the N -tuple of iterative control and iterative value function. As the system dynamics is necessary in PI algorithm, off-policy RL method is developed for discrete-time N -player NZS games. The off-policy N -coupled Hamilton-Jacobi (HJ) equation is derived based on quadratic value functions. According to the Kronecker product, the N -coupled HJ equation is decomposed into unknown parameter part and the system operation data part, which makes the N -coupled HJ equation solved independent of system dynamics. The least square is used to calculate the iterative value function and N -tuple of iterative control. The existence of Nash equilibrium is proved. The result of the proposed method for discrete-time unknown dynamics NZS games is indicated by the simulation examples.",
        "DOI": "10.1109/TCYB.2019.2957406",
        "affiliation_name": "College of Information Science and Engineering, Northeastern University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Listen to E-scooter riders: Mining rider satisfaction factors from app store reviews",
        "paper_author": "Aman J.J.C.",
        "publication": "Transportation Research Part D: Transport and Environment",
        "citied_by": "70",
        "cover_date": "2021-06-01",
        "Abstract": "In this study, app store reviews from two major micromobility companies are investigated using machine learning techniques to identify the factors that influence rider satisfaction. The Latent Dirichlet Allocation model is applied to over 12,000 rider-generated reviews to identify twelve topics discussed within the reviews. These topics cover areas such as pricing, safety, customer service, map, refund, payment, app interface, and ease of use, to name a few. Using logistic regression, the most significant factors influencing rider satisfaction were identified. Moreover, name-centered gender prediction analysis is employed to identify rider gender and then discover differences in review content and factors of satisfaction across gender. Results suggest rider satisfaction levels tend to vary across topics and gender. Women were more satisfied with the services and exhibited more positive sentiment than men. Yet, scooter is still a male dominated mode of transportation. Findings contribute to the existing literature by demonstrating the use of app store reviews in a transportation mobility study. The development of a method to assess factors contributing to rider satisfaction offers the ability to evaluate e-scooter rider needs and barriers. An apparent policy opportunity to increase scooter ridership includes an emphasis on contributing factors such as ease of use, safety (speed and riding lane), as well as app issues that showed significant influence on user satisfaction. It is recommended that a policy approach focused on improving rider satisfaction and delivering service improvements incorporate opinion mining as a methodology.",
        "DOI": "10.1016/j.trd.2021.102856",
        "affiliation_name": "Bobby B. Lyle School of Engineering",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Forecasting electricity consumption of OECD countries: A global machine learning modeling approach",
        "paper_author": "Sen D.",
        "publication": "Utilities Policy",
        "citied_by": "26",
        "cover_date": "2021-06-01",
        "Abstract": "Electricity is a critical utility for social growth. Accurate estimation of its consumption plays a vital role in economic development. A database that included past electricity consumption data from all OECD countries was prepared. Since national trends may be transferable from one country to another, the entire database was modeled and simulated via machine learning techniques to forecast the energy consumption of each country. Understanding similarities among the profiles of different countries could increase predictive accuracy and improve associated public policies.",
        "DOI": "10.1016/j.jup.2021.101222",
        "affiliation_name": "Istanbul Bilgi Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Türkiye"
    },
    {
        "paper_title": "Learning to unknot",
        "paper_author": "Gukov S.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "29",
        "cover_date": "2021-06-01",
        "Abstract": "We introduce natural language processing into the study of knot theory, as made natural by the braid word representation of knots. We study the UNKNOT problem of determining whether or not a given knot is the unknot. After describing an algorithm to randomly generate N-crossing braids and their knot closures and discussing the induced prior on the distribution of knots, we apply binary classification to the UNKNOT decision problem. We find that the Reformer and shared-QK Transformer network architectures outperform fully-connected networks, though all perform at 95% accuracy. Perhaps surprisingly, we find that accuracy increases with the length of the braid word, and that the networks learn a direct correlation between the confidence of their predictions and the degree of the Jones polynomial. Finally, we utilize reinforcement learning (RL) to find sequences of Markov moves and braid relations that simplify knots and can identify unknots by explicitly giving the sequence of unknotting actions. Trust region policy optimization (TRPO) performs consistently well, reducing 80% of the unknots with up to 96 crossings we tested to the empty braid word, and thoroughly outperformed other RL algorithms and random walkers. Studying these actions, we find that braid relations are more useful in simplifying to the unknot than one of the Markov moves.",
        "DOI": "10.1088/2632-2153/abe91f",
        "affiliation_name": "California Institute of Technology",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Satellite-based data fusion crop type classification and mapping in Rio Grande do Sul, Brazil",
        "paper_author": "Pott L.P.",
        "publication": "ISPRS Journal of Photogrammetry and Remote Sensing",
        "citied_by": "65",
        "cover_date": "2021-06-01",
        "Abstract": "Field-scale crop monitoring is essential for agricultural management and policy making for food security and sustainability. Automating crop classification process while elaborating a workflow is a key step for reliable and precise crop mapping. This study aims to develop an approach for crop classification in the state of Rio Grande do Sul, Brazil, following the specific goals of i) evaluating spatial satellite-based features to guide crop data collection; ii) testing transfer learning model with subsequent growing season data; iii) examining accuracy in early-season prediction model; and lastly, iv) developing a crop classification model for estimating large scale crop area. As main data inputs, Sentinel-2, Sentinel-1, and Shuttle Radar Topographic Mission (SRTM) Digital Elevation data were used to extract features to input in the Random Forest classifier. Spatial variability of satellite features was evaluated using Moran's I Index and cluster k-means. Crop area prediction data were obtained at municipality level to compare with census data (standard method). A crop summer map layer was generated for three major crops: soybeans (Glycine max L.), corn (Zea mays L.), and rice (Oryza sativa L.) in the state of Rio Grande do Sul, Brazil. The crop classification model achieved an overall accuracy of 0.95. Model performance was influenced by sample size and spatial variability of the samples. The random forest model was transferred to the next growing season with 0.89 and 0.91 overall accuracy for 250 and 750 samples, respectively. However, overall accuracy increased from 0.93 to 0.95 when 50 to 250 samples of same-year data was aggregated to the model. Similar accuracy was obtained for predictions done with data until March relative to when the entire season was considered, until May. When data for more growing seasons were aggregated, the model produced more accurate early season predictions (January and February). Soybean prediction area obtained the highest performance (R2 = 0.94), relative to rice (R2 = 0.90) and corn (R2 = 0.37). The rice prediction area presented a high precision, but the crop area was overestimated due to errors with wetland target relative to other class. Lastly, this study presents the first crop map layer of the three major field crops for the state of Rio Grande do Sul, Brazil, serving as a foundation for the creation of crop type maps for other states in the country and around the globe.",
        "DOI": "10.1016/j.isprsjprs.2021.04.015",
        "affiliation_name": "Universidade Federal de Santa Maria",
        "affiliation_city": "Santa Maria",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "A hierarchical agent-based approach to simulate a dynamic decision-making process of evacuees using reinforcement learning",
        "paper_author": "Hassanpour S.",
        "publication": "Journal of Choice Modelling",
        "citied_by": "11",
        "cover_date": "2021-06-01",
        "Abstract": "Simulation models are an undeniable tool to help researchers and designers forecast effects of definite policies regarding pedestrian social and collective movement behaviour. Considering both the environment's details and the complexity of human behaviour in choosing paths simultaneously is the main challenge in micro-simulation pedestrian dynamics models. This paper aims to present a novel comprehensive hierarchical agent-based simulation of pedestrian evacuation from a dynamic network of the environment using reinforcement learning, which is the closest to human behaviour among the other machine learning algorithms. In the approach, agents autonomously decide through a three-layer hierarchical model, including goal, node, and cell selection layers. A multinomial logit model is used to model the process of choosing the main movement direction at each time-step. The proposed model was successfully tested to simulate the pedestrian evacuation process from the Britomart Transport Centre platforms in Auckland during an abstract destructive event. Maximum evacuation flow, total evacuation time, average evacuation time, and average evacuation flow were investigated as dependent variables through different evacuation scenarios. The results from the approach can be used by designers and managers to optimise the quality of evacuation; also, the proposed model has the potential of becoming a potent tool for constructional management if coupled with other constructional tools.",
        "DOI": "10.1016/j.jocm.2021.100288",
        "affiliation_name": "Imam Khomeini International University",
        "affiliation_city": "Qazvin",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "A social network analysis of the organizations focusing on tuberculosis, malaria and pneumonia",
        "paper_author": "Lopreite M.",
        "publication": "Social Science and Medicine",
        "citied_by": "6",
        "cover_date": "2021-06-01",
        "Abstract": "In this paper,we present an original study on the use of social media data to analyze the structure of the global health networks (GHNs) relative to health organizations targeted to malaria, tuberculosis (TBC) and pneumonia as well as twitter popularity, evaluating the performance of their strategies in response to the arising health threats. We use a machine learning ensemble classifier and social network analysis to discover the Twitter users that represent organizations or groups active for each disease. We have found evidence that the GHN of TBC is the more mature, active and global. Meanwhile, the networks of malaria and pneumonia are found to be less connected and lacking global coverage. Our analysis validates the use of social media to analyze GHNs and to propose these networks as an important organizational tool in mobilizing the community versus global sustainable development goals.",
        "DOI": "10.1016/j.socscimed.2021.113940",
        "affiliation_name": "Scuola IMT Alti Studi Lucca",
        "affiliation_city": "Lucca",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Deciphering Indian inflationary expectations through text mining: an exploratory approach",
        "paper_author": "Banerjee A.",
        "publication": "Indian Economic Review",
        "citied_by": "1",
        "cover_date": "2021-06-01",
        "Abstract": "Inflationary forecasts tend to play a crucial role in macroeconomic and financial decision/policy making. In particular, in an inflation-targeting framework, it is of paramount importance. While traditionally, model-based and survey-based inflation expectations are being used, in recent times, a literature has emerged to forecast various macro-aggregates using text-based sentiment estimates. Taking a cue from this approach, in this paper we attempt to decipher inflationary sentiments using text mining from two leading financial dailies, viz., the Economic Times and Business Line. We consciously avoid using social media news due to severe challenges and high noise-to-signal ratio. In our algorithm we aggregate CPI basket level (viz., food, fuel, cloth & miscellaneous) sentiment into an overall index of inflation, adapting techniques from natural language processing. Our results from this text-based model indicate significant success in tracking actual inflation.",
        "DOI": "10.1007/s41775-021-00106-9",
        "affiliation_name": "Indian Institute of Management Calcutta",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India"
    },
    {
        "paper_title": "CMOs and AI: Can trained machine learning be justified with the concept of know–how?",
        "paper_author": "Mazzi F.",
        "publication": "World Patent Information",
        "citied_by": "1",
        "cover_date": "2021-06-01",
        "Abstract": "Contract manufacturing organizations (CMOs) engage machine learning in their processes. Such machine learning systems increase their capacity based on data that are often exclusive property of the commissioner according to the contract. Moreover, CMOs are required not to use for competitors the knowledge acquired through the work for the commissioner. Nonetheless, machine learning, trained by the work for a commissioner, are afterwards employed for different commissioners, often including competitors. The paper evaluates whether CMOs can rely on the concept of know-how to justify their trained machine learning, and it concludes that such solution could be acceptable from a policy perspective if specific conditions apply.",
        "DOI": "10.1016/j.wpi.2021.102036",
        "affiliation_name": "Faculty of Humanities and Social Sciences",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Aspect based sentiment analysis for demonetization tweets by optimized recurrent neural network using fire fly-oriented multi-verse optimizer",
        "paper_author": "Datta S.",
        "publication": "Sadhana - Academy Proceedings in Engineering Sciences",
        "citied_by": "25",
        "cover_date": "2021-06-01",
        "Abstract": "In this paper, it is proposed to understand the opinion of the public regarding the policy of demonetization that is implemented recently in India through Aspect-based Sentiment Analysis (ABSA) that predicts the sentiment of specific aspects present in the text. The major aim is to identify the relevant contexts for various aspects. Most of the conventional techniques have adopted attention mechanisms and deep learning concepts that decrease the prediction accuracy and generate huge noise. Another major disadvantage with the attention mechanisms is that the sentiment related to few context words alters with various aspects, and hence it cannot be concluded from itself alone. This paper adopts the optimized deep learning concept for performing the ABSA for demonetization tweets. The proposed model involves various phases such as pre-processing, aspect extraction, polarity feature extraction, and sentiment classification. Initially, the different demonetization tweets collected from the Kaggle dataset are taken. Pre-processing is done with the help of four phases like stop words removal, punctuation removal, lower case conversion, and stemming from minimizing the data to its reduced format. This pre-processed data is further performed with aspect extraction to extract the opinion words. These extracted aspect words are converted to the features with the help of polarity score computation and Word2vec. The weight of the polarity scores is optimized using hybridization of two meta-heuristic algorithms like FireFly Algorithm (FF), and Multi-Verse Optimization (MVO), and the new algorithm is termed as Fire Fly-oriented Multi-Verse Optimizer (FF-MVO). Further, combined features are subjected to a deep learning algorithm called Recurrent Neural Network (RNN). As a modification to the existing RNN, the hidden neurons are optimized by the hybrid FF-MVO, FF-MVO-RNN classifies the positive and negative sentiments. Finally, the comparative analysis of different machine learning algorithms proves the competent performance of the proposed model.",
        "DOI": "10.1007/s12046-021-01608-1",
        "affiliation_name": "University of Engineering &amp; Management Kolkata",
        "affiliation_city": "Kolkata",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Leveraging machine learning to characterize the role of socio-economic determinants on physical health and well-being among veterans",
        "paper_author": "Makridis C.A.",
        "publication": "Computers in Biology and Medicine",
        "citied_by": "8",
        "cover_date": "2021-06-01",
        "Abstract": "Introduction: We investigate the contribution of demographic, socio-economic, and geographic characteristics as determinants of physical health and well-being to guide public health policies and preventative behavior interventions (e.g., countering coronavirus). Methods: We use machine learning to build predictive models of overall well-being and physical health among veterans as a function of these three sets of characteristics. We link Gallup's U.S. Daily Poll between 2014 and 2017 over a range of demographic and socio-economic characteristics with zipcode characteristics from the Census Bureau to build predictive models of overall and physical well-being. Results: Although the predictive models of overall well-being have weak performance, our classification of low levels of physical well-being performed better. Gradient boosting delivered the best results (80.2% precision, 82.4% recall, and 80.4% AUROC) with perceptions of purpose in the workplace and financial anxiety as the most predictive features. Our results suggest that additional measures of socio-economic characteristics are required to better predict physical well-being, particularly among vulnerable groups, like veterans. Conclusion: Socio-economic characteristics explain large differences in physical and overall well-being. Effective predictive models that incorporate socio-economic data will provide opportunities to create real-time and personalized feedback to help individuals improve their quality of life.",
        "DOI": "10.1016/j.compbiomed.2021.104354",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Distributed deep reinforcement learning for simulation control",
        "paper_author": "Pawar S.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "10",
        "cover_date": "2021-06-01",
        "Abstract": "Several applications in the scientific simulation of physical systems can be formulated as control/optimization problems. The computational models for such systems generally contain hyperparameters, which control solution fidelity and computational expense. The tuning of these parameters is non-Trivial and the general approach is to manually spot-check for good combinations. This is because optimal hyperparameter configuration search becomes intractable when the parameter space is large and when they may vary dynamically. To address this issue, we present a framework based on deep reinforcement learning (RL) to train a deep neural network agent that controls a model solve by varying parameters dynamically. First, we validate our RL framework for the problem of controlling chaos in chaotic systems by dynamically changing the parameters of the system. Subsequently, we illustrate the capabilities of our framework for accelerating the convergence of a steady-state computational fluid dynamics solver by automatically adjusting the relaxation factors of the discretized Navier Stokes equations during run-Time. The results indicate that the run-Time control of the relaxation factors by the learned policy leads to a significant reduction in the number of iterations for convergence compared to the random selection of the relaxation factors. Our results point to potential benefits for learning adaptive hyperparameter learning strategies across different geometries and boundary conditions with implications for reduced computational campaign expenses.",
        "DOI": "10.1088/2632-2153/abdaf8",
        "affiliation_name": "College of Engineering, Architecture and Technology",
        "affiliation_city": "Stillwater",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Technological progress and monetary policy: Managing the fourth industrial revolution",
        "paper_author": "Poloz S.S.",
        "publication": "Journal of International Money and Finance",
        "citied_by": "11",
        "cover_date": "2021-06-01",
        "Abstract": "This paper looks at the implications for monetary policy of the widespread adoption of artificial intelligence and machine learning, which is sometimes called the “fourth industrial revolution.” The paper reviews experiences from the previous three industrial revolutions, developing a template of shared characteristics: new technology displaces workers; investor hype linked to the new technology leads to financial excesses; new types of jobs are created; productivity and potential output rise; prices and inflation fall; and real debt burdens increase, which can provoke crises when asset prices crash. The experience of the Federal Reserve during 1995–2006 is particularly instructive. The paper uses the Bank of Canada's main structural model, ToTEM (Terms-of-Trade Economic Model), to replicate that experience and consider options for monetary policy. Under a Taylor rule, monetary policy may allow growth to run as long as inflation remains subdued, easing the burden of adjustment on those workers directly affected by the new technology, while macroprudential policies help check financial excesses. This argues for a family of Taylor rules enhanced by the addition of financial stability considerations.",
        "DOI": "10.1016/j.jimonfin.2021.102373",
        "affiliation_name": "Banque du Canada",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Solving the online batching problem using deep reinforcement learning",
        "paper_author": "Cals B.",
        "publication": "Computers and Industrial Engineering",
        "citied_by": "28",
        "cover_date": "2021-06-01",
        "Abstract": "In e-commerce markets, on-time delivery is of great importance to customer satisfaction. In this paper, we present a Deep Reinforcement Learning (DRL) approach, together with a heuristic, for deciding how and when arrived orders should be batched and picked in a warehouse to minimize the number of tardy orders. In particular, the technique facilitates making decisions on whether an order should be picked individually (pick-by-order) or picked in a batch with other orders (pick-by-batch), and if so, with which other orders. We approach the problem by formulating it as a semi-Markov decision process and developing a vector-based state representation that includes the characteristics of the warehouse system. This allows us to create a deep reinforcement learning solution that learns a strategy by interacting with the environment and solve the problem with a proximal policy optimization algorithm. We evaluate the performance of the proposed DRL approach by comparing it with several batching and sequencing heuristics in different problem settings. The results show that the DRL approach can develop a strategy that produces consistent, good solutions and performs better than the proposed heuristics in most of the tested cases. We show that the strategy learned by DRL is different from the hand-crafted heuristics. In this paper, we demonstrate that the benefits from recent advancements of Deep Reinforcement Learning can be transferred to solve sequential decision-making problems in warehousing operations.",
        "DOI": "10.1016/j.cie.2021.107221",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Gaming the beamlines-employing reinforcement learning to maximize scientific outcomes at large-scale user facilities",
        "paper_author": "Maffettone P.M.",
        "publication": "Machine Learning: Science and Technology",
        "citied_by": "13",
        "cover_date": "2021-06-01",
        "Abstract": "Beamline experiments at central facilities are increasingly demanding of remote, high-throughput, and adaptive operation conditions. To accommodate such needs, new approaches must be developed that enable on-the-fly decision making for data intensive challenges. Reinforcement learning (RL) is a domain of AI that holds the potential to enable autonomous operations in a feedback loop between beamline experiments and trained agents. Here, we outline the advanced data acquisition and control software of the Bluesky suite, and demonstrate its functionality with a canonical RL problem: cartpole. We then extend these methods to efficient use of beamline resources by using RL to develop an optimal measurement strategy for samples with different scattering characteristics. The RL agents converge on the empirically optimal policy when under-constrained with time. When resource limited, the agents outperform a naive or sequential measurement strategy, often by a factor of 100%. We interface these methods directly with the data storage and provenance technologies at the National Synchrotron Light Source II, thus demonstrating the potential for RL to increase the scientific output of beamlines, and layout the framework for how to achieve this impact.",
        "DOI": "10.1088/2632-2153/abc9fc",
        "affiliation_name": "Brookhaven National Laboratory",
        "affiliation_city": "Upton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Review of geographic information systems-based rooftop solar photovoltaic potential estimation approaches at urban scales",
        "paper_author": "Gassar A.A.A.",
        "publication": "Applied Energy",
        "citied_by": "142",
        "cover_date": "2021-06-01",
        "Abstract": "In urban environments, decentralized energy systems from renewable photovoltaic resources, clean and available, are gradually replacing conventional energy systems as an attractive source for electricity generation. Especially with the availability of unexploited rooftop areas and the ease of installation, along with technological development and permanent cost reductions of photovoltaic panels. However, the optimal use of these systems requires accurate estimates of supply (rooftop solar photovoltaic potential) and the design of an intelligent distributed-system integrated with power grids. Geographic information systems (GISs)-based estimation is justified as a promising approach for estimating rooftop solar photovoltaic potential, in particular, the possibility of combining GISs with LiDAR (Lighting-Detection-And-Ranging) to build robust approaches leading to accurate estimates of the rooftop solar photovoltaic potential. Accordingly, this study aims to present a comprehensive review of GISs-based rooftop solar photovoltaic potential estimation approaches that have been applied at different scales, including countries. The study classified GISs-based approaches into sampling, geostatistics, modeling, and machine learning. The applications, advantages, and disadvantages of each approach were reviewed and discussed. The results revealed that GISs-based rooftop solar photovoltaic potential estimation approaches, can be applied to the large-scale spatial-temporal assessment of future energy systems with decentralized electrical energy grids. Assessment results can be employed to propose effective-policies for rooftop photovoltaic integration in built environments. However, the development of a new methodology that integrates GISs with machine learning to provide an accurate and less computationally demanding alternative to LiDAR-based approaches, will contribute significantly to large-scale estimates of the solar photovoltaic potential of building rooftops.",
        "DOI": "10.1016/j.apenergy.2021.116817",
        "affiliation_name": "Hanyang University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Social distance monitoring framework using deep learning architecture to control infection transmission of COVID-19 pandemic",
        "paper_author": "Ahmed I.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "71",
        "cover_date": "2021-06-01",
        "Abstract": "The recent outbreak of the COVID-19 affected millions of people worldwide, yet the rate of infected people is increasing. In order to cope with the global pandemic situation and prevent the spread of the virus, various unprecedented precaution measures are adopted by different countries. One of the crucial practices to prevent the spread of viral infection is social distancing. This paper intends to present a social distance framework based on deep learning architecture as a precautionary step that helps to maintain, monitor, manage, and reduce the physical interaction between individuals in a real-time top view environment. We used Faster-RCNN for human detection in the images. As the human's appearance significantly varies in a top perspective; therefore, the architecture is trained on the top view human data set. Moreover, taking advantage of transfer learning, a new trained layer is fused with a pre-trained architecture. After detection, the pair-wise distance between peoples is estimated in an image using Euclidean distance. The detected bounding box's information is utilized to measure the central point of an individual detected bounding box. A violation threshold is defined that uses distance to pixel information and determines whether two people violate social distance or not. Experiments are conducted using various test images; results demonstrate that the framework effectively monitors the social distance between peoples. The transfer learning technique enhances the overall performance of the framework by achieving an accuracy of 96% with a False Positive Rate of 0.6%.",
        "DOI": "10.1016/j.scs.2021.102777",
        "affiliation_name": "Institute of Management Sciences",
        "affiliation_city": "Peshawar",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Who is analysing what? The opportunities, risks and implications of using predictive risk modelling with Indigenous Australians in child protection: A scoping review",
        "paper_author": "Krakouer J.",
        "publication": "Australian Journal of Social Issues",
        "citied_by": "15",
        "cover_date": "2021-06-01",
        "Abstract": "Predictive risk modelling using administrative data is increasingly being promoted to tackle complex social policy issues, including the risk of child maltreatment and recurring involvement with child protection systems. This paper discusses opportunities and risks concerning predictive risk modelling with administrative datasets to address Indigenous Australian overrepresentation in Australian child protection systems. A scoping review using five databases, and the Google search engine, examined peer-reviewed and grey literature on risks associated with predictive risk models (PRMs) for racial and ethnic populations in child protection systems, such as Indigenous Australians. The findings revealed a dearth of research, especially considering Indigenous populations. Although PRMs have been developed for Australian child protection systems, no empirical research was found in relation to Indigenous Australians. The implications for utilising administrative data to address Indigenous Australian overrepresentation are discussed, focusing on methodological limitations of predictive analytics, and notions of fairness and bias. Participatory model development, transparency and Indigenous data sovereignty are crucial to ensure the development of fair and unbiased PRMs in Australian child protection systems. Yet, while PRMs may offer substantial benefits as decision support tools, significant developments – which fully include Indigenous Australians – are needed before they can be used with Indigenous Australians.",
        "DOI": "10.1002/ajs4.155",
        "affiliation_name": "University of Melbourne",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Financial inclusion: Measures and applications to Africa",
        "paper_author": "Kebede J.",
        "publication": "Economic Analysis and Policy",
        "citied_by": "35",
        "cover_date": "2021-06-01",
        "Abstract": "Financial inclusion (FI) is increasingly becoming a global policy priority because it enables access to financial services, such as savings, payments, risk management, and credit, to households and firms with a wide range of needs. However, to the best of our knowledge, no study has yet been undertaken on measures of FI and the nexus between FI and bank market structure in Africa. We used panel data from 17 African countries from 2004 to 2018 to measure FI and examine its nexus with bank market structure in these countries. We employed two-stage unsupervised machine learning to index FI: its dimensions in the first stage and overall FI in the second stage. Then, we employed an endogenous panel threshold model to examine bank market power and asset concentration impacts on FI. We found that bank market power enhances availability and accessibility dimensions but reduces the usage dimension. The impact of a higher regime market power on usage is worse than that of a lower regime market power. Asset concentration impacts on overall FI, availability, and usage are more pronounced under a lower regime concentration. The results imply that bank asset concentration and market power beyond thresholds are not desirable for promoting FI. The results also imply that scrutinizing potential sensitivity of the results to FI dimensions is vital.",
        "DOI": "10.1016/j.eap.2021.03.008",
        "affiliation_name": "Griffith Business School",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Optimal Policies for Quantum Markov Decision Processes",
        "paper_author": "Ying M.S.",
        "publication": "International Journal of Automation and Computing",
        "citied_by": "10",
        "cover_date": "2021-06-01",
        "Abstract": "Markov decision process (MDP) offers a general framework for modelling sequential decision making where outcomes are random. In particular, it serves as a mathematical framework for reinforcement learning. This paper introduces an extension of MDP, namely quantum MDP (qMDP), that can serve as a mathematical model of decision making about quantum systems. We develop dynamic programming algorithms for policy evaluation and finding optimal policies for qMDPs in the case of finite-horizon. The results obtained in this paper provide some useful mathematical tools for reinforcement learning techniques applied to the quantum world.",
        "DOI": "10.1007/s11633-021-1278-z",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Unraveling Street-Level Air Pollution upon a Pivotal City of Yangtze River Delta, China",
        "paper_author": "Feng R.",
        "publication": "Aerosol Science and Engineering",
        "citied_by": "1",
        "cover_date": "2021-06-01",
        "Abstract": "We use two machine learning models—random forest (RF) and recurrent neural network (RNN)—to analyze and predict air pollutants in a pivotal city of YRD, China. We quantitatively show the determinants for the atmospheric pollutants, providing insights for air pollution control policies. We propose, test and verify a five-step avenue to forecast the main atmospheric pollutants (SO2, NO2, CO, O3, PM2.5 and PM10) in the future 24 h. Step one, WRF is used to generate the meteorological conditions in the next 24 h. Step two, SO2 and CO are predicted by RNN using WRF-simulated meteorological conditions. Step three, NO2 is predicted by RNN using WRF-simulated meteorological conditions and RNN-simulated CO. Step four, O3 is predicted by RNN using WRF-simulated meteorological conditions and RNN-simulated CO and NO2. Step five, PM2.5 and PM10 are predicted by RNN using WRF-simulated meteorological conditions and RNN-simulated SO2, CO and NO2. The significant role that dew-point deficit plays in shaping SO2, NO2 and O3 is recognized. CO was strongly positively linked with NO2 and PM2.5. Decrease of CO may trigger the crescendo of ground-level O3. Stratospheric downward transport played paltry role in shaping tropospheric O3 at Hangzhou. We also identify that some illegal factories were surreptitiously emitting trichlorofluoromethane (CFCl3), one of the strongest stratospheric ozone-depleter that should have been forbidden since 2010.",
        "DOI": "10.1007/s41810-021-00093-7",
        "affiliation_name": "Sir Run Run Shaw Hospital",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine learning approach to market behavior estimation with applications in revenue management",
        "paper_author": "Gautam N.",
        "publication": "Journal of Revenue and Pricing Management",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "Demand forecasting models used in airline revenue management are primarily based on airline’s own sales data. These models have limited visibility into overall market conditions and competitive landscape. Market factors significantly influence customer behavior and hence should be considered for determining optimal control policy. We discuss data sources available to airlines that provide visibility into the future competitive schedule, market size forecast, and market share estimation. We also describe methodologies based on Machine Learning algorithms that can use to forecast these quantities and explain how they can be leveraged to improve pricing and revenue management practices.",
        "DOI": "10.1057/s41272-021-00317-y",
        "affiliation_name": "Sabre Inc.",
        "affiliation_city": "Southlake",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Risk assessment of VAT invoice crime levels of companies based on DFPSVM: a case study in China",
        "paper_author": "Ding N.",
        "publication": "Risk Management",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "In recent years, with the implementation of the policy of “Replacing Business Tax with Value-Added Tax” and “Streamlining Administration, Delegating Powers and Improving Regulation and Services” in China, criminals have been issuing false invoices, and such cases have shown a trend of high frequency in the category of economic crimes. Tax departments and public security departments are facing increasingly a serious crime situation that has created a new challenge. By studying the current trend of false invoice crime, the difficulties of investigation in such cases are analyzed. Using the tax information of enterprises that have conducted false invoice as the breakthrough point, the machine learning method is introduced to build a risk pre-warning assessment model based on the Support Vector Machine (SVM) method to detect enterprises issuing false invoices. Three steps were designed in this paper. First, a risk pre-warning assessment model was established to detect enterprises issuing false invoices. Second, enterprises were classified into three groups according to the risk levels: A, B, and C. Third, collected data were used to make an empirical analysis, and the results show that the accuracy rate of the model is 97%. In China, due to the high crime rate of tax fraud cases, it is important to obtain data from tax and public security departments to establish a model that can detect such crimes as early as possible. The police and tax authorities can use this model to jointly combat such crimes.",
        "DOI": "10.1057/s41283-021-00068-5",
        "affiliation_name": "People's Public Security University of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Pattern Discovery for climate and environmental policy indicators",
        "paper_author": "Herman K.S.",
        "publication": "Environmental Science and Policy",
        "citied_by": "24",
        "cover_date": "2021-06-01",
        "Abstract": "Quantitative environmental policy indicators are useful for modeling the impact of environmental policy on the economy. They can be important tools for policy-makers, companies, investors, and researchers alike. Well-crafted environmental policies lead to cleaner environments whilst encouraging innovative behaviour to stimulate green growth and ‘win-wins’ for the economy and the environment. Such win-win policies are increasingly sought out by policymakers, evidenced in the growing number of green 'new deals' and 'net zero' carbon emissions pledges at a national level. But there is a gap between the needs for environmental policy data and the supply of reliable indicators and indexes. This disconnect has negative consequences for policy feedback as well as the inducement of potential innovators of environmental technologies. While there are now a wide range of indicators and indexes, these largely remain inadequate for various reasons. This is disappointing considering the immense progress that has been made in machine learning and pattern discovery methods—methods that are already fully deployed in other research disciplines. Such automated techniques can limit human biases which currently plague the environmental indicator's scholarship. Against this backdrop, the main objective of this paper is to highlight how researchers can carefully collect these data and augment the effectiveness of environmental policy indicators. This is an important research area that, apart from a handful of studies, is not sufficiently developed.",
        "DOI": "10.1016/j.envsci.2021.02.003",
        "affiliation_name": "University College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Can biomass energy curtail environmental pollution? A quantum model approach to Germany",
        "paper_author": "Magazzino C.",
        "publication": "Journal of Environmental Management",
        "citied_by": "61",
        "cover_date": "2021-06-01",
        "Abstract": "This paper aims to investigate the causal relationship among renewable energy technologies, biomass energy consumption, per capita GDP, and CO2 emissions for Germany. We constructed an innovative algorithm, the Quantum model, and applied it with Machine Learning experiments – through a software capable of emulating a quantum system – to data over the period of 1990–2018. This process is possible after eliminating the “irreversibility” of classical computations (unitary transformations) by making the process “reversible”. The empirical findings support the powerful role of biomass energy in reducing carbon dioxide emissions, although the effect of renewable energy technology displays a much stronger magnitude. Moreover, income remains an important determinant of environmental pollution in Germany.",
        "DOI": "10.1016/j.jenvman.2021.112293",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Imaging time-series with features to enable visual recognition of regional energy consumption by bio-inspired optimization of deep learning",
        "paper_author": "Chou J.S.",
        "publication": "Energy",
        "citied_by": "20",
        "cover_date": "2021-06-01",
        "Abstract": "To increase the efficiency of energy use, ensure the stability of the power supply, and achieve balance in the energy supply, power management units have proposed plans that integrate energy-saving with intelligent systems, in which smart grids are used to distribute power and to manage power consumption. Imagery deep learning technology is proposed to address the knowledge gap, and highly accurate energy consumption predictions can be made by converting the 1-D time-series and features to 2-D images for visual recognition. Models based on machine learning and convolutional neural networks (CNNs) were used to predict future power consumption. Performance indicators were evaluated to determine the prediction accuracy and identify the best model for predicting power consumption. A metaheuristic—Jellyfish Search (JS)—is incorporated into the best model to optimize its hyperparameters to ensure model accuracy and stability. After the hybrid JS-CNNs model was constructed, validation was carried out. The analytical results provide insights into the formulation of energy policy for management units and can help power supply agencies to distribute regional power in a way that minimizes unnecessary energy loss. This study contributes to the prediction of future energy consumption trends, reveals power consumption patterns in cities and counties across a nation.",
        "DOI": "10.1016/j.energy.2021.120100",
        "affiliation_name": "University of Architecture Ho Chi Minh City",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Global natural gas demand to 2025: A learning scenario development model",
        "paper_author": "Hafezi R.",
        "publication": "Energy",
        "citied_by": "35",
        "cover_date": "2021-06-01",
        "Abstract": "Scenario development approaches are designed to deal with chaotic behaviors of complex systems and are widely used in the case of energy-related demand forecasting and policy planning. Building on traditional qualitative scenario models, a novel Learning Scenario Development Model (LSDM), incorporating qualitative and quantitative components, is proposed to generate different scenarios for global natural gas demand to 2025 in order to discover and compare the likely behavior of alternative future natural gas markets. This model, consists of five phases: 1) organize the fundamental data set, 2) investigate a data mining based pre-process procedure to initialize the quantitative dimension of the model, 3) select a set of procedures for forecasting global natural gas demand to 2025, referred to as the mixed model, 4) generate a reference case scenario (business as usual) using the mixed model, and 5) develop alternative scenarios (five in this study) applying a qualitative expert-based process. Unlike other scenario models, the LSDM is equipped with validation procedures that enable decision makers to develop alternative scenarios based on various input strategies to evaluate and simulate them. For the application of global natural gas demand, results suggest a gentle uptrend for the reference case (about 4232 bcm in 2025). The alternative scenarios considered support a continued increase for the global natural gas demand, but at different rates depending on the removal or addition of multiple natural gas suppliers (from 2013 to 2025, the scenarios considered display demand growth varying from 23.5% to 25%).",
        "DOI": "10.1016/j.energy.2021.120167",
        "affiliation_name": "DWA Energy Ltd.",
        "affiliation_city": "Lincoln",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "ML-driven classification scheme for dynamic interference-aware resource scheduling in cloud infrastructures[Formula presented]",
        "paper_author": "Meyer V.",
        "publication": "Journal of Systems Architecture",
        "citied_by": "19",
        "cover_date": "2021-06-01",
        "Abstract": "Computing systems continue to evolve, resulting in increased performance when processing workloads in large data centers due to the virtualization benefits. This technology is the key factor that allows multiple applications to share resources, thereby enhancing the overall hardware utilization of cloud computing environments. However, multiple cloud-services contending for shared resources are susceptible to cross-application interference, which can lead to significant performance degradation and, consequently, an increase in Service Level Agreements violations. Nevertheless, state-of-the-art resource scheduling still relies mainly on resource capacity, adopting heuristics such as bin-packing and overlooking this source of overhead. But in recent years, interference-aware scheduling has gained traction, with the investigation of ways to classify applications regarding their interference levels and the proposal of static interference models and policies for scheduling co-hosted cloud applications. The preliminary results already show a considerable improvement in resource utilization and can be considered as the first steps toward a dynamic scheduling strategy. In this scenario, this paper proposes a machine learning-driven classification scheme for dynamic interference-aware resource scheduling in cloud computing environments. The main goal is to present how a classification approach, that better represents the workload variations, affects resource scheduling. In the first place, we analyze how hardware resources react to different applications with dynamic workloads. Then, we explore distinct interference classification formats and evaluate their efficiency, taking the dynamic nature of cloud workloads into account. Lastly, we present an interference-aware application classifier based on machine learning techniques and compare it with related work, adopting a variety of workload patterns. Preliminary results revealed an improvement in resource utilization efficiency by 27%, on average, when applying our classification approach in cloud infrastructures.",
        "DOI": "10.1016/j.sysarc.2021.102064",
        "affiliation_name": "Pontifícia Universidade Católica do Rio Grande do Sul",
        "affiliation_city": "Porto Alegre",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "SFC Embedding Meets Machine Learning: Deep Reinforcement Learning Approaches",
        "paper_author": "Liu Y.",
        "publication": "IEEE Communications Letters",
        "citied_by": "37",
        "cover_date": "2021-06-01",
        "Abstract": "Service function chain (SFC) has been recognized as one of the most important technologies that can satisfy dynamic service demands in the edge clouds. However, how to efficiently embed SFCs in the dynamic edge-cloud scenarios remains as a challenging problem. Considering different network topologies, we devise two deep reinforcement learning (DRL)-based methods for two network sizes: a deep deterministic policy gradient (DDPG) based method for the small-scale networks and an asynchronous advantage actor-critic (A3C) based approach for the large-scale networks. Simulation results demonstrate that our proposals can efficiently deal with the SFC-DMP in edge clouds and outperform the state-of-the-art methods in terms of the delay.",
        "DOI": "10.1109/LCOMM.2021.3061991",
        "affiliation_name": "Peoples Liberation Army Engineering University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Interpretation of contextual influences with explanatory tools: Travel mode likelihood mapping using GPS trajectories",
        "paper_author": "Lee K.",
        "publication": "Transactions in GIS",
        "citied_by": "1",
        "cover_date": "2021-06-01",
        "Abstract": "Past studies have failed to address the spatially and temporally varying impacts of environmental factors regarding the uncertain geographic context problem. This study seeks to provide an innovative framework to facilitate the understanding of spatially and temporally varying impacts of multiple contexts on individuals' travel modes using GIS and machine learning techniques. It adopts machine learning techniques to create likelihood maps to predict the spatiotemporal patterns of individual travel behaviors and uses explanatory tools to explore the spatially and temporally varying impacts. The most notable change at a local level in the spatial dimension was that assaults and offenses involving children turned out to be important in two selected communities in Chicago. Regarding the temporally varying impact, batteries, other offenses, and robberies showed negative associations with the walking prediction to some extent at the afternoon peak (5–7:59 p.m.) during weekdays. The proposed approach will enable meaningful interpretation of complex interactions between multiple environmental factors and individual travel behaviors to suggest policies in urban planning and design.",
        "DOI": "10.1111/tgis.12729",
        "affiliation_name": "University of Seoul",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Effectiveness of autoencoder for lake area extraction from high-resolution RGB imagery: an experimental study",
        "paper_author": "Tercan E.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "7",
        "cover_date": "2021-06-01",
        "Abstract": "The surface areas of lakes alter constantly due to many factors such as climate change, land use policies, and human interventions, and their surface areas tend to decrease. It is necessary for obtain baseline datasets such as surface areas and boundaries of water bodies with high accuracy, effectively, economically, and practically by using satellite images in terms of management and planning of lakes. Extracting surface areas of water bodies using image classification algorithms and high-resolution RGB satellite images and evaluating the effectiveness of different image classification algorithms have become an important research domain. In this experimental study, eight different machine learning-based classification approaches, namely, k-nearest neighborhood (kNN), subspaced kNN, support vector machines (SVMs), random forest (RF), bagged tree (BT), Naive Bayes (NB), and linear discriminant (LD), have been utilized to extract the surface areas of lakes. Lastly, autoencoder (AE) classification algorithm was applied, and the effectiveness of all those algorithms was compared. Experimental studies were carried out on three different lakes (Hazar Lake, Salda Lake, Manyas Lake) using high-resolution Turkish RASAT RGB satellite images. The results indicated that AE algorithm obtained the highest accuracy values in both quantitative and qualitative analyses. Another important aspect of this study is that Structural Similarity Index (SSIM) and Universal Image Quality Index (UIQI) metrics that can evaluate close to human perception are used for comparison. With this application, it has been shown that overall accuracy calculated from test data may be inadequate in some cases by using SSIM, UIQI, mean squared error (MSE), peak signal to noise ratio (PSNR), and Cohen’s KAPPA metrics. In the last application, the robustness of AE was examined with boxplots.",
        "DOI": "10.1007/s11356-021-12893-y",
        "affiliation_name": "Republic of Turkey General Directorate of Highways",
        "affiliation_city": "Ankara",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Estimation of ambient PM<inf>2.5</inf> in Iraq and Kuwait from 2001 to 2018 using machine learning and remote sensing",
        "paper_author": "Li J.",
        "publication": "Environment International",
        "citied_by": "61",
        "cover_date": "2021-06-01",
        "Abstract": "Iraq and Kuwait are in a region of the world known to be impacted by high levels of fine particulate matter (PM2.5) attributable to sources that include desert dust and ambient pollution, but historically have had limited pollution monitoring networks. The inability to assess PM2.5 concentrations have limited the assessment of the health impact of these exposures, both in the native populations and previously deployed military personnel. As part of a Department of Veterans Affairs Cooperative Studies Program health study of land-based U.S. military personnel who were previously deployed to these countries, we developed a novel approach to estimate spatially and temporarily resolved daily PM2.5 exposures 2001–2018. Since visibility is proportional to ground-level particulate matter concentrations, we were able to take advantage of extensive airport visibility data that became available as a result of regional military operations over this time period. First, we combined a random forest machine learning and a generalized additive mixed model to estimate daily high resolution (1 km × 1 km) visibility over the region using satellite-based aerosol optical depth (AOD) and airport visibility data. The spatially and temporarily resolved visibility data were then used to estimate PM2.5 concentrations from 2001 to 2018 by converting visibility to PM2.5 using empirical relationships derived from available regional PM2.5 monitoring stations. We adjusted for spatially resolved meteorological parameters, land use variables, including the Normalized Difference Vegetation Index, and satellite-derived estimates of surface dust as a measure of sandstorm activity. Cross validation indicated good model predictive ability (R2 = 0.71), and there were considerable spatial and temporal differences in PM2.5 across the region. Annual average PM2.5 predictions for Iraq and Kuwait were 37 and 41 μg/m3, respectively, which are greater than current U.S. and WHO standards. PM2.5 concentrations in many U.S. bases and large cities (e.g. Bagdad, Balad, Kuwait city, Karbala, Najaf, and Diwaniya) had annual average PM2.5 concentrations above 45 μg/m3 with weekly averages as high as 150 μg/m3 depending on calendar year. The highest annual PM2.5 concentration for both Kuwait and Iraq were observed in 2008, followed by 2009, which was associated with extreme drought in these years. The lowest PM2.5 values were observed in 2014. On average, July had the highest concentrations, and November had the lowest values, consistent with seasonal patterns of air pollution in this region. This is the first study that estimates long-term PM2.5 exposures in Iraq and Kuwait at a high resolution based on measurements data that will allow the study of health effects and contribute to the development of regional environmental policies. The novel approach demonstrated may be used in other parts of the world with limited monitoring networks.",
        "DOI": "10.1016/j.envint.2021.106445",
        "affiliation_name": "VA Boston Healthcare System",
        "affiliation_city": "West Roxbury",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An offline multi-scale unsaturated poromechanics model enabled by self-designed/self-improved neural networks",
        "paper_author": "Heider Y.",
        "publication": "International Journal for Numerical and Analytical Methods in Geomechanics",
        "citied_by": "20",
        "cover_date": "2021-06-01",
        "Abstract": "Supervised machine learning via artificial neural network (ANN) has gained significant popularity for many geomechanics applications that involves multi-phase flow and poromechanics. For unsaturated poromechanics problems, the multi-physics nature and the complexity of the hydraulic laws make it difficult to design the optimal setup, architecture, and hyper-parameters of the deep neural networks. This paper presents a meta-modeling approach that utilizes deep reinforcement learning (DRL) to automatically discover optimal neural network settings that maximize a pre-defined performance metric for the machine learning constitutive laws. This meta-modeling framework is cast as a Markov Decision Process (MDP) with well-defined states (subsets of states representing the proposed neural network (NN) settings), actions, and rewards. Following the selection rules, the artificial intelligence (AI) agent, represented in DRL via NN, self-learns from taking a sequence of actions and receiving feedback signals (rewards) within the selection environment. By utilizing the Monte Carlo Tree Search (MCTS) to update the policy/value networks, the AI agent replaces the human modeler to handle the otherwise time-consuming trial-and-error process that leads to the optimized choices of setup from a high-dimensional parametric space. This approach is applied to generate two key constitutive laws for the unsaturated poromechanics problems: (1) the path-dependent retention curve with distinctive wetting and drying paths. (2) The flow in the micropores, governed by an anisotropic permeability tensor. Numerical experiments have shown that the resultant ML-generated material models can be integrated into a finite element (FE) solver to solve initial-boundary-value problems as replacements of the hand-craft constitutive laws.",
        "DOI": "10.1002/nag.3196",
        "affiliation_name": "The Fu Foundation School of Engineering and Applied Science",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "From predictions to prescriptions: A data-driven response to COVID-19",
        "paper_author": "Bertsimas D.",
        "publication": "Health Care Management Science",
        "citied_by": "47",
        "cover_date": "2021-06-01",
        "Abstract": "The COVID-19 pandemic has created unprecedented challenges worldwide. Strained healthcare providers make difficult decisions on patient triage, treatment and care management on a daily basis. Policy makers have imposed social distancing measures to slow the disease, at a steep economic price. We design analytical tools to support these decisions and combat the pandemic. Specifically, we propose a comprehensive data-driven approach to understand the clinical characteristics of COVID-19, predict its mortality, forecast its evolution, and ultimately alleviate its impact. By leveraging cohort-level clinical data, patient-level hospital data, and census-level epidemiological data, we develop an integrated four-step approach, combining descriptive, predictive and prescriptive analytics. First, we aggregate hundreds of clinical studies into the most comprehensive database on COVID-19 to paint a new macroscopic picture of the disease. Second, we build personalized calculators to predict the risk of infection and mortality as a function of demographics, symptoms, comorbidities, and lab values. Third, we develop a novel epidemiological model to project the pandemic’s spread and inform social distancing policies. Fourth, we propose an optimization model to re-allocate ventilators and alleviate shortages. Our results have been used at the clinical level by several hospitals to triage patients, guide care management, plan ICU capacity, and re-distribute ventilators. At the policy level, they are currently supporting safe back-to-work policies at a major institution and vaccine trial location planning at Janssen Pharmaceuticals, and have been integrated into the US Center for Disease Control’s pandemic forecast.",
        "DOI": "10.1007/s10729-020-09542-0",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Feasibility of machine learning methods for predicting hospital emergency room visits for respiratory diseases",
        "paper_author": "Lu J.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "9",
        "cover_date": "2021-06-01",
        "Abstract": "The prediction of hospital emergency room visits (ERV) for respiratory diseases after the outbreak of PM2.5 is of great importance in terms of public health, medical resource allocation, and policy decision support. Recently, the machine learning methods bring promising solutions for ERV prediction in view of their powerful ability of short-term forecasting, while their performances still exist unknown. Therefore, we aim to check the feasibility of machine learning methods for ERV prediction of respiratory diseases. Three different machine learning models, including autoregressive integrated moving average (ARIMA), multilayer perceptron (MLP), and long short-term memory (LSTM), are introduced to predict daily ERV in urban areas of Beijing, and their performances are evaluated in terms of the mean absolute error (MAE), root mean squared error (RMSE), mean absolute percentage error (MAPE), and coefficient of determination (R2). The results show that the performance of ARIMA is the worst, with a maximum R2 of 0.70 and minimum MAE, RMSE, and MAPE of 99, 124, and 26.56, respectively, while MLP and LSTM perform better, with a maximum R2 of 0.80 (0.78) and corresponding MAE, RMSE, and MAPE of 49 (33), 62 (42), and 14.14 (9.86). In addition, it demonstrates that MLP cannot detect the time lag effect properly, while LSTM does well in the description and prediction of exposure-response relationship between PM2.5 pollution and infecting respiratory disease.",
        "DOI": "10.1007/s11356-021-12658-7",
        "affiliation_name": "Southern Marine Science and Engineering Guangdong Laboratory",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Adversarial Network Traffic: Towards Evaluating the Robustness of Deep-Learning-Based Network Traffic Classification",
        "paper_author": "Sadeghzadeh A.M.",
        "publication": "IEEE Transactions on Network and Service Management",
        "citied_by": "65",
        "cover_date": "2021-06-01",
        "Abstract": "Network traffic classification is used in various applications such as network traffic management, policy enforcement, and intrusion detection systems. Although most applications encrypt their network traffic and some of them dynamically change their port numbers, Machine Learning (ML) and especially Deep Learning (DL)-based classifiers have shown impressive performance in network traffic classification. In this article, we evaluate the robustness of DL-based network traffic classifiers against Adversarial Network Traffic (ANT). ANT causes DL-based network traffic classifiers to predict incorrectly using Universal Adversarial Perturbation (UAP) generating methods. Since there is no need to buffer network traffic before sending ANT, it is generated live. We partition the input space of the DL-based network traffic classification into three categories: packet classification, flow content classification, and flow time series classification. To generate ANT, we propose three new attacks injecting UAP into network traffic. AdvPad attack injects a UAP into the content of packets to evaluate the robustness of packet classifiers. AdvPay attack injects a UAP into the payload of a dummy packet to evaluate the robustness of flow content classifiers. AdvBurst attack injects a specific number of dummy packets with crafted statistical features based on a UAP into a selected burst of a flow to evaluate the robustness of flow time series classifiers. The results indicate injecting a little UAP into network traffic, highly decreases the performance of DL-based network traffic classifiers in all categories.",
        "DOI": "10.1109/TNSM.2021.3052888",
        "affiliation_name": "Sharif University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Machine intelligence approach: To solve load balancing problem with high quality of service performance for multi-controller based Software Defined Network",
        "paper_author": "Srivastava V.",
        "publication": "Sustainable Computing: Informatics and Systems",
        "citied_by": "6",
        "cover_date": "2021-06-01",
        "Abstract": "In this paper, we have proposed a DRL based method to obtain the route based on an optimized load of SDN which is based on self-learning of human intelligence. In this proposal, the Bio-Inspired RBM is used for Bio-Inspired Deep Belief Architecture (BDBA) for implementing deep learning to obtain the optimized route. This Bio-Inspired RBM has two parts one is simple RBM and another part is inspired by self-learning of human intelligence based on emotion learning of the limbic system of the brain. Every Bio-Inspired RBM is fined tune using the reward function R which captures the environmental dynamics in the form of network policies. Software Defined Network (SDN) concept resolves several problems of network infrastructure to decouple the responsibilities of the control plane and data plane. The single controller improves control on the network but decreases the reliability of the system in the case of failure of the controller. The distributed controller improves reliability and also reduces system failure. The route optimization is a big challenge in distributed SDN. Some route optimization techniques have been proposed which requires some prior knowledge. Deep Reinforcement Learning (DRL) is one of the techniques for route optimization which does not require any prior knowledge and runs in real-time. This technique learns from environment dynamics and optimizes anonymously. The high demand for internet usages and business activities using distributed SDN also facing complex problems that can be resolved using the self-learning methodology of human intelligence. Self-learning of human intelligence plays a dominant role in making complex decisions for any sudden problem.",
        "DOI": "10.1016/j.suscom.2021.100511",
        "affiliation_name": "Birla Institute of Technology, Mesra",
        "affiliation_city": "Ranchi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A Network Intelligence Architecture for Efficient VNF Lifecycle Management",
        "paper_author": "Lange S.",
        "publication": "IEEE Transactions on Network and Service Management",
        "citied_by": "22",
        "cover_date": "2021-06-01",
        "Abstract": "Network softwarization paradigms such as SDN and NFV provide network operators with advantages in terms of scalability, cost and resource efficiency, as well as flexibility. However, in order to fully reap these benefits and cope with new challenges regarding the heterogeneity of user demands and an ever-growing service landscape, management and operation of such networks requires a high degree of automation that ensures fast and proactive decision making. With the recent success of machine learning (ML) across numerous domains, a shift from traditional rule-based policies towards ML-based approaches in the context of network management is taking place. Although many individual contributions cover use cases such as predicting various network characteristics or optimizing the configuration of components, a fully integrated architecture for achieving Network Intelligence is still missing. Hence, in this work, we propose such an architecture that combines the capabilities of softwarized networks with ML-based management. The contribution of this article is threefold: first, we present the proposed architecture alongside its components. Second, we implement a proof-of-concept version of all components in our OpenStack-based testbed. Finally, we demonstrate in a case study regarding VNF resource prediction how the proposed architecture can be used to generate realistic data sets to train and evaluate ML-based models for this task.",
        "DOI": "10.1109/TNSM.2020.3015244",
        "affiliation_name": "Pohang University of Science and Technology",
        "affiliation_city": "Pohang",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Fertile soil for intrapreneurship: Impartial institutions and human capital",
        "paper_author": "Ljunge M.",
        "publication": "Journal of Institutional Economics",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "Intrapreneurs, entrepreneurial employees, constitute an important force behind innovations in the economy. Yet, what factors that promote intrapreneurship at the country level are an underdeveloped research area. This paper provides an important contribution regarding the methodological approach and the broad set of potential explanatory factors studied. Based on machine-learning techniques (Least Absolute Shrinkage and Selection Operator (LASSO) and Extreme Bounds Analysis (EBA)), we investigate the influence of over 60 factors capturing institutional, demographic, cultural, and developmental factors. We find that the quality of government measured as impartiality, i.e. that the public institutions treat the citizens in a non-discriminatory fashion and do not favor some groups or individuals, and the level of human capital, measured as the average years of schooling, are the most important factors predicting the level of intrapreneurship across countries. Instrumental variable results support a causal interpretation. The findings emphasize the importance of policy to establish well-functioning and impartial institutions as well as to promote higher education.",
        "DOI": "10.1017/S1744137420000612",
        "affiliation_name": "Research Institute of Industrial Economics",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Hybrid machine learning based energy policy and management in the renewable-based microgrids considering hybrid electric vehicle charging demand",
        "paper_author": "Lei M.",
        "publication": "International Journal of Electrical Power and Energy Systems",
        "citied_by": "56",
        "cover_date": "2021-06-01",
        "Abstract": "In this paper, a secured energy management architecture for both islanded and grid-connected operation modes of renewable hybrid AC-DC microgrids considering various renewable energy sources, distributed power generation units, energy storage, and plug-in hybrid electric vehicles (PHEV) is proposed. In this architecture, whale optimization algorithm (WOA) is employed to minimize the operation cost of the grid and also an intrusion detection system (IDS) based on the sequential hypothesis testing (SHT) approach is introduced to detect identity-based cyber-attacks (i.e. Sybil attack, masquerading attack) on the wireless-based advanced metering infrastructures (AMI). The proposed IDS makes use of the received signal strength (RSS) value to distinguish different signal sources and detect cyber-attacks. The feasibility and performance of the proposed architecture are tested on a practical hybrid microgrid, which is constructed based on the IEEE 33-bus test system. the results are provided for both islanded and grid-connected operation modes.",
        "DOI": "10.1016/j.ijepes.2020.106702",
        "affiliation_name": "Shiraz University of Technology",
        "affiliation_city": "Shiraz",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "How to survive a pandemic: The corporate resiliency of travel and leisure companies to the COVID-19 outbreak",
        "paper_author": "Kaczmarek T.",
        "publication": "Tourism Management",
        "citied_by": "90",
        "cover_date": "2021-06-01",
        "Abstract": "What protects travel and leisure companies from a global pandemic, such as COVID-19? To answer this question, we investigate data on over 1200 travel and leisure companies in 52 countries. We consider 80 characteristics, such as company financial ratios, macroeconomic variables, and government policy responses. Using regressions and machine learning tools, we demonstrate that firms with low valuations, limited leverage, and high investments have been more immune to the pandemic-induced crash. We also find a beneficial effect of stringent containment and closure policies. Finally, our results indicate that countries with less individualism may be better positioned to cope with the pandemic. Our findings have implications for regulatory bodies, managers, and investors concerning future pandemic outbreaks.",
        "DOI": "10.1016/j.tourman.2020.104281",
        "affiliation_name": "Montpellier Business School",
        "affiliation_city": "Montpellier",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Health-Behaviors Associated With the Growing Risk of Adolescent Suicide Attempts: A Data-Driven Cross-Sectional Study",
        "paper_author": "Wei Z.",
        "publication": "American Journal of Health Promotion",
        "citied_by": "9",
        "cover_date": "2021-06-01",
        "Abstract": "Purpose: Identify and examine the associations between health behaviors and increased risk of adolescent suicide attempts, while controlling for socio-economic and demographic differences. Design: A data-driven analysis using cross-sectional data. Setting: Communities in the state of Montana from 1999 to 2017. Selected Montana as it persistently ranks among the top 3 vulnerable states in the U.S. over the past years. Subjects: Selected 22,447 adolescents of whom 1,631 adolescents attempted suicide at least once. Measures: Overall 29 variables (predictors) accounting for psychological behaviors, illegal substances consumption, daily activities at schools and demographic backgrounds were considered. Analysis: A library of machine learning algorithms along with the traditionally-used logistic regression were used to model and predict suicide attempt risk. Model performances—goodness-of-fit and predictive accuracy—were measured using accuracy, precision, recall and F-score metrics. Additionally, χ2 analysis was used to evaluate the statistical significance of each variable. Results: The non-parametric Bayesian tree ensemble model outperformed all other models, with 80.0% accuracy in goodness-of-fit (F-score: 0.802) and 78.2% in predictive accuracy (F-score: 0.785). Key health-behaviors identified include: being sad/hopeless (p < 0.0001), followed by safety concerns at school (p < 0.0001), physical fighting (p < 0.0001), inhalant usage (p < 0.0001), illegal drugs consumption at school (p < 0.0001), current cigarette usage (p < 0.0001), and having first sex at an early age (below 15 years of age). Additionally, the minority groups (American Indian/Alaska Natives, Hispanics/Latinos) (p < 0.0001), and females (p < 0.0001) are also found to be highly vulnerable to attempting suicides. Conclusion: Significant contribution of this work is understanding the key health-behaviors and health disparities that lead to higher frequency of suicide attempts among adolescents, while accounting for the non-linearity and complex interactions among the outcome and the exposure variables. Findings provide insights on key health-behaviors that can be viewed as early warning signs/precursors of suicide attempts among adolescents.",
        "DOI": "10.1177/0890117120977378",
        "affiliation_name": "School of Engineering and Applied Sciences",
        "affiliation_city": "Buffalo",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Efficient Batch-Mode Reinforcement Learning Using Extreme Learning Machines",
        "paper_author": "Liu J.",
        "publication": "IEEE Transactions on Systems, Man, and Cybernetics: Systems",
        "citied_by": "8",
        "cover_date": "2021-06-01",
        "Abstract": "As a class of batch-mode reinforcement learning (RL) methods for Markov decision problems with large or continuous state spaces, approximate policy iteration (API) has received increasing attention in the past decades. One open problem in the design of API algorithms is how to construct the basis functions or features for value function approximation (VFA). In this paper, we propose a novel batch-mode RL approach with randomly projected features for VFA. The proposed approach can be viewed as an extension of extreme learning machines (ELMs) to RL problems so it can be called ELM-API. The ELMs have been popularly studied in supervised learning problems, but there is not much work on the extension of ELMs to learning control problems. The proposed approach has advantages over the previous API algorithms in that the features for VFA can be quickly generated without complex parameter selection and the performance will be adaptive to different sample sets in batch-mode RL. In particular, the ELM-API approach can realize fast and efficient feature reconstruction when training sample sets are relatively small. Comprehensive simulation studies on two benchmark learning control problems were carried out to test the performance of API algorithms with different feature construction methods. It is shown that the ELM-API algorithm can obtain comparable or better performance than the previous API approaches. To further show the effectiveness of ELM-API in real-world applications, the simulation results on a more challenging high-dimensional lane-changing decision problem in dynamic traffic environment are also reported, which show the capability of the ELM-API algorithm in learning satisfactory lane-changing policies with high data efficiency.",
        "DOI": "10.1109/TSMC.2019.2926806",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Conflicting roles for humans in learning health systems and AI-enabled healthcare",
        "paper_author": "Kasperbauer T.J.",
        "publication": "Journal of Evaluation in Clinical Practice",
        "citied_by": "5",
        "cover_date": "2021-06-01",
        "Abstract": "The goals of learning health systems (LHS) and of AI in medicine overlap in many respects. Both require significant improvements in data sharing and IT infrastructure, aim to provide more personalized care for patients, and strive to break down traditional barriers between research and care. However, the defining features of LHS and AI diverge when it comes to the people involved in medicine, both patients and providers. LHS aim to enhance physician-patient relationships while developments in AI emphasize a physicianless experience. LHS also encourage better coordination of specialists across the health system, but AI aims to replace many specialists with technology and algorithms. This paper argues that these points of conflict may require a reconsideration of the role of humans in medical decision making. Although it is currently unclear to what extent machines will replace humans in healthcare, the parallel development of LHS and AI raises important questions about the exact role for humans within AI-enabled healthcare.",
        "DOI": "10.1111/jep.13510",
        "affiliation_name": "IU Center for Bioethics",
        "affiliation_city": "Indianapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Network policy aware placement of tasks for elastic applications in IaaS-cloud environment",
        "paper_author": "Sridharan R.",
        "publication": "Cluster Computing",
        "citied_by": "7",
        "cover_date": "2021-06-01",
        "Abstract": "Using cloud computing as a base, new technologies like data analytics, Internet of Things, machine learning etc., have emerged. Applications that use these technologies, depend on cloud datacenters (DC) for their computing power. Performance of these applications depends on dynamic resource provisioning by DC, as there is unpredictability of rate at which data arrives for immediate processing. Cloud service providers implement this dynamism in Infrastructure-as-a-Service (IaaS) environment, using elastic virtual machines (VM). Placing these VMs onto same physical machines (PM) and/or on the network neighborhood machines is believed to increase application performance as the network latency is minimal. Deploying sub-optimal VM placement schemes creates unwanted cross network traffic resulting in poor application performance and increases the DC operating cost. This paper formulates the policy and elastic aware placement (PEAP) as an optimization problem, with additional constraints such as fixed PM, balanced PM and co-location VMs. Further, we propose PEAP algorithm which considers individual requests demanding for one or more VMs as a whole for placement along with the life-time of requests. Proposed algorithm gives optimal VM placements for increased application performance and DC efficacy. CloudSimPlus based experiments demonstrate that as compared to first fit decreasing (FFD). First fit increasing (FFI) and first come first serve (FCFS) algorithms, the proposed technique leads to reduced resource fragmentation and resource migrations. PEAP achieves placement of all the elastic VMs together with reduced network cost, thereby increasing the application performance.",
        "DOI": "10.1007/s10586-020-03194-z",
        "affiliation_name": "National Institute of Technology Tiruchirappalli",
        "affiliation_city": "Tiruchirappalli",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Drivers and challenges of precision agriculture: a social media perspective",
        "paper_author": "Ofori M.",
        "publication": "Precision Agriculture",
        "citied_by": "46",
        "cover_date": "2021-06-01",
        "Abstract": "Precision agriculture, which has existed for over four decades, ensures efficient use of agricultural resources for increased productivity and sustainability with the use of technology. Due to the lingering perception that the adoption of precision agriculture has been slow, this study examines public thoughts on the practice of precision agriculture by employing social media analytics. A machine learning-based social media analytics tool—trained to identify and classify posts using lexicons, emoticons, and emojis—was used to capture sentiments and emotions of social media users towards precision agriculture. The study also validated the drivers and challenges of precision agriculture by comparing extant literature with social media data. By mining online data from January 2010 to December 2019, this research captured over 40,000 posts discussing a myriad of concerns related to the practice. An analysis of these posts uncovered joy as the most predominant emotion, also reflected the prevalence of positive sentiments. Robust regulatory and institutional policies that promote both national and international agenda for PA adoption, and the potential of agricultural technology adoption to result in net-positive job creation were identified as the most prevalent drivers. On the other hand, the cost and complexity of currently available technologies, as well as the need for proper data security and privacy were the most common challenges present in social media dialogue.",
        "DOI": "10.1007/s11119-020-09760-0",
        "affiliation_name": "Dakota State University",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An Impact-Oriented Approach to Epidemiological Modeling",
        "paper_author": "Shah N.R.",
        "publication": "Journal of General Internal Medicine",
        "citied_by": "2",
        "cover_date": "2021-06-01",
        "Abstract": "NA",
        "DOI": "10.1007/s11606-020-06230-1",
        "affiliation_name": "Stanford University School of Medicine",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Comparison of Deep Reinforcement Learning and Model Predictive Control for Adaptive Cruise Control",
        "paper_author": "Lin Y.",
        "publication": "IEEE Transactions on Intelligent Vehicles",
        "citied_by": "154",
        "cover_date": "2021-06-01",
        "Abstract": "This study compares Deep Reinforcement Learning (DRL) and Model Predictive Control (MPC) for Adaptive Cruise Control (ACC) design in car-following scenarios. A first-order system is used as the Control-Oriented Model (COM) to approximate the acceleration command dynamics of a vehicle. Based on the equations of the control system and the multi-objective cost function, we train a DRL policy using Deep Deterministic Policy Gradient (DDPG) and solve the MPC problem via Interior-Point Optimization (IPO). Simulation results for the episode costs show that, when there are no modeling errors and the testing inputs are within the training data range, the DRL solution is equivalent to MPC with a sufficiently long prediction horizon. Particularly, the DRL episode cost is only 5.8% higher than the benchmark optimal control solution provided by optimizing the entire episode via IPO. The DRL control performance degrades when the testing inputs are outside the training data range, indicating inadequate machine learning generalization. When there are modeling errors due to control delay, disturbances, and/or testing with a High-Fidelity Model (HFM) of the vehicle, the DRL-trained policy performs better when the modeling errors are large while having similar performances as MPC when the modeling errors are small.",
        "DOI": "10.1109/TIV.2020.3012947",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "The Number of Confirmed Cases of Covid-19 by using Machine Learning: Methods and Challenges",
        "paper_author": "Ahmad A.",
        "publication": "Archives of Computational Methods in Engineering",
        "citied_by": "59",
        "cover_date": "2021-06-01",
        "Abstract": "Covid-19 is one of the biggest health challenges that the world has ever faced. Public health policy makers need the reliable prediction of the confirmed cases in future to plan medical facilities. Machine learning methods learn from the historical data and make predictions about the events. Machine learning methods have been used to predict the number of confirmed cases of Covid-19. In this paper, we present a detailed review of these research papers. We present a taxonomy that groups them in four categories. We further present the challenges in this field. We provide suggestions to the machine learning practitioners to improve the performance of machine learning methods for the prediction of confirmed cases of Covid-19.",
        "DOI": "10.1007/s11831-020-09472-8",
        "affiliation_name": "Liwa College",
        "affiliation_city": "Abu Dhabi",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "What Drives U.S. Congressional Members’ Policy Attention on Twitter?",
        "paper_author": "Hemphill L.",
        "publication": "Policy and Internet",
        "citied_by": "29",
        "cover_date": "2021-06-01",
        "Abstract": "Social media platforms like Twitter enable policymakers to communicate their policy preferences directly and provide a bird's-eye view of their diverse policy agendas. In this article, we leverage politicians’ social media data to study political attention using a supervised machine-learning classifier that detects policy areas in individual tweets. We examine how individual diversity and institutional factors affect differential attention to public policy among members of the U.S. Congress. Our novel approach to measuring policy attention builds on work by the Comparative Agendas Project, in order to study members’ political attention in near real-time and to uncover both intragroup and intergroup differences. Using this classifier, we labeled more than one million tweets and found statistically significant differences in both the level and distribution of attention between parties, chambers, and genders. However, these differences were small enough to suggest that other Congressional members’ characteristics are also at play. We explored institutional factors (e.g., committee assignment, caucus), partisan issue preferences (e.g., issue ownership), and the political environment (e.g., partisan issues, confirmations, etc.) that may help explain the patterns of political attention that appear in Congress's tweets.",
        "DOI": "10.1002/poi3.245",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Policy and the structure of roll call voting in the US house",
        "paper_author": "De Marchi S.",
        "publication": "Journal of Public Policy",
        "citied_by": "4",
        "cover_date": "2021-06-01",
        "Abstract": "Competition in the US Congress has been characterised along a single, left-right ideological dimension. We challenge this characterisation by showing that the content of legislation has far more predictive power than alternative measures, most notably legislators' ideological positions derived from scaling roll call votes. Using a machine learning approach, we identify a topic model for final passage votes in the 111th through the 113th House of Representatives and conduct out-of-sample tests to evaluate the predictive power of bill topics relative to other measures. We find that bill topics and congressional committees are important for predicting roll call votes but that other variables, including member ideology, lack predictive power. These findings raise serious doubts about the claim that congressional politics can be boiled down to competition along a single left-right continuum and shed new light on the debate about levels of polarisation in Congress.",
        "DOI": "10.1017/S0143814X20000069",
        "affiliation_name": "Kent State University",
        "affiliation_city": "Kent",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "‘Where are the people? What are they doing? Why are they doing it?’(Mindell) Situating artificial intelligence within a socio-technical framework",
        "paper_author": "Holton R.",
        "publication": "Journal of Sociology",
        "citied_by": "24",
        "cover_date": "2021-06-01",
        "Abstract": "This article explores the sociology of artificial intelligence (AI), focusing on interactions between social actors and technological processes. The aim is to locate social actors in the key elements of Bell’s framework for understanding AI, featuring big data, algorithms, machine learning, sensors and rationale/logic. We dispute notions of human autonomy and machine autonomy, seeking alternatives to both anthropocentric and technological determinist accounts of AI. While human actors and technological devices are co-producers of the assemblages around AI, we challenge the argument that their respective contributions are symmetrical. The theoretical problem is to establish quite how human actors are positioned asymmetrically within AI processes. This challenge has strong resonances for issues of inequality, democracy, governance and public policy. The theoretical questions raised do not support the argument that sociology should respond to the rise of big data by becoming a primarily empirical discipline.",
        "DOI": "10.1177/1440783319873046",
        "affiliation_name": "University of South Australia",
        "affiliation_city": "Adelaide",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Intelligent Control of a Permanent Magnet DC Motor",
        "paper_author": "Bujgoi G.",
        "publication": "2021 22nd International Carpathian Control Conference, ICCC 2021",
        "citied_by": "0",
        "cover_date": "2021-05-31",
        "Abstract": "This paper presents the use of artificial intelligence for the control of a permanent magnet DC motor. The system can be found especially in robotic systems that perform repetitive operations. The control law is generated by an intelligent Reinforcement Learning algorithm. From the numerous variants of this type of algorithm, the Policy Iteration type algorithm was chosen. The algorithm was experimentally implemented using a data acquisition system and Matlab/Simulink software. The control system was tested for several variants of the load (by changing its inertia moment). The simulation and experimental results show that the intelligent control method based on reinforcement learning has better trajectory tracking and vibrations suppression.",
        "DOI": "10.1109/ICCC51557.2021.9454643",
        "affiliation_name": "University of Craiova",
        "affiliation_city": "Craova",
        "affiliation_country": "Romania"
    },
    {
        "paper_title": "The Home in the Digital Age",
        "paper_author": "Argandoña A.",
        "publication": "The Home in the Digital Age",
        "citied_by": "5",
        "cover_date": "2021-05-31",
        "Abstract": "The Home in the Digital Age is a set of multidisciplinary studies exploring the impact of digital technologies in the home, with a shift of emphasis from technology to the people living and using this in their homes. The book covers a wide variety of topics on the design, introduction and use of digital technologies in the home, combining the technological dimension with the cognitive, emotional, cultural and symbolic dimensions of the objects that incorporate digital technologies and project them onto people's lives. It offers a coherent approach, that of the home, which gives unity to the discussion. Scholars of the home, the house and the family will find here the connection with the problems derived from the use of domestic robots and connected devices. Students of artificial intelligence, machine learning, robotics, big data and other branches of digital technologies will find ideas and arguments to apply their disciplines to the home and participate fruitfully in forums where digital technologies are built and negotiated in the home. Experts from various disciplines psychologists and sociologists; philosophers, epistemologists and ethicists; economists; engineers, architects, urban planners and designers and so on and also those interested in developing policies for the home and family will find this book contains well-founded and useful ideas to focus their work.",
        "DOI": "10.4324/9781003080114",
        "affiliation_name": "IESE Business School",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Optimal Load Balancing with Locality Constraints",
        "paper_author": "Weng W.",
        "publication": "SIGMETRICS 2021 - Abstract Proceedings of the 2021 ACM SIGMETRICS / International Conference on Measurement and Modeling of Computer Systems",
        "citied_by": "4",
        "cover_date": "2021-05-31",
        "Abstract": "Applications in cloud platforms motivate the study of efficient load balancing under job-server constraints and server heterogeneity. In this paper, we study load balancing on a bipartite graph where left nodes correspond to job types and right nodes correspond to servers, with each edge indicating that a job type can be served by a server. Thus edges represent locality constraints, i.e., an arbitrary job can only be served at servers which contain certain data and/or machine learning (ML) models. Servers in this system can have heterogeneous service rates. In this setting, we investigate the performance of two policies named Join-the-Fastest-of-the-Shortest-Queue (JFSQ) and Join-the-Fastest-of-the-Idle-Queue (JFIQ), which are simple variants of Join-the-Shortest-Queue and Join-the-Idle-Queue, where ties are broken in favor of the fastest servers. Under a \"well-connected\"graph condition, we show that JFSQ and JFIQ are asymptotically optimal in the mean response time when the number of servers goes to infinity. In addition to asymptotic optimality, we also obtain upper bounds on the mean response time for finite-size systems. We further show that the well-connectedness condition can be satisfied by a random bipartite graph construction with relatively sparse connectivity.",
        "DOI": "10.1145/3410220.3456279",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Retraction: BSO feature selection based machine learning solar radiation prediction",
        "paper_author": "Kumar T.R.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-05-27",
        "Abstract": "Benefits of solar power production is constantly increasing to the electrical power grid. Renewable energy sources are becoming alternatives for energy resource around the world. In order to reduce environmental pollution and CO2 emissions, an ideal solution is provided to overcome the energy crisis. Renewable energy forecasting improves the accuracy and significantly improved by developing more solar forecasting models using numerical weather predictions. The solar radiation value reaching the system is very important in determining the energy production potential of the solar energy system. In this, we discuss the development of the project with machine learning combined with multiple metrological models to improve the accuracy of solar radiation forecasting. To implement combination of two models, Bird Swarm Optimization algorithm for select features and for classification Convolutional Neural Network is used. CNN is a system prediction which are including numerous atmospheric based on satellite images or several other weather prediction products.",
        "DOI": "10.1088/1742-6596/1916/1/012030",
        "affiliation_name": "Sri Krishna College of Technology",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Transfer learning for multiagent reinforcement learning systems",
        "paper_author": "da Silva F.L.",
        "publication": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
        "citied_by": "6",
        "cover_date": "2021-05-27",
        "Abstract": "Learning to solve sequential decision-making tasks is difficult. Humans take years exploring the environment essentially in a random way until they are able to reason, solve difficult tasks, and collaborate with other humans towards a common goal. Artificial Intelligent agents are like humans in this aspect. Reinforcement Learning (RL) is a well-known technique to train autonomous agents through interactions with the environment. Unfortunately, the learning process has a high sample complexity to infer an effective actuation policy, especially when multiple agents are simultaneously actuating in the environment. However, previous knowledge can be leveraged to accelerate learning and enable solving harder tasks. In the same way humans build skills and reuse them by relating different tasks, RL agents might reuse knowledge from previously solved tasks and from the exchange of knowledge with other agents in the environment. In fact, virtually all of the most challenging tasks currently solved by RL rely on embedded knowledge reuse techniques, such as Imitation Learning, Learning from Demonstration, and Curriculum Learning. This book surveys the literature on knowledge reuse in multiagent RL. The authors define a unifying taxonomy of state-of-the-art solutions for reusing knowledge, providing a comprehensive discussion of recent progress in the area. In this book, readers will find a comprehensive discussion of the many ways in which knowledge can be reused in multiagent sequential decision-making tasks, as well as in which scenarios each of the approaches is more efficient. The authors also provide their view of the current low-hanging fruit developments of the area, as well as the still-open big questions that could result in breakthrough developments. Finally, the book provides resources to researchers who intend to join this area or leverage those techniques, including a list of conferences, journals, and implementation tools. This book will be useful for a wide audience; and will hopefully promote new dialogues across communities and novel developments in the area.",
        "DOI": "10.2200/S01091ED1V01Y202104AIM049",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Interpretability of Machine Learning Solutions in Public Healthcare: The CRISP-ML Approach",
        "paper_author": "Kolyshkina I.",
        "publication": "Frontiers in Big Data",
        "citied_by": "32",
        "cover_date": "2021-05-26",
        "Abstract": "Public healthcare has a history of cautious adoption for artificial intelligence (AI) systems. The rapid growth of data collection and linking capabilities combined with the increasing diversity of the data-driven AI techniques, including machine learning (ML), has brought both ubiquitous opportunities for data analytics projects and increased demands for the regulation and accountability of the outcomes of these projects. As a result, the area of interpretability and explainability of ML is gaining significant research momentum. While there has been some progress in the development of ML methods, the methodological side has shown limited progress. This limits the practicality of using ML in the health domain: the issues with explaining the outcomes of ML algorithms to medical practitioners and policy makers in public health has been a recognized obstacle to the broader adoption of data science approaches in this domain. This study builds on the earlier work which introduced CRISP-ML, a methodology that determines the interpretability level required by stakeholders for a successful real-world solution and then helps in achieving it. CRISP-ML was built on the strengths of CRISP-DM, addressing the gaps in handling interpretability. Its application in the Public Healthcare sector follows its successful deployment in a number of recent real-world projects across several industries and fields, including credit risk, insurance, utilities, and sport. This study elaborates on the CRISP-ML methodology on the determination, measurement, and achievement of the necessary level of interpretability of ML solutions in the Public Healthcare sector. It demonstrates how CRISP-ML addressed the problems with data diversity, the unstructured nature of data, and relatively low linkage between diverse data sets in the healthcare domain. The characteristics of the case study, used in the study, are typical for healthcare data, and CRISP-ML managed to deliver on these issues, ensuring the required level of interpretability of the ML solutions discussed in the project. The approach used ensured that interpretability requirements were met, taking into account public healthcare specifics, regulatory requirements, project stakeholders, project objectives, and data characteristics. The study concludes with the three main directions for the development of the presented cross-industry standard process.",
        "DOI": "10.3389/fdata.2021.660206",
        "affiliation_name": "The MARCS Institute for Brain, Behaviour and Development",
        "affiliation_city": "Bankstown",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Deep Reinforcement Learning Approach for Augmented Reality Games",
        "paper_author": "Magdy R.",
        "publication": "2021 International Mobile, Intelligent, and Ubiquitous Computing Conference, MIUCC 2021",
        "citied_by": "5",
        "cover_date": "2021-05-26",
        "Abstract": "The Augmented Reality (AR) technology has been around since 1968. It has been used in various applications serving different domains. Especially in the gaming domain, AR made a huge success. Nevertheless, these AR games rarely used Machine Learning (ML) techniques. Instead, they used simple kind of Artificial Intelligence (AI) algorithms. Hence, these games are un-realistic and predictable and so players often got bored too quickly.The use of ML enhances the players' experience dramatically and offers new and creative ways to playing games in AR. The main contribution of this paper is to propose a new approach that adopts Deep Reinforcement Learning (DRL) in AR games. In the proposed approach, a new algorithm is introduced to detect the player's behavior and update its policy. To evaluate the proposed approach, the paper introduces a method that gathers synthetic data in a custom-made environment. To study the impact of the proposed approach, we compare DRL policies of the agents before and after applying the proposed algorithm. The results reveal that the accumulative rewards of the proposed algorithm performs better than the untrained policies.",
        "DOI": "10.1109/MIUCC52538.2021.9447671",
        "affiliation_name": "Faculty of Computer Science",
        "affiliation_city": "Cairo",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Machine learning concept-based IoT platforms for smart cities' implementation and requirements",
        "paper_author": "Saravanan M.",
        "publication": "Machine Learning Paradigm for Internet of Things Applications",
        "citied_by": "0",
        "cover_date": "2021-05-25",
        "Abstract": "In developing countries, smart cities are a challenge due to the exponential rise in population. With the rise in demand and availability for goods and facilities, it is now one of the world's most dynamic networks. Intelligent machines are crucial in the construction of critical infrastructure and smart cities in this new age. The increase in population has created new opportunities for smart city management and administration. In the smart city model, information and communication technology (ICT) plays a vital role in policy formulation, decision-making, implementation, and, finally, effective resource allocation. The study's key objective is to explore the role of artificial intelligence, machine learning, and deep reinforcement learning in the evolution of cities. Rapid advancements in computing and hardware, as well as high-speed internet connectivity, have enabled large amounts of data to be transmitted into the physical world.",
        "DOI": "NA",
        "affiliation_name": "VIT Bhopal University",
        "affiliation_city": "Sehore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Analysis of Spurious Local Solutions of Optimal Control Problems: One-Shot Optimization Versus Dynamic Programming",
        "paper_author": "Ding Y.",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "1",
        "cover_date": "2021-05-25",
        "Abstract": "Dynamic programming (DP) has a rich theoretical foundation and a broad range of applications, especially in the classic area of optimal control and the recent area of reinforcement learning (RL). Many optimal control problems can be solved as a single optimization problem, named one-shot optimization, or via a sequence of optimization problems using DP. However, the computation of their global optima often faces the NP-hardness issue due to the non-linearity of the dynamics and non-convexity of the cost, and thus only local optimal solutions may be obtained at best. Furthermore, in many cases arising in machine learning and model-free approaches, DP is the only viable choice, and therefore it is essential to understand when DP combined with a local search solver works. In this work, we introduce the notions of spurious local minimizers for the one-shot optimization and spurious local minimum policies for DP, and show that there is a deep connection between them. In particular, we prove that under mild conditions the DP method using local search can successfully solve the optimal control problem to global optimality if and only if the one-shot optimization is free of spurious solutions. This result paves the way to understand the performance of local search methods in optimal control and RL.",
        "DOI": "10.23919/ACC50511.2021.9483238",
        "affiliation_name": "UC Berkeley’s Industrial Engineering and Operations Research Department",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Neural Stochastic Contraction Metrics for Learning-based Control and Estimation",
        "paper_author": "Tsukamoto H.",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "0",
        "cover_date": "2021-05-25",
        "Abstract": "We present Neural Stochastic Contraction Metrics (NSCM), a new design framework for provably-stable learning-based control and estimation for a class of stochastic nonlinear systems. It uses a spectrally-normalized deep neural network to construct a contraction metric and its differential Lyapunov function, sampled via simplified convex optimization in the stochastic setting. Spectral normalization constrains the state-derivatives of the metric to be Lipschitz continuous, thereby ensuring exponential boundedness of the mean squared distance of system trajectories under stochastic disturbances. The trained NSCM model allows autonomous systems to approximate optimal stable control and estimation policies in real-time, and outperforms existing nonlinear control and estimation techniques including the state-dependent Riccati equation, iterative LQR, EKF, and the deterministic NCM, as shown in simulation results.",
        "DOI": "10.23919/ACC50511.2021.9482701",
        "affiliation_name": "California Institute of Technology Division of Engineering and Applied Science",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "On Distributed Model-Free Reinforcement Learning Control with Stability Guarantee",
        "paper_author": "Mukherjee S.",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "0",
        "cover_date": "2021-05-25",
        "Abstract": "Distributed learning can enable scalable and effective decision making in numerous complex cyber-physical systems such as smart transportation, robotics swarm, power systems, etc. However, stability of the system is usually not guaranteed in most existing learning paradigms; and this limitation can hinder the wide deployment of machine learning in decision making of safety-critical systems. This paper presents a stability-guaranteed distributed reinforcement learning (SGDRL) framework for interconnected linear subsystems, without knowing the subsystem models. While the learning process requires data from a peer-to-peer (p2p) communication architecture, the control implementation of each subsystem is only based on its local states. The stability of the interconnected subsystems will be ensured by a diagonally dominant eigenvalue condition, which will then be used in a model-free RL algorithm to learn the stabilizing control gains. The RL algorithm structure follows an off-policy iterative framework, with interleaved policy evaluation and policy update steps. We numerically validate our theoretical results by performing simulations on four interconnected sub-systems.",
        "DOI": "10.23919/ACC50511.2021.9482972",
        "affiliation_name": "Pacific Northwest National Laboratory",
        "affiliation_city": "Richland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning to be safe, in finite time",
        "paper_author": "Castellano A.",
        "publication": "Proceedings of the American Control Conference",
        "citied_by": "1",
        "cover_date": "2021-05-25",
        "Abstract": "This paper aims to put forward the concept that learning to take safe actions in unknown environments, even with probability one guarantees, can be achieved without the need for an unbounded number of exploratory trials, provided that one is willing to relax its optimality requirements mildly. We focus on the canonical multi-armed bandit problem and seek to study the exploration-preservation trade-off intrinsic within safe learning. More precisely, by defining a handicap metric that counts the number of unsafe actions, we provide an algorithm for discarding unsafe machines (or actions), with probability one, that achieves constant handicap. Our algorithm is rooted in the classical sequential probability ratio test, redefined here for continuing tasks. Under standard assumptions on sufficient exploration, our rule provably detects all unsafe machines in an (expected) finite number of rounds. The analysis also unveils a trade-off between the number of rounds needed to secure the environment and the probability of discarding safe machines. Our decision rule can wrap around any other algorithm to optimize a specific auxiliary goal since it provides a safe environment to search for (approximately) optimal policies. Simulations corroborate our theoretical findings and further illustrate the aforementioned trade-offs.",
        "DOI": "10.23919/ACC50511.2021.9482829",
        "affiliation_name": "Universidad de la Republica",
        "affiliation_city": "Montevideo",
        "affiliation_country": "Uruguay"
    },
    {
        "paper_title": "Future Land Use for Insect Meat Production Among Countries: A Global Classification",
        "paper_author": "Doi H.",
        "publication": "Frontiers in Nutrition",
        "citied_by": "8",
        "cover_date": "2021-05-25",
        "Abstract": "A potentially suitable alternative to reduce land use by livestock production is insect meat production. However, land use predictions for insect meat production, which are important in the planning of food production strategies in each country, have not been well-performed. To consider the strategy of insect meat production with regard to land use, the categorical perspectives of countries would be highly useful. Here, using previous simulation results, we used random forest machine learning to classify the potential land use of 157 countries for insect meat production under future climate change. From the categorical maps, we showed the global distribution of five different country categories and found that the land area of the countries may be an important factor in considering the future increase in insect meat production. Our classification could be used to help formulate future food policies by considering the increase in insect meat production in each country, as well as regionally and/or globally.",
        "DOI": "10.3389/fnut.2021.661056",
        "affiliation_name": "University of Hyogo",
        "affiliation_city": "Kobe",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Carceral-community epidemiology, structural racism, and COVID-19 disparities",
        "paper_author": "Reinhart E.",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "44",
        "cover_date": "2021-05-25",
        "Abstract": "Black and Hispanic communities are disproportionately affected by both incarceration and COVID-19. The epidemiological relationship between carceral facilities and community health during the COVID-19 pandemic, however, remains largely unexamined. Using data from Cook County Jail, we examine temporal patterns in the relationship between jail cycling (i.e., arrest and processing of individuals through jails before release) and community cases of COVID-19 in Chicago ZIP codes. We use multivariate regression analyses and a machine-learning tool, elastic regression, with 1,706 demographic control variables. We find that for each arrested individual cycled through Cook County Jail in March 2020, five additional cases of COVID-19 in their ZIP code of residence are independently attributable to the jail as of August. A total 86% of this additional disease burden is borne by majority-Black and/or -Hispanic ZIPs, accounting for 17% of cumulative COVID-19 cases in these ZIPs, 6% in majority-White ZIPs, and 13% across all ZIPs. Jail cycling in March alone can independently account for 21% of racial COVID-19 disparities in Chicago as of August 2020. Relative to all demographic variables in our analysis, jail cycling is the strongest predictor of COVID-19 rates, considerably exceeding poverty, race, and population density, for example. Arrest and incarceration policies appear to be increasing COVID-19 incidence in communities. Our data suggest that jails function as infectious disease multipliers and epidemiological pumps that are especially affecting marginalized communities. Given disproportionate policing and incarceration of racialized residents nationally, the criminal punishment system may explain a large proportion of racial COVID-19 disparities noted across the United States.",
        "DOI": "10.1073/pnas.2026577118",
        "affiliation_name": "The World Bank, USA",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Demand and supply-side determinants of electric power consumption and representative roadmaps to 100% renewable systems",
        "paper_author": "Ma J.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "9",
        "cover_date": "2021-05-25",
        "Abstract": "The need to transform electric power systems to a cleaner electricity mix to help save the climate is undisputable but existing transition pathways have become unreliable due to inadequate representation of both demand and supply-side determinants of electric power supply, as well as failure to inculcate volatility in electric power systems in the core transition modelling. This study inculcates demand and supply-side determinants to investigate the long- and short-run causal relationships between the electric power system, macroeconomic performance, demography, environmental quality, and capital formation, for Sweden. We also propose and implement econometric and two-stage attention-based machine learning models for volatility-consistent electric power forecasting. Using annual data spanning 1990–2018, the results suggest a long-run relationship exists between electricity generation and the independent variables. Empirical results for the volatility-consistent attention-based machine learning model predict that Sweden's electric power demand in 2050 could reach ∼112 TWh if conservation practices are implemented, and ∼146 TWh if otherwise. If conservation practices are implemented, evidence from selected volatility-consistent simulations show that Sweden can provide 100% of all her electricity demand from cleaner sources by 2030. The findings depict that Sweden must implement stringent and radical policies to achieve its mid-century green electricity targets.",
        "DOI": "10.1016/j.jclepro.2021.126832",
        "affiliation_name": "CSIR - Institute for Scientific and Technological Information",
        "affiliation_city": "Accra",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "2021 IEEE International Black Sea Conference on Communications and Networking, BlackSeaCom 2021",
        "paper_author": "NA",
        "publication": "2021 IEEE International Black Sea Conference on Communications and Networking, BlackSeaCom 2021",
        "citied_by": "0",
        "cover_date": "2021-05-24",
        "Abstract": "The proceedings contain 71 papers. The topics discussed include: implementation and evaluation of age-aware downlink scheduling policies; geometric constellation shaping using initialized autoencoders; analysis and optimization of the network throughput in IEEE 802.15.13 based visible light communication networks; fog computing and D2D networks integration; circuit with directional coupler properties, in microstrip technology, for 2.4GHz ISM band applications; detecting indicators of compromise in web applications using access logs; implementation of a click based IDS on SDN-NFV architecture and performance evaluation; PrEmISES - optimizing the semantically-enabled data used by small and medium enterprises; adaptive MAC protocols for IoT edge computing architectures with event-triggered traffic; and adversarial machine learning security problems for 6g: mmWave beam prediction use-case.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "2021 12th International Conference on Information and Communication Systems, ICICS 2021",
        "paper_author": "NA",
        "publication": "2021 12th International Conference on Information and Communication Systems, ICICS 2021",
        "citied_by": "0",
        "cover_date": "2021-05-24",
        "Abstract": "The proceedings contain 85 papers. The topics discussed include: multi-topic labelling classification based on LSTM; COVID-19 diagnosis in chest X-ray images by combining pre-trained CNN models with flat and hierarchical classification approaches; Arabic topic labeling using naïve bayes (NB); multi-label Arabic text classification based on deep learning; URL phishing detection using machine learning techniques based on URLs lexical analysis; a BERT-based system for multi-topic labeling of Arabic contents; SEFlowViz: a visualization tool for SELinux policy analysis; and alive+: a private cloud messaging system for android devices.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Horizontal Privacy-Preserving Linear Regression Which is Highly Efficient for Dataset of Low Dimension",
        "paper_author": "Lu L.",
        "publication": "ASIA CCS 2021 - Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security",
        "citied_by": "3",
        "cover_date": "2021-05-24",
        "Abstract": "Linear regression is a widely used machine learning model for applications such as personalized health-care prediction, recommendation systems, and policy making etc. Nowadays one important trend of applying this model (also others) is privacy-preserving linear regression, in which multiple parties, each possessing a part of dataset, jointly perform the learning process, while paying a specific attention to the goal of preserving privacy of their data. Consequently some works on how to achieve this goal with various properties appear in recent years. In this paper, we present a new privacy-preserving linear regression protocol for the scenario where dataset is distributed horizontally, which works highly efficiently in particular when training dataset is of low dimension. Our protocol uses two non-colluding servers, in which multiple data providers share their private data, i.e. a dxd matrix where d denotes the dimension of dataset, into two shares and send shares to the two servers respectively which then jointly perform the training process securely. Our technical novelties are as follows. We remark that in the method of solving linear systems (SLS), one mainstream method for linear regression (while the other one is stochastic gradient descent (SGD)), the time complexity only depends on the dimension, regardless of the number of samples. Note that known works using SLS employ garbled circuits for entire linear systems and thus use heavy computation. We implement SLS via the share-computation method which is known for securely implementing SGD and has not been applied to SLS to our knowledge, and thus inherit the advantages from them both (note that SLS admits fast computation when dataset is of low dimension, and the share-computation method is faster than the method of garbled circuits for entire linear systems). In the share-computation for SLS we propose a hybrid method, combining garbled circuits and secret sharing, to realize a secure and round-efficient division for fixed-point number (8+2θ rounds, where θ is a small number of iterations and is set to 5 in our experiment). We then use the division protocol to implement our new protocol for linear regression. As a consequence, our protocol is highly efficient for dataset of low dimension. We implement our protocol in C++ and the experiments show that our protocol is much more efficient than the state of the art implementations for privacy-preserving linear regression for dataset of low dimension.",
        "DOI": "10.1145/3433210.3453105",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Digital Twin Enhanced Assembly Based on Deep Reinforcement Learning",
        "paper_author": "Li J.",
        "publication": "2021 11th International Conference on Information Science and Technology, ICIST 2021",
        "citied_by": "7",
        "cover_date": "2021-05-21",
        "Abstract": "Discrete manufacturing is becoming a popular modality, which places a higher demand on the flexibility of the production line. Traditional assembly lines require extensive manual design and cannot meet the need for flexibility. Due to the rise of reinforcement learning, we suspect that modern algorithms are crucial to further improve the flexibility of assembly. In this paper, we propose a digital twin enhanced assembly method with deep reinforcement learning. A digital twin model of the assembly line is first built. Then, the deep deterministic policy gradient based reinforcement learning agent is trained on the digital twin model. The simulation of the reinforcement learning environment is based on a mixture of simulation engine and real signals. Thus, we can balance the training efficiency and the simulation accuracy. Finally, to validate our proposed method, peg-in-hole assembly experiments were conducted and good results were observed.",
        "DOI": "10.1109/ICIST52614.2021.9440555",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Explainable AI and Reinforcement Learning—A Systematic Review of Current Approaches and Trends",
        "paper_author": "Wells L.",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "131",
        "cover_date": "2021-05-20",
        "Abstract": "Research into Explainable Artificial Intelligence (XAI) has been increasing in recent years as a response to the need for increased transparency and trust in AI. This is particularly important as AI is used in sensitive domains with societal, ethical, and safety implications. Work in XAI has primarily focused on Machine Learning (ML) for classification, decision, or action, with detailed systematic reviews already undertaken. This review looks to explore current approaches and limitations for XAI in the area of Reinforcement Learning (RL). From 520 search results, 25 studies (including 5 snowball sampled) are reviewed, highlighting visualization, query-based explanations, policy summarization, human-in-the-loop collaboration, and verification as trends in this area. Limitations in the studies are presented, particularly a lack of user studies, and the prevalence of toy-examples and difficulties providing understandable explanations. Areas for future study are identified, including immersive visualization, and symbolic representation.",
        "DOI": "10.3389/frai.2021.550030",
        "affiliation_name": "Commonwealth Scientific and Industrial Research Organisation",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Temporal and state abstractions for efficient learning, transfer, and composition in humans.",
        "paper_author": "Xia L.",
        "publication": "Psychological Review",
        "citied_by": "16",
        "cover_date": "2021-05-20",
        "Abstract": "Humans use prior knowledge to efficiently solve novel tasks, but how they structure past knowledge during learning to enable such fast generalization is not well understood. We recently proposed that hierarchical state abstraction enabled generalization of simple one-step rules, by inferring context clusters for each rule. However, humans’ daily tasks are often temporally extended, and necessitate more complex multi-step, hierarchically structured strategies. The options framework in hierarchical reinforcement learning provides a theoretical framework for representing such transferable strategies. Options are abstract multi-step policies, assembled from simpler one-step actions or other options, that can represent meaningful reusable strategies as temporal abstractions. We developed a novel sequential decision-making protocol to test if humans learn and transfer multi-step options. In a series of four experiments, we found transfer effects at multiple hierarchical levels of abstraction that could not be explained by flat reinforcement learning models or hierarchical models lacking temporal abstractions. We extended the options framework to develop a quantitative model that blends temporal and state abstractions. Our model captures the transfer effects observed in human participants. Our results provide evidence that humans create and compose hierarchical options, and use them to explore in novel contexts, consequently transferring past knowledge and speeding up learning. (PsycInfo Database Record (c) 2021 APA, all rights reserved)",
        "DOI": "10.1037/rev0000295",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Dual mode controlled water surface garbage collecting robot by using embedded deep learning",
        "paper_author": "Panyavaraporn J.",
        "publication": "ECTI-CON 2021 - 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology: Smart Electrical System and Technology, Proceedings",
        "citied_by": "3",
        "cover_date": "2021-05-19",
        "Abstract": "Plastic waste has become one of the most prevailing environmental concerns in modern society. Without proper environmental control policies and regulations in place, we have witnessed plastic garbage being irresponsibly disposed of into rivers and other water reservoirs, causing blockage of water passage as well as toxic contamination. Since plastic materials are unable to degrade in nature so quickly as biomaterials, human workers are typically required to collect plastic garbage, either manually or mechanically assisted. In some conditions, the maneuvers could cause personal injuries and infections. To resolve this issue, this paper proposes the design and development of a prototype water surface garbage collecting robot. The prototype was implemented on a Raspberry Pi board and controllable from an Android device via wireless (WiFi™) channel. Controlling robot movement, speed, and conveyor belt could be done either manually or automatically. The former was enabled by intuitive user interface, while the latter relied on deep learning of local scene acquired within active range. Experimental results of automatic operation, driven by deep learning models demonstrated garbage collecting performance at 83.25% accuracy.",
        "DOI": "10.1109/ECTI-CON51831.2021.9454919",
        "affiliation_name": "Suranaree University of Technology",
        "affiliation_city": "Nakhon Ratchasima",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Autonomous Driving Systems: Developing an Approach based on A* and Double Q-Learning",
        "paper_author": "Jamshidi F.",
        "publication": "2021 7th International Conference on Web Research, ICWR 2021",
        "citied_by": "8",
        "cover_date": "2021-05-19",
        "Abstract": "Autonomous driving is the most attractive field to research by academic and industrial socials that intelligent transportation play a vital role in structure of autonomous driving systems. Artificial Intelligence (AI) is an infrastructure for autonomous driving by designing of intelligent machine. Deep Learning is one of subfields of Artificial Intelligence that create models by mimicking human brain's functioning to make decision that it has shown great success in autonomous diving systems field. However, it performs very poorly in some stochastic environments caused by large overestimations of action values. Thus, we use the double estimator to Q-learning to construct Double Q-learning with a new off-policy reinforcement learning algorithm. By this algorithm, we can approximate the maximum expected value for any number of random variables and it underestimate rather than overestimate the maximum expected value. Moreover, we use an optimization method based on A* to improve routing in automation driving. Our proposed approach based on double Q-Learning and A* is evaluated on an example environment with random obstacles and compare results to use Q-Learning alone. Results show the proposed approach has better performance based on duration of trip to destination and collision to obstacles.",
        "DOI": "10.1109/ICWR51868.2021.9443139",
        "affiliation_name": "East China Normal University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "What's my App?: ML-based classification of RTC applications",
        "paper_author": "Markudova D.",
        "publication": "Performance Evaluation Review",
        "citied_by": "5",
        "cover_date": "2021-05-19",
        "Abstract": "With the spread of broadband Internet, Real-Time Communication (RTC) platforms have become increasingly popular and have transformed the way people communicate. Thus, it is fundamental that the network adopts traffic management policies that ensure appropriate Quality of Experience to users of RTC applications. A key step for this is the identification of the applications behind RTC traffic, which in turn allows to allocate adequate resources and make decisions based on the specific application's requirements. In this paper, we introduce a machine learning-based system for identifying the traffic of RTC applications. It builds on the domains contacted before starting a call and leverages techniques from Natural Language Processing (NLP) to build meaningful features. Our system works in real-time and is robust to the peculiarities of the RTP implementations of different applications, since it uses only control traffic. Experimental results show that our approach classifies 5 well-known meeting applications with an F1 score of 0.89.",
        "DOI": "10.1145/3466826.3466841",
        "affiliation_name": "Cisco Systems",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reimagining data responsibility: 10 new approaches toward a culture of trust in re-using data to address critical public needs",
        "paper_author": "Verhulst S.G.",
        "publication": "Data and Policy",
        "citied_by": "14",
        "cover_date": "2021-05-18",
        "Abstract": "Data and data science offer tremendous potential to address some of our most intractable public problems (including the Covid-19 pandemic). At the same time, recent years have shown some of the risks of existing and emerging technologies. An updated framework is required to balance potential and risk, and to ensure that data is used responsibly. Data responsibility is not itself a new concept. However, amid a rapidly changing technology landscape, it has become increasingly clear that the concept may need updating, in order to keep up with new trends such as big data, open data, the Internet of things, and artificial intelligence, and machine learning. This paper seeks to outline 10 approaches and innovations for data responsibility in the 21st century. The 10 emerging concepts we have identified include: End-to-end data responsibility Decision provenance Professionalizing data stewardship From data science to question science Contextual consent Responsibility by design Data asymmetries and data collaboratives Personally identifiable inference Group privacy Data assemblies Each of these is described at greater length in the paper, and illustrated with examples from around the world. Put together, they add up to a framework or outline for policy makers, scholars, and activists who seek to harness the potential of data to solve complex social problems and advance the public good. Needless to say, the 10 approaches outlined here represent just a start. We envision this paper more as an exercise in agenda-setting than a comprehensive survey.",
        "DOI": "10.1017/dap.2021.4",
        "affiliation_name": "New York University",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "MLIoT: An End-to-End Machine Learning System for the Internet-of-Things",
        "paper_author": "Boovaraghavan S.",
        "publication": "IoTDI 2021 - Proceedings of the 2021 International Conference on Internet-of-Things Design and Implementation",
        "citied_by": "12",
        "cover_date": "2021-05-18",
        "Abstract": "Modern Internet of Things (IoT) applications, from contextual sensing to voice assistants, rely on ML-based training and serving systems using pre-trained models to render predictions. However, real-world IoT environments are diverse, with rich IoT sensors and need ML models to be personalized for each setting using relatively less training data. Most existing general-purpose ML systems are optimized for specific and dedicated hardware resources and do not adapt to changing resources and different IoT application requirements. To address this gap, we propose MLIoT, an end-to-end Machine Learning System tailored towards supporting the entire lifecycle of IoT applications. MLIoT adapts to different IoT data sources, IoT tasks, and compute resources by automatically training, optimizing, and serving models based on expressive application-specific policies. MLIoT also adapts to changes in IoT environments or compute resources by enabling re-training, and updating models served on the fly while maintaining accuracy and performance. Our evaluation across a set of benchmarks show that MLIoT can handle multiple IoT tasks, each with individual requirements, in a scalable manner while maintaining high accuracy and performance. We compare MLIoT with two state-of-the-art hand-tuned systems and a commercial ML system showing that MLIoT improves accuracy from 50%-75% while reducing or maintaining latency. &copy; 2021 Owner/Author.",
        "DOI": "10.1145/3450268.3453522",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Understanding the effects of influential factors on housing prices by combining extreme gradient boosting and a hedonic price model (Xgboost-hpm)",
        "paper_author": "Li S.",
        "publication": "Land",
        "citied_by": "26",
        "cover_date": "2021-05-18",
        "Abstract": "The characteristics of housing and location conditions are the main drivers of spatial differences in housing prices, which is a topic attracting high interest in both real estate and geography research. One of the most popular models, the hedonic price model (HPM), has limitations in identifying nonlinear relationships and distinguishing the importance of influential factors. Therefore, extreme gradient boosting (XGBoost), a popular machine learning technology, and the HPM were combined to analyse the comprehensive effects of influential factors on housing prices. XGBoost was employed to identify the importance order of factors and HPM was adopted to reveal the value of the original non-market priced influential factors. The results showed that combining the two models can lead to good performance and increase understanding of the spatial variations in housing prices. Our work found that (1) the five most important variables for Shenzhen housing prices were distance to city centre, green view index, population density, property management fee and economic level; (2) space quality at the human scale had important effects on housing prices; and (3) some traditional factors, especially variables related to education, should be modified according to the development of the real estate market. The results showed that the demonstrated multisource geo-tagged data fusion framework, which integrated XGBoost and HPM, is practical and supports a comprehensive understanding of the relationships between housing prices and influential factors. The findings in this article provide essential implications for informing equitable housing policies and designing liveable neighbourhoods.",
        "DOI": "10.3390/land10050533",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "When Deep Learning May Not Be the Right Tool for Traffic Classification",
        "paper_author": "Ismailaj K.",
        "publication": "Proceedings of the IM 2021 - 2021 IFIP/IEEE International Symposium on Integrated Network Management",
        "citied_by": "7",
        "cover_date": "2021-05-17",
        "Abstract": "Traffic Classification System (TCS) allows inferring the application that is generating given network traffic. Other systems can use this information to enforce specific network policies on the analyzed traffic. In recent years, Traffic Classifier (TC) based on Deep Learning (DL) have outperformed traditional methods such as port-based and statistical Machine Learning (ML). Although these TC can achieve high accuracy on raw data, most of those works do not provide any reasoning or interpretation about how the trained model could achieve such performance. This lack of interpretability may lead to unpredicted behaviour of the systems that consume such information. To understand what the DL models are learning, we conduct a set of experiments reveal what the DL models are learning and we validate our reasoning by building and training simpler ML models that use the revealed features and could even outperform the DL models in some evaluations.",
        "DOI": "NA",
        "affiliation_name": "Universiteit Antwerpen",
        "affiliation_city": "Antwerpen",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Using machine learning to assess public policies: A real case study for supporting SMEs development in Italy",
        "paper_author": "Perboli G.",
        "publication": "2021 IEEE Technology and Engineering Management Conference - Europe, TEMSCON-EUR 2021",
        "citied_by": "3",
        "cover_date": "2021-05-17",
        "Abstract": "In recent years, several initiatives have been taken by governments to support investments in small and medium-sized enterprises. The aim is to foster their access to finance, and thus enhance their competitiveness. This paper investigates, through artificial intelligence, the socio-economic effects of these financial instruments on the performance and business continuity of the beneficiary companies. Moreover, this paper illustrates how artificial intelligence can support public decision-makers in creating and deploying regional policies. This study is a part of the collaboration among Arisk Srl and some policy-makers of the Regional Government of Piedmont (Italy).",
        "DOI": "10.1109/TEMSCON-EUR52034.2021.9488581",
        "affiliation_name": "Politecnico di Torino",
        "affiliation_city": "Turin",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "A hybrid constrained coral reefs optimization algorithm with machine learning for optimizing multi-reservoir systems operation",
        "paper_author": "Emami M.",
        "publication": "Journal of Environmental Management",
        "citied_by": "25",
        "cover_date": "2021-05-15",
        "Abstract": "The continuous growing demand for water, prolonged periods of drought, and climatic uncertainties attributed mainly to climate change mean surface water reservoirs more than ever need to be managed efficiently. Several optimization algorithms have been developed to optimize multi-reservoir systems operation, mostly during severe dry/wet seasons, to mitigate extreme-events consequences. Yet, convergence speed, presence of local optimums, and calculation-cost efficiency are challenging while looking for the global optimum. In this paper, the problem of finding an efficient optimal operation policy in multi-reservoir systems is discussed. The complexity of the long-term operating rules and the reservoirs' upstream and downstream joint-demands projected in recursive constraints make this problem formidable. The original Coral Reefs Optimization (CRO) algorithm, which is a meta-heuristic evolutionary algorithm, and two modified versions have been used to solve this problem. Proposed modifications reduce the calculation cost by narrowing the search space called a constrained-CCRO and adjusting reproduction operators with a reinforcement learning approach, namely the Q-Learning method (i.e., the CCRO-QL algorithm). The modified versions search for the optimum solution in the feasible region instead of the entire problem domain. The models’ performance has been evaluated by solving five mathematical benchmark problems and a well-known continuous four-reservoir system (CFr) problem. Obtained results have been compared with those in the literature and the global optimum, which Linear Programming (LP) achieves. The CCRO-QL is shown to be very calculation-cost-effective in locating the global optimum or near-optimal solutions and efficient in terms of convergence, accuracy, and robustness.",
        "DOI": "10.1016/j.jenvman.2021.112250",
        "affiliation_name": "University of Tehran",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Artificial intelligence to support the integration of variable renewable energy sources to the power system",
        "paper_author": "Boza P.",
        "publication": "Applied Energy",
        "citied_by": "118",
        "cover_date": "2021-05-15",
        "Abstract": "The power sector is increasingly relying on variable renewable energy sources (VRE) whose share in energy production is expected to further increase. A key challenge for adopting these energy sources is their high integration costs. Artificial intelligence (AI) solutions and data-intensive technologies are already used in different parts of the electricity value chain and, due to the growing complexity and data generation potential of the future smart grid, have the potential to create significant value in the system. However, different uncertainties or lack of understanding about its impact often hinder the commitment of decision makers to invest in AI and data intensive technologies, also in the energy sector. While previous work has outlined a number of ways AI solutions can be used in the power sector, the goal of this article is to consider the value creation potential of AI in terms of managing VRE integration costs. We use an economic model of variable renewable integration cost from the literature to present a systematic review of how AI can decrease substantial integration costs. We review a number of use cases and discuss challenges estimating the value creation of AI solutions in the power sector.",
        "DOI": "10.1016/j.apenergy.2021.116754",
        "affiliation_name": "INSEAD, Europe",
        "affiliation_city": "Fontainebleau",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Monitoring data-driven Reinforcement Learning controller training: A comparative study of different training strategies for a real-world energy system",
        "paper_author": "Schreiber T.",
        "publication": "Energy and Buildings",
        "citied_by": "15",
        "cover_date": "2021-05-15",
        "Abstract": "With increasing complexity of building energy systems and rising shares of renewable energies in the grids, the requirements for building automation and control systems (BACS) are increasing. The use of storage systems enables the decoupling of energy demand and supply and to consider dynamic constraints in the control of the systems. The resulting optimization problem is very challenging to solve with the state-of-the-art rule-based-control (RBC) approach. Model Predictive Control (MPC) on the other hand allows a nearly optimal operation but comes with expensive modeling efforts and high computational costs. These drawbacks are contrasted by promising results from the field of Reinforcement Learning (RL). RL can be model-free, is highly adaptive and learns a policy by interacting with the controlled system. However, the literature also addresses a number of questions, to be answered before RL for BACS can be realized. One is the slow convergence of the training process, which makes the application of a pre-training strategy necessary. Therefore, we design and compare different pre-training work-flows for a real-world energy system, in a demand response scenario. We apply a data-driven approach, covering all aspects from raw monitoring data to the trained algorithm. The considered energy system consists of two compression chillers and an ice storage. The objective of the control task is to charge and discharge the storage with respect to dynamic constraints. We use machine learning models of the energy system to train and evaluate a state-of-the-art RL algorithm (DQN) under five different pre-training strategies. We compare, online and offline training and initialization of the RL controller together with a guiding RBC. We demonstrate that offline training with a guiding RBC provides stable learning and a RL controller that always outperforms this guiding RBC. Unguided exploration on the other hand leads to higher accumulated cost savings. Based on our findings, we derive recommendations for practical application and future research questions.",
        "DOI": "10.1016/j.enbuild.2021.110856",
        "affiliation_name": "Rheinisch-Westfälische Technische Hochschule Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Towards the use of Data Engineering, Advanced Visualization techniques and Association Rules to support knowledge discovery for public policies",
        "paper_author": "Conejero J.M.",
        "publication": "Expert Systems with Applications",
        "citied_by": "13",
        "cover_date": "2021-05-15",
        "Abstract": "Education and employment are key aspects of a country's well-being. Governments expend valuable resources on designing education plans and employment programs. These two aspects are usually analysed separately, although, as they are closely related, considering them together might improve their efficacy. The problem lies, at least in part, in the fact that different public entities manage their own data with their own isolated systems, and do not develop joint educational and employment policies. In order to facilitate working towards this goal, in this manuscript, we make use of Data Engineering, Data Visualization, and Intelligent Data Analytics methods to create a decision support system for the Government of Extremadura. Extremadura is a European Union Objective 1 region in Spain with high rates of unemployment and secondary school drop-out. Data Engineering is used to create a Data Warehouse that unifies the different data sources into a central repository for quick access and control. This allows dealing with the challenge of transforming, processing, storing and accessing the data. Data Visualization techniques are applied to create an interactive dashboard that assists users in analysing and interpreting the data in the Data Warehouse repository. Thus, charts, diagrams, and maps are created specifically to help technical or political decision-makers. Finally, Intelligent Data Analytics techniques are used to incorporate Association Rules into the visualization dashboard. Its goal is to identify associations, relationships, and patterns in data that, at least in plain sight, are not readable or interpretable by humans. It does this by inferring knowledge that humans cannot pick out by themselves. As a result, a complete system was defined and implemented to support public administrations in their decision-making and definition of precise evidence-based policies in the areas of education and employment. In particular, it allows the definition of unified strategies to reduce the unemployment rate.",
        "DOI": "10.1016/j.eswa.2020.114509",
        "affiliation_name": "International University of La Rioja",
        "affiliation_city": "Logrono",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Dynamic Energy Dispatch Based on Deep Reinforcement Learning in IoT-Driven Smart Isolated Microgrids",
        "paper_author": "Lei L.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "77",
        "cover_date": "2021-05-15",
        "Abstract": "Microgrids (MGs) are small, local power grids that can operate independently from the larger utility grid. Combined with the Internet of Things (IoT), a smart MG can leverage the sensory data and machine learning techniques for intelligent energy management. This article focuses on deep reinforcement learning (DRL)-based energy dispatch for IoT-driven smart isolated MGs with diesel generators (DGs), photovoltaic (PV) panels, and a battery. A finite-horizon partial observable Markov decision process (POMDP) model is formulated and solved by learning from historical data to capture the uncertainty in future electricity consumption and renewable power generation. In order to deal with the instability problem of DRL algorithms and unique characteristics of finite-horizon models, two novel DRL algorithms, namely, finite-horizon deep deterministic policy gradient (FH-DDPG) and finite-horizon recurrent deterministic policy gradient (FH-RDPG), are proposed to derive energy dispatch policies with and without fully observable state information. A case study using real isolated MG data is performed, where the performance of the proposed algorithms are compared with the other baseline DRL and non-DRL algorithms. Moreover, the impact of uncertainties on MG performance is decoupled into two levels and evaluated, respectively.",
        "DOI": "10.1109/JIOT.2020.3042007",
        "affiliation_name": "ERGON Energy",
        "affiliation_city": "Rockhampton",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Evaluation of Evolutionary Algorithms under Frugal Learning Constraints for Online Policy Capturing",
        "paper_author": "Marois A.",
        "publication": "Proceedings - 2021 IEEE International Conference on Cognitive and Computational Aspects of Situation Management, CogSIMA 2021",
        "citied_by": "1",
        "cover_date": "2021-05-14",
        "Abstract": "Decision making can be modeled in various ways for the design of decision-support systems. One strategy privileged for this purpose is policy capturing, i.e. using statistical techniques (and more recently machine learning) to model judgement policies. The Cognitive Shadow is a prototype tool suited for frugal learning that automatically learns a user's decision pattern in real time based on an ensemble of seven supervised learning algorithms. This tool can provide advisory warnings when the user decision is inconsistent with the predicted outcome. Evolutionary computation methods could reinforce the system's efficiency because of their ability to deal with computational complexity via evolution-inspired optimization mechanisms. The goal of this study was to assess the potential of evolutionary algorithms for frugal learning in an online policy capturing context. To do so, we tested three evolutionary algorithms on three different datasets (each split in three sizes), and compared both their prediction performance and training time with that of the other modeling techniques already implemented in the Cognitive Shadow system. Although all three evolutionary models were generally outperformed by non-evolutionary learning algorithms, one genetic programming method showed good prediction performance for the more complex use cases with the smaller datasets.",
        "DOI": "10.1109/CogSIMA51574.2021.9475930",
        "affiliation_name": "Ecole Nationale Superieure d'Electronique, Informatique et Radiocommunications de Bordeaux",
        "affiliation_city": "Talence",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Subjectivity in the Creation of Machine Learning Models",
        "paper_author": "Cummings M.L.",
        "publication": "Journal of Data and Information Quality",
        "citied_by": "10",
        "cover_date": "2021-05-13",
        "Abstract": "Transportation analysts are inundated with requests to apply popular machine learning modeling techniques to datasets to uncover never-before-seen relationships that could potentially revolutionize safety, congestion, and mobility. However, the results from such models can be influenced not just by biases in underlying data, but also through practitioner-induced biases. To demonstrate the significant number of subjective judgments made in the development and interpretation of machine learning models, we developed Logistic Regression and Neural Network models for transportation-focused datasets including those looking at driving injury/fatalities and pedestrian fatalities. We then developed five different representations of feature importance for each dataset, including different feature interpretations commonly used in the machine learning community. Twelve distinct judgments were highlighted in the development and interpretation of these models, which produced inconsistent results. Such inconsistencies can lead to very different interpretations of the results, which can lead to errors of commission and omission, with significant cost and safety implications if policies are erroneously adapted from such outcomes.",
        "DOI": "10.1145/3418034",
        "affiliation_name": "Pratt School of Engineering",
        "affiliation_city": "Durham",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "AIS-based profiling of fishing vessels falls short as a \"proof of concept\" for identifying forced labor at sea",
        "paper_author": "Swartz W.",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "16",
        "cover_date": "2021-05-11",
        "Abstract": "NA",
        "DOI": "10.1073/pnas.2100341118",
        "affiliation_name": "Memorial University of Newfoundland",
        "affiliation_city": "St John's",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Engineering a large-scale traffic signal control: A multi-agent reinforcement learning approach",
        "paper_author": "Chen Y.",
        "publication": "IEEE INFOCOM 2021 - IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2021",
        "citied_by": "10",
        "cover_date": "2021-05-10",
        "Abstract": "Reinforcement learning is of vital significance in machine learning and is also a promising approach for traffic signal control in urban road networks with assistance of deep neural networks. However, in a large scale urban network, the centralized reinforcement learning approach is beset with difficulties due to the extremely high dimension of joint action space. The multi-agent reinforcement learning (MARL) approach overcomes the high dimension problem by employing distributed local agents whose action space is much smaller. Even though, MARL approach introduces another issue that multiple agents interact with environment simultaneously causing its instability so that training each agent independently may not converge. This paper presents an actor-critic based decentralized MARL approach to control traffic signal which overcomes the shortcomings of both centralized RL approach and independent MARL approach. In particular, a distributed critic network is designed which overcomes the difficulty to train a large-scale neural network in centralized RL approach. Moreover, a difference reward method is proposed to evaluate the contribution of each agent, which accelerates the convergence of algorithm and makes agents optimize policy in a more accurate direction. The proposed MARL approach is compared against the fully independent approach and the centralized learning approach in a grid network. Simulation results demonstrate its effectiveness in terms of average travel speed, travel delay and queue length over other MARL algorithms.",
        "DOI": "10.1109/INFOCOMWKSHPS51825.2021.9484451",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Bayesian online learning for energy-aware resource orchestration in virtualized RANs",
        "paper_author": "Ayala-Romero J.A.",
        "publication": "Proceedings - IEEE INFOCOM",
        "citied_by": "22",
        "cover_date": "2021-05-10",
        "Abstract": "Radio Access Network Virtualization (vRAN) will spearhead the quest towards supple radio stacks that adapt to heterogeneous infrastructure: from energy-constrained platforms deploying cells-on-wheels (e.g., drones) or battery-powered cells to green edge clouds. We perform an in-depth experimental analysis of the energy consumption of virtualized Base Stations (vBSs) and render two conclusions: (i) characterizing performance and power consumption is intricate as it depends on human behavior such as network load or user mobility; and (ii) there are many control policies and some of them have non-linear and monotonic relations with power and throughput. Driven by our experimental insights, we argue that machine learning holds the key for vBS control. We formulate two problems and two algorithms: (i) BP-vRAN, which uses Bayesian online learning to balance performance and energy consumption, and (ii) SBP-vRAN, which augments our Bayesian optimization approach with safe controls that maximize performance while respecting hard power constraints. We show that our approaches are data-efficient and have provably performance, which is paramount for carrier-grade vRANs. We demonstrate the convergence and flexibility of our approach and assess its performance using an experimental prototype.",
        "DOI": "10.1109/INFOCOM42981.2021.9488845",
        "affiliation_name": "I2CAT Foundation",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Short-Term power load forecasting based on combined kernel Gaussian process hybrid model",
        "paper_author": "Lingyu L.",
        "publication": "E3S Web of Conferences",
        "citied_by": "1",
        "cover_date": "2021-05-10",
        "Abstract": "As one of the countries with the most energy consumption in the world, electricity accounts for a large proportion of the energy supply in our country. According to the national basic policy of energy conservation and emission reduction, it is urgent to realize the intelligent distribution and management of electricity by prediction. Due to the complex nature of electricity load sequences, the traditional model predicts poor results. As a kernel-based machine learning model, Gaussian Process Mixing (GPM) has high predictive accuracy, can multi-modal prediction and output confidence intervals. However, the traditional GPM often uses a single kernel function, and the prediction effect is not optimal. Therefore, this paper will combine a variety of existing kernel to build a new kernel, and use it for load sequence prediction. In the electricity load prediction experiments, the prediction characteristics of the load sequences are first analyzed, and then the prediction is made based on the optimal hybrid kernel function constructed by GPM and compared with the traditional prediction model. The results show that the GPM based on the hybrid kernel is not only superior to the single kernel GPM but also superior to some traditional prediction models such as ridge regression, kernel regression and GP.",
        "DOI": "10.1051/e3sconf/202125601009",
        "affiliation_name": "China Southern Power Grid",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Enhancing the understanding of hydrological responses induced by ecological water replenishment using improved machine learning models: A case study in Yongding River",
        "paper_author": "Sun K.",
        "publication": "Science of the Total Environment",
        "citied_by": "44",
        "cover_date": "2021-05-10",
        "Abstract": "The ecological water replenishment (EWR) of Yongding River has been an important project implemented in response to the Development of an Ecological Civilization policy in China since 2016. A reasonable amount of EWR requires a systematic understanding of the relationship among the surface water, groundwater, ecology and economy. However, studying surface water-groundwater interactions still remains an important issue. Thus, a coupled model integrating a Muskingum method-based open channel flow model and machine learning-based groundwater model is developed to describe the dynamic changes in streamflow and groundwater level in response to the EWR of Yongding River. The model is calibrated using observed streamflow data as well as groundwater level data on a daily scale for the spring EWR in 2020. The simulated results match well with the observed data and suggest that significant groundwater level increases occur only around the main channel of Yongding River. Fifteen scenarios under different EWR schemes are set to obtain reasonable streamflow during EWR, and then the responses of streamflow and groundwater level changes are simulated. Reasonable streamflow at the Guanting Reservoir need to be above 65 m3/s to ensure the streamflow can pass through Beijing and significant groundwater level recoveries of 170 million m3 through EWR. The developed models can improve the understanding of the interaction between surface water and groundwater and provide a quick assessment of the factors influencing the different EWR schemes and thus aid in effective EWR project management.",
        "DOI": "10.1016/j.scitotenv.2021.145489",
        "affiliation_name": "Beijing Normal University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Designing for Narrative Influence:: Speculative Storytelling for Social Good in Times of Public Health and Climate Crises",
        "paper_author": "Lc R.A.Y.",
        "publication": "Conference on Human Factors in Computing Systems - Proceedings",
        "citied_by": "9",
        "cover_date": "2021-05-08",
        "Abstract": "Health and safety concerns have led to policies that put individuals under lockdown, but such restrictions lose effectiveness in the long-term due to inherent human needs of connection and physical action. People maintain prosocial behaviors long-term only if they make decisions themselves intrinsically as opposed to forced restrictions. To build systems for effecting positive social purpose in pandemic and environmental concerns, we apply speculative design to create story structures and interactions that promote behaviors for social good. We designed stories and interactions using both plot-based narrative frameworks and character-based machine-learning-generated dialogues for effecting cooperation. We then ran a series of workshops investigating how designers negotiate and collaborate to tell stories for social purpose using a \"finish each other's stories\"approach. This work illustrates the application of design fiction to promote sustainable behavioral patterns that value societal good.",
        "DOI": "10.1145/3411763.3450373",
        "affiliation_name": "City University of Hong Kong",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Dynamic job-shop scheduling in smart manufacturing using deep reinforcement learning",
        "paper_author": "Wang L.",
        "publication": "Computer Networks",
        "citied_by": "163",
        "cover_date": "2021-05-08",
        "Abstract": "Job-shop scheduling problem (JSP) is used to determine the processing order of the jobs and is a typical scheduling problem in smart manufacturing. Considering the dynamics and the uncertainties such as machine breakdown and job rework of the job-shop environment, it is essential to flexibly adjust the scheduling strategy according to the current state. Traditional methods can only obtain the optimal solution at the current time and need to rework if the state changes, which leads to high time complexity. To address the issue, this paper proposes a dynamic scheduling method based on deep reinforcement learning (DRL). In the proposed method, we adopt the proximal policy optimization (PPO) to find the optimal policy of the scheduling to deal with the dimension disaster of the state and action space caused by the increase of the problem scale. Compared with the traditional scheduling methods, the experimental results show that the proposed method can not only obtain comparative results but also can realize adaptive and real-time production scheduling.",
        "DOI": "10.1016/j.comnet.2021.107969",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "ScaleDRL: A Scalable Deep Reinforcement Learning Approach for Traffic Engineering in SDN with Pinning Control",
        "paper_author": "Sun P.",
        "publication": "Computer Networks",
        "citied_by": "43",
        "cover_date": "2021-05-08",
        "Abstract": "As modern communication networks become more complicated and dynamic, designing a good Traffic Engineering (TE) policy becomes difficult due to the complexity of solving the optimal traffic scheduling problem. Traditional methods usually design a fixed model of the network traffic and solve an objective function to get a TE policy, which cannot ensure the solution efficiency. The emerging Deep Reinforcement Learning (DRL) together with the Software-Defined Networking (SDN) technologies provide us with a chance to design a model-free TE scheme through Machine Learning (ML). However, existing DRL-based TE solutions are all faced with a scalability problem, i.e., the solution cannot be applied to large networks. In this paper, we propose to combine the control theory and DRL technology to achieve an efficient network control scheme for TE. The proposed scheme ScaleDRL employs the idea from the pinning control theory to select a subset of links in the network and name them critical links. Based on the traffic distribution information collected by the SDN controller, we use a DRL algorithm to dynamically adjust a set of link weights for the critical links. Through a weighted shortest path algorithm, the forwarding paths of the network flows can be dynamically adjusted using the dynamic link weights. The packet-level simulation shows that ScaleDRL reduces the average end-to-end transmission delay by up to 39% compared to the state-of-the-art DRL-based TE scheme in different network topologies.",
        "DOI": "10.1016/j.comnet.2021.107891",
        "affiliation_name": "National Digital Switching System Engineering &amp; Technological Research Center",
        "affiliation_city": "Zhengzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Android malware detection through machine learning on kernel task structures",
        "paper_author": "Wang X.",
        "publication": "Neurocomputing",
        "citied_by": "45",
        "cover_date": "2021-05-07",
        "Abstract": "With the advent of smart phones, the popularity of free Android applications has risen rapidly. This has led to malicious Android apps being involuntarily installed, which violate the user privacy or conduct attack. Malware detection on Android platforms therefore is a growing concern because of the undesirable similarity between malicious behavior and benign behavior, which can lead to slow detection, and allow compromises to persist for comparatively long periods of time in infected phones. The contributions of this paper are first a multiple dimensional, kernel feature-based framework and feature weight-based detection (WBD) designed to categorize and comprehend the characteristics of Android malware and benign apps. Furthermore, our software agent is orchestrated and implemented for the data collection and storage to scan thousands of benign and malicious apps automatically. We examine 112 kernel attributes of executing the task data structure in the Android system and evaluate the detection accuracy with a number of datasets of various dimensions. We find that memory- and signal-related features contribute to more precise classification than schedule-related and other descriptors of task states listed in our paper. Particularly, memory-related features provide fine-grain classification policies for preserving higher classification precision than the signal-related and others. Furthermore, we study and evaluate 80 newly infected attributes of the Android kernel task structure, prioritizing the 70 features of most significance based on dimensional reduction to optimize the efficiency of high-dimensional classification. Our second contribution is that our experiments demonstrate that, as compared to existing techniques with a short list of task structure features (16 or 32 features), our method can achieve 94%-98% accuracy and 2%–7% false positive rate, while detecting malware apps with reduced-dimensional features that adequately abbreviate online malware detections and advance offline malware inspections.",
        "DOI": "10.1016/j.neucom.2020.12.088",
        "affiliation_name": "Ocean University of China",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Optimal path finding using iterative SARSA",
        "paper_author": "Mohan P.",
        "publication": "Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021",
        "citied_by": "12",
        "cover_date": "2021-05-06",
        "Abstract": "This paper presents a novel and state-of-the-art algorithm named Iterative SARSA to effectively determine the optimal trajectory for an autonomous mobile robot present in an unknown environment. Additionally, a detailed comparative analysis of the proposed algorithm is provided along with other traditional reinforcement learning algorithms using apropos parameters such as path length, computational time, and execution risk. The traditional algorithms used here are Q-learning and SARSA (State-Action-Reward-State-Action). Based on the calculation of next step, these algorithms use either of two reinforcement learning methods - the on-policy or off-policy. While SARSA and Iterative SARSA use the on-policy method, Q-learning utilizes the off-policy method. Optimized trajectory planning along with obstacle avoidance has always been a challenging yet foundational component of various principal applications. Being one of the most primary algorithms of machine learning, any development using Iterative SARSA should render a greater applicative scope.",
        "DOI": "10.1109/ICICCS51141.2021.9432202",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Solar power production forecasting in india using machine learning approach",
        "paper_author": "Garg I.",
        "publication": "Proceedings - 5th International Conference on Intelligent Computing and Control Systems, ICICCS 2021",
        "citied_by": "4",
        "cover_date": "2021-05-06",
        "Abstract": "In this work, the machine learning technique is applied for forecasting of electricity production from solar energy. Electricity consumption per capita (kWh per capita), total electricity consumption in India (GWh), and GDP per capita (INR per capita) are the most influential economic factors in solar power production in India and considered as contributory factors of the proposed model. The best model has the least error in terms of RMSE (0.28), MAD (0.20), and MSE (0.20), along with the best fit of R-squared value. The performance of proposed and conventional models is compared. The proposed model is found to be more accurate. Power generation from solar energy is forecasted 73.66 GW by 2025 and 144.66 GW by 2030. This study will help the government agencies, policymakers to frame policies accordingly. It will give a preliminary idea to the investors to make decisions precisely",
        "DOI": "10.1109/ICICCS51141.2021.9432263",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "The impact of robots and AI/ML on skills and work organisation",
        "paper_author": "Holm J.R.",
        "publication": "Globalisation, New and Emerging Technologies, and Sustainable Development: The Danish Innovation System in Transition",
        "citied_by": "4",
        "cover_date": "2021-05-03",
        "Abstract": "The chapter focuses on how new automation technologies are affecting the skills of employees and their form of work organisation. The analysis makes use of unique data from the 2019 Danish TASK Survey carried out at the employee level which measures work organisation, skills gaps and forms of training for employees using robots, artificial intelligence and machine learning (AI/ML) in their daily work activity. The analysis goes deeper into the effects of robotics and AI/ML for individual workers than previous studies and has policy implications for the performance of the Danish national system of innovation by identifying sectors and occupations that could potentially benefit from increased investments in training for skills development.",
        "DOI": "10.4324/9781003037750-12",
        "affiliation_name": "Aalborg University Business School",
        "affiliation_city": "Aalborg",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Café and restaurant under my home: Predicting urban commercialization through machine learning",
        "paper_author": "Noh S.C.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "3",
        "cover_date": "2021-05-02",
        "Abstract": "The small commercial stores opening in housing structures in Seoul have been soaring since the beginning of this century. While commercialization generally increases urban vitality and achieves land use mix, cafés and restaurants in low-rise residential areas may attract numerous passenger populations, with increased noise and crimes, in the residential area. The urban commercialization is so fast and prevalent that neither urban researchers nor policymakers can respond to it timely without a practical prediction tool. Focusing on cafés and restaurants, we propose an XGBoost machine learning model that can predict commercial store openings in urban residential areas and further play the role of an early warning system. Our findings highlight a large degree of difference in the predictor importance between the variables used in our machine learning model. The most important predictor relates to land price, indicating that economic motivation leads to the conversion of urban housing to small cafés and restaurants. The Mapo neighborhood is predicted to be the most prone to the commercialization of urban housing, therefore, its urgency to be prepared against expected commercialization deserves underscoring. Overall, our results show that the machine learning approach can be applied to predict changes in land uses and contribute to timely policy designs in rapidly changing urban context.",
        "DOI": "10.3390/su13105699",
        "affiliation_name": "Hanshin University",
        "affiliation_city": "Osan",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "A deep neural network-based method for prediction of dementia using big data",
        "paper_author": "Kim J.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "18",
        "cover_date": "2021-05-02",
        "Abstract": "The rise in dementia among the aging Korean population will quickly create a financial burden on society, but timely recognition of early warning for dementia and proper responses to the occurrence of dementia can enhance medical treatment. Health behavior and medical service usage data are relatively more accessible than clinical data, and a prescreening tool with easily accessible data could be a good solution for dementia-related problems. In this paper, we apply a deep neural network (DNN) to prediction of dementia using health behavior and medical service usage data, using data from 7031 subjects aged over 65 collected from the Korea National Health and Nutrition Examination Survey (KNHANES) in 2001 and 2005. In the proposed model, principal component analysis (PCA) featuring and min/max scaling are used to preprocess and extract relevant background features. We compared our proposed methodology, a DNN/scaled PCA, with five wellknown machine learning algorithms. The proposed methodology shows 85.5% of the area under the curve (AUC), a better result than that using other algorithms. The proposed early prescreening method for possible dementia can be used by both patients and doctors.",
        "DOI": "10.3390/ijerph18105386",
        "affiliation_name": "Kent State University",
        "affiliation_city": "Kent",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Building a Purposeful Legacy: Congenital Heart Surgeons Society 2020 Presidential Address",
        "paper_author": "Dearani J.A.",
        "publication": "World Journal for Pediatric and Congenital Heart Surgery",
        "citied_by": "8",
        "cover_date": "2021-05-01",
        "Abstract": "NA",
        "DOI": "10.1177/21501351211006416",
        "affiliation_name": "Mayo Clinic",
        "affiliation_city": "Rochester",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Deep Cybersecurity: A Comprehensive Overview from Neural Network and Deep Learning Perspective",
        "paper_author": "Sarker I.H.",
        "publication": "SN Computer Science",
        "citied_by": "142",
        "cover_date": "2021-05-01",
        "Abstract": "Deep learning, which is originated from an artificial neural network (ANN), is one of the major technologies of today’s smart cybersecurity systems or policies to function in an intelligent manner. Popular deep learning techniques, such as multi-layer perceptron, convolutional neural network, recurrent neural network or long short-term memory, self-organizing map, auto-encoder, restricted Boltzmann machine, deep belief networks, generative adversarial network, deep transfer learning, as well as deep reinforcement learning, or their ensembles and hybrid approaches can be used to intelligently tackle the diverse cybersecurity issues. In this paper, we aim to present a comprehensive overview from the perspective of these neural networks and deep learning techniques according to today’s diverse needs. We also discuss the applicability of these techniques in various cybersecurity tasks such as intrusion detection, identification of malware or botnets, phishing, predicting cyberattacks, e.g. denial of service, fraud detection or cyberanomalies, etc. Finally, we highlight several research issues and future directions within the scope of our study in the field. Overall, the ultimate goal of this paper is to serve as a reference point and guidelines for the academia and professionals in the cyber industries, especially from the deep learning point of view.",
        "DOI": "10.1007/s42979-021-00535-6",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Precise governance of haze pollution based on machine learning",
        "paper_author": "Sun Y.",
        "publication": "Resources Science",
        "citied_by": "2",
        "cover_date": "2021-05-01",
        "Abstract": "The implementation of precise governance of haze pollution is an important measure to deal with haze pollution. Using the PM2.5 of 263 Chinese cities from 2001 to 2016, this study constructed a recursive partitioning analysis method of decision tree based on machine learning, quantified the interactions between haze pollution zoning factors and governance factors, and then identified the haze pollution governance regions and governance factors. The results show that: (1) Geographic location, administrative level, industrial structure, regional planning, and economic zone are the main factors to identify the precise governance regions of urban haze pollution in China. Based on these factors, four types of urban haze pollution governance regions were identified. (2) In coastal cities, increasing the level of economic development and reducing the proportion of the secondary industry are conducive to improving the level of haze pollution governance. In non-coastal cities, reducing population density is helpful for alleviating haze pollution. Furthermore, in non-coastal and non-provincial capital cities, improving the level of science and technology progress is beneficial for controlling haze pollution. (3) The long-term trend of urban haze pollution governance zoning factors in China is highly consistent with the national policies during the“Five-Year Plan”periods. Therefore, scientific policies and precise regulation are conducive to the Precise governance of haze pollution.",
        "DOI": "10.18402/resci.2021.05.02",
        "affiliation_name": "Shandong University of Finance and Economics",
        "affiliation_city": "Jinan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Democracy on a Shoestring",
        "paper_author": "Sellers J.S.",
        "publication": "Vanderbilt Law Review",
        "citied_by": "4",
        "cover_date": "2021-05-01",
        "Abstract": "Democracy requires money. Voters must be registered, voting rolls updated, election dates advertised, voting technology purchased and tested, poll workers trained, ballots designed, votes counted and verified, and on and on. Despite the importance of election expenditures, we have a shamefully inadequate amount of information about how much our elections cost. This Article, based on a novel and painstakingly hand-coded dataset, provides much needed information on election expenditures across multiple years from four states: California, Arizona, Texas, and Florida. These states, given their unique characteristics, provide a compelling sample set. In what we believe to be a completely novel approach to the collection of election expenditure data, we supplement our hand-coded data with predictive machine learning. This allows us to estimate average annual election spending across multiple government units. Our findings, unsurprisingly, reveal great variation both across and within states. But our findings also reveal that much of the variation is seemingly unconnected to poverty, race, and other traditional explanations of electoral disadvantage. This brings into question many basic assumptions legislators, courts, and scholars harbor about election expenditures. Our findings implicate not only policy discussions about election funding but also the limitations of doctrinal interventions and judicial remedies that are divorced from issues of resource allocation. The Article proceeds in five parts: Part I provides background on election funding, including a discussion of election costs and what the most common funding sources are. This Part also discusses election law doctrines and how they do not directly consider election expenditures. Part II outlines our data and methods. Part III presents our main findings. Part IV responds to the findings and explores potential doctrines under which election expenditures might be considered. Part V weighs the pros and cons of several nondoctrinal proposals for election administration reform.",
        "DOI": "NA",
        "affiliation_name": "The University of Oklahoma",
        "affiliation_city": "Norman",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Back to the fields? Increased agricultural land greenness after a COVID-19 lockdown",
        "paper_author": "Hammad A.T.",
        "publication": "Environmental Research Communications",
        "citied_by": "5",
        "cover_date": "2021-05-01",
        "Abstract": "In response to the 2020 COVID-19 pandemic, policymakers worldwide adopted unprecedented measures to limit disease spread, with major repercussions on economic activities and the environment. Here we provide empirical evidence of the impact of a lockdown policy on satellite-measured agricultural land greenness in Badung, a highly populated regency of Bali, Indonesia. Using machine learning and satellite data, we estimate what the Enhanced Vegetation Index (EVI) of cropland would have been without a lockdown. Based on on this counterfactual, we estimate a significant increase in the EVI over agricultural land after the beginning of the lockdown period. The finding is robust to a placebo test. Based on evidence from official reports and international press outlets, we suggest that the observed increase in EVI might be caused by labour reallocation to agriculture from the tourism sector, hardly hit by the lockdown measures. Our results show that machine learning and satellite data can be effectively combined to estimate the effects of exogenous events on land productivity.",
        "DOI": "10.1088/2515-7620/ABFFA4",
        "affiliation_name": "Fondazione Eni Enrico Mattei",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Smart Simon Bot with Public Sentiment Analysis for Novel Covid-19 Tweets Stratification",
        "paper_author": "Ramya B.N.",
        "publication": "SN Computer Science",
        "citied_by": "10",
        "cover_date": "2021-05-01",
        "Abstract": "In present modern era, the outbreak of COVID-19 pandemic has created informational crisis. The public sentiments collected from different reflexions (hashtags, comments, tweets, posts of twitter) are measured accordingly, ensuring different policy decisions and messaging are incorporated. The implementation demonstrates intuition in to the advancement of fear sentiment eventually as COVID-19 approaches maximum levels in the world, by making use of detailed textual analysis with the help of required text data visualization. In addition, technical outline of machine learning stratification approaches are provided in the frame of text analytics, and comparing their efficiency in stratifying coronavirus tweets of different lengths. Using Naïve Bayes method, 91% accuracy is achieved for short tweets and using logistic regression classification method, 74% accuracy is achieved for short tweets.",
        "DOI": "10.1007/s42979-021-00625-5",
        "affiliation_name": "GSSS Institute of Engineering &amp; Technology for Women",
        "affiliation_city": "Mysore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Improved Machine Learning Algorithms for Optimizing Coherent Pulse Stacking Amplification",
        "paper_author": "Du W.",
        "publication": "2021 Conference on Lasers and Electro-Optics, CLEO 2021 - Proceedings",
        "citied_by": "1",
        "cover_date": "2021-05-01",
        "Abstract": "We apply momentum stochastic parallel gradient descent (MSPGD) and policy gradient algorithms to optimize coherent pulse stacking (CPS), and demonstrate their increased effectiveness compared to traditionally used stochastic parallel gradient descent (SPGD) algorithm.",
        "DOI": "NA",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Research on Mobile Caravan Insurance Recommendation Method Based on Machine Learning",
        "paper_author": "Li H.",
        "publication": "Proceedings - 2021 International Conference on Artificial Intelligence, Big Data and Algorithms, CAIBDA 2021",
        "citied_by": "1",
        "cover_date": "2021-05-01",
        "Abstract": "With the continuous progress of computer computing performance, network transmission and other information technology, machine learning methods are more widely used in various industries. In this paper, we study the caravan insurance recommendation algorithm based on machine learning methods for the insurance product recommendation business problem. The article analyses data exploration, data pre-processing, building classification models and balancing data sets, focusing on the taking, distribution and visualisation of the various types of feature fields of the data to show the distribution of variables. Based on the construction of a preliminary logistic regression model, this paper performs a balancing dataset operation to address the problem of dataset imbalance. The results of the model tests show that: user characteristics social class and rental house characteristics have a significant negative effect on the purchase of mobile caravan insurance; private insurance, public equipment and the number of fire insurance policies taken out have a significant positive effect on the purchase of mobile caravan insurance.",
        "DOI": "10.1109/CAIBDA53561.2021.00010",
        "affiliation_name": "Beijing University of Chemical Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "AI-based resource allocation: Reinforcement learning for adaptive auto-scaling in serverless environments",
        "paper_author": "Schuler L.",
        "publication": "Proceedings - 21st IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing, CCGrid 2021",
        "citied_by": "65",
        "cover_date": "2021-05-01",
        "Abstract": "Serverless computing has emerged as a compelling new paradigm of cloud computing models in recent years. It promises the user services at large scale and low cost while eliminating the need for infrastructure management. On cloud provider side, flexible resource management is required to meet fluctuating demand. It can be enabled through automated provisioning and deprovisioning of resources. A common approach among both commercial and open source serverless computing platforms is workload-based auto-scaling, where a designated algorithm scales instances according to the number of incoming requests. In the recently evolving serverless framework Knative a request-based policy is proposed, where the algorithm scales resources by a configured maximum number of requests that can be processed in parallel per instance, the so-called concurrency. As we show in a baseline experiment, this predefined concurrency level can strongly influence the performance of a serverless application. However, identifying the concurrency configuration that yields the highest possible quality of service is a challenging task due to various factors, e.g. varying workload and complex infrastructure characteristics, influencing throughput and latency. While there has been considerable research into intelligent techniques for optimizing auto-scaling for virtual machine provisioning, this topic has not yet been discussed in the area of serverless computing. For this reason, we investigate the applicability of a reinforcement learning approach to request-based auto-scaling in a serverless framework. Our results show that within a limited number of iterations our proposed model learns an effective scaling policy per workload, improving the performance compared to the default auto-scaling configuration.",
        "DOI": "10.1109/CCGrid51090.2021.00098",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Image-Based Social Sensing: Combining AI and the Crowd to Mine Policy-Adherence Indicators from Twitter",
        "paper_author": "Negri V.",
        "publication": "Proceedings - International Conference on Software Engineering",
        "citied_by": "13",
        "cover_date": "2021-05-01",
        "Abstract": "Social Media provides a trove of information that, if aggregated and analysed appropriately can provide important statistical indicators to policy makers. In some situations these indicators are not available through other mechanisms. For example, given the ongoing COVID-19 outbreak, it is essential for governments to have access to reliable data on policy-Adherence with regards to mask wearing, social distancing, and other hard-To-measure quantities. In this paper we investigate whether it is possible to obtain such data by aggregating information from images posted to social media. The paper presents VisualCit, a pipeline for image-based social sensing combining recent advances in image recognition technology with geocoding and crowdsourcing techniques. Our aim is to discover in which countries, and to what extent, people are following COVID-19 related policy directives. We compared the results with the indicators produced within the CovidDataHub behavior tracker initiative. Preliminary results shows that social media images can produce reliable indicators for policy makers.",
        "DOI": "10.1109/ICSE-SEIS52602.2021.00019",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Improving reproducibility in machine learning research (a report from the neurips 2019 reproducibility program)",
        "paper_author": "Pineau J.",
        "publication": "Journal of Machine Learning Research",
        "citied_by": "160",
        "cover_date": "2021-05-01",
        "Abstract": "One of the challenges in machine learning research is to ensure that presented and published results are sound and reliable. Reproducibility, that is obtaining similar results as presented in a paper or talk, using the same code and data (when available), is a necessary step to verify the reliability of research findings. Reproducibility is also an important step to promote open and accessible research, thereby allowing the scientific community to quickly integrate new findings and convert ideas to practice. Reproducibility also promotes the use of robust experimental workows, which potentially reduce unintentional errors. In 2019, the Neural Information Processing Systems (NeurIPS) conference, the premier international conference for research in machine learning, introduced a reproducibility program, designed to improve the standards across the community for how we conduct, communicate, and evaluate machine learning research. The program contained three components: A code submission policy, a community-wide reproducibility challenge, and the inclusion of the Machine Learning Reproducibility checklist as part of the paper submission process. In this paper, we describe each of these components, how it was deployed, as well as what we were able to learn from this initiative.",
        "DOI": "NA",
        "affiliation_name": "Institut Polytechnique de Paris",
        "affiliation_city": "Palaiseau",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Practices for engineering trustworthy machine learning applications",
        "paper_author": "Serban A.",
        "publication": "Proceedings - 2021 IEEE/ACM 1st Workshop on AI Engineering - Software Engineering for AI, WAIN 2021",
        "citied_by": "12",
        "cover_date": "2021-05-01",
        "Abstract": "Following the recent surge in adoption of machine learning (ML), the negative impact that improper use of ML can have on users and society is now also widely recognised. To address this issue, policy makers and other stakeholders, such as the European Commission or NIST, have proposed high-level guidelines aiming to promote trustworthy ML (i.e., lawful, ethical and robust). However, these guidelines do not specify actions to be taken by those involved in building ML systems. In this paper, we argue that guidelines related to the development of trustworthy ML can be translated to operational practices, and should become part of the ML development life cycle. Towards this goal, we ran a multi-vocal literature review, and mined operational practices from white and grey literature. Moreover, we launched a global survey to measure practice adoption and the effects of these practices. In total, we identified 14 new practices, and used them to complement an existing catalogue of ML engineering practices. Initial analysis of the survey results reveals that so far, practice adoption for trustworthy ML is relatively low. In particular, practices related to assuring security of ML components have very low adoption. Other practices enjoy slightly larger adoption, such as providing explanations to users. Our extended practice catalogue can be used by ML development teams to bridge the gap between high-level guidelines and actual development of trustworthy ML systems; it is open for review and contributions.",
        "DOI": "10.1109/WAIN52551.2021.00021",
        "affiliation_name": "Universiteit Leiden",
        "affiliation_city": "Leiden",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Social engineering attack detection using machine learning: Text phishing attack",
        "paper_author": "Alsufyani A.A.",
        "publication": "Indian Journal of Computer Science and Engineering",
        "citied_by": "9",
        "cover_date": "2021-05-01",
        "Abstract": "— The expansion of the internet leads to an increase in the number of cyber-attacks over the days. One of the most common cybersecurity attacks is social engineering, which depends on human physiology. The phishing attack is the most popular form of social engineering. The phishing attacks have many forms, but the traditional one from them is the messages. We need techniques to protect us from these attacks. Awareness, usage policies, and other procedures are not enough. Therefore, we proposed to use natural language processing (NLP) along with machine learning techniques for text phishing detection in this paper. We started with 6,224 emails from an existing dataset that contains both phishing and legitimate emails. NLP was used for preparing the data before extracting features from it and using the features for training the classification models by machine learning algorithm and for testing these models. The features were extracted using Continuous Bag of Words (CBOW) in the Word2Vec algorithm. We training four models using four different machine learning algorithms which are k-nearest neighbors (KNN), Multinomial Naive Bayes (MNB), Decision Tree and AdaBoost. The developed models had to classify the text messages into two categories, which are phishing and legitimate. While the dataset is unbalanced, we used performance measurements for unbalanced data in the evaluation process. Three of our models, that were trained by KNN, Decision Tree and AdaBoost algorithms, obtained considerable values while the MNB model obtained an insignificant value.",
        "DOI": "10.21817/indjcse/2021/v12i3/211203298",
        "affiliation_name": "Taif University",
        "affiliation_city": "Taif",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Machine Learning Algorithms for Predicting the Spread of Covid‒19 in Indonesia",
        "paper_author": "Arlis S.",
        "publication": "TEM Journal",
        "citied_by": "5",
        "cover_date": "2021-05-01",
        "Abstract": "Coronavirus 2019 or Covid-19 is a major problem for health, and it is a global pandemic that has to be controlled. Covid-19 spread so fast to 196 countries, including Indonesia. The government has to study the pattern and predict its spread in order to make policies that will be implemented to tackle the spread of some of the existing data. Therefore this research was conducted as a precautionary measure against the Covid-19 pandemic by predicting the rate of spread of Covid-19. The application of the machine learning method by combining the k-means clustering algorithm in determining the cluster, k-nearest neighbor for prediction and Iterative Dichotomiser (ID3) for mapping patterns is expected to be able to predict the level of spread of Covid-19 in Indonesia with an accuracy rate of 90%.",
        "DOI": "10.18421/TEM102-61",
        "affiliation_name": "Universitas Putra Indonesia",
        "affiliation_city": "Padang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Ensuring that biomedical AI benefits diverse populations",
        "paper_author": "Zou J.",
        "publication": "EBioMedicine",
        "citied_by": "55",
        "cover_date": "2021-05-01",
        "Abstract": "Artificial Intelligence (AI) can potentially impact many aspects of human health, from basic research discovery to individual health assessment. It is critical that these advances in technology broadly benefit diverse populations from around the world. This can be challenging because AI algorithms are often developed on non-representative samples and evaluated based on narrow metrics. Here we outline key challenges to biomedical AI in outcome design, data collection and technology evaluation, and use examples from precision health to illustrate how bias and health disparity may arise in each stage. We then suggest both short term approaches—more diverse data collection and AI monitoring—and longer term structural changes in funding, publications, and education to address these challenges.",
        "DOI": "10.1016/j.ebiom.2021.103358",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Influence of Irrigation Drivers Using Boosted Regression Trees: Kansas High Plains",
        "paper_author": "Lamb S.E.",
        "publication": "Water Resources Research",
        "citied_by": "18",
        "cover_date": "2021-05-01",
        "Abstract": "Groundwater levels across parts of western Kansas have been declining at unsustainable rates due to pumping for agricultural irrigation despite water-saving efforts. Accelerating this decline is the complex agricultural landscape, consisting of both categorical (e.g., management boundaries) and numerical (e.g., crop prices) factors that drive irrigation decisions, making integrated water budget management a challenge. Furthermore, these factors frequently change through time, rendering management strategies outdated within relatively short time scales. This study uses boosted regression trees to simultaneously analyze categorical and numerical data against annual irrigation pumping to determine the relative influence of each factor on groundwater pumping across both space and time. In all, 45 key water use variables covering approximately 19,000 groundwater wells were tested against irrigation pumping from 2006 to 2016 across five categories: (1) management/policy, (2) hydrology, (3) weather, (4) land/agriculture, and (5) economics. Study results showed that variables from all five categories were included among the top 10 drivers to irrigation, and the greatest influence came from variables such as irrigated area per well, saturated thickness, soil permeability, summer precipitation, and pumping costs (depth to water table). Variables that had little influence included regional management boundaries and irrigation technology. The results of this study are further used to target the factors that statistically lead to the greatest volumes of groundwater pumping to help develop robust management strategy suggestions and achieve water management goals of the region.",
        "DOI": "10.1029/2020WR028867",
        "affiliation_name": "University of Nebraska–Lincoln",
        "affiliation_city": "Lincoln",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A COVID-19 pandemic artificial intelligence-based system with deep learning forecasting and automatic statistical data acquisition: Development and implementation study",
        "paper_author": "Yu C.S.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "32",
        "cover_date": "2021-05-01",
        "Abstract": "Background: More than 79.2 million confirmed COVID-19 cases and 1.7 million deaths were caused by SARS-CoV-2; the disease was named COVID-19 by the World Health Organization. Control of the COVID-19 epidemic has become a crucial issue around the globe, but there are limited studies that investigate the global trend of the COVID-19 pandemic together with each country's policy measures. Objective: We aimed to develop an online artificial intelligence (AI) system to analyze the dynamic trend of the COVID-19 pandemic, facilitate forecasting and predictive modeling, and produce a heat map visualization of policy measures in 171 countries. Methods: The COVID-19 Pandemic AI System (CPAIS) integrated two data sets: the data set from the Oxford COVID-19 Government Response Tracker from the Blavatnik School of Government, which is maintained by the University of Oxford, and the data set from the COVID-19 Data Repository, which was established by the Johns Hopkins University Center for Systems Science and Engineering. This study utilized four statistical and deep learning techniques for forecasting: autoregressive integrated moving average (ARIMA), feedforward neural network (FNN), multilayer perceptron (MLP) neural network, and long short-term memory (LSTM). With regard to 1-year records (ie, whole time series data), records from the last 14 days served as the validation set to evaluate the performance of the forecast, whereas earlier records served as the training set. Results: A total of 171 countries that featured in both databases were included in the online system. The CPAIS was developed to explore variations, trends, and forecasts related to the COVID-19 pandemic across several counties. For instance, the number of confirmed monthly cases in the United States reached a local peak in July 2020 and another peak of 6,368,591 in December 2020. A dynamic heat map with policy measures depicts changes in COVID-19 measures for each country. A total of 19 measures were embedded within the three sections presented on the website, and only 4 of the 19 measures were continuous measures related to financial support or investment. Deep learning models were used to enable COVID-19 forecasting; the performances of ARIMA, FNN, and the MLP neural network were not stable because their forecast accuracy was only better than LSTM for a few countries. LSTM demonstrated the best forecast accuracy for Canada, as the root mean square error (RMSE), mean absolute error (MAE), and mean absolute percentage error (MAPE) were 2272.551, 1501.248, and 0.2723075, respectively. ARIMA (RMSE=317.53169; MAPE=0.4641688) and FNN (RMSE=181.29894; MAPE=0.2708482) demonstrated better performance for South Korea. Conclusions: The CPAIS collects and summarizes information about the COVID-19 pandemic and offers data visualization and deep learning-based prediction. It might be a useful reference for predicting a serious outbreak or epidemic. Moreover, the system undergoes daily updates and includes the latest information on vaccination, which may change the dynamics of the pandemic.",
        "DOI": "10.2196/27806",
        "affiliation_name": "College of Medicine",
        "affiliation_city": "Taipei",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Short-term load forecasting using encoder-decoder wavenet: Application to the french grid",
        "paper_author": "Rueda F.D.",
        "publication": "Energies",
        "citied_by": "38",
        "cover_date": "2021-05-01",
        "Abstract": "The prediction of time series data applied to the energy sector (prediction of renewable energy production, forecasting prosumers’ consumption/generation, forecast of country-level con-sumption, etc.) has numerous useful applications. Nevertheless, the complexity and non-linear behaviour associated with such kind of energy systems hinder the development of accurate algo-rithms. In such a context, this paper investigates the use of a state-of-art deep learning architecture in order to perform precise load demand forecasting 24-h-ahead in the whole country of France using RTE data. To this end, the authors propose an encoder-decoder architecture inspired by WaveNet, a deep generative model initially designed by Google DeepMind for raw audio waveforms. WaveNet uses dilated causal convolutions and skip-connection to utilise long-term information. This kind of novel ML architecture presents different advantages regarding other statistical algorithms. On the one hand, the proposed deep learning model’s training process can be parallelized in GPUs, which is an advantage in terms of training times compared to recurrent networks. On the other hand, the model prevents degradations problems (explosions and vanishing gradients) due to the residual connections. In addition, this model can learn from an input sequence to produce a forecast sequence in a one-shot manner. For comparison purposes, a comparative analysis between the most performing state-of-art deep learning models and traditional statistical approaches is presented: Autoregressive-Integrated Moving Average (ARIMA), Long-Short-Term-Memory, Gated-Recurrent-Unit (GRU), Multi-Layer Perceptron (MLP), causal 1D-Convolutional Neural Networks (1D-CNN) and ConvLSTM (Encoder-Decoder). The values of the evaluation indicators reveal that WaveNet exhibits superior performance in both forecasting accuracy and robustness.",
        "DOI": "10.3390/en14092524",
        "affiliation_name": "Universidad de Sevilla",
        "affiliation_city": "Sevilla",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Single-step deep reinforcement learning for open-loop control of laminar and turbulent flows",
        "paper_author": "Ghraieb H.",
        "publication": "Physical Review Fluids",
        "citied_by": "44",
        "cover_date": "2021-05-01",
        "Abstract": "This research gauges the ability of deep reinforcement learning (DRL) techniques to assist the optimization and control of fluid mechanical systems. It relies on introducing single-step proximal policy optimization (PPO), a \"degenerate\"version of the PPO algorithm, intended for situations where the optimal policy to be learnt by a neural network does not depend on state, as is notably the case in open-loop control problems. The numerical reward fed to the neural network is computed with an in-house stabilized finite elements environment implementing the variational multiscale method. Several prototypical separated flows in two dimensions are used as testbed. The method is applied first to two relatively simple optimization test cases (maximizing the mean lift of a NACA 0012 airfoil and the fluctuating lift of two side-by-side circular cylinders, both in laminar regimes) to assess convergence and accuracy by comparing to in-house direct numerical simulation (DNS) data. The potential of single-step PPO for reliable black-box optimization of computational fluid dynamics systems is then showcased by tackling several problems of open-loop control with parameter spaces large enough to dismiss DNS. The approach proves relevant to map the best positions for placement of a small control cylinder in the attempt to reduce drag in laminar and turbulent cylinder flows. All results are consistent with in-house data obtained by the adjoint method, and the drag of a square cylinder at Reynolds numbers in the range of a few thousands is reduced by 30%, which matches well reference experimental data available from literature. The method also successfully reduces the drag of the fluidic pinball, an equilateral triangle arrangement of rotating cylinders immersed in a turbulent stream. Consistently with reference machine learning results from the literature, drag is reduced by almost 60% using a so-called boat tailing actuation made up of a slowly rotating front cylinder and two downstream cylinders rotating in opposite directions so as to reduce the gap flow between them.",
        "DOI": "10.1103/PhysRevFluids.6.053902",
        "affiliation_name": "Mines Paris - PSL",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "A Malicious Code Static Detection Framework Based on Multi-Feature Ensemble Learning",
        "paper_author": "Yang W.",
        "publication": "Jisuanji Yanjiu yu Fazhan/Computer Research and Development",
        "citied_by": "14",
        "cover_date": "2021-05-01",
        "Abstract": "With the popularity of the Internet and the rapid development of 5G communication technology, the threats to cyberspace are increasing, especially the exponential increase in the number of malware and the explosive increase in the number of variants of their families. The traditional signature-based malware detection is too slow to handle the millions of new malwares emerged every day, while the false positive and false negative rates of general machine learning classifiers are significantly too high. At the same time malware packing, obfuscation and other adversarial techniques have caused more trouble to the situation. Based on this, we propose a static malware detection framework based on multi-feature ensemble learning. By extracting the non-PE (Portable Executable) structure feature, visible string feature, sink assembly code sequences feature, PE structure feature and function call relationship feature from the malware, we construct models matching each feature, and use Bagging and Stacking ensemble algorithms to reduce the risk of overfitting. Finally we adopt the weighted voting algorithm to further aggregate the output results of the ensemble model. The experimental results show the detection accuracy of multi-feature multi-model aggregation algorithm can reach 96.99%, which prove the method has better malware identification ability than other static detection methods, and higher recognition rate for malwares using packing or obfuscation techniques.",
        "DOI": "10.7544/issn1000-1239.2021.20200912",
        "affiliation_name": "Key Laboratory of Computer Network and Information Integration, Ministry of Education",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Responsible development of autonomous robotics in agriculture",
        "paper_author": "Rose D.C.",
        "publication": "Nature Food",
        "citied_by": "77",
        "cover_date": "2021-05-01",
        "Abstract": "NA",
        "DOI": "10.1038/s43016-021-00287-9",
        "affiliation_name": "University of Lincoln",
        "affiliation_city": "Lincoln",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Short-term prediction of covid-19 cases using machine learning models",
        "paper_author": "Satu M.S.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "73",
        "cover_date": "2021-05-01",
        "Abstract": "The first case in Bangladesh of the novel coronavirus disease (COVID-19) was reported on 8 March 2020, with the number of confirmed cases rapidly rising to over 175,000 by July 2020. In the absence of effective treatment, an essential tool of health policy is the modeling and forecasting of the progress of the pandemic. We, therefore, developed a cloud-based machine learning short-term forecasting model for Bangladesh, in which several regression-based machine learning models were applied to infected case data to estimate the number of COVID-19-infected people over the following seven days. This approach can accurately forecast the number of infected cases daily by training the prior 25 days sample data recorded on our web application. The outcomes of these efforts could aid the development and assessment of prevention strategies and identify factors that most affect the spread of COVID-19 infection in Bangladesh.",
        "DOI": "10.3390/app11094266",
        "affiliation_name": "Noakhali Science and Technology University",
        "affiliation_city": "Noakhali",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "A machine learning prediction model for waiting time to kidney transplant",
        "paper_author": "Sapiertein Silva J.F.",
        "publication": "PLoS ONE",
        "citied_by": "11",
        "cover_date": "2021-05-01",
        "Abstract": "Background Predicting waiting time for a deceased donor kidney transplant can help patients and clinicians to discuss management and contribute to a more efficient use of resources. This study aimed at developing a predictor model to estimate time on a kidney transplant waiting list using a machine learning approach. Methods A retrospective cohort study including data of patients registered, between January 1, 2000 and December 31, 2017, in the waiting list of São Paulo State Organ Allocation System (SP-OAS) /Brazil. Data were randomly divided into two groups: 75% for training and 25% for testing. A Cox regression model was fitted with deceased donor transplant as the outcome. Sensitivity analyses were performed using different Cox models. Cox hazard ratios were used to develop the risk-prediction equations. Results Of 54,055 records retrieved, 48,153 registries were included in the final analysis. During the study period, approximately 1/3 of the patients were transplanted with a deceased donor. The major characteristics associated with changes in the likelihood of transplantation were age, subregion, cPRA, and frequency of HLA-DR, -B and -A. The model developed was able to predict waiting time with good agreement in internal validation (c-index = 0.70). Conclusion The kidney transplant waiting time calculator developed shows good predictive performance and provides information that may be valuable in assisting candidates and their providers. Moreover, it can significantly improve the use of economic resources and the management of patient care before transplant.",
        "DOI": "10.1371/journal.pone.0252069",
        "affiliation_name": "Universidade Estadual Paulista \"Júlio de Mesquita Filho\"",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Effect of restriction of fluoroquinolone antibiotics on clostridioides difficile infections in the university hospital Hradec Králové",
        "paper_author": "Vaverková K.",
        "publication": "Antibiotics",
        "citied_by": "3",
        "cover_date": "2021-05-01",
        "Abstract": "Clostridioides difficile is the most common pathogen responsible for hospital-acquired diarrhea. This complication of antibiotic treatment mainly endangers the health of elder patients. Preventing the development of C. difficile infections (CDI) is still a challenge that needs to be addressed. In our study, the results of 872 C. difficile positive stool samples were used to describe the epidemiological situation affected by a change in the prescription of fluoroquinolone antibiotics. In a total, 93 of strains were typed by polymerase chain reaction (PCR) and capillary gel electrophoresis. Between years 2014 and 2018 the decline in the fluoroquinolones consumption was 69.3 defined daily dose (DDD) per 1000 patient-days (from 103.3 to 34.0), in same period CDI incidence declined by 1.3 cases per 10,000 patient-bed days (from 5.6 to 4.3). Results of epidemiologic and statistical analysis shows that decline in fluoroquinolones consumption has significant influence on CDI incidence and prevalence of hypervirulent strains. In the University Hospital Hradec Králové properly managed antibiotic stewardship policy has reduced CDI incidence by 23.2% and lowered rate of hypervirulent ribotypes 001 and 176.",
        "DOI": "10.3390/antibiotics10050519",
        "affiliation_name": "Krajská nemocnice Liberec, a.s.",
        "affiliation_city": "Liberec",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Deep reinforcement learning approaches for global public health strategies for COVID-19 pandemic",
        "paper_author": "Kwak G.H.",
        "publication": "PLoS ONE",
        "citied_by": "28",
        "cover_date": "2021-05-01",
        "Abstract": "Background Unprecedented public health measures have been used during this coronavirus 2019 (COVID-19) pandemic to control the spread of SARS-CoV-2 virus. It is a challenge to implement timely and appropriate public health interventions. Methods and findings Population and COVID-19 epidemiological data between 21st January 2020 to 15th November 2020 from 216 countries and territories were included with the implemented public health interventions. We used deep reinforcement learning, and the algorithm was trained to enable agents to try to find optimal public health strategies that maximized total reward on controlling the spread of COVID-19. The results suggested by the algorithm were analyzed against the actual timing and intensity of lockdown and travel restrictions. Early implementations of the actual lockdown and travel restriction policies, usually at the time of local index case were associated with less burden of COVID-19. In contrast, our agent suggested to initiate at least minimal intensity of lockdown or travel restriction even before or on the day of the index case in each country and territory. In addition, the agent mostly recommended a combination of lockdown and travel restrictions and higher intensity policies than the policies implemented by governments, but did not always encourage rapid full lockdown and full border closures. The limitation of this study was that it was done with incomplete data due to the emerging COVID-19 epidemic, inconsistent testing and reporting. In addition, our research focuses only on population health benefits by controlling the spread of COVID-19 without balancing the negative impacts of economic and social consequences. Interpretation Compared to actual government implementation, our algorithm mostly recommended earlier intensity of lockdown and travel restrictions. Reinforcement learning may be used as a decision support tool for implementation of public health interventions during COVID-19 and future pandemics.",
        "DOI": "10.1371/journal.pone.0251550",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Local and application-specific geodemographics for data-led urban decision making",
        "paper_author": "Otley A.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "0",
        "cover_date": "2021-05-01",
        "Abstract": "This work seeks to introduce improvements to the traditional variable selection procedures employed in the development of geodemographic classifications. It presents a proposal for shifting from a traditional approach for generating general-purpose one-size-fits-all geodemographic classifications to application-specific classifications. This proposal addresses the recent scepticism towards the utility of general-purpose applications by employing supervised machine learning techniques in order to identify contextually relevant input variables from which to develop geodemographic classifications with increased discriminatory power. A framework introducing such techniques in the variable selection phase of geodemographic classification development is presented via a practical use-case that is focused on generating a geodemographic classification with an increased capacity for discriminating the propensity for Library use in the UK city of Leeds. Two local classifications are generated for the city, one a general-purpose classification, and the other, an application-specific classification incorporating supervised Feature Selection methods in the selection of input variables. The discriminatory power of each classification is evaluated and compared, with the result successfully demonstrating the capacity for the application-specific approach to generate a more contextually relevant result, and thus underpins increasingly targeted public policy decision making, particularly in the context of urban planning.",
        "DOI": "10.3390/su13094873",
        "affiliation_name": "University of Leeds",
        "affiliation_city": "Leeds",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Article-level classification of scientific publications: A comparison of deep learning, direct citation and bibliographic coupling",
        "paper_author": "Rivest M.",
        "publication": "PLoS ONE",
        "citied_by": "29",
        "cover_date": "2021-05-01",
        "Abstract": "Classification schemes for scientific activity and publications underpin a large swath of research evaluation practices at the organizational, governmental, and national levels. Several research classifications are currently in use, and they require continuous work as new classification techniques becomes available and as new research topics emerge. Convolutional neural networks, a subset of “deep learning” approaches, have recently offered novel and highly performant methods for classifying voluminous corpora of text. This article benchmarks a deep learning classification technique on more than 40 million scientific articles and on tens of thousands of scholarly journals. The comparison is performed against bibliographic coupling-, direct citation-, and manual-based classifications—the established and most widely used approaches in the field of bibliometrics, and by extension, in many science and innovation policy activities such as grant competition management. The results reveal that the performance of this first iteration of a deep learning approach is equivalent to the graph-based bibliometric approaches. All methods presented are also on par with manual classification. Somewhat surprisingly, no machine learning approaches were found to clearly outperform the simple label propagation approach that is direct citation. In conclusion, deep learning is promising because it performed just as well as the other approaches but has more flexibility to be further improved. For example, a deep neural network incorporating information from the citation network is likely to hold the key to an even better classification algorithm.",
        "DOI": "10.1371/journal.pone.0251493",
        "affiliation_name": "Science-Metrix",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Carbon price forecasting based on improved ceemdan and extreme learning machine optimized by sparrow search algorithm",
        "paper_author": "Zhou J.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "51",
        "cover_date": "2021-05-01",
        "Abstract": "Effective carbon pricing policies have become an effective tool for many countries to encourage emission reduction. An accurate carbon price prediction model is helpful for the implementation of energy conservation and emission reduction policies and the decision-making of governments and investors. However, it is difficult for a single prediction model to achieve high prediction accuracy because of the high complexity of the carbon price series. Many studies have proved the nonlinear characteristics of carbon trading prices, but there are very few studies on the chaotic nature of carbon price series. As a consequence, this paper proposes an innovative hybrid model for carbon price prediction. A decomposition-reconstruction-prediction-integration scheme is designed to predict carbon prices. Firstly, several intrinsic mode functions (IMFs) and one residue were obtained from the raw data decomposed by ICEEMDAN. Next, the decomposed subsection is reconstructed into a new sequence according to the calculation results by the Lempel-Ziv complexity algorithm. Then, considering the chaotic characteristics of sequence, the input variables of the models are determined through the phase space reconstruction (PSR) algorithm combined with the partial autocorrelation function (PACF). Finally, the Sparrow search algorithm (SSA) is introduced to optimize the extreme learning machine (ELM) model, which is applied in the carbon price prediction for the purpose of verifying the validity of the proposed combination model, which is applied to the pilots of Hubei, Beijing, and Guangdong. The empirical results show that the combination model outperformed the 13 other models in predicting accuracy, speed, and stability. The decomposition-reconstruction-prediction-integration strategy is a method for predicting the carbon price efficiently.",
        "DOI": "10.3390/su13094896",
        "affiliation_name": "North China Electric Power University (Baoding)",
        "affiliation_city": "Baoding",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Methodology of implementing virtual reality in education for industry 4.0",
        "paper_author": "Paszkiewicz A.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "67",
        "cover_date": "2021-05-01",
        "Abstract": "This paper presents an entirely new approach to the use of virtual reality (VR) in the educational process for the needs of Industry 4.0. It is based on the proposed comprehensive methodology, including the design, creation, implementation and evaluation of individual courses implemented in a VR environment. An essential feature of the new methodology is its universality and comprehensiveness. Thanks to that, it can be applied in such areas as higher education, aviation, automotive, shipbuilding, energy and many others. The paper also identifies the significant advantages and disadvantages of VR-based education that may determine its use scope and profile. In addition, on the basis of the proposed methodology, a model of a training station using VR technology has been developed to enable the realization of training classes in the field of firefighting activities that should be undertaken during the hazard arising from the operation of a numerically controlled production machine. Results of the conducted training using this station were also presented. The study showed the potential of training based on a virtual environment to improve participants’ skills and knowledge. The development and implementation of adequate courses in the VR environment can reduce costs and increase the safety and efficiency of employees’ performed activities.",
        "DOI": "10.3390/su13095049",
        "affiliation_name": "Politechnika Rzeszowska im. Ignacego Łukasiewicza",
        "affiliation_city": "Rzeszow",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Using a Secure, Continually Updating, Web Source Processing Pipeline to Support the Real-Time Data Synthesis and Analysis of Scientific Literature: Development and Validation Study",
        "paper_author": "Vaghela U.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "2",
        "cover_date": "2021-05-01",
        "Abstract": "Background: The scale and quality of the global scientific response to the COVID-19 pandemic have unquestionably saved lives. However, the COVID-19 pandemic has also triggered an unprecedented \"infodemic\"; the velocity and volume of data production have overwhelmed many key stakeholders such as clinicians and policy makers, as they have been unable to process structured and unstructured data for evidence-based decision making. Solutions that aim to alleviate this data synthesis-related challenge are unable to capture heterogeneous web data in real time for the production of concomitant answers and are not based on the high-quality information in responses to a free-text query. Objective: The main objective of this project is to build a generic, real-time, continuously updating curation platform that can support the data synthesis and analysis of a scientific literature framework. Our secondary objective is to validate this platform and the curation methodology for COVID-19-related medical literature by expanding the COVID-19 Open Research Dataset via the addition of new, unstructured data. Methods: To create an infrastructure that addresses our objectives, the PanSurg Collaborative at Imperial College London has developed a unique data pipeline based on a web crawler extraction methodology. This data pipeline uses a novel curation methodology that adopts a human-in-the-loop approach for the characterization of quality, relevance, and key evidence across a range of scientific literature sources. Results: REDASA (Realtime Data Synthesis and Analysis) is now one of the world's largest and most up-to-date sources of COVID-19-related evidence; it consists of 104,000 documents. By capturing curators' critical appraisal methodologies through the discrete labeling and rating of information, REDASA rapidly developed a foundational, pooled, data science data set of over 1400 articles in under 2 weeks. These articles provide COVID-19-related information and represent around 10% of all papers about COVID-19. Conclusions: This data set can act as ground truth for the future implementation of a live, automated systematic review. The three benefits of REDASA's design are as follows: (1) it adopts a user-friendly, human-in-the-loop methodology by embedding an efficient, user-friendly curation platform into a natural language processing search engine; (2) it provides a curated data set in the JavaScript Object Notation format for experienced academic reviewers' critical appraisal choices and decision-making methodologies; and (3) due to the wide scope and depth of its web crawling method, REDASA has already captured one of the world's largest COVID-19-related data corpora for searches and curation.",
        "DOI": "10.2196/25714",
        "affiliation_name": "Institute of Biology, College of Science, University of the Philippines, Diliman",
        "affiliation_city": "Quezon City",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "Constructionism and AI: A history and possible futures",
        "paper_author": "Kahn K.",
        "publication": "British Journal of Educational Technology",
        "citied_by": "37",
        "cover_date": "2021-05-01",
        "Abstract": "Abstract: Constructionism, long before it had a name, was intimately tied to the field of Artificial Intelligence. Soon after the birth of Logo at BBN, Seymour Papert set up the Logo Group as part of the MIT AI Lab. Logo was based upon Lisp, the first prominent AI programming language. Many early Logo activities involved natural language processing, robotics, artificial game players, and generating poetry, art, and music. In the 1970s researchers explored enhancements to Logo to support AI programming by children. In the 1980s the Prolog community, inspired by Logo's successes, began exploring how to adapt logic programming for use by school children. While there have been over 40 years of active AI research in creating intelligent tutoring systems, there was little AI-flavoured constructionism after the 1980s until about 2017 when suddenly a great deal of activity started. Amongst those activities were attempts to enhance Scratch, Snap!, and MIT App Inventor with new blocks for speech synthesis, speech recognition, image recognition, and the use of pre-trained deep learning models. The Snap! enhancements also include support for word embeddings, as well as blocks to enable learners to create, train, and use deep neural networks. Student and teacher project-oriented resources highlighting these new AI programming components appeared at the same time. In this paper, we review this history, providing a unique perspective on AI developments—both social and technical—from a constructionist perspective. Reflecting on these, we close with speculations about possible futures for AI and constructionism. Practitioner notes What is already known about this topic There exist excellent broad surveys of the current status of teaching machine learning in schools, for example Marques et al. (2020). There are historical collections of AI and education research papers that include descriptions of constructionist activities, for example Yazdani (1984). What this paper adds This paper adds an in-depth focus on historical and current efforts on AI and education that support constructionist teaching. This focus enables us to delve deeper than a broad survey. Uniquely, we provide a 50-year historical perspective on constructionist AI tools, trials, and research. Grounded in this history and our survey of current tools and projects, we provide speculations about future directions. Implications for practice and/or policy We hope our descriptions of current AI programming tools for non-experts placed in a broad historical context will be of use to teachers wishing to introduce AI to their students in a constructionist manner, as well as to developers and researchers aiming to support such teaching.",
        "DOI": "10.1111/bjet.13088",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Potential distribution and connectivity for recolonizing cougars in the Great Lakes region, USA",
        "paper_author": "Gantchoff M.G.",
        "publication": "Biological Conservation",
        "citied_by": "10",
        "cover_date": "2021-05-01",
        "Abstract": "Cougars (Puma concolor) have lost substantial portions of their historical range yet increased sightings suggest potential for re-establishment in some regions; greater understanding of potential distribution and connectivity is necessary to make sound management and policy decisions. Specifically, the Great Lakes region of the USA will likely be an important area for cougar range expansion into the Midwest and Eastern USA. We used verified cougar observations to model and predict potential distribution and connectivity in the Great Lakes region. We compiled all confirmed observations of cougars from Michigan, Minnesota, and Wisconsin (2010–2020); which resulted in 180 reports (154 images/videos, 20 signs, 6 mortalities). We developed an ensemble distribution model (1 km res) based on three machine learning methods. We used weighted cost-distances to identify linkages between core areas and circuit theory to model overall connectivity potential. We calculated selection ratios for land covers (30 m res) at fine and coarse scales. The ensemble distribution model had good performance (ROC of 0.94). Suitability was positively associated with increasing vegetation structure, lower distance to natural cover, and mid-high terrain ruggedness. Forest covers were always selected for regardless of scale, and human development was avoided only at the coarser scale. We identified 191 core patches and 362 linkages connecting them; only 50.1% of them were located within legally protected areas. We identified high regional connectivity in a generally west-east direction. Successful conservation of large carnivores like cougars will depend on conserving not only habitat patches and linkages but also efforts to facilitate long-term coexistence.",
        "DOI": "10.1016/j.biocon.2021.109144",
        "affiliation_name": "State of Michigan",
        "affiliation_city": "Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Watershed science: Linking hydrological science with sustainable management of river basins",
        "paper_author": "He C.",
        "publication": "Science China Earth Sciences",
        "citied_by": "18",
        "cover_date": "2021-05-01",
        "Abstract": "Over the past decades, a number of water sciences and management programs have been developed to better understand and manage the water cycles at multiple temporal and spatial scales for various purposes, such as ecohydrology, global hydrology, sociohydrology, supply management, demand management, and integrated water resources management (IWRM). At the same time, rapid advancements have also been taking place in tracing, mapping, remote sensing, machine learning, and modelling technologies in hydrological research. Despite those programs and advancements, a water crisis is intensifying globally. The missing link is effective interactions between the hydrological research and water resource management to support implementation of the UN Sustainable Development Goals (SDGs) at multiple spatial scales. Since the watershed is the natural unit for water resources management, watershed science offers the potential to bridge this missing link. This study first reviews the advances in hydrological research and water resources management, and then discusses issues and challenges facing the global water community. Subsequently, it describes the core components of watershed science: (1) hydrological analysis; (2) water-operation policies; (3) governance; (4) management and feedback. The framework takes into account water availability, water uses, and water quality; explicitly focuses on the storage, fluxes, and quality of the hydrological cycle; defines appropriate local water resource thresholds through incorporating the planetary boundary framework; and identifies specific actionable measures for water resources management. It provides a complementary approach to the existing water management programs in addressing the current global water crisis and achieving the UN SDGs.",
        "DOI": "10.1007/s11430-020-9723-4",
        "affiliation_name": "Lanzhou University",
        "affiliation_city": "Lanzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "KIcker: An Industrial Drive and Control Foosball System automated with Deep Reinforcement Learning",
        "paper_author": "De Blasi S.",
        "publication": "Journal of Intelligent and Robotic Systems: Theory and Applications",
        "citied_by": "11",
        "cover_date": "2021-05-01",
        "Abstract": "The majority of efforts in the field of sim-to-real Deep Reinforcement Learning focus on robot manipulators, which is justified by their importance for modern production plants. However, there are only a few studies for a more extensive use in manufacturing processes. In this paper, we contribute to this by automating a complex manufacturing-like process using simulation-based Deep Reinforcement Learning. The setup and workflow presented here are designed to mimic the characteristics of real manufacturing processes and proves that Deep Reinforcement Learning can be applied to physical systems built from industrial drive and control components by transferring policies learned in simulation to the real machine. Aided by domain randomization, training in a virtual environment is crucial due to the benefit of accelerated training speed and the desire for safe Reinforcement Learning. Our key contribution is to demonstrate the applicability of simulation-based Deep Reinforcement Learning in industrial automation technology. We introduce an industrial drive and control system, based on the classic pub game Foosball, from both an engineering and a simulation perspective, describing the strategies applied to increase transfer robustness. Our approach allowed us to train a self-learning agent to independently learn successful control policies for demanding Foosball tasks based on sparse reward signals. The promising results prove that state-of-the-art Deep Reinforcement Learning algorithms are able to produce models trained in simulation, which can successfully control industrial use cases without using the actual system for training beforehand.",
        "DOI": "10.1007/s10846-021-01389-z",
        "affiliation_name": "Bosch Rexroth AG",
        "affiliation_city": "Lohr",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Systematic map of the literature on carbon lock-in induced by long-lived capital",
        "paper_author": "Fisch-Romito V.",
        "publication": "Environmental Research Letters",
        "citied_by": "40",
        "cover_date": "2021-05-01",
        "Abstract": "Long-lived capital-stocks (LLCS) such as infrastructure and buildings have significant and long-lasting implications for greenhouse gas emissions. They contribute to carbon lock-in and may hinder a rapid decarbonization of energy systems. Here we provide a systematic map of the literature on carbon lock-in induced by LLCS. Based on a structured search of the Web of Science and Scopus, we identified 226 publications from 38 095 search results using a supervised machine learning approach. We show biases toward power generation and toward developed countries. We also identify 11 indicators used to quantify carbon lock-in. Quantifications of committed emissions (cumulative emissions that would occur over the remaining operational lifetime of an asset) or stranded assets (premature retirement/retrofitting or under-utilization of assets along a given pathway) are the most commonly used metrics, whereas institutional indicators are scarcely represented. The synthesis of quantifications shows that (i) global committed emissions have slightly increased over time, (ii) coal power plants are a major source of committed emissions and are exposed to risk of becoming stranded, (iii) delayed mitigation action increases stranded assets and (iv) sectoral distribution and amount of stranded assets differ between countries. A thematic analysis of policy implications highlights the need to assure stability and legitimacy of climate policies and to enable coordination between stakeholders. Carbon pricing is one of the most cited policy instrument, but the literature emphasizes that it should not be the only instrument used and should instead be complemented with other policy instruments, such as technical regulations and financial support for low carbon capital deployment. Further research is warranted on urban-scale, in developing countries and outside the electricity generation sector, notably on buildings, where stranded assets could be high.",
        "DOI": "10.1088/1748-9326/aba660",
        "affiliation_name": "Mercator Research Institute on Global Commons and Climate Change",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Distributed spectrum management in cognitive radio networks by consensus-based reinforcement learning",
        "paper_author": "Dašić D.",
        "publication": "Sensors",
        "citied_by": "7",
        "cover_date": "2021-05-01",
        "Abstract": "In this paper, we propose a new algorithm for distributed spectrum sensing and channel selection in cognitive radio networks based on consensus. The algorithm operates within a multi-agent reinforcement learning scheme. The proposed consensus strategy, implemented over a directed, typically sparse, time-varying low-bandwidth communication network, enforces collaboration between the agents in a completely decentralized and distributed way. The motivation for the proposed approach comes directly from typical cognitive radio networks’ practical scenarios, where such a decentralized setting and distributed operation is of essential importance. Specifically, the proposed setting provides all the agents, in unknown environmental and application conditions, with viable network-wide information. Hence, a set of participating agents becomes capable of successful calculation of the optimal joint spectrum sensing and channel selection strategy even if the individual agents are not. The proposed algorithm is, by its nature, scalable and robust to node and link failures. The paper presents a detailed discussion and analysis of the algorithm’s characteristics, including the effects of denoising, the possibility of organizing coordinated actions, and the convergence rate improvement induced by the consensus scheme. The results of extensive simulations demonstrate the high effectiveness of the proposed algorithm, and that its behavior is close to the centralized scheme even in the case of sparse neighbor-based inter-node communication.",
        "DOI": "10.3390/s21092970",
        "affiliation_name": "Univerzitet Union Nikola Tesla",
        "affiliation_city": "Belgrade",
        "affiliation_country": "Serbia"
    },
    {
        "paper_title": "Prediction models for public health containment measures on covid-19 using artificial intelligence and machine learning: A systematic review",
        "paper_author": "Payedimarri A.B.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "29",
        "cover_date": "2021-05-01",
        "Abstract": "Artificial Intelligence (AI) and Machine Learning (ML) have expanded their utilization in different fields of medicine. During the SARS-CoV-2 outbreak, AI and ML were also applied for the evaluation and/or implementation of public health interventions aimed to flatten the epidemiolog-ical curve. This systematic review aims to evaluate the effectiveness of the use of AI and ML when applied to public health interventions to contain the spread of SARS-CoV-2. Our findings showed that quarantine should be the best strategy for containing COVID-19. Nationwide lockdown also showed positive impact, whereas social distancing should be considered to be effective only in com-bination with other interventions including the closure of schools and commercial activities and the limitation of public transportation. Our findings also showed that all the interventions should be initiated early in the pandemic and continued for a sustained period. Despite the study limitation, we concluded that AI and ML could be of help for policy makers to define the strategies for containing the COVID-19 pandemic.",
        "DOI": "10.3390/ijerph18094499",
        "affiliation_name": "KU Leuven– University Hospital Leuven",
        "affiliation_city": "Leuven",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Machine learning research towards combating COVID-19: Virus detection, spread prevention, and medical assistance",
        "paper_author": "Shahid O.",
        "publication": "Journal of Biomedical Informatics",
        "citied_by": "50",
        "cover_date": "2021-05-01",
        "Abstract": "COVID-19 was first discovered in December 2019 and has continued to rapidly spread across countries worldwide infecting thousands and millions of people. The virus is deadly, and people who are suffering from prior illnesses or are older than the age of 60 are at a higher risk of mortality. Medicine and Healthcare industries have surged towards finding a cure, and different policies have been amended to mitigate the spread of the virus. While Machine Learning (ML) methods have been widely used in other domains, there is now a high demand for ML-aided diagnosis systems for screening, tracking, predicting the spread of COVID-19 and finding a cure against it. In this paper, we present a journey of what role ML has played so far in combating the virus, mainly looking at it from a screening, forecasting, and vaccine perspective. We present a comprehensive survey of the ML algorithms and models that can be used on this expedition and aid with battling the virus.",
        "DOI": "10.1016/j.jbi.2021.103751",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Towards smart transportation system: A case study on the rebalancing problem of bike sharing system based on reinforcement learning",
        "paper_author": "Li G.",
        "publication": "Journal of Organizational and End User Computing",
        "citied_by": "21",
        "cover_date": "2021-05-01",
        "Abstract": "Smart transportation system is a cross-field research topic that involves both the organizations that manage the large-scaled system and individual end-users who enjoy these services. Recent advancement of machine learning-based algorithms has either enabled or improved a wide range of applications due to its strength in making accurate predictions for complex problems with a minimal amount of domain knowledge and great ability of generalization. These nice properties imply potential to be explored for building smart transportation system. This paper studies how deep reinforcement learning (DRL) can be used to optimize the operating policy in modern bike sharing systems. As a case study, the authors demonstrate the potential power of the modern DRL by showing a policy-gradient-based reinforcement learning approach to the rebalancing problem in a bike sharing system, which can simultaneously improve both the user experience and reduce the operational expense.",
        "DOI": "10.4018/JOEUC.20210501.oa3",
        "affiliation_name": "Qingdao Binhai University",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Analyzing Indian general public's perspective on anxiety, stress and trauma during Covid-19 - A machine learning study of 840,000 tweets",
        "paper_author": "Praveen S.V.",
        "publication": "Diabetes and Metabolic Syndrome: Clinical Research and Reviews",
        "citied_by": "42",
        "cover_date": "2021-05-01",
        "Abstract": "Background and aims: Ever since COVID-19 was declared a pandemic by WHO in late March 2020, more and more people began to share their opinions online about the anxiety, stress, and trauma they suffered because of the pandemic. However, very few studies were conducted to analyze the general public's perception of what causes stress, anxiety, and trauma during COVID-19. This study focuses particularly on understanding Indian citizens. Methods: By using Machine learning techniques, particularly Natural language processing, this study focuses on understanding the attitude of Indian citizens while discussing the anxiety, stress, and trauma created because of COVID-19 and the major reasons that cause it. We used Tweets as data for this study. We have used 840,000 tweets for this study. Results: Our sentiment analysis study revealed the interesting fact that, even while discussing about the stress, anxiety, and trauma caused by COVID-19, most of the tweets were in neutral sentiments. Death and Lockdown caused by the COVID-19 were the two most important aspects that cause stress, anxiety, and Trauma among Indian citizens. Conclusion: It is important for policymakers and health professionals to understand common citizen's perspectives of what causes them stress, anxiety, and trauma to formulate policies and treat the patients. Our study shows that Indian citizens use social media to share their opinions about COVID-19 and as a coping mechanism in unprecedented time.",
        "DOI": "10.1016/j.dsx.2021.03.016",
        "affiliation_name": "National Institute of Technology Tiruchirappalli",
        "affiliation_city": "Tiruchirappalli",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Automated eco-driving in urban scenarios using deep reinforcement learning",
        "paper_author": "Wegener M.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "91",
        "cover_date": "2021-05-01",
        "Abstract": "Urban settings are challenging environments to implement eco-driving strategies for automated vehicles. It is often assumed that sufficient information on the preceding vehicle pulk is available to accurately predict the traffic situation. Because vehicle-to-vehicle communication was introduced only recently, this assumption will not be valid until a sufficiently high penetration of the vehicle fleet has been reached. Thus, in the present study, we employed Reinforcement Learning (RL) to develop eco-driving strategies for cases where little data on the traffic situation are available. An A-segment electric vehicle was simulated using detailed efficiency models to accurately determine its energy-saving potential. A probabilistic traffic environment featuring signalized urban roads and multiple preceding vehicles was integrated into the simulation model. Only information on the traffic light timing and minimal sensor data were provided to the control algorithm. A twin-delayed deep deterministic policy gradient (TD3) agent was implemented and trained to control the vehicle efficiently and safely in this environment. Energy savings of up to 19% compared with a simulated human driver and up to 11% compared with a fine-tuned Green Light Optimal Speed Advice (GLOSA) algorithm were determined in a probabilistic traffic scenario reflecting real-world conditions. Overall, the RL agents showed a better travel time and energy consumption trade-off than the GLOSA reference.",
        "DOI": "10.1016/j.trc.2021.102967",
        "affiliation_name": "Rheinisch-Westfälische Technische Hochschule Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Spatio-Temporal Deep Learning Approach to Map Deforestation in Amazon Rainforest",
        "paper_author": "Maretto R.V.",
        "publication": "IEEE Geoscience and Remote Sensing Letters",
        "citied_by": "46",
        "cover_date": "2021-05-01",
        "Abstract": "We address the task of mapping deforested areas in the Brazilian Amazon. Accurate maps are an important tool for informing effective deforestation containment policies. The main existing approaches to this task are largely manual, requiring significant effort by trained experts. To reduce this effort, we propose a fully automatic approach based on spatio-temporal deep convolutional neural networks. We introduce several domain-specific components, including approaches for: image preprocessing; handling image noise, such as clouds and shadow; and constructing the training data set. We show that our preprocessing protocol reduces the impact of noise in the training data set. Furthermore, we propose two spatio-temporal variations of the U-Net architecture, which make it possible to incorporate both spatial and temporal contexts. Using a large, real-world data set, we show that our method outperforms a traditional U-Net architecture, thus achieving approximately 95% accuracy.",
        "DOI": "10.1109/LGRS.2020.2986407",
        "affiliation_name": "Universidade Federal de Goiás",
        "affiliation_city": "Goiania",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "25 years of European merger control",
        "paper_author": "Affeldt P.",
        "publication": "International Journal of Industrial Organization",
        "citied_by": "5",
        "cover_date": "2021-05-01",
        "Abstract": "We study the determinants of common European merger policy over its first 25 years, from 1990 to 2014. Using a novel dataset at the level of the relevant antitrust markets and containing all relevant merger cases notified to the European Commission, we evaluate how consistently arguments related to structural market parameters – dominance, rising concentration, barriers to entry, and foreclosure – were applied over time and across different geographic market definitions. On average, linear probability models overestimate the effects of structural indicators. Using non-parametric machine learning techniques, we find that dominance is positively correlated with competitive concerns, especially in markets with a substantial increase in post-merger concentration and in complex mergers. Yet, its importance decreased following the 2004 merger policy reform. Competitive concerns are also correlated with rising concentration, especially if entry barriers and foreclosure are of concern. The impact of these structural indicators in explaining competitive concerns is independent of the geographic market definition and does not change over time.",
        "DOI": "10.1016/j.ijindorg.2021.102720",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Farmers' heterogeneous perceptions of marginal land for biofuel crops in US Midwestern states considering biophysical and socioeconomic factors",
        "paper_author": "Yang P.",
        "publication": "GCB Bioenergy",
        "citied_by": "13",
        "cover_date": "2021-05-01",
        "Abstract": "Planting bioenergy crops on marginal land is critical for avoiding competition with food crop production. While many studies have estimated marginal land availability using various methods, only a few studies have considered the role of socioeconomic factors in affecting perceptions about the availability of marginal land. This study analyzes land-use survey data to examine the determinants of farmers' perceptions of marginal land availability on their farms. We find that farmers' perceptions are affected by a combination of unfavorable biophysical (e.g., soil water capacity, temperature variability, and slope) and socioeconomic factors, of which farm size appears to be significant. Interestingly, we identify different determinants of perceptions among farmers that claim to have marginal land and those that do not; the former are determined mainly by unfavorable biophysical factors, while the latter are mainly explained by small farm size. We further apply a prediction model that is trained by a machine learning algorithm to Midwestern states, and derive maps of marginal land likelihood and associated dominant influencing factors. The results suggest that marginal land is primarily under pastureland and grassland cover and in the Dakotas and Nebraska; there is also some marginal land under crop production in the Corn Belt. Our findings contribute to improving understanding of the complex determinants of heterogeneous perceptions of marginal land and can inform the design of more targeted policies for bioenergy crop adoption.",
        "DOI": "10.1111/gcbb.12821",
        "affiliation_name": "The Grainger College of Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Violent and non-violent offending in patients with schizophrenia: Exploring influences and differences via machine learning",
        "paper_author": "Sonnweber M.",
        "publication": "Comprehensive Psychiatry",
        "citied_by": "23",
        "cover_date": "2021-05-01",
        "Abstract": "Objectives: The link between schizophrenia and violent offending has long been the subject of research with significant impact on mental health policy, clinical practice and public perception of the dangerousness of people with psychiatric disorders. The present study attempts to identify factors that differentiate between violent and non-violent offenders based on a unique sample of 370 forensic offender patients with schizophrenia spectrum disorder by employing machine learning algorithms and an extensive set of variables. Methods: Using machine learning algorithms, 519 variables were explored in order to differentiate violent and non-violent offenders. To minimize the risk of overfitting, the dataset was split, employing variable filtering, machine learning model building and selection embedded in a nested resampling approach on one subset. The best model was then selected, and the most important variables applied on the second data subset. Results: Ten factors regarding criminal and psychiatric history as well as clinical, developmental, and social factors were identified to be most influential in differentiating between violent and non-violent offenders and are discussed in light of prior research on this topic. With an AUC of 0.76, a sensitivity of 72% and a specificity of 62%, a correct classification into violent and non-violent offences could be determined in almost three quarters of cases. Conclusions: Our findings expand current research on the factors influencing violent offending in patients with SSD, which is crucial for the development of preventive and therapeutic strategies that could potentially reduce the prevalence of violence in this population. Limitations, clinical relevance and future directions are discussed.",
        "DOI": "10.1016/j.comppsych.2021.152238",
        "affiliation_name": "Psychiatrische Universitätsklinik Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Applying machine learning techniques for caching in next-generation edge networks: A comprehensive survey",
        "paper_author": "Shuja J.",
        "publication": "Journal of Network and Computer Applications",
        "citied_by": "98",
        "cover_date": "2021-05-01",
        "Abstract": "Edge networking is a complex and dynamic computing paradigm that aims to push cloud re-sources closer to the end user improving responsiveness and reducing backhaul traffic. User mobility, preferences, and content popularity are the dominant dynamic features of edge networks. Temporal and social features of content, such as the number of views and likes are leveraged to estimate the popularity of content from a global perspective. However, such estimates should not be mapped to an edge network with particular social and geographic characteristics. In next generation edge networks, i.e., 5G and beyond 5G, machine learning techniques can be applied to predict content popularity based on user preferences, cluster users based on similar content interests, and optimize cache placement and replacement strategies provided a set of constraints and predictions about the state of the network. These applications of machine learning can help identify relevant content for an edge network. This article investigates the application of machine learning techniques for in-network caching in edge networks. We survey recent state-of-the-art literature and formulate a comprehensive taxonomy based on (a) machine learning technique (method, objective, and features), (b) caching strategy (policy, location, and replacement), and (c) edge network (type and delivery strategy). A comparative analysis of the state-of-the-art literature is presented with respect to the parameters identified in the taxonomy. Moreover, we debate research challenges and future directions for optimal caching decisions and the application of machine learning in edge networks.",
        "DOI": "10.1016/j.jnca.2021.103005",
        "affiliation_name": "Umm Al-Qura University",
        "affiliation_city": "Makkah",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Reinforcement learning of occupant behavior model for cross-building transfer learning to various HVAC control systems",
        "paper_author": "Deng Z.",
        "publication": "Energy and Buildings",
        "citied_by": "68",
        "cover_date": "2021-05-01",
        "Abstract": "Occupant behavior plays an important role in the evaluation of building performance. However, many contextual factors, such as occupancy, mechanical system and interior design, have a significant impact on occupant behavior. Most previous studies have built data-driven behavior models, which have limited scalability and generalization capability. Our investigation built a policy-based reinforcement learning (RL) model for the behavior of adjusting the thermostat and clothing level. Occupant behavior was modelled as a Markov decision process (MDP). The action and state space in the MDP contained occupant behavior and various impact parameters. The goal of the occupant behavior was a more comfortable environment, and we modelled the reward for the adjustment action as the absolute difference in the thermal sensation vote (TSV) before and after the action. We used Q-learning to train the RL model in MATLAB and validated the model with collected data. After training, the model predicted the behavior of adjusting the thermostat set point with R2 from 0.75 to 0.8, and the mean absolute error (MAE) was less than 1.1 °C (2 °F) in an office building. This study also transferred the behavior knowledge of the RL model to other office buildings with different HVAC control systems. The transfer learning model predicted the occupant behavior with R2 from 0.73 to 0.8, and the MAE was less than 1.1 °C (2 °F) most of the time. Going from office buildings to residential buildings, the transfer learning model also had an R2 over 0.6. Therefore, the RL model combined with transfer learning was able to predict the building occupant behavior accurately with good scalability, and without the need for data collection.",
        "DOI": "10.1016/j.enbuild.2021.110860",
        "affiliation_name": "Lyles School of Civil and Construction Engineering",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Adaptive and extendable control of unmanned surface vehicle formations using distributed deep reinforcement learning",
        "paper_author": "Wang S.",
        "publication": "Applied Ocean Research",
        "citied_by": "52",
        "cover_date": "2021-05-01",
        "Abstract": "Future ocean exploration will be dominated by a large-scale deployment of marine robots such as unmanned surface vehicles (USVs). Without the involvement of human operators, USVs exploit oceans, especially the complex marine environments, in an unprecedented way with an increased mission efficiency. However, current autonomy level of USVs is still limited, and the majority of vessels are being remotely controlled. To address such an issue, artificial intelligence (AI) such as reinforcement learning can effectively equip USVs with high-level intelligence and consequently achieve full autonomous operation. Also, by adopting the concept of multi-agent intelligence, future trend of USV operations is to use them as a formation fleet. Current researches in USV formation control are largely based upon classical control theories such as PID, backstepping and model predictive control methods with the impact by using advanced AI technologies unclear. This paper, therefore, paves the way in this area by proposing a distributed deep reinforcement learning algorithm for USV formations. More importantly, using the proposed algorithm USV formations can learn two critical abilities, i.e. adaptability and extendibility that enable formations to arbitrarily increase the number of USVs or change formation shapes. The effectiveness of algorithms has been verified and validated through a number of computer-based simulations.",
        "DOI": "10.1016/j.apor.2021.102590",
        "affiliation_name": "Wuhan University of Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Review prognosis system to predict employees job satisfaction using deep neural network",
        "paper_author": "Rustam F.",
        "publication": "Computational Intelligence",
        "citied_by": "20",
        "cover_date": "2021-05-01",
        "Abstract": "With the multitude of companies that flourish today, job seekers want to join companies with highly satisfied employees. So, job satisfaction prediction is an important task that helps companies in sustaining or redesigning employee policies. Such predictions not only help in reducing employee attrition but also affect the goodwill and reputation of a company. The higher satisfaction level of current employees attracts potential new employees and confirms the positive policies of a company toward its employees. Job satisfaction prediction can be performed using employee reviews either manually or via automated machine learning algorithms. This study first evaluates four widely used machine learning algorithms, that is, random forest, logistic regression, support vector classifier, and gradient boosting, and then proposes a deep learning model to predict employee job satisfaction level. Experiments are carried out on a dataset that contains text reviews from the employees of Google, Facebook, Amazon, Microsoft, and Apple. Three feature extraction methods are analyzed as well including term frequency-inverse document frequency (TF-IDF), bag-of-words (BOW), and global vector for word representation (GloVe). Performance is evaluated using accuracy, precision, recall, F1 score, as well as, macro average precision, and weighted average. The performance of the proposed model is compared with state-of-the-art deep learning models. Results demonstrate that the proposed model performs better than both the machine learning and state-of-the-art approaches.",
        "DOI": "10.1111/coin.12440",
        "affiliation_name": "The Islamia University of Bahawalpur",
        "affiliation_city": "Bahawalpur",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Intelligent colocation of HPC workloads",
        "paper_author": "Zacarias F.V.",
        "publication": "Journal of Parallel and Distributed Computing",
        "citied_by": "11",
        "cover_date": "2021-05-01",
        "Abstract": "Many HPC applications suffer from a bottleneck in the shared caches, instruction execution units, I/O or memory bandwidth, even though the remaining resources may be underutilized. It is hard for developers and runtime systems to ensure that all critical resources are fully exploited by a single application, so an attractive technique for increasing HPC system utilization is to colocate multiple applications on the same server. When applications share critical resources, however, contention on shared resources may lead to reduced application performance. In this paper, we show that server efficiency can be improved by first modeling the expected performance degradation of colocated applications based on measured hardware performance counters, and then exploiting the model to determine an optimized mix of colocated applications. This paper presents a new intelligent resource manager and makes the following contributions: (1) a new machine learning model to predict the performance degradation of colocated applications based on hardware counters and (2) an intelligent scheduling scheme deployed on an existing resource manager to enable application co-scheduling with minimum performance degradation. Our results show that our approach achieves performance improvements of 7% (avg) and 12% (max) compared to the standard policy commonly used by existing job managers.",
        "DOI": "10.1016/j.jpdc.2021.02.010",
        "affiliation_name": "Centro Nacional de Supercomputación",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Machine learning-based dispatch of drone-delivered defibrillators for out-of-hospital cardiac arrest",
        "paper_author": "Chu J.",
        "publication": "Resuscitation",
        "citied_by": "32",
        "cover_date": "2021-05-01",
        "Abstract": "Background: Drone-delivered defibrillators have the potential to significantly reduce response time for out-of-hospital cardiac arrest (OHCA). However, optimal policies for the dispatch of such drones are not yet known. We sought to develop dispatch rules for a network of defibrillator-carrying drones. Methods: We identified all suspected OHCAs in Peel Region, Ontario, Canada from Jan. 2015 to Dec. 2019. We developed drone dispatch rules based on the difference between a predicted ambulance response time to a calculated drone response time for each OHCA. Ambulance response times were predicted using linear regression and neural network models, while drone response times were calculated using drone specifications from recent pilot studies and the literature. We evaluated the dispatch rules based on response time performance and dispatch decisions, comparing them to two baseline policies of never dispatching and always dispatching drones. Results: A total of 3573 suspected OHCAs were included in the study with median and mean historical ambulance response times of 5.8 and 6.2 min. All machine learning-based dispatch rules significantly reduced the median response time to 3.9 min and mean response time to 4.1–4.2 min (all P < 0.001) and were non-inferior to universally dispatching drones (all P < 0.001) while reducing the number of drone flights by up to 30%. Dispatch rules with more drone flights achieved higher sensitivity but lower specificity and accuracy. Conclusion: Machine learning-based dispatch rules for drone-delivered defibrillators can achieve similar response time reductions as universal drone dispatch while substantially reducing the number of trips.",
        "DOI": "10.1016/j.resuscitation.2021.02.028",
        "affiliation_name": "Sunnybrook Research Institute",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Mining topic and sentiment dynamics in physician rating websites during the early wave of the COVID-19 pandemic: Machine learning approach",
        "paper_author": "Shah A.M.",
        "publication": "International Journal of Medical Informatics",
        "citied_by": "40",
        "cover_date": "2021-05-01",
        "Abstract": "Introduction: An increasing number of patients are voicing their opinions and expectations about the quality of care in online forums and on physician rating websites (PRWs). This paper analyzes patient online reviews (PORs) to identify emerging and fading topics and sentiment trends in PRWs during the early stage of the COVID-19 outbreak. Methods: Text data were collected, including 55,612 PORs of 3430 doctors from three popular PRWs in the United States (RateMDs, HealthGrades, and Vitals) from March 01 to June 27, 2020. An improved latent Dirichlet allocation (LDA)-based topic modeling (topic coherence-based LDA [TCLDA]), manual annotation, and sentiment analysis tool were applied to extract a suitable number of topics, generate corresponding keywords, assign topic names, and determine trends in the extracted topics and specific emotions. Results: According to the coherence value and manual annotation, the identified taxonomy includes 30 topics across high-rank and low-rank disease categories. The emerging topics in PRWs focus mainly on themes such as treatment experience, policy implementation regarding epidemic control measures, individuals’ attitudes toward the pandemic, and mental health across high-rank diseases. In contrast, the treatment process and experience during COVID-19, awareness and COVID-19 control measures, and COVID-19 deaths, fear, and stress were the most popular themes for low-rank diseases. Panic buying and daily life impact, treatment processes, and bedside manner were the fading themes across high-rank diseases. In contrast, provider attitude toward patients during the pandemic, detection at public transportation, passenger, travel bans and warnings, and materials supplies and society support during COVID-19 were the most fading themes across low-rank diseases. Regarding sentiment analysis, negative emotions (fear, anger, and sadness) prevail during the early wave of the COVID-19. Conclusion: Mining topic dynamics and sentiment trends in PRWs may provide valuable knowledge of patients’ opinions during the COVID-19 crisis. Policymakers should consider these PORs and develop global healthcare policies and surveillance systems through monitoring PRWs. The findings of this study identify research gaps in the areas of e-health and text mining and offer future research directions.",
        "DOI": "10.1016/j.ijmedinf.2021.104434",
        "affiliation_name": "Antai College of Economics and Management",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reducing fossil fuel-based generation: Impact on wholesale electricity market prices in the North-Italy bidding zone",
        "paper_author": "Flammini M.G.",
        "publication": "Electric Power Systems Research",
        "citied_by": "12",
        "cover_date": "2021-05-01",
        "Abstract": "Decarbonisation policies aim at reducing fossil fuel based generation in favour of cleaner renewable energy sources. Changes in the generation mix to supply future electricity demand will require tools capable to emulate the bidding behaviour of new generation plants. Price forecasting tools lacking this feature and only based on historical data time series might soon become not satisfactory for this scope. This paper presents a methodology that, by considering hourly electricity generation offers (price, volumes) datasets, allows simulating future electricity wholesale's prices. This is done by taking into account new generation units and the dismissing of old (coal-based) units according to the demand and generation forecasts in the European Ten Year Network Development Plan (TYNDP) 2030 scenarios. Machine learning, clustering and distribution sampling techniques are used in this work to finally estimate prices distribution in 2030 in the biggest bidding zone of the Italian market. The results suggest that the prices obtained in the different scenarios do converge to those estimated by the TYNDP. The approach used bypasses the need to have access to all the transactions of a given market. Probability distributions are in fact enough in the proposed methodology to achieve similar results to those based on full knowledge of transaction datasets.",
        "DOI": "10.1016/j.epsr.2021.107095",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Estimating the CAP greening effect by machine learning techniques: A big data ex post analysis",
        "paper_author": "Bertoni D.",
        "publication": "Environmental Science and Policy",
        "citied_by": "23",
        "cover_date": "2021-05-01",
        "Abstract": "Greening payment represents one of the main and controversial novelties of the current Common Agricultural Policy (CAP) 2015–2020 programming period. Such payments bind a portion of farm subsidies to compliance with specified practices, such as crop diversification. Unlike previous ex ante simulations, the present contribution attempts to estimate the ex post impact of greening payments in terms of land use change using a parcel-level constant sample (2011–2017) dataset of approximately 4.5 million observations. First, Markov chains and a weighted χ2 test detect a discontinuity in farmland transition probabilities only in farms that are initially non-compliant with the greening rules. Such a discontinuity is not observed in farms that are not eligible for or already compliant with the greening rules. This evidence, even if indirect, suggests that the greening payment has induced farmland conversion in farms with a lower degree of crop diversification. The greening impact on farmland allocation in this farm group was subsequently simulated using machine learning techniques. This policy has reduced maize monoculture and increased nitrogen-fixing crops, fallow land and other cereals in the targeted farms. Environmental gains (reduction in greenhouse gas emissions –GHG- and input use) and farm economic losses due to land use change have been derived, providing the first tentative cost-benefit analysis of such policy tool. Due to data limitations, indirect costs and benefits of greening (improvement in pest management, land quality and biodiversity) have not been assessed. More research and detailed environmental monitoring data are required to assess such indirect effects and to provide a more comprehensive cost-benefit ex-post analysis of greening policy",
        "DOI": "10.1016/j.envsci.2021.01.008",
        "affiliation_name": "Università degli Studi di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Assessing the impact of drought conditions on groundwater potential in Godavari Middle Sub-Basin, India using analytical hierarchy process and random forest machine learning algorithm",
        "paper_author": "Masroor M.",
        "publication": "Groundwater for Sustainable Development",
        "citied_by": "48",
        "cover_date": "2021-05-01",
        "Abstract": "Severe drought conditions have affected ever increasing demand of water in Godavari Middle Sub-Basin of India. Thus, assessment of drought and its impact on groundwater potential zones is essential for effective management of water resource in the Sub-basin. We utilized site-specific factors for ascertaining the groundwater potential zones. Analytical hierarchy process (AHP) was used for assigning weights to the factors and preparing map of groundwater potential zones. One-month (meteorological), three and six months (agricultural) and twelve months (hydrological) droughts were determined using standardized precipitation index (SPI) during 1979–2013. Vulnerable drought zones were identified using weighted sum overlay analysis. Random forest (RF) algorithm was utilized for assessing the impact of drought conditions on groundwater potential zones. Validation of random forest was carried out by dividing groundwater potential and drought maps into training (80%) and testing (20%) datasets in Jupyter notebook Python IDE (Integrated Development environment). Findings revealed that nearly half of the area of the Sub-basin experienced low and very low groundwater potential. RF analysis revealed that the groundwater potential in the northern and southern parts of the Sub-basin was severely affected by drought during the study period. Random forest regression (R2 being 0.858) indicated high accuracy of the model. Thus, RF model has proved to be an effective tool for analyzing relationship between drought and groundwater potential zones. The other drought prone areas interested to attempt drought and its impact assessment on groundwater potential may find this approach useful for policy measures.",
        "DOI": "10.1016/j.gsd.2021.100554",
        "affiliation_name": "Jamia Millia Islamia",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Predictions and mitigation strategies of PM<inf>2.5</inf> concentration in the Yangtze River Delta of China based on a novel nonlinear seasonal grey model",
        "paper_author": "Zhou W.",
        "publication": "Environmental Pollution",
        "citied_by": "66",
        "cover_date": "2021-05-01",
        "Abstract": "High delicate particulate matter (PM2.5) concentration can seriously reduce air quality, destroy the environment, and even jeopardize human health. Accordingly, accurate prediction for PM2.5 plays a vital role in taking precautions against upcoming air ambient pollution incidents. However, due to the disturbance of seasonal and nonlinear characteristics in the raw series, pronounced forecasts are confronted with tremendous handicaps, even though for seasonal grey prediction models in the preceding researches. A novel seasonal nonlinear grey model is initially designed to address such issues by integrating the seasonal adjustment factor, the conventional Weibull Bernoulli grey model, and the cultural algorithm, simultaneously depicting the seasonality and nonlinearity of the original data. Experimental results from PM2.5 forecasting of four major cities (Shanghai, Nanjing, Hangzhou, and Hefei) in the YRD validate that the proposed model can obtain more accurate predictive results and stronger robustness, in comparison with grey prediction models (SNGBM(1,1) and SGM(1,1)), conventional econometric technology (SARIMA), and machine learning methods (LSSVM and BPNN) by employing accuracy levels. Finally, the future PM2.5 concentration is forecasted from 2020 to 2022 using the proposed model, which provides early warning information for policy-makers to develop PM2.5 alleviation strategies.",
        "DOI": "10.1016/j.envpol.2021.116614",
        "affiliation_name": "Changzhou University",
        "affiliation_city": "Changzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Microclimates hold the key to spatial forest planning under climate change: Cyanolichens in temperate rainforest",
        "paper_author": "Ellis C.J.",
        "publication": "Global Change Biology",
        "citied_by": "16",
        "cover_date": "2021-05-01",
        "Abstract": "There is deepening interest in how microclimatic refugia can reduce species threat, if suitable climatic conditions are maintained locally, despite global climate change. Microclimates are a particularly important consideration in topographically heterogeneous landscapes, while in some habitats, such as forests and woodlands, microclimates are also extremely labile and affected by management practices that could consequently be used to offset climate change impact. This study explored a conservation priority guild—cyanolichen epiphytes in temperate rainforest—quantifying the niche response to macroclimate, and landscape or woodland stand structures that determine the microclimate. Based on epiphyte survey in a core region of European temperate rainforest (western Scotland), a ‘random forest’ machine-learning model confirmed a strong cyanolichen response to summer dryness, as well as the effects of distance to running water, topographic heatload and tree species identity, which modify the local moisture regime and/or lichen growth rates. By quantifying this response to macroclimate, landscape and stand structures, it was possible to estimate an extent to which woodland may be expanded in the future, to offset a negative effect of increasing summer dryness projected through to the 2080s. Using current policy as a yardstick, sufficient woodland expansion could be delivered relatively quickly for median impacted sites, but with times to woodland delivery extending over 10, 20 and 25 years for sites at the 75th, 90th and 95th percentiles of cyanolichen decline. Furthermore, the extent of new woodland required, and delivery times, increase almost threefold on average, as new woodland becomes distributed over wider riparian zones. These contrasting implications emphasize an urgent need for afforestation that achieves targeted spatial planning responsive to microclimates as refugia.",
        "DOI": "10.1111/gcb.15514",
        "affiliation_name": "Royal Botanic Garden Edinburgh",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Federated semi-supervised learning for COVID region segmentation in chest CT using multi-national data from China, Italy, Japan",
        "paper_author": "Yang D.",
        "publication": "Medical Image Analysis",
        "citied_by": "203",
        "cover_date": "2021-05-01",
        "Abstract": "The recent outbreak of Coronavirus Disease 2019 (COVID-19) has led to urgent needs for reliable diagnosis and management of SARS-CoV-2 infection. The current guideline is using RT-PCR for testing. As a complimentary tool with diagnostic imaging, chest Computed Tomography (CT) has been shown to be able to reveal visual patterns characteristic for COVID-19, which has definite value at several stages during the disease course. To facilitate CT analysis, recent efforts have focused on computer-aided characterization and diagnosis with chest CT scan, which has shown promising results. However, domain shift of data across clinical data centers poses a serious challenge when deploying learning-based models. A common way to alleviate this issue is to fine-tune the model locally with the target domains local data and annotations. Unfortunately, the availability and quality of local annotations usually varies due to heterogeneity in equipment and distribution of medical resources across the globe. This impact may be pronounced in the detection of COVID-19, since the relevant patterns vary in size, shape, and texture. In this work, we attempt to find a solution for this challenge via federated and semi-supervised learning. A multi-national database consisting of 1704 scans from three countries is adopted to study the performance gap, when training a model with one dataset and applying it to another. Expert radiologists manually delineated 945 scans for COVID-19 findings. In handling the variability in both the data and annotations, a novel federated semi-supervised learning technique is proposed to fully utilize all available data (with or without annotations). Federated learning avoids the need for sensitive data-sharing, which makes it favorable for institutions and nations with strict regulatory policy on data privacy. Moreover, semi-supervision potentially reduces the annotation burden under a distributed setting. The proposed framework is shown to be effective compared to fully supervised scenarios with conventional data sharing instead of model weight sharing.",
        "DOI": "10.1016/j.media.2021.101992",
        "affiliation_name": "NVIDIA",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Forecasting the dynamics of cumulative COVID-19 cases (confirmed, recovered and deaths) for top-16 countries using statistical machine learning models: Auto-Regressive Integrated Moving Average (ARIMA) and Seasonal Auto-Regressive Integrated Moving Average (SARIMA)",
        "paper_author": "ArunKumar K.E.",
        "publication": "Applied Soft Computing",
        "citied_by": "152",
        "cover_date": "2021-05-01",
        "Abstract": "Most countries are reopening or considering lifting the stringent prevention policies such as lockdowns, consequently, daily coronavirus disease (COVID-19) cases (confirmed, recovered and deaths) are increasing significantly. As of July 25th, there are 16.5 million global cumulative confirmed cases, 9.4 million cumulative recovered cases and 0.65 million deaths. There is a tremendous necessity of supervising and estimating future COVID-19 cases to control the spread and help countries prepare their healthcare systems. In this study, time-series models — Auto-Regressive Integrated Moving Average (ARIMA) and Seasonal Auto-Regressive Integrated Moving Average (SARIMA) are used to forecast the epidemiological trends of the COVID-19 pandemic for top-16 countries where 70%–80% of global cumulative cases are located. Initial combinations of the model parameters were selected using the auto-ARIMA model followed by finding the optimized model parameters based on the best fit between the predictions and test data. Analytical tools Auto-Correlation function (ACF), Partial Auto-Correlation Function (PACF), Akaike Information Criterion (AIC) and Bayesian Information Criterion (BIC) were used to assess the reliability of the models. Evaluation metrics Mean Absolute Error (MAE), Mean Square Error (MSE), Root Mean Square Error (RMSE) and Mean Absolute Percent Error (MAPE) were used as criteria for selecting the best model. A case study was presented where the statistical methodology was discussed in detail for model selection and the procedure for forecasting the COVID-19 cases of the USA. Best model parameters of ARIMA and SARIMA for each country are selected manually and the optimized parameters are then used to forecast the COVID-19 cases. Forecasted trends for confirmed and recovered cases showed an exponential rise for countries such as the United States, Brazil, South Africa, Colombia, Bangladesh, India, Mexico and Pakistan. Similarly, trends for cumulative deaths showed an exponential rise for countries Brazil, South Africa, Chile, Colombia, Bangladesh, India, Mexico, Iran, Peru, and Russia. SARIMA model predictions are more realistic than that of the ARIMA model predictions confirming the existence of seasonality in COVID-19 data. The results of this study not only shed light on the future trends of the COVID-19 outbreak in top-16 countries but also guide these countries to prepare their health care policies for the ongoing pandemic. The data used in this work is obtained from publicly available John Hopkins University's COVID-19 database.",
        "DOI": "10.1016/j.asoc.2021.107161",
        "affiliation_name": "Department of Civil and Environmental Engineering",
        "affiliation_city": "Rapid City",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Customers segmentation in eco-friendly hotels using multi-criteria and machine learning techniques",
        "paper_author": "Yadegaridehkordi E.",
        "publication": "Technology in Society",
        "citied_by": "73",
        "cover_date": "2021-05-01",
        "Abstract": "This study aims to investigate the travellers' choice behaviour towards green hotels through existing online travel reviews on TripAdvisor. Accordingly, a method combining segmentation and the Technique for Order of Preference by Similarity to Ideal Solution (TOPSIS) techniques was developed to segment travellers based on their provided reviews and to prioritize green hotel attributes based on their level of importance in each segment. The data were taken from travellers' online reviews of Malaysian eco-friendly hotels on TripAdvisor. The results showed that the sleep quality was one of the most imporant factors for eco-hotel selection in the majority of segments. The developed method in this study was able to analyse travellers’ reviews and ratings on eco-friendly hotels to identify the future choice behaviour and aid travellers in their decision-making process. The study provides new insights for hotel managers and green policy makers on developing environmental-friendly practices.",
        "DOI": "10.1016/j.techsoc.2021.101528",
        "affiliation_name": "Faculty of Engineering",
        "affiliation_city": "Johor Bahru",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Improving lifetime of wireless sensor networks based on nodes’ distribution using Gaussian mixture model in multi-mobile sink approach",
        "paper_author": "Hojjatinia H.",
        "publication": "Telecommunication Systems",
        "citied_by": "5",
        "cover_date": "2021-05-01",
        "Abstract": "Saving energy in Wireless Sensor Networks (WSNs), is critical in different applications, such as environment monitoring, keeping human awareness and etc. Many studies have investigated energy consumption and improved the WSN lifetime longevity by reducing the energy consumption. Still, proposed approaches overlook the nodes’ distribution role in energy model and routing protocol, which is a key factor in a WSN. In this work, we propose a novel approach; namely GDECA; which assumes nodes’ distributions are mixtures of Gaussian distribution, as an assumption applied in real world. So GDECA rely on a distribution estimation borrowed from Machine Learning (ML) to fit the Gaussian Mixture Model (GMM) to the nodes and calculate the parameters for these distributions. Next, the estimated parameters are employed in Cluster Head CH selection policy. Besides, sinks routing is determined based on nodes distribution. Results showed the improvement close to 40–50% in energy consumption. As another outcome, GDECA keeps all the nodes active until end of the simulation. Observations also demonstrate that sinks path calculation using this approach is optimum, and randomly changing number of sinks increases energy consumption.",
        "DOI": "10.1007/s11235-021-00753-6",
        "affiliation_name": "Islamic Azad University, Science and Research Branch",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Analysis of the policy guarantee mechanism of rural infrastructure based on deep learning",
        "paper_author": "Jin X.",
        "publication": "Technological Forecasting and Social Change",
        "citied_by": "12",
        "cover_date": "2021-05-01",
        "Abstract": "Rural infrastructure is the key factor affecting the farmers’ income and agricultural production, and plays an important role in development of rural areas. In order to ensure continuous improvement and sustainable development of rural infrastructure, it is necessary to establish a set of guarantee mechanisms that involve policies and regulations, organizational leadership, capital investment and system management of rural infrastructure. Deep learning is a method that simulates the human brain to extract features from input data in a hierarchical manner and thereby improves data interpretation. The better interpreted data can enhance the accuracy of detection and forecast tasks. This paper analyzes the policy guarantee mechanism of rural key infrastructure policies based on deep learning to provide a scientific basis for application of this mechanism in rural China.",
        "DOI": "10.1016/j.techfore.2021.120605",
        "affiliation_name": "Guangdong University of Finance &amp; Economics",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep learning neural networks for spatially explicit prediction of flash flood probability",
        "paper_author": "Panahi M.",
        "publication": "Geoscience Frontiers",
        "citied_by": "94",
        "cover_date": "2021-05-01",
        "Abstract": "Flood probability maps are essential for a range of applications, including land use planning and developing mitigation strategies and early warning systems. This study describes the potential application of two architectures of deep learning neural networks, namely convolutional neural networks (CNN) and recurrent neural networks (RNN), for spatially explicit prediction and mapping of flash flood probability. To develop and validate the predictive models, a geospatial database that contained records for the historical flood events and geo-environmental characteristics of the Golestan Province in northern Iran was constructed. The step-wise weight assessment ratio analysis (SWARA) was employed to investigate the spatial interplay between floods and different influencing factors. The CNN and RNN models were trained using the SWARA weights and validated using the receiver operating characteristics technique. The results showed that the CNN model (AUC = 0.832, RMSE = 0.144) performed slightly better than the RNN model (AUC = 0.814, RMSE = 0.181) in predicting future floods. Further, these models demonstrated an improved prediction of floods compared to previous studies that used different models in the same study area. This study showed that the spatially explicit deep learning neural network models are successful in capturing the heterogeneity of spatial patterns of flood probability in the Golestan Province, and the resulting probability maps can be used for the development of mitigation plans in response to the future floods. The general policy implication of our study suggests that design, implementation, and verification of flood early warning systems should be directed to approximately 40% of the land area characterized by high and very susceptibility to flooding.",
        "DOI": "10.1016/j.gsf.2020.09.007",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Flood susceptibility modelling using advanced ensemble machine learning models",
        "paper_author": "Towfiqul Islam A.R.M.",
        "publication": "Geoscience Frontiers",
        "citied_by": "340",
        "cover_date": "2021-05-01",
        "Abstract": "Because of the tremendous damage to properties, infrastructures, and human casualties, floods are one of the greatest devastating disasters from nature. Due to the dynamic and complex nature of the flash flood, it is challenging to predict the sites which are vulnerable to flash floods. Therefore, earlier identification of flash flood susceptible sites can be performed using advanced machine learning models for managing flood disasters. In this study, we applied and assessed two new hybrid ensemble models, namely Dagging and Random Subspace (RS) coupled with Artificial Neural Network (ANN), Random Forest (RF), and Support Vector Machine (SVM) which are the other three state-of-the-art machine learning models for modelling flood susceptibility maps at the Teesta River basin, the northern region of Bangladesh. The application of these models includes twelve flood influencing factors with 413 current and former flooding points, which were transferred in a GIS environment. The information gain ratio, the multicollinearity diagnostics tests were employed to determine the association between the occurrences and flood influential factors. For the validation and the comparison of these models, for the ability to predict the statistical appraisal measures such as Freidman, Wilcoxon signed-rank, and t-paired tests and Receiver Operating Characteristic Curve (ROC) were employed. The value of the Area Under the Curve (AUC) of ROC was above 0.80 for all models. For flood susceptibility modelling, the Dagging model performs superior, followed by RF, the ANN, the SVM, and the RS, then the several benchmark models. The methodology and solution-oriented results presented in this paper will assist the regional as well as local authorities and the policy-makers for mitigating the risks related to floods and also help in developing appropriate mitigation measures to avoid potential damages.",
        "DOI": "10.1016/j.gsf.2020.09.006",
        "affiliation_name": "CERIS – Civil Engineering Research and Innovation for Sustainability",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Computational Media Intelligence: Human-Centered Machine Analysis of Media",
        "paper_author": "Somandepalli K.",
        "publication": "Proceedings of the IEEE",
        "citied_by": "27",
        "cover_date": "2021-05-01",
        "Abstract": "Media is created by humans for humans to tell stories. There exists a natural and imminent need for creating human-centered media analytics to illuminate the stories being told and to understand their impact on individuals and society at large. An objective understanding of media content has numerous applications for different stakeholders, from creators to decision-/policy-makers to consumers. Advances in multimodal signal processing and machine learning (ML) can enable detailed and nuanced characterization of media content (of who, what, how, where, and why) at scale. They can also aid our understanding of the impact of media on a range of issues, including individual experiences, behavioral, cultural, and societal trends, and commercial outcomes. Modern deep learning models combined with audiovisual signal processing can analyze entertainment media, such as Film TV content to quantify gender, age, and race representations. This creates awareness in an objective way that was hitherto impossible. On the other hand, text mining and natural language processing allow nuanced understanding of language use and spoken interactions in media, such as News to track patterns and trends across different contexts. Moreover, advances in human sensing have enabled us to directly measure the influence of media on an individual's physiology (and brain), while social media analysis enables tracking the societal impact of media content on different cross sections of the society. This article reviews representative methodologies and algorithms, tools, and systems advancing human-centered media understanding through ML in the pursuit of developing computational media intelligence.",
        "DOI": "10.1109/JPROC.2020.3047978",
        "affiliation_name": "Faculty of Science, Engineering and Medicine",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Novel Online Sequential Learning-Based Adaptive Routing for Edge Software-Defined Vehicular Networks",
        "paper_author": "Zhao L.",
        "publication": "IEEE Transactions on Wireless Communications",
        "citied_by": "93",
        "cover_date": "2021-05-01",
        "Abstract": "To provide efficient networking services at the edge of Internet-of-Vehicles (IoV), Software-Defined Vehicular Network (SDVN) has been a promising technology to enable intelligent data exchange without giving additional duties to the resource constrained vehicles. Compared with conventional centralized SDVNs, hybrid SDVNs combine the centralized control of SDVNs and self-organized distributed routing of Vehicular Ad-hoc NETworks (VANETs) to mitigate the burden on the central controller caused by the frequent uplink and downlink transmissions. Although a wide variety of routing protocols have been developed, existing protocols are designed for specific scenarios without considering flexibility and adaptivity in dynamic vehicular networks. To address this problem, we propose an efficient online sequential learning-based adaptive routing scheme, namely, Penicillium reproduction-based Online Learning Adaptive Routing scheme (POLAR) for hybrid SDVNs. By utilizing the computational power of edge servers, this scheme can dynamically select a routing strategy for a specific traffic scenario by learning the pattern from network traffic. Firstly, this paper applies Geohash to divide the large geographical area into multiple grids, which facilitates the collection and processing of real-time traffic data for regional management in controller. Secondly, a new Penicillium Reproduction Algorithm (PRA) with outstanding optimization capabilities is designed to improve the learning effectiveness of Online Sequential Extreme Learning Machine (OS-ELM). Finally, POLAR is deployed in control plane to generate decision-making model (i.e., routing policy). Based on the real-time featured data, this scheme can choose the optimal routing strategy for a specific area. Extensive simulation results show that POLAR is superior to a single traditional routing protocol in terms of packet delivery ratio and latency.",
        "DOI": "10.1109/TWC.2020.3046275",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Forecasting annual natural gas consumption via the application of a novel hybrid model",
        "paper_author": "Gao F.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "24",
        "cover_date": "2021-05-01",
        "Abstract": "Accurate prediction of natural gas consumption (NGC) can offer effective information for energy planning and policy-making. In this study, a novel hybrid forecasting model based on support vector machine (SVM) and improved artificial fish swarm algorithm (IAFSA) is proposed to predict annual NGC. An adaptive learning strategy based on sigmoid function is introduced to improve the performance of traditional artificial fish swarm algorithm (AFSA), which provides a dynamic adjustment for parameter moving step step and visual scope visual. IAFSA is used to obtain the optimal parameters of SVM. In addition, the annual NGC data of China is selected as an example to evaluate the prediction performance of the proposed model. Experimental results reveal that the proposed model in this study outperforms the benchmark models such as artificial neural network (ANN) and partial least squares regression (PLS). The mean absolute percentage error (MAPE), root mean squared error (RMSE), and mean absolute error (MAE) values are as low as 0.512, 1.4958, and 1.0940. Finally, the proposed model is employed to predict NGC in China from 2020 to 2025.",
        "DOI": "10.1007/s11356-020-12275-w",
        "affiliation_name": "Institutes of Science and Development",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Automated stem cell production by bio-inspired control",
        "paper_author": "Monostori L.",
        "publication": "CIRP Journal of Manufacturing Science and Technology",
        "citied_by": "7",
        "cover_date": "2021-05-01",
        "Abstract": "The potential in treating chronic and life-threatening diseases by stem cell therapies can greatly be exploited via the efficient automation of stem cell production. Working with living material though poses severe challenges to automation. Recently, production platforms has been developed and tested worldwide with the aim to increase the reproducibility, quality and throughput of the process, to minimize human errors, and to reduce costs of production. A distinctive feature of this domain is the symbiotic co-existence and co-evolution of the technical, information and communication, as well as biological ingredients in production structures. A challenging way to overcome the issues of automated production is the use of biologically inspired control algorithms. In the paper an approach is described which combines digital, agent-based simulation and reinforcement learning for this purpose. The modelling of the cell growth behaviour, which is an important prerequisite of the simulation, is also introduced, together with an appropriate model fitting procedure. The applicability of the proposed approach is demonstrated by the results of a comprehensive investigation.",
        "DOI": "10.1016/j.cirpj.2021.03.013",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "Data-Driven Approach for Evaluating the Energy Efficiency in Multifamily Residential Buildings",
        "paper_author": "Seyrfar A.",
        "publication": "Practice Periodical on Structural Design and Construction",
        "citied_by": "44",
        "cover_date": "2021-05-01",
        "Abstract": "Cities account for more than 70% of global fossil fuel use and greenhouse gas emissions. This number is likely to increase due to urban population growth. Much of the energy used in cities is consumed in buildings (e.g., for space conditioning and lighting). Better understanding of energy use patterns therefore is paramount. This paper leveraged advances in machine learning to model energy consumption in residential buildings and gain insights into building energy consumption trends in Chicago. By merging demographic and socioeconomic data collected from the US Census Bureau with energy benchmarking data for Chicago, three models were developed using three different machine learning algorithms: back-propagation neural network (BPNN), extreme gradient boosting (XGBoost), and random forest (RF). The results showed that XGBoost better predicts the building energy use, with an accuracy of 68%. Furthermore, Shapley Additive Explanations (SHAP) was used to interpret the impact of each variable used on building energy consumption. Overall, the insights gained in this study can help policy makers and planners to address building energy use better.",
        "DOI": "10.1061/(ASCE)SC.1943-5576.0000555",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Support vector subset scan for spatial pattern detection",
        "paper_author": "Fitzpatrick D.",
        "publication": "Computational Statistics and Data Analysis",
        "citied_by": "2",
        "cover_date": "2021-05-01",
        "Abstract": "Discovery of localized and irregularly shaped anomalous patterns in spatial data provides useful context for operational decisions across many policy domains. The support vector subset scan (SVSS) integrates the penalized fast subset scan with a kernel support vector machine classifier to accurately detect spatial clusters without imposing hard constraints on the shape or size of the pattern. The method iterates between (1) efficiently maximizing a penalized log-likelihood ratio over subsets of locations to obtain an anomalous pattern, and (2) learning a high-dimensional decision boundary between locations included in and excluded from the anomalous subset. On each iteration, location-specific penalties to the log-likelihood ratio are assigned according to distance to the decision boundary, encouraging patterns which are spatially compact but potentially highly irregular in shape. SVSS outperforms competing methods for spatial cluster detection at the task of detecting randomly generated patterns in simulated experiments. SVSS enables discovery of practically-useful anomalous patterns for disease surveillance in Chicago, IL, crime hotspot detection in Portland, OR, and pothole cluster detection in Pittsburgh, PA, as demonstrated by experiments using publicly available data sets from these domains.",
        "DOI": "10.1016/j.csda.2020.107149",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Assessment of solar photovoltaic potentials on urban noise barriers using street-view imagery",
        "paper_author": "Zhong T.",
        "publication": "Renewable Energy",
        "citied_by": "49",
        "cover_date": "2021-05-01",
        "Abstract": "Solar energy captured by solar photovoltaic (PV) systems has great potential to meet the high demand for renewable energy sources in urban areas. A photovoltaic noise barrier (PVNB) system, which integrates a PV system with a noise barrier, is a promising source for harvesting solar energy to overcome the problem of having limited land available for solar panel installations. When estimating the solar PV potential at the city scale, it is difficult to identify sites for installing solar panels. A computational framework is proposed for estimating the solar PV potential of PVNB systems based on both existing and planned noise barrier sites. The proposed computational framework can identify suitable sites for installing photovoltaic panels. A deep learning-based method is used to detect existing noise barrier sites from massive street-view images. The planned noise barrier sites are identified with urban policies. Based on the existing and planned sites of noise barriers in Nanjing, the annual solar PV potentials in 2019 are 29,137 MW h and 113,052 MW h, respectively. The estimation results show that the potential PVNB systems based on the existing and planned noise barrier in 2019 have the potential installed capacity of 14.26 MW and 57.24 MW, with corresponding potential annual power generation of 4662 MW h and 18,088 MW h, respectively.",
        "DOI": "10.1016/j.renene.2020.12.044",
        "affiliation_name": "Singapore-MIT Alliance for Research and Technology",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Has the COVID-19 Crisis Affected the Growth of United States Food and Drug Administration Drug Approvals? The Answer is Not Yet! A Time Series (Forecasting) Study",
        "paper_author": "Daizadeh I.",
        "publication": "Therapeutic Innovation and Regulatory Science",
        "citied_by": "4",
        "cover_date": "2021-05-01",
        "Abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-19; HCoV-19; COVID-19) has affected all daily activities. Has it also affected the number of United States (FDA) drug approvals over time? The short answer from empirical time series forecasting is not yet. Care should be taken as the crisis continues through maintaining the scientific, economic, political, and social supportive structures to sustain momentum. This conclusion is based on analyzing the results of (non-overlapping) forecasting routines (viz., complex exponential smoothing, auto-regressive fractionally integrated moving average, extreme learning machine, and multi-layer perceptron) performed on longitudinal (1939-present) FDA (CDER) drug approvals taking into regard pre- and extant-COVID-19 eras. This is an initial study and there are caveats with the approach, and as such, all data and programs are provided to support replication of the results and furthering of the investigation.",
        "DOI": "10.1007/s43441-020-00249-6",
        "affiliation_name": "Takeda Pharmaceuticals U.S.A., Inc.",
        "affiliation_city": "Lexington",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Money laundering and terrorism financing detection using neural networks and an abnormality indicator",
        "paper_author": "Rocha-Salazar J.d.J.",
        "publication": "Expert Systems with Applications",
        "citied_by": "43",
        "cover_date": "2021-05-01",
        "Abstract": "This study proposes a comprehensive model that helps improve self-comparisons and group-comparisons for customers to detect suspicious transactions related to money laundering (ML) and terrorism financing (FT) in financial systems. The self-comparison is improved by establishing a more comprehensive know your customer (KYC) policy, adding non-transactional characteristics to obtain a set of variables that can be classified into four categories: inherent, product, transactional, and geographic. The group-comparison involving the clustering process is improved by using an innovative transaction abnormality indicator, based on the variance of the variables. To illustrate the way this methodology works, random samples were extracted from the data warehouse of an important financial institution in Mexico. To train the algorithms, 26,751 and 3527 transactions and their features, involving natural and legal persons, respectively, were selected randomly from January 2020. To measure the prediction accuracy, test sets of 1000 and 600 transactions were selected randomly for natural and legal persons, respectively, from February 2020. The proposed model manages to decrease the proportion of false positives and increase accuracy when compared to the rule-based system. On reducing the false positive rate, the company's costs for investigating suspicious customers also decrease significantly.",
        "DOI": "10.1016/j.eswa.2020.114470",
        "affiliation_name": "Universidad Complutense de Madrid",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Exploring the growth of COVID-19 cases using exponential modelling across 42 countries and predicting signs of early containment using machine learning",
        "paper_author": "Kasilingam D.",
        "publication": "Transboundary and Emerging Diseases",
        "citied_by": "23",
        "cover_date": "2021-05-01",
        "Abstract": "The coronavirus disease 2019 (COVID-19) pandemic spread by the single-stranded RNA severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) belongs to the seventh generation of the coronavirus family. Following an unusual replication mechanism, its extreme ease of transmissivity has put many countries under lockdown. With the uncertainty of developing a cure/vaccine for the infection in the near future, the onus currently lies on healthcare infrastructure, policies, government activities, and behaviour of the people to contain the virus. This research uses exponential growth modelling studies to understand the spreading patterns of SARS-CoV-2 and identifies countries that showed early signs of containment until March 26, 2020. Predictive supervised machine learning models are built using infrastructure, environment, policies, and infection-related independent variables to predict early containment. COVID-19 infection data across 42 countries are used. Logistic regression results show a positive significant relationship between healthcare infrastructure and lockdown policies, and signs of early containment. Machine learning models based on logistic regression, decision tree, random forest, and support vector machines are developed and show accuracies between 76.2% and 92.9% to predict early signs of infection containment. Other policies and the decisions taken by countries to contain the infection are also discussed.",
        "DOI": "10.1111/tbed.13764",
        "affiliation_name": "Government College of Engineering Srirangam",
        "affiliation_city": "Tiruchirappalli",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Reinforcement Learning with Task Decomposition for Cooperative Multiagent Systems",
        "paper_author": "Sun C.",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "60",
        "cover_date": "2021-05-01",
        "Abstract": "In this article, we study cooperative multiagent systems (MASs) with multiple tasks by using reinforcement learning (RL)-based algorithms. The target for a single-agent RL system is represented by its scalar reward signals. However, for an MAS with multiple cooperative tasks, the holistic reward signal consists of multiple parts to represent the tasks, which makes the problem complicated. Existing multiagent RL algorithms search distributed policies with holistic reward signals directly, making it difficult to obtain an optimal policy for each task. This article provides efficient learning-based algorithms such that each agent can learn a joint optimal policy to accomplish these multiple tasks cooperatively with other agents. The main idea of the algorithms is to decompose the holistic reward signal for each agent into multiple parts according to the subtasks, and then the proposed algorithms learn multiple value functions with the decomposed reward signals and update the policy with the sum of distributed value functions. In addition, this article presents a theoretical analysis of the proposed approach. Finally, the simulation results for both discrete decision-making and continuous control problems have demonstrated the effectiveness of the proposed algorithms.",
        "DOI": "10.1109/TNNLS.2020.2996209",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Computational approaches and machine learning for individual-level treatment predictions",
        "paper_author": "Paulus M.P.",
        "publication": "Psychopharmacology",
        "citied_by": "22",
        "cover_date": "2021-05-01",
        "Abstract": "Rationale: The impact of neuroscience-based approaches for psychiatry on pragmatic clinical decision-making has been limited. Although neuroscience has provided insights into basic mechanisms of neural function, these insights have not improved the ability to generate better assessments, prognoses, diagnoses, or treatment of psychiatric conditions. Objectives: To integrate the emerging findings in machine learning and computational psychiatry to address the question: what measures that are not derived from the patient’s self-assessment or the assessment by a trained professional can be used to make more precise predictions about the individual’s current state, the individual’s future disease trajectory, or the probability to respond to a particular intervention? Results: Currently, the ability to use individual differences to predict differential outcomes is very modest possibly related to the fact that the effect sizes of interventions are small. There is emerging evidence of genetic and neuroimaging-based heterogeneity of psychiatric disorders, which contributes to imprecise predictions. Although the use of machine learning tools to generate clinically actionable predictions is still in its infancy, these approaches may identify subgroups enabling more precise predictions. In addition, computational psychiatry might provide explanatory disease models based on faulty updating of internal values or beliefs. Conclusions: There is a need for larger studies, clinical trials using machine learning, or computational psychiatry model parameters predictions as actionable outcomes, comparing alternative explanatory computational models, and using translational approaches that apply similar paradigms and models in humans and animals.",
        "DOI": "10.1007/s00213-019-05282-4",
        "affiliation_name": "Laureate Institute for Brain Research",
        "affiliation_city": "Tulsa",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Energy Justice Through Solar: Constructing and Engaging Low-Income Households",
        "paper_author": "Si Y.",
        "publication": "Frontiers in Sustainable Cities",
        "citied_by": "10",
        "cover_date": "2021-04-29",
        "Abstract": "Minimal research has assessed the policy process of developing solar programs at the state level, and no research yet has investigated how these policies characterize and engage with the target populations they are designed to benefit. Grounded in Schneider and Ingram's social construction framework (SCF) and applying computational methods (i.e., text analysis and machine learning), this research examines how low-income households are socially constructed in policy provisions, how their social construction has been reinforced through public participation, and how to classify low-income households among target populations. Based on the case of Massachusetts, this research analyzes the 2020 Solar Massachusetts Renewable Target (SMART) Emergency Regulation as well as its public comments. We find that low-income households constitute a visible target group of this program and their characterizations as “deserving policy benefits” are positively constructed by policy makers. Furthermore, the conveyed messages and attitudes regarding the assigned benefits to low-income households have been reinforced through public participation. Despite this advantageous positive construction, low-income households have less political power (i.e., measured by topic prevalence in the public comments) than other target groups such as large corporations (e.g., solar developers or solar installers) and less ability to participate or be represented in the policy process, making their voices less likely to be heard by policy makers. With positive social construction but weaker political power, low-income households fall into the category of “dependents” instead of “advantaged,” which may engender undesirable policy outcomes minimizing the intended long-term benefits of the policies to low-income households. This research reveals procedural injustices in energy policies and highlights the importance of more inclusive policy-making process, while also offering a novel theoretical lens to understand the rationale and dynamics of developing solar statutes targeting low-income households.",
        "DOI": "10.3389/frsc.2021.632020",
        "affiliation_name": "Northeastern University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Off-Policy Evaluation of the Performance of a Robot Swarm: Importance Sampling to Assess Potential Modifications to the Finite-State Machine That Controls the Robots",
        "paper_author": "Pagnozzi F.",
        "publication": "Frontiers in Robotics and AI",
        "citied_by": "1",
        "cover_date": "2021-04-29",
        "Abstract": "Due to the decentralized, loosely coupled nature of a swarm and to the lack of a general design methodology, the development of control software for robot swarms is typically an iterative process. Control software is generally modified and refined repeatedly, either manually or automatically, until satisfactory results are obtained. In this paper, we propose a technique based on off-policy evaluation to estimate how the performance of an instance of control software—implemented as a probabilistic finite-state machine—would be impacted by modifying the structure and the value of the parameters. The proposed technique is particularly appealing when coupled with automatic design methods belonging to the AutoMoDe family, as it can exploit the data generated during the design process. The technique can be used either to reduce the complexity of the control software generated, improving therefore its readability, or to evaluate perturbations of the parameters, which could help in prioritizing the exploration of the neighborhood of the current solution within an iterative improvement algorithm. To evaluate the technique, we apply it to control software generated with an AutoMoDe method, (Formula presented.). In a first experiment, we use the proposed technique to estimate the impact of removing a state from a probabilistic finite-state machine. In a second experiment, we use it to predict the impact of changing the value of the parameters. The results show that the technique is promising and significantly better than a naive estimation. We discuss the limitations of the current implementation of the technique, and we sketch possible improvements, extensions, and generalizations.",
        "DOI": "10.3389/frobt.2021.625125",
        "affiliation_name": "Université Libre de Bruxelles",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "A Large Publicly Available Corpus of Website Privacy Policies Based on DMOZ",
        "paper_author": "Nokhbeh Zaeem R.",
        "publication": "CODASPY 2021 - Proceedings of the 11th ACM Conference on Data and Application Security and Privacy",
        "citied_by": "17",
        "cover_date": "2021-04-26",
        "Abstract": "Studies have shown website privacy policies are too long and hard to comprehend for their target audience. These studies and a more recent body of research that utilizes machine learning and natural language processing to automatically summarize privacy policies greatly benefit, if not rely on, corpora of privacy policies collected from the web. While there have been smaller annotated corpora of web privacy policies made public, we are not aware of any large publicly available corpus. We use DMOZ, a massive open-content directory of the web, and its manually categorized 1.5 million websites, to collect hundreds of thousands of privacy policies associated with their categories, enabling research on privacy policies across different categories/market sectors. We review the statistics of this corpus and make it available for research. We also obtain valuable insights about privacy policies, e.g., which websites post them less often. Our corpus of web privacy policies is a valuable tool at the researchers' disposal to investigate privacy policies. For example, it facilitates comparison among different methods of privacy policy summarization by providing a benchmark, and can be used in unsupervised machine learning to summarize privacy policies.",
        "DOI": "10.1145/3422337.3447827",
        "affiliation_name": "The University of Texas at Austin",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Accelerated Training via Device Similarity in Federated Learning",
        "paper_author": "Wang Y.",
        "publication": "EdgeSys 2021 - Proceedings of the 4th International Workshop on Edge Systems, Analytics and Networking, Part of EuroSys 2021",
        "citied_by": "15",
        "cover_date": "2021-04-26",
        "Abstract": "Federated Learning is a privacy-preserving, machine learning technique that generates a globally shared model with in-situ model training on distributed devices. These systems are often comprised of millions of user devices and only a subset of available devices can be used for training in each epoch. Designing a device selection strategy is challenging, given that devices are highly heterogeneous in both their system resources and training data. This heterogeneity makes device selection very crucial for timely model convergence and sufficient model accuracy. Existing approaches have addressed system heterogeneity for device selection but have largely ignored the data heterogeneity. In this work, we analyze the impact of data heterogeneity on device selection, model convergence, model accuracy, and fault tolerance in a federated learning setting. Based on our analysis, we propose that clustering devices with similar data distributions followed by selecting the devices with the best processing capacity from each cluster can significantly improve the model convergence without compromising model accuracy. This clustering also guides us in designing policies for fault tolerance in the system. We propose three methods for identifying groups of devices with similar data distributions. We also identify and discuss rich trade-offs between privacy, bandwidth consumption, and computation overhead for each of these proposed methods. Our preliminary experiments show that the proposed methods can provide a 46%-58% reduction in training time compared to existing approaches in reaching the same accuracy.",
        "DOI": "10.1145/3434770.3459734",
        "affiliation_name": "University of Minnesota Twin Cities",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reinforcement learning method for supercritical airfoil aerodynamic design",
        "paper_author": "Li R.",
        "publication": "Hangkong Xuebao/Acta Aeronautica et Astronautica Sinica",
        "citied_by": "6",
        "cover_date": "2021-04-25",
        "Abstract": "Reinforcement learning as a machine learning method for learning policies learns in a way similar to human learning process, interacting with the environment and learning how to achieve more rewards. The elements and algorithms of reinforcement learning are defined and adjusted in this paper for the supercritical airfoil aerodynamic design process. The results of imitation learning are then studied, and the policies from the imitation learning are adopted in reinforcement learning. The influence of different pretraining processes is studied, and the final policies tested in other similar environments. The results show that pretraining can improve reinforcement learning efficiency and policy robustness. The final policies obtained in this study can also have satisfactory performance in other similar environments.",
        "DOI": "10.7527/S1000-6893.2020.23810",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Design and Implementation of Garbage Classification System Based on Deep Learning",
        "paper_author": "Wang Y.",
        "publication": "2021 7th International Conference on Control, Automation and Robotics, ICCAR 2021",
        "citied_by": "2",
        "cover_date": "2021-04-23",
        "Abstract": "The rapid development of computer vision makes man-machine interaction possible and has a wide application prospect. At present, the Chinese government has implemented the garbage classification policy in various places, and garbage classification has been paid more and more attention by people. But it happens all the time that garbage is misclassified. This essay proposes an image recognition system to help people classify garbage, which can identify different kinds of garbage. The training data set used to train the system is made up of images taken by a camera. The image is preprocessed by rotation, cutting and other methods. Then ResNet50 is selected to train the preprocessed image. The experimental results show that the garbage classification system in this essay can classify garbage effectively and improve the accuracy of garbage classification.",
        "DOI": "10.1109/ICCAR52225.2021.9463488",
        "affiliation_name": "Shenzhen Institute of Advanced Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Integration of Blockchain and Machine Learning for Microgrids",
        "paper_author": "Li Z.",
        "publication": "2021 IEEE 6th International Conference on Computer and Communication Systems, ICCCS 2021",
        "citied_by": "2",
        "cover_date": "2021-04-23",
        "Abstract": "Recently, the emerging applications of ubiquitous renewable energy has driven the increasing research on microgrids where distributed green energy sources, e.g., solar and wind power, are deployed. The microgrid integrating distributed renewable energy generators, energy storage elements, and loads provides power nearby the users, has been proposed for massive distributed applications of renewable energy sources as a small-scale power system due to its easy and flexible deployment. In this paper, we study to integrate blockchain techniques and machine learning for solving the problems of data sharing, processing, and prediction in microgrids. First, we present the existing research and overviews on blockchain techniques and machine learning. Then, we point out the potential applications of blockchain combined with machine learning for microgrids. Finally, we further discuss the open issues, challenges, and future prospects of adopting blockchain techniques and machine learning in microgrids.",
        "DOI": "10.1109/ICCCS52626.2021.9449300",
        "affiliation_name": "China Southern Power Grid",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "COVID-19 Pandemic Prevention Mobile Application for on Campus Classroom",
        "paper_author": "Tangtisanon P.",
        "publication": "2021 IEEE 6th International Conference on Computer and Communication Systems, ICCCS 2021",
        "citied_by": "4",
        "cover_date": "2021-04-23",
        "Abstract": "COVID-19 pandemic is a novel coronavirus that has not been found in humans before. This virus can be transmitted to other humans primarily through respiratory secretions when an infected person coughs or talks. To avoid human to human transmission of this pandemic, the government extend the state of emergency policies which cause vital damage for many business sections worldwide including educational institution. Many schools decide to let the students learn at home. However, in practical courses such as a chemical workshop, students must come to the laboratory room to perform experiments which may increase the risk of infection. In order to prevent the spread of COVID-19 between students and staff, anybody entering the school must conduct a risk assessment, measure a body temperature and wear a face mask at all times. Many COVID-19 contact tracing platforms allow users to assess infection risk and notify if they have been exposed to infected persons. Unfortunately, they cannot be used effectively with the on-campus education system. The proposed mobile application was developed to handle the needs of the onsite education system during the ongoing COVID-19 situation in schools. The application contains three main functions which are a COVID-19 self-assessment, a roll-call, and a social distancing function. This paper focused on the roll-call function using face recognition and Global Positioning System (GPS). In a normal situation, the student just opens an application, shows his or her face to a smartphone camera then the application will detect a face part and easily recognize the student's identification. However, in the new normal situation where everyone must wear a mask, it will be a very difficult task to perform face recognition since almost half of the face is hidden. The convolutional neural network (CNN) was applied to train a CNN model using a dataset of 18 peoples with non face mask wearing and face mask wearing. The face mask wearing consisted of three different face mask types: Disposable surgical mask (DS), N95 face respirators (N95) and general 3D mask (3D). After that, the model was exported to the proposed mobile application. Experimental results on a realworld dataset show that the proposed model can be used with a high accuracy rate in non face mask samples. In face mask samples, the 3D mask has the highest accuracy rate.",
        "DOI": "10.1109/ICCCS52626.2021.9449201",
        "affiliation_name": "King Mongkut's Institute of Technology Ladkrabang",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "On computable expressions of policies for digital health: Use for privacy consent",
        "paper_author": "Milosevic Z.",
        "publication": "Studies in Health Technology and Informatics",
        "citied_by": "1",
        "cover_date": "2021-04-19",
        "Abstract": "This paper proposes a formal model for expressing policies in digital health. The aim is to support computable expressions of legislative, regulative and organizational policies. The model is grounded in the semantics of deontic logic [1] and in modelling concepts for expressing accountability, specified in the new RM-ODP Enterprise Language standard [2]. An example of privacy consent based on the FHIR consent resource [3] is used to explain the use of these modelling concepts. The example involves multiple stakeholders and illustrates the complexity associated with the use of machine learning and artificial intelligence systems as part of healthcare delivery governed by informed consent policies.",
        "DOI": "10.3233/SHTI210011",
        "affiliation_name": "Deontik",
        "affiliation_city": null,
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "SVM Approach for Forecasting International Tourism Arrival in East Java",
        "paper_author": "Purnaningrum E.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "8",
        "cover_date": "2021-04-19",
        "Abstract": "The maneuver of international tourists visiting Indonesia, especially the East Java area, in positive correlation with time. In accordance with the government's work program to increase GDP from the tourism sector. However, the condition necessary to be supported by the existence of feasibility and adequate tourism services. Facility improvements certainly require a projection of international tourist arrivals visiting East Java. SVM is a machine learning method that has shown excellent performance in predicting time series. In addition, analysis results have shown that SVM had able to predict foreign tourist visits with a high degree of accuracy. Therefore, this research can be used as a support for tourism facility procurement policies, especially in East Java.",
        "DOI": "10.1088/1742-6596/1863/1/012060",
        "affiliation_name": "Universitas PGRI Adi Buana Surabaya",
        "affiliation_city": "Surabaya",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Understanding and assembling user behaviours using features of Moodle data for eLearning usage from performance of course-student weblog",
        "paper_author": "Chayanukro S.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "4",
        "cover_date": "2021-04-15",
        "Abstract": "In reality, students learn via eLearning (electronic online learning) system in different ways depending on their learning needs, learning behaviours as well as eLearning system policy for users. However, most learning outcome prediction models of eLearning systems are still not stable and still cannot be applied in many situations as the use of eLearning is considered to be highly dynamic. Therefore, the objective of this work is understand if eLearning system can be predicted based eLearning usage by exploiting Moodle log data. To understand it, features from web log course-student in Moodle is being considered, a number of machine learning techniques also have been applied for benchmarking in this study. The result found that the current group doesn't give better understanding and significant groups of factors that could be able to predict the learning outcome.",
        "DOI": "10.1088/1742-6596/1869/1/012087",
        "affiliation_name": "Universiti Utara Malaysia",
        "affiliation_city": "Sintok",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Modelling wheat yield with antecedent information, satellite and climate data using machine learning methods in Mexico",
        "paper_author": "Gómez D.",
        "publication": "Agricultural and Forest Meteorology",
        "citied_by": "54",
        "cover_date": "2021-04-15",
        "Abstract": "Wheat is one of the most important cereal crops in the world, and its demand is expected to increase about 60% by 2050. Thus, appropriate and reliable yield forecasts are fundamental to ensure price stability and food security around the globe. In this study, we developed a Machine Learning (ML) approach to combine satellite and climate data with antecedent wheat yield information (YieldBaseLine) from 2004 – 2018, at municipal level, in Mexico. We compared the performance of four linear (generalized linear model –glm-, ridge regression –ridge-, lasso, partial least squares –pls-) and four non-linear algorithms (k-nearest neighbours –kknn-, support vector machine radial –svmR-, extreme gradient boosting -xgbTree- and random forest –rf) before harvest time. Additionally, we evaluated their performance using five different feature selection scenarios (No FS, FS = 0.9, FS = 0.75, FS = 0.9 and YieldBaseLine). The models were independently tested using two different approaches: random sampling and selective sampling. In the random sampling, the non-linear models performed generally better under the FS = 0.5 scenario, whereas the non-linear models were less sensitive to feature reduction. The results also evidenced the capacity of the YieldBaseLine predictor, combined with satellite and climate data, to address the inter-annual and spatial variability in the study area. The highest prediction accuracy was obtained by the rf method (No FS) with R2 = 0.84. To further prove the model's operability in a simulated real-case scenario, we held out the last year records (2018) to test the models. The best performing model was again the rf (R2 = 0.81). This study proposes a robust methodology to model crop yield (at large scale) and it may be used with operative purposes. Therefore, it can be of interest to decision and law makers, producers, authorities or the wheat industry. In addition, it can help to establish appropriate food security and trading policies. A similar approach can be applied to other regions or crops.",
        "DOI": "10.1016/j.agrformet.2020.108317",
        "affiliation_name": "Universidad de Valladolid",
        "affiliation_city": "Valladolid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Evaluation of different boosting ensemble machine learning models and novel deep learning and boosting framework for head-cut gully erosion susceptibility",
        "paper_author": "Chen W.",
        "publication": "Journal of Environmental Management",
        "citied_by": "114",
        "cover_date": "2021-04-15",
        "Abstract": "The objective of this study is to assess the gully head-cut erosion susceptibility and identify gully erosion prone areas in the Meimand watershed, Iran. In recent years, this study area has been greatly influenced by several head-cut gullies due to unusual climatic factors and human induced activity. The present study is therefore intended to address this issue by developing head-cut gully erosion prediction maps using boosting ensemble machine learning algorithms, namely Boosted Tree (BT), Boosted Generalized Linear Models (BGLM), Boosted Regression Tree (BRT), Extreme Gradient Boosting (XGB), and Deep Boost (DB). Initially, we produced a gully erosion inventory map using a variety of resources, including published reports, Google Earth images, and field records of the Global Positioning System (GPS). Subsequently, we distributed this information randomly and choose 70% (102) of the test gullies and the remaining 30% (43) for validation. The methodology was designed using morphometric and thematic determinants, including 14 head-cut gully erosion conditioning features. We have also investigated the following: (a) Multi-collinearity analysis to determine the linearity of the independent variables, (b) Predictive capability of piping models using train and test dataset and (c) Variables importance affecting head-cut gully erosion. The study reveals that altitude, land use, distances from road and soil characteristics influenced the method with the greatest impact on head-cut gully erosion susceptibility. We presented five head-cut gully erosion susceptibility maps and investigated their predictive accuracy through area under curve (AUC). The AUC test reveals that the DB machine learning method demonstrated significantly higher accuracy (AUC = 0.95) than the BT (AUC = 0.93), BGLM (AUC = 0.91), BRT (AUC = 0.94) and XGB (AUC = 0.92) approaches. The predicted head-cut gully erosion susceptibility maps can be used by policy makers and local authorities for soil conservation and to prevent threats to human activities.",
        "DOI": "10.1016/j.jenvman.2021.112015",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Causal Datasheet for Datasets: An Evaluation Guide for Real-World Data Analysis and Data Collection Design Using Bayesian Networks",
        "paper_author": "Butcher B.",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "15",
        "cover_date": "2021-04-14",
        "Abstract": "Developing data-driven solutions that address real-world problems requires understanding of these problems’ causes and how their interaction affects the outcome–often with only observational data. Causal Bayesian Networks (BN) have been proposed as a powerful method for discovering and representing the causal relationships from observational data as a Directed Acyclic Graph (DAG). BNs could be especially useful for research in global health in Lower and Middle Income Countries, where there is an increasing abundance of observational data that could be harnessed for policy making, program evaluation, and intervention design. However, BNs have not been widely adopted by global health professionals, and in real-world applications, confidence in the results of BNs generally remains inadequate. This is partially due to the inability to validate against some ground truth, as the true DAG is not available. This is especially problematic if a learned DAG conflicts with pre-existing domain doctrine. Here we conceptualize and demonstrate an idea of a “Causal Datasheet” that could approximate and document BN performance expectations for a given dataset, aiming to provide confidence and sample size requirements to practitioners. To generate results for such a Causal Datasheet, a tool was developed which can generate synthetic Bayesian networks and their associated synthetic datasets to mimic real-world datasets. The results given by well-known structure learning algorithms and a novel implementation of the OrderMCMC method using the Quotient Normalized Maximum Likelihood score were recorded. These results were used to populate the Causal Datasheet, and recommendations could be made dependent on whether expected performance met user-defined thresholds. We present our experience in the creation of Causal Datasheets to aid analysis decisions at different stages of the research process. First, one was deployed to help determine the appropriate sample size of a planned study of sexual and reproductive health in Madhya Pradesh, India. Second, a datasheet was created to estimate the performance of an existing maternal health survey we conducted in Uttar Pradesh, India. Third, we validated generated performance estimates and investigated current limitations on the well-known ALARM dataset. Our experience demonstrates the utility of the Causal Datasheet, which can help global health practitioners gain more confidence when applying BNs.",
        "DOI": "10.3389/frai.2021.612551",
        "affiliation_name": "Harvard T.H. Chan School of Public Health",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A machine learning based modelling framework to predict nitrate leaching from agricultural soils across the netherlands",
        "paper_author": "Spijker J.",
        "publication": "Environmental Research Communications",
        "citied_by": "22",
        "cover_date": "2021-04-14",
        "Abstract": "Throughout recent decades, the excessive use of animal manure and fertiliser put a threat on the quality of ground and surface waters in main agricultural production areas in Europe and other parts of the world. Finding a balance between agricultural production and environmental protection is a prerequisite for sustainable development of ground and surface waters and soil quality. To protect groundwater quality, the European Commission has stipulated a limit value for NO3− of 50 mg l−1. Member states are obliged to monitor and regulate nitrate concentrations in groundwater. In the Netherlands, this monitoring is carried out by sampling nitrate concentrations in water leaching from the root zone at farm level within the national Minerals Policy Monitoring Program. However, due to the costly procedure, only a limited number of about 450 farms can be sampled each year. While this is sufficient for providing a national overview of nitrate leaching, as a result of current and future challenges regarding the sustainable development of the agricultural system, Dutch policymakers need to gain insight into the spatial distribution of nitrate at smaller spatial scales. This study aimed to develop a predictive modelling framework to create annual maps with full national coverage of nitrate concentrations leaching from the root zone of Dutch agricultural soils, and to test this model for the year 2017. We used nitrate data from a national monitoring program and combined them with a large set of auxiliary spatial data, such as soil types, groundwater levels and crop types. We used the Random Forest (RF) algorithm as a prediction and interpolation method. Using the model, we could explain 58% of variance, and statistical errors indicate that the interpolation and map visualisation is suitable for interpretation of the spatial variability of nitrate concentrations in the Netherlands. We used the variable importance from the RF and the partial dependency of the most important variables to get more insight into the major factors explaining the spatial variability. Our study also shows the caveats of data-driven algorithms such as RF. For some areas where no training data was available, the model’s predictions are unexpected and might indicate a model bias. The combination of visualisation of the spatial variability and the interpretation of variable importance and partial dependence results in understanding which areas are more vulnerable to NO3− leaching, in terms of land use and geomorphology. Our modelling framework can be used to target specific areas and to take more targeted regional policy measurements for the balance between agricultural production and protecting the environment.",
        "DOI": "10.1088/2515-7620/abf15f",
        "affiliation_name": "Rijksinstituut voor Volksgezondheid en Milieu",
        "affiliation_city": "Bilthoven",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Anchoring Bias Affects Mental Model Formation and User Reliance in Explainable AI Systems",
        "paper_author": "Nourani M.",
        "publication": "International Conference on Intelligent User Interfaces, Proceedings IUI",
        "citied_by": "70",
        "cover_date": "2021-04-14",
        "Abstract": "EXplainable Artificial Intelligence (XAI) approaches are used to bring transparency to machine learning and artificial intelligence models, and hence, improve the decision-making process for their end-users. While these methods aim to improve human understanding and their mental models, cognitive biases can still influence a user's mental model and decision-making in ways that system designers do not anticipate. This paper presents research on cognitive biases due to ordering effects in intelligent systems. We conducted a controlled user study to understand how the order of observing system weaknesses and strengths can affect the user's mental model, task performance, and reliance on the intelligent system, and we investigate the role of explanations in addressing this bias. Using an explainable video activity recognition tool in the cooking domain, we asked participants to verify whether a set of kitchen policies are being followed, with each policy focusing on a weakness or a strength. We controlled the order of the policies and the presence of explanations to test our hypotheses. Our main finding shows that those who observed system strengths early-on were more prone to automation bias and made significantly more errors due to positive first impressions of the system, while they built a more accurate mental model of the system competencies. On the other hand, those who encountered weaknesses earlier made significantly fewer errors since they tended to rely more on themselves, while they also underestimated model competencies due to having a more negative first impression of the model. Our work presents strong findings that aim to make intelligent system designers aware of such biases when designing such tools.",
        "DOI": "10.1145/3397481.3450639",
        "affiliation_name": "University of Florida",
        "affiliation_city": "Gainesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Scaling neuroscience research using federated learning",
        "paper_author": "Stripelis D.",
        "publication": "Proceedings - International Symposium on Biomedical Imaging",
        "citied_by": "23",
        "cover_date": "2021-04-13",
        "Abstract": "The amount of biomedical data continues to grow rapidly. However, the ability to analyze these data is limited due to privacy and regulatory concerns. Machine learning approaches that require data to be copied to a single location are hampered by the challenges of data sharing. Federated Learning is a promising approach to learn a joint model over data silos. This architecture does not share any subject data across sites, only aggregated parameters, often in encrypted environments, thus satisfying privacy and regulatory requirements. Here, we describe our Federated Learning architecture and training policies. We demonstrate our approach on a brain age prediction model on structural MRI scans distributed across multiple sites with diverse amounts of data and subject (age) distributions. In these heterogeneous environments, our Semi-Synchronous protocol provides faster convergence.",
        "DOI": "10.1109/ISBI48211.2021.9433925",
        "affiliation_name": "Information Sciences Institute",
        "affiliation_city": "Marina del Rey",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Short-term forecasts of expected deaths",
        "paper_author": "Rizzi S.",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "9",
        "cover_date": "2021-04-13",
        "Abstract": "We introduce a method for making short-term mortality forecasts of a few months, illustrating it by estimating how many deaths might have happened if some major shock had not occurred. We apply the method to assess excess mortality from March to June 2020 in Denmark and Sweden as a result of the first wave of the coronavirus pandemic; associated policy interventions; and behavioral, healthcare, social, and economic changes. We chose to compare Denmark and Sweden because reliable data were available and because the two countries are similar but chose different responses to COVID-19: Denmark imposed a rather severe lockdown; Sweden did not. We make forecasts by age and sex to predict expected deaths if COVID-19 had not struck. Subtracting these forecasts from observed deaths gives the excess death count. Excess deaths were lower in Denmark than Sweden during the first wave of the pandemic. The later/earlier ratio we propose for shortcasting is easy to understand, requires less data than more elaborate approaches, and may be useful in many countries in making both predictions about the future and the past to study the impact on mortality of coronavirus and other epidemics. In the application to Denmark and Sweden, prediction intervals are narrower and bias is less than when forecasts are based on averages of the last 5 y, as is often done. More generally, later/earlier ratios may prove useful in short-term forecasting of illnesses and births as well as economic and other activity that varies seasonally or periodically.",
        "DOI": "10.1073/PNAS.2025324118",
        "affiliation_name": "Syddansk Universitet",
        "affiliation_city": "Odense",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Model-free reinforcement learning with ensemble for a soft continuum robot arm",
        "paper_author": "Morimoto R.",
        "publication": "2021 IEEE 4th International Conference on Soft Robotics, RoboSoft 2021",
        "citied_by": "34",
        "cover_date": "2021-04-12",
        "Abstract": "Soft robots have more passive degrees of freedom (DoFs) than rigid-body robots, which makes controller design difficult. Model-free reinforcement learning (RL) is a promising tool to resolve control problems in soft robotics alongside detailed and elaborate modeling. However, the adaptation of RL to soft robots requires consideration of the unique nature of soft bodies. In this work, a continuum robot arm is used as an example of a soft robot, and we propose an Ensembled Light-weight model-Free reinforcement learning Network (ELFNet), which is an RL framework with a computationally light ensemble. We demonstrated that the proposed system could learn control policies for a continuum robot arm to reach target positions using its tip not only in simulations but also in the real world. We used a pneumatically controlled continuum robot arm that operates with nine flexible rubber artificial muscles. Each artificial muscle can be controlled independently by pressure control valves, demonstrating that the policy can be learned using a real robot alone. We found that our method is more suitable for compliant robots than other RL methods because the sample efficiency is better than that of the other methods, and there is a significant difference in the performance when the number of passive DoFs is large. This study is expected to lead to the development of model-free RL in future soft robot control.",
        "DOI": "10.1109/RoboSoft51838.2021.9479340",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Bank Loan Strategy Based on Evaluation and Decision Model",
        "paper_author": "Ge Y.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-04-12",
        "Abstract": "In real life, in the face of small and medium-sized enterprises lacking mortgage assets, banks usually provide loans to enterprises with strong strength and stable supply-demand relationship according to credit policies, transaction notes information of enterprises and influence of upstream and downstream enterprises, and can give preferential interest rate to enterprises with high reputation and small credit risk. In order to better meet the application of the model in real life, the enterprise loan mode is introduced, and the risk assessment of each loan mode is carried out according to the actual situation. Finally, the fuzzy neural network model is introduced. The enterprise loan mode and three secondary indicators are taken as the input of the fuzzy neural network. Finally, a three-level index: loan risk assessment is obtained. Using Python program to preprocess the data, the original indicators in the given materials are extracted as the first level indicators, and then on the basis of the first level indicators, the main factor analysis and other methods are used to analyze the characteristics and scoring of the second level indicators. Then, the entropy weight is established to obtain the higher-level index loan tendency, and the loan propensity and enterprise reputation are used as parameters to establish the decision-making Model, step by step to get the bank's quota allocation, interest rate, and finally get the bank allocation plan. In order to supplement the unknown data, this paper uses the known information to forecast the whole process of the unknown quantity, and then uses the data to forecast. First of all, it forecasts whether the default occurs, adds the predicted value to the whole eigenvalue, then forecasts the reputation rating, and finally completes the reasonable supplement of location data. TOPSIS model, SPSS software simulation machine learning, Fisher discriminant analysis",
        "DOI": "10.1088/1742-6596/1865/4/042018",
        "affiliation_name": "School of Communications and Information Engineering",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Bayesian network in B2B policy application",
        "paper_author": "Tang K.",
        "publication": "2021 IEEE 6th International Conference on Intelligent Computing and Signal Processing, ICSP 2021",
        "citied_by": "0",
        "cover_date": "2021-04-09",
        "Abstract": "Under the influence of COVID-19, more and more e-commerce companies are in urgent need to understand the causality and impact probability of B2B strategies, and formulate effective cooperative operation strategies. Although recently, few articles believe that B2B strategies are beneficial to improving enterprise profitability. In this paper, data from 362 takeout APP users were surveyed by questionnaire. Through machine learning, Bayesian Networks (BNs) algorithm was adopted to analyze the B2B strategy adopted by the takeout industry for the impact of COVID-19. Firstly, BNs analysis structure is designed according to prior knowledge and market information. Then the maximum likelihood estimation is used to calculate the conditional dependence probability. Finally, the effectiveness of BNs model is verified by training set and test set. The results show that the causal relationship between B2B strategies is highly concentrated in rider's daily health clock, and this strategy is also dependent on green passcode, highlighting the reliability of the windowing strategy. The contribution of this paper is to introduce BNs to B2B strategies and dependent probabilities, specifically providing a feasible way to find the causal relationship between strategies.",
        "DOI": "10.1109/ICSP51882.2021.9408834",
        "affiliation_name": "Fujian University of Technology",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The Urgency of Policy Formulation: Dynamics of Covid-19 Handling and Big Data",
        "paper_author": "Suhermanto D.F.",
        "publication": "IOP Conference Series: Earth and Environmental Science",
        "citied_by": "1",
        "cover_date": "2021-04-09",
        "Abstract": "This paper attempts to discuss the role of big data to formulate policies in responding to social and economic threats due to Covid-19 pandemic in Indonesia. The use of big data as a primary source is based on the dynamic of spreading cases in other countries that were suddenly flared. Those primary resources are online or open data such as population, social economic condition and infection case. In related indicators, population is a big portrait of the countries, thus we observed the number of new infection per day, month and how it impacts the economy. The research problem is how big data is used to formulate policy during the Covid-19 time. We use Decision Theory under Uncertainty to explain three indicators that influence decision-making under Covid-19. This research applied Machine Learning R and SIR Model to obtain the latest data. The argument is that big data can be used as a base resource for the policy formulation and decision-making. In this case, base resource refers to first input in the policy formulation process as well as input and output information in the decision-making process.",
        "DOI": "10.1088/1755-1315/717/1/012005",
        "affiliation_name": "Universitas Muhammadiyah Malang",
        "affiliation_city": "Malang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "A Data Mining based Target Regression-Oriented Approach to Modelling of Health Insurance Claims",
        "paper_author": "Dutta K.",
        "publication": "Proceedings - 5th International Conference on Computing Methodologies and Communication, ICCMC 2021",
        "citied_by": "16",
        "cover_date": "2021-04-08",
        "Abstract": "Machine learning or Data mining algorithms can be used for predicting future management and thus treated as powerful tools. In recent days, data mining has become very important for gaining vital information in healthcare industries. The Health care insurance cost plays a vital role in developing medical facilities. To provide better medical facilities, it is very essential to forecast the cost of medical insurance which is one of the possibilities to enhance medical facilities. The paper deals with predicting the cost of the health insurance which has to be paid by the patient. Here various data mining regression algorithms such as decision tree, random forest, polynomial regression and linear regression are implemented to achieve the best prediction analysis. A comparison has been done between the actual and predicted expenses of the prediction premium and eventually, a graph has been plotted on this basis which will enlighten us to choose the best-suited regression algorithm for the insurance policy prediction. After the execution of these regression algorithms for prediction, correctness has been measured by the Coefficient of determination (r2_score), Root Mean Squared Error (RMSE) and Mean Squared Error (MSE) of each algorithm to check for the best-suited algorithm. Random Forest Regression was the best algorithm with an r2_score of 0.862533 which can be used in its best possible way for the correct prediction of the health insurance cost.",
        "DOI": "10.1109/ICCMC51019.2021.9418038",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Covid-19 Dynamic Monitoring and Real-Time Spatio-Temporal Forecasting",
        "paper_author": "da Silva C.C.",
        "publication": "Frontiers in Public Health",
        "citied_by": "25",
        "cover_date": "2021-04-08",
        "Abstract": "Background: Periodically, humanity is often faced with new and emerging viruses that can be a significant global threat. It has already been over a century post—the Spanish Flu pandemic, and we are witnessing a new type of coronavirus, the SARS-CoV-2, which is responsible for Covid-19. It emerged from the city of Wuhan (China) in December 2019, and within a few months, the virus propagated itself globally now resulting more than 50 million cases with over 1 million deaths. The high infection rates coupled with dynamic population movement demands for tools, especially within a Brazilian context, that will support health managers to develop policies for controlling and combating the new virus. Methods: In this work, we propose a tool for real-time spatio-temporal analysis using a machine learning approach. The COVID-SGIS system brings together routinely collected health data on Covid-19 distributed across public health systems in Brazil, as well as taking to under consideration the geographic and time-dependent features of Covid-19 so as to make spatio-temporal predictions. The data are sub-divided by federative unit and municipality. In our case study, we made spatio-temporal predictions of the distribution of cases and deaths in Brazil and in each federative unit. Four regression methods were investigated: linear regression, support vector machines (polynomial kernels and RBF), multilayer perceptrons, and random forests. We use the percentage RMSE and the correlation coefficient as quality metrics. Results: For qualitative evaluation, we made spatio-temporal predictions for the period from 25 to 27 May 2020. Considering qualitatively and quantitatively the case of the State of Pernambuco and Brazil as a whole, linear regression presented the best prediction results (thematic maps with good data distribution, correlation coefficient >0.99 and RMSE (%) <4% for Pernambuco and around 5% for Brazil) with low training time: [0.00; 0.04 ms], CI 95%. Conclusion: Spatio-temporal analysis provided a broader assessment of those in the regions where the accumulated confirmed cases of Covid-19 were concentrated. It was possible to differentiate in the thematic maps the regions with the highest concentration of cases from the regions with low concentration and regions in the transition range. This approach is fundamental to support health managers and epidemiologists to elaborate policies and plans to control the Covid-19 pandemics.",
        "DOI": "10.3389/fpubh.2021.641253",
        "affiliation_name": "Universidade Federal de Pernambuco",
        "affiliation_city": "Recife",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Learning to safely approve updates to machine learning algorithms",
        "paper_author": "Feng J.",
        "publication": "ACM CHIL 2021 - Proceedings of the 2021 ACM Conference on Health, Inference, and Learning",
        "citied_by": "4",
        "cover_date": "2021-04-08",
        "Abstract": "Machine learning algorithms in healthcare have the potential to continually learn from real-world data generated during healthcare delivery and adapt to dataset shifts. As such, regulatory bodies like the US FDA have begun discussions on how to autonomously approve modifications to algorithms. Current proposals evaluate algorithmic modifications via hypothesis testing and control a definition of online approval error that only applies if the data is stationary over time, which is unlikely in practice. To this end, we investigate designing approval policies for modifications to ML algorithms in the presence of distributional shifts. Our key observation is that the approval policy most efficient at identifying and approving beneficial modifications varies across problem settings. So, rather than selecting a fixed approval policy a priori, we propose learning the best approval policy by searching over a family of approval strategies. We define a family of strategies that range in their level of optimism when approving modifications. To protect against settings where no version of the ML algorithm performs well, this family includes a pessimistic strategy that rescinds approval. We use the exponentially weighted averaging forecaster (EWAF) to learn the most appropriate strategy and derive tighter regret bounds assuming the distributional shifts are bounded. In simulation studies and empirical analyses, we find that wrapping approval strategies within EWAF is a simple yet effective approach to protect against distributional shifts without significantly slowing down approval of beneficial modifications.",
        "DOI": "10.1145/3450439.3451864",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "COVID-19-Induced Lockdowns Indicate the Short-Term Control Effect of Air Pollutant Emission in 174 Cities in China",
        "paper_author": "Lu D.",
        "publication": "Environmental Science and Technology",
        "citied_by": "32",
        "cover_date": "2021-04-06",
        "Abstract": "The contradiction between the regional imbalance and an one-size-fits-all policy is one of the biggest challenges in current air pollution control in China. With the recent implementation of first-level public health emergency response (FLPHER) in response to the COVID-19 pandemic in China (a total of 77 041 confirmed cases by February 22, 2020), human activities were extremely decreased nationwide and almost all economic activities were suspended. Here, we show that this scenario represents an unprecedented \"base period\"to probe the short-term emission control effect of air pollution at a city level. We quantify the FLPHER-induced changes of NO2, SO2, PM2.5, and PM10 levels in 174 cities in China. A machine learning prediction model for air pollution is established by coupling a generalized additive model, random effects meta-analysis, and weather research and forecasting model with chemistry analysis. The short-term control effect under the current energy structure in each city is estimated by comparing the predicted and observed results during the FLPHER period. We found that the short-term emission control effect ranges within 53.0%-98.3% for all cities, and southern cities show a significantly stronger effect than northern cities (P < 0.01). Compared with megacities, small-medium cities show a similar control effect on NO2 and SO2 but a larger effect on PM2.5 and PM10.",
        "DOI": "10.1021/acs.est.0c07170",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Towards Deep Learning: A Review on Adversarial Attacks",
        "paper_author": "Irfan M.M.",
        "publication": "2021 International Conference on Artificial Intelligence, ICAI 2021",
        "citied_by": "8",
        "cover_date": "2021-04-05",
        "Abstract": "Attacker determines their targets strategically and deliberately depend on vulnerabilities they have ascertained. Organization and individuals mostly try to protect themselves from one occurrence or type on an attack. Still, they have to acknowledge that the attacker may easily move focus to advanced uncovered vulnerabilities. Even if someone successfully tackles several attacks, risks remain, and the need to face threats will happen for the predictable future. Machine learning algorithms have earned much popularity in artificial intelligence (A.I) in the modern era. Large organizations like Google, Facebook, and Microsoft use large volumes of user data to train machine learning models. Then they use it for social ads. Like these days, Whatsapp will make a new privacy policy to share their data on Facebook. That data may be used for companies advertisements in future. So, in this way, the privacy of an individual might be breech out. Due to the high probability of attacks and the leakage of sensitive data in deep learning on distributive computation, adversarial examples demonstrated the vulnerability of machine learning techniques in terms of robustness. Besides, this allowed adversaries to make use of the vulnerability to target machine learning systems. Although adversarial attacks on real-world applications did not occur until recently, it is difficult to inject an artificial adversary to the model that is being hosted without infringement of the reliability. Recently few attacks occur in terms of facial recognition, road signs classification by finally, the difference between theoretical methodologies for the generation of adversarial examples and practical schemes of attacks on real-world applications. To direct future studies in the real defence of adversarial examples in real-world applications, For realistic attacks, we integrate the threat model with adversarial examples and give an overview with future direction.",
        "DOI": "10.1109/ICAI52203.2021.9445247",
        "affiliation_name": "University of Jinan",
        "affiliation_city": "Jinan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Novel Preprocessing Technique for Toxic Comment Classification",
        "paper_author": "Husnain M.",
        "publication": "2021 International Conference on Artificial Intelligence, ICAI 2021",
        "citied_by": "12",
        "cover_date": "2021-04-05",
        "Abstract": "The threat of online abuse and harassment is increasing day by day in the cyber community. To tackle this problem, many platforms have devised policies. But these policies require prior identification of the content that is inappropriate and offensive. Furthermore, the data contains various aspects of negativity, for example, a particular piece of comment can express, disgust, disbelief, and threat at the same time. It points that even the negativity/toxicity exhibited in a comment can have various facets. Hence, the challenge is to identify what exactly is exhibited in comments so that respective policies can be formulated and applied to penalize the offender. This study makes use of two approaches to identify these underlying toxicities in the comments. The first approach is to train separate classifiers against each facet of the toxicity in comments. The second approach deals with the problem as a multi-label classification problem. Different machine learning approaches including logistic regression, Naïve Bayes, and decision tree classification are employed to carry out this study. The dataset is taken from Kaggle and 10-fold cross-validation is used to report the robustness of the model. The study uses a novel preprocessing scheme that transforms the multi-label classification problem into the multi-class classification problem. The preprocessing strategy has shown a significant improvement in the accuracies when employed for simple classification models encouraging its use for other sophisticated models as well. Experimental results show that in both the binary classification and the multi-classification, logistic regression turns out to be a better performer. This indicates the potential use of the preprocessing for the neural classification models.",
        "DOI": "10.1109/ICAI52203.2021.9445252",
        "affiliation_name": "National University of Computer and Emerging Sciences Islamabad",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Vehicle Insurance Policy Document Summarizer, AI Insurance Agent and On-The-Spot Claimer",
        "paper_author": "Samarasinghe H.T.D.",
        "publication": "2021 6th International Conference for Convergence in Technology, I2CT 2021",
        "citied_by": "2",
        "cover_date": "2021-04-02",
        "Abstract": "This paper proposes an automated vehicle insurance policy summarizing application. 'Explain to Me' is one such software/tool which enable you to summarize the content of documents regarding vehicle insurance policies by using the NLP, machine learning and deep learning applications. The program targets mainly insurance users and suppliers of insurance services. Due to the increase of vehicle accidents, the vehicle insurance industry has gained more popularity currently. Therefore, different insurance companies have introduced a variety of insurance policies to customers. Vehicle insurance policy documents consist lot of insurance terms that should be read with more attention. As the main objective, this system filters unnecessary data in the particular document, and finalize a summary as the output. As another major component, the application 'On the spot claimer' which is never before in Sri Lankan vehicle insurance industry, is another major part of this project that works as suggesting the most relevant insurance claiming that can be claimed by the user after detection of the type of damage through mobile phone camera. Another part of this research project, the function known as the Recommender, which works along with the summarization tool, is a recommendation system with a view of recommending more favorable rules for the assertion of alternatives that exist in the corresponding, equivalent documents of other companies. Finally, in order to interact with custody concerns about how to insure an automobile, CNN, which are based on the extraction of images, are used for the implementation of the ETM system in NLP.",
        "DOI": "10.1109/I2CT51068.2021.9418137",
        "affiliation_name": "Sri Lanka Institute of Information Technology",
        "affiliation_city": "Colombo",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Perceptive VM Allocation in Cloud Data Centers for Effective Resource Management",
        "paper_author": "Savitha S.",
        "publication": "2021 6th International Conference for Convergence in Technology, I2CT 2021",
        "citied_by": "4",
        "cover_date": "2021-04-02",
        "Abstract": "Virtual Machine allocation in cloud computing centers has become an important research area. Efficient VM allocation can reduce power consumption and average response time which can benefit both the end users as well as the cloud vendors. This work presents a perceptive priority aware VM allocation policy named P-PAVA algorithm, which takes into account the priority of an application along with its compute, memory and bandwidth requirement. The algorithm performs allocation of the applications based on the priority it gets using a machine learning based prediction model. Furthermore, to reduce the overhead of the allocation algorithm, parallelization is employed before assigning various workloads. To achieve this, the algorithm employs the First fit technique as a baseline for the requests allocation with a criteria as low priority. When compared to the state of the art algorithm for VM allocation for priority aware applications, P-PAVA performs better on several criteria such as average response time, execution time and power consumption.",
        "DOI": "10.1109/I2CT51068.2021.9417960",
        "affiliation_name": "Christ University",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Barrister-Processing and Summarization of Terms Conditions / Privacy Policies",
        "paper_author": "Perera T.",
        "publication": "2021 6th International Conference for Convergence in Technology, I2CT 2021",
        "citied_by": "3",
        "cover_date": "2021-04-02",
        "Abstract": "'You're confused into thinking these are there to inform users, as opposed to protect companies,' said Albert Gidari, the consulting director of privacy at the Stanford Centre for Internet and Society. Terms of service and privacy agreements are verbose and full of legal jargon, and the justifications for the processing and sale of your data are opaquely defined by corporations. The data market has become the powerhouse of the internet, and these terms and privacy rules that we accept without understanding or sometimes even reading help fuel the age of surveillance capitalism. It is common to access a wealth of services and applications, each with a long terms and conditions declaration and a one-click 'allow' option. Often users accept these stipulations usually without ever reading the contractual obligations, let alone understanding their particulars. This work proposes a framework which is an automated text summarization application that can convert long, legalese, difficult-to-comprehend, terms and conditions / privacy policies to summarized, simplified simple English speech; using machine learning and natural language processing, which will dramatically decrease the reading time of these legalese documents and shed special attention on class action waivers. It is probably better to behave with one rule in mind until we reshape privacy policy to suit our needs, or we find an acceptable substitute. To be straightforward and concise: there is always someone watching.",
        "DOI": "10.1109/I2CT51068.2021.9418090",
        "affiliation_name": "Informatics Institute of Technology",
        "affiliation_city": "Colombo",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Ambient pm<inf>2.5</inf> estimates and variations during covid-19 pandemic in the yangtze river delta using machine learning and big data",
        "paper_author": "Lu D.",
        "publication": "Remote Sensing",
        "citied_by": "13",
        "cover_date": "2021-04-02",
        "Abstract": "The lockdown of cities in the Yangtze River Delta (YRD) during COVID-19 has provided many natural and typical test sites for estimating the potential of air pollution control and reduction. To evaluate the reduction of PM2.5 concentration in the YRD region by the epidemic lockdown policy, this study employs big data, including PM2.5 observations and 29 independent variables regarding Aerosol Optical Depth (AOD), climate, terrain, population, road density, and Gaode map Point of interesting (POI) data, to build regression models and retrieve spatially continuous distributions of PM2.5 during COVID-19. Simulation accuracy of multiple machine learning regression models, i.e., random forest (RF), support vector regression (SVR), and artificial neural network (ANN) were compared. The results showed that the RF model outperformed the SVR and ANN models in the inversion of PM2.5 in the YRD region, with the model-fitting and cross-validation coefficients of determination R2 reached 0.917 and 0.691, mean absolute error (MAE) values were 1.026 µg m−3 and 2.353 µg m−3, and root mean square error (RMSE) values were 1.413 µg m−3, and 3.144 µg m−3, re-spectively. PM2.5 concentrations during COVID-19 in 2020 have decreased by 3.61 µg m−3 compared to that during the same period of 2019 in the YRD region. The results of this study provide a cost-effective method of air pollution exposure assessment and help provide insight into the atmospheric changes under strong government controlling strategies.",
        "DOI": "10.3390/rs13081423",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Iowa City",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mapping a cloud-free rice growth stages using the integration of proba-v and sentinel-1 and its temporal correlation with sub-district statistics",
        "paper_author": "Ramadhani F.",
        "publication": "Remote Sensing",
        "citied_by": "10",
        "cover_date": "2021-04-02",
        "Abstract": "Monitoring rice production is essential for securing food security against climate change threats, such as drought and flood events becoming more intense and frequent. The current practice to survey an area of rice production manually and in near real-time is expensive and involves a high workload for local statisticians. Remote sensing technology with satellite-based sensors has grown in popularity in recent decades as an alternative approach, reducing the cost and time required for spatial analysis over a wide area. However, cloud-free pixels of optical imagery are required to pro-duce accurate outputs for agriculture applications. Thus, in this study, we propose an integration of optical (PROBA-V) and radar (Sentinel-1) imagery for temporal mapping of rice growth stages, including bare land, vegetative, reproductive, and ripening stages. We have built classification models for both sensors and combined them into 12-day periodical rice growth-stage maps from January 2017 to September 2018 at the sub-district level over Java Island, the top rice production area in Indonesia. The accuracy measurement was based on the test dataset and the predicted cross-correlated with monthly local statistics. The overall accuracy of the rice growth-stage model of PROBA-V was 83.87%, and the Sentinel-1 model was 71.74% with the Support Vector Machine clas-sifier. The temporal maps were comparable with local statistics, with an average correlation between the vegetative area (remote sensing) and harvested area (local statistics) is 0.50, and lag time 89.5 days (n = 91). This result was similar to local statistics data, which correlate planting and the harvested area at 0.61, and the lag time as 90.4 days, respectively. Moreover, the cross-correlation between the predicted rice growth stage was also consistent with rice development in the area (r > 0.52, p < 0.01). This novel method is straightforward, easy to replicate and apply to other areas, and can be scaled up to the national and regional level to be used by stakeholders to support improved agricultural policies for sustainable rice production.",
        "DOI": "10.3390/rs13081498",
        "affiliation_name": "Badan Penelitian dan Pengembangan Pertanian",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Article mapping opuntia stricta in the arid and semi-arid environment of kenya using sentinel-2 imagery and ensemble machine learning classifiers",
        "paper_author": "Muthoka J.M.",
        "publication": "Remote Sensing",
        "citied_by": "12",
        "cover_date": "2021-04-02",
        "Abstract": "Globally, grassland biomes form one of the largest terrestrial covers and present critical social–ecological benefits. In Kenya, Arid and Semi-arid Lands (ASAL) occupy 80% of the landscape and are critical for the livelihoods of millions of pastoralists. However, they have been invaded by Invasive Plant Species (IPS) thereby compromising their ecosystem functionality. Opuntia stricta, a well-known IPS, has invaded the ASAL in Kenya and poses a threat to pastoralism, leading to livestock mortality and land degradation. Thus, identification and detailed estimation of its cover is essential for drawing an effective management strategy. The study aimed at utilizing the Sentinel-2 multispectral sensor to detect Opuntia stricta in a heterogeneous ASAL in Laikipia County, using ensemble machine learning classifiers. To illustrate the potential of Sentinel-2, the detection of Opuntia stricta was based on only the spectral bands as well as in combination with vegetation and topographic indices using Extreme Gradient Boost (XGBoost) and Random Forest (RF) classifiers to detect the abundance. Study results showed that the overall accuracies of Sentinel 2 spectral bands were 80% and 84.4%, while that of combined spectral bands, vegetation, and topographic indices was 89.2% and 92.4% for XGBoost and RF classifiers, respectively. The inclusion of topographic indices that enhance characterization of biological processes, and vegetation indices that minimize the influence of soil and the effects of atmosphere, contributed by improving the accuracy of the classification. Qualitatively, Opuntia stricta spatially was found along river banks, flood plains, and near settlements but limited in forested areas. Our results demonstrated the potential of Sentinel-2 multispectral sensors to effectively detect and map Opuntia stricta in a complex heterogeneous ASAL, which can support conservation and rangeland management policies that aim to map and list threatened areas, and conserve the biodiversity and productivity of rangeland ecosystems.",
        "DOI": "10.3390/rs13081494",
        "affiliation_name": "University of Sussex",
        "affiliation_city": "Brighton",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Multi-view data integration methods for radiotherapy structure name standardization",
        "paper_author": "Syed K.",
        "publication": "Cancers",
        "citied_by": "6",
        "cover_date": "2021-04-02",
        "Abstract": "Standardization of radiotherapy structure names is essential for developing data-driven personalized radiotherapy treatment plans. Different types of data are associated with radiotherapy structures, such as the physician-given text labels, geometric (image) data, and Dose-Volume Histograms (DVH). Prior work on structure name standardization used just one type of data. We present novel approaches to integrate complementary types (views) of structure data to build better-performing machine learning models. We present two methods, namely (a) intermediate integration and (b) late integration, to combine physician-given textual structure name features and geometric information of structures. The dataset consisted of 709 prostate cancer and 752 lung cancer patients across 40 radiotherapy centers administered by the U.S. Veterans Health Administration (VA) and the Department of Radiation Oncology, Virginia Commonwealth University (VCU). We used randomly selected data from 30 centers for training and ten centers for testing. We also used the VCU data for testing. We observed that the intermediate integration approach outperformed the models with a single view of the dataset, while late integration showed comparable performance with single-view results. Thus, we demonstrate that combining different views (types of data) helps build better models for structure name standardization to enable big data analytics in radiation oncology.",
        "DOI": "10.3390/cancers13081796",
        "affiliation_name": "VCU College of Engineering",
        "affiliation_city": "Richmond",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Does physical activity predict obesity—a machine learning and statistical method-based analysis",
        "paper_author": "Cheng X.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "32",
        "cover_date": "2021-04-02",
        "Abstract": "Background: Obesity prevalence has become one of the most prominent issues in global public health. Physical activity has been recognized as a key player in the obesity epidemic. Objectives: The objectives of this study are to (1) examine the relationship between physical activity and weight status and (2) assess the performance and predictive power of a set of popular machine learning and traditional statistical methods. Methods: National Health and Nutrition Examination Survey (NHANES, 2003 to 2006) data were used. A total of 7162 participants met our inclusion criteria (3682 males and 3480 females), with average age ranging from 48.6 (normal weight) to 52.1 years old (overweight). Eleven classifying algorithms—including logistic regression, naïve Bayes, Radial Basis Function (RBF), local k-nearest neighbors (k-NN), classification via regression (CVR), random subspace, decision table, multiobjective evolutionary fuzzy classifier, random tree, J48, and multilayer perceptron—were implemented and evaluated, and they were compared with traditional logistic regression model estimates. Results: With physical activity and basic demographic status, of all methods analyzed, the random subspace classifier algorithm achieved the highest overall accuracy and area under the receiver operating characteristic (ROC) curve (AUC). The duration of vigorous-intensity activity in one week and the duration of moderate-intensity activity in one week were important attributes. In general, most algorithms showed similar performance. Logistic regression was middle-ranking in terms of overall accuracy, sensitivity, specificity, and AUC among all methods. Conclusions: Physical activity was an important factor in predicting weight status, with gender, age, and race/ethnicity being less but still essential factors associated with weight outcomes. Tailored intervention policies and programs should target the differences rooted in these demographic factors to curb the increase in the prevalence of obesity and reduce disparities among sub-demographic populations.",
        "DOI": "10.3390/ijerph18083966",
        "affiliation_name": "School of Basic Medical Sciences",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A topical review on machine learning, software defined networking, internet of things applications: Research limitations and challenges",
        "paper_author": "Imran ",
        "publication": "Electronics (Switzerland)",
        "citied_by": "62",
        "cover_date": "2021-04-02",
        "Abstract": "In recent years, rapid development has been made to the Internet of Things communication technologies, infrastructure, and physical resources management. These developments and research trends address challenges such as heterogeneous communication, quality of service requirements, unpredictable network conditions, and a massive influx of data. One major contribution to the research world is in the form of software-defined networking applications, which aim to deploy rule-based management to control and add intelligence to the network using high-level policies to have integral control of the network without knowing issues related to low-level configurations. Machine learning techniques coupled with software-defined networking can make the networking decision more intelligent and robust. The Internet of Things application has recently adopted virtualization of resources and network control with software-defined networking policies to make the traffic more controlled and maintainable. However, the requirements of software-defined networking and the Internet of Things must be aligned to make the adaptations possible. This paper aims to discuss the possible ways to make software-defined networking enabled Internet of Things application and discusses the challenges solved using the Internet of Things leveraging the software-defined network. We provide a topical survey of the application and impact of software-defined networking on the Internet of things networks. We also study the impact of machine learning techniques applied to software-defined networking and its application perspective. The study is carried out from the different perspectives of software-based Internet of Things networks, including wide-area networks, edge networks, and access networks. Machine learning techniques are presented from the perspective of network resources management, security, classification of traffic, quality of experience, and quality of service prediction. Finally, we discuss challenges and issues in adopting machine learning and software-defined networking for the Internet of Things applications.",
        "DOI": "10.3390/electronics10080880",
        "affiliation_name": "University of Central Asia",
        "affiliation_city": "Naryn",
        "affiliation_country": "Kyrgyzstan"
    },
    {
        "paper_title": "Coverage path planning using reinforcement learning-based tsp for htetran — A polyabolo-inspired self-reconfigurable tiling robot",
        "paper_author": "Le A.V.",
        "publication": "Sensors",
        "citied_by": "23",
        "cover_date": "2021-04-02",
        "Abstract": "One of the critical challenges in deploying the cleaning robots is the completion of covering the entire area. Current tiling robots for area coverage have fixed forms and are limited to cleaning only certain areas. The reconfigurable system is the creative answer to such an optimal coverage problem. The tiling robot’s goal enables the complete coverage of the entire area by reconfiguring to different shapes according to the area’s needs. In the particular sequencing of navigation, it is essential to have a structure that allows the robot to extend the coverage range while saving energy usage during navigation. This implies that the robot is able to cover larger areas entirely with the least required actions. This paper presents a complete path planning (CPP) for hTetran, a polyabolo tiled robot, based on a TSP-based reinforcement learning optimization. This structure simultaneously produces robot shapes and sequential trajectories whilst maximizing the reward of the trained reinforcement learning (RL) model within the predefined polyabolo-based tileset. To this end, a reinforcement learning-based travel sales problem (TSP) with proximal policy optimization (PPO) algorithm was trained using the complementary learning computation of the TSP sequencing. The reconstructive results of the proposed RL-TSP-based CPP for hTetran were compared in terms of energy and time spent with the conventional tiled hypothetical models that incorporate TSP solved through an evolutionary based ant colony optimization (ACO) approach. The CPP demonstrates an ability to generate an ideal Pareto optima trajectory that enhances the robot’s navigation inside the real environment with the least energy and time spent in the company of conventional techniques.",
        "DOI": "10.3390/s21082577",
        "affiliation_name": "Singapore University of Technology and Design",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Multi-Step-Ahead Crude Oil Price Forecasting Based on Hybrid Model",
        "paper_author": "Tang Z.",
        "publication": "China Journal of Econometrics",
        "citied_by": "2",
        "cover_date": "2021-04-01",
        "Abstract": "Accurately predicting the crude oil prices is vital for governors to make policies and essential for market participants to make investment decisions. We propose a hybrid multi-step-ahead forecasting model that integrates the secondary decomposition algorithm which combines variational modal decomposition (VMD) and integrated empirical modal decomposition (EEMD), differential evolution (DE) and extreme learning machine (ELM), namely, VMD-RES.-EEMD-DE-ELM, for more accurate crude oil price forecasting in this paper. To illustrate the superiority of the proposed model, the sample data of Brent and West Texas Intermediate (WTI) are used to validate the performance of the proposed model. The empirical results confirm that the proposed model achieves better performance compared to several other benchmark models in terms of forecasting accuracy and stability.",
        "DOI": "10.12012/CJoE2020-0010",
        "affiliation_name": "Fuzhou University",
        "affiliation_city": "Fuzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep Reinforcement Learning with Python: With PyTorch, TensorFlow and OpenAI Gym",
        "paper_author": "Sanghi N.",
        "publication": "Deep Reinforcement Learning with Python: With PyTorch, TensorFlow and OpenAI Gym",
        "citied_by": "6",
        "cover_date": "2021-04-01",
        "Abstract": "Deep reinforcement learning is a fast-growing discipline that is making a significant impact in fields of autonomous vehicles, robotics, healthcare, finance, and many more. This book covers deep reinforcement learning using deep-q learning and policy gradient models with coding exercise. You'll begin by reviewing the Markov decision processes, Bellman equations, and dynamic programming that form the core concepts and foundation of deep reinforcement learning. Next, you'll study model-free learning followed by function approximation using neural networks and deep learning. This is followed by various deep reinforcement learning algorithms such as deep q-networks, various flavors of actor-critic methods, and other policy-based methods. You'll also look at exploration vs exploitation dilemma, a key consideration in reinforcement learning algorithms, along with Monte Carlo tree search (MCTS), which played a key role in the success of AlphaGo. The final chapters conclude with deep reinforcement learning implementation using popular deep learning frameworks such as TensorFlow and PyTorch. In the end, you'll understand deep reinforcement learning along with deep q networks and policy gradient models implementation with TensorFlow, PyTorch, and Open AI Gym. What You'll Learn • Examine deep reinforcement learning • Implement deep learning algorithms using OpenAI's Gym environment • Code your own game playing agents for Atari using actor-critic algorithms • Apply best practices for model building and algorithm training Who This Book Is For Machine learning developers and architects who want to stay ahead of the curve in the field of AI and deep learning.",
        "DOI": "10.1007/978-1-4842-6809-4",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Multi-Scale Deep Network for Automatic Sleep Staging",
        "paper_author": "Haoran B.",
        "publication": "Chinese Journal of Biomedical Engineering",
        "citied_by": "0",
        "cover_date": "2021-04-01",
        "Abstract": "Sleep quality assessment and diagnosis highly depends on the doctors' effort and experience. It is quite labor intensive and time consuming for the doctor to inspect the long-term sleep monitoring records. The current automatic sleep staging mainly uses traditional machine learning and it highly relies on the features designed by experts. However, these features are usually incapable to capture the deep level features hidden in the measured data, and the behave not well for some staging such as N1 . This paper proposed an automatic sleep staging algorithm based on multi-scale deep network. It used the deep network to automatically extract sleep signal features and used multi-scale analysis and discrimination criteria relating to the difficulty measure in the classification of different sleep stages. The classification results of stage W, N2, N3 and REM were selected and output in advance based on shallow layer features, and the fallible transition stage N1 entered a deeper network for further analysis. This policy improved the overall classification efficiency and especially the classification accuracy of the N1 stage. When extracting 197 sets of sample data for training and testing in the Sleep - EDFx data set and using only single-channel EEG signals, the average classification accuracy achieved 83%, and Kappa value was 0.749, which indicated that the constructed models were highly consistent. F1 - score at stage N1 achieved 0.51. Compared with traditional machine learning algorithms and a variety of deep networks, the overall classification accuracy and accuracy of the N1 stage were improved. And at the same time, there was no apparent calculation increase. It is suitable for automatic real-time analysis.",
        "DOI": "10.3969/j.issn.0258-8021.2021.02.06",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Recent Developments in Estimating Treatment Effects for Panel Data",
        "paper_author": "Cai Z.",
        "publication": "China Journal of Econometrics",
        "citied_by": "3",
        "cover_date": "2021-04-01",
        "Abstract": "This survey paper highlights some recent developments in estimating treatment effects for panel data. First, this paper begins with a brief introduction of the basic model setup in modern econometric analysis of program or economic policy evaluation for panel data. Second, the primary attention goes to the focus on estimating both the average and quantile treatment effects for panel data. Finally, it concludes the paper by addressing theoretically, methodologically and empirically some possible future research directions for young scholars in econometrics and statistics, particularly, some interesting and challenging research topics related to a combination of machine learning and casual inference for panel data.",
        "DOI": "10.12012/CJoE2021-0016",
        "affiliation_name": "University of Kansas",
        "affiliation_city": "Lawrence",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mapping changes in artisanal and small-scale mining (ASM) landscape using machine and deep learning algorithms. - a proxy evaluation of the 2017 ban on ASM in Ghana",
        "paper_author": "Nyamekye C.",
        "publication": "Environmental Challenges",
        "citied_by": "26",
        "cover_date": "2021-04-01",
        "Abstract": "Artisanal and Small-Scale Mining (ASM) landscapes form integral part of the Land use land cover (LULC) in the developing worlds. However, the spatial, spectral, and temporal footprints of ASM present some challenges for using most of the freely available optical satellite sensors for change analysis. The challenge is even profound in tropical West African countries like Ghana where there is prolonged cloud cover. Whiles very few studies have used Sentinel-2 data to map change analysis in ASM landscape, none examined the contribution of individual S2 bands to the ASM classifications. Also, despite the capabilities of Machine Learning (ML) and Deep Learning (DL) models for LULC classifications, few studies have compared the performances of different classifiers in mapping ASM landscape. This study utilized Sentinel-2 data, four ML and DL models (Artificial Neural Network –ANN, Random Forest – RF, Support Vector Machines –SVM, a pixel-based Convolutional Neural Network-CNN) and image segmentation to examine the performance of S2 bands and ML and DL algorithms for change analysis in ASM landscape, with the Birim Basin in Ghana as a study area. The result of the change analysis was used to assess changes in LULC during the recent ban on the expansion of ASM in the country. It was found out that ANN is a better classifier of ASM achieving the highest overall accuracy (OA) of 99.80% on the segmented Sentinel-2 bands. The study also found out that the Band 5 Vegetation Red Edge (VRE) 1 contributed most to classifying ASM, with the segmented VRE 1 being superlative over the other predictors. In terms of expansion, ASM increased by 59.17 km2 within the period of the study (January 2017 to December 2018), suggesting that ASM still took place under the watch of the ban. The classification results showed that most of the peripheral of forest and farmland have been converted to ASM with little disturbance within the interior of the forest reserves. The study revealed that, the ban was yielding very little or no results due to a number of policy deficiencies including low staff strength, lack of logistics and low remuneration. Enforcement of legal instruments against ASM and farming activities within the forest reserves, improvement in the monitoring systems and intensification of public education on the value of forest and the need to protect it are some of the major recommendations that could control encroachment on the forest reserves.",
        "DOI": "10.1016/j.envc.2021.100053",
        "affiliation_name": "Koforidua Technical University",
        "affiliation_city": "Koforidua",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Few-shot Aircraft Detection Based on Deep Reinforcement Learning",
        "paper_author": "Wang N.",
        "publication": "Proceedings - 2021 3rd International Conference on Advances in Computer Technology, Information Science and Communication, CTISC 2021",
        "citied_by": "0",
        "cover_date": "2021-04-01",
        "Abstract": "Data dependence is one of the challenging problems in aircraft object detection tasks in the field of remote sensing. Compared with traditional machine learning methods, deep learning relies heavily on large amounts of training data to understand potential data patterns. Specifically, due to the few number of samples, the generalization performance of the model is limited. To deal with this issue, this paper combines deep learning with perceptive ability and reinforcement learning with decision-making ability to achieve an effective object detection method. Firstly, we adopt an improved LSTM network to generate the strategy of data augmentation; Secondly, the strategy is applied to train and test of the object detection network to get F1-score as reward; Then, the policy gradient in reinforcement learning is employed to update the LSTM network, so that the network can generate profitable augmentation strategies that are more conducive to improving the accuracy of object detection. Finally, these processes are looped until the network reaches convergence. Compared with the existing object detection algorithm based on deep learning, the performance of our deep reinforcement learning (DRL) method is superior to the prevalent algorithms in aircraft detection on the public data sets DIOR and RSOD.",
        "DOI": "10.1109/CTISC52352.2021.00052",
        "affiliation_name": "Beihang University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Travel Time Prediction and Route Performance Analysis in BRTS based on Sparse GPS Data",
        "paper_author": "Kakarla A.",
        "publication": "IEEE Vehicular Technology Conference",
        "citied_by": "0",
        "cover_date": "2021-04-01",
        "Abstract": "A Bus Rapid Transit System (BRTS) with earmarked lanes potentially provides efficient public transportation, and helps in controlling urban traffic congestion. While travel time prediction (TTP) is essential in a BRTS, existing algorithms generally assume GPS logs available at short uniform intervals. However, those are rarely evaluated on BRTS in emerging economies, where logged GPS data could be available at sparse nonuniform intervals. To fill the gap, we study the efficacy of certain well known ML models, namely, Random Forests (RF), Light Gradient Boosting (LGB), and Extreme Gradient Boosting (XGBoost, XGB) in utilizing historical data. Performance of those ensemble learning methods is compared with that of a conventional travel time prediction (CTTP) method, which uses historical averaging. It was found that XGB was superior to other methods at hand, and the prediction error by approximately 60% compared to the CTTP method. Alongside improving the experience of commuters, the proposed XGB-based TTP method also improves the estimation of intersection crossing time (ICT), which potentially leads to efficient traffic policy making.",
        "DOI": "10.1109/VTC2021-Spring51267.2021.9448832",
        "affiliation_name": "Indian Institute of Technology Hyderabad",
        "affiliation_city": "Sangareddy",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Distance-Based Neural Combinatorial Optimization for Context-based Route Planning",
        "paper_author": "Hamzehi S.",
        "publication": "IEEE Vehicular Technology Conference",
        "citied_by": "0",
        "cover_date": "2021-04-01",
        "Abstract": "Platform-based large-scale journey planning of autonomous vehicles and context-sensitive route planning applications require new scalable approaches in order to work within an on-demand mobility service. In this work we present and test a machine learning-based approach for distance-based roundtrip planning in a Traveling Salesman Problem (TSP) setting. We introduce our applied Distance-Based Pointer Network (DBPN) algorithm which solves mini-batches of multiple symmetric and asymmetric 2D Euclidean TSPs. We provide our algorithm and test results for symmetric and asymmetric TSP distances, as present in real road and traffic networks. Subsequently, we compare our results with an industry standard routing solver OR-Tools. Here, we focus on solving comparably small TSP instances which commonly occur on our platform-based service. Our results show that compared to the State-of-the-Art methods such as the Coordinate-Based Pointer Network (CBPN) and OR-Tools, our approach solves asymmetric TSPs which cannot be solved by the CBPN approach. The results furthermore show that our approach achieves near-optimal results by a 5.9% mean absolute percentage error, compared to the OR-Tools solution. By solving 1000 TSPs, we show that our DBPN approach is approximately 27 times faster than the OR-Tools solver.",
        "DOI": "10.1109/VTC2021-Spring51267.2021.9448741",
        "affiliation_name": "BMW of North America, LLC",
        "affiliation_city": "Woodcliff Lake",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Cybersecurity by prediction of time synchronization using bayesian base gradient descent approach",
        "paper_author": "Arunachalam A.",
        "publication": "Journal of Scientific and Industrial Research",
        "citied_by": "0",
        "cover_date": "2021-04-01",
        "Abstract": "Time Commerce tends to struggle, which necessities an improved time framework.Legal escalations for conflicts of time commerce in the digital economy demand a solution that helps to address technology, standards, and policies. To meet the demand, we have to build a system that can understand every domain essential for building an inter-organizational system. \"Date\" and \"Timestamp\" reflect the root of the current term \"Date Trade\" in the cyber world. The threat to these roots has been studied in-depth and proposed solutions specific to UTC NPLI. The electricity grid shifts to the energy network to improve operating efficiency and reliability by developing advanced information and communication technology. However, the Internet also provides a range of entry points dependent on the internet, which produce additional vulnerabilities due to malicious cyber-attacks, thereby threatening Nations' economic health. This paper proposes therefore a new mechanism to protect critical infrastructure against these malicious attacks, based on interval state predictors. This paper uses the prediction-based approach for reducing the impact of such attacks from cyberspace. In prediction, we have used a machine learning approach like Bayesian classifier by Bayesian approach to forecasting time synchronization concerning universal time clock (UTC). In our analysis, we have taken the basic UTC, UTC, and UTC likelihood proposed approach on basis of communication. This work has improved considerably the results to take care of CPS against such cybersecurity threats.",
        "DOI": "NA",
        "affiliation_name": "Annamalai University",
        "affiliation_city": "Chidambaram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Sentinel-2 images and machine learning as tool for monitoring of the common agricultural policy: Calasparra rice as a case study",
        "paper_author": "López-Andreu F.J.",
        "publication": "Agronomy",
        "citied_by": "20",
        "cover_date": "2021-04-01",
        "Abstract": "The European Commission introduces the Control by Monitoring through new technologies to manage Common Agricultural Policy funds through the Regulation 2018/746. The advances in remote sensing have been considered one of these new technologies, mainly since the European Space Agency designed the Copernicus Programme. The Sentinel-1 (radar range) and Sentinel-2 (optical range) satellites have been designed for monitoring agricultural problems based on the characteristics they provide. The data provided by the Sentinel 2 missions, together with the emergence of different scientific disciplines in artificial intelligence —especially machine learning— offer the perfect basis for identifying and classifying any crop and its phenological state. Our research is based on developing and evaluating a pixel-based supervised classification scheme to produce accurate rice crop mapping in a smallholder agricultural zone in Calasparra, Murcia, Spain. Several models are considered to obtain the most suitable model for each element of the time series used; pixel-based classification is performed and finished with a statistical treatment. The highly accurate results obtained, especially across the most significant vegetative development dates, indicate the benefits of using Sentinel-2 data combined with Machine Learning techniques to identify rice crops. It should be noted that it was possible to locate rice crop areas with an overall accuracy of 94% and standard deviation of 1%, which could be increased to 96% (±1%) if we focus on the months of the crop’s highest development state. Thanks to the proposed methodology, the on-site inspections carried out, 5% of the files, have been replaced by remote sensing evaluations of 100% of the analyzed season files. Besides, by adjusting the model input data, it is possible to detect unproductive or abandoned plots.",
        "DOI": "10.3390/agronomy11040621",
        "affiliation_name": "Murcia Institute of Agri-Food Research and Development (IMIDA)",
        "affiliation_city": "Murcia",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Assessing the sentinel-2 capabilities to identify abandoned crops using deep learning",
        "paper_author": "Portalés-Julià E.",
        "publication": "Agronomy",
        "citied_by": "19",
        "cover_date": "2021-04-01",
        "Abstract": "The termination or interruption of agro-forestry practices for a long period gradually results in abandoned land. Abandoned land parcels do not match the requirements to access to the basic payment of the European Common Agricultural Policy (CAP). Therefore, the identification of those parcels is key in order to return fair subsidies to farmers. In this context, the present work proposes a methodology to detect abandoned crops in the Valencian Community (Spain) from remote sensing data. The approach is based on the assessment of multitemporal Sentinel-2 images and derived spectral indices, which are used as predictors for training machine learning and deep learning classifiers. Several classification scenarios, including both abandoned and active parcels, were evaluated. The best results (98.2% overall accuracy) were obtained when a bi-directional Long Short Term Memory (BiLSTM) network was trained with a multitemporal dataset composed of twelve reflectance time series, and a derived bare soil spectral index (BSI). In this scenario we were able to effectively distinguish abandoned crops from active ones. The results revealed Sentinel-2 features are well suited for land use identification including abandoned lands, and open the possibility of implementing this type of remote sensing based methodology into the CAP payments supervision.",
        "DOI": "10.3390/agronomy11040654",
        "affiliation_name": "Universitat de València",
        "affiliation_city": "Valencia",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Assisted-fog-based framework for IoT-based healthcare data preservation",
        "paper_author": "Sarrab M.",
        "publication": "International Journal of Cloud Applications and Computing",
        "citied_by": "34",
        "cover_date": "2021-04-01",
        "Abstract": "Healthcare has witnessed a technological advancement in improving the quality of care and speeding the process of diagnosing patients due to its intervention with the internet of medical things. IoT in healthcare (H-IoT) plays a significant role in facilitating the process of diagnosing and detecting diseases. Different IoT-based medical sensors are used to measure biometrics and send them to the cloud for more analysis. However, the sensed data are massive and vary in their criticality level in which some sensed data are more critical (health-related data) than others. Moreover, computing such critical data in the cloud encounters some delay which is not preferable in real-time monitoring applications. Thus, this work proposes an IoT-fog-based framework to classify the streamed data according to their criticality level and compute the critical data in the fog to detect abnormalities with low latency and high response time. Before designing the proposed work, an analysis was conducted to explore the real data collected by IoT-based medical apps. The exploration of the data involved downloading and manually analyzing up-to-date privacy policies of eight IoT-based medical apps that provide details about data collection practices. The study showed that the streamed data in H-IoT include medical sensors data, apps registration data (personal information), device information, and other information related to cookies. The proposed work introduced the design of fog-based data classification and the algorithm for such classification. The implementation and evaluation of the proposed framework is future work.",
        "DOI": "10.4018/IJCAC.2021040101",
        "affiliation_name": "Sultan Qaboos University",
        "affiliation_city": "Muscat",
        "affiliation_country": "Oman"
    },
    {
        "paper_title": "Using reinforcement learning to estimate human joint moments from electromyography or joint kinematics: An alternative solution to musculoskeletal-based biomechanics",
        "paper_author": "Wu W.",
        "publication": "Journal of Biomechanical Engineering",
        "citied_by": "22",
        "cover_date": "2021-04-01",
        "Abstract": "Reinforcement learning (RL) has potential to provide innovative solutions to existing challenges in estimating joint moments in motion analysis, such as kinematic or electromyography (EMG) noise and unknown model parameters. Here, we explore feasibility of RL to assist joint moment estimation for biomechanical applications. Forearm and hand kinematics and forearm EMGs from four muscles during free finger and wrist movement were collected from six healthy subjects. Using the proximal policy optimization approach, we trained two types of RL agents that estimated joint moment based on measured kinematics or measured EMGs, respectively. To quantify the performance of trained RL agents, the estimated joint moment was used to drive a forward dynamic model for estimating kinematics, which was then compared with measured kinematics using Pearson correlation coefficient. The results demonstrated that both trained RL agents are feasible to estimate joint moment for wrist and metacarpophalangeal (MCP) joint motion prediction. The correlation coefficients between predicted and measured kinematics, derived from the kinematics-driven agent and subject-specific EMG-driven agents, were 98%±1% and 94%±3% for the wrist, respectively, and were 95%±2% and 84%±6% for the metacarpophalangeal joint, respectively. In addition, a biomechanically reasonable joint moment-angle-EMG relationship (i.e., dependence of joint moment on joint angle and EMG) was predicted using only 15 s of collected data. In conclusion, this study illustrates that an RL approach can be an alternative technique to conventional inverse dynamic analysis in human biomechanics study and EMG-driven human-machine interfacing applications.",
        "DOI": "10.1115/1.4049333",
        "affiliation_name": "Department of Biomedical Engineering",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Digital Twins for Intelligent Authorization in the B5G-Enabled Smart Grid",
        "paper_author": "Lopez J.",
        "publication": "IEEE Wireless Communications",
        "citied_by": "57",
        "cover_date": "2021-04-01",
        "Abstract": "Beyond fifth generation (B5G) communication networks and computation paradigms in the edge are expected to be integrated into power grid infrastructures over the coming years. In this sense, AI technologies will play a fundamental role to efficiently manage dynamic information flows of future applications, which impacts the authorization policies applied in such a complex scenario. This article studies how digital twins can evolve their context awareness capabilities and simulation technologies to anticipate faults or to detect cyber-security issues in real time, and update access control policies accordingly. Our study analyzes the evolution of monitoring platforms and architecture decentralization, including the application of machine learning and blockchain technologies in the smart grid, toward the goal of implementing autonomous and self-learning agents in the medium and long term. We conclude this study with future challenges on applying digital twins to B5G-based smart grid deployments.",
        "DOI": "10.1109/MWC.001.2000336",
        "affiliation_name": "Universidad de Málaga",
        "affiliation_city": "Malaga",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Artificial intelligence approach for analyzing anaemia prevalence in children and adolescents in brics countries: A review",
        "paper_author": "Dukhi N.",
        "publication": "Current Research in Nutrition and Food Science",
        "citied_by": "14",
        "cover_date": "2021-04-01",
        "Abstract": "Anemia prevalence, especially among children and adolescents, is a serious public health burden in the BRICS countries. This article gives an overview of the current anaemia status in children and adolescents in three BRICS countries, as part of a study that utilizes an artificial intelligence approach for analyzing anaemia prevalence in children and adolescents in South Africa, India and Russia. It posits that the use of machine learning in this area of health research is still novel. The weightage assessment of the crosslink between anaemia risk indicators using a machine learning approach will assist policy makers in identifying the areas of priority to intervene in the BRICS participating countries. Health interventions utilizing artificial intelligence and more specifically, machine learning techniques, remains nascent in LMICs but could lead to improved health outcomes.",
        "DOI": "10.12944/CRNFSJ.9.1.01",
        "affiliation_name": "Human Sciences Research Council of South Africa",
        "affiliation_city": "Pretoria",
        "affiliation_country": "South Africa"
    },
    {
        "paper_title": "Simulation annealing diagnosis algorithm method for optimized forecast of the dynamic response of floating offshore wind turbines",
        "paper_author": "Chen P.",
        "publication": "Journal of Hydrodynamics",
        "citied_by": "14",
        "cover_date": "2021-04-01",
        "Abstract": "Design of floating offshore wind turbines (FOWTs) needs reliable and innovative technologies to overcome the challenges on how to better predict the dynamic responses in terms of aero-hydro-servo-elastic disciplines. This paper aims to demonstrate the optimized prediction of the dynamic response of FOWTs by Simulation annealing diagnosis algorithm (SADA). SADA is an Artificial Intelligence technology-based method, which utilizes the advantages of numerical simulation, basin experiment and machine learning algorithms. The actor network in deep deterministic policy gradient (DDPG) is adopted to take actions to adjust the Key disciplinary parameters (KDPs) in each loop according to the feedback of 6DOF motions of platform in dynamic response analysis. The results demonstrated that the mean values of the platform’s motions and rotor axial thrust force could be predicted with higher accuracy. On this basis, other physical quantities that designers are more concerned about but cannot be obtained from experiments and actual measurements will be predicted by SADA with more credibility. This SADA method differs from traditional supervised learning applications in renewable energy, which do not need to be provided physical quantities with strong direct correlation. All targets can be artificially set for SADA to obtain a better self-learning performance. In general, designers can use SADA to get a more accurate and optimized prediction of the dynamic response of FOWTs, especially those physical quantities that cannot be directly obtained through the basin experiments.",
        "DOI": "10.1007/s42241-021-0033-9",
        "affiliation_name": "Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Emotions of COVID-19: Content analysis of self-reported information using artificial intelligence",
        "paper_author": "Adikari A.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "37",
        "cover_date": "2021-04-01",
        "Abstract": "Background: The COVID-19 pandemic has disrupted human societies around the world. This public health emergency was followed by a significant loss of human life; the ensuing social restrictions led to loss of employment, lack of interactions, and burgeoning psychological distress. As physical distancing regulations were introduced to manage outbreaks, individuals, groups, and communities engaged extensively on social media to express their thoughts and emotions. This internet-mediated communication of self-reported information encapsulates the emotional health and mental well-being of all individuals impacted by the pandemic. Objective: This research aims to investigate the human emotions related to the COVID-19 pandemic expressed on social media over time, using an artificial intelligence (AI) framework. Methods: Our study explores emotion classifications, intensities, transitions, and profiles, as well as alignment to key themes and topics, across the four stages of the pandemic: declaration of a global health crisis (ie, prepandemic), the first lockdown, easing of restrictions, and the second lockdown. This study employs an AI framework comprised of natural language processing, word embeddings, Markov models, and the growing self-organizing map algorithm, which are collectively used to investigate social media conversations. The investigation was carried out using 73,000 public Twitter conversations posted by users in Australia from January to September 2020. Results: The outcomes of this study enabled us to analyze and visualize different emotions and related concerns that were expressed and reflected on social media during the COVID-19 pandemic, which could be used to gain insights into citizens' mental health. First, the topic analysis showed the diverse as well as common concerns people had expressed during the four stages of the pandemic. It was noted that personal-level concerns expressed on social media had escalated to broader concerns over time. Second, the emotion intensity and emotion state transitions showed that fear and sadness emotions were more prominently expressed at first; however, emotions transitioned into anger and disgust over time. Negative emotions, except for sadness, were significantly higher (P<.05) in the second lockdown, showing increased frustration. Temporal emotion analysis was conducted by modeling the emotion state changes across the four stages of the pandemic, which demonstrated how different emotions emerged and shifted over time. Third, the concerns expressed by social media users were categorized into profiles, where differences could be seen between the first and second lockdown profiles. Conclusions: This study showed that the diverse emotions and concerns that were expressed and recorded on social media during the COVID-19 pandemic reflected the mental health of the general public. While this study established the use of social media to discover informed insights during a time when physical communication was impossible, the outcomes could also contribute toward postpandemic recovery and understanding psychological impact via emotion changes, and they could potentially inform health care decision making. This study exploited AI and social media to enhance our understanding of human behaviors in global emergencies, which could lead to improved planning and policy making for future crises.",
        "DOI": "10.2196/27341",
        "affiliation_name": "La Trobe University",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A machine-learning approach to human footprint index estimation with applications to sustainable development",
        "paper_author": "Keys P.W.",
        "publication": "Environmental Research Letters",
        "citied_by": "27",
        "cover_date": "2021-04-01",
        "Abstract": "The human footprint index (HFI) is an extensively used tool for interpreting the accelerating pressure of humanity on Earth. Up to now, the process of creating the HFI has required significant data and modeling, and updated versions of the index often lag the present day by many years. Here we introduce a near-present, global-scale machine learning-based HFI (ml-HFI) which is capable of routine update using satellite imagery alone. We present the most up-to-date map of the HFI, and document changes in human pressure during the past 20 years (2000-2019). Moreover, we demonstrate its utility as a monitoring tool for the United Nations Sustainable Development Goal 15 (SDG15), 'Life on Land', which aims to foster sustainable development while conserving biodiversity. We identify 43 countries that are making progress toward SDG15 while also experiencing increases in their ml-HFI. We examine a subset of these in the context of conservation policies that may or may not enable continued progress toward SDG15. This has immediate policy relevance, since the majority of countries globally are not on track to achieve Goal 15 by the declared deadline of 2030. Moving forward, the ml-HFI may be used for ongoing monitoring and evaluation support toward the twin goals of fostering a thriving society and global Earth system.",
        "DOI": "10.1088/1748-9326/abe00a",
        "affiliation_name": "Walter Scott, Jr. College of Engineering",
        "affiliation_city": "Fort Collins",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Addressing missing environmental data via a machine learning scheme",
        "paper_author": "Tzanis C.G.",
        "publication": "Atmosphere",
        "citied_by": "9",
        "cover_date": "2021-04-01",
        "Abstract": "An important aspect in environmental sciences is the study of air quality, using statistical methods (environmental statistics) which utilize large datasets of climatic parameters. The air-quality-monitoring networks that operate in urban areas provide data on the most important pollutants, which, via environmental statistics, can be used for the development of continuous surfaces of pollutants’ concentrations. Generating ambient air-quality maps can help guide policy makers and researchers to formulate measures to minimize the adverse effects. The information needed for a mapping application can be obtained by employing spatial interpolation methods to the available data, for generating estimations of air-quality distributions. This study used point-monitoring data from the network of stations that operates in Athens, Greece. A machine-learning scheme was applied as a method to spatially estimate pollutants’ concentrations, and the results can be effectively used to implement missing values and provide representative data for statistical analyses purposes.",
        "DOI": "10.3390/atmos12040499",
        "affiliation_name": "National and Kapodistrian University of Athens",
        "affiliation_city": "Athens",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Analyzing the Importance of Broker Identities in the Limit Order Book through Deep Learning",
        "paper_author": "Choi S.P.M.",
        "publication": "Big Data",
        "citied_by": "2",
        "cover_date": "2021-04-01",
        "Abstract": "Limit order books (LOBs) have been widely adopted as a trading mechanism in global securities markets, and the degree of LOB transparency is one of the most studied topics in market design. In the past, this issue was mainly researched through the comparison of LOB transparency in a market before and after a policy change, although such instances were rare and occurred decades ago. This article analyzes the importance of broker identities (IDs) in the LOB with respect to price movement predictability by proposing a different approach. By analyzing raw LOB data, an enormous dataset of selected Hong Kong stocks is divided into two parts, namely the prices and order volumes (anonymous LOBs), and a list of broker IDs in the bid and ask queues. A deep learning model is then employed to predict the mid-price movement after 20 ticks. Our result indicates that the best F1 scores of the anonymous LOB and broker ID models are fairly high, ranging from 57.63% to 68.70% and from 53.70% to 59.39%, respectively. When comparing the performance of both datasets, surprisingly, the overall F1 prediction performance based solely on the broker ID dataset can reach, on average, 85.13% that of the anonymous LOB dataset. The contributions of this study are twofold. First, a machine learning-based tool for finance researchers is proposed to quantitatively measure the price predictability of LOB features, and the results of the impact of LOB transparency on traders' profitability are novel as this study is empirical. Second, the empirical result strongly suggests that the broker ID queues in the LOB consist of significant information content for price prediction, and thus, the study provides insights for regulators to determine the appropriate degree of LOB transparency to guarantee a fair market for all investors.",
        "DOI": "10.1089/big.2020.0053",
        "affiliation_name": "Hong Kong Metropolitan University",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Comparison of public responses to containment measures during the initial outbreak and resurgence of COVID-19 in China: Infodemiology study",
        "paper_author": "Zhou X.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "20",
        "cover_date": "2021-04-01",
        "Abstract": "Background: COVID-19 cases resurged worldwide in the second half of 2020. Not much is known about the changes in public responses to containment measures from the initial outbreak to resurgence. Monitoring public responses is crucial to inform policy measures to prepare for COVID-19 resurgence. Objective: This study aimed to assess and compare public responses to containment measures during the initial outbreak and resurgence of COVID-19 in China. Methods: We curated all COVID-19-related posts from Sina Weibo (China's version of Twitter) during the initial outbreak and resurgence of COVID-19 in Beijing, China. With a Python script, we constructed subsets of Weibo posts focusing on 3 containment measures: lockdown, the test-trace-isolate strategy, and suspension of gatherings. The Baidu open-source sentiment analysis model and latent Dirichlet allocation topic modeling, a widely used machine learning algorithm, were used to assess public engagement, sentiments, and frequently discussed topics on each containment measure. Results: A total of 8,985,221 Weibo posts were curated. In China, the containment measures evolved from a complete lockdown for the general population during the initial outbreak to a more targeted response strategy for high-risk populations during COVID-19 resurgence. Between the initial outbreak and resurgence, the average daily proportion of Weibo posts with negative sentiments decreased from 57% to 47% for the lockdown, 56% to 51% for the test-trace-isolate strategy, and 55% to 48% for the suspension of gatherings. Among the top 3 frequently discussed topics on lockdown measures, discussions on containment measures accounted for approximately 32% in both periods, but those on the second-most frequently discussed topic shifted from the expression of negative emotions (11%) to its impacts on daily life or work (26%). The public expressed a high level of panic (21%) during the initial outbreak but almost no panic (1%) during resurgence. The more targeted test-trace-isolate measure received the most support (60%) among all 3 containment measures in the initial outbreak, and its support rate approached 90% during resurgence. Conclusions: Compared to the initial outbreak, the public expressed less engagement and less negative sentiments on containment measures and were more supportive toward containment measures during resurgence. Targeted test-trace-isolate strategies were more acceptable to the public. Our results indicate that when COVID-19 resurges, more targeted test-trace-isolate strategies for high-risk populations should be promoted to balance pandemic control and its impact on daily life and the economy.",
        "DOI": "10.2196/26518",
        "affiliation_name": "London School of Hygiene &amp; Tropical Medicine",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Public discourse against masks in the COVID-19 Era: Infodemiology study of twitter data",
        "paper_author": "Al-Ramahi M.",
        "publication": "JMIR Public Health and Surveillance",
        "citied_by": "54",
        "cover_date": "2021-04-01",
        "Abstract": "Background: Despite scientific evidence supporting the importance of wearing masks to curtail the spread of COVID-19, wearing masks has stirred up a significant debate particularly on social media. Objective: This study aimed to investigate the topics associated with the public discourse against wearing masks in the United States. We also studied the relationship between the anti-mask discourse on social media and the number of new COVID-19 cases. Methods: We collected a total of 51,170 English tweets between January 1, 2020, and October 27, 2020, by searching for hashtags against wearing masks. We used machine learning techniques to analyze the data collected. We investigated the relationship between the volume of tweets against mask-wearing and the daily volume of new COVID-19 cases using a Pearson correlation analysis between the two-time series. Results: The results and analysis showed that social media could help identify important insights related to wearing masks. The results of topic mining identified 10 categories or themes of user concerns dominated by (1) constitutional rights and freedom of choice; (2) conspiracy theory, population control, and big pharma; and (3) fake news, fake numbers, and fake pandemic. Altogether, these three categories represent almost 65% of the volume of tweets against wearing masks. The relationship between the volume of tweets against wearing masks and newly reported COVID-19 cases depicted a strong correlation wherein the rise in the volume of negative tweets led the rise in the number of new cases by 9 days. Conclusions: These findings demonstrated the potential of mining social media for understanding the public discourse about public health issues such as wearing masks during the COVID-19 pandemic. The results emphasized the relationship between the discourse on social media and the potential impact on real events such as changing the course of the pandemic. Policy makers are advised to proactively address public perception and work on shaping this perception through raising awareness, debunking negative sentiments, and prioritizing early policy intervention toward the most prevalent topics.",
        "DOI": "10.2196/26780",
        "affiliation_name": "Texas A&amp;M University-San Antonio",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modeling the impact of public response on the COVID-19 pandemic in Ontario",
        "paper_author": "Eastman B.",
        "publication": "PLoS ONE",
        "citied_by": "2",
        "cover_date": "2021-04-01",
        "Abstract": "The outbreak of SARS-CoV-2 is thought to have originated in Wuhan, China in late 2019 and has since spread quickly around the world. To date, the virus has infected tens of millions of people worldwide, compelling governments to implement strict policies to counteract community spread. Federal, provincial, and municipal governments have employed various public health policies, including social distancing, mandatory mask wearing, and the closure of schools and businesses. However, the implementation of these policies can be difficult and costly, making it imperative that both policy makers and the citizenry understand their potential benefits and the risks of non-compliance. In this work, a mathematical model is developed to study the impact of social behaviour on the course of the pandemic in the province of Ontario. The approach is based upon a standard SEIRD model with a variable transmission rate that depends on the behaviour of the population. The model parameters, which characterize the disease dynamics, are estimated from Ontario COVID-19 epidemiological data using machine learning techniques. A key result of the model, following from the variable transmission rate, is the prediction of the occurrence of a second wave using the most current infection data and disease-specific traits. The qualitative behaviour of different future transmission-reduction strategies is examined, and the time-varying reproduction number is analyzed using existing epidemiological data and future projections. Importantly, the effective reproduction number, and thus the course of the pandemic, is found to be sensitive to the adherence to public health policies, illustrating the need for vigilance as the economy continues to reopen.",
        "DOI": "10.1371/journal.pone.0249456",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Sovereign debt and currency crises prediction models using machine learning techniques",
        "paper_author": "Alaminos D.",
        "publication": "Symmetry",
        "citied_by": "14",
        "cover_date": "2021-04-01",
        "Abstract": "Sovereign debt and currencies play an increasingly influential role in the development of any country, given the need to obtain financing and establish international relations. A recurring theme in the literature on financial crises has been the prediction of sovereign debt and currency crises due to their extreme importance in international economic activity. Nevertheless, the limitations of the existing models are related to accuracy and the literature calls for more investigation on the subject and lacks geographic diversity in the samples used. This article presents new models for the prediction of sovereign debt and currency crises, using various computational techniques, which increase their precision. Also, these models present experiences with a wide global sample of the main geographical world zones, such as Africa and the Middle East, Latin America, Asia, Europe, and globally. Our models demonstrate the superiority of computational techniques concerning statistics in terms of the level of precision, which are the best methods for the sovereign debt crisis: fuzzy decision trees, AdaBoost, extreme gradient boosting, and deep learning neural decision trees, and for forecasting the currency crisis: deep learning neural decision trees, extreme gradient boosting, random forests, and deep belief network. Our research has a large and potentially significant impact on the macroeconomic policy adequacy of the countries against the risks arising from financial crises and provides instruments that make it possible to improve the balance in the finance of the countries.",
        "DOI": "10.3390/sym13040652",
        "affiliation_name": "Universidad Pontificia Comillas",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Land cover mapping and ecological risk assessment in the context of recent ecological migration",
        "paper_author": "Zhang T.",
        "publication": "Remote Sensing",
        "citied_by": "21",
        "cover_date": "2021-04-01",
        "Abstract": "In order to protect the ecological environment and solve the poverty problem in the western region, China has established an ecological migration (EM) policy. This policy aims to relocate populations from poverty-stricken areas with fragile ecological environments, which inevitably leads to changes in land cover and the ecological environment. The objective of this study was to identify the effects of EM in a typical region (Wuwei), including changes in the land cover and ecological risk (ER). A land cover change monitoring method was implemented for the 2010-2019 period for six land cover classes using random forest, which is an effective supervised machine learning method. The land cover change patterns were analyzed by determining the area changes of the six classes and applying a land use transition matrix, and a landscape ecological risk model based on landscape disturbance and fragility was used. Our results demonstrate that the increase and decrease in the area of cultivated land, unused land, and construction land can be divided into two stages (2010-2015 and 2015-2019). The area of water and perennial snow doubled during the study periods. The major land cover transitions were between unused land and construction land and between unused land and crop land. In addition, the ER value for the Qilian Mountain National Nature Reserve decreased because of the implementation of EM in the study area, indicating that the ecological environment was effectively improved. The results demonstrate the advantage of the proposed approach in understanding the impact of EM on regional land cover changes and the ecological environment so as to provide guidance for follow-up planning and development.",
        "DOI": "10.3390/rs13071381",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Improvement of earthquake risk awareness and seismic literacy of korean citizens through earthquake vulnerability map from the 2017 pohang earthquake, South Korea",
        "paper_author": "Han J.",
        "publication": "Remote Sensing",
        "citied_by": "19",
        "cover_date": "2021-04-01",
        "Abstract": "Earthquake activities in and around the Korean Peninsula are relatively low in number and intensity compared with neighboring countries such as Japan and China. However, recent seismic activity caused great alarm and concern among citizens and government authorities, and uncovered the level of preparedness toward earthquake disasters. A survey has been conducted on 1256 participants to investigate the seismic literacy of Korean citizens, including seismic knowledge, awareness and management using a questionnaire of citizen earthquake literacy (CEL). The results declared that the citizens had low awareness and literacy, which means that they are not properly prepared for earthquake hazards. To develop an earthquake risk reduction plan and program efficiently and effectively, not only must it appropriately characterize the target audience, but also indicate high potential earthquake zones and potential earthquake damage. Therefore, this study mapped and analyzed the seismic vulnerability in southeast Korea using LogitBoost, logistic model tree (LMT), and logistic regression (LR) machine learning algorithms based on a building damage inventory map. The damaged buildings’ locations were generated after the 2017 Pohang earthquake using the damage proxy map (DPM) method from the Sentinel-1 synthetic aperture radar (SAR) data. DPMs detected coherence loss, which indicates damaged buildings in urban areas in the Pohang earthquake and shows a good correlation with the Korea Meteorological Administration (KMA) report with modified Mercalli intensity (MMI) scale values of more than VII (seven). The damage locations were randomly divided into two datasets: 50% for training the vulnerability models and 50% for validating the models in terms of accuracy and reliability. Fifteen seismic-related factors were used to construct a model of each algorithm. Model validation based on the area under the receiver operating curve (AUC) was used to determine model accuracy. The AUC values of seismic vulnerability maps using the LogitBoost, LMT, and LR algorithms were 0.769, 0.851, and 0.749, respectively. We suggest that earthquake preparedness efforts should focus on reconstruction, retrofitting, renovation, and seismic education in areas with high seismic vulnerability in South Korea. The results of this study are expected to be beneficial for engineers and policymakers aiming at developing disaster risk reduction plans, policies, and programs due to future seismic activity in South Korea.",
        "DOI": "10.3390/rs13071365",
        "affiliation_name": "Kangwon National University",
        "affiliation_city": "Chuncheon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Method of stock prices forecast based on proximal reinforcement learning",
        "paper_author": "Cen Y.F.",
        "publication": "Kongzhi yu Juece/Control and Decision",
        "citied_by": "2",
        "cover_date": "2021-04-01",
        "Abstract": "Stock prices forecast is a hot and challenging topic in financial time series research. It is of great significance for the investors in theirs stock trading, to maximize revenue and to avoid risks by adopting a reasonable and effective forecasting method. A stock prices forecast method based on proximal reinforcement learning which combines proximal policy optimization (PPO) and reinforcement learning (RL), namely PPORL, is proposed, and the forecasting process is regarded as a time series prediction problem. Furthermore, the relative strength index (RSI) and move average of five days (MA5) are also introduced working as a trading strategy, which can automatically capture potential trading points, and avoid trading risks. By comparing the prediction performance and trading decision performance with long short-term memory (LSTM) and recurrent neural network (RNN) models on the SSE composite index (SZZS), the SZSE component index (SZCZ) and the CSI300 index (HS300), and a variety of error evaluation methods are used for quantitative analysis of the prediction results, which shows the effectiveness and robustness of the PPORL in forecasting performance and trading decision.",
        "DOI": "10.13195/j.kzyjc.2019.1245",
        "affiliation_name": "Zhejiang University of Technology",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The Multiclass Classification of Newspaper Articles with Machine Learning: The Hybrid Binary Snowball Approach",
        "paper_author": "Sebåk M.",
        "publication": "Political Analysis",
        "citied_by": "24",
        "cover_date": "2021-04-01",
        "Abstract": "In this article, we present a machine learning-based solution for matching the performance of the gold standard of double-blind human coding when it comes to content analysis in comparative politics. We combine a quantitative text analysis approach with supervised learning and limited human resources in order to classify the front-page articles of a leading Hungarian daily newspaper basedon their full text. Our goal was to assign items in our dataset to one of 21 policy topics based onthe codebook of the Comparative Agendas Project. The classification of the imbalanced classes of topics was handled by a hybrid binary snowball workflow. This relies on limited human resources as well as supervised learning; it simplifies the multiclass problem to one of binary choice; and it is based on a snowball approach as we augment the training set with machine-classified observations after each successful round and also between corpora. Our results show that our approach provided better precision results (of over 80% for most topic codes) than what is customary for human coders and most computer-assisted coding projects. Nevertheless, this high precision came at the expense of a relatively low, below 60%, share of labeled articles.",
        "DOI": "10.1017/pan.2020.27",
        "affiliation_name": "Magyar Tudomanyos Akademia",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "A strong seasonality pattern for covid-19 incidence rates modulated by uv radiation levels",
        "paper_author": "Karapiperis C.",
        "publication": "Viruses",
        "citied_by": "13",
        "cover_date": "2021-04-01",
        "Abstract": "The Covid-19 pandemic has required nonpharmaceutical interventions, primarily physical distancing, personal hygiene and face mask use, to limit community transmission, irrespective of seasons. In fact, the seasonality attributes of this pandemic remain one of its biggest unknowns. Early studies based on past experience from respiratory diseases focused on temperature or humidity, with disappointing results. Our hypothesis that ultraviolet (UV) radiation levels might be a factor and a more appropriate parameter has emerged as an alternative to assess seasonality and exploit it for public health policies. Using geographical, socioeconomic and epidemiological criteria, we selected twelve North-equatorial-South countries with similar characteristics. We then obtained UV levels, mobility and Covid-19 daily incidence rates for nearly the entire 2020. Using machine learning, we demonstrated that UV radiation strongly associated with incidence rates, more so than mobility did, indicating that UV is a key seasonality indicator for Covid-19, irrespective of the initial conditions of the epidemic. Our findings can inform the implementation of public health emergency measures, partly based on seasons in the Northern and Southern Hemispheres, as the pandemic unfolds into 2021.",
        "DOI": "10.3390/v13040574",
        "affiliation_name": "Chemical Process &amp; Energy Resources Institute",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Article synthetic dataset generation of driver telematics",
        "paper_author": "So B.",
        "publication": "Risks",
        "citied_by": "22",
        "cover_date": "2021-04-01",
        "Abstract": "This article describes the techniques employed in the production of a synthetic dataset of driver telematics emulated from a similar real insurance dataset. The synthetic dataset generated has 100,000 policies that included observations regarding driver’s claims experience, together with associated classical risk variables and telematics-related variables. This work is aimed to produce a resource that can be used to advance models to assess risks for usage-based insurance. It follows a three-stage process while using machine learning algorithms. In the first stage, a synthetic portfolio of the space of feature variables is generated applying an extended SMOTE algorithm. The second stage is simulating values for the number of claims as multiple binary classifications applying feedforward neural networks. The third stage is simulating values for aggregated amount of claims as regression using feedforward neural networks, with number of claims included in the set of feature variables. The resulting dataset is evaluated by comparing the synthetic and real datasets when Poisson and gamma regression models are fitted to the respective data. Other visualization and data summarization produce remarkable similar statistics between the two datasets. We hope that researchers interested in obtaining telematics datasets to calibrate models or learning algorithms will find our work ot be valuable.",
        "DOI": "10.3390/risks9040058",
        "affiliation_name": "Université du Québec à Montréal",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Land use/land cover (LULC) analysis (2009–2019) with Google Earth Engine and 2030 prediction using Markov-CA in the Rondônia State, Brazil",
        "paper_author": "Floreano I.X.",
        "publication": "Environmental Monitoring and Assessment",
        "citied_by": "46",
        "cover_date": "2021-04-01",
        "Abstract": "The Amazonian biome is important not only for South America but also for the entire planet, providing essential environmental services. The state of Rondônia ranks third in deforestation rates in the Brazilian Legal Amazon (BLA) political division. This study aims to evaluate the land use/land cover (LULC) changes over the past ten years (2009–2019), as well as, to predict the LULC in the next 10 years, using TerrSet 18.3 software, in the state of Rondônia, Brazil. The machine learning algorithms within the Google Earth Engine cloud-based platform employed a Random Forest classifier in image classifications. The Markov-CA deep learning algorithm predicted future LULC changes by comparing scenarios of one and three transitions. The results showed a reduction in forested areas of about 15.7% between 2009 and 2019 in the Rondônia state. According to the predictive model, by 2030, around 30% of the remaining forests will be logged, most likely converted into occupied areas. The results reinforce the importance of measures and policies integrated with investments in research and satellite monitoring to reduce deforestation in the Brazilian Amazon and ensure the continuity of the Amazonian role in halting climate change.",
        "DOI": "10.1007/s10661-021-09016-y",
        "affiliation_name": "Universidade Federal do Estado do Rio de Janeiro",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Vaccination as a control tool in bovine tuberculosis: Social media monitoring to assess public response to government policy development and implementation",
        "paper_author": "Dicks F.",
        "publication": "Vaccines",
        "citied_by": "6",
        "cover_date": "2021-04-01",
        "Abstract": "Vaccine hesitancy does not only concern human vaccines but incorporates One Health policies also; including vaccination of cattle and badgers as part of the government’s bovine tuberculosis eradication strategy for England. Both digital and social media can propagate healthcare misinformation and thus affect vaccine policy support. The use of social media monitoring to understand real-time public perceptions of One Health policies is crucial to identify misinformation and address public concerns appropriately to achieve successful policy implementation. Digital and social media data surrounding two government announcements regarding the bovine tuberculosis eradication strategy for England were collected and screened using the Meltwater media monitoring platform. Communication patterns were studied using InfraNodus. Twitter analysis was conducted to identify key influencers, public engagement, and trending communications. Online social media activity increased rapidly after each announcement. Initially, badger culling took primary public concern and major influencers were identified. Cattle vaccination dominated discussion after the second announcement, with public perception being influenced by increased online activity from news sites, animal welfare charities, governmental bodies, and medical professionals. The greatest ambiguity towards the strategy was detected within farming communities, with the main disparity existing between cattle vaccination and badger culling opinions. Social media monitoring has potential use in surveying public perception of government policy, both prior to, and after implementation to identify and address areas of miscommunication and misinformation to improve public support for One Health policies.",
        "DOI": "10.3390/vaccines9040314",
        "affiliation_name": "School of Biosciences and Medicine",
        "affiliation_city": "Guildford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "The what, why, and how of changing cooling energy consumption in India's urban households",
        "paper_author": "Khosla R.",
        "publication": "Environmental Research Letters",
        "citied_by": "29",
        "cover_date": "2021-04-01",
        "Abstract": "India's urbanising middle class is at the brink of an unprecedented increase in residential cooling demand, yet little is understood about the dynamics of changing cooling consumption. Based on empirical analyses, this research examines a set of fundamental questions around India's cooling transition. How is cooling conceptualised and what cooling strategies do households use? How, when and why are people purchasing and using their air conditioners (ACs)? Who is buying energy-efficient ACs? Is cooling consumption gendered? Using descriptive statistics, machine learning, and regression analysis to characterize AC usage, we examine a sample dataset (n = 2092) that is representative of areas in Delhi with above average AC penetration. We unpack perceptions of thermal comfort, and characterize the conditions under which households have greater AC use and make energy efficient purchase choices. AC usage is found to be a function of household habits (such as exposure to ACs in the workplace or schools), structural factors, and socio demographic features. While most ACs are in the middle energy-efficiency range, preferences, behaviours and awareness around energy efficiency are found to affect AC use as well as influence the purchase of more efficient ACs. Notable gender differences are observed, and women are found to be less involved in decision-making around cooling appliances and less aware of the technical know-how or energy-efficient schemes. Policy recommendations for a low-carbon cooling trajectory are discussed.",
        "DOI": "10.1088/1748-9326/abecbc",
        "affiliation_name": "Ashoka University",
        "affiliation_city": "Sonipat",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Condition monitoring of high voltage circuit breakers: Past to future",
        "paper_author": "Razi-Kazemi A.A.",
        "publication": "IEEE Transactions on Power Delivery",
        "citied_by": "87",
        "cover_date": "2021-04-01",
        "Abstract": "High voltage circuit breakers (HVCBs) play a critical role on providing the desired reliability, and resiliency in power systems. In order to extend their lifetime and predict the failures, various maintenance policies could be applied on these critical components. Amongst these strategies, condition-based maintenance (CBM) provides a satisfactory agreement with future smart environment. This paper aims to provide an insight into the relevant developments in this subject and to explore the viable visions compatible with future research stream. Accordingly, three directions, i.e., diagnostic signals, intelligent modelling and using monitoring data in asset management have been addressed in this paper. It presents challenges dealing with real-time assessment of the diagnostic signals relating to measurements, and analyses. Subsequently, the issues associated with using artificial intelligent (AI) and Machine learning for providing intelligent algorithms have been discussed. Finally, the connection between the monitoring data and the asset management approach is investigated. The latter is looking for the subjects including remaining lifetime estimation, prioritization, and health index definitions. This paper has attempted to make a bridge from past to future research trends in the failure diagnosis of HVCBs.",
        "DOI": "10.1109/TPWRD.2020.2991234",
        "affiliation_name": "K. N. Toosi University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Few-Shot Model-Based Adaptation in Noisy Conditions",
        "paper_author": "Arndt K.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "6",
        "cover_date": "2021-04-01",
        "Abstract": "Few-shot adaptation is a challenging problem in the context of simulation-to-real transfer in robotics, requiring safe and informative data collection. In physical systems, additional challenge may be posed by domain noise, which is present in virtually all real-world applications. In this letter, we propose to perform few-shot adaptation of dynamics models in noisy conditions using an uncertainty-aware Kalman filter-based neural network architecture. We show that the proposed method, which explicitly addresses domain noise, improves few-shot adaptation error over a blackbox adaptation LSTM baseline, and over a model-free on-policy reinforcement learning approach, which tries to learn an adaptable and informative policy at the same time. The proposed method also allows for system analysis by analyzing hidden states of the model during and after adaptation.",
        "DOI": "10.1109/LRA.2021.3068104",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Recommendations for the safe, effective use of adaptive CDS in the US healthcare system: an AMIA position paper",
        "paper_author": "Petersen C.",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "48",
        "cover_date": "2021-04-01",
        "Abstract": "The development and implementation of clinical decision support (CDS) that trains itself and adapts its algorithms based on new data - here referred to as Adaptive CDS - present unique challenges and considerations. Although Adaptive CDS represents an expected progression from earlier work, the activities needed to appropriately manage and support the establishment and evolution of Adaptive CDS require new, coordinated initiatives and oversight that do not currently exist. In this AMIA position paper, the authors describe current and emerging challenges to the safe use of Adaptive CDS and lay out recommendations for the effective management and monitoring of Adaptive CDS.",
        "DOI": "10.1093/jamia/ocaa319",
        "affiliation_name": "IBM Watson Health",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning framework for carbon emissions predictions incorporating a RReliefF driven features selection and an iterative neural network architecture improvement",
        "paper_author": "Crespo A.M.F.",
        "publication": "SN Applied Sciences",
        "citied_by": "3",
        "cover_date": "2021-04-01",
        "Abstract": "Abstract: Inaccurate carbon emissions predictions may be one of the root factors leading to the overall ineffectiveness of the European Union environmental regulatory framework. Therefore, the present article aims at introducing a novel computational learning framework for carbon emissions prediction incorporating a RReliefF driven features selection and an iterative neural network architecture improvement. Our learning framework algorithmic architecture iteratively chains the features selection process and the backpropagation artificial neural network architecture design based on the data assessment accomplished by the RReliefF algorithm. Thus a better features set / neural network architecture combination is obtained for each specific prediction target. The implemented framework was trained and tested with real world data obtained from the European Union, International Energy Agency, Organisation for Economic Co-operation and Development, and World Bank, for the period 1990–2017. The framework evaluation against current mainstream machine learning models, and its benchmarking comparing to recent published researches on carbon emissions prediction indicates that our research contribution is relevant and capable of supporting the improvement of environmental policies. Graphic abstract: [Figure not available: see fulltext.].",
        "DOI": "10.1007/s42452-021-04411-z",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Uncertainty-aware contact-safe model-based reinforcement learning",
        "paper_author": "Kuo C.Y.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "15",
        "cover_date": "2021-04-01",
        "Abstract": "This letter presents contact-safe Model-based Reinforcement Learning (MBRL) for robot applications that achieves contact-safe behaviors in the learning process. In typical MBRL, we cannot expect the data-driven model to generate accurate and reliable policies to the intended robotic tasks during the learning process due to sample scarcity. Operating these unreliable policies in a contact-rich environment could cause damage to the robot and its surroundings. To alleviate the risk of causing damage through unexpected intensive physical contacts, we present the contact-safe MBRL that associates the probabilistic Model Predictive Control's (pMPC) control limits with the model uncertainty so that the allowed acceleration of controlled behavior is adjusted according to learning progress. Control planning with such uncertainty-aware control limits is formulated as a deterministic MPC problem using a computation-efficient approximated GP dynamics and an approximated inference technique. Our approach's effectiveness is evaluated through bowl mixing tasks with simulated and real robots, scooping tasks with a real robot as examples of contact-rich manipulation skills.",
        "DOI": "10.1109/LRA.2021.3065271",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Can social media data be used to evaluate the risk of human interactions during the COVID-19 pandemic?",
        "paper_author": "Li L.",
        "publication": "International Journal of Disaster Risk Reduction",
        "citied_by": "9",
        "cover_date": "2021-04-01",
        "Abstract": "The U.S. has taken multiple measures to contain the spread of COVID-19, including the implementation of lockdown orders and social distancing practices. Evaluating social distancing is critical since it reflects the risk of close human interactions. While questionnaire surveys or mobility data-based systems have provided valuable insights, social media data can contribute as an additional instrument to help monitor the risk of human interactions during the pandemic. For this reason, this study introduced a social media-based approach that quantifies the pro/anti-lockdown ratio as an indicator of the risk of human interactions. With the aid of natural language processing and machine learning techniques, this study classified the lockdown-related tweets and quantified the pro/anti-lockdown ratio for each state over time. The anti-lockdown ratio showed a moderate and negative correlation with the state-level social distancing index on a weekly basis, suggesting that people are more likely to travel out of the state where the higher anti-lockdown level is observed. The study further showed that the perception expressed on social media could reflect people's behaviors. The findings of the study are of significance for government agencies to assess the risk of close human interactions and to evaluate their policy effectiveness in the context of social distancing and lockdown.",
        "DOI": "10.1016/j.ijdrr.2021.102142",
        "affiliation_name": "A. James Clark School of Engineering",
        "affiliation_city": "College Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An imageomics and multi-network based deep learning model for risk assessment of liver transplantation for hepatocellular cancer",
        "paper_author": "He T.",
        "publication": "Computerized Medical Imaging and Graphics",
        "citied_by": "43",
        "cover_date": "2021-04-01",
        "Abstract": "Introduction: Liver transplantation (LT) is an effective treatment for hepatocellular carcinoma (HCC), the most common type of primary liver cancer. Patients with small HCC (<5 cm) are given priority over others for transplantation due to clinical allocation policies based on tumor size. Attempting to shift from the prevalent paradigm that successful transplantation and longer disease-free survival can only be achieved in patients with small HCC to expanding the transplantation option to patients with HCC of the highest tumor burden (>5 cm), we developed a convergent artificial intelligence (AI) model that combines transient clinical data with quantitative histologic and radiomic features for more objective risk assessment of liver transplantation for HCC patients. Methods: Patients who received a LT for HCC between 2008–2019 were eligible for inclusion in the analysis. All patients with post-LT recurrence were included, and those without recurrence were randomly selected for inclusion in the deep learning model. Pre- and post-transplant magnetic resonance imaging (MRI) scans and reports were compressed using CapsNet networks and natural language processing, respectively, as input for a multiple feature radial basis function network. We applied a histological image analysis algorithm to detect pathologic areas of interest from explant tissue of patients who recurred. The multilayer perceptron was designed as a feed-forward, supervised neural network topology, with the final assessment of recurrence risk. We used area under the curve (AUC) and F-1 score to assess the predictability of different network combinations. Results: A total of 109 patients were included (87 in the training group, 22 in the testing group), of which 20 were positive for cancer recurrence. Seven models (AUC; F-1 score) were generated, including clinical features only (0.55; 0.52), magnetic resonance imaging (MRI) only (0.64; 0.61), pathological images only (0.64; 0.61), MRI plus pathology (0.68; 0.65), MRI plus clinical (0.78, 0.75), pathology plus clinical (0.77; 0.73), and a combination of clinical, MRI, and pathology features (0.87; 0.84). The final combined model showed 80 % recall and 89 % precision. The total accuracy of the implemented model was 82 %. Conclusion: We validated that the deep learning model combining clinical features and multi-scale histopathologic and radiomic image features can be used to discover risk factors for recurrence beyond tumor size and biomarker analysis. Such a predictive, convergent AI model has the potential to alter the LT allocation system for HCC patients and expand the transplantation treatment option to patients with HCC of the highest tumor burden.",
        "DOI": "10.1016/j.compmedimag.2021.101894",
        "affiliation_name": "Houston Methodist Hospital",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A survey on autonomous vehicle control in the era of mixed-autonomy: From physics-based to AI-guided driving policy learning",
        "paper_author": "Di X.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "164",
        "cover_date": "2021-04-01",
        "Abstract": "This paper serves as an introduction and overview of the potentially useful models and methodologies from artificial intelligence (AI) into the field of transportation engineering for autonomous vehicle (AV) control in the era of mixed autonomy when AVs drive alongside human-driven vehicles (HV). It is the first-of-its-kind survey paper to comprehensively review literature in both transportation engineering and AI for mixed traffic modeling. We will discuss state-of-the-art applications of AI-guided methods, identify opportunities and obstacles, and raise open questions. We divide the stage of AV deployment into four phases: the pure HVs, the HV-dominated, the AV-dominated, and the pure AVs. This paper is primarily focused on the latter three phases. Models used for each phase are summarized, encompassing game theory, deep (reinforcement) learning, and imitation learning. While reviewing the methodologies, we primarily focus on the following research questions: (1) What scalable driving policies are to control a large number of AVs in mixed traffic comprised of human drivers and uncontrollable AVs? (2) How do we estimate human driver behaviors? (3) How should the driving behavior of uncontrollable AVs be modeled in the environment? (4) How are the interactions between human drivers and autonomous vehicles characterized? We also provide a list of public datasets and simulation software related to AVs. Hopefully this paper will not only inspire our transportation community to rethink the conventional models that are developed in the data-shortage era, but also start conversations with other disciplines, in particular robotics and machine learning, to join forces towards creating a safe and efficient mixed traffic ecosystem.",
        "DOI": "10.1016/j.trc.2021.103008",
        "affiliation_name": "The Fu Foundation School of Engineering and Applied Science",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Underutilization of epilepsy surgery: Part II: Strategies to overcome barriers",
        "paper_author": "Samanta D.",
        "publication": "Epilepsy and Behavior",
        "citied_by": "36",
        "cover_date": "2021-04-01",
        "Abstract": "Interventions focused on utilization of epilepsy surgery can be divided into groups: those that improve patients’ access to surgical evaluation and those that facilitate completion of the surgical evaluation and treatment. Educational intervention, technological innovation, and effective coordination and communication can significantly improve patients’ access to surgery. Patient and public facing, individualized (analog and/or digital) communication can raise awareness and acceptance of epilepsy surgery. Educational interventions aimed at providers may mitigate knowledge gaps using practical and concise consensus statements and guidelines, while specific training can improve awareness around implicit bias. Innovative technology, such as clinical decision-making toolkits within the electronic medical record (EMR), machine learning techniques, online decision-support tools, nomograms, and scoring algorithms can facilitate timely identification of appropriate candidates for epilepsy surgery with individualized guidance regarding referral appropriateness, postoperative seizure freedom rate, and risks of complication after surgery. There are specific strategies applicable for epilepsy centers’ success: building a multidisciplinary setup, maintaining/tracking volume and complexity of cases, collaborating with other centers, improving surgical outcome with reduced complications, utilizing advanced diagnostics tools, and considering minimally invasive surgical techniques. Established centers may use other strategies, such as multi-stage procedures for multifocal epilepsy, advanced functional mapping with tailored surgery for epilepsy involving the eloquent cortex, and generation of fresh hypotheses in cases of surgical failure. Finally, improved access to epilepsy surgery can be accomplished with policy changes (e.g., anti-discrimination policy, exemption in transportation cost, telehealth reimbursement policy, patient-centered epilepsy care models, pay-per-performance models, affordability and access to insurance, and increased funding for research). Every intervention should receive regular evaluation and feedback-driven modification to ensure appropriate utilization of epilepsy surgery.",
        "DOI": "10.1016/j.yebeh.2021.107853",
        "affiliation_name": "UAMS College of Medicine",
        "affiliation_city": "Little Rock",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Exploring nonlinear effects of the built environment on ridesplitting: Evidence from Chengdu",
        "paper_author": "Tu M.",
        "publication": "Transportation Research Part D: Transport and Environment",
        "citied_by": "106",
        "cover_date": "2021-04-01",
        "Abstract": "Ridesplitting, a form of ridesourcing services that matches riders with similar routes to the same driver, is a high occupancy travel mode that can bring considerable benefits. However, the current ratio of ridesplitting in the ridesourcing services is relatively low and its influencing factors remain unrevealed. Therefore, this paper uses a machine learning method, gradient boosting decision tree (GBDT) model, to explore the nonlinear effects of built environment on the ridesplitting ratio of origin–destination pairs (census tract to census tract). The GBDT model also provides the relative importance ranking of all the built environment factors. The results indicate that distance to city center, land use diversity and road density are the key influencing factors of ridesplitting ratio. In addition, the non-linear thresholds of built environment factors are identified based on partial dependence plots, which could provide policy implications for the government and transportation network companies to promote ridesplitting.",
        "DOI": "10.1016/j.trd.2021.102776",
        "affiliation_name": "Perception, les Interactions, les Comportements et la Simulation des Usagers de la Route et de la rue (COSYS-PICS-L)",
        "affiliation_city": "Marne-la-Vallee",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Network-wide traffic signal control optimization using a multi-agent deep reinforcement learning",
        "paper_author": "Li Z.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "107",
        "cover_date": "2021-04-01",
        "Abstract": "Inefficient traffic control may cause numerous problems such as traffic congestion and energy waste. This paper proposes a novel multi-agent reinforcement learning method, named KS-DDPG (Knowledge Sharing Deep Deterministic Policy Gradient) to achieve optimal control by enhancing the cooperation between traffic signals. By introducing the knowledge-sharing enabled communication protocol, each agent can access to the collective representation of the traffic environment collected by all agents. The proposed method is evaluated through two experiments respectively using synthetic and real-world datasets. The comparison with state-of-the-art reinforcement learning-based and conventional transportation methods demonstrate the proposed KS-DDPG has significant efficiency in controlling large-scale transportation networks and coping with fluctuations in traffic flow. In addition, the introduced communication mechanism has also been proven to speed up the convergence of the model without significantly increasing the computational burden.",
        "DOI": "10.1016/j.trc.2021.103059",
        "affiliation_name": "State Key Laboratory of Internet of Things for Smart City",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "Estimating economic severity of Air Traffic Flow Management regulations",
        "paper_author": "Delgado L.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "15",
        "cover_date": "2021-04-01",
        "Abstract": "The development of trajectory-based operations and the rolling network operations plan in European air traffic management network implies a move towards more collaborative, strategic flight planning. This opens up the possibility for inclusion of additional information in the collaborative decision-making process. With that in mind, we define the indicator for the economic risk of network elements (e.g., sectors or airports) as the expected costs that the elements impose on airspace users due to Air Traffic Flow Management (ATFM) regulations. The definition of the indicator is based on the analysis of historical ATFM regulations data, that provides an indication of the risk of accruing delay. This risk of delay is translated into a monetary risk for the airspace users, creating the new metric of the economic risk of a given airspace element. We then use some machine learning techniques to find the parameters leading to this economic risk. The metric is accompanied by an indication of the accuracy of the delay–cost prediction model. Lastly, the economic risk is transformed into a qualitative economic severity classification. The economic risks and consequently economic severity can be estimated for different temporal horizons and time periods providing an indicator which can be used by Air Navigation Service Providers to identify areas which might need the implementation of strategic measures (e.g., resectorisation or capacity provision change), and by Airspace Users to consider operation of routes which use specific airspace regions.",
        "DOI": "10.1016/j.trc.2021.103054",
        "affiliation_name": "Università degli Studi di Trieste",
        "affiliation_city": "Trieste",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Probabilistic Adaptive Control for Robust Behavior Imitation",
        "paper_author": "Jankowski J.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "1",
        "cover_date": "2021-04-01",
        "Abstract": "In the context of learning from demonstration (LfD), trajectory policy representations such as probabilistic movement primitives (ProMPs) allow for rich modeling of demonstrated skills. To reproduce a learned skill with a real robot, a feedback controller is required to cope with perturbations and to react to dynamic changes in the environment. In this letter, we propose a generalized probabilistic control approach that merges the probabilistic modeling of the demonstrated movements and the feedback control action for reproducing the demonstrated behavior. We show that our controller can be easily employed, outperforming both original controller and a controller with constant feedback gains. Furthermore, we show that the proposed approach is able to solve dynamically changing tasks by modeling the demonstrated behavior as Gaussian mixtures and by introducing context variables. We demonstrate the capability of the approach with experiments in simulation and by teaching a 7-axis Franka Emika Panda robot to drop a ball into a moving box with only few demonstrations.",
        "DOI": "10.1109/LRA.2021.3061310",
        "affiliation_name": "Institut Dalle Molle D'intelligence Artificielle Perceptive",
        "affiliation_city": "Martigny",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Learning Variable Impedance Control via Inverse Reinforcement Learning for Force-Related Tasks",
        "paper_author": "Zhang X.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "76",
        "cover_date": "2021-04-01",
        "Abstract": "Many manipulation tasks require robots to interact with unknown environments. In such applications, the ability to adapt the impedance according to different task phases and environment constraints is crucial for safety and performance. Although many approaches based on deep reinforcement learning (RL) and learning from demonstration (LfD) have been proposed to obtain variable impedance skills on contact-rich manipulation tasks, these skills are typically task-specific and could be sensitive to changes in task settings. This letter proposes an inverse reinforcement learning (IRL) based approach to recover both the variable impedance policy and reward function from expert demonstrations. We explore different action space of the reward functions to achieve a more general representation of expert variable impedance skills. Experiments on two variable impedance tasks (Peg-in-Hole and Cup-on-Plate) were conducted in both simulations and on a real FANUC LR Mate 200iD/7 L industrial robot. The comparison results with behavior cloning and force-based IRL proved that the learned reward function in the gain action space has better transferability than in the force space. Experiment videos are available at https://msc.berkeley.edu/research/impedance-irl.html.",
        "DOI": "10.1109/LRA.2021.3061374",
        "affiliation_name": "Department of Mechanical Engineering",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Visual Navigation among Humans with Optimal Control as a Supervisor",
        "paper_author": "Tolani V.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "31",
        "cover_date": "2021-04-01",
        "Abstract": "Real world visual navigation requires robots to operate in unfamiliar, human-occupied dynamic environments. Navigation around humans is especially difficult because it requires anticipating their future motion, which can be quite challenging. We propose an approach that combines learning-based perception with model-based optimal control to navigate among humans based only on monocular, first-person RGB images. Our approach is enabled by our novel data-generation tool, HumANav, that allows for photorealistic renderings of indoor environment scenes with humans in them, which are then used to train the perception module entirely in simulation. Through simulations and experiments on a mobile robot, we demonstrate that the learned navigation policies can anticipate and react to humans without explicitly predicting future human motion, generalize to previously unseen environments and human behaviors, and transfer directly from simulation to reality. Videos describing our approach and experiments, as well as a demo of HumANav are available on the project website.1",
        "DOI": "10.1109/LRA.2021.3060638",
        "affiliation_name": "Department of Electrical Engineering and Computer Sciences",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Robust Policy Search for Robot Navigation",
        "paper_author": "Garcia-Barcos J.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "2",
        "cover_date": "2021-04-01",
        "Abstract": "Complex robot navigation and control problems can be framed as policy search problems. However, interactive learning in uncertain environments can be expensive, requiring the use of data-efficient methods. Bayesian optimization is an efficient nonlinear optimization method where queries are carefully selected to gather information about the optimum location. This is achieved by a surrogate model, which encodes past information, and the acquisition function for query selection. Bayesian optimization can be very sensitive to uncertainty in the input data or prior assumptions. In this letter, we incorporate both robust optimization and statistical robustness, showing that both types of robustness are synergistic. For robust optimization we use an improved version of unscented Bayesian optimization which provides safe and repeatable policies in the presence of policy uncertainty. We also provide new theoretical insights. For statistical robustness, we use an adaptive surrogate model and we introduce the Boltzmann selection as a stochastic acquisition method to have convergence guarantees and improved performance even with surrogate modeling errors. We present results in several optimization benchmarks and robot tasks.",
        "DOI": "10.1109/LRA.2021.3060408",
        "affiliation_name": "Universidad de Zaragoza",
        "affiliation_city": "Zaragoza",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "The spectral treasure house of miniaturized instruments for food safety, quality and authenticity applications: A perspective",
        "paper_author": "Müller-Maatsch J.",
        "publication": "Trends in Food Science and Technology",
        "citied_by": "23",
        "cover_date": "2021-04-01",
        "Abstract": "Background: Optical technologies, relying on spectral analysis, are more and more implemented in portable devices for food analysis. Thereby, each food safety, quality or authenticity provision as well as each technology requires the generation of a dedicated spectral database with reference data. Currently, knowledge on how these databases might be connected or transferred across food commodities, targeted compounds or devices are very limited. Hence, repetitive work is conducted and technologies are not optimally used. Scope and approach: This perspective focuses on the currently available technologies and approaches for data handling and database transfer across miniaturized devices and technologies for food safety, quality and authenticity assessments. Key findings and conclusions: For almost every food commodity or target compound a miniaturized spectroscopic device can be applied with the respective database to compare findings. Recent developments in optical spectroscopy allow more possibilities for their use as well as facilitate the production of portable devices. A multifunctional device hyphenating several sensors and broadening the application range is still not marketed. Newly developed software architecture, accessing and extracting data, helps to overcome sample heterogenicity or spurious measured data. In addition, several data fusion approaches using machine learning and deep learning strategies are available to fuse spectroscopic data with itself or other non-spectroscopic data. Following the research results presented in this field, spectral data can possibly be re-used and shared across instruments and locations, highly increasing the applicability of data sets. Thereby, obstacles such as policy or confidentiality are taken into account.",
        "DOI": "10.1016/j.tifs.2021.01.091",
        "affiliation_name": "Institute for Photonics and Nanotechnologies, Rome",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "“Coronavation: Keep Calm, and Carry On”",
        "paper_author": "Seales W.B.",
        "publication": "Surgical Innovation",
        "citied_by": "0",
        "cover_date": "2021-04-01",
        "Abstract": "In this essay, I summarize a few ideas inspired by my involvement in the “Coronavation” working group, which spanned 2020’s COVID-19 crisis. Health-care practitioners, computer scientists, and engineers alike, we strive to meet the challenges associated with practice under threat of pandemic with the same ideals driving the rapid, positive developments in health care today: innovation, collaboration and technology convergence, and acquisition of valuable data that leads to better approaches and new ideas. The ideas sketched here, forged by the need for practical pandemic responses, are rooted in those ideals.",
        "DOI": "10.1177/1553350621997781",
        "affiliation_name": "Stanley and Karen Pigman College of Engineering",
        "affiliation_city": "Lexington",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "TAMPC: A Controller for Escaping Traps in Novel Environments",
        "paper_author": "Zhong S.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "5",
        "cover_date": "2021-04-01",
        "Abstract": "We propose an approach to online model adaptation and control in the challenging case of hybrid and discontinuous dynamics where actions may lead to difficult-to-escape 'trap' states, under a given controller. We first learn dynamics for a system without traps from a randomly collected training set (since we do not know what traps will be encountered online). These 'nominal' dynamics allow us to perform tasks in scenarios where the dynamics matches the training data, but when unexpected traps arise in execution, we must find a way to adapt our dynamics and control strategy and continue attempting the task. Our approach, Trap-Aware Model Predictive Control (TAMPC), is a two-level hierarchical control algorithm that reasons about traps and non-nominal dynamics to decide between goal-seeking and recovery policies. An important requirement of our method is the ability to recognize nominal dynamics even when we encounter data that is out-of-distribution w.r.t the training data. We achieve this by learning a representation for dynamics that exploits invariance in the nominal environment, thus allowing better generalization. We evaluate our method on simulated planar pushing and peg-in-hole as well as real robot peg-in-hole problems against adaptive control, reinforcement learning, trap-handling baselines, where traps arise due to unexpected obstacles that we only observe through contact. Our results show that our method outperforms the baselines on difficult tasks, and is comparable to prior trap-handling methods on easier tasks.",
        "DOI": "10.1109/LRA.2021.3057789",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Improving efficiency of training a virtual treatment planner network via knowledge-guided deep reinforcement learning for intelligent automatic treatment planning of radiotherapy",
        "paper_author": "Shen C.",
        "publication": "Medical Physics",
        "citied_by": "20",
        "cover_date": "2021-04-01",
        "Abstract": "Purpose: We previously proposed an intelligent automatic treatment planning framework for radiotherapy, in which a virtual treatment planner network (VTPN) is built using deep reinforcement learning (DRL) to operate a treatment planning system (TPS) by adjusting treatment planning parameters in it to generate high-quality plans. We demonstrated the potential feasibility of this idea in prostate cancer intensity-modulated radiation therapy (IMRT). Despite the success, the process to train a VTPN via the standard DRL approach with an ϵ-greedy algorithm was time-consuming. The required training time was expected to grow with the complexity of the treatment planning problem, preventing the development of VTPN for more complicated but clinically relevant scenarios. In this study, we proposed a novel knowledge-guided DRL (KgDRL) approach that incorporated knowledge from human planners to guide the training process to improve the efficiency of training a VTPN. Method: Using prostate cancer IMRT as a test bed, we first summarized a number of rules in the actions of adjusting treatment planning parameters of our in-house TPS. During the training process of VTPN, in addition to randomly navigating the large state-action space, as in the standard DRL approach using the ϵ-greedy algorithm, we also sampled actions defined by the rules. The priority of sampling actions from rules decreased over the training process to encourage VTPN to explore new policy on parameter adjustment that were not covered by the rules. To test this idea, we trained a VTPN using KgDRL and compared its performance with another VTPN trained using the standard DRL approach. Both networks were trained using 10 training patient cases and five additional cases for validation, while another 59 cases were employed for the evaluation purpose. Results: It was found that both VTPNs trained via KgDRL and standard DRL spontaneously learned how to operate the in-house TPS to generate high-quality plans, achieving plan quality scores of 8.82 (±0.29) and 8.43 (±0.48), respectively. Both VTPNs outperformed treatment planning purely based on the rules, which had a plan score of 7.81 (±1.59). VTPN trained with eight episodes using KgDRL was able to perform similar to that trained using DRL with 100 epochs. The training time was reduced from more than a week to ~13 hrs. Conclusion: The proposed KgDRL framework was effective in accelerating the training process of a VTPN by incorporating human knowledge, which will facilitate the development of VTPN for more complicated treatment planning scenarios.",
        "DOI": "10.1002/mp.14712",
        "affiliation_name": "UT Southwestern Medical School",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modeling and forecasting number of confirmed and death caused COVID-19 in IRAN: A comparison of time series forecasting methods",
        "paper_author": "Talkhi N.",
        "publication": "Biomedical Signal Processing and Control",
        "citied_by": "56",
        "cover_date": "2021-04-01",
        "Abstract": "Background: The COVID-19 pandemic conditions are still prevalent in Iran and other countries and the monitoring system is gradually discovering new cases every day. Therefore, it is a cause for concern around the world, and forecasting the number of future patients and death cases, although not entirely accurate, helps the governments and health-policy makers to make the necessary decisions and impose restrictions to reduce prevalence. Methods: In this study, we aimed to find the best model for forecasting the number of confirmed and death cases in Iran. For this purpose, we applied nine models including NNETAR, ARIMA, Hybrid, Holt-Winter, BSTS, TBATS, Prophet, MLP, and ELM network models. The quality of forecasting models is evaluated by three performance metrics, RMSE, MAE, and MAPE. The best model is selected by the lowest value of performance metrics. Then, the number of confirmed and the death cases forecasted for the 30 next days. The used data in this study is the absolute number of confirmed, death cases from February 20 to August 15, 2020. Results: Our findings suggested that based on existing data in Iran, the suitable model with the lowest performance metrics for confirmed cases data obtained MLP network and the Holt-Winter model is the suitable model for forecasting death cases in the future. These models forecasted on September 14, 2020, we will have 2484 new confirmed and 114 new death cases of COVID-19. Conclusion: According to the results of this study and the existing data, we concluded that the MLP and Holt-Winter models had the lowest error in forecasting in comparison to other methods. Some models had fitted poorly in the test phase and this is because many other factors that are either not available or have been ignored in this study and can affect the accuracy of forecast results. Based on the trend of data and forecast results, the number of confirmed cases and death cases are almost constant and decreasing, respectively. However, due to disease progression and ignoring the recommendations and protocols of the Ministry of health, there is a possibility of re-emerging this disease more seriously in Iran and this requires more preventive care.",
        "DOI": "10.1016/j.bspc.2021.102494",
        "affiliation_name": "School of Health",
        "affiliation_city": "Mashhad",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Robot learning with crash constraints",
        "paper_author": "Marco A.",
        "publication": "IEEE Robotics and Automation Letters",
        "citied_by": "20",
        "cover_date": "2021-04-01",
        "Abstract": "In the past decade, numerous machine learning algorithms have been shown to successfully learn optimal policies to control real robotic systems. However, it is common to encounter failing behaviors as the learning loop progresses. Specifically, in robot applications where failing is undesired but not catastrophic, many algorithms struggle with leveraging data obtained from failures. This is usually caused by (i) the failed experiment ending prematurely, or (ii) the acquired data being scarce or corrupted. Both complicate the design of proper reward functions to penalize failures. In this letter, we propose a framework that addresses those issues. We consider failing behaviors as those that violate a constraint and address the problem of learning with crash constraints, where no data is obtained upon constraint violation. The no-data case is addressed by a novel GP model (GPCR) for the constraint that combines discrete events (failure/success) with continuous observations (only obtained upon success). We demonstrate the effectiveness of our framework on simulated benchmarks and on a real jumping quadruped, where the constraint threshold is unknown a priori. Experimental data is collected, by means of constrained Bayesian optimization, directly on the real robot. Our results outperform manual tuning and GPCR proves useful on estimating the constraint threshold.",
        "DOI": "10.1109/LRA.2021.3057055",
        "affiliation_name": "Max Planck Institute for Intelligent Systems",
        "affiliation_city": "Tubingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Farmer typology and implications for policy design – An unsupervised machine learning approach",
        "paper_author": "Graskemper V.",
        "publication": "Land Use Policy",
        "citied_by": "43",
        "cover_date": "2021-04-01",
        "Abstract": "Within the European Union, there is currently a vivid debate about the European Green Deal with its Farm to Fork Strategy and the related future design of the Common Agricultural Policy post 2020. This paper contributes to this debate by providing a clustering of German farmers analysing objective data (N = 812) using Partitioning Around Medoids (PAM) as a crucial pre-requisite for an effective design and communication of future agricultural policies. Accordingly, German farmers can be clustered into three different groups. The conventional growers are the oldest group of farmers, showing the highest land growth rate, and are characterized by a focus on traditional and politically subsidised activities. The versatile youngsters are rather young in age and the majority of them have completed some form of higher education. Their business profile is diverse. The third group of family-based farmers has the highest shares of family support within their farming business and consists mostly of dairy farmers. Policy and communication design needs to consider all these different profiles. Especially new and innovative programs could be developed and tested together with the versatile youngsters. Furthermore, aspects ensuring an effective and economically rewarding production of agricultural goods should be taken into account to offer a perspective for the conventional growers and for food security. Moreover, the family-based farmers constitute a promising target group for rural development programs.",
        "DOI": "10.1016/j.landusepol.2021.105328",
        "affiliation_name": "Georg-August-Universität Göttingen",
        "affiliation_city": "Gottingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Monetary policy spillovers under intermediate exchange rate regimes",
        "paper_author": "Ahmed R.",
        "publication": "Journal of International Money and Finance",
        "citied_by": "6",
        "cover_date": "2021-04-01",
        "Abstract": "Testing the international Trilemma traditionally relies on discretely classified exchange rate regimes. This simplification limits the implications drawn for middle-ground policies like managed floats or basket pegs, and inhibits inference on the empirical shape of the exchange rate stability – monetary autonomy trade-off. To address these issues, this paper proposes a continuous measure of exchange rate flexibility for estimating monetary policy spillovers along the entire spectrum of peg intensities. Monetary spillovers generally increase with exchange rate stability, even within middle ground policies, and basket pegs diversify such spillovers. I then estimate the empirical shape of the trade-off using machine learning techniques, finding that the relationship between monetary autonomy and exchange rate stability is significantly non-linear in both advanced economies and emerging markets. Specifically, partially targeting the exchange rate translates to disproportionately smaller or larger monetary spillovers along middle-ground exchange rate regimes. For emerging markets in particular, active reserves management is a key mechanism associated with these non-linearities.",
        "DOI": "10.1016/j.jimonfin.2020.102342",
        "affiliation_name": "University of Southern California",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "THE INTELLECTUAL IDEAS INSIDE CENTRAL BANKS: WHAT'S CHANGED (OR NOT) SINCE THE CRISIS?",
        "paper_author": "Windsor C.",
        "publication": "Journal of Economic Surveys",
        "citied_by": "4",
        "cover_date": "2021-04-01",
        "Abstract": "I explore how the intellectual ideas inside central banks have shifted over the first two decades of the new century. To do this I collect every research paper published by advanced economy central banks and examine them using tools from computational linguistics. The analysis points to a shift in the intellectual focus, from a relatively macroeconomic perspective towards a less aggregated view. In part, these changes seem to reflect lessons from the 2008 financial crisis – for example, that macroeconomic models can only get you so far and that microeconomic data are useful for teasing out the causes of aggregate fluctuations. There has been an increase in the amount of research dedicated to the banking and household sectors and a reduction in the amount of intellectual effort invested in modelling the macroeconomy – though some of these shifts had already begun before the crisis. Consistent with this, the similarity of central banking research to that published in top macroeconomic journals has been widening since the crisis.",
        "DOI": "10.1111/joes.12413",
        "affiliation_name": "Reserve Bank of Australia",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "An Online Policy for Energy-Efficient State Control of Manufacturing Equipment",
        "paper_author": "Frigerio N.",
        "publication": "IEEE Transactions on Automation Science and Engineering",
        "citied_by": "8",
        "cover_date": "2021-04-01",
        "Abstract": "Machine state control is one of the most promising energy-efficient measures for machining processes. A proper control reduces the energy consumed during idle periods by switching off/on the machines. A critical barrier for practical implementation is related to the knowledge of part arrival process that is affected by uncertainty. The stochastic processes involved in the system are usually assumed to be known. However, real production environments are subject to several sources of randomness that are difficult to model a priori. This work provides an online time-based algorithm that is able to control the machine state. Through a method for the estimation of the stochastic process, the algorithm provides the optimal control parameters based on a collected set of observations. A new policy is formulated to manage the control over time such that changes in the control parameters are applied only under certain conditions. Potential benefits are discussed using realistic numerical cases. Note to Practitioners-This article analyzes the control problem of switching off/on a machine tool for energy saving during machine idle periods. A control policy based on time information is investigated when the machine requires a startup time to resume the service after being switched off. The proposed policy works online while acquiring information from the real system. An algorithm is described for identifying and applying the optimal control parameters. The results of this research will be useful for a practical implementation of a switching policy for energy saving. This implementation requires the estimation of the power adsorbed by the machine in four different states and, therefore, it reduces the implementation effort for practitioners.",
        "DOI": "10.1109/TASE.2020.3044107",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Modeling and predicting city-level CO<inf>2</inf> emissions using open access data and machine learning",
        "paper_author": "Li Y.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "23",
        "cover_date": "2021-04-01",
        "Abstract": "Globally, urban has been the major contributor to greenhouse gas (GHG) emissions and thus plays an increasingly important role in its efforts to reduce CO2 emissions. However, quantifying city-level CO2 emissions is generally a difficult task due to lacking or lower quality of energy-related statistics data, especially for some underdeveloped areas. To address this issue, this study used a set of open access data and machine learning methods to estimate and predict city-level CO2 emissions across China. Two feature selection technologies including Recursive Feature Elimination and Boruta were used to extract the important critical variables and input parameters for modeling CO2 emissions. Finally, 18 out of 31 predictor variables were selected to establish prediction models of CO2 emissions. We found that the statistical indicators of urban environment pollution (such as industrial SO2 and dust emissions per capita) are the most important variables for predicting the city-level CO2 emissions in China. The XGBoost models obtained the highest estimation accuracy with R2 > 0.98 and lower relative error (about 0.8%) than other methods. The CO2 emissions predictive accuracy can be improved modestly by combing geospatial and meteorological interpolation predictor variables (e.g., DEM, annual average precipitation, and air temperature). We also observed an S-shape relationship between urban CO2 emissions per capita and urban economic growth when the rest variables were held constant, rather than a U-shaped one. The findings presented herein provide a first proof of concept that easily available socioeconomic statistical records and geospatial data at urban areas have the potential to accurately predict city-level CO2 emissions with the aid of machine learning algorithms. Our approach can be used to generate carbon footprint maps frequently for the undeveloped regions with scarce detailed energy-related statistical data, to assist policy-makers in designing specific measures of reducing and allocating carbon emissions reduction goal.",
        "DOI": "10.1007/s11356-020-12294-7",
        "affiliation_name": "Heilongjiang University of Science and Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A comparative study of patient and staff safety evaluation using tree-based machine learning algorithms",
        "paper_author": "Simsekler M.C.E.",
        "publication": "Reliability Engineering and System Safety",
        "citied_by": "24",
        "cover_date": "2021-04-01",
        "Abstract": "Medical errors constitute a significant challenge affecting patient and staff safety in complex and dynamic healthcare systems. While vv v various organizational factors may contribute to such errors, limited studies have addressed patient and staff safety issues simultaneously in the same study setting. To evaluate this, we conduct an exploratory analysis using two types of tree-based machine learning algorithms, random forests and gradient boosting, and the hospital-level aggregate staff experience survey data from UK hospitals. Based on staff views and priorities, the results from both algorithms suggest that “health and wellbeing” is the leading theme associated with the number of reported errors and near misses harming patient and staff safety. Specifically, “work-related stress” is the most important survey item associated with safety outcomes. With respect to prediction accuracy, both algorithms provide similar results with comparable values in error metrics. Based on the analytical results, healthcare risk managers and decision-makers can develop and implement policies and practices that address staff experience and prioritize resources effectively to improve patient and staff safety.",
        "DOI": "10.1016/j.ress.2020.107416",
        "affiliation_name": "School of Business Administration",
        "affiliation_city": "Sharjah",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Impact of teachers’ grading policy on the identification of at-risk students in learning analytics",
        "paper_author": "Lu O.H.T.",
        "publication": "Computers and Education",
        "citied_by": "21",
        "cover_date": "2021-04-01",
        "Abstract": "The purpose of learning analytics is to promote student success in the classroom. To implement the framework of learning analytics, researchers have adopted machine learning methodologies to identify at-risk students at an early stage. In theory, machine learning is a mathematical algorithm that improves automation through experience. The experience is the data collected from online learning platforms, and in general, the data contain various features such as the number of times that a student accesses the learning material each week. Relevant studies have demonstrated extremely high accuracy in identifying at-risk students using identification models trained by machine learning. However, numerous details and data challenges have been overlooked in prior studies, calling into question the accuracy of past contributions. In this study, we focused on one type of data challenge: data imbalance. The data imbalance problems in education are usually the result of teachers’ grading policy. To highlight the seriousness of this issue, we collected data from 12 blended learning courses and summarized 3 types of grading policies: discrimination, stringency, and leniency. We then provided evidence that the leniency strategy causes the illusion of high accuracy of at-risk student identification. Finally, we verified a robust method to address the effectiveness of the leniency strategy, and using these results, we summarized the characteristics of students who tend to be misidentified by machine learning methodology.",
        "DOI": "10.1016/j.compedu.2020.104109",
        "affiliation_name": "National Pingtung University",
        "affiliation_city": "Pingtung",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Methodological considerations in MVC epidemiological research",
        "paper_author": "Fridman L.",
        "publication": "Injury Prevention",
        "citied_by": "2",
        "cover_date": "2021-04-01",
        "Abstract": "Background The global burden of MVC injuries and deaths among vulnerable road users, has led to the implementation of prevention programmes and policies at the local and national level. MVC epidemiological research is key to quantifying MVC burden, identifying risk factors and evaluating interventions. There are, however, several methodological considerations in MVC epidemiological research. Methods This manuscript collates and describes methodological considerations in MVC epidemiological research, using examples drawn from published studies, with a focus on the vulnerable road user population of children and adolescents. Results Methodological considerations in MVC epidemiological research include the availability and quality of data to measure counts and calculate event rates and challenges in evaluation related to study design, measurement and statistical analysis. Recommendations include innovative data collection (eg, naturalistic design, stepped-wedge clinical trials), combining data sources for a more comprehensive representation of collision events, and the use of machine learning/artificial intelligence for large data sets. Conclusions MVC epidemiological research can be challenging at all levels: data capture and quality, study design, measurement and analysis. Addressing these challenges using innovative data collection and analysis methods is required.",
        "DOI": "10.1136/injuryprev-2020-043987",
        "affiliation_name": "SickKids Research Institute",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Estimation of Surface Moisture Content using Sentinel-1 C-band SAR Data Through Machine Learning Models",
        "paper_author": "Datta S.",
        "publication": "Journal of the Indian Society of Remote Sensing",
        "citied_by": "18",
        "cover_date": "2021-04-01",
        "Abstract": "Monitoring the spatio-temporal variation in soil moisture content (SMC) of the surface soil layer is essential for agriculture and water resource management activities, especially in regions where the socio-economic condition and livelihood depend upon agriculture and allied sectors. In the present study, we have compared different machine learning (ML) and linear regression models to estimate the SMC integrating field observed soil moisture and Sentinel-1 SAR data. Total 56 soil samples were collected from the surface soil layer (~ 5 cm) in correspondence with the passing date of the Sentinel-1 sensor over the study area. The surface SMC was estimated for bare soil areas, which was extracted by applying the threshold values on vegetation and water index maps derived from the Sentinel-2 multispectral data. The univariate linear regression with the co-polarized VV band provided higher accuracy compared to the cross-polarized VH band. However, the multiple linear regression with VV and VH bands indicated similar accuracy as obtained by the VV band alone. The random forest model was observed as the best performing ML model for soil moisture estimation (R2 = 0.87 and 0.93 during modeling and validation, respectively; RMSE: ~ 0.03). The obtained results indicate well accurate surface soil moisture verified with in-situ information collected during the dry rabi crop season (January to March 2019). The maximum SMC was observed for March, followed by February and January, that corroborated with the total monthly precipitation and irrigation activities. The study highlights the potentiality of ML models and Sentinel-1 SAR data for soil moisture estimation, which is useful for policy-level implications and decision making in agriculture and water resource management activities.",
        "DOI": "10.1007/s12524-020-01261-x",
        "affiliation_name": "Vidyasagar University",
        "affiliation_city": "Purba Midnapore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Minimizing the global warming impact of pavement infrastructure through reinforcement learning",
        "paper_author": "Renard S.",
        "publication": "Resources, Conservation and Recycling",
        "citied_by": "37",
        "cover_date": "2021-04-01",
        "Abstract": "Life cycle assessment (LCA) studies are frequently used to evaluate the environmental burdens of pavement facilities. This information can be used by decision-makers to advise their construction and maintenance policies. Within the pavement life cycle, there are a variety of uncertainties, such as future traffic growth and pavement deterioration. Currently, there is a lack of research examining the use of LCA models that can simultaneously optimize construction and maintenance plans while accounting for several sources of uncertainty. This study presents an approach to LCA modeling that implements a sub-type of reinforcement learning (RL) algorithms called Q-learning. Q-learning offers a model-free approach that can efficiently manage stochastic problems of parametric and non-parametric form. The algorithm iteratively learns a set of near-optimal decision rules to proactively manage pavement assets for a diverse range of possible future scenarios. These decision-rules are stored in a convenient look-up table, which will appeal to practitioners for its ease of use in probabilistic LCA studies. This paper subsequently tests the performance of the Q-learning approach across three representative case studies with varying traffic volumes: a local street-highway, a state highway, and an interstate. The case study results show that, on average, the proposed algorithm reduces the expected global warming impact of pavement infrastructure between 13% and 18% over a 50-year analysis period. Based on our results, Q-learning is a promising approach that can help decision-makers account for several sources of uncertainty and implement improved management strategies to mitigate the environmental impacts of their products and systems.",
        "DOI": "10.1016/j.resconrec.2020.105240",
        "affiliation_name": "The University of British Columbia",
        "affiliation_city": "Vancouver",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Crop yield prediction in cotton for regional level using random forest approach",
        "paper_author": "Prasad N.R.",
        "publication": "Spatial Information Research",
        "citied_by": "94",
        "cover_date": "2021-04-01",
        "Abstract": "Early and precise estimation of crop yield plays a crucial role in quantitative and financial assessment at field level, to lay down strategic plans for import–export policies for agricultural commodities and to doubling the income of farmers. In this study, a machine learning based random forest (RF) algorithm was used to predicate cotton yield at three distinct times before the actual harvest in the state of Maharashtra in India using R package. Long-term agromet-spectral variables derived from multi-sensor satellites with actual crop yield from 2001 to 2017, were used to generate co-linearity of predictor variables and further, calibrate and validate the RF model. The performance of the RF model was found reliable and faster in predicting the crop yield with the most influencing variables with 69%, 60% and 39% of coefficient of determination (R2) in the final yield for September, December and February months, respectively using CART decision tree and recursive feature elimination method in R programming. Results showed as RF algorithm has the capability to integrate and process a large number of inputs as derived from different satellite modalities, unscaled and non-uniform ground based information, expert knowledge, etc. With high precision and avoid over fitting of the model.",
        "DOI": "10.1007/s41324-020-00346-6",
        "affiliation_name": "Indian Institute of Remote Sensing",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A novel scheme for employee churn problem using multi-attribute decision making approach and machine learning",
        "paper_author": "Jain N.",
        "publication": "Journal of Intelligent Information Systems",
        "citied_by": "45",
        "cover_date": "2021-04-01",
        "Abstract": "Employee churn (ECn) is a crucial problem for any organization that adversely affects its overall revenue and brand image. Many machine learning (ML) based systems have been developed to solve the ECn problem. However, they miss out on some essential issues such as employee categorization, category-wise churn prediction, and retention policy for effectively addressing the ECn problem. By considering all these issues, we propose, in this paper, a multi-attribute decision making (MADM) based scheme coupled with ML algorithms. The proposed scheme is referred as employee churn prediction and retention (ECPR). We first design an accomplishment-based employee importance model (AEIM) that utilizes a two-stage MADM approach for grouping the employees in various categories. Preliminarily, we formulate an improved version of the entropy weight method (IEWM) for assigning relative weights to the employee accomplishments. Then, we utilize the technique for order preference by similarity to ideal solution (TOPSIS) for quantifying the importance of the employees to perform their class-based categorization. The CatBoost algorithm is then applied for predicting class-wise employee churn. Finally, we propose a retention policy based on the prediction results and ranking of the features. The proposed ECPR scheme is tested on a benchmark dataset of the human resource information system (HRIS), and the results are compared with other ML algorithms using various performance metrics. We show that the system using the CatBoost algorithm outperforms other ML algorithms.",
        "DOI": "10.1007/s10844-020-00614-9",
        "affiliation_name": "Indian Institute of Technology (Indian School of Mines), Dhanbad",
        "affiliation_city": "Dhanbad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "RIS Enhanced Massive Non-Orthogonal Multiple Access Networks: Deployment and Passive Beamforming Design",
        "paper_author": "Liu X.",
        "publication": "IEEE Journal on Selected Areas in Communications",
        "citied_by": "154",
        "cover_date": "2021-04-01",
        "Abstract": "A novel framework is proposed for the deployment and passive beamforming design of a reconfigurable intelligent surface (RIS) with the aid of non-orthogonal multiple access (NOMA) technology. The problem of joint deployment, phase shift design, as well as power allocation in the multiple-input-single-output (MISO) NOMA network is formulated for maximizing the energy efficiency with considering users particular data requirements. To tackle this pertinent problem, machine learning approaches are adopted in two steps. Firstly, a novel long short-Term memory (LSTM) based echo state network (ESN) algorithm is proposed to predict users' tele-Traffic demand by leveraging a real dataset. Secondly, a decaying double deep Q-network (D3QN) based position-Acquisition and phase-control algorithm is proposed to solve the joint problem of deployment and design of the RIS. In the proposed algorithm, the base station, which controls the RIS by a controller, acts as an agent. The agent periodically observes the state of the RIS-enhanced system for attaining the optimal deployment and design policies of the RIS by learning from its mistakes and the feedback of users. Additionally, it is proved that the proposed D3QN based deployment and design algorithm is capable of converging within mild conditions. Simulation results are provided for illustrating that the proposed LSTM-based ESN algorithm is capable of striking a tradeoff between the prediction accuracy and computational complexity. Finally, it is demonstrated that the proposed D3QN based algorithm outperforms the benchmarks, while the NOMA-enhanced RIS system is capable of achieving higher energy efficiency than orthogonal multiple access (OMA) enabled RIS system.",
        "DOI": "10.1109/JSAC.2020.3018823",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Aggregate density-based concept drift identification for dynamic sensor data models",
        "paper_author": "Asghari M.",
        "publication": "Neural Computing and Applications",
        "citied_by": "4",
        "cover_date": "2021-04-01",
        "Abstract": "The reduced costs of embedded systems and sensor technology coupled with the increased speed in communication enables businesses and consumers to deploy a large number of sensing devices. This conjunction of technologies has come to be known as the Internet of Things (IoT). Data collected from IoT devices are continuously increasing, and many approaches have been proposed to deal with the big data that is now generated. Multiple artificial intelligent techniques have been proposed and used to extract knowledge out of these continuously growing datasets. In this paper, we demonstrate that a better understanding of data can be achieved through dynamic modeling. This dynamic behavior is observed in many practical scenarios and needs to be taken into account to have a higher accuracy in prediction and analysis for policy making and business-related decisions. We propose and test a novel methodology to detect the dynamic nature of data over time. Machine learning models have been known to suffer from changes in streaming data over time which is defined as concept drift and therefore by detecting this phenomena such models can be improved.",
        "DOI": "10.1007/s00521-020-05190-1",
        "affiliation_name": "J.B. Speed School of Engineering",
        "affiliation_city": "Louisville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Combining experimental evidence with machine learning to assess anti-corruption educational campaigns among Russian university students",
        "paper_author": "Denisova-Schmidt E.",
        "publication": "Empirical Economics",
        "citied_by": "8",
        "cover_date": "2021-04-01",
        "Abstract": "This paper examines how anti-corruption educational campaigns affect the attitudes of Russian university students toward corruption and academic integrity in the short run. About 2000 survey participants were randomly assigned to one of four different information materials (brochures or videos) about the negative consequences of corruption or to a control group. While we do not find important effects in the full sample, applying machine learning methods for detecting effect heterogeneity suggests that some subgroups of students might react to the same information differently, albeit statistical significance mostly vanishes when accounting for multiple hypotheses testing. Taking the point estimates at face value, students who commonly plagiarize appear to develop stronger negative attitudes toward corruption in the aftermath of our intervention. Unexpectedly, some information materials seem inducing more tolerant views on corruption among those who plagiarize less frequently and in the group of male students, while the effects on female students are generally close to zero. Therefore, policy makers aiming to implement anti-corruption education at a larger scale should scrutinize the possibility of (undesired) heterogeneous effects across student groups.",
        "DOI": "10.1007/s00181-020-01827-1",
        "affiliation_name": "Boston College",
        "affiliation_city": "Chestnut Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Artificial Intelligence (AI): Multidisciplinary perspectives on emerging challenges, opportunities, and agenda for research, practice and policy",
        "paper_author": "Dwivedi Y.K.",
        "publication": "International Journal of Information Management",
        "citied_by": "1841",
        "cover_date": "2021-04-01",
        "Abstract": "As far back as the industrial revolution, significant development in technical innovation has succeeded in transforming numerous manual tasks and processes that had been in existence for decades where humans had reached the limits of physical capacity. Artificial Intelligence (AI) offers this same transformative potential for the augmentation and potential replacement of human tasks and activities within a wide range of industrial, intellectual and social applications. The pace of change for this new AI technological age is staggering, with new breakthroughs in algorithmic machine learning and autonomous decision-making, engendering new opportunities for continued innovation. The impact of AI could be significant, with industries ranging from: finance, healthcare, manufacturing, retail, supply chain, logistics and utilities, all potentially disrupted by the onset of AI technologies. The study brings together the collective insight from a number of leading expert contributors to highlight the significant opportunities, realistic assessment of impact, challenges and potential research agenda posed by the rapid emergence of AI within a number of domains: business and management, government, public sector, and science and technology. This research offers significant and timely insight to AI technology and its impact on the future of industry and society in general, whilst recognising the societal and industrial influence on pace and direction of AI development.",
        "DOI": "10.1016/j.ijinfomgt.2019.08.002",
        "affiliation_name": "University of Bradford School of Management",
        "affiliation_city": "Bradford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Big Brain Data: On the Responsible Use of Brain Data from Clinical and Consumer-Directed Neurotechnological Devices",
        "paper_author": "Kellmeyer P.",
        "publication": "Neuroethics",
        "citied_by": "54",
        "cover_date": "2021-04-01",
        "Abstract": "The focus of this paper are the ethical, legal and social challenges for ensuring the responsible use of “big brain data”—the recording, collection and analysis of individuals’ brain data on a large scale with clinical and consumer-directed neurotechnological devices. First, I highlight the benefits of big data and machine learning analytics in neuroscience for basic and translational research. Then, I describe some of the technological, social and psychological barriers for securing brain data from unwarranted access. In this context, I then examine ways in which safeguards at the hardware and software level, as well as increasing “data literacy” in society, may enhance the security of neurotechnological devices and protect the privacy of personal brain data. Regarding ethical and legal ramifications of big brain data, I first discuss effects on the autonomy, the sense of agency and authenticity, as well as the self that may result from the interaction between users and intelligent, particularly closed-loop, neurotechnological devices. I then discuss the impact of the “datafication” in basic and clinical neuroscience research on the just distribution of resources and access to these transformative technologies. In the legal realm, I examine possible legal consequences that arises from the increasing abilities to decode brain states and their corresponding subjective phenomenological experiences on the hitherto inaccessible privacy of these information. Finally, I discuss the implications of big brain data for national and international regulatory policies and models of good data governance.",
        "DOI": "10.1007/s12152-018-9371-x",
        "affiliation_name": "Universität Freiburg",
        "affiliation_city": "Freiburg im Breisgau",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "An intelligent control plane for security services deployment in SDN-based networks",
        "paper_author": "Mbaye M.",
        "publication": "Intelligent Network Management and Control: Intelligent Security, Multi-criteria Optimization, Cloud Computing, Internet of Vehicles, Intelligent Radio",
        "citied_by": "0",
        "cover_date": "2021-03-26",
        "Abstract": "The software-defined networking (SDN) approach involves the management of a network infrastructure by software applications. In classical networks, machine learning (ML) and artificial intelligence (AI) have generally proved their effectiveness for security. The concept of an SDN-based network was created in order to meet the challenges related to network development. This chapter aims to approach AI-based intelligent control techniques that enable an intelligent management of security deployment. It presents ML techniques that are most commonly used for security purposes. This is followed by an example of intrusion detection systems as an illustration of AI contribution to the SDN security field. Network administrators implement IDS to avoid intrusion attacks and apply the network security policy. An IDS monitors the traffic and sends intrusion alerts to the administrator console when a suspicious message is detected. The stakes of using AI and ML tools for security management in SDN-based networks are very high.",
        "DOI": "10.1002/9781119817840.ch2",
        "affiliation_name": "IMT Atlantique",
        "affiliation_city": "Nantes",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Intelligent security of computer networks",
        "paper_author": "Semmoud A.",
        "publication": "Intelligent Network Management and Control: Intelligent Security, Multi-criteria Optimization, Cloud Computing, Internet of Vehicles, Intelligent Radio",
        "citied_by": "0",
        "cover_date": "2021-03-26",
        "Abstract": "Artificial intelligence (AI) and machine learning have rapidly progressed in recent years, facilitating the development of a broad range of applications. AI is a broad domain to be explored by cybersecurity researchers and experts. As the capacity of intelligent systems increases, they will first reach and then surpass human capacities in many fields. Intrusion detection is defined as the process of intelligent monitoring of events occurring in a computer system or network and their analysis in search for signs of security policy breach. Fuzzy logic has been used in the field of computer networks security, particularly for intrusion detection, for two main reasons. First, several quantitative parameters used in the context of intrusion detection, for example processor use time and connection interval, can be potentially considered as fuzzy variables. Second, the security concept is itself fuzzy.",
        "DOI": "10.1002/9781119817840.ch1",
        "affiliation_name": "Université Abou Bekr Belkaid Tlemcen",
        "affiliation_city": "Tlemcen",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "Learning media development based on CNC simulator as the digital tool to support the CNC practice learning during COVID-19 new normal",
        "paper_author": "Suyetno A.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "2",
        "cover_date": "2021-03-26",
        "Abstract": "Covid-19 pandemic changed human's lifestyle in various areas. Indonesia Government enacted many rules to avoid Covid-19 transmission. The Ministry of Education and Culture issued a policy through a circular regarding the arrangement of learning activities from home during the Covid-19 emergency. Due to the policy, classical in-class learning method changed into virtual through online classes. The CNC simulation makes it possible for students to visualize model and concept into realization. The CNC Simulator is a computer program that could simulate the setting and operation of the CNC machine. The CNC simulator can be used as a digital tool to support the CNC practice learning activity, which was hindered by social activities restrictions during the COVID-19 pandemic. This research used the ADDIE development model, according to Lee and Owens. The stages were: (1) analysis, (2) design, (3) development, (4) implementation, and (5) evaluation. Based on the evaluation, it could be concluded that all five indicators fell into the category of proper to use without revision because on average, they had above 80% score. The final score was 84.25%; thus, learning media based on CNC simulator was proper to sue in the learning activity.",
        "DOI": "10.1088/1742-6596/1833/1/012009",
        "affiliation_name": "Universitas Negeri Malang",
        "affiliation_city": "Malang",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Text Based Hate-Speech Analysis",
        "paper_author": "Sachdeva J.",
        "publication": "Proceedings - International Conference on Artificial Intelligence and Smart Systems, ICAIS 2021",
        "citied_by": "17",
        "cover_date": "2021-03-25",
        "Abstract": "The definition of the term 'hate speech' as per Oxford is 'a speech that might involve abusive or threatening words which can have or can express pre-bias against a special community/group. This pre-bias can be anything like religion, race or sexual orientation, caste.' Hatred is generally based on ethnicity, religion, disability, gender, caste, and sexual orientation the internet and social media has become a powerful tool for such propagandist to spread hate and reach new audience. The anonymity and flexibility that the internet offers allow such haters to easily and safely propagate hate without any fear. Lack of regulation and legal policy worsens the situation a bit more. The need of the hour is for automated state of the art and scalable methods for hate speech detection and classification.This paper introduces two ensemble-based models in which the first one is based on Linear SVC, Logistic Regression, Random Forest and other based on Random Forest, KNN, Logistic Regression. Also, few deep learning models using self-trained and pre-trained word embeddings have been introduced for Twitter hate speech classification systems. The proposed research work has attempted to classify the tweets assign them in one of the 3 categories i.e., Racist, Sexist or None.",
        "DOI": "10.1109/ICAIS50930.2021.9396013",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Building a Resilient, Sustainable, and Healthier Food Supply through Innovation and Technology",
        "paper_author": "McClements D.J.",
        "publication": "Annual Review of Food Science and Technology",
        "citied_by": "66",
        "cover_date": "2021-03-25",
        "Abstract": "The modern food supply faces many challenges. The global population continues to grow and people are becoming wealthier, so the food production system must respond by creating enough high-quality food to feed everyone with minimal damage to our environment. The number of people suffering or dying from diet-related chronic diseases, such as obesity, diabetes, heart disease, stroke, and cancer, continues to rise, which is partly linked to overconsumption of highly processed foods, especially high-calorie or rapidly digestible foods. After falling for many years, the number of people suffering from starvation or malnutrition is rising, and thishas been exacerbated by the global COVID-19 pandemic. The highly integrated food supply chains that spread around the world are susceptible to disruptions due to policy changes, economic stresses, and natural disasters, as highlighted by the recent pandemic. In this perspective article, written by members of the Editorial Committee of the Annual Review of Food Science and Technology, we highlight some of the major challenges confronting the modern food supply chain as well as how innovations in policy and technology can be used to address them. Pertinent technological innovations include robotics, machine learning, artificial intelligence, advanced diagnostics, nanotechnology, biotechnology, gene editing, vertical farming, and soft matter physics. Many of these technologies are already being employed across the food chain by farmers, distributors, manufacturers, and consumers to improve the quality, nutrition, safety, and sustainability of the food supply. These innovations are required to stimulate the development and implementation of new technologies to ensure a more equitable, resilient, and efficient food production system. Where appropriate, these technologies should be carefully tested before widespread implementation so that proper risk-benefit analyses can be carried out. They can then be employed without causing unforeseen adverse consequences. Finally, it is important to actively engage all stakeholders involved in the food supply chain throughout the development and testing of these new technologies to support their adoption if proven safe and effective.",
        "DOI": "10.1146/annurev-food-092220-030824",
        "affiliation_name": "University of Maryland, College Park",
        "affiliation_city": "College Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "How diatom-, invertebrate- and fish-based diagnostic tools can support the ecological assessment of rivers in a multi-pressure context: Temporal trends over the past two decades in France",
        "paper_author": "Alric B.",
        "publication": "Science of the Total Environment",
        "citied_by": "18",
        "cover_date": "2021-03-25",
        "Abstract": "The degradation of aquatic ecosystems, induced by worldwide intensification in the use of both land and aquatic resources, has highlighted the critical need for innovative methods allowing an objective quantification and ranking of anthropogenic pressure effects on aquatic organisms. Such diagnostic tools have a great potential for defining robust management responses to anthropogenic pressures. Our objective was to explore how the outputs of three diagnostic tools (based on benthic diatoms, macroinvertebrates and fishes) could be combined to (i) disentangle the temporal effects of multiple pressures over two decades and (ii) provide policy-relevant information for stream managers and decision makers. The diagnostic tools estimated, using taxonomy- and trait-based metrics, the impairment probabilities of biotic assemblages over time by different pressure categories, describing the alteration of water quality, hydromorphology and land use related to anthropogenic activities, in French streams (number of sites = 312). The main result shows that a large proportion of the time series exhibited no significant temporal patterns over the two decades (61.5% to 87.8%, depending on the used tests). Among time series exhibiting significant change, positive trends in impairment probabilities (i.e., degradation) were less frequent than negative ones, indicating a modest improvement in water quality at national scale over the study period. However, trends can be substantially different according to hydroecoregion and pressure category. The three biological compartments displayed convergent temporal responses according to the pressure category and regional context (e.g., lowland plains vs. mountains, pristine vs. agricultural regions). Altogether, this study proposes a unifying approach to integrate a vast amount of information in a single ecological diagnosis using an unparalleled database on natural and anthropized environments. Strengthening the synthesis of biological information provided by various biological compartments should be a priority before implementing evidence-based sustainable conservation and restoration actions.",
        "DOI": "10.1016/j.scitotenv.2020.143915",
        "affiliation_name": "Université de Lorraine",
        "affiliation_city": "Nancy",
        "affiliation_country": "France"
    },
    {
        "paper_title": "DiffLoop: Tuning PID controllers by differentiating through the feedback loop",
        "paper_author": "Kumar A.R.",
        "publication": "2021 55th Annual Conference on Information Sciences and Systems, CISS 2021",
        "citied_by": "6",
        "cover_date": "2021-03-24",
        "Abstract": "Since most industrial control applications use PID controllers, PID tuning and anti-windup measures are significant problems. This paper investigates tuning the feedback gains of a PID controller via back-calculation and automatic differentiation tools. In particular, we episodically use a cost function to generate gradients and perform gradient descent to improve controller performance. We provide a theoretical framework for analyzing this non-convex optimization and establish a relationship between back-calculation and disturbance feedback policies. We include numerical experiments on linear systems with actuator saturation to show the efficacy of this approach.",
        "DOI": "10.1109/CISS50987.2021.9400299",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "2021 55th Annual Conference on Information Sciences and Systems, CISS 2021",
        "paper_author": "NA",
        "publication": "2021 55th Annual Conference on Information Sciences and Systems, CISS 2021",
        "citied_by": "0",
        "cover_date": "2021-03-24",
        "Abstract": "The proceedings contain 118 papers. The topics discussed include: facilitated deep learning models for image captioning; model-free safe policy learning via hard action barrier functions; exploring blockchain for the coordination of distributed energy resources; anticipatory thinking: a testing and representation challenge for self-driving cars; online optimization with predictions and non-convex losses; enhanced determination of gene groups based on optimal kernel PCA with hierarchical clustering algorithm; mechanism design for large scale network utility maximization; rate of prefix-free codes in LQG control systems with side information; autonomy’s hierarchy of needs: smart city ecosystems for autonomous space habitats; and malware subspecies detection method by suffix arrays and machine learning.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "High-resolution global map of smallholder and industrial closed-canopy oil palm plantations",
        "paper_author": "Descals A.",
        "publication": "Earth System Science Data",
        "citied_by": "112",
        "cover_date": "2021-03-24",
        "Abstract": "Oil seed crops, especially oil palm, are among the most rapidly expanding agricultural land uses, and their expansion is known to cause significant environmental damage. Accordingly, these crops often feature in public and policy debates which are hampered or biased by a lack of accurate information on environmental impacts. In particular, the lack of accurate global crop maps remains a concern. Recent advances in deep-learning and remotely sensed data access make it possible to address this gap.We present a map of closed-canopy oil palm (Elaeis guineensis) plantations by typology (industrial versus smallholder plantations) at the global scale and with unprecedented detail (10m resolution) for the year 2019. The DeepLabv3C model, a convolutional neural network (CNN) for semantic segmentation, was trained to classify Sentinel-1 and Sentinel-2 images onto an oil palm land cover map. The characteristic backscatter response of closed-canopy oil palm stands in Sentinel-1 and the ability of CNN to learn spatial patterns, such as the harvest road networks, allowed the distinction between industrial and smallholder plantations globally (overall accuracyD 98:52_0:20 %), outperforming the accuracy of existing regional oil palm datasets that used conventional machine-learning algorithms. The user's accuracy, reflecting commission error, in industrial and smallholders was 88.22_2.73% and 76.56_4.53 %, and the producer's accuracy, reflecting omission error, was 75.78_3.55% and 86.92_5.12 %, respectively. The global oil palm layer reveals that closed-canopy oil palm plantations are found in 49 countries, covering a mapped area of 19.60 Mha; the area estimate was 21.00_0.42 Mha (72.7% industrial and 27.3% smallholder plantations). Southeast Asia ranks as the main producing region with an oil palm area estimate of 18.69_0.33 Mha or 89% of global closed-canopy plantations. Our analysis confirms significant regional variation in the ratio of industrial versus smallholder growers, but it also confirms that, from a typical land development perspective, large areas of legally defined smallholder oil palm resemble industrial-scale plantings. Since our study identified only closed-canopy oil palm stands, our area estimate was lower than the harvested area reported by the Food and Agriculture Organization (FAO), particularly in West Africa, due to the omission of young and sparse oil palm stands, oil palm in nonhomogeneous settings, and semi-wild oil palm plantations. An accurate global map of planted oil palm can help to shape the ongoing debate about the environmental impacts of oil seed crop expansion, especially if other crops can be mapped to the same level of accuracy. As our model can be regularly rerun as new images become available, it can be used to monitor the expansion of the crop in monocultural settings. The global oil palm layer for the second half of 2019 at a spatial resolution of 10m can be found at.",
        "DOI": "10.5194/essd-13-1211-2021",
        "affiliation_name": "European Commission Joint Research Centre",
        "affiliation_city": "Brussels",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "A causal modelling for desertion and graduation prediction using Bayesian networks: A Chilean case",
        "paper_author": "Peralta B.",
        "publication": "2021 IEEE International Conference on Automation/24th Congress of the Chilean Association of Automatic Control, ICA-ACCA 2021",
        "citied_by": "0",
        "cover_date": "2021-03-22",
        "Abstract": "Currently the high rates of university dropouts and low graduation are social problems that are very relevant in Chilean society. Predicting these events can allow institutions to take action to avoid them. The typical prediction models based on machine learning are capable of making reliable predictions, however they do not allow to understand the causality that originates both events, which could help to take better actions. This work proposes to find, analyze and weigh the causal relationships that allow predicting whether a student will drop out or will graduate according to the information available using a framework with Bayesian networks. The study is based on real data from the Universidad Católica de Temuco in Chile collected over three years. The results reveal variables and relevant relationships according the opinion of human experts, which suggest that the proposed model provides better capabilities to represent the causality of university dropout and graduation. From the results we believe that it is feasible to design better retention policies and timely degree at a university.",
        "DOI": "10.1109/ICAACCA51523.2021.9465333",
        "affiliation_name": "Universidad Católica de Temuco",
        "affiliation_city": "Temuco",
        "affiliation_country": "Chile"
    },
    {
        "paper_title": "Towards Robust Android Malware Detection Models using Adversarial Learning",
        "paper_author": "Rathore H.",
        "publication": "2021 IEEE International Conference on Pervasive Computing and Communications Workshops and other Affiliated Events, PerCom Workshops 2021",
        "citied_by": "7",
        "cover_date": "2021-03-22",
        "Abstract": "Malware analysis and detection is an endless competitive battle between malware designers and the anti-malware community. Recently researchers have proposed state-of-the-art malware detection models built using machine learning and deep learning which are necessary to detect advanced metamorphic malware. But these malware detection models are susceptible to adversarial attacks. Therefore we propose to design robust Android malware detection models against adversarial attacks using reinforcement learning. We propose the Single Policy and Multi Policy based Evasion Attacks for Perfect Knowledge and Limited Knowledge scenario respectively against many malware detection models built using four different sets of classifiers (bagging, boosting and deep neural network). The motivation is to identify the adversarial vulnerability in Android malware detection models and then propose defence against them.",
        "DOI": "10.1109/PerComWorkshops51409.2021.9430980",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani",
        "affiliation_city": "Pilani",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Hybrid Deep Learning Architecture to Forecast Maximum Load Duration Using Time-of-Use Pricing Plans",
        "paper_author": "Kim J.",
        "publication": "Computers, Materials and Continua",
        "citied_by": "3",
        "cover_date": "2021-03-22",
        "Abstract": "Load forecasting has received crucial research attention to reduce peak load and contribute to the stability of power grid using machine learning or deep learning models. Especially, we need the adequate model to forecast the maximum load duration based on time-of-use, which is the electricity usage fare policy in order to achieve the goals such as peak load reduction in a power grid. However, the existing single machine learning or deep learning forecasting cannot easily avoid overfitting. Moreover, a majority of the ensemble or hybrid models do not achieve optimal results for forecasting the maximum load duration based on time-of-use. To overcome these limitations, we propose a hybrid deep learning architecture to forecast maximum load duration based on time-of-use. Experimental results indicate that this architecture could achieve the highest average of recall and accuracy (83.43%) compared to benchmarkmodels. To verify the effectiveness of the architecture, another experimental result shows that energy storage system (ESS) scheme in accordance with the forecast results of the proposed model (LSTM-MATO) in the architecture could provide peak load cost savings of 17,535,700KRWeach year comparing with original peak load costs without the method. Therefore, the proposed architecture could be utilized for practical applications such as peak load reduction in the grid.",
        "DOI": "10.32604/cmc.2021.016042",
        "affiliation_name": "Zayed University",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Prediction Modelling of COVID-19 on Provinces in Indonesia using Long Short-Term Memory Machine Learning",
        "paper_author": "Wibowo F.W.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "6",
        "cover_date": "2021-03-22",
        "Abstract": "The COVID-19 is a dangerous virus that has been declared by the world health organization (WHO) as a pandemic. Many countries have taken policies to control the virus's spread and have played an active role in overcoming this global pandemic, including Indonesia. Indonesia consists of many islands, so the level of distribution varies. Although the mortality rate is shallow than the cure rate, this virus's spread must be controlled. This paper aims to model the prediction of infected cases, cases of recovery from COVID-19, and mortality for each province in Indonesia using the Long Short-Term Memory (LSTM) machine learning method. The results of the model evaluation of this method used the root mean squared error (RMSE) approach.",
        "DOI": "10.1088/1742-6596/1844/1/012006",
        "affiliation_name": "Universitas Amikom Yogyakarta",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Deep reinforcement learning of transition states",
        "paper_author": "Zhang J.",
        "publication": "Physical Chemistry Chemical Physics",
        "citied_by": "27",
        "cover_date": "2021-03-21",
        "Abstract": "Combining reinforcement learning (RL) and molecular dynamics (MD) simulations, we propose a machine-learning approach, called RL‡, to automatically unravel chemical reaction mechanisms. In RL‡, locating the transition state of a chemical reaction is formulated as a game, and two functions are optimized, one for value estimation and the other for policy making, to iteratively improve our chance of winning this game. Both functions can be approximated by deep neural networks. By virtue of RL‡, one can directly interpret the reaction mechanism according to the value function. Meanwhile, the policy function allows efficient sampling of the transition path ensemble, which can be further used to analyze reaction dynamics and kinetics. Through multiple experiments, we show that RL‡can be trainedtabula rasahence allowing us to reveal chemical reaction mechanisms with minimal subjective biases.",
        "DOI": "10.1039/d0cp06184k",
        "affiliation_name": "Shenzhen Bay Laboratory",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting stream water quality under different urban development pattern scenarios with an interpretable machine learning approach",
        "paper_author": "Wang R.",
        "publication": "Science of the Total Environment",
        "citied_by": "106",
        "cover_date": "2021-03-20",
        "Abstract": "Urban development pattern significantly impacts stream water quality by influencing pollutant generation, build-up, and wash-off processes. It is thus necessary to understand and predict stream water quality in accordance with different urban development patterns to effectively advise urban growth planning and policies. To do so, we collected pollutant concentration data on nitrate (NO3−-N), total phosphate (TP), and Escherichia coli (E. coli) from 1047 sampling stations in the Texas Gulf Region. We utilized a Random Forest (RF) machine learning model to predict stream water quality under four planning scenarios with different urban densities and configurations. SHapley Additive exPlanations (SHAP) was used to prove the importance of urban development pattern in influencing stream water quality. The spatial variations of the impact of these patterns were explored with Geographically Weighted Regression (GWR). SHAP results indicated that Largest Patch Index (LPI), Patch Cohesion Index (COHESION), Splitting Index (SPLIT), and Landscape Division Index (DIVISION) were the most important urban development pattern metrics affecting stream water quality. The spatial variations of such patterns were shown to impact stream water quality depending on pollutants, seasonality, climate, and urbanization level. RF prediction results suggested that high density aggregated development was more effective in reducing TP and NO3−-N concentrations than the current sprawl development, but had the potential risk of increasing E. coli pollution in the wet season. The results of this study provide empirical evidence and a potential mechanistic explanation that stream water quality degradation is a consequence of urban sprawl. Lastly, machine learning is a powerful tool for scenario prediction in land use planning to forecast environmental impacts under different urban development pattern scenarios.",
        "DOI": "10.1016/j.scitotenv.2020.144057",
        "affiliation_name": "Michigan State University",
        "affiliation_city": "East Lansing",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Global association between satellite-derived nitrogen dioxide (NO<inf>2</inf>) and lockdown policies under the COVID-19 pandemic",
        "paper_author": "Zhang H.",
        "publication": "Science of the Total Environment",
        "citied_by": "30",
        "cover_date": "2021-03-20",
        "Abstract": "The COVID-19 pandemic has severely affected various aspects of life, at different levels and in different countries on almost every continent. In response, many countries have closed their borders and imposed lockdown policies, possibly bringing benefits to people's health with significantly less emission from air pollutants. Currently, most studies or reports are based on local observations at the city or country level. There remains a lack of systematic understanding of the impacts of different lockdown policies on the air quality from a global perspective. This study investigates the impacts of COVID-19 pandemic towards global air quality through examining global nitrogen dioxide (NO2) dynamics from satellite observations between 1 January and 30 April 2020. We used the Apriori algorithm, an unsupervised machine learning method, to investigate the association among confirmed cases of COVID-19, NO2 column density, and the lockdown policies in 187 countries. The findings based on weekly data revealed that countries with new cases adopted various lockdown policies to stop or prevent the virus from spreading whereas those without tended to adopt a wait-and-see attitude without enforcing lockdown policies. Interestingly, decreasing NO2 concentration due to lockdown was associated with international travel controls but not with public transport closure. Increasing NO2 concentration was associated with the “business as usual” strategy as evident from North America and Europe during the early days of COVID-19 outbreak (late January to early February 2020), as well as in recent days (in late April) after many countries have started to resume economic activities. This study enriches our understanding of the heterogeneous patterns of global associations among the COVID-19 spreading, lockdown policies and their environmental impacts on NO2 dynamics.",
        "DOI": "10.1016/j.scitotenv.2020.144148",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Mass load prediction for lithium-ion battery electrode clean production: A machine learning approach",
        "paper_author": "Liu K.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "103",
        "cover_date": "2021-03-20",
        "Abstract": "With the advent of sustainable and clean energy, lithium-ion batteries have been widely utilised in cleaner productions such as energy storage systems and electrical vehicles, but the management of their electrode production chain has a direct and crucial impact on the battery performance and production efficiency. To achieve a cleaner production chain of battery electrode involving strongly-coupled intermediate parameters and control parameters, a reliable approach to quantify the feature importance and select the key feature variables for predicting battery intermediate products is urgently required. In this paper, a Gaussian process regression-based machine learning framework, which incorporates powerful automatic relevance determination kernels, is proposed for directly quantifying the importance of four intermediate production feature variables and analysing their influences on the prediction of battery electrode mass load. Specifically, these features include three intermediate parameters from the mixing step and a control parameter from the coating step. After deriving four different automatic relevance determination kernels, the importance of these four feature variables based on a regression modelling is comprehensively analysed. Comparative results demonstrate that the proposed automatic relevance determination kernel-based Gaussian process regression models could not only quantify the importance weights for reliable feature selections but also help to achieve satisfactory electrode mass load prediction. Due to the data-driven nature, the proposed framework can be conveniently extended to improve the analysis and control of battery electrode production, further benefitting the manufactured battery yield, efficiencies and performance to achieve cleaner battery production.",
        "DOI": "10.1016/j.jclepro.2020.125159",
        "affiliation_name": "Shenzhen Institute of Advanced Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Comprehensive opinion analysis on recent QUAD formation in Indo Pacific region using Twitter corpus",
        "paper_author": "Panwar D.S.",
        "publication": "2021 7th International Conference on Advanced Computing and Communication Systems, ICACCS 2021",
        "citied_by": "1",
        "cover_date": "2021-03-19",
        "Abstract": "India is known for its highly disciplined foreign policies, strategic location, vibrant and massive Diaspora. India envisages enhancing its scope of cooperation, trade and widens its sphere of relations with the Pacific. As a result, the world is witnessing the rise of Indo-Pacific ties. Before the 1980's the keystone of the universe was called the Atlantic, but now a radical shift to the east is noticed by the term 'Indo-Pacific. In this respect, a recent development occurred as a partnership, the Malabar exercise, in the waters of the Pacific and the Indian Oceanic region, which supports and proclaim free, open, and comprehensive Indo-Pacific and stays committed on a rule-based order. Considering the mass inclusion of people on social media platforms and contemplating their opinion has been of much interest in the research. Understanding and categorizing a large dataset of ideas into positive, negative, and neutral aspects is challenging. Our motive is to elucidate how the world, especially the citizens, is welcoming this strategic and influencing partnership. Also, Could social media influence the meaning of partnership? Our paper is divided into two aspects, one dealing with the comparison of various techniques and the other telling opinions of people regarding Indo-pacific relations. We used a geo-specific dataset obtained in various languages. Also, we applied a blend of various ML and DL techniques, feature extraction models, and opinion-based classification, which not only gives an analysis of opinions regarding 'Indo-pacific' but also provides an in-depth insight to the comparison of various state-of-the-art sentiment analysis techniques, which is provided as a continuation of earlier review presented on sentiment analysis. The word-cloud visualization system assists people in understanding the changes of public sentiment reactions better.",
        "DOI": "10.1109/ICACCS51430.2021.9441772",
        "affiliation_name": "Delhi Technological University",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Crop Yield Prediction Using Random Forest Algorithm",
        "paper_author": "Suresh N.",
        "publication": "2021 7th International Conference on Advanced Computing and Communication Systems, ICACCS 2021",
        "citied_by": "44",
        "cover_date": "2021-03-19",
        "Abstract": "Most agricultural crops have been badly affected by the effect of global climate change in India. In terms of their output over the past 20 years. It will allow policy makers and farmers to take effective marketing and storage steps to predict crop yields earlier in their harvest. This project will allow farmers to capture the yield of their crops before cultivation in the field of agriculture and thus help them make the necessary decisions. Implementation of such a method with a web-based graphic software that is simple to use and the machine learning algorithm can then be distributed. The results obtained are granted access to the farmer. And yet there are various methods or protocols for such very data analytics in crop yield prediction, and we are able to predict agricultural productivity with guidance of all those algorithms. It utilizes a Random Forest Algorithm. By researching such problems and issues such as weather, temperature, humidity, rainfall, humidity, there are no adequate solutions and inventions to resolve the situation we face. In countries like India, even in the agricultural sector, as there are many types of increasing economic growth. In addition, the processing is useful for forecasting the production of crop yields.",
        "DOI": "10.1109/ICACCS51430.2021.9441871",
        "affiliation_name": "K L Deemed to be University",
        "affiliation_city": "Vaddeswaram",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Using satellite imagery to understand and promote sustainable development",
        "paper_author": "Burke M.",
        "publication": "Science",
        "citied_by": "229",
        "cover_date": "2021-03-19",
        "Abstract": "Accurate and comprehensivemeasurements of a range of sustainable development outcomes are fundamental inputs into both research and policy. We synthesize the growing literature that uses satellite imagery to understand these outcomes, with a focus on approaches that combine imagery with machine learning. We quantify the paucity of ground data on key human-related outcomes and the growing abundance and improving resolution (spatial, temporal, and spectral) of satellite imagery. We then review recent machine learning approaches to model-building in the context of scarce and noisy training data, highlighting how this noise often leads to incorrect assessment of model performance. We quantify recent model performance across multiple sustainable development domains, discuss research and policy applications, explore constraints to future progress, and highlight research directions for the field.",
        "DOI": "10.1126/science.abe8628",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Smart Residential Energy Management System (REMS) Using Machine Learning",
        "paper_author": "Wijesingha J.R.",
        "publication": "Proceedings of 2nd IEEE International Conference on Computational Intelligence and Knowledge Economy, ICCIKE 2021",
        "citied_by": "10",
        "cover_date": "2021-03-17",
        "Abstract": "Electricity consumption is increasing day by day in every corner of the world which leads to imbalance of supply and demand. In the current scenario, everybody searches for cheaper and environmentally friendly approaches in accessing electricity. In order to mitigate falling into a huge energy crisis, both the utility and consumer could involve in energy management which is a convenient and trending approach. We believe it should be started from the ground level, which is the consumer scope. This paper proposes a method for a smart Residential Energy Management System (REMS) using Machine Learning. Specifically, the proposed system (REMS) effectively switches pre-prioritized possible loads without limiting consumption, between the grid and renewably energized local storage with rooftop solar at the residential premises, using Machine Learning algorithms. Reduction of the electricity bill with a reliable power supply as much as possible in residential premises is also concerned, with the use of by load shifting algorithm. Available average solar power prediction using Artificial Neural Network and Optimum utilization of available solar power generation and the energy storage using Reinforcement Learning features are also included in the system. Ultimately, the grid dependency is reduced at the Residential premises.",
        "DOI": "10.1109/ICCIKE51210.2021.9410779",
        "affiliation_name": "University of Moratuwa",
        "affiliation_city": "Moratuwa",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Meteorology-driven variability of air pollution (PM1) revealed with explainable machine learning",
        "paper_author": "Stirnberg R.",
        "publication": "Atmospheric Chemistry and Physics",
        "citied_by": "70",
        "cover_date": "2021-03-17",
        "Abstract": "Air pollution, in particular high concentrations of particulate matter smaller than 1 span classCombining double low lineinline-formulam in diameter (PMspan classCombining double low lineinline-formula1), continues to be a major health problem, and meteorology is known to substantially influence atmospheric PM concentrations. However, the scientific understanding of the ways in which complex interactions of meteorological factors lead to high-pollution episodes is inconclusive. In this study, a novel, data-driven approach based on empirical relationships is used to characterize and better understand the meteorology-driven component of PMspan classCombining double low lineinline-formula1 variability. A tree-based machine learning model is set up to reproduce concentrations of speciated PMspan classCombining double low lineinline-formula1 at a suburban site southwest of Paris, France, using meteorological variables as input features. The model is able to capture the majority of occurring variance of mean afternoon total PMspan classCombining double low lineinline-formula1 concentrations (coefficient of determination (span classCombining double low lineinline-formulaiR/i2) of 0.58), with model performance depending on the individual PMspan classCombining double low lineinline-formula1 species predicted. Based on the models, an isolation and quantification of individual, season-specific meteorological influences for process understanding at the measurement site is achieved using SHapley Additive exPlanation (SHAP) regression values. Model results suggest that winter pollution episodes are often driven by a combination of shallow mixed layer heights (MLHs), low temperatures, low wind speeds, or inflow from northeastern wind directions. Contributions of MLHs to the winter pollution episodes are quantified to be on average span classCombining double low lineinline-formulag1/45 span classCombining double low lineinline-formulag/mspan classCombining double low lineinline-formula3 for MLHs below span classCombining double low lineinline-formula<500 m a.g.l. Temperatures below freezing initiate formation processes and increase local emissions related to residential heating, amounting to a contribution to predicted PMspan classCombining double low lineinline-formula1 concentrations of as much as span classCombining double low lineinline-formulag1/49 span classCombining double low lineinline-formulag/mspan classCombining double low lineinline-formula3. Northeasterly winds are found to contribute span classCombining double low lineinline-formulag1/45 span classCombining double low lineinline-formulag/mspan classCombining double low lineinline-formula3 to predicted PMspan classCombining double low lineinline-formula1 concentrations (combined effects of span classCombining double low lineinline-formulaiu/i-and span classCombining double low lineinline-formulaiv/i-wind components), by advecting particles from source regions, e.g. central Europe or the Paris region. Meteorological drivers of unusually high PMspan classCombining double low lineinline-formula1 concentrations in summer are temperatures above span classCombining double low lineinline-formulag1/425 span classCombining double low lineinline-formulagC (contributions of up to span classCombining double low lineinline-formulag1/42.5 span classCombining double low lineinline-formulag/mspan classCombining double low lineinline-formula3), dry spells of several days (maximum contributions of span classCombining double low lineinline-formulag1/41.5 span classCombining double low lineinline-formulag/mspan classCombining double low lineinline-formula3), and wind speeds below span classCombining double low lineinline-formulag1/42 m/s (maximum contributions of span classCombining double low lineinline-formulag1/43 span classCombining double low lineinline-formulag/mspan classCombining double low lineinline-formula3), which cause a lack of dispersion. High-resolution case studies are conducted showing a large variability of processes that can lead to high-pollution episodes. The identification of these meteorological conditions that increase air pollution could help policy makers to adapt policy measures, issue warnings to the public, or assess the effectiveness of air pollution measures./p.",
        "DOI": "10.5194/acp-21-3919-2021",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "2021 4th International Conference on Energy Conservation and Efficiency, ICECE 2021 - Proceedings",
        "paper_author": "NA",
        "publication": "2021 4th International Conference on Energy Conservation and Efficiency, ICECE 2021 - Proceedings",
        "citied_by": "0",
        "cover_date": "2021-03-16",
        "Abstract": "The proceedings contain 28 papers. The topics discussed include: an efficient energy management system for hybrid power sources; hybrid grey wolf optimizer sine cosine algorithm based maximum power point tracking control of PV systems under uniform irradiance and partial shading condition; maximum power point tracking of PV system under uniform irradiance and partial shading conditions using machine learning algorithm trained by sailfish optimizer; economic and performance analysis of PV system and grid supply for high rise building and luxury villa in Pakistan; impacts of high penetration of wind power on transmission system; renewable portfolio standard from the perspective of policy network theory for Saudi Arabia Vision 2030 targets; abundance of sun resource brings extra profits on dish Stirling solar power station; and biomass pelletizing: characterization of cow dung assisted solid recovered bio-fuel from agricultural waste.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Provisioning of Contention Resolution in Multiple UAVs to Establish Collaborative Tasks",
        "paper_author": "Saravanan M.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-03-16",
        "Abstract": "As demand for commercial roles for Unmanned Aerial Vehicles (UAVs)is at its peak, market players are finding it more difficult to accommodate the ever-changing dynamic market requirement. As UAVs are used across multiple verticals such as photography, delivery, providing medical assistance, tracking, etc., the demand has pushed open the floodgates for this sector. UAV platforms today offer only the idea of leasing a drone for a specific period which works well if the requirements are known prior. In the case of an agile environment, the platform services need to incorporate the policy of leasing and releasing UAVs on a need basis. Our paper focuses on the idea of a dynamic UAV as a service platform wherein the UAVs are hired from the public using some selection and provisioning methods. Such a solution will assist in the fast-paced and cost-effective development, but also enable interoperability between multiple companies to share the resources. Regarding this, we have introduced a new contention resolution framework to handle multiple UAVs during the collaborative operation. The proposed framework which comprises a new protocol, task filter, and the application of the Machine Learning (ML) model to perform probabilistic ranking and assign the UAVs for the specific tasks that will address the required situation efficiently.",
        "DOI": "10.1088/1742-6596/1831/1/012019",
        "affiliation_name": "Telefonaktiebolaget LM Ericsson",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Bench to Bedside Discovery, Innovation, Global Health Equity, and Security",
        "paper_author": "Dzau V.J.",
        "publication": "Circulation",
        "citied_by": "0",
        "cover_date": "2021-03-16",
        "Abstract": "NA",
        "DOI": "10.1161/CIRCULATIONAHA.121.054151",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "The Future of Blood Testing Is the Immunome",
        "paper_author": "Arnaout R.A.",
        "publication": "Frontiers in Immunology",
        "citied_by": "33",
        "cover_date": "2021-03-15",
        "Abstract": "It is increasingly clear that an extraordinarily diverse range of clinically important conditions—including infections, vaccinations, autoimmune diseases, transplants, transfusion reactions, aging, and cancers—leave telltale signatures in the millions of V(D)J-rearranged antibody and T cell receptor [TR per the Human Genome Organization (HUGO) nomenclature but more commonly known as TCR] genes collectively expressed by a person’s B cells (antibodies) and T cells. We refer to these as the immunome. Because of its diversity and complexity, the immunome provides singular opportunities for advancing personalized medicine by serving as the substrate for a highly multiplexed, near-universal blood test. Here we discuss some of these opportunities, the current state of immunome-based diagnostics, and highlight some of the challenges involved. We conclude with a call to clinicians, researchers, and others to join efforts with the Adaptive Immune Receptor Repertoire Community (AIRR-C) to realize the diagnostic potential of the immunome.",
        "DOI": "10.3389/fimmu.2021.626793",
        "affiliation_name": "Beth Israel Deaconess Medical Center",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "How US law will evaluate artificial intelligence for covid-19",
        "paper_author": "Krass M.",
        "publication": "The BMJ",
        "citied_by": "12",
        "cover_date": "2021-03-15",
        "Abstract": "NA",
        "DOI": "10.1136/bmj.n234",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Does \"aI\" stand for augmenting inequality in the era of covid-19 healthcare?",
        "paper_author": "Leslie D.",
        "publication": "The BMJ",
        "citied_by": "111",
        "cover_date": "2021-03-15",
        "Abstract": "NA",
        "DOI": "10.1136/bmj.n304",
        "affiliation_name": "Ada Lovelace Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "An Adaptive ADRC Control for Parkinson's Patients Using Machine Learning",
        "paper_author": "Faraji B.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "18",
        "cover_date": "2021-03-15",
        "Abstract": "Parkinson's disease (PD) is one of the most common diseases that its main complications are hand and head tremors and inflexibility of muscles. One of the prevalent treatments that employ for reducing the symptoms of that is deep brain stimulation (DBS). In practice, a sensor is located in the patient's finger for detecting and evaluating the tremor values in PD. Using an open-loop control structure for stimulating one area of basal ganglia (BG) is the common approach, but in this work, two areas of BG, named subthalamic nucleus (STN) and globus pallidus internal (GPi) are stimulated in a closed-loop manner separately for i) reducing the intensity of electric field and consequently disappearing the side effects of DBS ii) decreasing hand tremor. In particular, an adaptive Active Disturbance Rejection Control (ADRC) based on a deep deterministic policy gradient (DDPG) and a conventional feedback controller are presented for simultaneous stimulating STN and GPi, respectively. In this way, the control coefficients of the ADRC are considered as the control objective parameters that are designed by the actor and critic neural networks (NNs) of DDPG. The suggested scheme is applied to a BG system model which is frequently studied in the literature. The comprehensive simulation studies are accomplished to confirm the supremacy of the ADRC based DDPG scheme over the state-of-the-art strategies. Moreover, hardware-in-the-loop (HiL) simulations are performed to verify the efficiency of the proposed scheme from real-time perspective.",
        "DOI": "10.1109/JSEN.2020.3048588",
        "affiliation_name": "University College of Rouzbahan",
        "affiliation_city": "Sari",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "A Q-learning based transient power optimization method for organic Rankine cycle waste heat recovery system in heavy duty diesel engine applications",
        "paper_author": "Xu B.",
        "publication": "Applied Energy",
        "citied_by": "33",
        "cover_date": "2021-03-15",
        "Abstract": "In recent years, the organic Rankine cycle waste heat recovery (ORC-WHR) technology gains popularity in heavy-duty diesel engine applications. Drastic fluctuations of the waste heat caused by variable daily operation of mobile heavy-duty trucks bring an extreme transient power optimization challenge to ORC-WHR systems. Existing power optimization methods either neglect transient behavior of the Rankine cycle system or compromise model accuracy for computation efficiency. Different from literature, this study first time proposes a model-free reinforcement learning method to achieve online transient power optimization for the ORC-WHR system and explains the benefits of learning method in this application. A tabular Q-learning is formulated to optimize the net power on an experimentally validated ORC-WHR system. Q-learning is explained in detail using states, action, and policy information. To quantify the power optimization of the proposed method, Proper-Integral-Derivative method, state-of-art offline and online Dynamic Programming methods are implemented. The results showed that Q-learning generated 22% more cumulative energy than the energy Proper-Integral-Derivative method generated. Furthermore, Q-learning produces 96.6% of cumulative energy that the offline Dynamic Programming generates over a transient engine condition, while it requires less computation cost and is executed online. Additionally, the Q-learning produces 0.5% more cumulative energy than the machine learning-based online Dynamic Programming results and exhibits better vapor temperature robustness than the online Dynamic Programming method (4 °C-28 °C superheat by Q-learning vs. 5 °C-94 °C superheat by online Dynamic Programming). Given the excellent power production performance, low computation cost requirement and high robustness, the proposed Q-learning method has the potential to improve the power production of the ORC-WHR system with different configurations.",
        "DOI": "10.1016/j.apenergy.2021.116532",
        "affiliation_name": "Clemson University College of Engineering, Computing and Applied Sciences",
        "affiliation_city": "Clemson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modelling heating and cooling energy demand for building stock using a hybrid approach",
        "paper_author": "Li X.",
        "publication": "Energy and Buildings",
        "citied_by": "94",
        "cover_date": "2021-03-15",
        "Abstract": "The building sector accounts for 30% of final energy consumption and 28% of global energy-related carbon dioxide emissions, with space heating and cooling consuming a large share of total buildings’ energy consumption. Building stock modelling for space heating and cooling energy prediction provides critical insights on the stock energy consumption and aid the building retrofit policy-making process with the evaluation of the energy-saving potential. By combining the physical modelling approach and data-driven approach, a hybrid approach is applicable for modelling the heating and cooling energy consumption of the building stock, including both residential buildings and non-residential buildings. Within this framework, the Urban Modelling Interface (UMI) tool has been used for physical modelling to generate heating and cooling energy use intensity. Then, ten different machine learning models, including Gaussian radial basis function kernel support vector regression, linear kernel support vector regression, polynomial kernel support vector regression, random forests, extreme gradient boosting, ordinary least-squares linear regression, ridge regression, least absolute shrinkage and selection operator, elastic net and artificial neural network, have been applied to predict heating and cooling energy use intensity (EUI). The approach has been demonstrated using a case study in Chongqing, China. The results show that machine learning models can achieve accurate building heating and cooling EUI prediction, with the polynomial kernel support vector regression showing the best accuracy at the level of a single building, and the Gaussian radial basis function kernel support vector regression performing the best at the stock level. Machine learning models generated by proposed hybrid approach not only provide quickly prediction of building space heating and cooling energy consumption at the stock level, but also support building retrofit decision makings by evaluate energy saving potential of various retrofit options.",
        "DOI": "10.1016/j.enbuild.2021.110740",
        "affiliation_name": "Chongqing University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Machine Learning Approach Based on Ultra-Local Model Control for Treating Cancer Pain",
        "paper_author": "Faraji B.",
        "publication": "IEEE Sensors Journal",
        "citied_by": "10",
        "cover_date": "2021-03-15",
        "Abstract": "Cancer illness still is one of the most common illnesses in the world, which is constantly rising. Chemotherapy plays a crucial role in treating cancer patients. In this paper, we have presented a novel intelligent sensor for controlling and adjusting chemotherapy parameters which consist of an ultra-local (ULM) controller based on a deep deterministic policy gradient (DDPG). First, the feedback signal is provided using a sensor to calculate the population of cells. Then, a controller sends the proper control commands to the actuator (chemotherapy). In the suggested scheme, the ULM is applied to the dynamic model of cancer. In order to shrink tumor cells and rising immune and normal cells at the same time. Moreover, for improving the performance of the established ULM scheme, a DDPG algorithm with the actor-critic structure is used for tuning the parameters of ULM in an adaptive manner. To demonstrate the supremacy of the DDPG based ULM controller, the conventional ULM and proportional integrator (PI) are also designed for the cancer treatment. Simulation outcomes prove the improved cancer treatment compared to the ULM and PI schemes.",
        "DOI": "10.1109/JSEN.2020.3042937",
        "affiliation_name": "University College of Rouzbahan",
        "affiliation_city": "Sari",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Deepening the IDA* algorithm for knowledge graph reasoning through neural network architecture",
        "paper_author": "Wang Q.",
        "publication": "Neurocomputing",
        "citied_by": "18",
        "cover_date": "2021-03-14",
        "Abstract": "Inferring missing links in Knowledge Graphs (KGs) is a key evaluation task for KG reasoning, which aims to find relations for a given entity pair. Existing research often employs the IDA* (Iterative Deepening A*) algorithm for the path discovery task owing to its efficiency and accuracy. However, it relies on heuristics to set cost functions and is also difficult to utilize useful context information in the search process. In this paper, we propose the Deep-IDA* framework which applies neural networks and reinforcement learning (RL) to empower the IDA* algorithm to tackle the path discovery problem in KG reasoning. We model KG reasoning as a Markov Decision Process (MDP) and divide our Deep-IDA* framework and the resulting path into two parts: path-finding and path-reasoning. For path-finding, we propose a policy network to model the cost from the source to a candidate location. In this process, we employ the GCN (Graph Convolutional Network) to embed the observable sub-track, then employ the LSTM (Long Short-Term Memory) to record the historical trajectory, and introduce the attention to utilize the context information, and finally form policy. For path-reasoning with the searched candidate paths passed from the former process, we employ a value network to estimate the cost from the candidate to the destination entity, using the GNN (Graph Neural Networks) to learn a message-passing algorithm that solves the path inference problem, and using the GRU (Gated Recurrent Unit) to update the historical information. Finally, the actor-learner algorithm is utilized to minimize the sum of the losses of the two parts. Experiment results on three datasets demonstrate the effectiveness and efficiency of our framework.",
        "DOI": "10.1016/j.neucom.2020.12.040",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Safe Blues: The case for virtual safe virus spread in the long-term fight against epidemics",
        "paper_author": "Dandekar R.",
        "publication": "Patterns",
        "citied_by": "3",
        "cover_date": "2021-03-12",
        "Abstract": "Viral spread is a complicated function of biological properties, the environment, preventative measures such as sanitation and masks, and the rate at which individuals come within physical proximity. It is these last two elements that governments can control through social-distancing directives. However, infection measurements are almost always delayed, making real-time estimation nearly impossible. Safe Blues is one way of addressing the problem caused by this time lag via online measurements combined with machine learning methods that exploit the relationship between counts of multiple forms of the Safe Blues strands and the progress of the actual epidemic. The Safe Blues protocols and techniques have been developed together with an experimental minimal viable product, presented as an app on Android devices with a server backend. Following initial exploration via simulation experiments, we are now preparing for a university-wide experiment of Safe Blues.",
        "DOI": "10.1016/j.patter.2021.100220",
        "affiliation_name": "Cornell University College of Engineering",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Thor: A deep learning approach for face mask detection to prevent the COVID-19 pandemic",
        "paper_author": "Snyder S.E.",
        "publication": "Conference Proceedings - IEEE SOUTHEASTCON",
        "citied_by": "30",
        "cover_date": "2021-03-10",
        "Abstract": "With the rapid worldwide spread of Coronavirus (COVID-19 and COVID-20), wearing face masks in public becomes a necessity to mitigate the transmission of this or other pandemics. However, with the lack of on-ground automated prevention measures, depending on humans to enforce face mask-wearing policies in universities and other organizational buildings, is a very costly and time-consuming measure. Without addressing this challenge, mitigating highly airborne transmittable diseases will be impractical, and the time to react will continue to increase. Considering the high personnel traffic in buildings and the effectiveness of countermeasures, that is, detecting and offering unmasked personnel with surgical masks, our aim in this paper is to develop automated detection of unmasked personnel in public spaces in order to respond by providing a surgical mask to them to promptly remedy the situation. Our approach consists of three key components. The first component utilizes a deep learning architecture that integrates deep residual learning (ResNet-50) with Feature Pyramid Network (FPN) to detect the existence of human subjects in the videos (or video feed). The second component utilizes Multi-Task Convolutional Neural Networks (MT-CNN) to detect and extract human faces from these videos. For the third component, we construct and train a convolutional neural network classifier to detect masked and unmasked human subjects. Our techniques were implemented in a mobile robot, Thor, and evaluated using a dataset of videos collected by the robot from public spaces of an educational institute in the U.S. Our evaluation results show that Thor is very accurate achieving an F_{1} score of 87.7% with a recall of 99.2% in a variety of situations, a reasonable accuracy given the challenging dataset and the problem domain.",
        "DOI": "10.1109/SoutheastCon45413.2021.9401874",
        "affiliation_name": "East Tennessee State University",
        "affiliation_city": "Johnson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An adaptive policy for on-line Energy-Efficient Control of machine tools under throughput constraint N Frigerio et al.",
        "paper_author": "Frigerio N.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "15",
        "cover_date": "2021-03-10",
        "Abstract": "Controlling the machine power state by switching off/on the machine when idle is one of the most promising energy efficient measure for machining processes. Part arrival process is affected by uncertainty and acquiring knowledge to obtain a proper and updated control model is difficult in industrial practice. Hence, control policies should be connected to the shop floor exploiting data acquired on-line. This work extends an on-line time-based policy recently proposed in the literature by including constraints on machine performance. A novel optimization algorithm is proposed to minimize energy consumption while assuring a target production rate and mitigating the risk of incurring in unexpected high energy consumption. Moreover, the policy is also broadened to autonomously adapt the control when the arrival process is non-stationary in time. The benefits of the proposed algorithms are assessed by means of realistic simulated cases and are around 25% of the energy consumed in idle states. Differently from existing studies dealing with the off-line problem, the proposed algorithm learns on-line while acquiring information from the real system.",
        "DOI": "10.1016/j.jclepro.2020.125367",
        "affiliation_name": "Politecnico di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "A regret-based behavioral model for shared water resources management: Application of the correlated equilibrium concept",
        "paper_author": "Eyni A.",
        "publication": "Science of the Total Environment",
        "citied_by": "19",
        "cover_date": "2021-03-10",
        "Abstract": "The competition over water use in shared water resources systems may lead to conflict. Conflict can lead to strategic behaviors with the consequence of “Tragedy of Common” in water resources. In this paper, a novel approach is proposed for the quantity and quality management of shared water resources using the Correlated Equilibrium (CE) concept. For the first time in water resources management studies, a Reinforcement Learning (RL)-based method, namely Regret Matching (RM), is proposed to simulate agents' behaviors. In the proposed methodology, an agent, which is responsible for water allocations, tries to reduce illegal water withdrawal from resources, using some non-mandatory and mandatory suggestions. This agent's objectives are leading the system towards social optimality (SO) and reaching the environmental sustainability goal. A modified RM algorithm is also developed for behavioral simulation in urban areas. The proposed methodology's applicability and efficiency are evaluated considering some criteria such as the concentration of the nitrate pollutant in groundwater, the groundwater table fluctuations, the rate of illegal water extraction from the groundwater, and the stakeholders' general satisfaction. The results of applying the methodology to the western part of the Tehran metropolitan area show its ability to deal with the water and treated wastewater allocation problems in urban areas and increase in the learning and cooperation among agents. According to the results, a meaningful decrease in nitrate concentration in the aquifer and an increase in groundwater table levels are observed. The results also indicate that the model could teach the stakeholders to act more responsibly towards protecting the environment and conserving shared water resources.",
        "DOI": "10.1016/j.scitotenv.2020.143892",
        "affiliation_name": "University of Tehran",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Research on the Economic Growth for Under-Developed Counties - Based on Two-way Fixed-effects Model",
        "paper_author": "Li Z.",
        "publication": "IOP Conference Series: Earth and Environmental Science",
        "citied_by": "2",
        "cover_date": "2021-03-09",
        "Abstract": "The county economy, especially the problem of poor counties, is currently a hot issue in China. At present, the research on the key factors for county economy is scarce, partly because it is difficult to obtain accurate and sufficient data. Because power consumption and industrial level are often highly correlated, and the power consumption is real-time data and hard to falsify, this paper used spatial, electricity consumption and economic data of 66 Chinese counties, which contains 29 poor counties, from 2009 to 2016 to find out the key factors for under-developed counties' economic growth by applying fixed effect regression model and machine learning models. The result shows that for poor counties, though the 1st industry is still the fundamental industry for county-level economy, the development of 3rd industry has significant positive impact on local economy. However, the development of 2nd industry, including recruiting large companies, and the input of electricity resources cannot well drive the local economies, which may suffer great loss due to the elimination policy of overcapacity in recent years. And the machine learning results support the above conclusions and suggest an obvious geographical cluster of poor counties, and the location, development of 1st and 3rd industry and net income of rural residents can explain most difference between the poor and non-poverty counties. These conclusions can be helpful for the government to lead the poor counties to get rid of poverty, and the cluster of poor counties should be focused.",
        "DOI": "10.1088/1755-1315/690/1/012065",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Contingency detection in multi-agent interactions",
        "paper_author": "Staley J.",
        "publication": "ACM/IEEE International Conference on Human-Robot Interaction",
        "citied_by": "0",
        "cover_date": "2021-03-08",
        "Abstract": "When a robot is deployed to learn a new task in a \"real-word\"environment, there may be multiple teachers and therefore multiple sources of feedback. Furthermore, there may be multiple optimal solutions for a given task and teachers may have preferences among those various solutions. We present an Interactive Reinforcement Learning (I-RL) algorithm, Multi-Teacher Activated Policy Shaping (M-TAPS), which addresses the problem of learning from multiple teachers and leverages differences between them as a means to explore the environment. We show that this algorithm can significantly increase an agent's robustness to the environment and quickly adopt to a teacher's preferences. Finally, we present a formal model for comparing human teachers and constructed oracle teachers and the way that they provide feedback to a robot.",
        "DOI": "10.1145/3434074.3447164",
        "affiliation_name": "Tufts University",
        "affiliation_city": "Medford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Active feedback learning with rich feedback",
        "paper_author": "Yu H.",
        "publication": "ACM/IEEE International Conference on Human-Robot Interaction",
        "citied_by": "2",
        "cover_date": "2021-03-08",
        "Abstract": "In this paper, we proposed rich feedback which contains multiple types of feedback to allow human teachers to provide a variety of useful information to the learning agent and modified Policy Shaping to accumulate the effects of rich feedback. Then we designed the ALPHA framework to actively request rich feedback and further developed it to use Deep Learning. The experimental results showed ALPHA with rich feedback can greatly improve learning and quickly lead the learning agent to the optimal solution.",
        "DOI": "10.1145/3434074.3447207",
        "affiliation_name": "Tufts University",
        "affiliation_city": "Medford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "When oracles go wrong: Using preferences as a means to explore",
        "paper_author": "Sheidlower I.S.",
        "publication": "ACM/IEEE International Conference on Human-Robot Interaction",
        "citied_by": "0",
        "cover_date": "2021-03-08",
        "Abstract": "When a robot is deployed to learn a new task in a \"real-word\"environment, there may be multiple teachers and therefore multiple sources of feedback. Furthermore, there may be multiple optimal solutions for a given task and teachers may have preferences among those various solutions. We present an Interactive Reinforcement Learning (I-RL) algorithm, Multi-Teacher Activated Policy Shaping (M-TAPS), which addresses the problem of learning from multiple teachers and leverages differences between them as a means to explore the environment. We show that this algorithm can significantly increase an agent's robustness to the environment and quickly adopt to a teacher's preferences. Finally, we present a formal model for comparing human teachers and constructed oracle teachers and the way that they provide feedback to a robot.",
        "DOI": "10.1145/3434074.3447189",
        "affiliation_name": "Tufts University",
        "affiliation_city": "Medford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Managerial optimism and corporate cash holdings",
        "paper_author": "Tran L.T.H.",
        "publication": "International Journal of Managerial Finance",
        "citied_by": "9",
        "cover_date": "2021-03-08",
        "Abstract": "Purpose: This paper examines the effects of managerial optimism on corporate cash holdings. Design/methodology/approach: The authors construct a novel measure of managerial optimism based on the linguistic tone of annual reports by applying a Naïve Bayesian Machine Learning algorithm to non-numeric parts of Vietnamese listed firms' reports from 2010 to 2016. The paper employs firm and year fixed effects model and also uses the generalized method of moments estimation as robustness checks. Findings: The authors find that the cash holding of firms managed by optimistic managers is higher than the cash holdings of firms managed by non-optimistic managers. Managerial optimism also influences corporate cash holdings through internal cash flows and the current year’s capital expenditures. Although the authors find no evidence that optimistic managers hold more cash to finance future growth opportunities in general, optimistic managers hold more cash for near future investment opportunities than non-optimistic managers do. Research limitations/implications: The novel measure proposed in this study is expected to provide great potential for future finance studies investigating the relation between managerial traits and corporate policies since it is applicable for any levels of financial market development. In addition, the findings highlight the important role, both direct and indirect, of managerial optimism on cash holdings. Related future research should take this psychological trait into account to gain a better understanding of corporate cash holding. Originality/value: This paper helps to extend the literature on managerial optimism measurement by introducing a new measure of managerial optimism based on the linguistic tone of annual reports. Furthermore, this is among the first studies directly linking annual report linguistic tone to cash holding. The paper also provides new evidence regarding how managerial optimism affects the relationship between the firm's growth opportunities and cash holding, given that mispricing corrections are naturally uncertain.",
        "DOI": "10.1108/IJMF-04-2019-0129",
        "affiliation_name": "University of Economics Ho Chi Minh City",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Development of a reference signal self-organizing control system based on deep reinforcement learning",
        "paper_author": "Iwasaki H.",
        "publication": "2021 IEEE International Conference on Mechatronics, ICM 2021",
        "citied_by": "2",
        "cover_date": "2021-03-07",
        "Abstract": "Intelligent control has received a significant amount of attention in recent years owing to its use in autonomous driving technology and other applications(1)-(3). Intelligent control is a control theory that uses machine learning algorithms to build control systems. In this study, we develop an intelligent control theory based on deep reinforcement learning. We proposed a reference signal self-organizing control system based on a deep deterministic policy gradient (DDPG). This proposed system is an extension of an existing control system using DDPG. We verify the effectiveness of the proposed system through swing-up and stabilizing control simulations using an inverted pendulum with an inertia rotor. We confirmed that the pendulum was inverted by the swing-up control at approximately 1.2 s and the pendulum was stabilized for approximately 8.8 s. Therefore, we confirmed the effectiveness of the proposed reference signal self-organizing control system.",
        "DOI": "10.1109/ICM46511.2021.9385676",
        "affiliation_name": "Tokai University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Research and Design of Credit Risk Assessment System Based on Big Data and Machine Learning",
        "paper_author": "Wen S.",
        "publication": "2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021",
        "citied_by": "1",
        "cover_date": "2021-03-05",
        "Abstract": "Since the outbreak of the COVID-19, small and medium-sized enterprises have been greatly affected. In order to cope with the difficulty of capital turnover for small and medium-sized enterprises, the government has successively introduced a series of financial policies to increase credit support and reduce financing costs. The rapid development of technology has also prompted further innovations in the operating models of banks and other credit platforms. However, banks and credit platforms must consider practical issues such as their own capital costs and risk assessment while they help small and medium-sized enterprises reduce financing costs. This paper aims to study and design a credit risk assessment system based on big data technology and machine learning algorithms. It is hoped that the system will enhance the bank's ability to identify the credit risks of small and medium-sized enterprises, so as to solve the problem of difficult and expensive financing for small and medium-sized enterprises. At the same time, it will reduce the bank's own bad loan ratio and increase profit margins. Achieving a win-win situation for small and medium-sized enterprises and banks, it's crucial to promote jointly the development of economy.",
        "DOI": "10.1109/ICBDA51983.2021.9403128",
        "affiliation_name": "Guangdong University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Deep Deterministic Policy Gradient-based Strategy for Stocks Portfolio Management",
        "paper_author": "Zhang H.",
        "publication": "2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021",
        "citied_by": "9",
        "cover_date": "2021-03-05",
        "Abstract": "With the improvement of computer performance and the development of GPU-Accelerated technology, trading with machine learning algorithms has attracted the attention of many researchers and practitioners. In this research, we propose a novel portfolio management strategy based on the framework of Deep Deterministic Policy Gradient, a policy-based reinforcement learning framework, and compare its performance to that of other trading strategies. In our framework, two Long Short-Term Memory neural networks and two fully connected neural networks are constructed. We also investigate the performance of our strategy with and without transaction costs. Experimentally, we choose eight US stocks consisting of four low-volatility stocks and four high-volatility stocks. We compare the compound annual return rate of our strategy against seven other strategies, e.g., Uniform Buy and Hold, Exponential Gradient and Universal Portfolios. In our case, the compound annual return rate is 14.12%, outperforming all other strategies. Furthermore, in terms of Sharpe Ratio (0.5988), our strategy is nearly 33% higher than that of the second-best performing strategy.",
        "DOI": "10.1109/ICBDA51983.2021.9403049",
        "affiliation_name": "Xi'an Jiaotong-Liverpool University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Modular Policy Evaluation System: A Policy Evaluation Framework Based on Text Mining",
        "paper_author": "Gao Y.",
        "publication": "2021 IEEE 6th International Conference on Big Data Analytics, ICBDA 2021",
        "citied_by": "3",
        "cover_date": "2021-03-05",
        "Abstract": "Nowadays, in the big data era, data processing technology facilitates us to get the utmost out of sufficient information in the data. However, few scholars apply big data technology to the field of policy evaluation. Therefore, under the Policy Modeling Consistency(PMC) index model framework, this paper thoroughly mines the valuable information in policy texts and proposes a modular policy evaluation system combining text mining and machine learning methods. The system is divided into four processing modules, including data acquisition, data processing, index evaluation construction, and score evaluation. Compared with the traditional policy evaluation methods, the modular policy evaluation system presents the advantages of objectivity, high accuracy, and high efficiency, assisting in government policies' implementation.",
        "DOI": "10.1109/ICBDA51983.2021.9403142",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Mobile robot navigation based on deep reinforcement learning with 2D-LiDAR sensor using stochastic approach",
        "paper_author": "Beomsoo H.",
        "publication": "ISR 2021 - 2021 IEEE International Conference on Intelligence and Safety for Robotics",
        "citied_by": "11",
        "cover_date": "2021-03-04",
        "Abstract": "In recent years, there has been a significant progress in mobile robotics and their applications in different fields. Currently, mobile robots are employed for applications such as service robots for delivery, exploration, mapping, search and rescue, and warehouses. Recent advances in computing efficiency and machine learning algorithms have increased the variations of intelligent robots that can navigate autonomously using sensor data. Particularly, reinforcement learning has recently enjoyed a wide variety of success in controlling the robot motion in an unknown environment. However, most of the reinforcement learning-based navigation gets the path plan with a deterministic method, which results in some errors. Therefore, we present a navigation policy for a mobile robot equipped with a 2D range sensor based on the Proximal Policy Optimization of a stochastic approach. The tested algorithm also includes a stochastic operation, which simplifies the policy network model. We trained a differential drive robot in multiple training environments, and based on such stochastic learning, the training data accumulates faster than before. We tested our algorithm in a virtual environment and present the results of successful planning and navigation for mobile robots.",
        "DOI": "10.1109/ISR50024.2021.9419565",
        "affiliation_name": "Hokkaido University",
        "affiliation_city": "Sapporo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Clinical presentation of COVID-19 - a model derived by a machine learning algorithm",
        "paper_author": "Yousef M.",
        "publication": "Journal of integrative bioinformatics",
        "citied_by": "4",
        "cover_date": "2021-03-04",
        "Abstract": "COVID-19 pandemic has flooded all triage stations, making it difficult to carefully select those most likely infected. Data on total patients tested, infected, and hospitalized is fragmentary making it difficult to easily select those most likely to be infected. The Israeli Ministry of Health made public its registry of immediate clinical data and the respective status of infected/not infected for all viral DNA tests performed up to Apr. 18th, 2020 including almost 120,000 tests. We used a machine-learning algorithm to find out which immediate clinical elements mattered the most in identifying the true status of the tested persons including age or gender matter, to enable future better allocation of surveillance policy for those belonging to high-risk groups. In addition to the analyses applied on the first batch of the available data (Apr. 11th), we further tested the algorithm on the independent second batch (Apr. 12th to 18th). Fever, cough and headache were the most diagnostic, differing in degree of importance in different subgroups. Higher percentage of men were found positive (9.3 vs. 7.3%), but gender did not matter for the clinical presentation. The prediction power of the model was high, with accuracy of 0.84 and area under the curve 0.92. We provide a hand-held short checklist with verbal description of importance for the leading symptoms, which should expedite the triage and enable proper selection of people for further follow-up.",
        "DOI": "10.1515/jib-2020-0050",
        "affiliation_name": "Zefat Academic College",
        "affiliation_city": "Safad",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Application of machine learning for E-justice",
        "paper_author": "Metsker O.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "3",
        "cover_date": "2021-03-04",
        "Abstract": "Decision support systems (DSS) in law enforcement have a long history. Starting from the late 50s, they have been developed through several architectural approaches. Still, having a proven capability of DSSes to improve legal practice, the real-world application is limited due to multiple issues, including lack of trust, interpretability, validity, scalability, etc. The paper develops a service-based decision support platform for machine learning applications for eGovernance and internal policy modelling and presents a case study of the application of the platform for the case of migration law enforcement. We have developed a decision support platform a number of micro services that connect with each other asynchronously via the REST protocol. The artificial intelligence core of the platform was built upon a knowledge base, which includes machine learning models and methods. In this work we have developed a method of structuring, analysis of legal data models based on machine learning. In the course of computational experiment, the efficiency of the developed method was proved and the interpretation of the obtained results was performed to provide recommendations for the enhancement of administrative regulation.",
        "DOI": "10.1088/1742-6596/1828/1/012006",
        "affiliation_name": "All-Russian State University of Justice",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Data leverage: A framework for empowering the public in its relationship with technology companies",
        "paper_author": "Vincent N.",
        "publication": "FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
        "citied_by": "33",
        "cover_date": "2021-03-03",
        "Abstract": "Many powerful computing technologies rely on implicit and explicit data contributions from the public. This dependency suggests a potential source of leverage for the public in its relationship with technology companies: by reducing, stopping, redirecting, or otherwise manipulating data contributions, the public can reduce the effectiveness of many lucrative technologies. In this paper, we synthesize emerging research that seeks to better understand and help people action this data leverage. Drawing on prior work in areas including machine learning, human-computer interaction, and fairness and accountability in computing, we present a framework for understanding data leverage that highlights new opportunities to change technology company behavior related to privacy, economic inequality, content moderation and other areas of societal concern. Our framework also points towards ways that policymakers can bolster data leverage as a means of changing the balance of power between the public and tech companies.",
        "DOI": "10.1145/3442188.3445885",
        "affiliation_name": "University of Minnesota Twin Cities",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
        "paper_author": "NA",
        "publication": "FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
        "citied_by": "0",
        "cover_date": "2021-03-03",
        "Abstract": "The proceedings contain 74 papers. The topics discussed include: price discrimination with fairness constraints; black feminist musings on algorithmic oppression; fairness violations and mitigation under covariate shift; reasons, values, stakeholders: a philosophical framework for explainable artificial intelligence; allocating opportunities in a dynamic model of intergenerational mobility; corporate social responsibility via multi-armed bandits; biases in generative art: a causal look from the lens of art history; designing an online infrastructure for collecting AI data from people with disabilities; fifty shades of grey: in praise of a nuanced approach towards trustworthy design; the distributive effects of risk prediction in environmental compliance: algorithmic design, environmental justice, and public policy; representativeness in statistics, politics, and machine learning; computer science communities: who is speaking, and who is listening to the women?; and can you fake it until you make it?: impacts of differentially private synthetic data on downstream classification fairness.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "The distributive effects of risk prediction in environmental compliance: Algorithmic design, environmental justice, and public policy",
        "paper_author": "Benami E.",
        "publication": "FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
        "citied_by": "5",
        "cover_date": "2021-03-03",
        "Abstract": "Government agencies are embracing machine learning to support a variety of resource allocation decisions. The U.S. Environmental Protection Agency (EPA), for example, has engaged academic research labs to test the use of machine learning in support of an important national initiative to reduce Clean Water Act violations. We evaluate prototypical risk prediction models that can support compliance interventions and demonstrate how critical algorithmic design choices can generate or mitigate disparate impact in environmental enforcement. First, we show that the definition of which facilities to focus on through this national compliance initiative hinges on arbitrary differences in state-level permitting schemes, causing a shift in environmental protection away from areas with more minority populations. Second, the policy objective to reduce the noncompliance rate is encoded in a classification model, which does not account for the extent of pollution beyond the permitted limit. We hence compare allocation schemes between regression and classification, and show that the latter directs attention towards facilities in more rural and white areas. Overall, our study illustrates that as machine learning enters government, algorithmic design can both embed and elucidate sources of administrative policy discretion with discernable distributional consequences.",
        "DOI": "10.1145/3442188.3445873",
        "affiliation_name": "Virginia Polytechnic Institute and State University",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Computer science communities: Who is speaking, and who is listening to the women? Using an ethics of care to promote diverse voices",
        "paper_author": "Cheong M.",
        "publication": "FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
        "citied_by": "12",
        "cover_date": "2021-03-03",
        "Abstract": "Those working on policy, digital ethics and governance often refer to issues in 'computer science', that includes, but is not limited to, common subfields such as Artificial Intelligence (AI), Computer Science (CS) Computer Security (InfoSec), Computer Vision (CV), Human Computer Interaction (HCI), Information Systems, (IS), Machine Learning (ML), Natural Language Processing (NLP) and Systems Architecture. Within this framework, this paper is a preliminary exploration of two hypotheses, namely 1) Each community has differing inclusion of minoritised groups (using women as our test case, by identifying female-sounding names); and 2) Even where women exist in a community, they are not published representatively. Using data from 20,000 research records, totalling 503,318 names, preliminary data supported our hypothesis. We argue that ACM has an ethical duty of care to its community to increase these ratios, and to hold individual computing communities to account in order to do so, by providing incentives and a regular reporting system, in order to uphold its own Code.",
        "DOI": "10.1145/3442188.3445874",
        "affiliation_name": "University of Melbourne",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Narratives and counternarratives on data sharing in Africa",
        "paper_author": "Abebe R.",
        "publication": "FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency",
        "citied_by": "68",
        "cover_date": "2021-03-03",
        "Abstract": "As machine learning and data science applications grow ever more prevalent, there is an increased focus on data sharing and open data initiatives, particularly in the context of the African continent. Many argue that data sharing can support research and policy design to alleviate poverty, inequality, and derivative effects in Africa. Despite the fact that the datasets in question are often extracted from African communities, conversations around the challenges of accessing and sharing African data are too often driven by non-African stakeholders. These perspectives frequently employ a deficit narratives, often focusing on lack of education, training, and technological resources in the continent as the leading causes of friction in the data ecosystem. We argue that these narratives obfuscate and distort the full complexity of the African data sharing landscape. In particular, we use storytelling via fictional personas built from a series of interviews with African data experts to complicate dominant narratives and to provide counternarratives. Coupling these personas with research on data practices within the continent, we identify recurring barriers to data sharing as well as inequities in the distribution of data sharing benefits. In particular, we discuss issues arising from power imbalances resulting from the legacies of colonialism, ethno-centrism, and slavery, disinvestment in building trust, lack of acknowledgement of historical and present-day extractive practices, and Western-centric policies that are ill-suited to the African context. After outlining these problems, we discuss avenues for addressing them when sharing data generated in the continent.",
        "DOI": "10.1145/3442188.3445897",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Traffic noise prediction applying multivariate bi-directional recurrent neural network",
        "paper_author": "Zhang X.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "31",
        "cover_date": "2021-03-02",
        "Abstract": "With the drastically increasing traffic in the last decades, crucial environmental problems have been caused, such as greenhouse gas emission and traffic noise pollution. These problems have adversely affected our life quality and health conditions. In this paper, modelling of traffic noise employing deep learning is investigated. The goal is to identify the best machine-learning model for predicting traffic noise from real-life traffic data with multivariate traffic features as input. An extensive study on recurrent neural network (RNN) is performed in this work for modelling time series traffic data, which was collected through an experimental campaign at an inner city roundabout, including both video traffic data and audio data. The preprocessing of the data, namely how to generate the appropriate input and output for deep learning model, is detailed in this paper. A selection of different architectures of RNN, such as many-to-one, many-to-many, encoder– decoder architectures, was investigated. Moreover, gated recurrent unit (GRU) and long short-term memory (LSTM) were further discussed. The results revealed that a multivariate bi-directional GRU model with many-to-many architecture achieved the best performance with both high accuracy and computation efficiency. The trained model could be promising for a future smart city concept; with the proposed model, real-time traffic noise predictions can be potentially feasible using only traffic data collected by different sensors in the city, thanks to the generated big data by smart cities. The forecast of excessive noise exposure can help the regulation and policy makers to make early decisions, in order to mitigate the noise level.",
        "DOI": "10.3390/app11062714",
        "affiliation_name": "Austrian Institute of Technology",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "A uav maneuver decision-making algorithm for autonomous airdrop based on deep reinforcement learning",
        "paper_author": "Li K.",
        "publication": "Sensors",
        "citied_by": "7",
        "cover_date": "2021-03-02",
        "Abstract": "How to operate an unmanned aerial vehicle (UAV) safely and efficiently in an interactive environment is challenging. A large amount of research has been devoted to improve the intelligence of a UAV while performing a mission, where finding an optimal maneuver decision-making policy of the UAV has become one of the key issues when we attempt to enable the UAV autonomy. In this paper, we propose a maneuver decision-making algorithm based on deep reinforcement learning, which generates efficient maneuvers for a UAV agent to execute the airdrop mission autonomously in an interactive environment. Particularly, the training set of the learning algorithm by the Prioritized Experience Replay is constructed, that can accelerate the convergence speed of decision network training in the algorithm. It is shown that a desirable and effective maneuver decision-making policy can be found by extensive experimental results.",
        "DOI": "10.3390/s21062233",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Weakly supervised reinforcement learning for autonomous highway driving via virtual safety cages",
        "paper_author": "Kuutti S.",
        "publication": "Sensors",
        "citied_by": "11",
        "cover_date": "2021-03-02",
        "Abstract": "The use of neural networks and reinforcement learning has become increasingly popular in autonomous vehicle control. However, the opaqueness of the resulting control policies presents a significant barrier to deploying neural network-based control in autonomous vehicles. In this paper, we present a reinforcement learning based approach to autonomous vehicle longitudinal control, where the rule-based safety cages provide enhanced safety for the vehicle as well as weak supervision to the reinforcement learning agent. By guiding the agent to meaningful states and actions, this weak supervision improves the convergence during training and enhances the safety of the final trained policy. This rule-based supervisory controller has the further advantage of being fully interpretable, thereby enabling traditional validation and verification approaches to ensure the safety of the vehicle. We compare models with and without safety cages, as well as models with optimal and constrained model parameters, and show that the weak supervision consistently improves the safety of exploration, speed of convergence, and model performance. Additionally, we show that when the model parameters are constrained or sub-optimal, the safety cages can enable a model to learn a safe driving policy even when the model could not be trained to drive through reinforcement learning alone.",
        "DOI": "10.3390/s21062032",
        "affiliation_name": "University of Surrey",
        "affiliation_city": "Guildford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A Review on Opinion Mining: Approaches, Practices and Application",
        "paper_author": "Ogochukwu O.C.",
        "publication": "International Journal on Recent and Innovation Trends in Computing and Communication",
        "citied_by": "0",
        "cover_date": "2021-03-01",
        "Abstract": "Opinion Mining also known as Sentiment Analysis (SA) has recently become the focus of many researchers, because analysis of online text is useful and demanded in many different applications. Analysis of social sentiments is a trending topic in this era because users share their emotions in more suitable format with the help of micro blogging services like twitter. Twitter provides information about individual's real-time feelings through the data resources provided by persons. The essential task is to extract user's tweets and implement an analysis and survey. However, this extracted information can very helpful to make prediction about the user's opinion towards specific policies. The motive of this paper is to perform a survey on sentiment analysis algorithms that shows the utilizing of different ML and Lexicon investigation methodologies and their accuracy. Our paper also focuses on the three kinds of machine learning algorithms for Sentiment Analysis- Supervised, Unsupervised Algorithms.",
        "DOI": "10.17762/ijritcc.v9i3.5456",
        "affiliation_name": "Nnamdi Azkiwe University",
        "affiliation_city": "Anambra",
        "affiliation_country": "Nigeria"
    },
    {
        "paper_title": "AUTOMATING ACCOUNTABILITY? PRIVACY POLICIES, DATA TRANSPARENCY, AND THE THIRD PARTY PROBLEM",
        "paper_author": "Lie D.",
        "publication": "University of Toronto Law Journal",
        "citied_by": "2",
        "cover_date": "2021-03-01",
        "Abstract": "We have a data transparency problem. Currently, one of the main mechanisms we have to understand data flows is through the self-reporting that organizations provide through privacy policies. These suffer from many well-known problems, problems that are becoming more acute with the increasing complexity of the data ecosystem and the role of third parties – the affiliates, partners, processors, ad agencies, analytic services, and data brokers involved in the contemporary data practices of organizations. In this article, we argue that automating privacy policy analysis can improve the usability of privacy policies as a transparency mechanism. Our argument has five parts. First, we claim that we need to shift from thinking about privacy policies as a transparency mechanism that enhances consumer choice and see them as a transparency mechanism that enhances meaningful accountability. Second, we discuss a research tool that we prototyped, called AppTrans (for Application Transparency), which can detect inconsistencies between the declarations in a privacy policy and the actions the mobile application can potentially take if it is used. We used AppTrans to test seven hundred applications and found that 59.5 per cent were collecting data in ways that were not declared in their policies. The vast majority of the discrepancies were due to third party data collection such as advertising and analytics. Third, we outline the follow-on research we did to extend AppTrans to analyse the information sharing of mobile applications with third parties, with mixed results. Fourth, we situate our findings in relation to the third party issues that came to light in the recent Cambridge Analytica scandal and the calls from regulators for enhanced technical safeguards in managing these third party relationships. Fifth, we discuss some of the limitations of privacy policy automation as a strategy for enhanced data transparency and the policy implications of these limitations.",
        "DOI": "10.3138/utlj-2020-0136",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Ethical implications of alzheimer’s disease prediction in asymptomatic individuals through artificial intelligence",
        "paper_author": "Ursin F.",
        "publication": "Diagnostics",
        "citied_by": "13",
        "cover_date": "2021-03-01",
        "Abstract": "Biomarker-based predictive tests for subjectively asymptomatic Alzheimer’s disease (AD) are utilized in research today. Novel applications of artificial intelligence (AI) promise to predict the onset of AD several years in advance without determining biomarker thresholds. Until now, little attention has been paid to the new ethical challenges that AI brings to the early diagnosis in asymptomatic individuals, beyond contributing to research purposes, when we still lack adequate treatment. The aim of this paper is to explore the ethical arguments put forward for AI aided AD prediction in subjectively asymptomatic individuals and their ethical implications. The ethical assessment is based on a systematic literature search. Thematic analysis was conducted inductively of 18 included publications. The ethical framework includes the principles of autonomy, beneficence, non-maleficence, and justice. Reasons for offering predictive tests to asymptomatic individuals are the right to know, a positive balance of the risk-benefit assessment, and the opportunity for future planning. Reasons against are the lack of disease modifying treatment, the accuracy and explicability of AI aided prediction, the right not to know, and threats to social rights. We conclude that there are serious ethical concerns in offering early diagnosis to asymptomatic individuals and the issues raised by the application of AI add to the already known issues. Nevertheless, pre-symptomatic testing should only be offered on request to avoid inflicted harm. We recommend developing training for physicians in communicating AI aided prediction.",
        "DOI": "10.3390/diagnostics11030440",
        "affiliation_name": "Universität Ulm",
        "affiliation_city": "Ulm",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Category 4: Constructing knowledge about public librarians’ roles in natural disasters: A heuristic inquiry into community resiliency in florida’s hurricane michael",
        "paper_author": "Mardis M.A.",
        "publication": "Library Trends",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "Vulnerable rural residents rely on public librarians for catastrophic weather support; however, many disaster policies are incomplete, outdated, or nonexistent, leaving public librarians with little more than their lived experiences to determine needed actions. Complicating matters further, many public librarians must prioritize community service over their personal needs like damaged homes and nonfunctioning utilities. In this study, researchers and public librarians co-constructed knowledge about library activities before, during, and after Hurricane Michael in 2018. In a heuristic inquiry across three case studies, researchers and participants reflected on actions, perceptions, and outcomes. This process enabled public librarians to realize that before Hurricane Michael, though they had received little communication or direction from municipal leaders, their outreach efforts effectively aided community preparedness. Public librarians noted that even with a limited communications infrastructure (e.g., lack of internet connectivity, fax machines, and cellular service) and hindering bureaucratic requirements, they identified, designed, and provided missing services to high-need communities. Participants saw that reestablishing library functions after the storm superseded their personal needs and updating library disaster policies. The study findings and research method offer researchers and practitioners collaborative ways to capture learning from stressful situations and improve community disaster resiliency.",
        "DOI": "10.1353/lib.2020.0046",
        "affiliation_name": "Florida State University",
        "affiliation_city": "Tallahassee",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Continuous intelligent pandemic monitoring (Cipm)",
        "paper_author": "Duan H.K.",
        "publication": "Journal of Emerging Technologies in Accounting",
        "citied_by": "1",
        "cover_date": "2021-03-01",
        "Abstract": "This proposal applies measurement science (accounting), assurance science (auditing), and machine learning predictive analytics to epidemic research. It utilizes accounting frameworks, such as Continuous Monitoring, to establish a system that can assess the realistic parameters and continuously monitor the evolution of COVID-19 by using exogenous variables. Continuous Intelligent Pandemic Monitoring (CIPM) can generate alerts following risk assessments from the time series, machine learning models, and cross-sectional analytics. CIPM provides policy guidance based on epidemic simulations. The goal is to validate the epidemic related numbers and to provide guidance to policymakers so that sufficient resources can be allocated to the upcoming high risk areas in order to control the spread and lower the impact of the disease. Through this study, we hope to provide different knowledge and perspectives to COVID-19 analysis and a different pandemic measurement and data validation approach.",
        "DOI": "10.2308/JETA-2020-061",
        "affiliation_name": "Rutgers University–New Brunswick",
        "affiliation_city": "New Brunswick",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning and price-based load scheduling for an optimal IoT control in the smart and frugal home",
        "paper_author": "Kaur R.",
        "publication": "Energy and AI",
        "citied_by": "14",
        "cover_date": "2021-03-01",
        "Abstract": "We pose and study a scheduling problem for an electric load to develop an Internet of Things (IoT) control system for power appliances, which takes advantage of real-time dynamic energy pricing. Using historical pricing data from a large U.S. power supplier, we study and compare several dynamic scheduling policies, which can be implemented in a smart home to activate a major appliance (dishwasher, washing machine, clothes dryer) at an optimal time of the day, to minimize electricity costs. We formulate our scheduling task as a supervised machine learning classification problem which activates the load during one of two preferred time bins. The features used in the machine learning problem are hourly market, spot and day-ahead prices along with delayed label of the prior day. We find that boosting tree-based algorithms outperform any other classification approach with measurable reduction of energy costs over certain types of naive and static policies. We observe that the delayed label has most predictive power across features, followed, on average, by spot, hourly market, and day-ahead energy prices. We further discuss implementation issues using a micro controller system coupled with cloud-based serverless computing and dynamic data storage. Our test system includes an interactive voice interface via an intelligent personal assistant.",
        "DOI": "10.1016/j.egyai.2020.100042",
        "affiliation_name": "The Grainger College of Engineering",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Estimating freeway level-of-service using crowdsourced data",
        "paper_author": "Hoseinzadeh N.",
        "publication": "Informatics",
        "citied_by": "13",
        "cover_date": "2021-03-01",
        "Abstract": "In traffic operations, the aim of transportation agencies and researchers is typically to reduce congestion and improve safety. To attain these goals, agencies need continuous and accurate information about the traffic situation. Level-of-Service (LOS) is a beneficial index of traffic operations used to monitor freeways. The Highway Capacity Manual (HCM) provides analytical methods to assess LOS based on traffic density and highway characteristics. Generally, obtaining reliable density data on every road in large networks using traditional fixed location sensors and cameras is expensive and otherwise unrealistic. Traditional intelligent transportation system facilities are typically limited to major urban areas in different states. Crowdsourced data are an emerging, low-cost solution that can potentially improve safety and operations. This study incorporates crowdsourced data provided byWaze to propose an algorithm for LOS assessment on an hourly basis. The proposed algorithm exploits various features from big data (crowdsourced Waze user alerts and speed/travel time variation) to perform LOS classification using machine learning models. Three categories of model inputs are introduced: Basic statistical measures of speed; travel time reliability measures; and the number of hourly Waze alerts. Data collected from fixed location sensors were used to calculate ground truth LOS. The results reveal that using Waze crowdsourced alerts can improve the LOS estimation accuracy by about 10% (accuracy = 0.93, Kappa = 0.83). The proposed method was also tested and confirmed by using data from after coronavirus disease 2019 (COVID-19) with severe traffic breakdown due to a stay-at-home policy. The proposed method is extendible for freeways in other locations. The results of this research provide transportation agencies with a LOS method based on crowdsourced data on different freeway segments, regardless of the availability of traditional fixed location sensors.",
        "DOI": "10.3390/informatics8010017",
        "affiliation_name": "Tickle College of Engineering",
        "affiliation_city": "Knoxville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Proceedings - 2nd International Conference on E-Commerce and Internet Technology, ECIT 2021",
        "paper_author": "NA",
        "publication": "Proceedings - 2nd International Conference on E-Commerce and Internet Technology, ECIT 2021",
        "citied_by": "0",
        "cover_date": "2021-03-01",
        "Abstract": "The proceedings contain 94 papers. The topics discussed include: research on the impact of online lending regulatory policies on P2P platforms take Paipaidai as an example; building Dongguan cross border e-commerce industry 'closed loop' ecosystem with blockchain technology; utilizing machine learning to predict happiness index; research on artificial intelligence, new retail and financial transformation; research on the construction of enterprise quality innovation model based on case analysis; research on financial management of e-commerce service industry; poverty prediction through machine learning; learning-based Airbnb price prediction model; research on the application model of public welfare crowdfunding based on blockchain technology; and application analysis of IoT technology in smart cities.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Analysis on Bilibili Video Categorical Segmentation Using XGBoost",
        "paper_author": "Liu Y.",
        "publication": "Proceedings - 2nd International Conference on E-Commerce and Internet Technology, ECIT 2021",
        "citied_by": "1",
        "cover_date": "2021-03-01",
        "Abstract": "Video media platforms such as YouTube and Bilibili, have been increasingly popular. The industry of video media is developing rapidly and it is one of the main industries that bring monetary to many countries. Bilibili is one of the largest and most popular video sites in China. To make better policies and decisions as well as remain competitive, organizers and uploaders of Bilibili have to understand the features of popular videos. Marketing segmentation can help to achieve this goal. This study presents Bilibili video segmentation with XGBoost, an advanced machine learning algorithm based on tree boosting system. The study was divided into two sections: the categorical analysis and the experiment. The statistical analysis and the experiment are all based on data of videos of the 100 most popular uploaders. In the experiment, the multiclass log loss of XGBoost was 0.519707. The results of this study will be helpful for the management and predictive analysis of Bilibili and the whole video media industry.",
        "DOI": "10.1109/ECIT52743.2021.00063",
        "affiliation_name": "Beijing No.4 High School",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Sales Prediction based on Machine Learning",
        "paper_author": "Huo Z.",
        "publication": "Proceedings - 2nd International Conference on E-Commerce and Internet Technology, ECIT 2021",
        "citied_by": "11",
        "cover_date": "2021-03-01",
        "Abstract": "With the increasing influence of the Internet on people's life, the development of e-commerce platforms is more rapid, with users and earnings of these platforms showing a growing trend. In recent years, the strong support of national policies has also provided a good environment for the development of the e-commerce industry. Under the impact of the epidemic this year, the role of the e-commerce industry in the development of the national economy has become more prominent. In such cases, the number and the competitiveness of e-commerce platforms and e-commerce enterprises are increasing. If a platform wants to maintain its advantage in the competition, it must be able to better meet the needs of users, and do a good job in all aspects of coordination and management. At this point, the accurate forecast of the sales volume of e-commerce platforms is particularly important. At present, there are many studies on e-commerce sales prediction, but we are still exploring the prediction model that can be better applied in different scenarios. In this paper, we try and evaluate two linear models, three machine learning models and two deep learning models, finding that machine learning and deep learning models have no advantage in improving the accuracy of sales forecast, but on a predictive basis, models perform better when they include information on calendar and price.",
        "DOI": "10.1109/ECIT52743.2021.00093",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Non-classical approach to identifying groups of countries based on open innovation indicators",
        "paper_author": "Baboshkin P.",
        "publication": "Journal of Open Innovation: Technology, Market, and Complexity",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "This article aims to highlight various methods and approaches to grouping countries, ac-cording to the behavior of their open innovation indicators. GDP, inflation and unemployment are the most important indicators of the economic and social policies of states, allowing them to be evaluated and models built. To find the relationships between open innovation indicators the paper uses marginal analysis and feature reduction, as well as machine learning methods (shift to the mean, agglomerative clustering and random forest methods). The results showed that, after isolat-ing all groups, the importance of the signs was established and the patterns of behavior of indicators for each group were compared and open innovation dynamics was analyzed. The conclusions showed that it is obvious that increasing the number of variables in the model and using more ex-tensive indicators can greatly increase the accuracy, in contrast to the generally accepted simple classifications. This approach makes it possible to more accurately find the connections between sectors of the economy or between state economies in general. An accompanying result of the study was the clarification of the equality of open innovation indicators for the analysis of their interrela-tionships between countries.",
        "DOI": "10.3390/joitmc7010077",
        "affiliation_name": "İstanbul Medipol Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Türkiye"
    },
    {
        "paper_title": "Understanding patterns and potential drivers of forest diversity in northeastern China using machine-learning algorithms",
        "paper_author": "Luo W.",
        "publication": "Journal of Vegetation Science",
        "citied_by": "8",
        "cover_date": "2021-03-01",
        "Abstract": "Question: Forest ecosystems are the most important global repositories of terrestrial biodiversity. The mixed temperate forests in northeastern China constitute one of the most biodiverse temperate regions globally and provide nearly one-third of China's wood supply. We ask what are the spatial patterns and potential drivers of tree species diversity in mixed temperate forests. Location: Temperate, mixed forests of northeastern China. Methods: Using a large set of ground-source forest inventory data (FIN) and geospatial covariates derived from published raster layers, we compared different machine-learning and statistical models to study spatial patterns of tree species diversity and their underpinning drivers. Results: The spatial distribution of tree species diversity (species richness and evenness) varied greatly across northeastern China. Tree species diversity varied most with climatic (annual precipitation and annual mean temperature), topographic (elevation and slope), and anthropogenic factors. Anthropogenic factors affected tree species evenness (importance value = 13%) more than tree species richness (importance value = 9%). Based on these relationships, we mapped spatial patterns of tree diversity throughout the region at a 1 km × 1 km resolution. Conclusions: Our findings shed light on the processes behind community assembly and biodiversity patterns in mixed temperate forests in northeastern China, and provide a benchmark for future assessment of biodiversity. Our high-resolution tree species diversity maps can be useful to landowners and land management agencies in their decision-making processes about sustainable forest management, biodiversity conservation, and forest restoration — a priority task outlined by the recently implemented 2050 China National Forest Management Plan.",
        "DOI": "10.1111/jvs.13022",
        "affiliation_name": "College of Agriculture",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Intelligent epidemiological surveillance in the Brazilian semiarid",
        "paper_author": "Valter R.",
        "publication": "2020 IEEE International Conference on E-Health Networking, Application and Services, HEALTHCOM 2020",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "Right after the Chinese example in conducting COVID-19 epidemic originated in Wuhan, the readiness to detect and respond by health authorities to local (sometimes global) epidemics has become central lately. Within the idea of health 4.0, information about the individual is essential in supporting public community health policies. This paper presents a proposal for an epidemiological surveillance system applied to arboviruses. Data mining techniques and Machine Learning (ML) are used to design mathematical models for detecting epidemics enhanced by Aedes Aegypti (vector for dengue, chikungunaya, yellow fever and zica). Based on data, it is proposed an adaptive manner to reach better stability on results. A Prove of Concept (PoC) is presented for dengue epidemics detection, a common endemic disease in the semiarid region of Brazil.",
        "DOI": "10.1109/HEALTHCOM49281.2021.9399018",
        "affiliation_name": "Fundacao Oswaldo Cruz",
        "affiliation_city": "Rio de Janeiro",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Forecasting of the COVID-19 pandemic situation of Korea",
        "paper_author": "Goo T.",
        "publication": "Genomics and Informatics",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "For the novel coronavirus disease 2019 (COVID-19), predictive modeling, in the literature, uses broadly susceptible exposed infected recoverd (SEIR)/SIR, agent-based, curve-fitting models. Governments and legislative bodies rely on insights from prediction models to suggest new policies and to assess the effectiveness of enforced policies. Therefore, access to accurate outbreak prediction models is essential to obtain insights into the likely spread and consequences of infectious diseases. The objective of this study is to predict the future COVID-19 situation of Korea. Here, we employed 5 models for this analysis; SEIR, local linear regression (LLR), negative binomial (NB) regression, segment Poisson, deep-learning based long short-term memory models (LSTM) and tree based gradient boosting machine (GBM). After prediction, model performance comparison was evelauated using relative mean squared errors (RMSE) for two sets of train (January 20, 2020–December 31, 2020 and January 20, 2020–January 31, 2021) and testing data (January 1, 2021–February 28, 2021 and February 1, 2021–February 28, 2021). Except for segmented Poisson model, the other models predicted a decline in the daily confirmed cases in the country for the coming future. RMSE values’ comparison showed that LLR, GBM, SEIR, NB, and LSTM respectively, performed well in the forecasting of the pandemic situation of the country. A good understanding of the epidemic dynamics would greatly enhance the control and prevention of COVID-19 and other infectious diseases. Therefore, with increasing daily confirmed cases since this year, these results could help in the pandemic response by informing decisions about planning, resource allocation, and decision concerning social distancing policies.",
        "DOI": "10.5808/gi.21028",
        "affiliation_name": "Seoul National University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Modeling the spatial distribution of anthrax in southern kenya",
        "paper_author": "Otieno F.T.",
        "publication": "PLoS Neglected Tropical Diseases",
        "citied_by": "17",
        "cover_date": "2021-03-01",
        "Abstract": "Background Anthrax is an important zoonotic disease in Kenya associated with high animal and public health burden and widespread socio-economic impacts. The disease occurs in sporadic outbreaks that involve livestock, wildlife, and humans, but knowledge on factors that affect the geographic distribution of these outbreaks is limited, challenging public health intervention planning. Methods Anthrax surveillance data reported in southern Kenya from 2011 to 2017 were modeled using a boosted regression trees (BRT) framework. An ensemble of 100 BRT experiments was developed using a variable set of 18 environmental covariates and 69 unique anthrax locations. Model performance was evaluated using AUC (area under the curve) ROC (receiver operating characteristics) curves. Results Cattle density, rainfall of wettest month, soil clay content, soil pH, soil organic carbon, length of longest dry season, vegetation index, temperature seasonality, in order, were identified as key variables for predicting environmental suitability for anthrax in the region. BRTs per-formed well with a mean AUC of 0.8. Areas highly suitable for anthrax were predicted pre-dominantly in the southwestern region around the shared Kenya-Tanzania border and a belt through the regions and highlands in central Kenya. These suitable regions extend west-wards to cover large areas in western highlands and the western regions around Lake Victo-ria and bordering Uganda. The entire eastern and lower-eastern regions towards the coastal region were predicted to have lower suitability for anthrax. Conclusion These modeling efforts identified areas of anthrax suitability across southern Kenya, including high and medium agricultural potential regions and wildlife parks, important for tourism and foreign exchange. These predictions are useful for policy makers in designing targeted surveillance and/or control interventions in Kenya. We thank the staff of Directorate of Veterinary Services under the Ministry of Agriculture, Livestock and Fisheries, for collecting and providing the anthrax historical occurrence data.",
        "DOI": "10.1371/journal.pntd.0009301",
        "affiliation_name": "South Eastern Kenya University",
        "affiliation_city": "Nairobi",
        "affiliation_country": "Kenya"
    },
    {
        "paper_title": "Digital mental health challenges and the horizon ahead for solutions",
        "paper_author": "Balcombe L.",
        "publication": "JMIR Mental Health",
        "citied_by": "65",
        "cover_date": "2021-03-01",
        "Abstract": "The demand outstripping supply of mental health resources during the COVID-19 pandemic presents opportunities for digital technology tools to fill this new gap and, in the process, demonstrate capabilities to increase their effectiveness and efficiency. However, technology-enabled services have faced challenges in being sustainably implemented despite showing promising outcomes in efficacy trials since the early 2000s. The ongoing failure of these implementations has been addressed in reconceptualized models and frameworks, along with various efforts to branch out among disparate developers and clinical researchers to provide them with a key for furthering evaluative research. However, the limitations of traditional research methods in dealing with the complexities of mental health care warrant a diversified approach. The crux of the challenges of digital mental health implementation is the efficacy and evaluation of existing studies. Web-based interventions are increasingly used during the pandemic, allowing for affordable access to psychological therapies. However, a lagging infrastructure and skill base has limited the application of digital solutions in mental health care. Methodologies need to be converged owing to the rapid development of digital technologies that have outpaced the evaluation of rigorous digital mental health interventions and strategies to prevent mental illness. The functions and implications of human-computer interaction require a better understanding to overcome engagement barriers, especially with predictive technologies. Explainable artificial intelligence is being incorporated into digital mental health implementation to obtain positive and responsible outcomes. Investment in digital platforms and associated apps for real-time screening, tracking, and treatment offer the promise of cost-effectiveness in vulnerable populations. Although machine learning has been limited by study conduct and reporting methods, the increasing use of unstructured data has strengthened its potential. Early evidence suggests that the advantages outweigh the disadvantages of incrementing such technology. The limitations of an evidence-based approach require better integration of decision support tools to guide policymakers with digital mental health implementation. There is a complex range of issues with effectiveness, equity, access, and ethics (eg, privacy, confidentiality, fairness, transparency, reproducibility, and accountability), which warrant resolution. Evidence-informed policies, development of eminent digital products and services, and skills to use and maintain these solutions are required. Studies need to focus on developing digital platforms with explainable artificial intelligence–based apps to enhance resilience and guide the treatment decisions of mental health practitioners. Investments in digital mental health should ensure their safety and workability. End users should encourage the use of innovative methods to encourage developers to effectively evaluate their products and services and to render them a worthwhile investment. Technology-enabled services in a hybrid model of care are most likely to be effective (eg, specialists using these services among vulnerable, at-risk populations but not severe cases of mental ill health).",
        "DOI": "10.2196/26811",
        "affiliation_name": "Griffith Health",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Machine learning models based on remote and proximal sensing as potential methods for in-season biomass yields prediction in commercial sorghum fields",
        "paper_author": "Habyarimana E.",
        "publication": "PLoS ONE",
        "citied_by": "11",
        "cover_date": "2021-03-01",
        "Abstract": "Crop yield monitoring demonstrated the potential to improve agricultural productivity through improved crop breeding, farm management and commodity planning. Remote and proximal sensing offer the possibility to cut crop monitoring costs traditionally associated with surveys and censuses. Fraction of absorbed photosynthetically active radiation (fAPAR), chlorophyll concentration (CI) and normalized difference vegetation (NDVI) indices were used in crop monitoring, but their comparative performances in sorghum monitoring is lacking. This work aimed therefore at closing this gap by evaluating the performance of machine learning modelling of in-season sorghum biomass yields based on Sentinel-2-derived fAPAR and simpler high-throughput optical handheld meters-derived NDVI and CI calculated from sorghum plants reflectance. Bayesian ridge regression showed good cross-validated performance, and high reliability (R2 = 35%) and low bias (mean absolute prediction error, MAPE = 0.4%) during the validation step. Hand-held optical meter-derived CI and Sentinel-2- derived fAPAR showed comparable effects on machine learning performance, but CI outperformed NDVI and was therefore considered as a good alternative to Sentinel-2's fAPAR. The best times to sample the vegetation indices were the months of June (second half) and July. The results obtained in this work will serve several purposes including improvements in plant breeding, farming management and sorghum biomass yield forecasting at extension services and policy making levels.",
        "DOI": "10.1371/journal.pone.0249136",
        "affiliation_name": "Sivas Science and Technology University",
        "affiliation_city": "Sivas",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Joint Load Control and Energy Sharing for Renewable Powered Small Base Stations: A Machine Learning Approach",
        "paper_author": "Piovesan N.",
        "publication": "IEEE Transactions on Green Communications and Networking",
        "citied_by": "38",
        "cover_date": "2021-03-01",
        "Abstract": "The deployment of dense networks of small base stations represents one of the most promising solutions for future mobile networks to meet the foreseen increasing traffic demands. However, such an infrastructure consumes a considerable amount of energy, which, in turn, may represent an issue for the environment and the operational expenses of the mobile operators. The use of renewable energy to supply the small base stations has been recently considered as a mean to reduce the energy footprint of the mobile networks. In this article, we consider a hierarchical structure in which part of the base stations are powered exclusively by solar panels and batteries. Base stations are grouped in clusters and connected in a micro-grid. A central controller enables base station sleep mode and energy sharing among the base stations based on the available energy budget and the traffic demands. We propose three different implementations of the controller through Machine Learning models, namely Imitation Learning, Q-Learning and Deep Q-Learning, capable of learning optimal sleep mode and energy sharing policies. We provide an exhaustive discussion on the achieved performance, complexity and feasibility of the proposed models together with the energy and cost savings attained.",
        "DOI": "10.1109/TGCN.2020.3027063",
        "affiliation_name": "Centre Tecnológic de Telecomunicacions de Catalunya",
        "affiliation_city": "Castelldefels",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Can't find that perfect gift? Blame the bots",
        "paper_author": "Somanath G.",
        "publication": "Computer Fraud and Security",
        "citied_by": "2",
        "cover_date": "2021-03-01",
        "Abstract": "Online fraud rings and retail scalping outfits are increasingly turning to automation and artificial intelligence (AI) for the same reasons that businesses in every industry have embraced these technologies. Simply put, deploying smart machines allows businesses to become more accurate, more efficient and more profitable. In the end, bad actors who work to take advantage of online brands and retailers are entrepreneurs. They embrace innovation and new ways of expanding their portfolios – and their success. Online fraud rings and retail scalping outfits are increasingly turning to automation and artificial intelligence (AI). As much as 70% of traffic to ecommerce checkout pages is generated by malicious bots. Retailers need to turn to machine learning and a powerful data platform, combining a robust fraud solution that can differentiate legitimate from fraudulent transactions with a flexible tool that can understand and monitor complex business policies, explains Gayathri Somanath of Signifyd.",
        "DOI": "10.1016/S1361-3723(21)00028-2",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Targeting and privacy in mobile advertising",
        "paper_author": "Rafieian O.",
        "publication": "Marketing Science",
        "citied_by": "80",
        "cover_date": "2021-03-01",
        "Abstract": "Mobile in-app advertising is now the dominant form of digital advertising. Although these ads have excellent user-tracking properties, they have raised concerns among privacy advocates. This has resulted in an ongoing debate on the value of different types of targeting information, the incentives of ad networks to engage in behavioral targeting, and the role of regulation. To answer these questions, we propose a unified modeling framework that consists of two components—a machine learning framework for targeting and an analytical auction model for examining market outcomes under coun-terfactual targeting regimes. We apply our framework to large-scale data from the leading in-app ad network of an Asian country. We find that an efficient targeting policy based on our machine learning framework improves the average click-through rate by 66.80% over the current system. These gains mainly stem from behavioral information compared with contextual information. Theoretical and empirical counterfactuals show that although total surplus grows with more granular targeting, the ad network’s revenues are nonmonotonic; that is, the most efficient targeting does not maximize ad network revenues. Rather, it is maximized when the ad network does not allow advertisers to engage in behavioral targeting. Our results suggest that ad networks may have economic incentives to preserve users’ privacy without external regulation.",
        "DOI": "10.1287/mksc.2020.1235",
        "affiliation_name": "Cornell SC Johnson College of Business",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A comprehensive overview of the COVID-19 literature: Machine learning-based bibliometric analysis",
        "paper_author": "Abd-Alrazaq A.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "44",
        "cover_date": "2021-03-01",
        "Abstract": "Background: Shortly after the emergence of COVID-19, researchers rapidly mobilized to study numerous aspects of the disease such as its evolution, clinical manifestations, effects, treatments, and vaccinations. This led to a rapid increase in the number of COVID-19-related publications. Identifying trends and areas of interest using traditional review methods (eg, scoping and systematic reviews) for such a large domain area is challenging. Objective: We aimed to conduct an extensive bibliometric analysis to provide a comprehensive overview of the COVID-19 literature. Methods: We used the COVID-19 Open Research Dataset (CORD-19) that consists of a large number of research articles related to all coronaviruses. We used a machine learning-based method to analyze the most relevant COVID-19-related articles and extracted the most prominent topics. Specifically, we used a clustering algorithm to group published articles based on the similarity of their abstracts to identify research hotspots and current research directions. We have made our software accessible to the community via GitHub. Results: Of the 196,630 publications retrieved from the database, we included 28,904 in our analysis. The mean number of weekly publications was 990 (SD 789.3). The country that published the highest number of COVID-19-related articles was China (2950/17,270, 17.08%). The highest number of articles were published in bioRxiv. Lei Liu affiliated with the Southern University of Science and Technology in China published the highest number of articles (n=46). Based on titles and abstracts alone, we were able to identify 1515 surveys, 733 systematic reviews, 512 cohort studies, 480 meta-analyses, and 362 randomized control trials. We identified 19 different topics covered among the publications reviewed. The most dominant topic was public health response, followed by clinical care practices during the COVID-19 pandemic, clinical characteristics and risk factors, and epidemic models for its spread. Conclusions: We provide an overview of the COVID-19 literature and have identified current hotspots and research directions. Our findings can be useful for the research community to help prioritize research needs and recognize leading COVID-19 researchers, institutes, countries, and publishers. Our study shows that an AI-based bibliometric analysis has the potential to rapidly explore a large corpus of academic publications during a public health crisis. We believe that this work can be used to analyze other eHealth-related literature to help clinicians, administrators, and policy makers to obtain a holistic view of the literature and be able to categorize different topics of the existing research for further analyses. It can be further scaled (for instance, in time) to clinical summary documentation. Publishers should avoid noise in the data by developing a way to trace the evolution of individual publications and unique authors.",
        "DOI": "10.2196/23703",
        "affiliation_name": "Hamad Bin Khalifa University, College of Science and Engineering",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar"
    },
    {
        "paper_title": "An effective hybrid approach for forecasting currency exchange rates",
        "paper_author": "Shen M.L.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "10",
        "cover_date": "2021-03-01",
        "Abstract": "Accurately forecasting the movement of exchange rates is of interest in a variety of fields, such as international business, financial management, and monetary policy, though this is not an easy task due to dramatic fluctuations caused by political and economic events. In this study, we develop a new forecasting approach referred to as FSPSOSVR, which is able to accurately predict exchange rates by combining particle swarm optimization (PSO), random forest feature selection, and support vector regression (SVR). PSO is used to obtain the optimal SVR parameters for predicting exchange rates. Our analysis involves the monthly exchange rates from January 1971 to December 2017 of seven countries including Australia, Canada, China, the European Union, Japan, Taiwan, and the United Kingdom. The out-of-sample forecast performance of the FSPSOSVR algorithm is compared with six competing forecasting models using the mean absolute percentage error (MAPE) and root mean square error (RMSE), including random walk, exponential smoothing, autoregres-sive integrated moving average (ARIMA), seasonal ARIMA, SVR, and PSOSVR. Our empirical results show that the FSPSOSVR algorithm consistently yields excellent predictive accuracy, which compares favorably with competing models for all currencies. These findings suggest that the proposed algorithm is a promising method for the empirical forecasting of exchange rates. Finally, we show the empirical relevance of exchange rate forecasts arising from FSPSOSVR by use of foreign exchange carry trades and find that the proposed trading strategies can deliver positive excess returns of more than 3% per annum for most currencies, except for AUD and NTD.",
        "DOI": "10.3390/su13052761",
        "affiliation_name": "National Kaohsiung University of Science and Technology",
        "affiliation_city": "Kaohsiung",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Learning from nighttime observations of gas flaring in north dakota for better decision and policy making",
        "paper_author": "Lu R.",
        "publication": "Remote Sensing",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "In today’s oil industry, companies frequently flare the produced natural gas from oil wells. The flaring activities are extensive in some regions including North Dakota. Besides company-reported data, which are compiled by the North Dakota Industrial Commission, flaring statistics such as count and volume can be estimated via Visible Infrared Imaging Radiometer Suite nighttime observations. Following data gathering and preprocessing, Bayesian machine learning implemented with Markov chain Monte Carlo methods is performed to tackle two tasks: flaring time series analysis and distribution approximation. They help further understanding of the flaring profiles and reporting qualities, which are important for decision/policy making. First, although fraught with measurement and estimation errors, the time series provide insights into flaring approaches and characteristics. Gaussian processes are successful in inferring the latent flaring trends. Second, distribution approximation is achieved by unsupervised learning. The negative binomial and Gaussian mixture models are utilized to describe the distributions of field flare count and volume, respectively. Finally, a nearest-neighbor-based approach for company level flared volume allocation is developed. Potential discrepancies are spotted between the company reported and the remotely sensed flaring profiles.",
        "DOI": "10.3390/rs13050941",
        "affiliation_name": "Space Research Institute of the Russian Academy of Sciences",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Open data and injuries in urban areas—A spatial analytical framework of Toronto using machine learning and spatial regressions",
        "paper_author": "Vaz E.",
        "publication": "PLoS ONE",
        "citied_by": "4",
        "cover_date": "2021-03-01",
        "Abstract": "Injuries have become devastating and often under-recognized public health concerns. In Canada, injuries are the leading cause of potential years of life lost before the age of 65. The geographical patterns of injury, however, are evident both over space and time, suggesting the possibility of spatial optimization of policies at the neighborhood scale to mitigate injury risk, foster prevention, and control within metropolitan regions. In this paper, Canada’s National Ambulatory Care Reporting System is used to assess unintentional and intentional injuries for Toronto between 2004 and 2010, exploring the spatial relations of injury throughout the city, together with Wellbeing Toronto data. Corroborating with these findings, spatial autocorrelations at global and local levels are performed for the reported over 1.7 million injuries. The sub-categorization for Toronto’s neighborhood further distills the most vulnerable communities throughout the city, registering a robust spatial profile throughout. Individual neighborhoods pave the need for distinct policy profiles for injury prevention. This brings one of the main novelties of this contribution. A comparison of the three regression models is carried out. The findings suggest that the performance of spatial regression models is significantly stronger, showing evidence that spatial regressions should be used for injury research. Wellbeing Toronto data performs reasonably well in assessing unintentional injuries, morbidity, and falls. Less so to understand the dynamics of intentional injuries. The results enable a framework to allow tailor-made injury prevention initiatives at the neighborhood level as a vital source for planning and participatory decision making in the medical field in developed cities such as Toronto.",
        "DOI": "10.1371/journal.pone.0248285",
        "affiliation_name": "NOVA Information Management School, Universidade Nova de Lisboa",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Seed optimization framework on draughts",
        "paper_author": "Lin C.N.",
        "publication": "Journal of Information Science and Engineering",
        "citied_by": "0",
        "cover_date": "2021-03-01",
        "Abstract": "Seed optimization has been successfully tested on many games such as Go, Domineering, Breakthrough, among others. Fixed seeds can outperform random seeds by selecting locally optimal seeds as different playing policies. In this article seed optimization has been tested for the Draughts program Scan. We provide a framework which can optimize a draughts program for competition. It does not affect the original program structure, so it improves the strength with no modifying algorithm and no penalty when executing. With the new Best Promise Seed framework, the win rate can be improved by replacing the random seeds with some pretested locally optimal seeds. The optimized program won the championship in the Computer Olympiad in 2015 and 2016. It shows that self learning methodology improves the strength of Scan against other competing programs. In addition, better locally optimal seed(s) may be discovered with a longer learning time, so further strength improvement is possible. All current draughts programs and other different game programs might gain benefit from this framework.",
        "DOI": "10.6688/JISE.202103_37(2).0010",
        "affiliation_name": "INRIA Institut National de Recherche en Informatique et en Automatique",
        "affiliation_city": "Le Chesnay",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Public sentiment toward solar energy—opinion mining of twitter using a transformer-based language model",
        "paper_author": "Kim S.Y.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "44",
        "cover_date": "2021-03-01",
        "Abstract": "Public acceptance and support for renewable energy are important determinants of the low-carbon energy transition. This paper examines public sentiment toward solar energy in the United States using data from Twitter, a micro-blogging platform on which people post messages, known as tweets. We filtered tweets specific to solar energy and performed a classification task using Robustly optimized Bidirectional Encoder Representations from Transformers (RoBERTa). Our RoBERTa-based sentiment classification model, fine-tuned with 6300 manually annotated tweets specific to solar energy, attains 80.2% accuracy for ternary (positive, neutral, or negative) classification. Analyzing 266,686 tweets during the period of January to December 2020, we find public sentiment varies widely across states (Coefficient of Variation = 164.66%). Within the study period, the Northeast U.S. region shows more positive sentiment toward solar energy than did the South U.S. region. Public opinion on solar energy is more positive in states with a larger share of Democratic voters in the 2020 presidential election. Public sentiment toward solar energy is more positive in states with consumer-friendly net metering policies and a more mature solar market. States that wish to gain public support for solar energy might want to consider implementing consumer-friendly net metering policies and support the growth of solar businesses.",
        "DOI": "10.3390/su13052673",
        "affiliation_name": "College of Engineering and Applied Science",
        "affiliation_city": "Boulder",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reviewing the scope and thematic focus of 100 000 publications on energy consumption, services and social aspects of climate change: A big data approach to demand-side mitigation",
        "paper_author": "Creutzig F.",
        "publication": "Environmental Research Letters",
        "citied_by": "42",
        "cover_date": "2021-03-01",
        "Abstract": "As current action remains insufficient to meet the goals of the Paris agreement let alone to stabilize the climate, there is increasing hope that solutions related to demand, services and social aspects of climate change mitigation can close the gap. However, given these topics are not investigated by a single epistemic community, the literature base underpinning the associated research continues to be undefined. Here, we aim to delineate a plausible body of literature capturing a comprehensive spectrum of demand, services and social aspects of climate change mitigation. As method we use a novel double-stacked expert-machine learning research architecture and expert evaluation to develop a typology and map key messages relevant for climate change mitigation within this body of literature. First, relying on the official key words provided to the Intergovernmental Panel on Climate Change by governments (across 17 queries), and on specific investigations of domain experts (27 queries), we identify 121 165 non-unique and 99 065 unique academic publications covering issues relevant for demand-side mitigation. Second, we identify a literature typology with four key clusters: policy, housing, mobility, and food/consumption. Third, we systematically extract key content-based insights finding that the housing literature emphasizes social and collective action, whereas the food/consumption literatures highlight behavioral change, but insights also demonstrate the dynamic relationship between behavioral change and social norms. All clusters point to the possibility of improved public health as a result of demand-side solutions. The centrality of the policy cluster suggests that political actions are what bring the different specific approaches together. Fourth, by mapping the underlying epistemic communities we find that researchers are already highly interconnected, glued together by common interests in sustainability and energy demand. We conclude by outlining avenues for interdisciplinary collaboration, synthetic analysis, community building, and by suggesting next steps for evaluating this body of literature.",
        "DOI": "10.1088/1748-9326/abd78b",
        "affiliation_name": "Mercator Research Institute on Global Commons and Climate Change",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "The challenges of machine learning and their economic implications",
        "paper_author": "Borrellas P.",
        "publication": "Entropy",
        "citied_by": "8",
        "cover_date": "2021-03-01",
        "Abstract": "The deployment of machine learning models is expected to bring several benefits. Nevertheless, as a result of the complexity of the ecosystem in which models are generally trained and deployed, this technology also raises concerns regarding its (1) interpretability, (2) fairness, (3) safety, and (4) privacy. These issues can have substantial economic implications because they may hinder the development and mass adoption of machine learning. In light of this, the purpose of this paper was to determine, from a positive economics point of view, whether the free use of machine learning models maximizes aggregate social welfare or, alternatively, regulations are required. In cases in which restrictions should be enacted, policies are proposed. The adaptation of current tort and anti-discrimination laws is found to guarantee an optimal level of interpretability and fairness. Additionally, existing market solutions appear to incentivize machine learning operators to equip models with a degree of security and privacy that maximizes aggregate social welfare. These findings are expected to be valuable to inform the design of efficient public policies.",
        "DOI": "10.3390/e23030275",
        "affiliation_name": "Universitat Ramon Llull, ESADE",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Education for future biobankers - The state-of-the-art and outlook",
        "paper_author": "Kinkorová J.",
        "publication": "EPMA Journal",
        "citied_by": "22",
        "cover_date": "2021-03-01",
        "Abstract": "Biobanking as a quickly growing branch of personalised medicine has undergone enormous progress during last two decades. Nowadays it is a well developed and structured multidisciplinary field that reflects developments and advances of biomedical research based on principles of predictive, preventive and personalised medicine (PPPM/3PM). All these trends in PPPM progress have to be translated into practice and education of new generation of scientists and healthcare givers. The importance of biobanks for multitasking research, personalised treatment, and health care systems was emphasised by many scientists and health care experts. As biobanking carries multidisciplinary character currently including more professionals than ten—twenty years ago, new generation of professional biobankers is urgently needed. To create new generation of biobankers who are fully competent to answer more and more scientific and practical questions, new study programmes, novel university curricula, and topic-dedicated courses are essential. The aim of the review is to present basic forms, trends of biobanking education offered by various biobanking related bodies and to highlight future needs. The first step is to cover all activities and duties of biobanks: acquiring, collecting, storageing and sharing biological samples and associated data, using adequate assessment for both - materials and data, taking into consideration ethical, legal, and societal issues (ELSI), responding to all stakeholder needs including pharmaceutical and other related industries, patient organisations and many other interested groups, emerging technologies and innovations as well as current and future requirements of health care systems. To compile educational programmes is a comprehensive task for all actors involved in the field of biobanking who contribute to the harmonised process of creating high educational level for future generation of biobankers. The exchange of experience involving extensive international collaboration is the way how to facilitate the process of creating optimal biobanking education.",
        "DOI": "10.1007/s13167-021-00234-5",
        "affiliation_name": "Charles University",
        "affiliation_city": "Prague",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "COVID-19 lockdown only partially alleviates health impacts of air pollution in Northern Italy",
        "paper_author": "Granella F.",
        "publication": "Environmental Research Letters",
        "citied_by": "30",
        "cover_date": "2021-03-01",
        "Abstract": "Evaluating the reduction in pollution caused by a sudden change in emissions is complicated by the confounding effect of weather variations. We propose an approach based on machine learning to build counterfactual scenarios that address the effect of weather and apply it to the COVID-19 lockdown of Lombardy, Italy. We show that the lockdown reduced background concentrations of PM2.5 by 3.84 µg m−3 (16%) and NO2 by 10.85 µg m−3 (33%). Improvement in air quality saved at least 11% of the years of life lost and 19% of the premature deaths attributable to COVID-19 in the region during the same period. The analysis highlights the benefits of improving air quality and the need for an integrated policy response addressing the full diversity of emission sources.",
        "DOI": "10.1088/1748-9326/abd3d2",
        "affiliation_name": "Euro-Mediterranean Center on Climate Change, Milan",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Application of the random forest classifier to map irrigated areas using google earth engine",
        "paper_author": "Magidi J.",
        "publication": "Remote Sensing",
        "citied_by": "99",
        "cover_date": "2021-03-01",
        "Abstract": "Improvements in irrigated areas’ classification accuracy are critical to enhance agricultural water management and inform policy and decision-making on irrigation expansion and land use planning. This is particularly relevant in water-scarce regions where there are plans to increase the land under irrigation to enhance food security, yet the actual spatial extent of current irrigation areas is unknown. This study applied a non-parametric machine learning algorithm, the random forest, to process and classify irrigated areas using images acquired by the Landsat and Sentinel satellites, for Mpumalanga Province in Africa. The classification process was automated on a big-data management platform, the Google Earth Engine (GEE), and the R-programming was used for post-processing. The normalised difference vegetation index (NDVI) was subsequently used to distinguish between irrigated and rainfed areas during 2018/19 and 2019/20 winter growing seasons. High NDVI values on cultivated land during the dry season are an indication of irrigation. The classification of cultivated areas was for 2020, but 2019 irrigated areas were also classified to assess the impact of the Covid-19 pandemic on agriculture. The comparison in irrigated areas between 2019 and 2020 facilitated an assessment of changes in irrigated areas in smallholder farming areas. The approach enhanced the classification accuracy of irrigated areas using ground-based training samples and very high-resolution images (VHRI) and fusion with existing datasets and the use of expert and local knowledge of the study area. The overall classification accuracy was 88%.",
        "DOI": "10.3390/rs13050876",
        "affiliation_name": "University of Venda",
        "affiliation_city": "Thohoyandou",
        "affiliation_country": "South Africa"
    },
    {
        "paper_title": "Incremental Propensity Score Effects for Time-fixed Exposures",
        "paper_author": "Naimi A.I.",
        "publication": "Epidemiology",
        "citied_by": "10",
        "cover_date": "2021-03-01",
        "Abstract": "When causal inference is of primary interest, a range of target parameters can be chosen to define the causal effect, such as average treatment effects (ATEs). However, ATEs may not always align with the research question at hand. Furthermore, the assumptions needed to interpret estimates as ATEs, such as exchangeability, consistency, and positivity, are often not met. Here, we present the incremental propensity score (PS) approach to quantify the effect of shifting each person's exposure propensity by some predetermined amount. Compared with the ATE, incremental PS may better reflect the impact of certain policy interventions and do not require that positivity hold. Using the Nulliparous Pregnancy Outcomes Study: monitoring mothers-to-be (nuMoM2b), we quantified the relationship between total vegetable intake and the risk of preeclampsia and compared it to average treatment effect estimates. The ATE estimates suggested a reduction of between two and three preeclampsia cases per 100 pregnancies for consuming at least half a cup of vegetables per 1,000 kcal. However, positivity violations obfuscate the interpretation of these results. In contrast, shifting each woman's exposure propensity by odds ratios ranging from 0.20 to 5.0 yielded no difference in the risk of preeclampsia. Our analyses show the utility of the incremental PS effects in addressing public health questions with fewer assumptions.",
        "DOI": "10.1097/EDE.0000000000001315",
        "affiliation_name": "Magee-Womens Research Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Autonomous robots: a new reality in healthcare? A project by European Association of Urology-Young Academic Urologist group",
        "paper_author": "Gómez Rivas J.",
        "publication": "Current Opinion in Urology",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "Purpose of reviewArtificial intelligence appears as a potential revolution in the general process of medical training, disease diagnosis and treatment. A novel disruptive technology of the 21st century will be 'learner' robots from artificial intelligence systems able to use all the combination of the available knowledge in medical repositories to give the best standard of care.Recent findingsThe autonomy level of robots depends on three factors: the complexity of the task; the environment in which the robot operates, and the required level of human-robot interaction. Autonomous robots in healthcare may be classified in delivery, nurse, and surgical robots. The increasing capability of robots to perform independent actions and complex tasks raises responsibility and accountability issues in a wide variety of application domains. Ethical analyses of these issues are underway and are mostly oriented toward the development of ethical policies requiring a law frame on robotic autonomous behaviors.SummaryAutonomous robots have the potential to improve current medical practice offering a more secure, reliable, and reproducible medicine. Many advancements are required for these new technologies to be fully integrated. Furthermore, the ethical implications of these technologies are yet to be evaluated.",
        "DOI": "10.1097/MOU.0000000000000842",
        "affiliation_name": "European Association of Urology",
        "affiliation_city": "Arnhem",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Emotion Classification of Case-Related Microblog Comments Integrating Emotional Knowledge",
        "paper_author": "Guo X.W.",
        "publication": "Jisuanji Xuebao/Chinese Journal of Computers",
        "citied_by": "12",
        "cover_date": "2021-03-01",
        "Abstract": "Currently, social media platforms represented by Weibo allow users to express their opinions and emotions anytime and anywhere due to their openness and convenience. The case-related microblog public opinion is a kind of Internet public opinion related to the case, which has the characteristics of fast transmission speed and high sensitivity. Emotion classification of case-related microblog comments is a multi-classification task of sentiment in a specific field, which aims to quickly and effectively identify the emotions in a large number of comments. This task helps relevant departments to timely evaluate public opinion risks and formulate relevant policies. Emotion classification usually uses the following methods: methods based on emotion dictionary, methods based on traditional machine learning, and methods based on deep learning. Emotion dictionary-based methods, which rely heavily on the emotion dictionary, and the Internet is full of new words to express emotions, it is impractical to improve the emotion dictionary in real-time. Traditional machine learning-based methods often use supervised learning methods, which rely on large amounts of labeled data and complex feature engineering. Deep learning-based methods generally encode text as a whole and lack the effective use of existing emotion computing resources. Since it is difficult for traditional methods to effectively use emotional knowledge such as the emotion words and emoticons commonly used in comments, this paper proposes an emotion classification method of case-related microblog comments that integrates emotional knowledge. This method uses a convolutional neural network with a semantic initialization filter and a fully connected network combined with an attention mechanism to fuse the semantic features and emotional knowledge features of comments to achieve emotion classification. Firstly, it integrates the existing sentiment computing resources to construct an emotional knowledge base that includes the case microblog emotion dictionary, emoticons, network buzzwords, negative words, and degree adverb words. Secondly, considering the role of the emotional knowledge base and part of speech, 15 kinds of emotional knowledge are defined, and the emotional knowledge representation of comments is constructed by the continuous vector representation method proposed in this paper. Then, the semantic representation and emotional knowledge representation of comments are input into a convolutional neural network with semantic initialization filters (INIT-CNN) and a fully connected network with attention mechanism, to obtain a deep semantic feature vector and an attention feature vector. Finally, the two feature vectors are concatenated to fuse semantic and emotional knowledge features to train an emotion classification model, called EK-INIT-CNN(Emotional knowledge enhanced INIT-CNN). In order to prove the effectiveness of the model in this paper, experiments were conducted on the case-related microblog comment dataset and the NLPCC Chinese microblog emotion analysis evaluation dataset. Experiments on the case-related microblog comment dataset show that compared to INIT-CNN, the Macro_Precision, Macro_Recall, and Macro_F1 indicators of EK-INIT-CNN have increased by 1.87%, 1.95%, and 1.88%, respectively. The performance of EK-INIT-CNN on NLPCC Chinese microblog emotion analysis evaluation dataset exceeds the best results in the known literature. Experiments show that this method can effectively integrate external emotion knowledge, and has obvious advantages in emotion classification tasks compared to traditional methods.",
        "DOI": "10.11897/SP.J.1016.2021.00564",
        "affiliation_name": "Kunming University of Science and Technology",
        "affiliation_city": "Kunming",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Multiagent Deep-Reinforcement-Learning-Based Virtual Resource Allocation through Network Function Virtualization in Internet of Things",
        "paper_author": "Shah H.A.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "41",
        "cover_date": "2021-03-01",
        "Abstract": "Resource allocation is a significant task in the emerging area of Internet of Things (IoT). IoT devices are usually low-cost devices with limited computational power and capabilities for long term communication. In this article, the network function virtualization (NFV) technique is used to access resources of the network and a reinforcement learning (RL) algorithm is used to solve the problem of resource allocation in IoT networks. The traffic of the IoT network uses the substrate network which is available through NFV for its data transmission. The data transmission needs of the IoT network are translated to virtual requests and service function chain (SFC) are mapped to the substrate network to serve the requests. The problem of SFC placement while meeting the system constraints of the IoT network is a nonconvex problem. In the proposed deep RL (DRL)-based resource allocation, the virtual layer acts as a common repository of the network resources. The optimization problem of SFC placement under the system constraints of IoT networks can be formulated as a Markovian decision process (MDP). The MDP problem is solved through a multiagent DRL algorithm where each agent serves an SFC. Two Q-networks are considered, where one Q-network solves the SFC placement problem while the other updates weights of the Q-network through keeping track of long-term policy changes. The virtual agents serving SFCs interact with the environment, receive reward collectively and update the policy by using the learned experiences. We show that the proposed scheme can solve the optimization problem of SFC placement through adequate reward design, state, and action space formulation. Simulation results demonstrate that the multiagent DRL scheme outperforms the reference schemes in terms of utility gained as measured through different network parameters.",
        "DOI": "10.1109/JIOT.2020.3022572",
        "affiliation_name": "Toronto Metropolitan University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "IHSF: An Intelligent Solution for Improved Performance of Reliable and Time-Sensitive Flows in Hybrid SDN-Based FC IoT Systems",
        "paper_author": "Ibrar M.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "40",
        "cover_date": "2021-03-01",
        "Abstract": "The integration of software-defined networking (SDN) into legacy networks causes both operational and deployment issues. In this context, this article proposes a novel approach, called An Intelligent Solution for Improved Performance of Reliable and Time-sensitive Flows in hybrid SDN-based fog computing IoT systems (IHSF). The proposed IHSF approach has three solutions: 1) a novel algorithm to deploy SDN switches between legacy switches to improve network observability; 2) a {K}-nearest neighbor regression algorithm to predict in real time the reliability of legacy links at the SDN controller based on historic data; this enables the SDN controller to make timely decisions, improving system performance; and 3) a reliable and time-sensitive deep deterministic policy gradient algorithm (RT-DDPG), which optimally computes forwarding paths in hybrid SDN-F for time-critical traffic flows generated by IoT applications. The simulation results show that our proposed IHSF solution has a better performance than the existing approach in terms of network observability time, number of disturbed flows, end-to-end delay, and packet delivery ratio.",
        "DOI": "10.1109/JIOT.2020.3024560",
        "affiliation_name": "Abdul Wali Khan University Mardan",
        "affiliation_city": "Mardan",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Deep reinforcement learning-based task scheduling in iot edge computing",
        "paper_author": "Sheng S.",
        "publication": "Sensors",
        "citied_by": "109",
        "cover_date": "2021-03-01",
        "Abstract": "Edge computing (EC) has recently emerged as a promising paradigm that supports resource-hungry Internet of Things (IoT) applications with low latency services at the network edge. However, the limited capacity of computing resources at the edge server poses great challenges for scheduling application tasks. In this paper, a task scheduling problem is studied in the EC scenario, and multiple tasks are scheduled to virtual machines (VMs) configured at the edge server by maximizing the long-term task satisfaction degree (LTSD). The problem is formulated as a Markov decision process (MDP) for which the state, action, state transition, and reward are designed. We leverage deep reinforcement learning (DRL) to solve both time scheduling (i.e., the task execution order) and resource allocation (i.e., which VM the task is assigned to), considering the diversity of the tasks and the heterogeneity of available resources. A policy-based REINFORCE algorithm is proposed for the task scheduling problem, and a fully-connected neural network (FCN) is utilized to extract the features. Simulation results show that the proposed DRL-based task scheduling algorithm outperforms the existing methods in the literature in terms of the average task satisfaction degree and success ratio.",
        "DOI": "10.3390/s21051666",
        "affiliation_name": "Shanghai Dianji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Article a deep learning model for classification of endoscopic gastroesophageal reflux disease",
        "paper_author": "Wang C.C.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "27",
        "cover_date": "2021-03-01",
        "Abstract": "Gastroesophageal reflux disease (GERD) is a common disease with high prevalence, and its endoscopic severity can be evaluated using the Los Angeles classification (LA grade). This paper proposes a deep learning model (i.e., GERD-VGGNet) that employs convolutional neural networks for automatic classification and interpretation of routine GERD LA grade. The proposed model employs a data augmentation technique, a two-stage no-freezing fine-tuning policy, and an early stopping criterion. As a result, the proposed model exhibits high generalizability. A dataset of images from 464 patients was used for model training and validation. An additional 32 patients served as a test set to evaluate the accuracy of both the model and our trainees. Experimental results demonstrate that the best model for the development set exhibited an overall accuracy of 99.2% (grade A–B), 100% (grade C–D), and 100% (normal group) using narrow-band image (NBI) endoscopy. On the test set, the proposed model resulted in an accuracy of 87.9%, which was significantly higher than the results of the trainees (75.0% and 65.6%). The proposed GERD-VGGNet model can assist automatic classification of GERD in conventional and NBI environments and thereby increase the accuracy of interpretation of the results by inexperienced endoscopists.",
        "DOI": "10.3390/ijerph18052428",
        "affiliation_name": "Chung Shan Medical University Hospital",
        "affiliation_city": "Taichung",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Advancing hypertension management in Asia 2021, beyond COVID-19",
        "paper_author": "Schutte A.E.",
        "publication": "Journal of Clinical Hypertension",
        "citied_by": "1",
        "cover_date": "2021-03-01",
        "Abstract": "NA",
        "DOI": "10.1111/jch.14211",
        "affiliation_name": "George Institute for Global Health",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Predicting corporate carbon footprints for climate finance risk analyses: A machine learning approach",
        "paper_author": "Nguyen Q.",
        "publication": "Energy Economics",
        "citied_by": "66",
        "cover_date": "2021-03-01",
        "Abstract": "Corporations have come under pressure from investors and other stakeholders to disclose and reduce their greenhouse gas emissions (GHG). Corporate GHG footprints, proxying for transition risk, are dominated by carbon emissions from energy use. Thus the growing attention on the carbon emissions of corporations from, principally, their energy use, motivates firms to invest in energy efficiency and renewable energy. However, only a subset of corporations disclose their GHG/carbon footprints. This paper uses machine learning to improve the prediction of corporate carbon emissions for risk analyses by investors. We introduce a two-step framework that applies a Meta-Elastic Net learner to combine predictions from multiple base-learners as the best emission prediction approach. It results in an accuracy gain based on mean absolute error of up to 30% as compared with the existing models. We also find that prediction accuracy can be further improved by incorporating additional predictors (energy production/consumption data) and additional firm disclosures in particular sectors and regions. This provides an indication of where policymakers should concentrate their efforts for greater level of disclosure.",
        "DOI": "10.1016/j.eneco.2021.105129",
        "affiliation_name": "University of Otago",
        "affiliation_city": "Dunedin",
        "affiliation_country": "New Zealand"
    },
    {
        "paper_title": "Approval of artificial intelligence and machine learning-based medical devices in the USA and Europe (2015–20): a comparative analysis",
        "paper_author": "Muehlematter U.J.",
        "publication": "The Lancet Digital Health",
        "citied_by": "355",
        "cover_date": "2021-03-01",
        "Abstract": "There has been a surge of interest in artificial intelligence and machine learning (AI/ML)-based medical devices. However, it is poorly understood how and which AI/ML-based medical devices have been approved in the USA and Europe. We searched governmental and non-governmental databases to identify 222 devices approved in the USA and 240 devices in Europe. The number of approved AI/ML-based devices has increased substantially since 2015, with many being approved for use in radiology. However, few were qualified as high-risk devices. Of the 124 AI/ML-based devices commonly approved in the USA and Europe, 80 were first approved in Europe. One possible reason for approval in Europe before the USA might be the potentially relatively less rigorous evaluation of medical devices in Europe. The substantial number of approved devices highlight the need to ensure rigorous regulation of these devices. Currently, there is no specific regulatory pathway for AI/ML-based medical devices in the USA or Europe. We recommend more transparency on how devices are regulated and approved to enable and improve public trust, efficacy, safety, and quality of AI/ML-based medical devices. A comprehensive, publicly accessible database with device details for Conformité Européene (CE)-marked medical devices in Europe and US Food and Drug Administration approved devices is needed.",
        "DOI": "10.1016/S2589-7500(20)30292-2",
        "affiliation_name": "UniversitatsSpital Zurich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Managing shutdown decisions in merchant commodity and energy production: A social commerce perspective",
        "paper_author": "Trivella A.",
        "publication": "Manufacturing and Service Operations Management",
        "citied_by": "11",
        "cover_date": "2021-03-01",
        "Abstract": "Problem definition: Merchant commodity and energy production assets operate in markets with volatile prices and exchange rates. Plant closures adversely affect societal entities beyond the specific plant being shut down, such as the parent company and the local community. Motivated by an aluminum producer, we study if mitigating these hardto-assess broader impacts of a shutdown is financially viable using the plant s operating flexibility. Academic/practical relevance: Our social commerce perspective toward managing shutdown decisions deviates from the commonly used asset value maximization objective in merchant operations. Identifying operating policies that delay or decrease the likelihood of a shutdown without incurring a significant asset value loss supports socially responsible plant shutdown decisions. Methodology:We formulate a constrained Markov decision process to manage shutdown decisions and limit the probability of future plant closures. We provide theoretical support for approximating this intractable model using unconstrained stochastic dynamic programs with modified shutdown costs and explore two classes of operating policies. Our first policy leverages anticipated regret theory, and the second policy generalizes, using machine learning, production-margin heuristics used in practice. We compute the former and latter policies using a least squares Monte Carlo method and combining this method with binary classification, respectively. Results: Anticipated-regret policies possess desirable asymptotic properties absent in classificationbased policies. On instances created using real data, anticipated-regret and classificationbased policies outperform practice-based production-margin strategies. Significant reductions in shutdown probability and delays in plant closures are possible while incurring small asset value losses. Managerial implications: A plant s operating flexibility provides an effective lever to balance the social objective to reduce closures and the financial goal to maximize asset value. Adhering to both objectives requires combining short-Term commitments with external stakeholders to avoid shutdown with longer-Term internal efforts to reduce the probability of plant closures.",
        "DOI": "10.1287/msom.2019.0850",
        "affiliation_name": "School of Business, Economics and Informatics",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Ophthalmology and the emergence of artificial intelligence",
        "paper_author": "Scheetz J.",
        "publication": "Medical Journal of Australia",
        "citied_by": "11",
        "cover_date": "2021-03-01",
        "Abstract": "NA",
        "DOI": "10.5694/mja2.50932",
        "affiliation_name": "University of Melbourne",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Towards Strong AI",
        "paper_author": "Butz M.V.",
        "publication": "KI - Kunstliche Intelligenz",
        "citied_by": "26",
        "cover_date": "2021-03-01",
        "Abstract": "Strong AI—artificial intelligence that is in all respects at least as intelligent as humans—is still out of reach. Current AI lacks common sense, that is, it is not able to infer, understand, or explain the hidden processes, forces, and causes behind data. Main stream machine learning research on deep artificial neural networks (ANNs) may even be characterized as being behavioristic. In contrast, various sources of evidence from cognitive science suggest that human brains engage in the active development of compositional generative predictive models (CGPMs) from their self-generated sensorimotor experiences. Guided by evolutionarily-shaped inductive learning and information processing biases, they exhibit the tendency to organize the gathered experiences into event-predictive encodings. Meanwhile, they infer and optimize behavior and attention by means of both epistemic- and homeostasis-oriented drives. I argue that AI research should set a stronger focus on learning CGPMs of the hidden causes that lead to the registered observations. Endowed with suitable information-processing biases, AI may develop that will be able to explain the reality it is confronted with, reason about it, and find adaptive solutions, making it Strong AI. Seeing that such Strong AI can be equipped with a mental capacity and computational resources that exceed those of humans, the resulting system may have the potential to guide our knowledge, technology, and policies into sustainable directions. Clearly, though, Strong AI may also be used to manipulate us even more. Thus, it will be on us to put good, far-reaching and long-term, homeostasis-oriented purpose into these machines.",
        "DOI": "10.1007/s13218-021-00705-x",
        "affiliation_name": "Eberhard Karls Universität Tübingen",
        "affiliation_city": "Tubingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Utilizing world urban database and access portal tools (WUDAPT) and machine learning to facilitate spatial estimation of heatwave patterns",
        "paper_author": "Shi Y.",
        "publication": "Urban Climate",
        "citied_by": "16",
        "cover_date": "2021-03-01",
        "Abstract": "Climate change lead to more intense, higher frequent and prolonged heat extremes. Understanding the spatial pattern of heatwave is vital for providing the corresponding weather services, making climate change adaptation strategies and heat-health actions. In this study, we present an approach to estimate the heatwave spatial patterns by utilizing the WUDAPT Level 0 data and machine learning. The analysis is based on two years (2009 and 2016) of air temperature data from 86 meteorological monitoring stations in Guangdong province of China, a subtropical region with frequent hot and sultry weather in summer. First, heatwave conditions were quantified by calculating the number of hot days and frequency of heatwave events in each year and used as the response variables. Then, random forest models were built by using a geospatial dataset consisting of WUDAPT and urban canopy parameters (UCP) as predictor variables. Based on the resultant models, spatial patterns of heatwave were estimated and mapped at 100 m spatial-resolution. The results show that this approach is able to estimate heatwave spatial patterns using open data and inform urban policy and decision-making. The study is also a new perspective and a feasible pathway of utilizing WUDPAT Level 0 product to facilitate urban environment applications.",
        "DOI": "10.1016/j.uclim.2021.100797",
        "affiliation_name": "Nanjing University of Information Science &amp; Technology",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A comparison of the value of two machine learning predictive models to support bovine tuberculosis disease control in England",
        "paper_author": "Romero M.P.",
        "publication": "Preventive Veterinary Medicine",
        "citied_by": "10",
        "cover_date": "2021-03-01",
        "Abstract": "Nearly a decade into Defra's current eradication strategy, bovine tuberculosis (bTB) remains a serious animal health problem in England, with c.30,000 cattle slaughtered annually in the fight against this insidious disease. There is an urgent need to improve our understanding of bTB risk in order to enhance the current disease control policy. Machine learning approaches applied to big datasets offer a potential way to do this. Regularized regression and random forest machine learning methodologies were implemented using 2016 herd-level data to generate the best possible predictive models for a bTB incident in England and its three surveillance risk areas (High-risk area [HRA], Edge area [EA] and Low-risk area [LRA]). Their predictive performance was compared and the best models in each area were used to characterize herds according to risk. While all models provided excellent discrimination, random forest models achieved the highest balanced accuracy (i.e. average of sensitivity and specificity) in England, HRA and LRA, whereas the regularized regression LASSO model did so in the EA. The time since the last confirmed incident was resolved was the only variable in the top-ten ranking in all areas according to both types of models, which highlights the importance of bTB history as a predictor of a new incident. Risk categorisation based on Receiver Operating Characteristic (ROC) analysis was carried out using the best predictive models in each area setting a 99 % threshold value for sensitivity and specificity (97 % in the LRA). Thirteen percent of herds in the whole of England as well as in its HRA, 14 % in its EA and 31 % in its LRA were classified as high-risk. These could be selected for the deployment of additional disease control measures at national or area level. In this way, low-risk herds within the area considered would not be penalised unnecessarily by blanket control measures and limited resources be used more efficiently. The methodology presented in this paper demonstrates a way to accurately identify high-risk farms to inform a targeted disease control and prevention strategy in England that supplements existing population strategies.",
        "DOI": "10.1016/j.prevetmed.2021.105264",
        "affiliation_name": "Animal and Plant Health Agency",
        "affiliation_city": "Addlestone",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Application of telemedicine and eHealth technology for clinical services in response to COVID‑19 pandemic",
        "paper_author": "Bokolo A.J.",
        "publication": "Health and Technology",
        "citied_by": "142",
        "cover_date": "2021-03-01",
        "Abstract": "Telemedicine and eHealth refer to the use of information and communication technology (ICT) embedded in software programs with highspeed telecommunications systems for delivery, management, and monitoring of healthcare services. Application of telemedicine have become timely while providing great potentials to protect both medical practitioners and patients, as well as limit social mobility of patients contributing to reduce the spread of the virus. This study employs data from the existing literature to describe the application of telemedicine and eHealth as a proactive measure to improve clinical care. Findings from this study present the significance of telemedicine and current applications adopted during the pandemic. More importantly, the findings present practical application of telemedicine and eHealth for clinical services. Also, polices initiated across the world to promote management of COVID-19 are discussed. Respectively, this study suggests that telemedicine and eHealth can be adopted in times of health emergency, as a convenient, safe, scalable, effective, and green method of providing clinical care.",
        "DOI": "10.1007/s12553-020-00516-4",
        "affiliation_name": "Norges Teknisk-Naturvitenskapelige Universitet",
        "affiliation_city": "Trondheim",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "The quest for multidimensional financial immunity to the COVID-19 pandemic: Evidence from international stock markets",
        "paper_author": "Zaremba A.",
        "publication": "Journal of International Financial Markets, Institutions and Money",
        "citied_by": "68",
        "cover_date": "2021-03-01",
        "Abstract": "What determines a country's financial immunity to a global pandemic? To answer this question, we investigate the behavior of 67 equity markets around the world during the COVID-19 outbreak in 2020. We consider a multidimensional data set that includes factors from finance, economics, demographics, technological development, healthcare, governance, culture, and law. Our study also accounts for government interventions, such as containment and closure policies, and economic stimuli. We apply machine learning techniques, panel regression, and factor analysis to ascertain sources of financial immunity to the coronavirus pandemic. Our findings demonstrate that stock markets in countries with low unemployment rates and populated with firms with conservative investment policies and low valuations relative to expected profits tend to be more immune to the healthcare crisis. We also find that firm government policy responses tend to support stock markets in times of the pandemic.",
        "DOI": "10.1016/j.intfin.2021.101284",
        "affiliation_name": "Southampton Business School",
        "affiliation_city": "Southampton",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Conspiracy vs science: A large-scale analysis of online discussion cascades",
        "paper_author": "Zhang Y.",
        "publication": "World Wide Web",
        "citied_by": "14",
        "cover_date": "2021-03-01",
        "Abstract": "With the emergence and rapid proliferation of social media platforms and social networking sites, recent years have witnessed a surge of misinformation spreading in our daily life. Drawing on a large-scale dataset which covers more than 1.4M posts and 18M comments from an online social media platform, we investigate the propagation of two distinct narratives–(i) conspiracy information, whose claims are generally unsubstantiated and thus referred as misinformation to some extent, and (ii) scientific information, whose origins are generally readily identifiable and verifiable. We find that conspiracy cascades tend to propagate in a multigenerational branching process whereas science cascades are more likely to grow in a breadth-first manner. Specifically, conspiracy information triggers larger cascades, involves more users and generations, persists longer, and is more viral and bursty than science information. Content analysis reveals that conspiracy cascades contain more negative words and emotional words which convey anger, fear, disgust, surprise and trust. We also find that conspiracy cascades are much more concerned with political and controversial topics. After applying machine learning models, we achieve an AUC score of nearly 90% in discriminating conspiracy from science narratives using the constructed features. We further investigate user’s role during the growth of cascades. In contrast with previous assumption that misinformation is primarily driven by a small set of users, we find that conspiracy cascades are more likely to be controlled by a broader set of users than science cascades, imposing new challenges on the management of misinformation. Although political affinity is thought to affect the consumption of misinformation, there is very little evidence that political orientation of the information source plays a role during the propagation of conspiracy information; Instead, we find that conspiracy information from media outlets with left or right orientation triggers smaller cascades and is less viral than information from online social media platforms (e.g., Twitter and Imgur) whose political orientations are unclear. Our study provides complementing evidence to current misinformation research and has practical policy implications to stem the propagation and mitigate the influence of misinformation online.",
        "DOI": "10.1007/s11280-021-00862-x",
        "affiliation_name": "Key Laboratory of System Control and Information Processing, Ministry of Education",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Use of Machine Learning to Determine the Information Value of a BMI Screening Program",
        "paper_author": "Zare S.",
        "publication": "American Journal of Preventive Medicine",
        "citied_by": "15",
        "cover_date": "2021-03-01",
        "Abstract": "Introduction: Childhood obesity continues to be a significant public health issue in the U.S. and is associated with short- and long-term adverse health outcomes. A number of states have implemented school-based BMI screening programs. However, these programs have been criticized for not being effective in improving students’ BMI or reducing childhood obesity. One potential benefit, however, of screening programs is the identification of younger children at risk of obesity as they age. Methods: This study used a unique panel data set from the BMI screening program for public school children in the state of Arkansas collected from 2003 to 2004 through the 2018–2019 academic years and analyzed in 2020. Machine learning algorithms were applied to understand the informational value of BMI screening. Specifically, this study evaluated the importance of BMI information during kindergarten to the accurate prediction of childhood obesity by the 4th grade. Results: Kindergarten BMI z-score is the most important predictor of obesity by the 4th grade and is much more important to prediction than sociodemographic and socioeconomic variables that would otherwise be available to policymakers in the absence of the screening program. Including the kindergarten BMI z-score of students in the model meaningfully increases the accuracy of the prediction. Conclusions: Data from the Arkansas BMI screening program greatly improve the ability to identify children at greatest risk of future obesity to the extent that better prediction can be translated into more effective policy and better health outcomes. This is a heretofore unexamined benefit of school-based BMI screening.",
        "DOI": "10.1016/j.amepre.2020.10.016",
        "affiliation_name": "UCR School of Medicine",
        "affiliation_city": "Riverside",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Hybrid deep reinforcement learning based eco-driving for low-level connected and automated vehicles along signalized corridors",
        "paper_author": "Guo Q.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "112",
        "cover_date": "2021-03-01",
        "Abstract": "Eco-Driving has great potential in reducing the fuel consumption of road vehicles, especially under the connected and automated vehicles (CAVs) environment. Traditional model-based Eco-Driving methods usually require sophisticated models and cannot deal with complex driving scenarios. This paper proposes a hybrid reinforcement learning (RL) based Eco-Driving algorithm considering both the longitudinal acceleration/deceleration and the lateral lane-changing operations. A deep deterministic policy gradient (DDPG) algorithm is designed to learn the continuous longitudinal acceleration/deceleration to reduce the fuel consumption as well as to maintain acceptable travel time. Collecting the critic's value of each single lane from DDPG and integrating the information of adjacent lanes, a deep Q-learning algorithm is developed to make the discrete lane-changing decision. Together, a hybrid deep Q-learning and policy gradient (HDQPG) method is developed for vehicles driving along multi-lane urban signalized corridors. The method can enable the controlled vehicle to learn well-established longitudinal fuel-saving strategies, and to perform appropriate lane-changing operations at proper times to avoid congested lanes. Numerical experiments show that HDQPG can reduce fuel consumption by up to 46% with marginal or no increase of travel times.",
        "DOI": "10.1016/j.trc.2021.102980",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Asynchrony Between Individual and Government Actions Accounts for Disproportionate Impact of COVID-19 on Vulnerable Communities",
        "paper_author": "Abdalla M.",
        "publication": "American Journal of Preventive Medicine",
        "citied_by": "8",
        "cover_date": "2021-03-01",
        "Abstract": "Introduction: Previously estimated effects of social distancing do not account for changes in individual behavior before the implementation of stay-at-home policies or model this behavior in relation to the burden of disease. This study aims to assess the asynchrony between individual behavior and government stay-at-home orders, quantify the true impact of social distancing using mobility data, and explore the sociodemographic variables linked to variation in social distancing practices. Methods: This study was a retrospective investigation that leveraged mobility data to quantify the time to behavioral change in relation to the initial presence of COVID-19 and the implementation of government stay-at-home orders. The impact of social distancing that accounts for both individual behavior and testing data was calculated using generalized mixed models. The role of sociodemographics in accounting for variation in social distancing behavior was modeled using a 10-fold cross-validated elastic net (linear machine learning model). Analysis was conducted in April‒July 2020. Results: Across all the 1,124 counties included in this analysis, individuals began to socially distance at a median of 5 days (IQR=3−8) after 10 cumulative cases of COVID-19 were confirmed in their state, with state governments taking a median of 15 days (IQR=12−19) to enact stay-at-home orders. Overall, people began social distancing at a median of 12 days (IQR=8−17) before their state enacted stay-at-home orders. Of the 16 studies included in the review, 13 exclusively used government dates as a proxy for social distancing behavior, and none accounted for both testing and mobility. Using government stay-at-home dates as a proxy for social distancing (10.2% decrease in the number of daily cases) accounted for only 55% of the true impact of the intervention when compared with estimates using mobility (18.6% reduction). Using 10-fold cross-validation, 23 of 43 sociodemographic variables were significantly and independently predictive of variation in individual social distancing, with delays corresponding to an increase in a county's proportion of people without a high school diploma and proportion of racial and ethnic minorities. Conclusions: This retrospective analysis of mobility patterns found that social distancing behavior occurred well before the onset of government stay-at-home dates. This asynchrony leads to the underestimation of the impact of social distancing. Sociodemographic characteristics associated with delays in social distancing can help explain the disproportionate case burden and mortality among vulnerable communities.",
        "DOI": "10.1016/j.amepre.2020.10.012",
        "affiliation_name": "Boston Children's Hospital",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The Future of Sensitivity Analysis: An essential discipline for systems modeling and policy support",
        "paper_author": "Razavi S.",
        "publication": "Environmental Modelling and Software",
        "citied_by": "352",
        "cover_date": "2021-03-01",
        "Abstract": "Sensitivity analysis (SA) is en route to becoming an integral part of mathematical modeling. The tremendous potential benefits of SA are, however, yet to be fully realized, both for advancing mechanistic and data-driven modeling of human and natural systems, and in support of decision making. In this perspective paper, a multidisciplinary group of researchers and practitioners revisit the current status of SA, and outline research challenges in regard to both theoretical frameworks and their applications to solve real-world problems. Six areas are discussed that warrant further attention, including (1) structuring and standardizing SA as a discipline, (2) realizing the untapped potential of SA for systems modeling, (3) addressing the computational burden of SA, (4) progressing SA in the context of machine learning, (5) clarifying the relationship and role of SA to uncertainty quantification, and (6) evolving the use of SA in support of decision making. An outlook for the future of SA is provided that underlines how SA must underpin a wide variety of activities to better serve science and society.",
        "DOI": "10.1016/j.envsoft.2020.104954",
        "affiliation_name": "College of Science",
        "affiliation_city": "Tucson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Why hate carbon taxes? Machine learning evidence on the roles of personal responsibility, trust, revenue recycling, and other factors across 23 European countries",
        "paper_author": "Levi S.",
        "publication": "Energy Research and Social Science",
        "citied_by": "85",
        "cover_date": "2021-03-01",
        "Abstract": "Carbon taxes are considered a key instrument for achieving deep decarbonization but are often unpopular among voters. While existing studies indicate that public opposition to carbon taxes is influenced by climate change belief and by political trust, less is known about the relevance of other factors. Moreover, it remains unclear why people oppose carbon taxes more fiercely than other climate policies. To enhance understanding of carbon tax opposition, I synthesize and categorize 28 conditions that potentially provoke public opposition to carbon taxes, assess their independent importance for predicting carbon tax opposition, and review the specific form in which they predict carbon tax opposition. This analysis draws on data from approximately 44,400 individuals from 23 European countries. It uses a random forest model, a machine learning method, to estimate independent prediction effects. The results identify the feeling of personal responsibility for trying to reduce climate change as the most important condition for predicting opposition to carbon taxes and for predicting attitudes on other climate policies. Political trust, in contrast, strongly predicts carbon tax opposition but not attitudes on other climate policies, suggesting that low political trust could explain the peculiar public aversion against carbon taxes. Recycling revenues from existing carbon prices back to households, often considered crucial for securing public support, is only associated with minor increases in the acceptance of higher carbon taxes. Finally, the results reveal that age, market liberal values, and good governance are related to carbon tax opposition in a non-monotonous pattern.",
        "DOI": "10.1016/j.erss.2020.101883",
        "affiliation_name": "Hertie School",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Machine learning techniques in nested stochastic simulations for life insurance",
        "paper_author": "Castellani G.",
        "publication": "Applied Stochastic Models in Business and Industry",
        "citied_by": "6",
        "cover_date": "2021-03-01",
        "Abstract": "The insurance regulatory regime introduced in the European Union by the “Solvency II” Directive 2009/138, that has become applicable on 1 January 2016, is aimed to safeguard policyholders and beneficiaries by requiring insurance undertakings to hold own funds able to cover losses, in excess to the expected ones, at the 99.5% confidence level, over a 1-year period. In order to assess risks and evaluate the regulatory Solvency Capital Requirement, undertakings should compute the probability distribution of the Net Asset Value over a 1-year period, with a financially inspired market consistent approach. In life insurance, given the peculiarities of the contracts, the valuation of the Net Asset Value distribution requires a nested Monte Carlo simulation, which is extremely time-consuming. Machine learning techniques are considered a promising candidate to reduce the computational burden of nested simulations. This work investigates the potential of well-established methods, such as deep learning networks and support vector regressors, when applied to the valuation of the Solvency Capital Requirement of participating life insurance policies, by empirically assessing their effectiveness and by comparing their efficiency and accuracy, also w.r.t. the “traditional” least squares Monte Carlo technique. The work aims also to contribute to the global process of renewal of the European insurance industry, where Solvency II has made the board of directors fully responsible of the choice of evaluation techniques and algorithmic processes, under the periodic monitoring of national supervisory authorities.",
        "DOI": "10.1002/asmb.2607",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Decoding pedestrian and automated vehicle interactions using immersive virtual reality and interpretable deep learning",
        "paper_author": "Kalatian A.",
        "publication": "Transportation Research Part C: Emerging Technologies",
        "citied_by": "33",
        "cover_date": "2021-03-01",
        "Abstract": "To ensure pedestrian-friendly streets in the era of automated vehicles, reassessment of current policies, practices, design, rules and regulations of urban areas is of importance. This study investigates pedestrian crossing behaviour which, as an important element of urban dynamics, is expected to be affected by the presence of automated vehicles. For this purpose, an interpretable machine learning framework is proposed to explore factors affecting pedestrians’ wait time before crossing mid-block crosswalks in the presence of automated vehicles. To collect rich behavioural data, we developed a dynamic and immersive virtual reality experiment, with 180 participants from a heterogeneous population in 4 different locations in the Greater Toronto Area (GTA). Pedestrian wait time behaviour is then analysed using a data-driven Cox Proportional Hazards (CPH) model, in which the linear combination of the covariates is replaced by a flexible non-linear deep neural network. The proposed model achieved a 5% improvement in goodness of fit, but more importantly, enabled us to incorporate a richer set of covariates. A game theoretic based interpretability method is used to understand the contribution of different covariates to the time pedestrians wait before crossing. Results show that the presence of automated vehicles on roads, wider lane widths, high density on roads, limited sight distance, and lack of walking habits are the main contributing factors to longer wait times. Our study suggested that, to move towards pedestrian-friendly urban areas, educational programs for children, enhanced safety measures for seniors, promotion of active modes of transportation, and revised traffic rules and regulations should be considered.",
        "DOI": "10.1016/j.trc.2020.102962",
        "affiliation_name": "Toronto Metropolitan University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A protein folding robot driven by a self-taught agent",
        "paper_author": "Chang O.",
        "publication": "BioSystems",
        "citied_by": "7",
        "cover_date": "2021-03-01",
        "Abstract": "This paper presents a computer simulation of a virtual robot that behaves as a peptide chain of the Hemagglutinin-Esterase protein (HEs) from human coronavirus. The robot can learn efficient protein folding policies by itself and then use them to solve HEs folding episodes. The proposed robotic unfolded structure inhabits a dynamic environment and is driven by a self-taught neural agent. The neural agent can read sensors and control the angles and interactions between individual amino acids. During the training phase, the agent uses reinforcement learning to explore new folding forms that conduce toward more significant rewards. The memory of the agent is implemented with neural networks. These neural networks are noise-balanced trained to satisfy the look for future conditions required by the Bellman equation. In the operating phase, the components merge into a wise up protein folding robot with look-ahead capacities, which consistently solves a section of the HEs protein.",
        "DOI": "10.1016/j.biosystems.2020.104315",
        "affiliation_name": "Yachay University for Experimental Technology and Research (Yachay Tech)",
        "affiliation_city": "Quito",
        "affiliation_country": "Ecuador"
    },
    {
        "paper_title": "Hybrid ensemble intelligent model based on wavelet transform, swarm intelligence and artificial neural network for electricity demand forecasting",
        "paper_author": "Ofori-Ntow Jnr E.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "80",
        "cover_date": "2021-03-01",
        "Abstract": "Availability of electrical energy affects many facets of an entire economy of a country. This has made short-term electrical load forecasting an important area in recent years for policy makers and academic researchers. However, it has been found that the actual load series exhibit some complex behaviours which are often characterised by nonlinearity, nonstationarity, and temporal variations. In this study, a three-level hybrid ensemble short-term load forecasting method consisting of Discrete Wavelet Transform (DWT), Particle Swarm Optimization (PSO), and Radial Basis Function Neural Network (RBFNN) is proposed. The DWT is applied to decompose the data to get a well-behaved requisite series for forecasting since the data becomes stable before using PSO. PSO is used to obtain the required optimal adjustable parameters of the RBFNN for the forecasting. The proposed hybrid ensemble method (DWT-PSO-RBFNN) was evaluated using Ghana Grid Company daily average demand data from 1 st December 2018 to 30th November 2019. The DWT-PSO-RBFNN approach was compared with three other DWT coupling methods namely RBFNN, Backpropagation Neural Network (BPNN), and Self Adaptive Differential Evolution – Extreme Learning Machine (SaDE-ELM). The statistical analysis revealed that the proposed method performed better based on MAPE, MAD, and RMSE emphasizing its great potential.",
        "DOI": "10.1016/j.scs.2020.102679",
        "affiliation_name": "University of Mines and Technology",
        "affiliation_city": "Tarkwa",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Safe cities in the new urban world: A comparative cluster dynamics analysis through machine learning",
        "paper_author": "Kourtit K.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "19",
        "cover_date": "2021-03-01",
        "Abstract": "Cities in the ‘New Urban World’ display an enormous diversity in appearance, growth and performance. The awareness is growing that the urban development potential (‘magnetism’) of cities is closely related to safety and security conditions in these cities. This paper develops a new analytical framework based on a wealth of empirical data on both safety/security and socio-economic magnetism achievements of many world cities, by combining two comprehensive relevant global urban data bases. The aim of the study is to offer a comparative analysis of the combined safety/security data and socio-economic performance data of 30 global cities, through the use of an advanced sequential cluster dynamics analysis that is (partly) inspired by a novel machine learning approach (using Python software). In this way, cities can be categorized according to their quantitative characteristic features represented by the relevant clusters. It appears that city safety/security features are an important predictor of the variability in overall urban performance regarding magnetism. This study allows also for drawing relevant policy lessons.",
        "DOI": "10.1016/j.scs.2020.102665",
        "affiliation_name": "Mohammed VI Polytechnic University",
        "affiliation_city": "Ben Guerir",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "The distribution of greenspace quantity and quality and their association with neighbourhood socioeconomic conditions in Guangzhou, China: A new approach using deep learning method and street view images",
        "paper_author": "Wang R.",
        "publication": "Sustainable Cities and Society",
        "citied_by": "74",
        "cover_date": "2021-03-01",
        "Abstract": "Awareness is mounting that urban greenspace is beneficial for residents’ health. While a plethora of studies have focused on greenspace quantity, scant attention has been paid to greenspace quality. Existing methods for assessing greenspace quality is either highly labor-intensive and/or prohibitively time-consuming. This study develops a new machine learning method to assess greenspace quality based on street view images collected from Guangzhou, China. It also examines whether greenspace exposure disparities are linked to the neighbourhood socioeconomic status (SES). The validation process indicated that our scoring system achieved high accuracy for predicting street view-based greenspace quality outside the training data. Results also show that there were marked differences in spatial distribution between aggregated NDVI (Normalized Difference Vegetation Index), street view greenness quantity and quality. Regression models show that neighbourhood SES is not associated with NDVI. Although neighbourhood SES is associated with both street view greenness quantity and quality index value, street view greenness quality is more sensitive to the change of neighbourhood SES. Our work suggests that policymakers and planners are advised to pay more attention to greenspace quality and greenspace exposure disparities in urban area.",
        "DOI": "10.1016/j.scs.2020.102664",
        "affiliation_name": "Temple University",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Applications of reinforcement learning in energy systems",
        "paper_author": "Perera A.T.D.",
        "publication": "Renewable and Sustainable Energy Reviews",
        "citied_by": "245",
        "cover_date": "2021-03-01",
        "Abstract": "Energy systems undergo major transitions to facilitate the large-scale penetration of renewable energy technologies and improve efficiencies, leading to the integration of many sectors into the energy system domain. As the complexities in this domain increase, it becomes challenging to control energy flows using existing techniques based on physical models. Moreover, although data-driven models, such as reinforcement learning (RL), have gained considerable attention in many fields, a direct shift into RL is not feasible in the energy domain irrespective of the ongoing complexities. To this end, a top-down approach is used to understand this behavior by reviewing the current state of the art. We classified RL papers in the literature into seven categories based on their area of application. Subsequently, publications under each category were further examined relative to problem diversity, RL technique employed, performance improvement (compared with other white and gray box models), verification, and reproducibility; many of the articles reported a 10–20% performance improvement with the use of RL. In most studies, however, deep learning techniques and state-of-the-art actor-critic methods (e.g., twin delayed deep deterministic policy gradient and soft actor-critic) were not applied. This has remarkably hindered performance improvements and problems related to complex energy flows have not been considered. Approximately half of the publications reported the use of Q-learning. Furthermore, despite the availability of historical data in the energy system domain, batch RL algorithms have not been exploited. Emerging multi-agent RL applications may be considered as a positive development that can enable the management of complex interactions among multiple parties. Most studies lack proper benchmarking compared to model-based approaches or gray-box models, and a majority cover energy dispatch problems and building energy management. Although RL can adequately solve problems that are considerably integrated in several sectors, only a limited number of publications have discussed its broad application. The present study clearly demonstrates that even without the full utilization of RL capacity, this technique has a considerable potential in resolving the continuously increasing complexity within the energy system domain.",
        "DOI": "10.1016/j.rser.2020.110618",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Data-Driven Predictive Modeling of Highway Construction Cost Items",
        "paper_author": "Mahdavian A.",
        "publication": "Journal of Construction Engineering and Management",
        "citied_by": "20",
        "cover_date": "2021-03-01",
        "Abstract": "The highway network is an economically necessary form of transportation that has a significant impact on the quality of the life of the citizens who use it. Cost overruns in highway projects have been a universal occurrence that jeopardize the development, maintenance, and expansion of this vital infrastructure. Incorrect cost estimations can drive decision makers to pass ineffective policies that have played a large role in the cost overruns of transportation construction projects. The existing prediction models in the literature are limited in one or multiple areas of modeling approach, inputs, and model development robustness. In this research, a model was developed to accurately predict the total construction cost of highway projects by utilizing machine learning algorithms. This study developed a modeling pipeline to automate much of the cost forecasting process, reducing the amount of manual work and dependence on skilled data scientists. This study used the Florida Department of Transportation's (FDOT's) critical highway construction cost items between 2001 and 2017 to test the model. The highways of Florida were selected for testing due to the states' population growth, high immigrant population, logistics, and hurricane frequency. This study used a pool of five categories of independent variables (69 variables total), including the construction market, energy market, socioeconomics, US economy, and temporal variables, which were compiled from relevant sources and existing literature. The results revealed that our linear model exhibits superiority in generalization and prediction of cost items over nonlinear models and is capable of accurately forecasting highway construction costs. Our suggested approach in this study also provides more accurate forecasts for the detailed cost estimation by considering the monthly historical information for the average 92.6% of the six highway construction types mentioned with a 92.51% prediction accuracy. By employing our developed model, local governments, network operators, contractors, and logistics sectors would be capable of a more exact prediction of highway construction costs.",
        "DOI": "10.1061/(ASCE)CO.1943-7862.0001991",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Use of machine-learning and receptor models for prediction and source apportionment of heavy metals in coastal reclaimed soils",
        "paper_author": "Zhang H.",
        "publication": "Ecological Indicators",
        "citied_by": "66",
        "cover_date": "2021-03-01",
        "Abstract": "Quantitative estimations of sources and spatial distribution of soil heavy metals (HMs) is essential for strategizing policies for soil protection and remediation. As a special soil ecosystem, the intensified human activities on coastal reclaimed lands generally causes soil contamination with HMs. This study aimed to apportion sources of HMs and predict their spatial distributions on coastal reclaimed lands. A total of 241 surface (0–20 cm) soil and sediment samples were collected from a reclamation zone following intensive agricultural use of eastern China. The concentrations of soil and sediment As, Cr, Cu, Ni, Pb, Zn, Cd, and Hg were measured along with organic carbon, nitrogen, phosphorus, pH, Cl, clay, silt, sand, CaO, Fe2O3, Al2O3, and SiO2. The potential sources of HMs were identified and apportioned using random forest (RF) and positive matrix factorization (PMF) models. According to the models, natural and a portion of anthropogenic sources, agricultural activities, and human emission from solar power generation and vehicle exhaust contributed 42.9%, 28.9%, and 28.2% of the total HMs, respectively. Separately, 65.0% of As, 36.6% of Cr, 49.1% of Cu, 46.4% of Ni, 39.5% of Pb, and 44.0% of Zn were originated from natural and some anthropogenic sources. Agricultural activities contributed 54.9% of Cd and 46.4% of Hg to the reclaimed soils. Emissions from solar power generation and vehicle exhaust had significant influences on Cr and Pb, with contributions of 39.0% and 28.0%, respectively. Furthermore, the RF model yielded satisfying results in predicting HM distributions based on the measurement of soil variables. When only considering independent variables, the RF model revealed slightly lower but still satisfactory abilities in HMs prediction. In reclaimed soils, the temporal increase and close relationship between soil Cd and phosphorus signified the potential threats of Cd contamination in coastal reclaimed soils. Therefore, the applications of Cd-rich phosphoric fertilizers should be considered with high concern.",
        "DOI": "10.1016/j.ecolind.2020.107233",
        "affiliation_name": "Ministry of Natural Resources of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Data-Driven Approaches to Targeting Promotion E-mails: The Case of Delayed Incentives",
        "paper_author": "Kadiyala B.",
        "publication": "Production and Operations Management",
        "citied_by": "6",
        "cover_date": "2021-03-01",
        "Abstract": "This paper empirically investigates using the e-mail channel to target customers with a delayed incentive promotion—specifically, gift card promotion—and derives data-driven e-mail targeting policies. Gift card promotions are popular across retailers because they incentivize customers to spend more than a fixed expenditure level on regularly priced products by rewarding customers with a gift card to be redeemed against a future purchase. The e-mail channel provides retailers with new sources of customer-level data, which enables better prediction of customers' responsiveness to e-mails (e.g., clicking) and the sales promotion that comes with it (e.g., participation in the promotion). We formulate the retailer's promotion e-mail targeting problem by maximizing two objectives—the promotion's profitability (i.e., profit-based targeting) and e-mail click-through rate (i.e., CTR-based targeting). We also take into account the retailer's promotion budget and exclusivity concerns in targeting e-mails. We use a comprehensive dataset from a Fortune 500 luxury fashion retailer's online channel and utilize both parametric and non-parametric methods to predict customers' response to promotion e-mails. Our data-driven targeting policies improve the promotion's profitability by 5.57% and e-mail CTR by 472.57%, on average, compared to our partner retailer's current e-mail policy. We also find that the CTR-based targeting policy lowers the promotion profitability by, on average, 9.09% compared to the profit-based one. However, the CTR-based policy recuperates the short-term losses in the long-term and increases the long-term profitability by 3.94%, on average, compared to the profit-based targeting policy.",
        "DOI": "10.1111/poms.13316",
        "affiliation_name": "David Eccles School of Business",
        "affiliation_city": "Salt Lake City",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Oncology services efficiency in the age of pandemic: A jackknife and bootstrap sensitivity analysis for robustness check of DEA scores",
        "paper_author": "Cinaroglu S.",
        "publication": "Journal of Cancer Policy",
        "citied_by": "7",
        "cover_date": "2021-03-01",
        "Abstract": "Background: Developing countries face great challenges in health care because of changing disease dynamics and the increasing burden of chronic diseases such as cancers. Thus, effective operational design of health services is critical to better manage scarce health care resources. This study aimed to examine the spatial distribution of the efficiency of Turkey's oncology services. Methods: Data was collected from the 2017 Public Hospitals Statistical Yearbook, and a total of 55 provinces with advanced centers for cancer were analyzed. This study applied Charnes, Cooper, and Rhodes's input-oriented data envelopment analysis (DEA) and performed jackknifing for robustness check of DEA scores. Results: The iteration procedure generated four models. The final model included 38 decision-making units (DMUs), and 50 % of provinces were found to have efficient oncology services. The final model's average conventional efficiency score was 0.79. Next, bootstrapped DEA procedure was incorporated into the final model to gather bias-corrected efficiency scores. After applying the bootstrapping approach, efficiency scores are significantly improved and the difference between conventional and bias-corrected efficiency scores are statistically significant (U = 475; p < 0.05). Conclusions: Geographic planning of cancer care services is a relevant principle in health operations design that requires specific health service configurations for preparedness of health crisis such as pandemic. The results highlighted that health policymakers must be aware of regional imbalances and eliminate them to provide advanced oncology care services for population groups in poor areas of the country. Policy summary: Health policy makers should prioritize a balanced geographical distribution of professional oncology services to provide vulnerable groups better access to critical care.",
        "DOI": "10.1016/j.jcpo.2020.100262",
        "affiliation_name": "Hacettepe Üniversitesi",
        "affiliation_city": "Ankara",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Using causal machine learning for predicting the risk of flight delays in air transportation",
        "paper_author": "Truong D.",
        "publication": "Journal of Air Transport Management",
        "citied_by": "42",
        "cover_date": "2021-03-01",
        "Abstract": "Delays in air transportation are a major concern that has negative impacts on the airline industry and the economy. Given the complexity of the National Air Space system, predicting the risk of flight delays and identifying significant predictors is vital to risk mitigation. The purpose of this paper is to perform data mining using causal machine learning algorithms in the USELEI process (Understanding, Sampling, Exploring, Learning, Evaluating, and Inferring) to predict the probability of flight delays in air transportation using data collected from different sources. The findings indicated significant effects of predictors, including reported arrivals and departures, arrival and departure demands, capacity, efficiency, and traffic volume at the origin and destination airports on the risk of flight delays. More importantly, causal interrelationships among variables in a fully structural network are presented to how these predictors interact with one another and how these interactions lead to delay incidents. Finally, sensitivity analysis and causal inference can be performed to evaluate various what-if scenarios and form effective strategies to mitigate the risk of delays.",
        "DOI": "10.1016/j.jairtraman.2020.101993",
        "affiliation_name": "Embry-Riddle Aeronautical University",
        "affiliation_city": "Daytona Beach",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A machine learning approach to segmentation of tourists based on perceived destination sustainability and trustworthiness",
        "paper_author": "Penagos-Londoño G.I.",
        "publication": "Journal of Destination Marketing and Management",
        "citied_by": "33",
        "cover_date": "2021-03-01",
        "Abstract": "Segmentation studies are crucial for planning sustainability strategies, and tourists' perceptions of destinations offer important segmentation criteria. The aim of this study is to understand and describe the tourist segments with similar levels of perceived destination sustainability and trustworthiness. Perceived sustainability and perceived trustworthiness are based on tourists’ perceptions of the impacts of tourism development and policies of destinations and are measured as multidimensional constructs. Based on a sample of 438 tourists from Chile and Ecuador aged over 17 years, a metaheuristic (genetic algorithm) is employed to select the most useful variables for segmentation using a machine learning process. The results reveal three tourist segments: Extremely optimistic (Segment 3), Optimistic (Segment 2) and Moderately optimistic (Segment 1). These segments differ considerably in terms of the impacts of the dimensions of destination sustainability (environmental, sociocultural, and economic) and trustworthiness (ability, benevolence, and integrity). However, they do not differ in terms of most sociodemographic characteristics. As segmentation criteria, perceived sustainability and trustworthiness can help when analyzing the effectiveness of sustainability strategies and actions by the public and private institutions at tourist destinations.",
        "DOI": "10.1016/j.jdmm.2020.100532",
        "affiliation_name": "Pontificia Universidad Javeriana",
        "affiliation_city": "Bogota",
        "affiliation_country": "Colombia"
    },
    {
        "paper_title": "Cloud Resource Scheduling with Deep Reinforcement Learning and Imitation Learning",
        "paper_author": "Guo W.",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "83",
        "cover_date": "2021-03-01",
        "Abstract": "The cloud resource management belongs to the category of combinatorial optimization problems, most of which have been proven to be NP-hard. In recent years, reinforcement learning (RL), as a special paradigm of machine learning, has been used to tackle these NP-hard problems. In this article, we present a deep RL-based solution, called DeepRM_Plus, to efficiently solve different cloud resource management problems. We use a convolutional neural network to capture the resource management model and utilize imitation learning in the reinforcement process to reduce the training time of the optimal policy. Compared with the state-of-the-art algorithm DeepRM, DeepRM_Plus is 37.5% faster in terms of the convergence rate. Moreover, DeepRM_Plus reduces the average weighted turnaround time and the average cycling time by 51.85% and 11.51%, respectively.",
        "DOI": "10.1109/JIOT.2020.3025015",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting carbonaceous aerosols and identifying their source contribution with advanced approaches",
        "paper_author": "Zhu J.J.",
        "publication": "Chemosphere",
        "citied_by": "13",
        "cover_date": "2021-03-01",
        "Abstract": "Organic carbon (OC) and elemental carbon (EC) play important roles in various atmospheric processes and health effects. Predicting carbonaceous aerosols and identifying source contributions are important steps for further epidemiological study and formulating effective emission control policies. However, we are not aware of any study that examined predictions of OC and EC, and this work is also the first study that attempted to use machine learning and hyperparameter optimization method to predict concentrations of specific aerosol contaminants. This paper describes an investigation of the characteristics and sources of OC and EC in fine particulate matter (PM2.5) from 2005 to 2010 in the City of Taipei. Respective hourly average concentrations of OC and EC were 5.2 μg/m3 and 1.6 μg/m3. We observed obvious seasonal variation in OC but not in EC. Hourly and daily OC and EC concentrations were predicted using generalized additive model and grey wolf optimized multilayer perceptron model, which could explain up to about 80% of the total variation. Subsequent clustering suggests that traffic emission was the major contribution to OC, accounting for about 80% in the spring, 65% in the summer, and 90% in the fall and winter. In the Taipei area, local emissions were the dominant sources of OC and EC in all seasons, and long-range transport had a significant contribution to OC and in PM2.5 in spring.",
        "DOI": "10.1016/j.chemosphere.2020.128966",
        "affiliation_name": "Armour College of Engineering",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Distributed computing for region-wide line source dispersion modeling",
        "paper_author": "Kim D.",
        "publication": "Computer-Aided Civil and Infrastructure Engineering",
        "citied_by": "4",
        "cover_date": "2021-03-01",
        "Abstract": "This work introduces a parallelly distributed computing technique to quantify the traffic-related pollutant concentrations at regional scales. The U.S. Environmental Protection Agency (EPA)-recommended dispersion model AERMOD involves complex model setup that requires extensive data inputs with strict formatting rules. These strict requirements increase the likelihood of human errors, especially in larger-scale high-resolution dispersion modeling. The paper presents a streamlined framework that integrates the processes of data preparation, link and receptor configuration, and mobile source emissions modeling. The emissions model is then connected with dispersion model through a parallel computing system. Such linkages allow high-resolution traffic-related air quality impacts to be estimated at the regional scales with high computational efficiency. The tool can be used by a broad audience, including any stakeholders interested in mobile source emissions modeling, and near-road pollutant concentration modeling under the National Environmental Policy Act, and Clean Air Act transportation and air quality conformity analysis.",
        "DOI": "10.1111/mice.12639",
        "affiliation_name": "University of New Mexico School of Engineering",
        "affiliation_city": "Albuquerque",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Optimizing clinical research procedures in public health emergencies",
        "paper_author": "Madariaga A.",
        "publication": "Medicinal Research Reviews",
        "citied_by": "7",
        "cover_date": "2021-03-01",
        "Abstract": "Public Health Emergencies of International Concern, such as the coronavirus disease 2019 pandemic, have a devastating impact on an individual and societal level, and there is an urgent need to learn, understand and bridge the therapeutic gap at a time of extreme stress on the patient, health care systems and staff. Well-designed, controlled clinical trials play a crucial role in the discovery of novel diagnostic and management strategies; however, these catastrophic circumstances pose unique challenges in initiating research studies at institutional, national, and international levels, highlighting the importance of a coordinated, collaborative approach. This review discusses key elements necessary to consider for developing clinical trials within a Public Health Emergency setting.",
        "DOI": "10.1002/med.21749",
        "affiliation_name": "University of Toronto",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine learning and national health data to improve evidence: Finding segmentation in individuals without private insurance",
        "paper_author": "dos Santos J.R.R.",
        "publication": "Health Policy and Technology",
        "citied_by": "4",
        "cover_date": "2021-03-01",
        "Abstract": "Objective: Individuals without private health insurance have less access to healthcare, therefore are more prone to experience poor health when compared to those who have. Segmentation is an approach to find homogenous groups of people with the purpose of tailoring services and products. In public policy, segmentation might be used to identify characteristics and needs of specific groups and deliver targeted programs and spare costs. We aim to identify and describe segments within the uninsured population to aid targeted policy actions and improve health. Methods: We used secondary data collected from a representative, nationwide health survey (n=18,204). For the purpose of our analysis, we included data from individuals who answered “no” to the question: “Do you have private health insurance?” (n=12,134). Variables pertaining information on socio-demographic, health status, access and care were used. A multiple correspondence analysis was performed to find principal components followed by a hierarchical cluster. Results: We found three clusters. The first (54.12% of our sample) composed by a group of young, middle aged and professionally active individuals without health problems. The second (36.70%), a cluster of aging individuals composed especially by elderly women, either retired or fulfilling domestic tasks, with a long-term health problem. The last (9.17%) composed by elder people, with long-term health problem and scoring low in mental health related questions. Conclusion: Our study found three clusters (profiles of individuals) among the uninsured. Ultimately, our findings aim to support policy makers to deliver customized actions to improve health and provide cost-effective policies.",
        "DOI": "10.1016/j.hlpt.2020.11.002",
        "affiliation_name": "Escola Nacional de Saúde Pública, Universidade Nova de Lisboa",
        "affiliation_city": "Lisbon",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Dynamic measurement of news-driven information friction in China's carbon market: Theory and evidence",
        "paper_author": "Zhang H.G.",
        "publication": "Energy Economics",
        "citied_by": "8",
        "cover_date": "2021-03-01",
        "Abstract": "This paper dynamically measures news-driven information friction in China's carbon market theoretically and empirically. The biggest difference between this paper and the existing literature is that this paper does not assume that the information shock is a white noise process but that the information shock comes from the news. This study does not use fiscal expenditure budget data and fiscal expenditure final data to estimate information friction but rather extends the standard Fève and Pietrunti (2016) theoretical framework to identify effective information and noise signals from market policy news by machine learning. A latent Dirichlet allocation model is employed to estimate the variance of effective information. China's carbon policy uncertainty as indicated by Chinese-language newspapers is used to estimate the variance of the noise signal. Therefore, we can calculate time-varying high-frequency information friction. The results of this study show that enterprises with different attributes in the same industry face different information friction. In China, state-owned industrial enterprises have the lowest levels of information friction. Joint-stock industrial enterprises have the highest levels of information friction. The higher the degree of policy information friction, the weaker the impact of effective information shocks and the greater the reduction in policy effects. These results have policy implications – the government should pay attention to enterprise attributes to reduce policy uncertainty and the degree of policy information friction, thereby enhancing the effectiveness of policy regulation.",
        "DOI": "10.1016/j.eneco.2020.104994",
        "affiliation_name": "Weifang University of Science and Technology",
        "affiliation_city": "Shouguang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Generating knowledge graphs by employing Natural Language Processing and Machine Learning techniques within the scholarly domain",
        "paper_author": "Dessì D.",
        "publication": "Future Generation Computer Systems",
        "citied_by": "67",
        "cover_date": "2021-03-01",
        "Abstract": "The continuous growth of scientific literature brings innovations and, at the same time, raises new challenges. One of them is related to the fact that its analysis has become difficult due to the high volume of published papers for which manual effort for annotations and management is required. Novel technological infrastructures are needed to help researchers, research policy makers, and companies to time-efficiently browse, analyse, and forecast scientific research. Knowledge graphs i.e., large networks of entities and relationships, have proved to be effective solution in this space. Scientific knowledge graphs focus on the scholarly domain and typically contain metadata describing research publications such as authors, venues, organizations, research topics, and citations. However, the current generation of knowledge graphs lacks of an explicit representation of the knowledge presented in the research papers. As such, in this paper, we present a new architecture that takes advantage of Natural Language Processing and Machine Learning methods for extracting entities and relationships from research publications and integrates them in a large-scale knowledge graph. Within this research work, we (i) tackle the challenge of knowledge extraction by employing several state-of-the-art Natural Language Processing and Text Mining tools, (ii) describe an approach for integrating entities and relationships generated by these tools, (iii) show the advantage of such an hybrid system over alternative approaches, and (vi) as a chosen use case, we generated a scientific knowledge graph including 109,105 triples, extracted from 26,827 abstracts of papers within the Semantic Web domain. As our approach is general and can be applied to any domain, we expect that it can facilitate the management, analysis, dissemination, and processing of scientific knowledge.",
        "DOI": "10.1016/j.future.2020.10.026",
        "affiliation_name": "FIZ Karlsruhe - Leibniz Institute for Information Infrastructure",
        "affiliation_city": "Eggenstein-Leopoldshafen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Susceptibility mapping of groundwater salinity using machine learning models",
        "paper_author": "Mosavi A.",
        "publication": "Environmental Science and Pollution Research",
        "citied_by": "65",
        "cover_date": "2021-03-01",
        "Abstract": "Increasing groundwater salinity has recently raised severe environmental and health concerns around the world. Advancement of the novel methods for spatial salinity modeling and prediction would be essential for effective management of the resources and planning mitigation policies. The current research presents the application of machine learning (ML) models in groundwater salinity mapping based on the dichotomous predictions. The groundwater salinity is predicted using the essential factors (i.e., identified by the simulated annealing feature selection methodology) through k-fold cross-validation methodology. Six ML models, namely, flexible discriminant analysis (FDA), mixture discriminant analysis (MAD), boosted regression tree (BRT), multivariate adaptive regression spline (MARS), random forest (RF), support vector machine (SVM), were employed to groundwater salinity mapping. The results of the modeling indicated that the SVM model had superior performance than other models. Variables of soil order, groundwater withdrawal, precipitation, land use, and elevation had the most contribute to groundwater salinity mapping. Results highlighted that the southern parts of the region and some parts in the north, northeast, and west have a high groundwater salinity, in which these areas are mostly matched with soil order of Entisols, bareland areas, and low elevations.",
        "DOI": "10.1007/s11356-020-11319-5",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Development of a prognostic model for mortality in COVID-19 infection using machine learning",
        "paper_author": "Booth A.L.",
        "publication": "Modern Pathology",
        "citied_by": "113",
        "cover_date": "2021-03-01",
        "Abstract": "Coronavirus disease 2019 (COVID-19) is a novel disease resulting from infection with severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2), which has quickly risen since the beginning of 2020 to become a global pandemic. As a result of the rapid growth of COVID-19, hospitals are tasked with managing an increasing volume of these cases with neither a known effective therapy, an existing vaccine, nor well-established guidelines for clinical management. The need for actionable knowledge amidst the COVID-19 pandemic is dire and yet, given the urgency of this illness and the speed with which the healthcare workforce must devise useful policies for its management, there is insufficient time to await the conclusions of detailed, controlled, prospective clinical research. Thus, we present a retrospective study evaluating laboratory data and mortality from patients with positive RT-PCR assay results for SARS-CoV-2. The objective of this study is to identify prognostic serum biomarkers in patients at greatest risk of mortality. To this end, we develop a machine learning model using five serum chemistry laboratory parameters (c-reactive protein, blood urea nitrogen, serum calcium, serum albumin, and lactic acid) from 398 patients (43 expired and 355 non-expired) for the prediction of death up to 48 h prior to patient expiration. The resulting support vector machine model achieved 91% sensitivity and 91% specificity (AUC 0.93) for predicting patient expiration status on held-out testing data. Finally, we examine the impact of each feature and feature combination in light of different model predictions, highlighting important patterns of laboratory values that impact outcomes in SARS-CoV-2 infection.",
        "DOI": "10.1038/s41379-020-00700-x",
        "affiliation_name": "The University of Texas Medical Branch at Galveston",
        "affiliation_city": "Galveston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "ArchNet: A data hiding design for distributed machine learning systems",
        "paper_author": "Chang K.",
        "publication": "Journal of Systems Architecture",
        "citied_by": "1",
        "cover_date": "2021-03-01",
        "Abstract": "Integrating idle embedded devices into cloud computing is a promising approach to support Distributed Machine Learning (DML). In this paper, we approach to address the data hiding problem in such DML systems. For the purpose of the data encryption in DML systems, we introduce the tripartite asymmetric encryption theorem to provide theoretical support. Based on the theorem, we design a general image encryption scheme (called ArchNet), which can encrypt original images via the encoder to resist against illegal users. ArchNet encrypts the dataset by a specific neural network, which is especially trained for encryption. The encrypted data can be easily recognized by deep learning model. However, the encrypted data cannot be recognized by human, which makes the illegal attacker difficult to steal the encrypted data. We use MNIST, Fashion-MNIST and Cifar-10 datasets to evaluate efficiency of our design. We deploy certain base models on the encrypted datasets and compare them with the RC4 algorithm and differential privacy policy. Our design can improve the accuracy on MNIST up to 97.26% compared with RC4. The accuracies on these three datasets encrypted by ArchNet are similar to the base model. ArchNet can be deployed on DML systems with embedded devices.",
        "DOI": "10.1016/j.sysarc.2020.101912",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Rejoinder to Discussions on “Approval policies for modifications to machine learning-based software as a medical device: A study of bio-creep”",
        "paper_author": "Feng J.",
        "publication": "Biometrics",
        "citied_by": "0",
        "cover_date": "2021-03-01",
        "Abstract": "We thank the discussants for sharing their unique perspectives on the problem of designing automatic algorithm change protocols (aACPs) for machine learning-based software as a medical device. Both Pennello et al. and Rose highlighted a number of challenges that arise in real-world settings, and we whole-heartedly agree that substantial extensions of our work are needed to understand if and how aACPs can be safely deployed in practice. Our work demonstrated that aACPs that appear to be harmless may allow for biocreep, even when the data distribution is assumed to be representative and stationary over time. While we investigated two solutions that protect against this specific issue, many more statistical and practical challenges remain and we look forward to future research on this topic.",
        "DOI": "10.1111/biom.13380",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Approval policies for modifications to machine learning-based software as a medical device: A study of bio-creep",
        "paper_author": "Feng J.",
        "publication": "Biometrics",
        "citied_by": "16",
        "cover_date": "2021-03-01",
        "Abstract": "Successful deployment of machine learning algorithms in healthcare requires careful assessments of their performance and safety. To date, the FDA approves locked algorithms prior to marketing and requires future updates to undergo separate premarket reviews. However, this negates a key feature of machine learning-the ability to learn from a growing dataset and improve over time. This paper frames the design of an approval policy, which we refer to as an automatic algorithmic change protocol (aACP), as an online hypothesis testing problem. As this process has obvious analogy with noninferiority testing of new drugs, we investigate how repeated testing and adoption of modifications might lead to gradual deterioration in prediction accuracy, also known as \"biocreep\" in the drug development literature. We consider simple policies that one might consider but do not necessarily offer any error-rate guarantees, as well as policies that do provide error-rate control. For the latter, we define two online error-rates appropriate for this context: bad approval count (BAC) and bad approval and benchmark ratios (BABR). We control these rates in the simple setting of a constant population and data source using policies aACP-BAC and aACP-BABR, which combine alpha-investing, group-sequential, and gate-keeping methods. In simulation studies, bio-creep regularly occurred when using policies with no error-rate guarantees, whereas aACP-BAC and aACP-BABR controlled the rate of bio-creep without substantially impacting our ability to approve beneficial modifications.",
        "DOI": "10.1111/biom.13379",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Discussion on “Approval policies for modifications to machine learning-based software as a medical device: A study of bio-creep” by Jean Feng, Scott Emerson, and Noah Simon",
        "paper_author": "Pennello G.",
        "publication": "Biometrics",
        "citied_by": "3",
        "cover_date": "2021-03-01",
        "Abstract": "NA",
        "DOI": "10.1111/biom.13381",
        "affiliation_name": "Food and Drug Administration, Center for Devices and Radiological Health",
        "affiliation_city": "Rockville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Discussion on “Approval policies for modifications to machine learning-based software as a medical device: A study of biocreep” by Jean Feng, Scott Emerson, and Noah Simon",
        "paper_author": "Rose S.",
        "publication": "Biometrics",
        "citied_by": "0",
        "cover_date": "2021-03-01",
        "Abstract": "NA",
        "DOI": "10.1111/biom.13378",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment",
        "paper_author": "Haendel M.A.",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "323",
        "cover_date": "2021-03-01",
        "Abstract": "Objective: Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers. Materials and Methods: The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics. Results: Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access. Conclusions: The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-Term impacts of COVID-19.",
        "DOI": "10.1093/jamia/ocaa196",
        "affiliation_name": "Department of Biomedical Engineering",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A benchmark of machine learning approaches for credit score prediction",
        "paper_author": "Moscato V.",
        "publication": "Expert Systems with Applications",
        "citied_by": "154",
        "cover_date": "2021-03-01",
        "Abstract": "Credit risk assessment plays a key role for correctly supporting financial institutes in defining their bank policies and commercial strategies. Over the last decade, the emerging of social lending platforms has disrupted traditional services for credit risk assessment. Through these platforms, lenders and borrowers can easily interact among them without any involvement of financial institutes. In particular, they support borrowers in the fundraising process, enabling the participation of any number and size of lenders. However, the lack of lenders’ experience and missing or uncertain information about borrower's credit history can increase risks in social lending platforms, requiring an accurate credit risk scoring. To overcome such issues, the credit risk assessment problem of financial operations is usually modeled as a binary problem on the basis of debt's repayment and proper machine learning techniques can be consequently exploited. In this paper, we propose a benchmarking study of some of the most used credit risk scoring models to predict if a loan will be repaid in a P2P platform. We deal with a class imbalance problem and leverage several classifiers among the most used in the literature, which are based on different sampling techniques. A real social lending platform (Lending Club) data-set, composed by 877,956 samples, has been used to perform the experimental analysis considering different evaluation metrics (i.e. AUC, Sensitivity, Specificity), also comparing the obtained outcomes with respect to the state-of-the-art approaches. Finally, the three best approaches have also been evaluated in terms of their explainability by means of different eXplainable Artificial Intelligence (XAI) tools.",
        "DOI": "10.1016/j.eswa.2020.113986",
        "affiliation_name": "Università degli Studi di Napoli Federico II",
        "affiliation_city": "Naples",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Supporting a data-driven approach to regulatory intelligence",
        "paper_author": "Robertson A.S.",
        "publication": "Nature Reviews Drug Discovery",
        "citied_by": "4",
        "cover_date": "2021-03-01",
        "Abstract": "Drug developers are increasingly applying data-driven analysis of the actions of regulatory agencies to gain insights into their expectations and applications of regulatory policy, but such strategies can be limited by the availability and quality of regulatory datasets. Here, we discuss how establishing a single, robust, accessible database of FDA regulatory actions could help address this limitation.",
        "DOI": "10.1038/d41573-020-00101-4",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Machine learning’s limitations in avoiding automation of bias",
        "paper_author": "Varona D.",
        "publication": "AI and Society",
        "citied_by": "11",
        "cover_date": "2021-03-01",
        "Abstract": "The use of predictive systems has become wider with the development of related computational methods, and the evolution of the sciences in which these methods are applied Solon and Selbst (Calif L REV 104: 671–732, 2016) and Pedreschi et al. (2007). The referred methods include machine learning techniques, face and/or voice recognition, temperature mapping, and other, within the artificial intelligence domain. These techniques are being applied to solve problems in socially and politically sensitive areas such as crime prevention and justice management, crowd management, and emotion analysis, just to mention a few. However, dissimilar predictions can be found nowadays as the result of the application of these methods resulting in misclassification, for example for the case of conviction risk assessment Office of Probation and Pretrial Services (2011) or decision-making process when designing public policies Lange (2015). The goal of this paper is to identify current gaps on fairness achievement within the context of predictive systems in artificial intelligence by analyzing available academic and scientific literature up to 2020. To achieve this goal, we have gathered available materials at the Web of Science and Scopus from last 5 years and analyzed the different proposed methods and their results in relation to the bias as an emergent issue in the Artificial Intelligence field of study. Our tentative conclusions indicate that machine learning has some intrinsic limitations which are leading to automate the bias when designing predictive algorithms. Consequently, other methods should be explored; or we should redefine the way current machine learning approaches are being used when building decision making/decision support systems for crucial institutions of our political systems such as the judicial system, just to mention one.",
        "DOI": "10.1007/s00146-020-00996-y",
        "affiliation_name": "Western University",
        "affiliation_city": "London",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Constrained attractor selection using deep reinforcement learning",
        "paper_author": "Wang X.S.",
        "publication": "JVC/Journal of Vibration and Control",
        "citied_by": "23",
        "cover_date": "2021-03-01",
        "Abstract": "This study describes an approach for attractor selection (or multistability control) in nonlinear dynamical systems with constrained actuation. Attractor selection is obtained using two different deep reinforcement learning methods: (1) the cross-entropy method and (2) the deep deterministic policy gradient method. The framework and algorithms for applying these control methods are presented. Experiments were performed on a Duffing oscillator, as it is a classic nonlinear dynamical system with multiple attractors. Both methods achieve attractor selection under various control constraints. Although these methods have nearly identical success rates, the deep deterministic policy gradient method has the advantages of a high learning rate, low performance variance, and a smooth control approach. This study demonstrates the ability of two reinforcement learning approaches to achieve constrained attractor selection.",
        "DOI": "10.1177/1077546320930144",
        "affiliation_name": "Pratt School of Engineering",
        "affiliation_city": "Durham",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Feasibility study on machine-learning-based hybrid renewable energy applications for engineering education",
        "paper_author": "Chandrasekaran S.",
        "publication": "Computer Applications in Engineering Education",
        "citied_by": "12",
        "cover_date": "2021-03-01",
        "Abstract": "In addition to the conventional natural resources such as petroleum extracts, natural gas and charcoal, and particularly with the current worldwide condition of economy of the energy sector, renewable energy sources are increasingly gaining attention. On the basis of recent researches, experts and environmentalists suggest that the renewable energy sources contribute for the major energy consumption. Rapid development of the renewable energy and energy-efficient technologies results in significant energy security and economic benefits, which lead to reduction in capital investment for electricity systems. Therefore, through power system planning, we can augment the quality and efficiency of the power supply. The challenges in meeting the power requirements can be addressed by machine learning (ML) technique, an interdisciplinary field that allows using the statistical techniques to solve the energy-related problems using pattern recognition, artificial neural network, and fuzzy and hybrid combinations. The recent innovations in web-based and mobile technologies led to the application of ML in energy sector.",
        "DOI": "10.1002/cae.22237",
        "affiliation_name": "Kalasalingam Academy of Research and Education",
        "affiliation_city": "Krishnankoil",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Predicting COVID-19 infections and deaths in Bangladesh using Machine Learning Algorithms",
        "paper_author": "Leon M.I.",
        "publication": "2021 International Conference on Information and Communication Technology for Sustainable Development, ICICT4SD 2021 - Proceedings",
        "citied_by": "6",
        "cover_date": "2021-02-27",
        "Abstract": "Since December 2019, the novel coronavirus(COVID-19) has caused over 700,000 deaths with more than 10 million people being infected. Bangladesh, the most densely populated country in the world, is now under community trans-mission of the COVID-19 outbreak. This has created huge health, social, and economic burdens. Till the 10th of February 2020, Bangladesh has reported over 500,000 infected cases and 8000 deaths. To prevent further detriment in our scenario, predicting future consequences are very important. Studies have shown that machine learning(ML) models work extremely well in providing precise information regarding COVID-19 to the authorities thus enabling them to make decisions accordingly. However, to the best of our knowledge, no ML models have been applied that can help in determining the pandemic circumstance for Bangladesh demographics. In this study, we explore different machine learning algorithms that can provide more accurate estimations for predicting future cases which includes infections and deaths due to COVID-19 for Bangladesh. Based on this the government and policymakers can make a decision about the lockdown, resource mobilization, etc. Our study shows that in predicting the pandemic situations, amidst many predicting models the Facebook Prophet Model provided the best accuracy. We believe that using this information the authorities can take decisions that will lead to the saving of countless lives of the people. Additionally, this will also help to reduce the immeasurable economic burden our country is facing due to the present status quo. Furthermore, this study will help analysts to construct predicting models for future explorations.",
        "DOI": "10.1109/ICICT4SD50815.2021.9396820",
        "affiliation_name": "United International University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Multi-Objective Optimal Design of Excitation Systems of Synchronous Condensers for HVDC Systems Based on MOEA/D",
        "paper_author": "Shi F.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "1",
        "cover_date": "2021-02-26",
        "Abstract": "In order to optimize the reactive power characteristics of synchronous condensers and improve the capability of condensers to support the voltage of AC systems, in this paper, the outer loop control of the reactive power of condensers and the outer loop control of the voltage of AC systems are introduced into the design of the main excitation systems of condensers in high voltage direct current (HVDC) systems. Meanwhile, taking the integral values, peak values and steady-state values of voltage deviations of AC systems as objective functions, the multi-objective optimization design of the proportional adjustment coefficients in the outer loop control of the reactive power of condensers and the voltage of AC systems is carried out via utilizing a multi-objective evolutionary algorithm based on decomposition (MOEA/D) combining with fuzzy control method. Its purpose is to alleviate the overvoltage problems of power grids caused by the feedback of the reactive power of condensers and the voltage of AC systems. Lastly, the simulation model of ±100 kV HVDC system with a synchronous condenser is established. The simulation results show that the optimal design method of excitation systems of synchronous condensers proposed in this paper can optimize the reactive power characteristics of the condenser, ensure the rapid regulation of the voltage of the AC system by the condenser, and solve the overvoltage problem in the AC system caused by the reactive power regulation of the condenser which can not change suddenly and the feedback links of the reactive power of the condenser and the voltage of the AC system in the excitation system.",
        "DOI": "10.1145/3457682.3457770",
        "affiliation_name": "Hohai University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Comparison of Deep Reinforcement Learning Algorithms in Enhancing Energy Trading in Microgrids",
        "paper_author": "Elamin M.",
        "publication": "Proceedings of: 2020 International Conference on Computer, Control, Electrical, and Electronics Engineering, ICCCEEE 2020",
        "citied_by": "4",
        "cover_date": "2021-02-26",
        "Abstract": "This paper aims to introduce a solution to Sudan's inadequate electricity supply; focusing on current unconnected rural areas and the high cost of connecting these areas to Sudan's national grid. Microgrids were introduced as a viable option to create small scale distributed grids that depend solely on renewable energy to generate sufficient electricity to satisfy their loads. The paper also aims to enhance the usability of Microgrids by introducing a Machine learning technique to their secondary control that uses energy trading to ensure that all loads in islanded Microgrids are secured. The algorithm uses Reinforcement learning as control for the trading procedure. Data was extracted from a Matlab simulation and was then used to enhance the design of the Reinforcement learning environment. A generic environment for microgrids was designed and implemented which be further used in Reinforcement learning smart grids applications. A set of trading rules were implemented so that the Reinforcement Learning agents can use them across three Microgrids. The agent sees the three micro grids as one primary and two acting as trading game players. Two deep Reinforcement learning algorithms were explored as a solution; the first was an on-policy algorithm; Proximal Policy Optimization (PPO), and the second was an off-policy algorithm; Deep Deterministic Policy Gradients (DDPG). The results of applying both algorithms at three villages in Northern Kordufan State, Hamza ELsheikh, Tannah, and Um Bader were then compared. The algorithms achieved grid equilibrium without any grid loss and achieved profit from the trading process, reducing the time of return for the initial cost of the microgrid.",
        "DOI": "10.1109/ICCCEEE49695.2021.9429565",
        "affiliation_name": "College of Science, Engineering and Technology",
        "affiliation_city": "Jackson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "An Economic Evaluation of Islanded Microgrids Implementation in Northern Kordofan State",
        "paper_author": "Elhassan F.",
        "publication": "Proceedings of: 2020 International Conference on Computer, Control, Electrical, and Electronics Engineering, ICCCEEE 2020",
        "citied_by": "0",
        "cover_date": "2021-02-26",
        "Abstract": "This research aims to introduce a solution to Sudan's inadequate electricity supply, focusing on current unconnected electricity grid users tackling the high cost of connecting rural regions to Sudan's national grid.This paper introduces islanded microgrids as a viable option to create new distributed grids that depend solely on renewable energy for electricity generation. In this study, an economic evaluation was conducted for three different microgrids located in western Sudan to provide the economic viability of hybrid islanded microgrid to encourage the system's implementation. The proposed system was simulated using MATLAB=SIMULINK with the addition of machine learning techniques for the power stability and quality enhancement along with the calculated economic dispatch the research showed that microgrid unlike utility grid can provide fixed electricity cost over lifetime moreover ML techniques provided a decrease in initial cost and a noticeable return on revenue with profit.",
        "DOI": "10.1109/ICCCEEE49695.2021.9429680",
        "affiliation_name": "College of Science, Engineering and Technology",
        "affiliation_city": "Jackson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Predictive policing and artificial intelligence",
        "paper_author": "McDaniel J.L.M.",
        "publication": "Predictive Policing and Artificial Intelligence",
        "citied_by": "13",
        "cover_date": "2021-02-26",
        "Abstract": "This edited text draws together the insights of numerous worldwide eminent academics to evaluate the condition of predictive policing and artificial intelligence (AI) as interlocked policy areas. Predictive and AI technologies are growing in prominence and at an unprecedented rate. Powerful digital crime mapping tools are being used to identify crime hotspots in real-time, as pattern-matching and search algorithms are sorting through huge police databases populated by growing volumes of data in an eff ort to identify people liable to experience (or commit) crime, places likely to host it, and variables associated with its solvability. Facial and vehicle recognition cameras are locating criminals as they move, while police services develop strategies informed by machine learning and other kinds of predictive analytics. Many of these innovations are features of modern policing in the UK, the US and Australia, among other jurisdictions. AI promises to reduce unnecessary labour, speed up various forms of police work, encourage police forces to more efficiently apportion their resources, and enable police officers to prevent crime and protect people from a variety of future harms. However, the promises of predictive and AI technologies and innovations do not always match reality. They often have significant weaknesses, come at a considerable cost and require challenging trade- off s to be made. Focusing on the UK, the US and Australia, this book explores themes of choice architecture, decision- making, human rights, accountability and the rule of law, as well as future uses of AI and predictive technologies in various policing contexts. The text contributes to ongoing debates on the benefits and biases of predictive algorithms, big data sets, machine learning systems, and broader policing strategies and challenges. Written in a clear and direct style, this book will appeal to students and scholars of policing, criminology, crime science, sociology, computer science, cognitive psychology and all those interested in the emergence of AI as a feature of contemporary policing.",
        "DOI": "10.4324/9780429265365",
        "affiliation_name": "University of Derby",
        "affiliation_city": "Derby",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "GrGym: When GNU Radio goes to (AI) Gym",
        "paper_author": "Zubow A.",
        "publication": "HotMobile 2021 - Proceedings of the 22nd International Workshop on Mobile Computing Systems and Applications",
        "citied_by": "9",
        "cover_date": "2021-02-24",
        "Abstract": "Trends like softwarization through the usage of flexible Software-defined Radio (SDR) platforms together with the usage of Machine Learning (ML) techniques are key enablers for building and running future high-performance communication networks in a cost-efficient way. In particular, Reinforcement Learning (RL) becomes very popular as an agent can explore the environment and adapt its behavior based on collected observations and reward values. However, for early deployments there is a pressing need for well-defined environments so that ML/RL-based algorithms can learn the best policies. In this paper, we present GrGym, a framework enabling the design of RL-driven solutions for communication networks based on the OpenAI Gym toolkit and the GNU Radio SDR platform. The GrGym framework allows integrating any GNU Radio program as an environment in the Gym framework by exposing its state and control knobs for the agent's learning purposes. Our framework is generic and can be easily extended to cover various communication problems. We present an illustrative example, where an IEEE 802.11 transmitter learns to adapt its modulation and coding rate based on the observed channel conditions.",
        "DOI": "10.1145/3446382.3448358",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Artificial intelligence autonomous unmanned aerial vehicle (UAV) system for remote sensing in security surveillance",
        "paper_author": "Matthew U.O.",
        "publication": "Proceedings of the 2020 IEEE 2nd International Conference on Cyberspace, CYBER NIGERIA 2020",
        "citied_by": "25",
        "cover_date": "2021-02-23",
        "Abstract": "Adapting artificial intelligence autonomous systems required a policy specification, policy enforcement and policy management on the key prioritized functions based on the inherent policy enforcement and self-definitive programmed knowledge by an autonomous system. In the current research, attempt was made to model an autonomous unmanned aerial vehicle (UAV) system to be able to detect humans within the thickest forest region amidst the escalating tension of bokoharam and bandits abductions within the Nigeria geographic space. The autonomous artificial intelligence UAVs was designed using laser-range detectors for location evaluation and pathway finding with very accurate precision. While the UAVs hovers in the neighborhood, it establishes an individualized 3-D map of its surrounding. The central objective of this study is to explore the scientific opportunities available for artificial intelligence unmanned aerial vehicle (Drones) modeled with machine learning (convolution neural network) on Internet of Things $(\\mathbf{IoTs})$ framework and adapt it to revolutionize the mission on environmental remote sensing, security surveillance, rescue and search mission. The paper established that Nigeria security forces could adopt artificial intelligence UAV to extradite terrorists within the Lake Chad Basin where bokoharam insurgency and banditry are prevalent. The paper further highlight that UAV could be very instrumental in search and rescue mission by the security forces.",
        "DOI": "10.1109/CYBERNIGERIA51635.2021.9428862",
        "affiliation_name": "Michael Okpara University of Agriculture",
        "affiliation_city": "Umuahia",
        "affiliation_country": "Nigeria"
    },
    {
        "paper_title": "Bending the Curve in Cardiovascular Disease Mortality: Bethesda + 40 and beyond",
        "paper_author": "Goff D.C.",
        "publication": "Circulation",
        "citied_by": "36",
        "cover_date": "2021-02-23",
        "Abstract": "More than 40 years after the 1978 Bethesda Conference on the Declining Mortality from Coronary Heart Disease provided the scientific community with a blueprint for systematic analysis to understand declining rates of coronary heart disease, there are indications the decline has ended or even reversed despite advances in our knowledge about the condition and treatment. Recent data show a more complex situation, with mortality rates for overall cardiovascular disease, including coronary heart disease and stroke, decelerating, whereas those for heart failure are increasing. To mark the 40th anniversary of the Bethesda Conference, the National Heart, Lung, and Blood Institute and the American Heart Association cosponsored the \"Bending the Curve in Cardiovascular Disease Mortality: Bethesda + 40\" symposium. The objective was to examine the immediate and long-term outcomes of the 1978 conference and understand the current environment. Symposium themes included trends and future projections in cardiovascular disease (in the United States and internationally), the evolving obesity and diabetes epidemics, and harnessing emerging and innovative opportunities to preserve and promote cardiovascular health and prevent cardiovascular disease. In addition, participant-led discussion explored the challenges and barriers in promoting cardiovascular health across the lifespan and established a potential framework for observational research and interventions that would begin in early childhood (or ideally in utero). This report summarizes the relevant research, policy, and practice opportunities discussed at the symposium.",
        "DOI": "10.1161/CIRCULATIONAHA.120.046501",
        "affiliation_name": "Public Health Foundation of India",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "To detect the distributed denial-of-service attacks in SDN using machine learning algorithms",
        "paper_author": "Banerjee S.",
        "publication": "Proceedings - IEEE 2021 International Conference on Computing, Communication, and Intelligent Systems, ICCCIS 2021",
        "citied_by": "4",
        "cover_date": "2021-02-19",
        "Abstract": "The reason for Software Defined Network (SDN) to gain importance in both the academics and industry as a new emerging way of network management, is its architecture which decouples the data plane (forwarding devices) and the control plane (controller) making it possible to upgrade and update into newer versions. SDN is a new or novel way of 'programmable networks' which has led to growth of innovative technologies and scenarios in terms of network virtualization, flexibility, enhanced growth control, dynamic network policy, reduced operational cost. Despite, these advantages; it is also one of main reasons for cyber threats. Amongst them the most vulnerable is the DDoS attacks. DDoS attack in SDN is quite a threat to the security in SDN network. It attacks at the network layer or application layer of the infrastructure. It can cause problems as simple as inability to refresh a particular page to as severe as failure of an entire server. In this paper, DDoS is taken into consideration with SDN and proposed a IDS which studied for detection of the attackers in the real time incoming traffic. Machine Learning algorithms such as Naïve Bayes, KNN, K-Means clustering, and Linear Regression are used to form the module 1 of the IDS (the Signature IDS) and Module 2 form for uses three way handshake to identify the exact host which is an intruder. On finding the intruder it is being placed in the Access Control List (ACL). Also, analysis of efficiency of different machine learning algorithm is performed to understand the effectiveness.",
        "DOI": "10.1109/ICCCIS51004.2021.9397068",
        "affiliation_name": "SRM Institute of Science and Technology, NCR Campus",
        "affiliation_city": "Ghaziabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Delivering High-Quality, Equitable Care in India: An Ethically-Resilient Framework for Healthcare Innovation After COVID-19",
        "paper_author": "Ozair A.",
        "publication": "Frontiers in Public Health",
        "citied_by": "3",
        "cover_date": "2021-02-18",
        "Abstract": "Developing countries struggle to provide high-quality, equitable care to all. Challenges of resource allocation frequently lead to ethical concerns of healthcare inequity. To tackle this, such developing nations continually need to implement healthcare innovation, coupled with capacity building to ensure new strategies continue to be developed and executed. The COVID-19 pandemic has made significant demands of healthcare systems across the world—to provide equitable healthcare to all, to ensure public health principles are followed, to find novel solutions for previously unencountered healthcare challenges, and to rapidly develop new therapeutics and vaccines for COVID-19. Countries worldwide have struggled to accomplish these demands, especially the latter two, considering that few nations had long-standing systems in place to ensure processes for innovation were on-going before the pandemic struck. The crisis represents a critical juncture to plan for a future. This future needs to incorporate a vision for the implementation of healthcare innovation, coupled with capacity building to ensure new strategies continue to be developed and executed. In this paper, the case of the massive Indian healthcare system is utilized to describe how it could implement this vision. An inclusive, ethically-resilient framework has been broadly laid out for healthcare innovation in the future, thereby ensuring success in both the short- and the long-term.",
        "DOI": "10.3389/fpubh.2021.640598",
        "affiliation_name": "King George's Medical University",
        "affiliation_city": "Lucknow",
        "affiliation_country": "India"
    },
    {
        "paper_title": "A systematic analysis on fintech and its applications",
        "paper_author": "Paul L.R.",
        "publication": "Proceedings of International Conference on Innovative Practices in Technology and Management, ICIPTM 2021",
        "citied_by": "15",
        "cover_date": "2021-02-17",
        "Abstract": "Today, FinTech is integrating with IoT and Artificial Intelligence to challenge banks at a very speedy pace. Fast support and better convenience are major characteristics of FinTech that makes it desirable to customers. This article covers some of the most active and prominent areas classified under the term FinTech they are: Cryptocurrency and digital cash, Smart contracts, Open banking, Blockchain technology, RegTech, InsurTech, Unbanked services, Robo-advisors, Crowd funding. This paper offers coherent research themes built on a critical assessment of the literature. This paper provides a review of the history of FinTech and the various areas under FinTech. Know-hows like Machine Learning, AI, and predictive analytics in financial services can directly affect overall business policy, revenue generation, and resource optimization.",
        "DOI": "10.1109/ICIPTM52218.2021.9388371",
        "affiliation_name": "Amity University",
        "affiliation_city": "Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Robust data-driven profile-based pricing schemes",
        "paper_author": "Cui J.",
        "publication": "2021 IEEE Power and Energy Society Innovative Smart Grid Technologies Conference, ISGT 2021",
        "citied_by": "3",
        "cover_date": "2021-02-16",
        "Abstract": "To enable an effective electricity market, a good pricing scheme is of vital importance. Among many practical schemes, customized pricing is commonly believed to be able to best exploit the flexibility in the demand side. However, due to the large volume of consumers in the electricity sector, such task is simply too overwhelming. In this paper, we first compare two data driven schemes: one based on load profile and the other based on user's marginal system cost. Vulnerability analysis shows that the former approach may lead to loopholes in the electricity market while the latter is able to guarantee the robustness, which yields our robust data-driven pricing scheme. Although k-means clustering is NP-hard, by exploiting the structure of our problem, we design an efficient yet optimal k-means clustering algorithm to implement our proposed scheme.",
        "DOI": "10.1109/ISGT49243.2021.9372155",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A multi-modal approach towards mining social media data during natural disasters - A case study of Hurricane Irma",
        "paper_author": "Mohanty S.D.",
        "publication": "International Journal of Disaster Risk Reduction",
        "citied_by": "30",
        "cover_date": "2021-02-15",
        "Abstract": "Streaming social media provides a real-time glimpse of extreme weather impacts. However, the volume of streaming data makes mining information a challenge for emergency managers, policy makers, and disciplinary scientists. Here we explore the effectiveness of data learned approaches to mine and filter information from streaming social media data from Hurricane Irma's landfall in Florida, USA. We use 54,383 Twitter messages (out of 784 K geolocated messages) from 16,598 users from Sept. 10–12, 2017 to develop 4 independent models to filter data for relevance: 1) a geospatial model based on forcing conditions at the place and time of each tweet, 2) an image classification model for tweets that include images, 3) a user model to predict the reliability of the tweeter, and 4) a text model to determine if the text is related to Hurricane Irma. All four models are independently tested, and can be combined to quickly filter and visualize tweets based on user-defined thresholds for each submodel. We envision that this type of filtering and visualization routine can be useful as a base model for data capture from noisy sources such as Twitter. The data can then be subsequently used by policy makers, environmental managers, emergency managers, and domain scientists interested in finding tweets with specific attributes to use during different stages of the disaster (e.g., preparedness, response, and recovery), or for detailed research.",
        "DOI": "10.1016/j.ijdrr.2020.102032",
        "affiliation_name": "The University of North Carolina at Greensboro",
        "affiliation_city": "Greensboro",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A new hybrid equilibrium optimized SysFor based geospatial data mining for tropical storm-induced flash flood susceptible mapping",
        "paper_author": "Ngo P.T.T.",
        "publication": "Journal of Environmental Management",
        "citied_by": "18",
        "cover_date": "2021-02-15",
        "Abstract": "Flash flood is one of the most dangerous hydrologic and natural phenomena and is considered as the top ranking of such events among various natural disasters due to their fast onset characteristics and the proportion of individual fatalities. Mapping the probability of flash flood events remains challenges because of its complexity and rapid onset of precipitation. Thus, this study aims to propose a state-of-the-art data mining approach based on a hybrid equilibrium optimized SysFor, namely, the HE-SysFor model, for spatial prediction of flash floods. A tropical storm region located in the Northwest areas of Vietnam is selected as a case study. For this purpose, 1866 flash-flooded locations and ten indicators were used. The results show that the proposed HE-SysFor model yielded the highest predictive performance (total accuracy = 93.8%, Kappa index = 0.875, F1-score = 0.939, and AUC = 0.975) and produced the better performance than those of the C4.5 decision tree (C4.5), the radial basis function-based support vector machine (SVM-RBF), the logistic regression (LReg), and deep learning neural network (DeepLNN) models in both the training and the testing phases. Among the ten indicators, elevation, slope, and land cover are the most important. It is concluded that the proposed model provides an alternative tool and may help for effectively monitoring flash floods in tropical areas and robust policies for decision making in mitigating the flash flood impacts.",
        "DOI": "10.1016/j.jenvman.2020.111858",
        "affiliation_name": "Thuyloi University",
        "affiliation_city": "Hanoi",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Case Report: Utilizing AI and NLP to Assist with Healthcare and Rehabilitation During the COVID-19 Pandemic",
        "paper_author": "Carriere J.",
        "publication": "Frontiers in Artificial Intelligence",
        "citied_by": "35",
        "cover_date": "2021-02-12",
        "Abstract": "The COVID-19 pandemic has profoundly affected healthcare systems and healthcare delivery worldwide. Policy makers are utilizing social distancing and isolation policies to reduce the risk of transmission and spread of COVID-19, while the research, development, and testing of antiviral treatments and vaccines are ongoing. As part of these isolation policies, in-person healthcare delivery has been reduced, or eliminated, to avoid the risk of COVID-19 infection in high-risk and vulnerable populations, particularly those with comorbidities. Clinicians, occupational therapists, and physiotherapists have traditionally relied on in-person diagnosis and treatment of acute and chronic musculoskeletal (MSK) and neurological conditions and illnesses. The assessment and rehabilitation of persons with acute and chronic conditions has, therefore, been particularly impacted during the pandemic. This article presents a perspective on how Artificial Intelligence and Machine Learning (AI/ML) technologies, such as Natural Language Processing (NLP), can be used to assist with assessment and rehabilitation for acute and chronic conditions.",
        "DOI": "10.3389/frai.2021.613637",
        "affiliation_name": "Alberta Health Services",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Topic classification of electric vehicle consumer experiences with transformer-based deep learning",
        "paper_author": "Ha S.",
        "publication": "Patterns",
        "citied_by": "25",
        "cover_date": "2021-02-12",
        "Abstract": "Transformer neural networks have emerged as the preeminent models for natural language processing, seeing production-level use with Google search and translation algorithms. These models have had a major impact on context learning from text in many fields, e.g., health care, finance, manufacturing; however, there have been no empirical advances to date in electric mobility. Given the digital transformations in energy and transportation, there are growing opportunities for real-time analysis of critical energy infrastructure. A large, untapped source of EV mobility data is unstructured text generated by mobile app users reviewing charging stations. Using transformer-based deep learning, we present multilabel classification of charging station reviews with performance exceeding human experts in some cases. This paves the way for automatic discovery and real-time tracking of EV user experiences, which can inform local and regional policies to address climate change.",
        "DOI": "10.1016/j.patter.2020.100195",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Prediction Model to Prioritize Individuals for a SARS-CoV-2 Test Built from National Symptom Surveys",
        "paper_author": "Shoer S.",
        "publication": "Med",
        "citied_by": "21",
        "cover_date": "2021-02-12",
        "Abstract": "Background: The gold standard for COVID-19 diagnosis is detection of viral RNA through PCR. Due to global limitations in testing capacity, effective prioritization of individuals for testing is essential. Methods: We devised a model estimating the probability of an individual to test positive for COVID-19 based on answers to 9 simple questions that have been associated with SARS-CoV-2 infection. Our model was devised from a subsample of a national symptom survey that was answered over 2 million times in Israel in its first 2 months and a targeted survey distributed to all residents of several cities in Israel. Overall, 43,752 adults were included, from which 498 self-reported as being COVID-19 positive. Findings: Our model was validated on a held-out set of individuals from Israel where it achieved an auROC of 0.737 (CI: 0.712–0.759) and auPR of 0.144 (CI: 0.119–0.177) and demonstrated its applicability outside of Israel in an independently collected symptom survey dataset from the US, UK, and Sweden. Our analyses revealed interactions between several symptoms and age, suggesting variation in the clinical manifestation of the disease in different age groups. Conclusions: Our tool can be used online and without exposure to suspected patients, thus suggesting worldwide utility in combating COVID-19 by better directing the limited testing resources through prioritization of individuals for testing, thereby increasing the rate at which positive individuals can be identified. Moreover, individuals at high risk for a positive test result can be isolated prior to testing. Funding: E.S. is supported by the Crown Human Genome Center, Larson Charitable Foundation New Scientist Fund, Else Kroener Fresenius Foundation, White Rose International Foundation, Ben B. and Joyce E. Eisenberg Foundation, Nissenbaum Family, Marcos Pinheiro de Andrade and Vanessa Buchheim, Lady Michelle Michels, and Aliza Moussaieff and grants funded by the Minerva foundation with funding from the Federal German Ministry for Education and Research and by the European Research Council and the Israel Science Foundation. H.R. is supported by the Israeli Council for Higher Education (CHE) via the Weizmann Data Science Research Center and by a research grant from Madame Olga Klein – Astrachan.",
        "DOI": "10.1016/j.medj.2020.10.002",
        "affiliation_name": "Clalit Health Services",
        "affiliation_city": "Tel Aviv-Yafo",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "Predicting user interaction behavior on government microblogs: A machine learning approach",
        "paper_author": "Li Y.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2021-02-11",
        "Abstract": "Nowadays, the Chinese government usually publishes policies via social media, where everyone can respond to the messages. Exploring the interaction behaviors of millions of users can help the government collect the users' opinions and make decisions. We use the machine learning algorithm Multilayer Perceptron Network model to predict the user's interactive behaviors under their comments/replies. We found that three kinds of features are useful in predicting user interaction behaviors: The Doc2vec word vector features, the user attributes, and the user history posting information. The experiments show the effectiveness of the neural network-based model, which provides a way to optimize the formulation and implementation of public policies.",
        "DOI": "10.1088/1742-6596/1780/1/012041",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Waste generation, wealth and GHG emissions from the waste sector: Is Denmark on the path towards circular economy?",
        "paper_author": "Magazzino C.",
        "publication": "Science of the Total Environment",
        "citied_by": "123",
        "cover_date": "2021-02-10",
        "Abstract": "Municipal solid waste (MSW) is one of the most urgent issues associated with economic growth and urban population. When untreated, it generates harmful and toxic substances spreading out into the soils. When treated, they produce an important amount of Greenhouse Gas (GHG) emissions directly contributing to global warming. With its promising path to sustainability, the Danish case is of high interest since estimated results are thought to bring useful information for policy purposes. Here, we exploit the most recent and available data period (1994–2017) and investigate the causal relationship between MSW generation per capita, income level, urbanization, and GHG emissions from the waste sector in Denmark. We use an experiment based on Artificial Neural Networks and the Breitung-Candelon Spectral Granger-causality test to understand how the variables, object of the study, manage to interact within a complex ecosystem such as the environment and waste. Through numerous tests in Machine Learning, we arrive at results that imply how economic growth, identifiable by changes in per capita GDP, affects the acceleration and the velocity of the neural signal with waste emissions. We observe a periodical shift from the traditional linear economy to a circular economy that has important policy implications.",
        "DOI": "10.1016/j.scitotenv.2020.142510",
        "affiliation_name": "Nord Universitet",
        "affiliation_city": "Bodo",
        "affiliation_country": "Norway"
    },
    {
        "paper_title": "Two-stage three-way enhanced technique for ensemble learning in inclusive policy text classification",
        "paper_author": "Liang D.",
        "publication": "Information Sciences",
        "citied_by": "52",
        "cover_date": "2021-02-08",
        "Abstract": "With the development of the social economy, small and medium-sized enterprises (SMEs) play a vital role in promoting economic development. Multiple local governments in China are developing policy recommended platforms in order to help SMEs better understand the inclusive policy. However, these online platforms manually extract the key information from the inclusive policy texts, which takes a lot of time and causes low efficiency. The policy text is composed of some paragraphs and each paragraph corresponds to a topic. When we classify the paragraphs into different topics, there exists a decision risk of text misclassification. Therefore, we design two-stage based three-way enhanced technique to automatically classify these text paragraphs into the predefined categories. At the first stage, by using ensemble learning algorithms, we construct an ensemble convolution neural network (CNN) model in order to ensure the generalization ability and stability of text classification results. Meanwhile, we develop a new weight determination method to integrate the prediction results of all base classifiers according to the accuracy and classification confidence. With the help of three-way decisions (3WD), we assign the samples with poor resolution to the boundary area for secondary classification, which can reduce the decision risk. At the second stage, in order to classify the boundary region samples and improve the overall classification results, we further utilize traditional machine learning method as the secondary classifier. Finally, we develop some comparison experiments to verify our proposed method. The experimental results show that the two-stage three-way enhanced classification framework is valid and obtains a better performance. Our proposed method can effectively support the designment of policy recommended platforms and serve SMEs.",
        "DOI": "10.1016/j.ins.2020.08.051",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Iterative Learning for Model Reactive Control: Application to Autonomous Multi-agent Control",
        "paper_author": "Shrit O.",
        "publication": "2021 International Conference on Automation, Robotics and Applications, ICARA 2021",
        "citied_by": "4",
        "cover_date": "2021-02-04",
        "Abstract": "In this paper, a decentralized autonomous controller aimed to control a fleet of quadrotors is designed, based on the iterative generation and exploitation of logged traces. The presented approach, inspired by model predictive control, aims to maintain the geometrical configuration for a set of quadrotors led by remotely controlled leaders. The novelty of this approach is to rely on inexpensive commercial off-the-shelf sensors (as opposed to positioning systems and/or cameras) that only measure the distance among quadrotors. In the first phase (trace generation) quadrotors are operated using randomized controllers based on domain knowledge, and their trajectories are registered. In the exploitation phase, a policy is learned from the traces generated in the previous phase, and the policy is iteratively refined, to achieve a robust reactive control of each quadrotor agent. Extensive experiments using RotorS, a Software In the Loop (SITL) framework in Gazebo simulator demonstrates the efficiency of the approach, and its ability to preserve the flocking structure of the quadrotors, following the (remotely and independently controlled) leaders.",
        "DOI": "10.1109/ICARA51699.2021.9376454",
        "affiliation_name": "École Nationale Supérieure de Techniques Avancées",
        "affiliation_city": "Palaiseau",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Sentiment Analysis for Zoning System Admission Policy Using Support Vector Machine and Naive Bayes Methods",
        "paper_author": "Ariyanto R.A.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "4",
        "cover_date": "2021-02-03",
        "Abstract": "Indonesia have low quality of education. According Trend International Mathematics and Science Study, Indonesian student's mathematical literacy is ranked 36 from 49 countries. For Science literacy, Indonesia is ranked 35 from 49 countries. To increase quality of education in Indonesia, Indonesia's government make a new policy for new student admission called zoning system. Zoning system is a new student admission according distance from house to school. Zoning system is new policy in Indonesia and there are still many pros and cons of the zoning system. Sentiment analysis is used to know whether Indonesia's people agree or disagree about zoning system policy. In this study, we use supervised statistical learning methods that are Support Vector Machine (SVM) and Naïve Bayes for sentiment analysis of zoning system admission policy. The results show that Indonesia's people tend to disagree with the zoning system admission policy because negative opinion is greater than positive opinion. Furthermore, accuracy rates of SVM and Naïve Bayes are 92.93% and 79.86% respectively. So, SVM is better than Naïve Bayes for sentiment analysis of zoning system admission policy.",
        "DOI": "10.1088/1742-6596/1776/1/012058",
        "affiliation_name": "Universitas Airlangga",
        "affiliation_city": "Surabaya",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "The rise of compound warm-season droughts in Europe",
        "paper_author": "Markonis Y.",
        "publication": "Science Advances",
        "citied_by": "104",
        "cover_date": "2021-02-03",
        "Abstract": "Drought is one of the main threats to food security and ecosystem productivity. During the past decades, Europe has experienced a series of droughts that caused substantial socioeconomic losses and environmental impacts. A key question is whether there are some similar characteristics in these droughts, especially when compared to the droughts that occurred further in the past. Answering this question is impossible with traditional single-index approaches and also short-term and often spatially inconsistent records. Here, using a multidimensional machine learning-based clustering algorithm and the hydrologic reconstruction of European drought, we determine the dominant drought types and investigate the changes in drought typology. We report a substantial increase in shorter warm-season droughts that are concurrent with an increase in potential evapotranspiration. If shifts reported here persist, then we will need new adaptive water management policies and, in the long run, we may observe considerable alterations in vegetation regimes and ecosystem functioning.",
        "DOI": "10.1126/sciadv.abb9668",
        "affiliation_name": "Samueli School of Engineering",
        "affiliation_city": "Irvine",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "New gen controlling variable using dragonfly algorithm in PV panel",
        "paper_author": "Urooj S.",
        "publication": "Energies",
        "citied_by": "11",
        "cover_date": "2021-02-02",
        "Abstract": "In the present scenario the depletion of conventional sources causes an energy crisis. The energy crisis causes load demand with respect to electricity. The use of renewable energy sources plays a vital role in reducing the energy crisis and in reduction of CO2 emission. The use of solar energy is the major source of power in generation as this is the root cause for the development of wind, tides, etc. However, due to climatic condition the availability of PV sources varies from time to time. Hence it is essential to track the maximum source of energy by implementing different types of MPPT algorithms. However, use of MPPT algorithms has the limitation of using the same during partial shadow conditions. The issue of tracking power under partial shadow conditions can be resolved by implementing an intelligent optimization tracking algorithm which involves a computation process. Though many of nature’s inspired algorithms were present to address real world problems, Mirjalili developed the dragonfly algorithm to provide a better optimization solution to the issues faced in real-time applications. The proposed concept focuses on the implementation of the dragonfly optimization algorithm to track the maximum power from solar and involves the concept of machine learning, image processing, and data computation.",
        "DOI": "10.3390/en14040790",
        "affiliation_name": "Audisankara College of Engineering &amp; Technology",
        "affiliation_city": "Gudur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Automatic assessment of privacy policies under the gdpr",
        "paper_author": "Sánchez D.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "18",
        "cover_date": "2021-02-02",
        "Abstract": "To comply with the EU General Data Protection Regulation (GDPR), companies managing personal data have been forced to review their privacy policies. However, privacy policies will not solve any problems as long as users do not read or are not able to understand them. In order to assist users in both issues, we present a system that automatically assesses privacy policies. Our proposal quantifies the degree of policy compliance with respect to the data protection goals stated by the GPDR and presents clear and intuitive privacy scores to the user. In this way, users will become immediately aware of the risks associated with the services and their severity; this will empower them to take informed decisions when accepting (or not) the terms of a service. We leverage manual annotations and machine learning to train a model that automatically tags privacy policies according to their compliance (or not) with the data protection goals of the GDPR. In contrast with related works, we define clear annotation criteria consistent with the GDPR, and this enables us not only to provide aggregated scores, but also fine-grained ratings that help to understand the reasons of the assessment. The latter is aligned with the concept of explainable artificial intelligence. We have applied our method to the policies of 10 well-known internet services. Our scores are sound and consistent with the results reported in related works.",
        "DOI": "10.3390/app11041762",
        "affiliation_name": "Universitat Rovira i Virgili",
        "affiliation_city": "Tarragona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Mitochondriopathies as a clue to systemic disorders—analytical tools and mitigating measures in context of predictive, preventive, and personalized (3p) medicine",
        "paper_author": "Liskova A.",
        "publication": "International Journal of Molecular Sciences",
        "citied_by": "30",
        "cover_date": "2021-02-02",
        "Abstract": "The mitochondrial respiratory chain is the main site of reactive oxygen species (ROS) production in the cell. Although mitochondria possess a powerful antioxidant system, an excess of ROS cannot be completely neutralized and cumulative oxidative damage may lead to decreasing mitochondrial efficiency in energy production, as well as an increasing ROS excess, which is known to cause a critical imbalance in antioxidant/oxidant mechanisms and a “vicious circle” in mitochondrial injury. Due to insufficient energy production, chronic exposure to ROS overproduction consequently leads to the oxidative damage of life-important biomolecules, including nucleic acids, proteins, lipids, and amino acids, among others. Different forms of mitochondrial dysfunction (mitochondriopathies) may affect the brain, heart, peripheral nervous and endocrine systems, eyes, ears, gut, and kid-ney, among other organs. Consequently, mitochondriopathies have been proposed as an attractive diagnostic target to be investigated in any patient with unexplained progressive multisystem disor-der. This review article highlights the pathomechanisms of mitochondriopathies, details advanced analytical tools, and suggests predictive approaches, targeted prevention and personalization of medical services as instrumental for the overall management of mitochondriopathy-related cascading pathologies.",
        "DOI": "10.3390/ijms22042007",
        "affiliation_name": "Universitätsklinikum Bonn",
        "affiliation_city": "Bonn",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Observation Time Effects in Reinforcement Learning on Contracts for Difference",
        "paper_author": "Wehrmann M.",
        "publication": "Journal of Risk and Financial Management",
        "citied_by": "0",
        "cover_date": "2021-02-01",
        "Abstract": "In this paper, we present a study on Reinforcement Learning optimization models for automatic trading, in which we focus on the effects of varying the observation time. Our Reinforcement Learning agents feature a Convolutional Neural Network (CNN) together with Long Short-Term Memory (LSTM) and act on the basis of different observation time spans. Each agent tries to maximize trading profit by buying or selling one of a number of contracts in a simulated market environment for Contracts for Difference (CfD), considering correlations between individual assets by architecture. To decide which action to take on a specific contract, an agent develops a policy which relies on an observation of the whole market for a certain period of time. We investigate whether or not there exists an optimal observation sequence length, and conclude that such a value depends on market dynamics.",
        "DOI": "10.3390/jrfm14020054",
        "affiliation_name": "Fachhochschule Münster - Abteilung Steinfurt",
        "affiliation_city": "Steinfurt",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Forecasting mortality rates using hybrid Lee–Carter model, artificial neural network and random forest",
        "paper_author": "Hong W.H.",
        "publication": "Complex and Intelligent Systems",
        "citied_by": "21",
        "cover_date": "2021-02-01",
        "Abstract": "Inaccurate prediction would cause the insurance company encounter catastrophic losses and may lead to overpriced premiums where low-earning consumers cannot afford to insure themselves. The ability to forecast mortality rates accurately can allow the insurance company to take preventive measures to introduce new policies with reasonable prices. In this paper, several Lee–Carter (LC) based models are used to forecast the mortality rates in a case study of the Malaysian population. The LC-ARIMA model and also a combination of the LC model with two machine learning (ML) methods, namely the random forest (RF) and artificial neural network (ANN) methods are utilized on the prediction of mortality rates for males and females in Malaysia, whereby the LC-Random Forest (LC-RF) hybrid model is a new model that is introduced in this paper. Seventeen years of mortality data in Malaysia are selected as the dataset for this research. To analyze how the forecasting models perform for other countries, we have determined the model that has the best fit and produced the best forecasted mortality rates for all the other countries that are studied. This research has showed that LC-ANN and LC-ARIMA are the best model in predicting the mortality rates of males and females in Malaysia, respectively. This study has also found that the LC-ARIMA model is the best performing model in forecasting the mortality rates in countries that have longer life expectancy and a good healthcare system such as Sweden, Ireland, Japan, Hong Kong, Norway, Switzerland and Czechia. In contrast, the LC-ANN model is the best performing model in forecasting the mortality rates in countries that have a less efficiency, less accessibility healthcare system, and bad personal behavior such as Malaysia, Canada and Latvia.",
        "DOI": "10.1007/s40747-020-00185-w",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "MLComp: A Methodology for Machine Learning-based Performance Estimation and Adaptive Selection of Pareto-Optimal Compiler Optimization Sequences",
        "paper_author": "Colucci A.",
        "publication": "Proceedings -Design, Automation and Test in Europe, DATE",
        "citied_by": "4",
        "cover_date": "2021-02-01",
        "Abstract": "Embedded systems have proliferated in various consumer and industrial applications with the evolution of Cyber-Physical Systems and the Internet of Things. These systems are subjected to stringent constraints so that embedded software must be optimized for multiple objectives simultaneously, namely reduced energy consumption, execution time, and code size. Compilers offer optimization phases to improve these metrics. However, proper selection and ordering of them depends on multiple factors and typically requires expert knowledge. State-of-the-art optimizers facilitate different platforms and applications case by case, and they are limited by optimizing one metric at a time, as well as requiring a time-consuming adaptation for different targets through dynamic profiling. To address these problems, we propose the novel MLComp methodology, in which optimization phases are sequenced by a Reinforcement Learning-based policy. Training of the policy is supported by Machine Learning-based analytical models for quick performance estimation, thereby drastically reducing the time spent for dynamic profiling. In our framework, different Machine Learning models are automatically tested to choose the best-fitting one. The trained Performance Estimator model is leveraged to efficiently devise Reinforcement Learning-based multi-objective policies for creating quasi-optimal phase sequences. Compared to state-of-the-art estimation models, our Performance Estimator model achieves lower relative error (< 2%) with up to 50 × faster training time over multiple platforms and application domains. Our Phase Selection Policy improves execution time and energy consumption of a given code by up to 12% and 6%, respectively. The Performance Estimator and the Phase Selection Policy can be trained efficiently for any target platform and application domain.",
        "DOI": "10.23919/DATE51398.2021.9474158",
        "affiliation_name": "Christian Doppler Forschungsgesellschaft",
        "affiliation_city": "Vienna",
        "affiliation_country": "Austria"
    },
    {
        "paper_title": "Origin: Enabling On-Device Intelligence for Human Activity Recognition Using Energy Harvesting Wireless Sensor Networks",
        "paper_author": "Mishra C.S.",
        "publication": "Proceedings -Design, Automation and Test in Europe, DATE",
        "citied_by": "10",
        "cover_date": "2021-02-01",
        "Abstract": "There is an increasing demand for performing machine learning tasks, such as human activity recognition (HAR) on emerging ultra-low-power internet of things (IoT) platforms. Recent works show substantial efficiency boosts from performing inference tasks directly on the IoT nodes rather than merely transmitting raw sensor data. However, the computation and power demands of deep neural network (DNN) based inference pose significant challenges when executed on the nodes of an energy-harvesting wireless sensor network (EH-WSN). Moreover, managing inferences requiring responses from multiple energy-harvesting nodes imposes challenges at the system level in addition to the constraints at each node. This paper presents a novel scheduling policy along with an adaptive ensemble learner to efficiently perform HAR on a distributed energy-harvesting body area network. Our proposed policy, Origin, strategically ensures efficient and accurate individual inference execution at each sensor node by using a novel activity-aware scheduling approach. It also leverages the continuous nature of human activity when coordinating and aggregating results from all the sensor nodes to improve final classification accuracy. Further, Origin proposes an adaptive ensemble learner to personalize the optimizations based on each individual user. Experimental results using two different HAR data-sets show Origin, while running on harvested energy, to be at least 2.5% more accurate than a classical battery-powered energy aware HAR classifier continuously operating at the same average power.",
        "DOI": "10.23919/DATE51398.2021.9474017",
        "affiliation_name": "Pennsylvania State University",
        "affiliation_city": "University Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Solving Highly Cyclic Distributed Optimization Problems without Busting the Bank: A Decimation-based Approach",
        "paper_author": "Cerquides J.",
        "publication": "Logic Journal of the IGPL",
        "citied_by": "2",
        "cover_date": "2021-02-01",
        "Abstract": "In the context of solving large distributed constraint optimization problems, belief-propagation and incomplete inference algorithms are candidates of choice. However, in general, when the problem structure is very cyclic, these solution methods suffer from bad performance, due to non-convergence and many exchanged messages. As to improve performances of the MaxSum inference algorithm when solving cyclic constraint optimization problems, we propose here to take inspiration from the belief-propagation-guided decimation used to solve sparse random graphs (k-satisfiability). We propose the novel DeciMaxSum method, which is parameterized in terms of policies to decide when to trigger decimation, which variables to decimate and which values to assign to decimated variables. Based on an empirical evaluation on a classical constraint optimization benchmarks (graph coloring, random graph and Ising model), some of these combinations of policies, using periodic decimation, cycle detection-based decimation, parallel and non parallel decimation, random or deterministic variable selection and deterministic or random sampling for value selection, outperform state-of-the-art competitors in many settings.",
        "DOI": "10.1093/jigpal/jzaa069",
        "affiliation_name": "Université Jean Monnet Saint Etienne",
        "affiliation_city": "Saint-Etienne",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Designing a Cost-Effective Cache Replacement Policy using Machine Learning",
        "paper_author": "Sethumurugan S.",
        "publication": "Proceedings - International Symposium on High-Performance Computer Architecture",
        "citied_by": "46",
        "cover_date": "2021-02-01",
        "Abstract": "Extensive research has been carried out to improve cache replacement policies, yet designing an efficient cache replacement policy that incurs low hardware overhead remains a challenging and time-consuming task. Given the surging interest in applying machine learning (ML) to challenging computer architecture design problems, we use ML as an offline tool to design a cost-effective cache replacement policy. We demonstrate that ML is capable of guiding and expediting the generation of a cache replacement policy that is competitive with state-of-The-Art hand-crafted policies. In this work, we use Reinforcement Learning (RL) to learn a cache replacement policy. After analyzing the learned model, we are able to focus on a few critical features that might impact system performance. Using the insights provided by RL, we successfully derive a new cache replacement policy-Reinforcement Learned Replacement (RLR). Compared to the state-of-The-Art policies, RLR has low hardware overhead, and it can be implemented without needing to modify the processor's control and data path to propagate information such as program counter. On average, RLR improves single-core and four-core system performance by 3.25% and 4.86% over LRU, with an overhead of 16.75KB for 2MB last-level cache (LLC) and 67KB for 8MB LLC.",
        "DOI": "10.1109/HPCA51647.2021.00033",
        "affiliation_name": "College of Science and Engineering",
        "affiliation_city": "Minneapolis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Decision support system for stock portfolio selection using artificial intelligence and machine learning",
        "paper_author": "Patalay S.",
        "publication": "Ingenierie des Systemes d'Information",
        "citied_by": "14",
        "cover_date": "2021-02-01",
        "Abstract": "Investing in stock market requires in-depth knowledge of finance and stock market dynamics. Stock Portfolio Selection and management involve complex financial analysis and decision making policies. An Individual investor seeking to invest in stock portfolio is need of a support system which can guide him to create a portfolio of stocks based on sound financial analysis. In this paper the authors designed a Financial Decision Support System (DSS) for creating and managing a portfolio of stock which is based on Artificial Intelligence (AI) and Machine learning (ML) and combining the traditional approach of mathematical models. We believe this a unique approach to perform stock portfolio, the results of this study are quite encouraging as the stock portfolios created by the DSS are based on strong financial health indices which in turn are giving Return on Investment (ROI) in the range of more than 11% in the short term and more than 61% in the long term, therefore beating the market index by a factor of 15%. This system has the potential to help millions of Individual Investors who can make their financial decisions on stocks and may eventually contribute to a more efficient financial system.",
        "DOI": "10.18280/isi.260109",
        "affiliation_name": "Vignans Foundation for Science Technology and Research University",
        "affiliation_city": "Guntur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Downscaling groundwater storage data in China to a 1-km resolution using machine learning methods",
        "paper_author": "Zhang J.",
        "publication": "Remote Sensing",
        "citied_by": "54",
        "cover_date": "2021-02-01",
        "Abstract": "High-resolution and continuous hydrological products have tremendous importance for the prediction of water-related trends and enhancing the capability for sustainable water resources management under climate change and human impacts. In this study, we used the random forest (RF) and extreme gradient boosting (XGBoost) methods to downscale groundwater storage (GWS) from 1◦ (~110 km) to 1 km by downscaling Gravity Recovery and Climate Experiment (GRACE) and Global Land Data Assimilation System (GLDAS) data from 1◦ (~110 km) and 0.25◦ (~25 km) respectively, to 1 km for China. Three evaluation metrics were employed for the testing dataset for 2004−2016: The R2 ranged from 0.77−0.89 for XGBoost (0.74−0.86 for RF), the correlation coefficient (CC) ranged from 0.88−0.94 for XGBoost (0.88−0.93 for RF) and the root-mean-square error (RMSE) ranged from 0.37−2.3 for XGBoost (0.4−2.53 for RF). The R2 of the XGBoost models for GLDAS was 0.64−0.82 (0.63−0.82 for RF), the CC was 0.80−0.91 (0.80−0.90 for RF) and the RMSE was 0.63−1.75 (0.63−1.77 for RF). The downscaled GWS derived from GRACE and GLDAS were validated using in situ measurements by comparing the time series variations and the downscaled products maintained the accuracy of the original data. The interannual changes within 9 river basins between pre-and post-downscaling were consistent, emphasizing the reliability of the downscaled products. Ultimately, annual downscaled TWS, GLDAS and GWS products were provided from 2004 to 2016, providing a solid data foundation for studying local GWS changes, conducting finer-scale hydrological studies and adapting water resources management and policy formulation to local condition.",
        "DOI": "10.3390/rs13030523",
        "affiliation_name": "Beijing Normal University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Understanding spatial patterns in rape reporting delays",
        "paper_author": "Klemmer K.",
        "publication": "Royal Society Open Science",
        "citied_by": "9",
        "cover_date": "2021-02-01",
        "Abstract": "Under-reporting and delayed reporting of rape crime are severe issues that can complicate the prosecution of perpetrators and prevent rape survivors from receiving needed support. Building on a massive database of publicly available criminal reports from two US cities, we develop a machine learning framework to predict delayed reporting of rape to help tackle this issue. Motivated by large and unexplained spatial variation in reporting delays, we build predictive models to analyse spatial, temporal and socio-economic factors that might explain this variation. Our findings suggest that we can explain a substantial proportion of the variation in rape reporting delays using only openly available data. The insights from this study can be used to motivate targeted, data-driven policies to assist vulnerable communities. For example, we find that younger rape survivors and crimes committed during holiday seasons exhibit longer delays. Our insights can thus help organizations focused on supporting survivors of sexual violence to provide their services at the right place and time. Due to the non-confidential nature of the data used in our models, even community organizations lacking access to sensitive police data can use these findings to optimize their operations.",
        "DOI": "10.1098/rsos.201795",
        "affiliation_name": "Faculty of Science, Engineering and Medicine",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Learning Health System in Crisis: Lessons From the COVID-19 Pandemic",
        "paper_author": "Romanelli R.J.",
        "publication": "Mayo Clinic Proceedings: Innovations, Quality and Outcomes",
        "citied_by": "26",
        "cover_date": "2021-02-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.mayocpiqo.2020.10.004",
        "affiliation_name": "Palo Alto Medical Foundation Research Institute",
        "affiliation_city": "Palo Alto",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Public opinions and concerns regarding the Canadian prime minister⇔s daily COVID-19 briefing: Longitudinal study of youtube comments using machine learning techniques",
        "paper_author": "Zheng C.",
        "publication": "Journal of Medical Internet Research",
        "citied_by": "9",
        "cover_date": "2021-02-01",
        "Abstract": "Background: During the COVID-19 pandemic in Canada, Prime Minister Justin Trudeau provided updates on the novel coronavirus and the government’s responses to the pandemic in his daily briefings from March 13 to May 22, 2020, delivered on the official Canadian Broadcasting Corporation (CBC) YouTube channel. Objective: The aim of this study was to examine comments on Canadian Prime Minister Trudeau’s COVID-19 daily briefings by YouTube users and track these comments to extract the changing dynamics of the opinions and concerns of the public over time. Methods: We used machine learning techniques to longitudinally analyze a total of 46,732 English YouTube comments that were retrieved from 57 videos of Prime Minister Trudeau’s COVID-19 daily briefings from March 13 to May 22, 2020. A natural language processing model, latent Dirichlet allocation, was used to choose salient topics among the sampled comments for each of the 57 videos. Thematic analysis was used to classify and summarize these salient topics into different prominent themes. Results: We found 11 prominent themes, including strict border measures, public responses to Prime Minister Trudeau’s policies, essential work and frontline workers, individuals’ financial challenges, rental and mortgage subsidies, quarantine, government financial aid for enterprises and individuals, personal protective equipment, Canada and China’s relationship, vaccines, and reopening. Conclusions: This study is the first to longitudinally investigate public discourse and concerns related to Prime Minister Trudeau’s daily COVID-19 briefings in Canada. This study contributes to establishing a real-time feedback loop between the public and public health officials on social media. Hearing and reacting to real concerns from the public can enhance trust between the government and the public to prepare for future health emergencies.",
        "DOI": "10.2196/23957",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Modeling vehicle ownership with machine learning techniques in the Greater Tamale Area, Ghana",
        "paper_author": "Zambang M.A.M.",
        "publication": "PLoS ONE",
        "citied_by": "7",
        "cover_date": "2021-02-01",
        "Abstract": "Vehicle ownership modeling and prediction is a crucial task in the transportation planning processes which, traditionally, uses statistical models in the modeling process. However, with the advancement in computing power of computers and Artificial Intelligence, Machine Learning (ML) algorithms are becoming an alternative or a complement to the statistical models in modeling the transportation planning processes. Although the application of ML algorithms to the transportation planning processes-like mode choice, and traffic forecasting and demand modeling-have received much attention in research and abound in literature, scanty attention is paid to its application to vehicle ownership modeling especially in the context of small to medium cities in developing countries. Therefore, this study attempts to fill this gap by modeling vehicle ownership in the Greater Tamale Area (GTA), a typically small to medium city in Ghana. Using a cross sectional survey of formal sectors workers, data was collected between June-August 2018. The study applied nine different ML classification algorithms to the dataset using 10-fold cross-validation technique/s and the Cohen- Kappa static/statistic to evaluate the predictive performance of each of the algorithms, and the Permutation Feature Importance to examine the features that contribute significantly to the prediction of vehicle ownership in GTA. The results showed that Linear Support Vector Classification (LinearSVC) classifier performed well in comparison with the other classifiers with regards to the overall predictive ability of the classifiers. In terms of class predictions, KNearest Neighbors (KNN) classifier performs well for no-vehicle class whiles Linear Support Vector Classification (LinearSVC) and GaussianNB classifiers performs well for motorcycle ownership. LinearSVC and Logistic Regression classifiers performed well on the car ownership class. Also, the results indicated that travel mode choice, average monthly income, average travel distance to workplace, average monthly expenditure on transport, duration of travel to workplace, occupational rank, age, household size and marital status were significant in predicting vehicle ownership for most of the classifiers. These findings could help policies makers carve out strategies that would reduce vehicle ownership but improve personal mobility. Copyright:",
        "DOI": "10.1371/journal.pone.0246044",
        "affiliation_name": "Jiangsu University",
        "affiliation_city": "Zhenjiang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "What predicts legislative success of early care and education policies?: Applications of machine learning and natural language processing in a cross-state early childhood policy analysis",
        "paper_author": "Park S.O.",
        "publication": "PLoS ONE",
        "citied_by": "6",
        "cover_date": "2021-02-01",
        "Abstract": "Following the pioneering efforts of a federal Head Start program, U.S. state policymakers have rapidly expanded access to Early Care and Education (ECE) programs with strong bipartisan support. Within the past decade the enrollment of 4 year-olds has roughly doubled in state-funded preschool. Despite these public investments, the content and priorities of early childhood legislation–enacted and failed–have rarely been examined. This study integrates perspectives from public policy, political science, developmental science, and machine learning in examining state ECE bills in identifying key factors associated with legislative success. Drawing from the Early Care and Education Bill Tracking Database, we employed Latent Dirichlet Allocation (LDA), a statistical topic identification model, to examine 2,396 ECE bills across the 50 U.S. states during the 2015-2018. First, a six-topic solution demonstrated the strongest fit theoretically and empirically suggesting two meta policy priorities: ‘ECE finance’ and ‘ECE services’. ‘ECE finance’ comprised three dimensions: (1) Revenues, (2) Expenditures, and (3) Fiscal Governance. ‘ECE services’ also included three dimensions: (1) PreK, (2) Child Care, and (3) Health and Human Services (HHS). Further, we found that bills covering a higher proportion of HHS, Fiscal Governance, or Expenditures were more likely to pass into law relative to bills focusing largely on PreK, Child Care, and Revenues. Additionally, legislative effectiveness of the bill’s primary sponsor was a strong predictor of legislative success, and further moderated the relation between bill content and passage. Highly effective legislators who had previously passed five or more bills had an extremely high probability of introducing a legislation that successfully passed regardless of topic. Legislation with expenditures as policy priorities benefitted the most from having an effective legislator. We conclude with a discussion of the empirical findings within the broader context of early childhood policy literature and suggest implications for future research and policy.",
        "DOI": "10.1371/journal.pone.0246730",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Estimation of the fraction of COVID-19 infected people in U.S. states and countries worldwide",
        "paper_author": "Noh J.",
        "publication": "PLoS ONE",
        "citied_by": "77",
        "cover_date": "2021-02-01",
        "Abstract": "Since the beginning of the coronavirus disease 2019 (COVID-19) pandemic, daily counts of confirmed cases and deaths have been publicly reported in real-time to control the virus spread. However, substantial undocumented infections have obscured the true size of the currently infected population, which is arguably the most critical number for public health policy decisions. We developed a machine learning framework to estimate time courses of actual new COVID-19 cases and current infections in all 50 U.S. states and the 50 most infected countries from reported test results and deaths. Using published epidemiological parameters, our algorithm optimized slowly varying daily ascertainment rates and a time course of currently infected cases each day. Severe under-ascertainment of COVID-19 cases was found to be universal across U.S. states and countries worldwide. In 25 out of the 50 countries, actual cumulative cases were estimated to be 5-20 times greater than the confirmed cases. Our estimates of cumulative incidence were in line with the existing seroprevalence rates in 46 U.S. states. Our framework projected for countries like Belgium, Brazil, and the U.S. that ~10% of the population has been infected once. In the U.S. states like Louisiana, Georgia, and Florida, more than 4% of the population was estimated to be currently infected, as of September 3, 2020, while in New York this fraction is 0.12%. The estimation of the actual fraction of currently infected people is crucial for any definition of public health policies, which up to this point may have been misguided by the reliance on confirmed cases. Copyright:",
        "DOI": "10.1371/journal.pone.0246772",
        "affiliation_name": "UT Southwestern Medical Center",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Topic Modeling and Text Analysis for Qualitative Policy Research",
        "paper_author": "Isoaho K.",
        "publication": "Policy Studies Journal",
        "citied_by": "126",
        "cover_date": "2021-02-01",
        "Abstract": "This paper contributes to a critical methodological discussion that has direct ramifications for policy studies: how computational methods can be concretely incorporated into existing processes of textual analysis and interpretation without compromising scientific integrity. We focus on the computational method of topic modeling and investigate how it interacts with two larger families of qualitative methods: content and classification methods characterized by interest in words as communication units and discourse and representation methods characterized by interest in the meaning of communicative acts. Based on analysis of recent academic publications that have used topic modeling for textual analysis, our findings show that different mixed-method research designs are appropriate when combining topic modeling with the two groups of methods. Our main concluding argument is that topic modeling enables scholars to apply policy theories and concepts to much larger sets of data. That said, the use of computational methods requires genuine understanding of these techniques to obtain substantially meaningful results. We encourage policy scholars to reflect carefully on methodological issues, and offer a simple heuristic to help identify and address critical points when designing a study using topic modeling.",
        "DOI": "10.1111/psj.12343",
        "affiliation_name": "Helsingin Yliopisto",
        "affiliation_city": "Helsinki",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Toward a Fully Automated Artificial Pancreas System Using a Bioinspired Reinforcement Learning Design: In Silico Validation",
        "paper_author": "Lee S.",
        "publication": "IEEE Journal of Biomedical and Health Informatics",
        "citied_by": "53",
        "cover_date": "2021-02-01",
        "Abstract": "Objective: The automation of insulin treatment is the most challenge aspect of glucose management for type 1 diabetes owing to unexpected exogenous events (e.g., meal intake). In this article, we propose a novel reinforcement learning (RL) based artificial intelligence (AI) algorithm for a fully automated artificial pancreas (AP) system. Methods: A bioinspired RL designing method was developed for automated insulin infusion. This method has reward functions that imply the temporal homeostatic objective and discount factors that reflect an individual specific pharmacological characteristic. The proposed method was applied to a training method using an RL algorithm and was evaluated in virtual patients from the FDA approved UVA/Padova simulator with unannounced meal intakes. Results: For a single-meal experiment with preprandial fasting, the trained policy demonstrated fully automated regulation in both the basal and postprandial phases. In the in silico trial with a variation of insulin sensitivity and dawn phenomenon, the policy achieved a mean glucose of 124.72 mg/dL and percentage time in the normal range of 89.56%. The layer-wise relevance propagation provides interpretable information on AI-driven decision for robustness to sensor noise, automated postprandial regulation, and insulin stacking avoidance. Conclusion: The AP algorithm based on the bioinspired RL approach enables fully automated blood glucose control with unannounced meal intake. Significance: The proposed framework can be extended to other drug-based treatments for systems with significant uncertainties.",
        "DOI": "10.1109/JBHI.2020.3002022",
        "affiliation_name": "Pohang University of Science and Technology",
        "affiliation_city": "Pohang",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Simulation, optimization, and machine learning in sustainable transportation systems: Models and applications",
        "paper_author": "de la Torre R.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "56",
        "cover_date": "2021-02-01",
        "Abstract": "The need for effective freight and human transportation systems has consistently increased during the last decades, mainly due to factors such as globalization, e-commerce activities, and mobility requirements. Traditionally, transportation systems have been designed with the main goal of reducing their monetary cost while offering a specified quality of service. During the last decade, however, sustainability concepts are also being considered as a critical component of transportation systems, i.e., the environmental and social impact of transportation activities have to be taken into account when managers and policy makers design and operate modern transportation systems, whether these refer to long-distance carriers or to metropolitan areas. This paper reviews the existing work on different scientific methodologies that are being used to promote Sustainable Transportation Systems (STS), including simulation, optimization, machine learning, and fuzzy sets. This paper discusses how each of these methodologies have been employed to design and efficiently operate STS. In addition, the paper also provides a classification of common challenges, best practices, future trends, and open research lines that might be useful for both researchers and practitioners.",
        "DOI": "10.3390/su13031551",
        "affiliation_name": "Boston University Metropolitan College",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Who cares about coal? Analyzing 70 years of German parliamentary debates on coal with dynamic topic modeling",
        "paper_author": "Müller-Hansen F.",
        "publication": "Energy Research and Social Science",
        "citied_by": "33",
        "cover_date": "2021-02-01",
        "Abstract": "Despite Germany's Paris Agreement pledge and coal exit legislation, the political debate around carbon-intensive coal remains heated. Coal power and mining have played an important, yet changing role in the history of German politics. In this paper, we analyze the entire parliamentary debate on coal in the German parliament (Bundestag) from its inception in 1949 to 2019. For this purpose we extract the more than 870,000 parliamentary speeches from all protocols in the history of the Bundestag. We identify the 9167 speeches mentioning coal and apply dynamic topic modeling – an unsupervised machine learning technique that reveals the changing thematic structure of large document collections over time – to analyze changes in parliamentary debates on coal over the past 70 years. The trends in topics and their varying internal structure reflect how energy policy was discussed and legitimized over time: Initially, coal was framed as a driver of economic prosperity and guarantee of energy security. In recent years, the debate evolved towards energy transition, coal phase-out and renewable energy expansion. Germany's smaller and younger parties, the Greens and the Left Party, debate coal more often in the context of the energy transition and climate protection than other parties. Our results reflect trends in other countries and other fields of energy policy. Methodologically, our study illustrates the potential of and need for computational methods to analyze vast corpora of text and to complement traditional social science methods.",
        "DOI": "10.1016/j.erss.2020.101869",
        "affiliation_name": "Wuppertal Institut für Klima, Umwelt, Energie",
        "affiliation_city": "Wuppertal",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "MobileVisFixer: Tailoring Web Visualizations for Mobile Phones Leveraging an Explainable Reinforcement Learning Framework",
        "paper_author": "Wu A.",
        "publication": "IEEE Transactions on Visualization and Computer Graphics",
        "citied_by": "31",
        "cover_date": "2021-02-01",
        "Abstract": "We contribute MobileVisFixer, a new method to make visualizations more mobile-friendly. Although mobile devices have become the primary means of accessing information on the web, many existing visualizations are not optimized for small screens and can lead to a frustrating user experience. Currently, practitioners and researchers have to engage in a tedious and time-consuming process to ensure that their designs scale to screens of different sizes, and existing toolkits and libraries provide little support in diagnosing and repairing issues. To address this challenge, MobileVisFixer automates a mobile-friendly visualization re-design process with a novel reinforcement learning framework. To inform the design of MobileVisFixer, we first collected and analyzed SVG-based visualizations on the web, and identified five common mobile-friendly issues. MobileVisFixer addresses four of these issues on single-view Cartesian visualizations with linear or discrete scales by a Markov Decision Process model that is both generalizable across various visualizations and fully explainable. MobileVisFixer deconstructs charts into declarative formats, and uses a greedy heuristic based on Policy Gradient methods to find solutions to this difficult, multi-criteria optimization problem in reasonable time. In addition, MobileVisFixer can be easily extended with the incorporation of optimization algorithms for data visualizations. Quantitative evaluation on two real-world datasets demonstrates the effectiveness and generalizability of our method.",
        "DOI": "10.1109/TVCG.2020.3030423",
        "affiliation_name": "Microsoft Research",
        "affiliation_city": "Redmond",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Synthesizing individual consumers′ credit historical data using generative adversarial networks",
        "paper_author": "Park N.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "3",
        "cover_date": "2021-02-01",
        "Abstract": "The financial sector accumulates a massive amount of consumer data that contain the most sensitive information daily. These data are strictly limited outside the financial institutions, sometimes even within the same organization, for various reasons such as privacy laws or asset management policy. Financial data has never been more valuable, especially when assessed jointly with data from different industries, including healthcare, insurance, credit bureau, and research institutions. Therefore, it is critical to generate synthetic datasets that retain the statistical or latent properties of the real datasets as well as the privacy protection guaranteed. In this paper, we apply Generative Adversarial Nets (GANs) to generating synthetic consumer credit data to be used for various educational purposes, specifically in developing machine learning models. GAN is preferable to other pseudonymization methods such as masking, swapping, shuffling, or perturbation, for it does not suffer from adding more attributes or data. This study is significant because it is the first attempt to generate the synthetic data of real-world credit data in practical use. The results find that synthetic consumer credit data using GAN shows a substantial utility without severely compromising privacy and would be a useful resource for big data training programs.",
        "DOI": "10.3390/app11031126",
        "affiliation_name": "Sejong University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Bringing onco‐innovation to Europe’s healthcare systems: The potential of biomarker testing, real world evidence, tumour agnostic therapies to empower personalised medicine",
        "paper_author": "Horgan D.",
        "publication": "Cancers",
        "citied_by": "15",
        "cover_date": "2021-02-01",
        "Abstract": "Rapid and continuing advances in biomarker testing are not being matched by uptake in health systems, and this is hampering both patient care and innovation. It also risks costing health systems the opportunity to make their services more efficient and, over time, more economical. The potential that genomics has brought to biomarker testing in diagnosis, prediction and research is being realised, pre‐eminently in many cancers, but also in an ever‐wider range of conditions— notably BRCA1/2 testing in ovarian, breast, pancreatic and prostate cancers. Nevertheless, the implementation of genetic testing in clinical routine setting is still challenging. Development is impeded by country‐related heterogeneity, data deficiencies, and lack of policy alignment on standards, approval—and the role of real‐world evidence in the process—and reimbursement. The acute nature of the problem is compellingly illustrated by the particular challenges facing the development and use of tumour agnostic therapies, where the gaps in preparedness for taking advantage of this innovative approach to cancer therapy are sharply exposed. Europe should already have in place a guarantee of universal access to a minimum suite of biomarker tests and should be planning for an optimum testing scenario with a wider range of biomarker tests integrated into a more sophisticated health system articulated around personalised medicine. Improving healthcare and winning advantages for Europe’s industrial competitiveness and innovation require an appropriate policy framework—starting with an update to outdated recommendations. We show herein the main issues and proposals that emerged during the previous advisory boards organised by the European Alliance for Personalized Medicine which mainly focus on possible scenarios of harmonisation of both oncogenetic testing and management of cancer patients.",
        "DOI": "10.3390/cancers13030583",
        "affiliation_name": "Centro de Investigación Biomédica en Red de Cáncer",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Predictors of contemporary under-5 child mortality in low-and middle-income countries: A machine learning approach",
        "paper_author": "Bizzego A.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "23",
        "cover_date": "2021-02-01",
        "Abstract": "Child Mortality (CM) is a worldwide concern, annually affecting as many as 6.81% children in low-and middle-income countries (LMIC). We used data of the Multiple Indicators Cluster Survey (MICS) (N = 275,160) from 27 LMIC and a machine-learning approach to rank 37 distal causes of CM and identify the top 10 causes in terms of predictive potency. Based on the top 10 causes, we identified households with improved conditions. We retrospectively validated the results by investigating the association between variations of CM and variations of the percentage of households with improved conditions at country-level, between the 2005–2007 and the 2013–2017 administrations of the MICS. A unique contribution of our approach is to identify lesser-known distal causes which likely account for better-known proximal causes: notably, the identified distal causes and preventable and treatable through social, educational, and physical interventions. We demonstrate how machine learning can be used to obtain operational information from big dataset to guide interventions and policy makers.",
        "DOI": "10.3390/ijerph18031315",
        "affiliation_name": "National Institute of Child Health and Human Development (NICHD)",
        "affiliation_city": "Bethesda",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Integrating machine learning, radio frequency identification, and consignment policy for reducing unreliability in smart supply chain management",
        "paper_author": "Sardar S.K.",
        "publication": "Processes",
        "citied_by": "48",
        "cover_date": "2021-02-01",
        "Abstract": "Adopting smart technologies for supply chain management leads to higher profits. The manufacturer and retailer are two supply chain players, where the retailer is unreliable and may not send accurate demand information to the manufacturer. As an advanced smart technology, Radio Frequency Identification (RFID) is implemented to track and trace each product’s movement on a real-time basis in the inventory. It takes this supply chain to a smart supply chain management. This research proposes a Machine Learning (ML) approach for on-demand forecasting under smart supply chain management. Using Long-Short-Term Memory (LSTM), the demand is forecasted to obtain the exact demand information to reduce the overstock or understock situation. A measurement for the environmental effect is also incorporated with the model. A consignment policy is applied where the manufacturer controls the inventory, and the retailer gets a fixed fee along with a commission for selling each product. The manufacturer installs RFID technology at the retailer’s place. Two mathematical models are solved using a classical optimization technique. The results from those two models show that the ML-RFID model gives a higher profit than the existing traditional system.",
        "DOI": "10.3390/pr9020247",
        "affiliation_name": "Hanyang University ERICA Campus",
        "affiliation_city": "Ansan",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Technoeconomic analysis for biofuels and bioproducts",
        "paper_author": "Scown C.D.",
        "publication": "Current Opinion in Biotechnology",
        "citied_by": "82",
        "cover_date": "2021-02-01",
        "Abstract": "Technoeconomic analysis (TEA) is an approach for conducting process design and simulation, informed by empirical data, to estimate capital costs, operating costs, mass balances, and energy balances for a commercial scale biorefinery. TEA serves as a useful method to screen potential research priorities, identify cost bottlenecks at the earliest stages of research, and provide the mass and energy data needed to conduct life-cycle environmental assessments. Recent studies have produced new tools and methods to enable faster iteration on potential designs, more robust uncertainty analysis, and greater accessibility through the use of open-source platforms. There is also a trend toward more expansive system boundaries to incorporate the impact of policy incentives, use-phase performance differences, and potential impacts on global market supply.",
        "DOI": "10.1016/j.copbio.2021.01.002",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "What current and missing data can teach us about medication errors",
        "paper_author": "Padula W.V.",
        "publication": "BMJ Quality and Safety",
        "citied_by": "1",
        "cover_date": "2021-02-01",
        "Abstract": "NA",
        "DOI": "10.1136/bmjqs-2019-010555",
        "affiliation_name": "USC School of Pharmacy",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application of unsupervised machine learning to identify and characterise hydroxychloroquine misinformation on Twitter",
        "paper_author": "Mackey T.K.",
        "publication": "The Lancet Digital Health",
        "citied_by": "36",
        "cover_date": "2021-02-01",
        "Abstract": "NA",
        "DOI": "10.1016/S2589-7500(20)30318-6",
        "affiliation_name": "Department of Family Medicine",
        "affiliation_city": "San Diego",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "How much carbon can be added to soil by sorption?",
        "paper_author": "Abramoff R.Z.",
        "publication": "Biogeochemistry",
        "citied_by": "33",
        "cover_date": "2021-02-01",
        "Abstract": "Quantifying the upper limit of stable soil carbon storage is essential for guiding policies to increase soil carbon storage. One pool of carbon considered particularly stable across climate zones and soil types is formed when dissolved organic carbon sorbs to minerals. We quantified, for the first time, the potential of mineral soils to sorb additional dissolved organic carbon (DOC) for six soil orders. We compiled 402 laboratory sorption experiments to estimate the additional DOC sorption potential, that is the potential of excess DOC sorption in addition to the existing background level already sorbed in each soil sample. We estimated this potential using gridded climate and soil geochemical variables within a machine learning model. We find that mid- and low-latitude soils and subsoils have a greater capacity to store DOC by sorption compared to high-latitude soils and topsoils. The global additional DOC sorption potential for six soil orders is estimated to be 107 ± 13 Pg C to 1 m depth. If this potential was realized, it would represent a 7% increase in the existing total carbon stock.",
        "DOI": "10.1007/s10533-021-00759-x",
        "affiliation_name": "Laboratoire de Géologie de l'École Normale Supérieure de Paris",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Task-Oriented Deep Reinforcement Learning for Robotic Skill Acquisition and Control",
        "paper_author": "Xiang G.",
        "publication": "IEEE Transactions on Cybernetics",
        "citied_by": "35",
        "cover_date": "2021-02-01",
        "Abstract": "Reinforcement learning (RL) and imitation learning (IL), especially equipped with deep neural networks, have been widely studied for autonomous robotic skill acquisition and control tasks. However, these methods and their extensions require extensive environmental interactions during training, which greatly prevents them from being applied to real-world robots. To alleviate this problem, we present an efficient model-free off-policy actor-critic algorithm for robotic skill acquisition and continuous control, by fusing the task reward with a task-oriented guiding reward, which is formulated by leveraging few and imperfect expert demonstrations. In this framework, the agent can explore the environment more intentionally, thus sampling efficiency can be achieved; moreover, the agent can also exploit the experience more effectively, thereby substantially improved performance can be realized simultaneously. The empirical results on robotic locomotion tasks show that the proposed scheme can lower sample complexity by 2-10 times in contrast with the state-of-the-art baseline deep RL (DRL) algorithms, while achieving performance better than that of the expert. Furthermore, the proposed algorithm achieves significant improvement in both sampling efficiency and asymptotic performance on tasks with sparse and delayed reward, wherein those baseline DRL algorithms struggle to make progress. This takes a substantial step forward to implement these methods to acquire skills autonomously for real robots.",
        "DOI": "10.1109/TCYB.2019.2949596",
        "affiliation_name": "Key Laboratory of System Control and Information Processing, Ministry of Education",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Intelligent cognitive radio Ad-hoc network: Planning, learning and dynamic configuration",
        "paper_author": "Lee K.E.",
        "publication": "Electronics (Switzerland)",
        "citied_by": "13",
        "cover_date": "2021-02-01",
        "Abstract": "Cognitive radio (CR) is an adaptive radio technology that can automatically detect available channels in a wireless spectrum and change transmission parameters to improve the radio operating behavior. A CR ad-hoc network (CRAHN) should be able to coexist with primary user (PU) systems and other CR secondary systems without causing harmful interference to licensed PUs as well as dynamically configure autonomous and decentralized networks. Therefore, an intelligent system structure is required for efficient spectrum use. In this paper, we present a learning-based distributed autonomous CRAHN network system model for network planning, learning, and dynamic configuration. Based on the system model, we propose machine learning-based optimization algorithms for spectrum sensing, cluster-based ad-hoc network configuration, and context-aware signal classification. Using the sensing engine and the cognitive engine, the surrounding spectrum usage and the neighbor network operation status can be analyzed. The proposed policy engine can create network operation policies for the dynamically changing surrounding wireless environment, detect policy conflicts, and infer the optimal policy for the current situation. The decision engine finally determines and configures the optimal CRAHN configuration parameters through cooperation with a learning engine, in which we implement the proposed machine-learning algorithms. The simulation results show that the proposed machine-learning CRAHN algorithms can construct CR cluster networks that have a long network lifetime and high spectrum utility. Additionally, with high signal context recognition performance, we can ensure coexistence with neighboring systems.",
        "DOI": "10.3390/electronics10030254",
        "affiliation_name": "Agency for Defense Development",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Delineation of an Urban Community Life Circle Based on a Machine-Learning Estimation of Spatiotemporal Behavioral Demand",
        "paper_author": "Li C.",
        "publication": "Chinese Geographical Science",
        "citied_by": "23",
        "cover_date": "2021-02-01",
        "Abstract": "Delineating life circles is an essential prerequisite for urban community life circle planning. Recent studies combined the environmental contexts with residents’ global positioning system (GPS) data to delineate the life circles. This method, however, is constrained by GPS data, and it can only be applied in the GPS surveyed communities. To address this limitation, this study developed a generalizable delineation method without the constraint of behavioral data. According to previous research, the community life circle consists of the walking-accessible range and internal structure. The core task to develop the generalizable method was to estimate the spatiotemporal behavioral demand for each plot of land to acquire the internal structure of the life circle, as the range can be delineated primarily based on environmental data. Therefore, behavioral demand estimation models were established through logistic regression and machine learning techniques, including decision trees and ensemble learning. The model with the lowest error rate was chosen as the final estimation model for each type of land. Finally, we used a community without GPS data as an example to demonstrate the effectiveness of the estimation models and delineation method. This article extends the existing literature by introducing spatiotemporal behavioral demand estimation models, which learn the relationships between environmental contexts, population composition and the existing delineated results based on GPS data to delineate the internal structure of the community life circle without employing behavioral data. Furthermore, the proposed method and delineation results also contributes to facilities adjustments and location selections in life circle planning, people-oriented transformation in urban planning, and activity space estimation of the population in evaluating and improving the urban policies.",
        "DOI": "10.1007/s11769-021-1174-z",
        "affiliation_name": "Peking University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Words against injustices: A deep narrative analysis of energy cultures in poverty of Abuja, Mumbai and Rio de Janeiro",
        "paper_author": "Debnath R.",
        "publication": "Energy Research and Social Science",
        "citied_by": "12",
        "cover_date": "2021-02-01",
        "Abstract": "Slum rehabilitation housing (SRH) are critical transitional spaces in urban informality that has deep-rooted implications on poverty alleviation efforts. However, current literature reports systemic injustices in SRH on access to essential services, including energy injustices. This study investigated distributive injustices in the SRH across three cities, Abuja, Mumbai and Rio de Janeiro, developing ‘energy cultures’ narratives. It employed a computational social science methodology that used textual analysis, followed by a constructivist grounded theoretic approach to inform just policy design. The analysis was performed at two scales to identify and contrast injustices in the study areas. The result at an aggregated scale showed commonalities were around the poor design of the built environment, administrative lags of the utilities and high electricity bills. Case study-specific results showed that poverty penalties were linked with the energy cultures of each SRHs. In the Mumbai case, poverty penalties were associated with the aspirational purchase of household appliances due to move from slums to SRH. The Abuja case showed low power quality and load shedding frequently damaged appliances that increase the maintenance costs for the occupants. The Rio de Janeiro SRH case had injustices embedded through the adoption of inefficient appliances received as charity from higher-income households. Fuel stacking was also observed in the SRH that illustrated cultural identities associated with cooking energy. The conclusion was drawn to support just policy design by considering the socio-cultural context of the built environment, improving utility governance and promoting cleaner fuel mix at the household level.",
        "DOI": "10.1016/j.erss.2020.101892",
        "affiliation_name": "Cambridge Judge Business School",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Telehealth in type 1 diabetes",
        "paper_author": "Kompala T.",
        "publication": "Current Opinion in Endocrinology, Diabetes and Obesity",
        "citied_by": "24",
        "cover_date": "2021-02-01",
        "Abstract": "Purpose of review The role of telehealth in the care of people with type 1 diabetes (T1D) has expanded dramatically during the coronavirus pandemic, and is expected to remain a major care delivery modality going forward. This review explores the landscape of recent evidence for telehealth in T1D care. Recent findings Telemedicine for routine T1D care has shown equivalence to standard in-person care, with respect to glycemic control, while also increasing access, convenience, and satisfaction. Telehealth use promotes increased engagement of adolescents with T1D. Telehealth platforms have successfully been used in the care of microvascular complications and to support mental health related to diabetes. Machine learning and advanced decision support will increasingly be used to augment T1D care, as recent evidence suggests increasing capabilities to improve glycemic control. A spectrum of digital connected care services are emerging to support people with diabetes with daily management of diabetes. Finally, policy and systems are required that promote data interoperability, telemedicine provision, and reimbursement to support the ongoing growth of telehealth in T1D. Summary A developing field of evidence supports use of telehealth in T1D. As this care modality scales, it has the potential to increase access to high-quality diabetes care for many people with T1D.",
        "DOI": "10.1097/MED.0000000000000600",
        "affiliation_name": "UCSF School of Medicine",
        "affiliation_city": "San Francisco",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Based Approach for Sustainable Social Protection Policies in Developing Societies",
        "paper_author": "Mumtaz Z.",
        "publication": "Mobile Networks and Applications",
        "citied_by": "5",
        "cover_date": "2021-02-01",
        "Abstract": "Machine learning has been increasingly used for making informed public policy decisions, however, its application in the area of social protection in developing societies has been largely overlooked. We have employed unsupervised machine learning K-means clustering technique for exploring a big data that comprised of 88 attributes and 570 instances for better targeting of households that are in urgent need of welfare from the government. The clusters formed showed common patterns relating to insecurities in terms of loss of income and property, unemployment, disasters and disease etc. faced by households in each cluster. We found that households falling in rural areas jurisdictions face severe insecurities compared to other localities and are in urgent need of social protection interventions. We concluded that by employing K-means clustering unsupervised machine learning approach big data (even if it is limited) can be explored effectively for better targeting of social protection interventions for both developing and smart societies. The unsupervised machine learning technique presented in this study is an efficient approach because it can be used by societies that are facing data constraints and can achieve optimal results for increasing the welfare of poor by using the said approach.",
        "DOI": "10.1007/s11036-020-01696-z",
        "affiliation_name": "The Australian National University",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "The Effect of Information Disclosure on Industry Payments to Physicians",
        "paper_author": "Guo T.",
        "publication": "Journal of Marketing Research",
        "citied_by": "29",
        "cover_date": "2021-02-01",
        "Abstract": "In 2019, U.S. pharmaceutical companies paid $3.6 billion to physicians in the form of gifts to promote their drugs. To curb inappropriate financial relationships between health care providers and firms, several state laws require firms to publicly declare the payments they make to physicians. In 2013, this disclosure law was rolled out to all 50 states. The authors investigate the causal impact of this increased transparency on subsequent payments between firms and physicians. While firms and physicians were informed of the disclosure regulation at data collection, complete transparency did not occur until the data were published online. The authors estimate the heterogeneous treatment effects of the online data disclosure exploiting the phased rollout of the disclosure laws across states, facilitated by recent advances in machine learning methods. Using a 29-month national panel covering $100 million in payments between 16 antidiabetic brands and 50,000 physicians, the authors find that the monthly payments changed insignificantly, on average, due to disclosure. However, the average null effect masks some unintended consequences of disclosure, wherein payments may have increased for more expensive drugs and among physicians who prescribed more heavily. The authors further explore potential mechanisms that can parsimoniously describe the data pattern.",
        "DOI": "10.1177/0022243720972106",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Ecosystem based multi-species management using Empirical Dynamic Programming",
        "paper_author": "Brias A.",
        "publication": "Ecological Modelling",
        "citied_by": "19",
        "cover_date": "2021-02-01",
        "Abstract": "Control theory and stochastic dynamic programming have long been used to develop optimal single-species management policies. However, most species interact with others through competition and predation as parts of complex ecosystems. As a consequence, it is unclear how far from optimal the single species policies currently in use actually are. Moreover, there are as yet no scalable algorithms for optimal ecosystem management. Here, we merge recently developed tools from machine learning and nonlinear dynamics to construct and evaluate near-optimal policies in multi-species systems. Specifically, a non-parametric model for the dynamics is estimated from time series data using Gaussian process-based dynamic modeling. A policy is then derived from the inferred dynamics using a temporal difference learning algorithm. Policy performance is benchmarked against single-species policies and the ad hoc ecosystem policies that have been previously offered. We found that EDP policies are closer to the true optimal policies than single-species policies in multi-species systems with two controls and three objectives. The Pareto fronts illustrate the flexibility of EDP policies compared with single-species policies.",
        "DOI": "10.1016/j.ecolmodel.2020.109423",
        "affiliation_name": "NOAA National Marine Fisheries Service Southwest Regional Office",
        "affiliation_city": "Long Beach",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The main trends for multi-tier supply chain in Industry 4.0 based on Natural Language Processing",
        "paper_author": "Zhou R.",
        "publication": "Computers in Industry",
        "citied_by": "28",
        "cover_date": "2021-02-01",
        "Abstract": "Multi-tier supply chains in Industry 4.0 are critical emerging issues today. This article briefly examines the Industry 4.0 policies in different countries. In order to decide on a better model and the number of topics in the model, a comparative test of the coherence value for two machine learning classification methods based on Latent Dirichlet Allocation was conducted. Subsequently, the article combines the traditional literature review method with a survey article referring to Industry 4.0 and multi-tier supply chain, indexed by science citation index expanded (SCI-EXPANDED) and social sciences citation index (SSCI) during 2009-2018. The research direction, research type, and research approaches of each paper were extracted, and the topics of all the articles were classified by machine learning, which provides feasible routes and valuable research directions for researchers in this field. Afterward, the research status and future research directions were identified. The combination of natural language processing in machine learning to classify research topics and traditional literature review to investigate article details greatly improved the objectivity and scientificity of the study and laid a solid foundation for further research.",
        "DOI": "10.1016/j.compind.2020.103369",
        "affiliation_name": "Concordia Institute for Information Systems Engineering",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Ecological environment management system based on artificial intelligence and complex numerical optimization",
        "paper_author": "Niu L.",
        "publication": "Microprocessors and Microsystems",
        "citied_by": "5",
        "cover_date": "2021-02-01",
        "Abstract": "Raw environmental management is an essential factor in the successful implementation of strategic power. Environmental management improves the level need to manage innovation. If get called substitution, the environmental management of change of, ecological to realization, must be sustainable economic development. With environmental and economic policies and market management, the portfolio management machine learns the ecological environment's essential benefits. Existing environmental protection measures and environmental management methods on (Field Programmable Gate Arrays) FPGA-based machine learning ecology ecological significance analysis of current development, must establish an ecological compensation mechanism by the current FPGA environmental management. Assumptions. Due to the lack of laws and regulations, an essential factor in the overall management of the ecological environment and environmental management practices. Therefore, it is necessary to establish a legal system of ecological compensation law. The establishment of ecological compensation is clear, eco-taxes, ecological compensation fund system, and ecological management and oversight point to explore current FPGA environmental management.",
        "DOI": "10.1016/j.micpro.2020.103627",
        "affiliation_name": "Qufu Normal University",
        "affiliation_city": "Qufu",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Using microprocessor and video surveillance system for data simulation of sports public service data platform",
        "paper_author": "Liu T.",
        "publication": "Microprocessors and Microsystems",
        "citied_by": "0",
        "cover_date": "2021-02-01",
        "Abstract": "The new open help hypothesis is another policy implementation hypothesis set up by acclaimed authoritative researchers. Its centre thought is to improve administration mindfulness, advance majority rule support, and seek after the augmentation of public interests. Field Programmable Gate Arrays (FPGA) and have been utilized to expand the throughput of cell neural organizations. All the more correctly, FPGAs have been as of late embraced to quicken the usage of profound learning organizations, because of their greatest parallelism, and because of their energy productivity capacities. Here, the strategy surveys the ongoing existing innovation of quickening machine learning to become familiar with the organization on FPGA. Feature the significant capacities utilized by different advancements to improve increasing speed execution The considerations contained in this hypothesis have significant hypothetical and functional essentialness for the development of China's people group sports public assistance gracefully. Along these lines, utilizing the new open help hypothesis has a significant beneficial outcome and incentive in investigating the flexibly of machine learning network sports public administrations. This examination utilizes writing technique, poll review strategy, field overview strategy and information measurements strategy to research the primary substance and gracefully substance of the network sports public help flexibly framework in Kunming. Joining the centre thoughts of the new open help hypothesis, it advances proposals and gives recommendations and premise to the development of the public assistance flexibly arrangement of metropolitan network sports public administrations.",
        "DOI": "10.1016/j.micpro.2020.103631",
        "affiliation_name": "Nantong University",
        "affiliation_city": "Nantong",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Estimation of methane emissions from energy combustion based on wireless sensors and machine learning",
        "paper_author": "Cui Y.",
        "publication": "Microprocessors and Microsystems",
        "citied_by": "2",
        "cover_date": "2021-02-01",
        "Abstract": "Methane emissions from garbage dumps have become a global mantra due to global climate change and its significant impact. The portable air quality meter used in this study estimates methane emissions from six storage locations. The results show that the spatial level is in the methane range. The previous method based on Neural Network and IOT (Internet of Thing) for methane emissions based energy combustion. In the previous method, Low complexity requires massive processing, and it cannot improve any application. So in the proposed methane, emissions from energy combustion are used for energy combustion, and sensors are easily interfaces with the controller without any complex. There is a time-varying level of methane-based on the high value during the rainy season. On the other hand, the number of methane emissions by the control station is not detected. According to the Air Quality Index (AQI) model, methane emissions are also moderate, confirming that methane emissions come from human activities in the garbage dump, excluding mainly radio stations, and estimating it as safe. They recommend policies intended to isolate methane emissions, including recycling, recycling and reduction. Climate change is an important issue that needs to be addressed immediately. The effects of climate change, such as ocean acidification and extreme weather conditions, are so severe that they are essential for learning the combat effectiveness behind these phenomena.",
        "DOI": "10.1016/j.micpro.2020.103604",
        "affiliation_name": "Jiangsu University",
        "affiliation_city": "Zhenjiang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Online sports tourism platform based on FPGA and machine learning",
        "paper_author": "Yang D.",
        "publication": "Microprocessors and Microsystems",
        "citied_by": "11",
        "cover_date": "2021-02-01",
        "Abstract": "Machine Learning (ML) is one of the intelligent methods shown promising results in the classification and prediction of structural domains. It is a large amount of money for the prediction area's sport to be increasingly expanding and needs a good prediction accuracy related to the cause bet. Sport tourism sports, to participate in leisure and entertainment purposes, will be driven. Activities. However, passive sports tourism visited the sport; are traveling for leisure or leisure activities. Sports tourism is an area that has experienced rapid growth in global tourism. Sports tourism, nostalgic sports tourism, active sports tourism, and passive Sports Tourism: Sports tourism can be divided into four types. At a phenomenal growth rate of the sports tourism industry, it has now attracted these travelers' facilities to increase your sports-related business time—the impact of sports tourism in support of tourism development. The sum of the questionnaire is used to collect information from Aqaba residents. It is to do multiple regression analysis to verify the hypothesis of the study. While the social impact variable does not significantly impact, it indicates that the current research results, two independent variables support tourism development that has a significant impact. From his empirical data and other research, he is about the launch of motivation and sports tourism. The front to answer the question, equipped with plan expectations and itinerary, and a specific network is a sporting event. It determines the travel; after the actual realization of this trip, it means nothing in terms of decided to participate. The correct access to data on sports and tourism competitiveness, it also, to determine an effective way of the corresponding policy, is necessary to provide the relevant local government's criteria.",
        "DOI": "10.1016/j.micpro.2020.103584",
        "affiliation_name": "Zhejiang University of Technology",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Wheat yield predictions at a county and field scale with deep learning, machine learning, and google earth engine",
        "paper_author": "Cao J.",
        "publication": "European Journal of Agronomy",
        "citied_by": "133",
        "cover_date": "2021-02-01",
        "Abstract": "To meet the challenges of climate change, increasing population and food demand, a timely, accurate and reliable estimation of crop yield at a large scale is more imperative than ever for crop management, food security evaluation, food trade and policy-making. In this study, taking the major winter wheat production regions of China as an example, we compared a traditional machine learning method (random forest, RF) and three deep learning (DL) models, including DNN (deep neural networks), 1D-CNN (1D convolutional neural networks), and LSTM (long short-term memory networks) to predict crop yields by integrating publicly available data within the GEE (Google Earth Engine) platform, including climate, satellite, soil properties, and spatial information data. The results showed that all four models could capture winter wheat yield variations in all the county-years, with R2 of recorded and simulated yields ranging from 0.83 to 0.90 and RMSE ranging from 561.18 to 959.62 kg/ha. They all performed well for winter wheat yield prediction at a county level from 2011 to 2015, with mean R2≥0.85 and RMSE ≤ 768 kg/ha. At a field level, the spatial pattern of estimated winter wheat yield could capture the spatial heterogeneity and yield differences between individual fields across a county fairly well. However, only the DNN and RF models had relatively good performance at the field level, with mean R2 values of 0.71, 0.66 and RMSE values of 1127 kg/ha and 956 kg/ha, respectively. The model comparisons showed that the performance of RF was not always worse than DL at both the county and field levels. Our findings demonstrated a scalable, simple and inexpensive framework for estimating crop yields at various scales in a timely manner and with reliable accuracy, which has important implications for crop yield forecasting, agricultural disaster monitoring, food trade policy, and food security warning.",
        "DOI": "10.1016/j.eja.2020.126204",
        "affiliation_name": "Institute of Geographic Sciences and Natural Resources Research, Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Simulation of Economic Benefits of Technological Innovation Based on FPGA and Machine Learning",
        "paper_author": "Sun Y.",
        "publication": "Microprocessors and Microsystems",
        "citied_by": "1",
        "cover_date": "2021-02-01",
        "Abstract": "Increasing capital assets in the high-tech sectors impact numbers on average annual employment, reports, technology imports and economic growth standards. Analyzing the impact of Innovation and standardization in high technology assesses the impact of these factors on the elongation that occurs in traditional products. Technological advances, reports, technical imports are expressed in terms of quality 52%. The number of reports on the impact of growth on the high technology sector is unusually large. Using the three levels, the regional innovation system in the publishing area of ​​the data output technology, economy publishing stage play, and social benefits publishing is a role model for innovation activities and to evaluate technological efficiency. Using the envelope analysis method model proposes to economic performance and social efficiency of innovation activities in each regional innovation system and policy proposals. Most economic Innovation is the key driver of economic growth. Economic stagnation is suggestive attitudes reflect these policy responses have reduced the economic dynamism and lower living standards. Technological advances in many countries, GDP (Gross Domestic Product) growth, and contribute. Machine learning (ML) with clusters of independent FPGA configuration for processing an application platform, has proposed a budget. FPGA configuration without the knowledge of researchers and developers, not looking for a budget-friendly solution to the most expensive on the market without relying on today's FPGA configuration to maximize applications' performance on their ML Focus on providing an economical platform solution.",
        "DOI": "10.1016/j.micpro.2020.103549",
        "affiliation_name": "Northeast Normal University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Computational Models of Human Decision-Making with Application to the Internet of Everything",
        "paper_author": "Maghsudi S.",
        "publication": "IEEE Wireless Communications",
        "citied_by": "11",
        "cover_date": "2021-02-01",
        "Abstract": "The concept of the Internet of Things (IoT) first appeared a few decades ago. Today, by the ubiquitous wireless connectivity, the boost of machine learning and artificial intelligence, and the advances in big data analytics, it is safe to say that IoT has evolved to a new concept called the Internet of Everything (IoE) or the Internet of All. IoE has four pillars, things, human, data, and processes, which render it as an inhomogeneous large-scale network. A crucial challenge of such a network is to develop management, analysis, and optimization policies that besides utility-maximizer machines, also take irrational humans into account. We discuss several networking applications in which appropriate modeling of human decision-making is vital. We then provide a brief review of computational models of human decision-making. Based on one such model, we develop a solution for a task offloading problem in fog computing and we analyze the implications of including humans in the loop.",
        "DOI": "10.1109/MWC.001.2000250",
        "affiliation_name": "The University of Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Socio-ecological drivers of vertebrate biodiversity and human-animal interfaces across an urban landscape",
        "paper_author": "Hassell J.M.",
        "publication": "Global Change Biology",
        "citied_by": "17",
        "cover_date": "2021-02-01",
        "Abstract": "Urbanization can have profound impacts on the distributional ecology of wildlife and livestock, with implications for biodiversity conservation, ecosystem services and human health. A wealth of studies have assessed biotic responses to urbanization in North America and Europe, but there is little empirical evidence that directly links human activities to urban biodiversity in the tropics. Results from a large-scale field study conducted in Nairobi, Kenya, are used to explore the impact of human activities on the biodiversity of wildlife and livestock with which humans co-exist across the city. The structure of sympatric wildlife, livestock and human populations are characterized using unsupervised machine learning, and statistical modelling is used to relate compositional variation in these communities to socio-ecological drivers occurring across the city. By characterizing landscape-scale drivers acting on these interfaces, we demonstrate that socioeconomics, elevation and subsequent changes in habitat have measurable impacts upon the diversity, density and species assemblage of wildlife, livestock and humans. Restructuring of wildlife and livestock assemblages (both in terms of species diversity and composition) has important implications for the emergence of novel diseases at urban interfaces, and we therefore use our results to generate a set of testable hypotheses that explore the influence of urban change on microbial communities. These results provide novel insight into the impact of urbanization on biodiversity in the tropics. An understanding of associations between urban processes and the structure of human and animal populations is required to link urban development to conservation efforts and risks posed by disease emergence to human health, ultimately informing sustainable urban development policy.",
        "DOI": "10.1111/gcb.15412",
        "affiliation_name": "Edinburgh Medical School",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Building footprint-derived landscape metrics for the identification of informal subdivisions and manufactured home communities: A pilot application in Hidalgo County, Texas",
        "paper_author": "Durst N.J.",
        "publication": "Land Use Policy",
        "citied_by": "9",
        "cover_date": "2021-02-01",
        "Abstract": "Informal subdivisions and manufactured home communities make up a substantial share of the United States’ housing stock but receive relatively little attention in the scholarly literature. The time-intensive nature of identifying these often-invisible communities through the analysis of satellite imagery and property records limits their systematic study. What research does exist on these communities suggests that they are often exposed to concentrated forms of economic, social, and environmental vulnerability. This paper uses big data to develop building footprint-derived landscape metrics capable of identifying and distinguishing between informal subdivisions and manufactured home communities based on their morphology. We use a data set of building footprints developed by Microsoft and released publicly in 2018 to measure the size, type, orientation, placement, and uniformity of housing in more than 2000 residential neighborhoods Hidalgo County, Texas, where more than 1000 informal subdivisions have been documented by prior research. Support vector machines (SVMs) and cross-validation are used to test the ability of these metrics to distinguish between three neighborhood types: informal subdivisions, manufactured housing communities, and formal subdivisions (or traditionally planned neighborhoods). Our models can accurately classify these three types of community approximately 91 % of the time. We then examine whether there is evidence to support the further disaggregation of these types of neighborhood, as is the case in both policy and scholarship. Our analysis of the morphology of these communities points to little evidence for the current distinction in state and federal law between pre- and post-1990 informal subdivisions; we do, however, find evidence for the need to distinguish between manufactured home communities with distinct tenure arrangements: namely, land-lease communities that we call manufactured home parks and land-owner communities that we call manufactured home subdivisions. We conclude by offering new research directions made possible by this novel identification method.",
        "DOI": "10.1016/j.landusepol.2020.105158",
        "affiliation_name": "The World Bank, USA",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Modeling the economic and environmental effects of corn nitrogen management strategies in Illinois",
        "paper_author": "Mandrini G.",
        "publication": "Field Crops Research",
        "citied_by": "16",
        "cover_date": "2021-02-01",
        "Abstract": "Eco-efficient use of nitrogen (N) fertilizer in Corn (Zea Mays L.) requires timely information about the supply of N from the soil and the response to N by the crop. These are complex processes, and multiple N management strategies (NMS) have been proposed over time. In this work, we used APSIM (Agricultural Production Systems sIMulator) to simulate the response of Corn's Yield to N for ca. 4200 fields in the state of Illinois in different weather scenarios. Ten different N management strategies were evaluated using environmental and economic indicators. They were created by combining different sources of trial data, different types of prediction models, different predictor variables measured on the fields, and different technologies to apply fertilizer in the field. This study provides knowledge that is unattainable through field experimentation, leveraging current knowledge on the mechanisms that drive the yield response to N to help farmers, researchers, and policymakers to select strategies in line with their objectives. Our results showed that an N management strategy that incorporates year-to-year variability in the predictions and uses data from trials spread in the region achieved the highest eco-efficiency. Such strategy would reduce the mean N-leaching by 12.7% without changing profits compared with the N management strategy most used by extension services in the area. Nitrogen measurements obtained by soil sampling were the most important predictor and could not be replaced by other less laborious variables. Variable-rate technology did not provide significant economic or environmental value in the area.",
        "DOI": "10.1016/j.fcr.2020.108000",
        "affiliation_name": "University of Illinois Urbana-Champaign",
        "affiliation_city": "Urbana",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Services Trade Policies and Economic Integration: New Evidence for Developing Countries",
        "paper_author": "Hoekman B.",
        "publication": "World Trade Review",
        "citied_by": "5",
        "cover_date": "2021-02-01",
        "Abstract": "This paper applies machine learning to recreate to a high degree of accuracy the OECD's Services Trade Restrictiveness Index (STRI) to provide quantitative evidence on the restrictiveness of services policies in 2016 for a sample of developing countries, using regulatory data collected by the World Bank and WTO. Resulting estimates are used to extend the OECD STRI approach to 23 additional countries, producing what we term a Services Policy Index (SPI). Converting the SPI to ad valorem equivalent terms shows that services policies are typically much more restrictive than tariffs on imports of goods, in particular in professional services and telecommunications. The SPI has strong explanatory power for bilateral trade in services at the sectoral level, as well as for aggregate goods and services trade.",
        "DOI": "10.1017/S1474745620000439",
        "affiliation_name": "European University Institute, San Domenico di Fiesole",
        "affiliation_city": "San Domenico di Fiesole",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Spatiotemporal dynamics and exposure analysis of daily PM2.5 using a remote sensing-based machine learning model and multi-time meteorological parameters",
        "paper_author": "Chen B.",
        "publication": "Atmospheric Pollution Research",
        "citied_by": "5",
        "cover_date": "2021-02-01",
        "Abstract": "Identifying spatiotemporal characteristics of daily fine particulate matter (PM2.5) concentrations is essential for assessing air quality and understanding the environmental consequences of urbanization. More importantly, exposure analysis can provide basic information for appropriate decision making. This paper demonstrates an integrated method incorporating satellite-based aerosol optical depth, machine learning models and multi-time meteorological parameters to analyze spatiotemporal dynamics and exposure levels of daily PM2.5 in the economically developed Yangtze River Delta (YRD) from 2016 to 2018. Ten-fold cross validation (CV) was implemented to evaluate the model performance. Compared to the models with daily means of meteorological fields, the models with multi-time meteorological parameters had higher CV coefficient of determination (R2) and lower CV root mean square error (RMSE) values. The model with the best performance achieved sample- (site-) based CV R2 values of 0.88 (0.88) and RMSE values of 10.33 (10.35) μg/m3. The YRD region was seriously polluted (exceeding the World Health Organization Interim Targets-1 standard of 35 μg/m3) during our study period, especially in Jiangsu Province, but with an improving trend. The residents in Zhejiang Province suffered the least from exposure, with 39 days (4% of the total days) characterized as over polluted (daily average > 75 μg/m3) in our study period. Air pollution in Shanghai Municipality mitigated the most from 2016 to 2018. With the advantages of high-accuracy and high-resolution (daily and 0.01 ° × 0.01 ° resolutions), the proposed method can guide for environmental policy planning.",
        "DOI": "10.1016/j.apr.2020.10.005",
        "affiliation_name": "College of Environmental and Resource Sciences",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting access to healthful food retailers with machine learning",
        "paper_author": "Amin M.D.",
        "publication": "Food Policy",
        "citied_by": "34",
        "cover_date": "2021-02-01",
        "Abstract": "Many U.S. households lack access to healthful food and rely on inexpensive, processed food with low nutritional value. Surveying access to healthful food is costly and finding the factors that affect access remains convoluted owing to the multidimensional nature of socioeconomic variables. We utilize machine learning with census tract data to predict the modified Retail Food Environment Index (mRFEI), which refers to the percentage of healthful food retailers in a tract and agnostically extract the features of no access—corresponding to a “food desert” and low access—corresponding to a “food swamp.” Our model detects food deserts and food swamps with a prediction accuracy of 72% out of the sample. We find that food deserts and food swamps are intrinsically different and require separate policy attention. Food deserts are lightly populated rural tracts with low ethnic diversity, whereas swamps are predominantly small, densely populated, urban tracts, with more non-white residents who lack vehicle access. Overall access to healthful food retailers is mainly explained by population density, presence of black population, property value, and income. We also show that our model can be used to obtain sensible predictions of access to healthful food retailers for any U.S. census tract.",
        "DOI": "10.1016/j.foodpol.2020.101985",
        "affiliation_name": "Texas Tech University",
        "affiliation_city": "Lubbock",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Big data, machine learning and artificial intelligence: A neurologist's guide",
        "paper_author": "Auger S.D.",
        "publication": "Practical Neurology",
        "citied_by": "32",
        "cover_date": "2021-02-01",
        "Abstract": "Modern clinical practice requires the integration and interpretation of ever-expanding volumes of clinical data. There is, therefore, an imperative to develop efficient ways to process and understand these large amounts of data. Neurologists work to understand the function of biological neural networks, but artificial neural networks and other forms of machine learning algorithm are likely to be increasingly encountered in clinical practice. As their use increases, clinicians will need to understand the basic principles and common types of algorithm. We aim to provide a coherent introduction to this jargon-heavy subject and equip neurologists with the tools to understand, critically appraise and apply insights from this burgeoning field.",
        "DOI": "10.1136/practneurol-2020-002688",
        "affiliation_name": "Barts and The London School of Medicine and Dentistry",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Machine learning approach to understand regional disparity of residential solar adoption in Australia",
        "paper_author": "Lan H.",
        "publication": "Renewable and Sustainable Energy Reviews",
        "citied_by": "30",
        "cover_date": "2021-02-01",
        "Abstract": "Although Australia has been successful in increasing the total number of residential solar photovoltaic (PV) panels, the disparity of PV adoption among regions has raised concerns about energy justice. To understand the regional difference of PV adoption in relation to the socioeconomic variance, this research introduced a machine learning approach, selected the Conditional Inference Trees algorithm and examined the residential PV installations in 2658 postcode areas covering six states of Australia. The study identified 18 scenarios based on 11 socioeconomic factors that explained the regional difference of residential PV adoption rate. A simple scenario was found for the region with a low density of population where the sparse population distribution is unadventurous for promoting PV among households and the PV adoption rate was reasonably low. The scenario became complex for the region with a high density of population, especially where the high density concurs with a high income; the concurrence was associated with many apartments and consequently a low adoption rate due to the lack of rooftop space. The most complex scenario was found for the region with a medium density of population where more socioeconomic factors interplayed and conditioned each other to explain the PV adoption variance. Generally, a high adoption rate was found for the region with a medium density of population and housing and a middle level of income. The complexity of the socioeconomic factors for explaining the regional difference of PV adoption should be addressed in search of more sophisticated energy policies.",
        "DOI": "10.1016/j.rser.2020.110458",
        "affiliation_name": "Griffith University",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "PAC-Bayes control: learning policies that provably generalize to novel environments",
        "paper_author": "Majumdar A.",
        "publication": "International Journal of Robotics Research",
        "citied_by": "17",
        "cover_date": "2021-02-01",
        "Abstract": "Our goal is to learn control policies for robots that provably generalize well to novel environments given a dataset of example environments. The key technical idea behind our approach is to leverage tools from generalization theory in machine learning by exploiting a precise analogy (which we present in the form of a reduction) between generalization of control policies to novel environments and generalization of hypotheses in the supervised learning setting. In particular, we utilize the probably approximately correct (PAC)-Bayes framework, which allows us to obtain upper bounds that hold with high probability on the expected cost of (stochastic) control policies across novel environments. We propose policy learning algorithms that explicitly seek to minimize this upper bound. The corresponding optimization problem can be solved using convex optimization (relative entropy programming in particular) in the setting where we are optimizing over a finite policy space. In the more general setting of continuously parameterized policies (e.g., neural network policies), we minimize this upper bound using stochastic gradient descent. We present simulated results of our approach applied to learning (1) reactive obstacle avoidance policies and (2) neural network-based grasping policies. We also present hardware results for the Parrot Swing drone navigating through different obstacle environments. Our examples demonstrate the potential of our approach to provide strong generalization guarantees for robotic systems with continuous state and action spaces, complicated (e.g., nonlinear) dynamics, rich sensory inputs (e.g., depth images), and neural network-based policies.",
        "DOI": "10.1177/0278364920959444",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Hypotheses, machine learning and soil mapping",
        "paper_author": "Wadoux A.M.J.C.",
        "publication": "Geoderma",
        "citied_by": "23",
        "cover_date": "2021-02-01",
        "Abstract": "Hypotheses are of major importance in scientific research. In current applications of machine learning algorithms for soil mapping the hypotheses being tested or developed are often ambiguous or undefined. Mapping soil properties or classes, however, does not tell much about the dynamics and processes that underly soil genesis and evolution. When the interest in the soil map is for applications in a context different than soil science, such as for policy making or baseline production of quantitative soil information, the interpretation should be made in light of this application. If otherwise, we recommend soil scientists to provide hypotheses to accompany their research. The hypothesis is formulated at the beginning of the research and, in some cases, motivates data collection. Here we argue that when applying data-driven techniques such as machine learning, developing hypotheses can be a useful end point of the research. The spatial pattern predicted by the machine learning model and the correlation found among the covariates are an opportunity to develop hypotheses which are likely to require additional analyses and datasets to be tested. Systematically providing scientific hypotheses in digital soil mapping studies will enable the soil science community to build on previous work, and to increase the credibility of data-driven algorithms as a means to accelerate discovery on soil processes.",
        "DOI": "10.1016/j.geoderma.2020.114725",
        "affiliation_name": "The University of Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A hybrid method of genetic algorithm and support vector machine for intrusion detection",
        "paper_author": "Tally M.T.",
        "publication": "International Journal of Electrical and Computer Engineering",
        "citied_by": "9",
        "cover_date": "2021-02-01",
        "Abstract": "With the development of web applications nowadays, intrusions represent a crucial aspect in terms of violating the security policies. Intrusions can be defined as a specific change in the normal behavior of the network operations that intended to violate the security policies of a particular network and affect its performance. Recently, several researchers have examined the capabilities of machine learning techniques in terms of detecting intrusions. One of the important issues behind using the machine learning techniques lies on employing proper set of features. Since the literature has shown diversity of feature types, there is a vital demand to apply a feature selection approach in order to identify the most appropriate features for intrusion detection. This study aims to propose a hybrid method of genetic algorithm and support vector machine. GA has been as a feature selection in order to select the best features, while SVM has been used as a classification method to categorize the behavior into normal and intrusion based on the selected features from GA. A benchmark dataset of intrusions (NSS-KDD) has been in the experiment. In addition, the proposed method has been compared with the traditional SVM. Results showed that GA has significantly improved the SVM classification by achieving 0.927 of f-measure.",
        "DOI": "10.11591/ijece.v11i1.pp900-908",
        "affiliation_name": "Ferdowsi University of Mashhad",
        "affiliation_city": "Mashhad",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Natural object manipulation using anthropomorphic robotic hand through deep reinforcement learning and deep grasping probability network",
        "paper_author": "Valarezo Añazco E.",
        "publication": "Applied Intelligence",
        "citied_by": "19",
        "cover_date": "2021-02-01",
        "Abstract": "Human hands can perform complex manipulation of various objects. It is beneficial if anthropomorphic robotic hands can manipulate objects like human hands. However, it is still a challenge due to the high dimensionality and a lack of machine intelligence. In this work, we propose a novel framework based on Deep Reinforcement Learning (DRL) with Deep Grasping Probability Network (DGPN) to grasp and relocate various objects with an anthropomorphic robotic hand much like a human hand. DGPN is used to predict the probability of successful human-like natural grasping based on the priors of human grasping hand poses and object touch areas. Thus, our DRL with DGPN rewards natural grasping hand poses according to object geometry for successful human-like manipulation of objects. The proposed DRL with DGPN is evaluated by grasping and relocating five objects including apple, light bulb, cup, bottle, and can. The performance of our DRL with DGPN is compared with the standard DRL without DGPN. The results show that the standard DRL only achieves an average success rate of 22.60%, whereas our DRL with DGPN achieves 89.40% for the grasping and relocation tasks of the objects.",
        "DOI": "10.1007/s10489-020-01870-6",
        "affiliation_name": "Kyung Hee University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Applying deep neural networks for user intention identification",
        "paper_author": "Khattak A.",
        "publication": "Soft Computing",
        "citied_by": "23",
        "cover_date": "2021-02-01",
        "Abstract": "The social media revolution has provided the online community an opportunity and facility to communicate their views, opinions and intentions about events, policies, services and products. The intent identification aims at detecting intents from user reviews, i.e., whether a given user review contains intention or not. The intent identification, also called intent mining, assists business organizations in identifying user’s purchase intentions. The prior works have focused on using only the CNN model to perform the feature extraction without retaining the sequence correlation. Moreover, many recent studies have applied classical feature representation techniques followed by a machine learning classifier. We examine the intention review identification problem using a deep learning model with an emphasis on maintaining the sequence correlation and also to retain information for a long time span. The proposed method consists of the convolutional neural network along with long short-term memory for efficient detection of intention in a given review, i.e., whether the review is an intent vs non-intent. The experimental results depict that the performance of the proposed system is better with respect to the baseline techniques with an accuracy of 92% for Dataset1 and 94% for Dataset2. Moreover, statistical analysis also depicts the effectiveness of the proposed method with respect to the comparing methods.",
        "DOI": "10.1007/s00500-020-05290-z",
        "affiliation_name": "National University of Modern Languages",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Understanding public perception of coronavirus disease 2019 (COVID-19) social distancing on Twitter",
        "paper_author": "Saleh S.N.",
        "publication": "Infection Control and Hospital Epidemiology",
        "citied_by": "61",
        "cover_date": "2021-02-01",
        "Abstract": "Objective: Social distancing policies are key in curtailing severe acute respiratory coronavirus virus 2 (SARS-CoV-2) spread, but their effectiveness is heavily contingent on public understanding and collective adherence. We studied public perception of social distancing through organic, large-scale discussion on Twitter. Design: Retrospective cross-sectional study. Methods: Between March 27 and April 10, 2020, we retrieved English-only tweets matching two trending social distancing hashtags, #socialdistancing and #stayathome. We analyzed the tweets using natural language processing and machine-learning models, and we conducted a sentiment analysis to identify emotions and polarity. We evaluated the subjectivity of tweets and estimated the frequency of discussion of social distancing rules. We then identified clusters of discussion using topic modeling and associated sentiments. Results: We studied a sample of 574,903 tweets. For both hashtags, polarity was positive (mean, 0.148; SD, 0.290); only 15% of tweets had negative polarity. Tweets were more likely to be objective (median, 0.40; IQR, 0-0.6) with ~30% of tweets labeled as completely objective (labeled as 0 in range from 0 to 1). Approximately half of tweets (50.4%) primarily expressed joy and one-fifth expressed fear and surprise. Each correlated well with topic clusters identified by frequency including leisure and community support (ie, joy), concerns about food insecurity and quarantine effects (ie, fear), and unpredictability of coronavirus disease 2019 (COVID-19) and its implications (ie, surprise). Conclusions: Considering the positive sentiment, preponderance of objective tweets, and topics supporting coping mechanisms, we concluded that Twitter users generally supported social distancing in the early stages of their implementation.",
        "DOI": "10.1017/ice.2020.406",
        "affiliation_name": "UT Southwestern Medical Center",
        "affiliation_city": "Dallas",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "TacticToe: Learning to Prove with Tactics",
        "paper_author": "Gauthier T.",
        "publication": "Journal of Automated Reasoning",
        "citied_by": "34",
        "cover_date": "2021-02-01",
        "Abstract": "We implement an automated tactical prover TacticToe on top of the HOL4 interactive theorem prover. TacticToe learns from human proofs which mathematical technique is suitable in each proof situation. This knowledge is then used in a Monte Carlo tree search algorithm to explore promising tactic-level proof paths. On a single CPU, with a time limit of 60 s, TacticToe proves 66.4% of the 7164 theorems in HOL4’s standard library, whereas E prover with auto-schedule solves 34.5%. The success rate rises to 69.0% by combining the results of TacticToe and E prover.",
        "DOI": "10.1007/s10817-020-09580-x",
        "affiliation_name": "Commonwealth Scientific and Industrial Research Organisation",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Decentralized Automotive Radar Spectrum Allocation to Avoid Mutual Interference Using Reinforcement Learning",
        "paper_author": "Liu P.",
        "publication": "IEEE Transactions on Aerospace and Electronic Systems",
        "citied_by": "46",
        "cover_date": "2021-02-01",
        "Abstract": "Nowadays, mutual interference among automotive radars has become a problem of wide concern. In this article, a decentralized spectrum allocation approach is presented to avoid mutual interference among automotive radars. Although decentralized spectrum allocation has been extensively studied in cognitive radio sensor networks, two challenges are observed for automotive sensors using radar. First, the allocation approach should be dynamic as all radars are mounted on moving vehicles. Second, each radar does not communicate with the others so it has quite limited information. A machine learning technique, reinforcement learning, is utilized because it can learn a decision-making policy in an unknown dynamic environment. As a single radar observation is incomplete, a long short-term memory recurrent network is used to aggregate radar observations through time so that each radar can learn to choose a frequency subband by combining both the present and past observations. Simulation experiments are conducted to compare the proposed approach with other common spectrum allocation methods such as the random and myopic policy, indicating that our approach outperforms the others.",
        "DOI": "10.1109/TAES.2020.3011869",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Asynchronous Episodic Deep Deterministic Policy Gradient: Toward Continuous Control in Computationally Complex Environments",
        "paper_author": "Zhang Z.",
        "publication": "IEEE Transactions on Cybernetics",
        "citied_by": "51",
        "cover_date": "2021-02-01",
        "Abstract": "Deep deterministic policy gradient (DDPG) has been proved to be a successful reinforcement learning (RL) algorithm for continuous control tasks. However, DDPG still suffers from data insufficiency and training inefficiency, especially, in computationally complex environments. In this article, we propose asynchronous episodic DDPG (AE-DDPG), as an expansion of DDPG, which can achieve more effective learning with less training time required. First, we design a modified scheme for data collection in an asynchronous fashion. Generally, for asynchronous RL algorithms, sample efficiency or/and training stability diminish as the degree of parallelism increases. We consider this problem from the perspectives of both data generation and data utilization. In detail, we redesign experience replay by introducing the idea of episodic control so that the agent can latch on good trajectories rapidly. In addition, we also inject a new type of noise in action space to enrich the exploration behaviors. Experiments demonstrate that our AE-DDPG achieves higher rewards and requires less time consumption than most popular RL algorithms in learning to run task which has a computationally complex environment. Not limited to the control tasks in the computationally complex environments, AE-DDPG also achieves higher rewards and two-fold to four-fold improvement in sample efficiency on average compared with other variants of DDPG in MuJoCo environments. Furthermore, we verify the effectiveness of each proposed technique component through abundant ablation study.",
        "DOI": "10.1109/TCYB.2019.2939174",
        "affiliation_name": "University of Science and Technology of China",
        "affiliation_city": "Hefei",
        "affiliation_country": "China"
    },
    {
        "paper_title": "TriDroid: a triage and classification framework for fast detection of mobile threats in android markets",
        "paper_author": "Amira A.",
        "publication": "Journal of Ambient Intelligence and Humanized Computing",
        "citied_by": "10",
        "cover_date": "2021-02-01",
        "Abstract": "The Android platform is highly targeted by malware developers, which aim to infect the maximum number of mobile devices by uploading their malicious applications to different app markets. In order to keep a healthy Android ecosystem, app-markets check the maliciousness of newly submitted apps. These markets need to (a) correctly detect malicious app, and (b) speed up the detection process of the most likely dangerous applications among an overwhelming flow of submitted apps, to quickly mitigate their potential damages. To address these challenges, we propose TriDroid, a market-scale triage and classification system for Android apps. TriDroid prioritizes apps analysis according to their risk likelihood. To this end, we categorize the submitted apps as: botnet, general malware, and benign. TriDroid starts by performing a (1) Triage process, which applies a fast coarse-grained and less-accurate analysis on a continuous stream of the submitted apps to identify their corresponding queue in a three-class priority queuing system. Then, (2) the Classification process extracts fine-grained static features from the apps in the priority queue, and applies three-class machine learning classifiers to confirm with high accuracy the classification decisions of the triage process. In addition to the priority queuing model, we also propose a multi-server queuing model where the classification of each app category is run on a different server. Experiments on a dataset with more than 24K malicious and 3K benign applications show that the priority model offers a trade-off between waiting time and processing overhead, as it requires only one server compared to the multi-server model. Also it successfully prioritizes malicious apps analysis, which allows a short waiting time for dangerous applications compared to the FIFO policy.",
        "DOI": "10.1007/s12652-020-02243-0",
        "affiliation_name": "Centre de Recherche sur l'Information Scientifique et Technique",
        "affiliation_city": "Ben Aknoun",
        "affiliation_country": "Algeria"
    },
    {
        "paper_title": "The Effect of Medicaid Expansion on the Nature of New Enrollees’ Emergency Department Use",
        "paper_author": "Ladhania R.",
        "publication": "Medical Care Research and Review",
        "citied_by": "12",
        "cover_date": "2021-02-01",
        "Abstract": "We examine changes in emergency department (ED) visit acuity and care intensity for uninsured patients who gained Medicaid insurance in 2014 under the Patient Protection and Affordable Care Act. We use 2013-2015 longitudinal patient visit-level data from 30 EDs across 7 states from an emergency medicine group. We examine changes in ED use by previously uninsured Medicaid patients and patients remaining uninsured who were repeat ED users (≥1 visit before and after expansion) using a propensity-score weighted approach with statistical machine learning to estimate the weights. Compared with those remaining uninsured in nonexpansion states, newly covered Medicaid patients in expansion states showed a 29% relative increase in hospital admissions and 32% increase in admissions for nonambulatory care sensitive conditions with no increases in care intensity. Obtaining Medicaid insurance increased the relative proportion of ED visits requiring hospital admission suggesting increased outpatient access for low-acuity conditions previously addressed with ED care.",
        "DOI": "10.1177/1077558719848270",
        "affiliation_name": "West Penn Allegheny Health System",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Detection and prevention of cross-site scripting attack with combined approaches",
        "paper_author": "Chen H.C.",
        "publication": "2021 International Conference on Electronics, Information, and Communication, ICEIC 2021",
        "citied_by": "12",
        "cover_date": "2021-01-31",
        "Abstract": "Cross-site scripting (XSS) attack is a kind of code injection that allows an attacker to inject malicious scripts code into a trusted web application. When a user tries to request the injected web page, he is not aware that the malicious script code might be affecting his computer. Nowadays, attackers are targeting the web applications that holding a sensitive data (e.g., bank transaction, e-mails, healthcare, and e-banking) to steal users' information and gain full access to the data which make the web applications to be more vulnerable. In this research, we applied three approaches to find a solution to this most challenging attacks issues. In the first approach, we implemented Random Forest (RF), Logistic Regression (LR), k-Nearest Neighbors (k-NN), and Support Vector Machine (SVM) algorithms to discover and classify XSS attack. In the second approach, we implemented the Content Security Policy (CSP) approach to detect XSS attacks in real-time. In the last approach, we propose a new approach that combines the Web Application Firewall (WAF), Intrusion Detection System (IDS), and Intrusion Prevention System (IPS) to detect and prevent XSS attack in real-time. Our experiment results demonstrated the high performance of AI algorithms. The CSP approach shows the results for the detection system report in real-time. In the third approach, we got more expected system results that make our third model system a more powerful tool to address this research problem than the other two approaches.",
        "DOI": "10.1109/ICEIC51217.2021.9369796",
        "affiliation_name": "Universitas Muhammadiyah Yogyakarta",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Globalisation from within: Enhancing digital productivity and technology transformation in the South",
        "paper_author": "Dunn H.S.",
        "publication": "Re-imagining Communication in Africa and the Caribbean: Global South Issues in Media, Culture and Technology",
        "citied_by": "1",
        "cover_date": "2021-01-30",
        "Abstract": "This chapter argues that in an era of smart technology, emerging robotics, machine learning and neural networks, countries of the Global South must re-evaluate how creative processes, economic outputs and education are to be managed to achieve greater digital productivity. New process tools such as those enlisted under the 'Fourth Industrial Revolution' require new thinking on how we get things done. Digital productivity is inextricably linked to human creativity as well as to new techno-industrial contexts in which corporate enterprises, governments and educational institutions must now more actively incorporate innovation. Central to this needed transformational process for many developing countries is the necessity for more strategic policy-making, including use of a deliberate human development strategy proposed here as 'Globalisation from Within'.",
        "DOI": "10.1007/978-3-030-54169-9_3",
        "affiliation_name": "University of Botswana",
        "affiliation_city": "Gaborone",
        "affiliation_country": "Botswana"
    },
    {
        "paper_title": "A Black-Box Adversarial Attack via Deep Reinforcement Learning on the Feature Space",
        "paper_author": "Li L.",
        "publication": "2021 IEEE Conference on Dependable and Secure Computing, DSC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-30",
        "Abstract": "In this paper we propose a novel black-box adversarial attack by using the reinforcement learning to learn the characteristics of the target classifier C. Our method does not need to find a substitute classifier that resembles C with respect to its structure and parameters. Instead, our method learns an optimal attacking policy of guiding the attacker to build an adversarial image from the original image. We work on the feature space of images, instead of the pixels of images directly. Our method achieves better results on many measures. Our method achieves 94.5 % attack success rate on a well-Trained digit classifier. Our adversarial images have better imperceptibility even though the norm distances to original images are larger than other methods. Since our method works on the characteristics of a classifier, it has better transferability. The transfer rate of our method could reach 52.1 % for a targeted class and 65.9% for a non-Targeted class. This improves over previous results of single-digit transfer rates. Also, we show that it is harder to defend our attack by incorporating defense mechanisms, such as MagNet, which uses a denoising technique. We show that our method achieves 65% attack success rate even though the target classifier employs MagNet to defend.",
        "DOI": "10.1109/DSC49826.2021.9346264",
        "affiliation_name": "National Chiao Tung University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Software-in-the-Loop Combined Reinforcement Learning Method for Dynamic Response Analysis of FOWTs",
        "paper_author": "Chen P.",
        "publication": "Frontiers in Marine Science",
        "citied_by": "17",
        "cover_date": "2021-01-28",
        "Abstract": "Floating offshore wind turbines (FOWTs) still face many challenges on how to better predict the dynamic responses. Artificial intelligence (AI) brings a new solution to overcome these challenges with intelligent strategies. A new AI technology-based method, named SADA, is proposed in this paper for the prediction of dynamic responses of FOWTs. Firstly, the methodology of SADA is introduced with the selection of Key Disciplinary Parameters (KDPs). The AI module in SADA was built in a coupled aero-hydro-servo-elastic in-house program DARwind and the policy decision is provided by the machine learning algorithms deep deterministic policy gradient (DDPG). Secondly, a set of basin experimental results of a Hywind Spar-type FOWT were employed to train the AI module. SADA weights KDPs by DDPG algorithms' actor network and changes their values according to the training feedback of 6DOF motions of Hywind platform through comparing the DARwind simulation results and that of experimental data. Many other dynamic responses that cannot be measured in basin experiment could be predicted in higher accuracy with this intelligent DARwind. Finally, the case study of SADA method was conducted and the results demonstrated that the mean values of the platform's motions can be predicted by AI-based DARwind with higher accuracy, for example the maximum error of surge motion is reduced by 21%. This proposed SADA method takes advantage of numerical-experimental method and the machine learning method, which brings a new and promising solution for overcoming the handicap impeding direct use of traditional basin experimental technology in FOWTs design.",
        "DOI": "10.3389/fmars.2020.628225",
        "affiliation_name": "Newcastle University",
        "affiliation_city": "Newcastle",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Monitoring hiring discrimination through online recruitment platforms",
        "paper_author": "Hangartner D.",
        "publication": "Nature",
        "citied_by": "50",
        "cover_date": "2021-01-28",
        "Abstract": "Women (compared to men) and individuals from minority ethnic groups (compared to the majority group) face unfavourable labour market outcomes in many economies1,2, but the extent to which discrimination is responsible for these effects, and the channels through which they occur, remain unclear3,4. Although correspondence tests5—in which researchers send fictitious CVs that are identical except for the randomized minority trait to be tested (for example, names that are deemed to sound ‘Black’ versus those deemed to sound ‘white’)—are an increasingly popular method to quantify discrimination in hiring practices6,7, they can usually consider only a few applicant characteristics in select occupations at a particular point in time. To overcome these limitations, here we develop an approach to investigate hiring discrimination that combines tracking of the search behaviour of recruiters on employment websites and supervised machine learning to control for all relevant jobseeker characteristics that are visible to recruiters. We apply this methodology to the online recruitment platform of the Swiss public employment service and find that rates of contact by recruiters are 4–19% lower for individuals from immigrant and minority ethnic groups, depending on their country of origin, than for citizens from the majority group. Women experience a penalty of 7% in professions that are dominated by men, and the opposite pattern emerges for men in professions that are dominated by women. We find no evidence that recruiters spend less time evaluating the profiles of individuals from minority ethnic groups. Our methodology provides a widely applicable, non-intrusive and cost-efficient tool that researchers and policy-makers can use to continuously monitor hiring discrimination, to identify some of the drivers of discrimination and to inform approaches to counter it.",
        "DOI": "10.1038/s41586-020-03136-0",
        "affiliation_name": "Konjunkturforschungsstelle",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Deep belief network and sentimental analysis for extracting on multi-variable features to predict stock market performance and accuracy",
        "paper_author": "Saitulasi K.",
        "publication": "2021 International Conference on Computer Communication and Informatics, ICCCI 2021",
        "citied_by": "25",
        "cover_date": "2021-01-27",
        "Abstract": "Deep Learning shows a drastic growth in many fields such as medical, voice recognitions, Siri Alexa and computer vision, so on. Even though machine learning and deep learning are developing point in data science the back bone for all these platforms are Big data Analytics. A massive data and information’s from all the website, social media and other networks produced so called Big data are focused in day to day life. When these information are collected from the various chat history such as Whatsapp, Facebook, Twitter and other for generating numerous development such as privacy policy, investing, stock markets, business, study process and many more. Professional involvement deals the deep learning concept to focus on the stock market procedure in particular to develop the Business enterprise, individual profits, product strategies and other decision making process also. However the main gap to be filled in this prediction was to look around the internet sources as well as real time population for stock market varies its accuracy due to the lack of hidden layer interaction. Here we propose a deep learning accuracy prediction named as sentimental analysis to perform an accuracy in a best way by applying Bi-directional long-short term memory (Bi-LSTM) and Deep belief network to overcome the issues and less accuracy given by doc2vec, long-short term memory (LSTM) and provides a good model for our sentimental Bi-LSTM model to find the best stock market analysis.",
        "DOI": "10.1109/ICCCI50826.2021.9456999",
        "affiliation_name": "Saveetha School of Engineering",
        "affiliation_city": "Chennai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Evaluation of risk analysis process in medical big data using Machine Learning",
        "paper_author": "Rajeshkumar K.",
        "publication": "2021 International Conference on Computer Communication and Informatics, ICCCI 2021",
        "citied_by": "0",
        "cover_date": "2021-01-27",
        "Abstract": "The ultimate aim of this review is to evolve the security privacy to the patient's information in medical organizations. The privacy of the user's information should be kept in secured manner from unauthorized users in medical big data. Whenever the personal information of the patient is leaked, that could damage the patient's reputations and also bring down the ethical value of medical organizations. So it has become imperative to establish medical service with secured mechanism and improve the risk prevention measures and privacy ensured strictly. It is mandatory that the medical organizations management policies should provide the required guarantee to the users.",
        "DOI": "10.1109/ICCCI50826.2021.9402607",
        "affiliation_name": "Theni Kammavar Sangam College of Technology",
        "affiliation_city": "Veerapand",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Performance and Predicting of Inbound Logistics Processes Using Machine Learning",
        "paper_author": "Albadrani A.",
        "publication": "2021 IEEE 11th Annual Computing and Communication Workshop and Conference, CCWC 2021",
        "citied_by": "5",
        "cover_date": "2021-01-27",
        "Abstract": "Manufacturing is changing quickly in parallel with market trends. Precise forecasting is critical for suppliers, impacting the worldwide supply chain network-a range of products derived from various sources and places in manufacturing plants in inbound logistics. Planning these inbound logistics depends on inventory readiness, plant planning, sourcing, and knowledge (continuously evolving). This paper focuses on machine learning algorithms such as K-nearest neighbors (KNN), Random Forests, Support Vector Machine (SVM) to improve the planning of inbound logistics systems. The presented algorithms track and train consumer preferences, policies, and other complex planning considerations in the planning process, such as time, strategy, and network design. In the planning process, half the time is spent preparing and collecting data, while the gained experience is not utilized efficiently. Therefore, designing potential inbound logistics processes are addressed using machine learning algorithms such as KNN, random forests, and SVM.",
        "DOI": "10.1109/CCWC51732.2021.9376171",
        "affiliation_name": "School of Engineering and Computer Science",
        "affiliation_city": "Rochester",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application of machine learning metrics for dynamic E-justice processes",
        "paper_author": "Metsker O.",
        "publication": "Conference of Open Innovation Association, FRUCT",
        "citied_by": "3",
        "cover_date": "2021-01-27",
        "Abstract": "Decision support systems (DSS) in law enforcement have a long history. Starting from the late 50s, they have been developed through several architectural approaches. Still, having a proven capability of DSSes to improve legal practice, the real-world application is limited due to multiple issues, including lack of trust, interpretability, validity, scalability, etc. The paper develops a service based decision support platform for machine learning applications for eGovernance and internal policy modelling and presents a case study of the application of the platform for the case of migration law enforcement. The artificial intelligence core of the platform was built upon a knowledge base, which includes machine learning models and methods. In this work we have developed a method of structuring, analysis of legal data models based on machine learning. In the course of computational experiment, the efficiency of the developed method was proved and the interpretation of the obtained results was performed to provide recommendations for the enhancement of administrative regulation.",
        "DOI": "10.23919/FRUCT50888.2021.9347598",
        "affiliation_name": "All-Russian State University of Justice",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Coronavirus exacerbates xenophobia: Consciousness of Twitter posting during the pandemic",
        "paper_author": "Zamri N.A.K.",
        "publication": "SEARCH Journal of Media and Communication Research",
        "citied_by": "1",
        "cover_date": "2021-01-24",
        "Abstract": "Free speech is not a license for racists to spread propaganda. However, the outbreak of COVID-19 and its subsequent spread across the globe has left a shocking wave of disbelief resulting in an upsurge of xenophobia in the society. Racism is a system of dominance and power designed to uphold the racially privileged. This study delves into the consciousness of Twitter postings during the COVID-19 pandemic and deconstructs the power dynamics in the hashtags used. The study’s data was analysed using Twitter Application Programming Interface (API) to identify the representation within tweet sample sets. The study concludes that social interactions on Twitter constructs power dynamics and these shared values create a new form of power resistance and subjugated knowledge. This leads to a discussion of power between social media intertwined with the machine learning tools in social science and humanities studies. This study contributes to the academic debates about the public sphere and social media's role in constructing meaning in cultural and social change. It also suggests that Twitter develops policies to prohibit hate speech and impose regulations to ensure that online spaces remain civil, safe, and democratic.",
        "DOI": "NA",
        "affiliation_name": "UiTM Kampus Alor Gajah",
        "affiliation_city": "Alor Gajah",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Implementing Predictive Model for Low Birth Weight in Afghanistan",
        "paper_author": "Zahirzada A.",
        "publication": "KST 2021 - 2021 13th International Conference Knowledge and Smart Technology",
        "citied_by": "10",
        "cover_date": "2021-01-21",
        "Abstract": "Birth weight is a significant determinant of the likelihood of survival of an infant. Low Birth Weight (LBW) has become an increasingly common problem, especially in developing and underdeveloped countries. Therefore, an ability to predict the LBW is beneficial and a good preventive measure. It is also a good indicator of future health risks of that infant. This study is concerned about the implementation of predictive LBW models for rural and urban areas of Afghanistan based on the data obtained from the Afghanistan Demographic and Health Survey 2015. The main objective of the study is to identify the most suitable machine learning techniques (i.e. classifiers) among the five popular ones. These are K-Nearest Neighbor (K-NN), Naïve Bayes, Neural Network, Random Forest, and Support Vector Machine (SVM). Prior to implementing the predictive models, data preprocessing is carried out. This is done by means of data cleansing and feature selection. The well-known Correlation based Feature Selection algorithm (CFS) is employed to select the top ten attributes. The classifier in this study comprises two categories, Normal and LBW. The preparation of the dataset is carefully done to ensure well-balanced samples in each category. The study reveals that Random Forest is the best classifier with an accuracy of 84.70% and 85.2% and with the Area Under the Curve (AUC) of 91.0% and 92.1% for both rural and urban areas, respectively. The study has a direct benefit to the health and prevention policy making in Afghanistan.",
        "DOI": "10.1109/KST51265.2021.9415792",
        "affiliation_name": "King Mongkut's University of Technology Thonburi",
        "affiliation_city": "Bangkok",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Curiosity-Driven Reinforced Learning of Undesired Actions in Autonomous Intelligent Agents",
        "paper_author": "Rosser C.",
        "publication": "SAMI 2021 - IEEE 19th World Symposium on Applied Machine Intelligence and Informatics, Proceedings",
        "citied_by": "4",
        "cover_date": "2021-01-21",
        "Abstract": "Autonomous exploring agents are encouraged to explore unknown states in an environment when equipped with an intrinsic motivating factor such as curiosity. Although intrinsic motivation is a useful mechanism for an autonomous exploring agent in an environment that provides sparse rewards, it doubles as a mechanism for causing the agents to act in undesirable ways. In this paper, we show that highly-curious agents, attached with neural networks trained with the Machine Learning Agent Toolkit's (ML-Agents) implementation of the Proximal Policy Optimization (PPO) algorithm, and Intrinsic Curiosity Module (ICM), learn undesirable or reckless behaviors relatively early in the training process. We also show that strong correlations in the PPO training statistics of misbehaving agents may indicate when an actual human should intervene for safety during the RL training process.",
        "DOI": "10.1109/SAMI50585.2021.9378666",
        "affiliation_name": "Jackson State University",
        "affiliation_city": "Jackson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application of Reinforcement Learning to a Mining System",
        "paper_author": "Fidencio A.X.",
        "publication": "SAMI 2021 - IEEE 19th World Symposium on Applied Machine Intelligence and Informatics, Proceedings",
        "citied_by": "4",
        "cover_date": "2021-01-21",
        "Abstract": "Automation techniques have been widely applied in different industry segments, among others, to increase both productivity and safety. In the mining industry, with the usage of such systems, the operator can be removed from hazardous environments without compromising task execution and it is possible to achieve more efficient and standardized operation. In this work a study case on the application of machine learning algorithms to a mining system example is presented, in which reinforcement learning algorithms were used to solve a control problem. As an example, a machine chain consisting of a Bucket Wheel Excavator, a Belt Wagon and a Hopper Car was used. This system has two material transfer points that need to remain aligned during operation in order to allow continuous material flow. To keep the alignment, the controller makes use of seven degrees of freedom given by slewing, luffing and crawler drives. Experimental tests were done in a simulated environment with two state-of-the-art algorithms, namely Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC). The trained agents were evaluated in terms of episode return and length, as well as alignment quality and action values used. Results show that, for the given task, the PPO agent performs quantitatively and qualitatively better than the SAC agent. However, none of the agents were able to completely solve the proposed testing task.",
        "DOI": "10.1109/SAMI50585.2021.9378663",
        "affiliation_name": "Technische Universität Dortmund",
        "affiliation_city": "Dortmund",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Research on Pricing Mechanism of Electricity Spot Market Based on Multi-agent Reinforcement Learning (Part I): Bi-level Optimization Model for Generators Under Different Pricing Mechanisms",
        "paper_author": "Tang C.",
        "publication": "Zhongguo Dianji Gongcheng Xuebao/Proceedings of the Chinese Society of Electrical Engineering",
        "citied_by": "42",
        "cover_date": "2021-01-20",
        "Abstract": "The pricing mechanism of electricity spot market is one of the key issues in market design, which interacts with the transaction behavior of generators. The design of pricing mechanism needs to consider possible transaction behavior of generators. However, bidding strategy of generators may vary a lot under different pricing mechanisms. To solve this nested problem systematically, two papers of different focuses were formed. As the first part, this paper discussed the applicability of reinforcement learning in bidding optimization of generators. Considering the two-stage process of system marginal price (SMP) and zonal marginal price (ZMP), the bi-level optimization models of generators under three kinds of pricing mechanisms of locational marginal price (LMP), SMP and ZMP were constructed. Then, a multi-agent reinforcement learning (MARL) method combining win or learn fast and policy hill-climbing (WoLF-PHC) algorithm was proposed to solve the model iteratively. In the bi-level models, bidding decision-making models of generators served as the upper layers, following with the market clearing model as lower layer. The interactive data were composed of the bidding information optimized by the decision-making layers and the market clearing information calculated by the clearing layer. The bidding strategies of generators were optimized through continuous interaction. Finally, taking IEEE 39 system as an example, four typical load scenarios were selected to optimize the bidding of generators under three pricing mechanisms. The results show that the proposed model and algorithm can effectively solve the optimal bidding strategy of generators and reach the market equilibrium results.",
        "DOI": "10.13334/j.0258-8013.pcsee.191550",
        "affiliation_name": "Shanghai University of Electric Power",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Time-resolved emission reductions for atmospheric chemistry modelling in Europe during the COVID-19 lockdowns",
        "paper_author": "Guevara M.",
        "publication": "Atmospheric Chemistry and Physics",
        "citied_by": "97",
        "cover_date": "2021-01-20",
        "Abstract": "We quantify the reductions in primary emissions due to the COVID-19 lockdowns in Europe. Our estimates are provided in the form of a dataset of reduction factors varying per country and day that will allow the modelling and identification of the associated impacts upon air quality. The country- and daily-resolved reduction factors are provided for each of the following source categories: energy industry (power plants), manufacturing industry, road traffic and aviation (landing and take-off cycle). We computed the reduction factors based on open-access and near-realtime measured activity data from a wide range of information sources. We also trained a machine learning model with meteorological data to derive weather-normalized electricity consumption reductions. The time period covered is from 21 February, when the first European localized lockdown was implemented in the region of Lombardy (Italy), until 26 April 2020. This period includes 5 weeks (23 March until 26 April) with the most severe and relatively unchanged restrictions upon mobility and socio-economic activities across Europe. The computed reduction factors were combined with the Copernicus Atmosphere Monitoring Service's European emission inventory using adjusted temporal emission profiles in order to derive time-resolved emission reductions per country and pollutant sector. During the most severe lockdown period, we estimate the average emission reductions to be -33 % for NOx, -8 % for non-methane volatile organic compounds (NMVOCs), -7 % for SOx and -7 % for PM2.5 at the EU-30 level (EU-28 plus Norway and Switzerland). For all pollutants more than 85 % of the total reduction is attributable to road transport, except SOx. The reductions reached -50 % (NOx), -14 % (NMVOCs), -12 % (SOx) and -15 % (PM2.5) in countries where the lockdown restrictions were more severe such as Italy, France or Spain. To show the potential for air quality modelling, we simulated and evaluated NO2 concentration decreases in rural and urban background regions across Europe (Italy, Spain, France, Germany, United-Kingdom and Sweden). We found the lockdown measures to be responsible for NO2 reductions of up to -58 % at urban background locations (Madrid, Spain) and -44 % at rural background areas (France), with an average contribution of the traffic sector to total reductions of 86 % and 93 %, respectively. A clear improvement of the modelled results was found when considering the emission reduction factors, especially in Madrid, Paris and London where the bias is reduced by more than 90 %. Future updates will include the extension of the COVID-19 lockdown period covered, the addition of other pollutant sectors potentially affected by the restrictions (commercial and residential combustion and shipping) and the evaluation of other air quality pollutants such as O3 and PM2.5. All the emission reduction factors are provided in the Supplement.",
        "DOI": "10.5194/acp-21-773-2021",
        "affiliation_name": "Centro Nacional de Supercomputación",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Approaches of artificial intelligence and machine learning in smart cities: Critical review",
        "paper_author": "Varshney H.",
        "publication": "IOP Conference Series: Materials Science and Engineering",
        "citied_by": "12",
        "cover_date": "2021-01-18",
        "Abstract": "Smart cities are aiming to develop a management system for growing urban cities, improve the economy, energy consumption, and living standards of their citizens. Information and communication technology (ICT) has a much more important place in decision making, policy design, and implementation of modern techniques to develop smart cities. This review aims primarily to investigate the role of artificial intelligence (AI) and machine learning (ML) in the development of smart cities. This survey leads to the systematic interpretation of current patterns in ICT-related information flow publications as well as to the identification of the usual technologies used to facilitate this communication. In this paper, we represent the detailed presentation of AI & ML in the intelligent transport system and the prediction of mix design and mechanical properties of concrete.",
        "DOI": "10.1088/1757-899X/1022/1/012019",
        "affiliation_name": "Zakir Husain College of Engineering and Technology",
        "affiliation_city": "Aligarh",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Research progress of automatic driving control technology based on reinforcement learning",
        "paper_author": "Pan F.",
        "publication": "Journal of Image and Graphics",
        "citied_by": "9",
        "cover_date": "2021-01-16",
        "Abstract": "Research on fully automatic driving has been largely spurred by some important international challenges and competitions, such as the well-known Defense Advanced Research Projects Agency Grand Challenge held in 2005. Self-driving cars and autonomous vehicles have migrated from laboratory development and testing conditions to driving on public roads. Self-driving cars are autonomous decision-making systems that process streams of observations coming from different on-board sources, such as cameras, radars, lidars, ultrasonic sensors, global positioning system units, and/or inertial sensors. The development of autonomous vehicles offers a decrease in road accidents and traffic congestions. Most driving scenarios can be simply solved with classical perception, path planning, and motion control methods. However, the remaining unsolved scenarios are corner cases where traditional methods fail. In the past decade, advances in the field of artificial intelligence (AI) and machine learning (ML) have greatly promoted the development of autonomous driving. Autonomous driving is a challenging application domain for ML. ML methods can be divided into supervised learning, unsupervised learning, and reinforcement learning (RL). RL is a family of algorithms that allow agents to learn how to act in different situations. In other words, a map or a policy is established from situations (states) to actions to maximize a numerical reward signal. Most autonomous vehicles have a modular hierarchical structure and can be divided into four components or four layers, namely, perception, decision making, control, and actuator. RL is suitable for decision making and control in complex traffic scenarios to improve the safety and comfort of autonomous driving. Traditional controllers utilize an a priori model composed of fixed parameters. When robots or other autonomous systems are used in complex environments, such as driving, traditional controllers cannot foresee every possible situation that the system has to cope with. An RL controller is a learning controller and uses training information to learn their models over time. With every gathered batch of training data, the approximation of the true system model becomes accurate. Deep neural networks have been applied as function approximators for RL agents, thereby allowing agents to generalize knowledge to new unseen situations, along with new algorithms for problems with continuous state and action spaces. This paper mainly introduces the current status and progress of the application of RL methods in autonomous driving control. This paper consists of five sections. The first section introduces the background of autonomous driving and some basic knowledge about ML and RL. The second section briefly describes the architecture of autonomous driving framework. The control layer is an important part of an autonomous vehicle and has always been a key area of autonomous driving technology research. The control system of autonomous driving mainly includes lateral control and longitudinal control, namely, steering control and velocity control. Lateral control deals with the path tracking problem, and longitudinal control deals with the problem of tracking the reference speed and keeping a safe distance from the preceding vehicle. The third section introduces the basic principles of RL methods and focuses on the current research status of RL in autonomous driving control. RL algorithms are based on Markov decision process and aim to learn mapping from situations to actions to maximize a scalar reward or reinforcement signal. RL is a new and extremely old topic in AI. It gradually became an active and identifiable area of ML in 1980 s. Q-learning is a widely used RL algorithm. However, it is based on tabular setting and can only deal with those problems with low dimension and discrete state/action spaces. A primary goal of AI is to solve complex tasks from unprocessed, high-dimensional, sensory input. Significant progress has been made by combining deep learning for sensory processing with RL, resulting in the \"deep Q network\" (DQN) algorithm that is capable of human-level performance on many Atari video games using unprocessed pixels for input. However, DQN can only handle discrete and low-dimensional action spaces. Deep deterministic policy gradient was proposed to handle those problems with continuous state/action spaces. It can learn policies directly from raw pixel inputs. The fourth section generalizes some typical applications of RL algorithm in autonomous driving, including some studies of our team. Unlike supervised learning, RL is more suitable for decision making and control of autonomous driving. Most of the RL algorithms used in autonomous driving mostly combine deep learning and use raw pixels as input to achieve end-to-end control. The last section discusses the challenges encountered in the application of RL algorithms in autonomous driving control. The first challenge is how to deploy the RL model trained on a simulator to run in a real environment and ensure safety. The second challenge is the RL problem in an environment with multiple participants. Multiagent RL is a direction of RL development, but training multiagents is more complicated than training a single agent. The third challenge is how to train an agent with a reasonable reward function. In most RL settings, we typically assume that a reward function is given, but this is not always the case. Imitation learning and reverse RL provide an effective solution for obtaining the real reward function that makes the performance of the agent close to a human. This article helps to understand the advantages and limitations of RL methods in autonomous driving control, the potential of deep RL, and can serve as reference for the design of automatic driving control systems.",
        "DOI": "10.11834/jig.200428",
        "affiliation_name": "Beijing University of Chemical Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Electricity market transaction model design combining blockchain and machine learning",
        "paper_author": "Liu Y.X.",
        "publication": "2021 IEEE International Conference on Consumer Electronics and Computer Engineering, ICCECE 2021",
        "citied_by": "1",
        "cover_date": "2021-01-15",
        "Abstract": "With the deteriorating environment and the issuance of various national policies, green energy has begun to rise and become an important part of the energy market. The traditional energy trading model is a centralized management model, and new energy is not suitable for the current situation due to its wide distribution. Some traditional transaction models, so we use blockchain technology to solve this problem. Aiming at the problems of transaction methods, energy price competition and how to implement the blockchain in energy transactions, the K-nearest neighbor algorithm in machine learning is used to realize the automatic auction at the same time, and the ACO algorithm competition based on multiple time scales is studied. The game realizes the legality of using smart contracts to restrict market transactions, solves the problem of distributed green energy grid connection, and combines with appropriate incentive mechanisms to increase the utilization rate of green energy and promote the rational development of ecology and human life.",
        "DOI": "10.1109/ICCECE51280.2021.9342201",
        "affiliation_name": "Shanghai Institute of Technology",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Self-organizing profiles to characterize representative temporal settings for daylight simulations",
        "paper_author": "Ayoub M.",
        "publication": "Solar Energy",
        "citied_by": "7",
        "cover_date": "2021-01-15",
        "Abstract": "While daylight studies vary in scale and complexity, they follow almost identical procedure that yields higher spatial and temporal dimensionality of luminance/illuminance values, which should be reduced into simpler performance metrics. Several complexities arise from depending solely on performance metrics that do not neither agree on unified thresholds, nor report luminous variations spaces might experience due to weather fluctuations. Few research attempts addressed those issues using predefined timesteps. However, they capture instantaneous performance samples of spaces to which they can only be applied, considering fractions of sky conditions that do not offer generalization. This research expands previous endeavors and presents an unprecedented approach that employs unsupervised machine learning to characterize the most representative temporal settings of given locations from widely accessible weather datasets to evaluate internal luminous conditions. The strengths of three algorithms are combined: the ability of Principal Component Analysis to reduce dimensionality, with Self-Organizing Maps and K-means to cluster the reduced data. To exemplify the proposed approach, three locations are investigated, expressing diverse sky conditions. Each of which reflected unique clustering patterns that were translated into temporal profile maps for visualization. This would provide architects and policy makers with methodology to facilitate building performance simulation and design.",
        "DOI": "10.1016/j.solener.2020.11.051",
        "affiliation_name": "Arab Academy for Science, Technology and Maritime Transport",
        "affiliation_city": "Alexandria",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "PrePass-Flow: A Machine Learning based technique to minimize ACL policy violation due to links failure in hybrid SDN",
        "paper_author": "Ibrar M.",
        "publication": "Computer Networks",
        "citied_by": "42",
        "cover_date": "2021-01-15",
        "Abstract": "The centralized architecture of Software-Defined Networking (SDN) reduces networking complexity and improves network manageability by omitting the need for box-by-box troubleshooting and management. However, due to both budget constraints and maturity level of the SDN-capable devices, organizations often are reluctant to adopt SDN in practice. Therefore, instead of migrating to a pure SDN architecture, an incremental SDN deployment strategy is preferred in practice. In this paper, we consider an incremental SDN deployment strategy known as hybrid SDN - involving simultaneous use of both SDN switches and legacy switches. The links connected to an SDN switch are called SDN links, and the rest are called legacy links. An SDN controller can directly poll the status of the SDN links via the connected SDN switches. At the same time, the status of the legacy links passes through SDN switches and reaches the controller, causing delay. As a result, the controller does not have the current status of legacy links in real-time. This delay may lead to undesired outcomes. For example, it causes network reachability problems due to Access Control List (ACL) policies. Therefore, to minimize the impact of network-layer failure in hybrid SDN, we propose a Machine Learning (ML) based technique called PrePass-Flow. PrePass-Flow predicts link failures before their occurrence, recomputes the locations of ACL policies, and installs the ACL policies in the recomputed locations in a proactive manner. The main objective of PrePass-Flow is to minimize the ACL policy violations and network reachability problems due to ACL policies in case of link failures. For the link status prediction, PrePass-Flow uses two supervised ML-based models: 1) a Logistic Regression (LR) model, and 2) a Support Vector Machine (SVM) model. Testing results show that the LR model performs better than both the SVM model and an existing approach in terms of Packet Delivery Ratio (PDR) and ACL policy violations. For instance, the LR model's accuracy is 4% better, precision is 5% higher, sensitivity is 10% better, and Area Under the Curve (AUC) is 6% greater than the SVM model's corresponding results.",
        "DOI": "10.1016/j.comnet.2020.107706",
        "affiliation_name": "Peng Cheng Laboratory",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Assessing UN indicators of land degradation neutrality and proportion of degraded land for Botswana using remote sensing based national level metrics",
        "paper_author": "Akinyemi F.O.",
        "publication": "Land Degradation and Development",
        "citied_by": "27",
        "cover_date": "2021-01-15",
        "Abstract": "Achieving land degradation neutrality (LDN) has been proposed as a way to stem the loss of land resources globally. To date, LDN operationalization at the country level has remained a challenge both from a policy and science perspective. Using an approach incorporating cloud-based geospatial computing with machine learning, national level datasets of land cover, land productivity dynamics, and soil organic carbon stocks were developed. Using the example of Botswana, LDN and proportion of degraded land were assessed. Between 2000 and 2015, grassland lost approximately 17% of its original extent, the highest level of loss for any land category; land productivity decline was highest in artificial surface areas (11%), whereas 36% of croplands show early signs of decline. With the use of national metrics (NM), degraded areas were found to be 32.6% compared to 51.4% of the total land area when global default datasets (DD) were used. Estimates of degraded land computed with NM and DD were validated in Palapye, an agro-pastoral region in eastern Botswana, where Composite Land Degradation Index (CLDI) field-based data exists. Comparing land degradation (LD) in the three datasets (NM, DD, and CLDI), NM estimates were closest to the field data. The extra efforts put into developing national level data for LD assessment in this study is, thus, well-justified. Beyond demonstrating remote sensing viability for LD assessment, the study developed procedures for generating and validating national level datasets. Using these procedures, LD monitoring will be enhanced in Botswana and elsewhere since these remote sensing datasets can be updated using freely available satellite datasets.",
        "DOI": "10.1002/ldr.3695",
        "affiliation_name": "Botswana International University of Science and Technology",
        "affiliation_city": "Palapye",
        "affiliation_country": "Botswana"
    },
    {
        "paper_title": "Enhancing dynamism in management and network slice establishment through deep learning",
        "paper_author": "Moreira R.",
        "publication": "International Conference on Information Networking",
        "citied_by": "2",
        "cover_date": "2021-01-13",
        "Abstract": "With the variety of applications and the different user requirements, it is necessary to offer tailored resources efficiently not only in access but also in the core of the network. Inspired by the definition and standardization of mobile networks, especially 5G that focused on business verticals, the term network slicing has received numerous state-of-the-art efforts to materialize an approach that meets dynamism, programmability, and flexibility requirements. Leveraged by SDN and NFV technologies, network slicing is inspiring by resource sharing similar to virtual machine management, allowing standard network hardware to accommodate a wide variety of logical networks with specific requirements and data and control planes. However, state-of-the-art approaches do not address resource slicing at the core of the network in detail and appropriately. Therefore, we built NASOR to provide network slicing over the Internet data plane spanning across multiple domains through a segment routing and a distributed-based approach. Our approach excels those found in state-of-the-art by delivering an open policy interface that allows third-party applications to manage network slices dynamically. In this sense, this paper exploits this interface through a mechanism of convolutional neural networks that classifies network traffic, instructing the path-setting agent to be aware of application which predominantly runs on the network improving dynamism in the network slices deployment. Experiments showcase the convolutional neural network applicability and suitability as an enabling technology to enhance and instruct NASOR to establish network slices over multiple domains.",
        "DOI": "10.1109/ICOIN50884.2021.9333872",
        "affiliation_name": "Universidade de Aveiro",
        "affiliation_city": "Aveiro",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Joint Behavioral Cloning and Reinforcement Learning Method for Propofol and Remifentanil Infusion in Anesthesia",
        "paper_author": "Shin M.J.",
        "publication": "International Conference on Information Networking",
        "citied_by": "4",
        "cover_date": "2021-01-13",
        "Abstract": "Total intravenous anesthesia using propofol and remifentanil is widely used. However, a rapid elimination property of the control of the drug infusion rate leads to problems. Recently, it has been shown that machine learning algorithms are able to more accurately predict drug effects than traditional prediction models. Based on this trend, this paper proposes a machine learning method that can simulate the transition dynamics of patient data during anesthesia to conFigure the interactive environment. In addition, we propose deep reinforcement learning with behavior cloning-based initialization to train the propofol and remifentanil control policies. As shown in the dataintensive performance evaluation, the proposed method achieves a desirable performance in terms of average bispectral index and blood pressure during the surgery simulation.",
        "DOI": "10.1109/ICOIN50884.2021.9333933",
        "affiliation_name": "Seoul National University Hospital",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Hit Ratio and Latency Optimization for Caching Systems: A Survey",
        "paper_author": "Tran A.T.",
        "publication": "International Conference on Information Networking",
        "citied_by": "11",
        "cover_date": "2021-01-13",
        "Abstract": "The rise of fifth-generation (5G) communication systems allows the super high-quality services to be implemented in real-life; however, it requires a massive amount of mobile data traffic to be simultaneously transmitted and processed. Fortunately, a significant percentage of mobile data traffic is indeed reusable and should be cached properly in somewhere, and then be delivered back to users' equipment (UEs) in the future requests. To proactively utilize this nature of content distribution, the caching techniques have attracted significant attention from the research community by alleviating unnecessary duplicated data transmission of popular content in mobile edge caching enabled networks. As a result, numerous scientific approaches under different perspectives have been published and hence should be categorized through specific criteria. In this study, we systematically and extensively survey the most recent caching techniques that were published. For each caching policy, we critically analyze its target in detail by performance metrics, including hit ratio, latency, and storage efficiency. Besides, we display the current trend by sorting them into common technical classes such as machine learning, deep learning, game theory, optimization techniques, etc. To visualize and predict the application of caching algorithms, in reality, we summarize their typical use cases.",
        "DOI": "10.1109/ICOIN50884.2021.9334019",
        "affiliation_name": "Sejong University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Intrinsically Motivated Exploration of Learned Goal Spaces",
        "paper_author": "Laversanne-Finot A.",
        "publication": "Frontiers in Neurorobotics",
        "citied_by": "5",
        "cover_date": "2021-01-12",
        "Abstract": "Finding algorithms that allow agents to discover a wide variety of skills efficiently and autonomously, remains a challenge of Artificial Intelligence. Intrinsically Motivated Goal Exploration Processes (IMGEPs) have been shown to enable real world robots to learn repertoires of policies producing a wide range of diverse effects. They work by enabling agents to autonomously sample goals that they then try to achieve. In practice, this strategy leads to an efficient exploration of complex environments with high-dimensional continuous actions. Until recently, it was necessary to provide the agents with an engineered goal space containing relevant features of the environment. In this article we show that the goal space can be learned using deep representation learning algorithms, effectively reducing the burden of designing goal spaces. Our results pave the way to autonomous learning agents that are able to autonomously build a representation of the world and use this representation to explore the world efficiently. We present experiments in two environments using population-based IMGEPs. The first experiments are performed on a simple, yet challenging, simulated environment. Then, another set of experiments tests the applicability of those principles on a real-world robotic setup, where a 6-joint robotic arm learns to manipulate a ball inside an arena, by choosing goals in a space learned from its past experience.",
        "DOI": "10.3389/fnbot.2020.555271",
        "affiliation_name": "Université de Bordeaux",
        "affiliation_city": "Bordeaux",
        "affiliation_country": "France"
    },
    {
        "paper_title": "A Cognitive FMCW Radar to Minimize a Sequence of Range-Doppler Measurements",
        "paper_author": "Altmann M.",
        "publication": "EuRAD 2020 - 2020 17th European Radar Conference",
        "citied_by": "3",
        "cover_date": "2021-01-10",
        "Abstract": "This paper proposes a cognitive radar setup to learn the minimal sequence of Range-Doppler measurements for accurate multi-target detection with adaptive parameters. This minimal measurement sequence is achieved by a novel reward definition in a Reinforcement Learning approach. Thus, the cognitive radar learns to optimize its measurement time and energy savings. Based on Range-Doppler maps, the Reinforcement Learning agent adapts the FMCW parameters like bandwidth, sweep time, chirp repetition time and number of chirps to optimize the recognition in a three-target scenario. The agent is trained using Proximal Policy Optimization (PPO) in a simulated radar environment.",
        "DOI": "10.1109/EuRAD48048.2021.00065",
        "affiliation_name": "Hochschule Heilbronn",
        "affiliation_city": "Heilbronn",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Ecological environment and socioeconomic factors drive long-term transmission and extreme outbreak of dengue fever in epidemic region of China",
        "paper_author": "Li C.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "11",
        "cover_date": "2021-01-10",
        "Abstract": "Dengue fever (DF) is among the most serious vector-borne diseases and is widespread in tropical and subtropical areas. Ecological environment and socioeconomic drivers have a significant effect on the rapid spread of DF. This study aimed to investigate the long-term relationship between the ecological environment and socioeconomic drivers with DF transmission in the dengue-pandemic city of Guangzhou, China over the period 1998–2016. Principle components analysis was conducted to select key ecological environment and socioeconomic drivers conducive to DF transmission. Statistical models and machine learning regression algorithms, including ordinary least squares analysis, generalized linear and generalized additive models, and support vector regression were utilized to model the occurrence of DF over a long period. Population density, night-time light, travel and land use were selected as key factors. According to the overall performance of the four models, a DF model based on a generalized additive model was chosen as having the best performance. This model not only detected significantly non-linear relationships between key ecological environment and socioeconomic drivers and the occurrence of DF with high correlation coefficient, but also perfectly fitted extreme outbreaks of DF. We have made suggestions about policies and measures regarding its prevention in Guangzhou and other regions where it is endemic from the perspectives of ecological environment and socioeconomic factors. This study aims to shed light on the role of the ecological environment and socioeconomic factors in the transmission of DF and provide the scientific basis and guidance for its future prevention and control.",
        "DOI": "10.1016/j.jclepro.2020.123870",
        "affiliation_name": "Southern Marine Science and Engineering Guangdong Laboratory",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Online classification of RTC traffic",
        "paper_author": "Perna G.",
        "publication": "2021 IEEE 18th Annual Consumer Communications and Networking Conference, CCNC 2021",
        "citied_by": "8",
        "cover_date": "2021-01-09",
        "Abstract": "Real-time communication (RTC) platforms have become increasingly popular in the last decade, together with the spread of broadband Internet access. They are nowadays a fundamental means for connecting people and supporting the economy, which relies more and more on forms of remote working. In this context, it is particularly important to act at the network level to ensure adequate Quality of Experience (QoE) to users, where proper traffic management policies are essential to prioritize RTC traffic. This, in turn, requires in-network devices to identify RTC streams and the type of content they carry. In this paper, we propose a machine learning-based application to classify, in real-time, the media streams generated by RTC applications encapsulated in Secure Real Time Protocol (SRTP) flows. Using carefully tuned features extracted from packet characteristics, we train a model to classify streams into an ample set of classes, including media type (audio/video), video quality and redundant streams. To validate our approach, we use traffic from more than 88 hours of multi-party meeting calls made using the Cisco Webex Teams application. We reach an overall accuracy of 97% with a light-weight decision tree model, which makes decisions using only 1 second of traffic.",
        "DOI": "10.1109/CCNC49032.2021.9369470",
        "affiliation_name": "Cisco Systems",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A hybrid distributed batch-stream processing approach for anomaly detection",
        "paper_author": "Pishgoo B.",
        "publication": "Information Sciences",
        "citied_by": "19",
        "cover_date": "2021-01-08",
        "Abstract": "Batch and stream processing are separately and efficiently applied in many applications. However, some newer data-driven applications such as the Internet of Things and cloud computing call for hybrid processing approaches in order to handle the speed and accuracy required for processing such complex data. In this paper, we propose a Hybrid Distributed Batch-Stream (HDBS) architecture for anomaly detection in real-time data. The hybrid architecture, while benefiting from the accuracy provided by batch processing, also enjoys the speed and real-time features of stream processing. In the proposed architecture, our focus is on the algorithmic aspects of hybrid processing including the interaction models between batch and stream processing units, the characteristics of batch and stream machine learning algorithms and the principles of merging the results of different processing units. The driving idea of such combination is that the results of batch and stream processing units are complementary with each other, as one of them constructs accurate models based on previous data, and the other one is capable of processing new stream data in real-time. Furthermore, we propose a generalized version of the HDBS with respect to its algorithms and communication policy levels. In the generalized HDBS architecture, we address the various aspects of the interaction between the batch and stream processing units, and the merging operations to produce the final results. the evaluations of the proposed architecture using various criteria (accuracy, space complexity, and time complexity) demonstrate that the accuracy of the proposed method is higher than the accuracy of the batch processing methods, its time complexity is also similar to one of the stream processing methods and much less than the batch processing methods, which makes our proposed architecture an efficient and practical solution for real-time anomaly detection.",
        "DOI": "10.1016/j.ins.2020.07.026",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine learning-based modeling and operation of plasma-enhanced atomic layer deposition of hafnium oxide thin films",
        "paper_author": "Ding Y.",
        "publication": "Computers and Chemical Engineering",
        "citied_by": "21",
        "cover_date": "2021-01-04",
        "Abstract": "Plasma-enhanced atomic layer deposition (PEALD) has demonstrated its superiority at coating ultra-conformal high dielectric thin-films, which are essential to the fin field-effect transistors (FinFETs) as well as the advanced 3D V-NAND (vertical Not-AND) flash memory cells. Despite the growing research interest, the exploration of the optimal operation policies for PEALD remains a complicated and expensive task. Our previous work has constructed a comprehensive 3D multiscale computational fluid dynamics (CFD) model for the PEALD process and demonstrated its potential to enhance the understanding of the process. Nevertheless, the limitation of computational resources and the relatively long computation time restrict the efficient exploration of the operating space and the optimal operating strategy. Thus, in this work, we apply a 2D axisymmetric reduction of the previous 3D model of PEALD reactors with and without the showerhead design. Furthermore, a data-driven model is derived based on a recurrent neural network (RNN) for process characterization. The developed integrated data-driven model is demonstrated to accurately characterize the key aspects of the deposition process as well as the gas-phase transport profile while maintaining computational efficiency. The derived data-driven model is further validated with the results from a full 3D multiscale CFD model to evaluate model discrepancy. Using the data-driven model, an operational strategy database is generated, from which the optimal operating conditions can be determined for the deposition of Hafnium Oxide (HfO2) thin-film based on an elementary cost analysis.",
        "DOI": "10.1016/j.compchemeng.2020.107148",
        "affiliation_name": "UCLA Samueli School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Does last year’s cost predict the present cost? An application of machine leaning for the japanese area-basis public health insurance database",
        "paper_author": "Nomura Y.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "7",
        "cover_date": "2021-01-02",
        "Abstract": "The increasing healthcare cost imposes a large economic burden for the Japanese gov-ernment. Predicting the healthcare cost may be a useful tool for policy making. A database of the area-basis public health insurance of one city was analyzed to predict the medical healthcare cost by the dental healthcare cost with a machine learning strategy. The 30,340 subjects who had continued registration of the area-basis public health insurance of Ebina city during April 2017 to September 2018 were analyzed. The sum of the healthcare cost was JPY 13,548,831,930. The per capita healthcare cost was JPY 446,567. The proportion of medical healthcare cost, medication cost, and dental healthcare cost was 78%, 15%, and 7%, respectively. By the results of the neural network model, the medical healthcare cost proportionally depended on the medical healthcare cost of the previous year. The dental healthcare cost of the previous year had a reducing effect on the medical healthcare cost. However, the effect was very small. Oral health may be a risk for chronic diseases. However, when evaluated by the healthcare cost, its effect was very small during the observation period.",
        "DOI": "10.3390/ijerph18020565",
        "affiliation_name": "Tsurumi University",
        "affiliation_city": "Yokohama",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Mapping paddy rice with satellite remote sensing: A review",
        "paper_author": "Zhao R.",
        "publication": "Sustainability (Switzerland)",
        "citied_by": "78",
        "cover_date": "2021-01-02",
        "Abstract": "Paddy rice is a staple food of three billion people in the world. Timely and accurate estimation of the paddy rice planting area and paddy rice yield can provide valuable information for the government, planners and decision makers to formulate policies. This article reviews the existing paddy rice mapping methods presented in the literature since 2010, classifies these methods, and analyzes and summarizes the basic principles, advantages and disadvantages of these methods. According to the data sources used, the methods are divided into three categories: (I) Optical mapping methods based on remote sensing; (II) Mapping methods based on microwave remote sensing; and (III) Mapping methods based on the integration of optical and microwave remote sensing. We found that the optical remote sensing data sources are mainly MODIS, Landsat, and Sentinel-2, and the emergence of Sentinel-1 data has promoted research on radar mapping methods for paddy rice. Multisource data integration further enhances the accuracy of paddy rice mapping. The best methods are phenology algorithms, paddy rice mapping combined with machine learning, and multisource data integration. Innovative methods include the time series similarity method, threshold method combined with mathematical models, and object-oriented image classification. With the development of computer technology and the establishment of cloud computing platforms, opportunities are provided for obtaining large-scale high-resolution rice maps. Multisource data integration, paddy rice mapping under different planting systems and the connection with global changes are the focus of future development priorities.",
        "DOI": "10.3390/su13020503",
        "affiliation_name": "Southwest University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep reinforcement learning-empowered resource allocation for mobile edge computing in cellular v2x networks",
        "paper_author": "Li D.",
        "publication": "Sensors (Switzerland)",
        "citied_by": "24",
        "cover_date": "2021-01-02",
        "Abstract": "With the rapid development of vehicular networks, vehicle-to-everything (V2X) communications have huge number of tasks to be calculated, which brings challenges to the scarce network resources. Cloud servers can alleviate the terrible situation regarding the lack of computing abilities of vehicular user equipment (VUE), but the limited resources, the dynamic environment of vehicles, and the long distances between the cloud servers and VUE induce some potential issues, such as extra communication delay and energy consumption. Fortunately, mobile edge computing (MEC), a promising computing paradigm, can ameliorate the above problems by enhancing the computing abilities of VUE through allocating the computational resources to VUE. In this paper, we propose a joint optimization algorithm based on a deep reinforcement learning algorithm named the double deep Q network (double DQN) to minimize the cost constituted of energy consumption, the latency of computation, and communication with the proper policy. The proposed algorithm is more suitable for dynamic scenarios and requires low-latency vehicular scenarios in the real world. Compared with other reinforcement learning algorithms, the algorithm we proposed algorithm improve the performance in terms of convergence, defined cost, and speed by around 30%, 15%, and 17%.",
        "DOI": "10.3390/s21020372",
        "affiliation_name": "Beijing Jiaotong University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Self-Motivated Communication Agent for Real-World Vision-Dialog Navigation",
        "paper_author": "Zhu Y.",
        "publication": "Proceedings of the IEEE International Conference on Computer Vision",
        "citied_by": "21",
        "cover_date": "2021-01-01",
        "Abstract": "Vision-Dialog Navigation (VDN) requires an agent to ask questions and navigate following the human responses to find target objects. Conventional approaches are only allowed to ask questions at predefined locations, which are built upon expensive dialogue annotations, and inconvenience the real-word human-robot communication and cooperation. In this paper, we propose a Self-Motivated Communication Agent (SCoA) that learns whether and what to communicate with human adaptively to acquire instructive information for realizing dialogue annotation-free navigation and enhancing the transferability in real-world unseen environment. Specifically, we introduce a whether-to-ask (WeTA) policy, together with uncertainty of which action to choose, to indicate whether the agent should ask a question. Then, a what-to-ask (WaTA) policy is proposed, in which, along with the oracle’s answers, the agent learns to score question candidates so as to pick up the most informative one for navigation, and meanwhile mimic oracle’s answering. Thus, the agent can navigate in a self-Q&A manner even in real-world environment where the human assistance is often unavailable. Through joint optimization of communication and navigation in a unified imitation learning and reinforcement learning framework, SCoA asks a question if necessary and obtains a hint for guiding the agent to move towards the target with less communication cost. Experiments on seen and unseen environments demonstrate that SCoA shows not only superior performance over existing baselines without dialog annotations, but also competing results compared with rich dialog annotations based counterparts.",
        "DOI": "10.1109/ICCV48922.2021.00162",
        "affiliation_name": "Huawei Noah's Ark Lab",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Rethinking Artificial Intelligence in China’s COVID-19 Pandemic",
        "paper_author": "Wang Q.",
        "publication": "Current and Future Application of Artificial Intelligence in Clinical Medicine",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The COVID-19 outbreak is currently rampant worldwide. The situation in China has been the toughest since the very beginning of the outbreak. However, the pace of the spread has been controlled after employing various policies to eliminate the further painful loss. The advancement of high technology in AI, big data, and machine learning has benefited mankind significantly, especially in this global public health crisis. This paper aims to rethink China’s experiences in the application of AI from the concept of the “general-purpose technology” and attempts to link the technical aspect of AI to the future of Chinese society and culture regarding this technology.",
        "DOI": "10.2174/9781681088419121010006",
        "affiliation_name": "Xi'an International Studies University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Survey of Fintech Research and Policy Discussion",
        "paper_author": "Allen F.",
        "publication": "Review of Corporate Finance",
        "citied_by": "155",
        "cover_date": "2021-01-01",
        "Abstract": "The intersection of finance and technology, known as fintech, has resulted in the dramatic growth of innovations and has changed the entire financial landscape. While fintech has a critical role to play in democratizing credit access to the unbanked and thin-file consumers around the globe, those consumers who are currently well served also turn to fintech for faster services and greater transparency. Fintech, particularly the blockchain, has the potential to be disruptive to financial systems and intermediation. Our aim in this paper is to provide a comprehensive fintech literature survey with relevant research studies and policy discussion around the various aspects of fintech. The topics include marketplace and peer-to-peer lending; credit scoring; alternative data; distributed ledger technologies; blockchain; smart contracts; cryptocurrencies and initial coin offerings; central bank digital currency; robo-advising; quantitative investment and trading strategies; cybersecurity; identity theft; cloud computing; use of big data, artificial intelligence. and machine learning; identity and fraud detection; anti-money laundering; Know Your Customers; natural language processing; regtech; insuretech; sandboxes; and fintech regulations.",
        "DOI": "10.1561/114.00000007",
        "affiliation_name": "Federal Reserve Bank of Philadelphia",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Ghosting Inside the Machine: Student Cheating, Online Education, and the Omertà of Institutional Liars",
        "paper_author": "Ralston S.J.",
        "publication": "Postdigital Science and Education (Netherlands)",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "‘Ghosting’, or the unethical practice of having someone other than the student registered in the course take the student’s exams, complete his or her assignments, and write his or her essays, has become a common method of cheating in today’s online higher education learning environment. Internet-based teaching technology and deceit go hand in hand because the technology establishes a set of perverse incentives for students to cheat and institutions to either tolerate or encourage this highly unethical form of behavior. For students, cheating becomes an increasingly attractive option as pre-digital safeguards—for instance, in-person exam proctoring requirements and face-to-face mentoring—are quietly phased out and eventually eliminated altogether. Also, as the punishments for violating academic integrity policies are relaxed, the temptation to cheat increases accordingly. For institutions, tolerating, normalizing, and encouraging one type of student cheating, ghosting, improves the profitability of their online divisions by bolstering student enrolments and retention. In universities and colleges across the globe, online divisions and programs have become thriving profit centers, not because of the commonly attributed reasons (student ease, safety during health crises, and convenience of taking courses online), but due to a single strategic insight: ubiquitous opportunities for ghosting improve profit margins and maximize revenue.",
        "DOI": "10.1007/978-3-030-72154-1_14",
        "affiliation_name": "Woolf University",
        "affiliation_city": "Valletta",
        "affiliation_country": "Malta"
    },
    {
        "paper_title": "Applied Machine Learning and Multi-criteria Decision-making in Healthcare",
        "paper_author": "Ozsahin I.",
        "publication": "Applied Machine Learning and Multi-criteria Decision-making in Healthcare",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "This book provides an ideal foundation for readers to understand the application of artificial intelligence (AI) and machine learning (ML) techniques to expert systems in the healthcare sector. It starts with an introduction to the topic and presents chapters which progressively explain decision-making theory that helps solve problems which have multiple criteria that can affect the outcome of a decision. Key aspects of the subject such as machine learning in healthcare, prediction techniques, mathematical models and classification of healthcare problems are included along with chapters which delve in to advanced topics on data science (deep-learning, artificial neural networks, etc.) and practical examples (influenza epidemiology and retinoblastoma treatment analysis). Key Features:-Introduces readers to the basics of AI and ML in expert systems for healthcare-Focuses on a problem solving approach to the topic-Provides information on relevant decision-making theory and data science used in the healthcare industry-Includes practical applications of AI and ML for advanced readers-Includes bibliographic references for further reading The reference is an accessible source of knowledge on multi-criteria decision-support systems in healthcare for medical consultants, healthcare policy makers, researchers in the field of medical biotechnology, oncology and pharmaceutical research and development.",
        "DOI": "10.2174/97816810887161210101",
        "affiliation_name": "Yakın Doğu Üniversitesi",
        "affiliation_city": "Nicosia",
        "affiliation_country": "Cyprus"
    },
    {
        "paper_title": "Comparison of Forecasting Models in the HIV Epidemiology Using Machine Learning Methods",
        "paper_author": "Yakut Ö.",
        "publication": "Applied Machine Learning and Multi-criteria Decision-making in Healthcare",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "In analyzing the Human immunodeficiency virus (HIV) epidemic dynamics, the biggest problem is uncertainty when planning for the future. In future evaluations, predicting what might happen will make the decisions% results more realistic. Policymakers will have the opportunity to take precautions against any negative changes that may occur. Machine learning methods that produce good and effective predictive results are needed to plan future policies, eliminate the negativities and overcome deciding in an uncertain environment. In this study, seven machine learning models used to make time-series analysis for medical purposes are theoretically explained. Machine learning methods such as Linear Regression, RepTree, Alternating Model Trees, M5, k Nearest Neighbor (kNN), Autoregressive Integrated Moving Average (ARIMA), and Random Forest were used. The dynamics of the HIV epidemic in Turkey have been made stationary time series, considering compliance of the correlation. Then, the time series were preprocessed using the Moving Average technique, and the time series was softened. The time series is divided into 2/3 training and 1/3 test sets. Machine learning methods were trained using these sets, parameter optimization of models was made and tested. Then these models were used to forecast the HIV epidemic Dynamics in Turkey in 3 years between 2019-Q4 and 2022-Q3. The Random Forest method has been successful as the model that produces the least error rate (Mean Absolute Percentage Error, MAPE) among these seven models. According to the estimation results of the Random Forest model, R2 (the coefficient of determination) value was 82.16%, E (efficiency) value was 0.6268, Slope value was 2.3362, and MAPE value was 5.4132%. The Random Forest model has been observed to give excellent results for the three-year forecast of dynamics of the HIV epidemic in Turkey.",
        "DOI": "10.2174/9781681088716121010009",
        "affiliation_name": "Kocaeli Üniversitesi",
        "affiliation_city": "İzmit",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "MEASURING THE INNOVATION IMPACT OF SCIENTIFIC RESEARCH: EXPLORING THE POTENTIALS OF AI",
        "paper_author": "Distel A.P.",
        "publication": "Academy of Management Annual Meeting Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Policy makers and funding agencies increasingly expect scientists to demonstrate the societal impact of their research. But how can they assess the broader impact of the research they provided funding for beyond the citation impact that publications associated with the funded research have? In this paper, we explore the potentials of machine learning to assess how scientific publications inform practice and as such shape actual decision-making in society. We suggest an artificial intelligence-based semantic processing approach (AI) that seeks to identify the use of published research results in the field of diabetes in new clinical practice guidelines.",
        "DOI": "10.5465/AMBPP.2021.247",
        "affiliation_name": "Rotterdam School of Management, Erasmus University",
        "affiliation_city": "Rotterdam",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "The Carbon Utilization and Storage Partnership of the Western United States",
        "paper_author": "Balch R.",
        "publication": "15th Greenhouse Gas Control Technologies Conference 2021, GHGT 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "In 2019, The United States Department of Energy created four new regional carbon storage partnerships following the success of the previous regional partnership program established in 2003. The new partnerships are designed to accelerate development of commercial storage projects in the United States. The Carbon Utilization and Storage Partnership of the Western United States (CUSP) was formed as an outgrowth of three of the former partnerships: The Southwest Regional Partnership on Carbon Sequestration; the WestCArb partnership; and the Big Sky Partnership (see map). The CUSP primary objective is to catalog, analyze and rank CCUS options for parts or all of 13 states that make up the contiguous western USA. The multi-state CUSP team and project coordinates the capabilities, experience, data collection methods and advanced modelling tools developed and refined through several decades of efforts via many previous NETL-sponsored projects. The CUSP team seeks to accelerate CCUS technology development and deployment in the Western U.S., with a Partnership that consists of 13 universities, seven geological surveys, three research institutes and three national laboratories. Goals of the CUSP project include assembly of existing CCUS data into a uniform database, and increased data collection and analysis of new data not yet present in EDX, NATCARB or other databases. Additionally, the CUSP seeks improvement of modeling tools used for risk prediction and economic scenario analysis, and identification of major technical challenges and development of CCUS deployment readiness indices. One primary deliverable of the CUSP project maps,interactive software and data products that delineate not only regions and specific targets that have the best prospects for commercially-viable CCUS, but also highlight technical challenges and their effects on CCUS development. Other products include analysis tools and large data sets tailored for machine learning efforts via the new DOE initiative on machine learning. These goals are being accomplished by updating existing data (for example, CO2 storage data collected during the creation of the National Carbon Atlas, EPA CO2 source data, and pipeline and infrastructure data), augmenting and refining that data where gaps are identified, and feeding the data into various analytical and optimization models to create a series of readiness indices for the Western Region of the United States. In addition to reducing geological characterization uncertainty, particularly for stacked storage reservoirs (saline+EOR), the project is incorporating a variety of soft data into models that will help identify the best prospects for commercially-viable CCUS and help quantify potential economic impact. This effort provides targeted regions with the most promising combination of geology, geography and infrastructure and industrial sectors for short term, midterm, and long-term CCUS projects, and identifies improvements necessary for maximizing success and assess scenarios that can swiftly and cost-effectively graduate potential projects to short-term status. Via SimCCS and additional desktop-based software tools, dynamic readiness mapping are developed and verified, modified as needed, and distributed. Use of these tools are supported by educational workshops and online training materials. Finally, the CUSP Partnership is participating in a variety of technology transfer programs to help facilitate regional efforts to guide and develop policies and permitting mechanisms to further CCUS in this region. The benefits of the CUSP project include improving the quality and interoperability of existing data, incorporation of more extensive, and detailed, technical as well as soft data into very large data sets for Machine Learning efforts, and using local and regional expertise to continue and improve technology transfer and stimulate stakeholder interest and knowledge of CCUS. Progress to date for major objectives will be presented, including preliminary heat maps of CCS/CCUS potential in the western United States.",
        "DOI": "10.2139/ssrn.3821160",
        "affiliation_name": "New Mexico Institute of Mining and Technology",
        "affiliation_city": "Socorro",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "wapr.tugon.ph: A Secure Helpline for Detecting Psychosocial Aid from Reports of Unlawful Killings in the Philippines",
        "paper_author": "Estuar M.R.J.E.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": ". Availability and affordance of information communications technology has provided additional medium to monitor human rights violation. Reporting, extraction, collection and verification of reports through natural language processing and machine learning techniques can now be integrated into one system. The processed narratives becomes readily available for response, monitoring, interventions, policy-making and even as evidence in court. This paper discusses the design and development of wapr.tugon.ph, a block-chain enabled NLP-based platform that provides a simple yet effective way of reporting, validating and securing human rights violation reports from victims or witnesses. wapr.tugon.ph allows for SMS-based and web-based reporting of human rights violation. Reports are processed for detection of emotions using NRCLex, and behaviors using Stanford Parser and modified Multi-Liason algorithm from narratives which serve as input to assess wellness. A total of 5,418 records were obtained from Reddit’s subreddits and HappyDB corpus to serve as baseline corpora for our model. Our best psychosocial wellness detection model produced an accuracy and F1 score of 84% on validation set (n = 1, 426) and 87% on test set (n = 666). An ethereum private blockchain is implemented to record all transactions made in the system for authenticity tracking. Findings underscore the importance of providing a system that assists in determining the appropriate psychosocial intervention to victims, families and witnesses of human rights violation. Specifically, the study contributes a framework in embedding a combined sentiment and behavior model that outputs: sentiments that are used to assess mental wellness, behaviors that are used to assess physical needs, and detection of wellness that serves as input to refer victims, families of victims and witnesses to appropriate agencies.",
        "DOI": "10.1007/978-3-030-80387-2_23",
        "affiliation_name": "Ateneo de Manila University",
        "affiliation_city": "Quezon City",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "Using Convolutional Neural Networks to Understand the Impact of COVID-19 on Electricity Demand in Texas",
        "paper_author": "Li V.",
        "publication": "Energy Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Economic consequences have been felt around the world as a result of COVID-19, among which have been changes in electricity demand. In this project, we use a convolutional neural network (CNN) to investigate whether there was a change in electricity demand in the state of Texas, located within the United States, during the pandemic, as compared to before it. Training the model on electricity demand and weather data, we were able to achieve a relative RMSE, relative MAE, and R2 of 0.049, 0.041, and 0.92, respectively, on a testing set that represented a normal, pre-pandemic year. The CNN showed better performance, as compared to a plain artificial neural network (ANN). Based on the predictions of the CNN and the actual demand in 2020–2021, we find that the hypothesis that demand decreased during the pandemic was partially supported. A larger decrease was present due to extreme weather events; therefore, we recommend that Texas fortify its electricity generation facilities against such events.",
        "DOI": "10.46855/energy-proceedings-9328",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Applied Energy Symposium: Low carbon cities and urban energy systems, 2021",
        "paper_author": "NA",
        "publication": "Energy Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 43 papers. The special focus in this conference is on Low carbon cities and urban energy systems. The topics include: IMPACTS OF SOCIAL DISTANCING RESTRICTIONS FOR THE COVID-19 ON RESIDENTIAL BUILDING ELECTRICITY ENERGY USE IN SEOUL; investigation of the novel integration of mashrabiya and heat transfer devices for buildings in hot climates; an Evaluation on the effect of thermal mass to modulate overheating in the cold climate in China and the role of shading devices and night ventilation; scenarios Analysis on the Regional Pathway under the Target of Carbon Peak and Carbon Neutrality: a Case Study of Sichuan Province; building Characteristics, Urban Contextual Form and Energy Use in Seoul—A Local Climate Zones Typology Approach; carbon Neutrality in Provincial Energy System: a Case Study of 2060 Sichuan Province; Research of the peak current in lithium-ion battery application with AI; the Carbon Footprint of Pacific Oyster Farming in China; renewable energy investment and carbon emissions under carbon cap-and-trade mechanisms and renewable portfolio standards; the Impact of Occupancy Energy Use Behaviour of High-Rise Dwellings In Southeast China; building Occupancy Prediction Through Machine Learning for Enhancing Energy Efficiency, Air Quality and Thermal Comfort: Review and Case Study; monetary policy drives economic prosperity: innegligible influence of energy; assessment of operational carbon emission reduction potential of green building technologies; a Low carbon Building-level Integrated Energy System Planning Method Considering Fuel Cell and Multiple Energy Storage; identification and comparison of key design parameters of high-rise and lowrise zero/low energy buildings in subtropical regions.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Reward Prediction for Representation Learning and Reward Shaping",
        "paper_author": "Hlynsson H.D.",
        "publication": "International Joint Conference on Computational Intelligence",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "One of the fundamental challenges in reinforcement learning (RL) is the one of data efficiency: modern algorithms require a very large number of training samples, especially compared to humans, for solving environments with high-dimensional observations. The severity of this problem is increased when the reward signal is sparse. In this work, we propose learning a state representation in a self-supervised manner for reward prediction. The reward predictor learns to estimate either a raw or a smoothed version of the true reward signal in an environment with a single terminating goal state. We augment the training of out-of-the-box RL agents in single-goal environments with visual inputs by shaping the reward using our reward predictor during policy learning. Using our representation for preprocessing high-dimensional observations, as well as using the predictor for reward shaping, is shown to facilitate faster learning of Actor Critic using Kronecker-factored Trust Region and Proximal Policy Optimization.",
        "DOI": "10.5220/0010640200003063",
        "affiliation_name": "Ruhr-Universitat Bochum",
        "affiliation_city": "Bochum",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Applied Energy Symposium: Low carbon cities and urban energy systems, 2021",
        "paper_author": "NA",
        "publication": "Energy Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 92 papers. The special focus in this conference is on Low carbon cities and urban energy systems. The topics include: IMPACTS OF SOCIAL DISTANCING RESTRICTIONS FOR THE COVID-19 ON RESIDENTIAL BUILDING ELECTRICITY ENERGY USE IN SEOUL; investigation of the novel integration of mashrabiya and heat transfer devices for buildings in hot climates; an Evaluation on the effect of thermal mass to modulate overheating in the cold climate in China and the role of shading devices and night ventilation; scenarios Analysis on the Regional Pathway under the Target of Carbon Peak and Carbon Neutrality: a Case Study of Sichuan Province; building Characteristics, Urban Contextual Form and Energy Use in Seoul—A Local Climate Zones Typology Approach; carbon Neutrality in Provincial Energy System: a Case Study of 2060 Sichuan Province; Research of the peak current in lithium-ion battery application with AI; the Carbon Footprint of Pacific Oyster Farming in China; renewable energy investment and carbon emissions under carbon cap-and-trade mechanisms and renewable portfolio standards; the Impact of Occupancy Energy Use Behaviour of High-Rise Dwellings In Southeast China; building Occupancy Prediction Through Machine Learning for Enhancing Energy Efficiency, Air Quality and Thermal Comfort: Review and Case Study; monetary policy drives economic prosperity: innegligible influence of energy; assessment of operational carbon emission reduction potential of green building technologies; a Low carbon Building-level Integrated Energy System Planning Method Considering Fuel Cell and Multiple Energy Storage; identification and comparison of key design parameters of high-rise and lowrise zero/low energy buildings in subtropical regions.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "TTL-Based Cache Utility Maximization Using Deep Reinforcement Learning",
        "paper_author": "Cho C.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Utility-driven caching opened up a new design opportunity for caching algorithms by modeling the admission and eviction control as a utility maximization process with essential support for service differentiation. Nevertheless, there is still to go in terms of adaptability to changing environment. Slow convergence to an optimal state may degrade actual user-experienced utility, which gets even worse in non-stationary scenarios where cache control should be adaptive to time-varying content request traffic. This paper proposes to exploit deep reinforcement learning (DRL) to enhance the adaptability of utility-driven time-to-live (TTL)-based caching. Employing DRL with long short-term memory helps a caching agent learn how it adapts to the temporal correlation of content popularities to shorten the transient-state before the optimal steady-state. In addition, we elaborately design the state and action spaces of DRL to overcome the curse of dimensionality, which is one of the most frequently raised issues in machine learning-based approaches. Experimental results show that policies trained by DRL can outperform the conventional utility-driven caching algorithm under some non-stationary environments where content request traffic changes rapidly.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685845",
        "affiliation_name": "Electronics and Telecommunications Research Institute",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Resource Scheduling in Satellite Networks: A Sparse Representation Based Machine Learning Approach",
        "paper_author": "Bao C.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "With the growth of global communication service demand, constructing large-scale satellite networks has become the future development trend for improved system performance. However, due to the high-speed orbit motion of satellites, the connection relationship of network topology (CRNT) is complex and changeable. This phenomenon is particularly pronounced in large-scale satellite networks and the existing representation schemes of CRNT for large-scale satellite networks have high space complexity. Therefore, we explore the sparse characterization of the inter-satellite visibility matrix and propose an integrated sparse space-time resource representation (ISST-RR) scheme to efficiently characterize the satellite network communication resources with low complexity from the dimension of time and space. On the basis of the proposed ISST-RR scheme, we further propose a multi-agent reinforcement learning with sparse representation based resource scheduling (MARLSR-RS) algorithm to obtain the optimal resource scheduling policy. Simulations demonstrate the efficiency of the proposed MARLSR-RS algorithm in terms of communication resource utilization. In addition, we investigate the impact of several typical netwrok parameters, e.g., transmission rate of observation satellites on network performance, which can provide a theoretical guidance for system design.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685507",
        "affiliation_name": "Xidian University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Deep Reinforcement Learning Based Big Data Resource Management for 5G/6G Communications",
        "paper_author": "Shi Z.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "With the advent of the Internet of Everything era, communication data has exploded, which requires more communication resources, such as frequency, time, and energy. In this context, this paper presents a machine learning-based data packet scheduling scheme to achieve efficient data packet transmission in the 5G/6G communication systems. To minimize the average number of packet overflows (APNO), we propose distributed deep deterministic policy gradient (DDPG)-based algorithm for multidimensional resource scheduling. To improve the algorithm stability and training efficiency, the strategy of centralized training and distributed execution is adopted, and an Action Adjuster is designed. The proposed algorithm enables the multidimensional resource management of the 5G/6G commu-nication systems without any information interaction between each agent. Simulation results show that the proposed Action Adjuster DDPG algorithm achieves faster convergence and less data overflow compared to other benchmark algorithms.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685098",
        "affiliation_name": "School of Electrical and Electronic Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "DeepDRAMA: Deep Reinforcement Learning-based Disaster Recovery with Mitigation Awareness in EONs",
        "paper_author": "Zou R.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Elastic Optical Networks (EONs) have become a promising solution to satisfy the dramatic growth of bandwidth demand due to 5G and cloud applications. Due to the flexibility of resource allocation, EONs provide high spectrum utilization efficiency, and because of this, developing efficient policies to ensure the survivability of EONs is a challenging problem. A well-designed disaster management plan is needed to prevent data loss during network failures and large-scale disasters. The bottleneck problem caused by disabled parts of the network causes difficulties for disaster recovery. Depending on the disaster, even traffic that may be far away from the disaster may be impacted by it. In this paper, we propose a new approach to disaster management using machine learning to facilitate efficient recovery. In addition to traffic immediately affected by the disaster, all traffic which is 'close to' the disaster is re-routed and re-assigned with possibly degraded service, while requests 'far from' the disaster are left unaffected. A deep reinforcement learning disaster recovery algorithm with mitigation awareness (DeepDRAMA) is proposed for recovery. A novel deep reinforcement learning agent is designed and trained for the agent to select the appropriate level of service degradation for re-assigned traffic. Simulation results show the performance improvement with DeepDRAMA.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685680",
        "affiliation_name": "Kagawa University",
        "affiliation_city": "Takamatsu",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Cost-Efficient Shuffling and Regrouping Based Defense for Federated Learning",
        "paper_author": "Huang S.M.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Federated learning (FL) enables multiple user de-vices to collaboratively train a global machine learning (ML) model by uploading their local models to the central server for aggregation. However, attackers may upload tampered local models (e.g., label-flipping attack) to corrupt the global model. Existing defense methods focus on outlier detection, but they are computationally intensive and can be circumvented by advanced model tampering. We employ a shuffling-based defense model to isolate the attackers from ordinary users. To explore the intrinsic properties, we simplify the defense model problem and formulate it as a Markov Decision Problem (MDP) to find the optimal policy. Then, we introduce a novel notion, (re)grouping, into the defense model to propose a new cost-efficient defense framework termed SAGE. Experiment results manifest that SAGE can effectively mitigate the impact of attacks in FL by efficiently decreasing the ratio of attacker devices to ordinary user devices. SAGE increases the testing accuracy of the targeted class by at most 40%.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685499",
        "affiliation_name": "National Chung Cheng University",
        "affiliation_city": "Min-Hsiung",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Flow-Packet Hybrid Traffic Classification for Class-Aware Network Routing",
        "paper_author": "Chowdhury S.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Network traffic classification using machine learning techniques has been widely studied. Most existing schemes classify entire traffic flows, but there are major limitations to their practicality. At a network router, the packets need to be processed with minimum delay, so the classifier cannot wait until the end of the flow to make a decision. Furthermore, a complicated machine learning algorithm can be too computationally expensive to implement inside the router. In this paper, we introduce flow-packet hybrid traffic classification (FPHTC), where the router makes a decision per packet based on a routing policy that is designed through transferring the learned knowledge from a flow-based classifier residing outside the router. We analyze the generalization bound of FPHTC and show its advantage over regular packet-based traffic classification. We present experimental results using a real-world traffic dataset to illustrate the classification performance of FPHTC. We show that it is robust toward traffic pattern changes and can be deployed with limited computational resource.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685838",
        "affiliation_name": "TELUS",
        "affiliation_city": null,
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Knowledge Caching for Federated Learning",
        "paper_author": "Zheng X.Y.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This work examines a novel wireless content distribution problem where machine learning models (e.g., deep neural networks) are cached at local small cell base-stations to facilitate access by users within their coverage. The models are trained by federated learning procedures which allow local users to collaboratively train the models using their locally stored data. Upon the completion of training, the model can also be accessed by all other users depending on their application demand. Different from conventional wireless caching problems, the placement of machine learning models should depend not only on the users' preferences but also on the data available at the users and their channel conditions. In this work, we propose to jointly optimize the caching decision, user selection, and wireless resource allocation, including transmit powers and bandwidth of the selected users, to minimize a training error bound. The problem is reduced to minimizing a weighted sum of local dataset sizes subject to constraints on the cache storage capacity, the communication and computation latency, and the total energy consumption. We first derive the minimum loss achievable for each cached model, and, then, determine the optimal models to cache by solving an equivalent 0-1 Knapsack problem that minimizes the total average loss. Simulations show that the proposed scheme can achieve lower extremity error bounds compared to preference-only and random caching policies.",
        "DOI": "10.1109/GLOBECOM46510.2021.9685861",
        "affiliation_name": "National Tsing Hua University",
        "affiliation_city": "Hsinchu",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "A comprehensive techno-eco-assessment of CO<inf>2</inf> enhanced oil recovery projects using a machine-learning assisted workflow",
        "paper_author": "You J.",
        "publication": "15th Greenhouse Gas Control Technologies Conference 2021, GHGT 2021",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "Injection of CO2 gas to partially depleted oil reservoirs not only enhances hydrocarbon production but also take advances of the underground porous media for carbon storage purposes. Therefore, carbon utilization to enhanced oil recovery (EOR) projects become more and more attractive in the petroleum industry. Notably, the use of anthropogenic CO2 in EOR project could be challenging due to the capital and operational costs of carbon capture, transportation, and recycling. In the meantime, the US government offers encouraging tax policies, Section 45 Q, to oil field operators who inject a large volume of CO2 to produce oil. Thus, the project economics of the CO2-EOR project could be even more complex, especially when the oil price is low at this time. In this article, a robust machine-learning assisted CO2-EOR project optimization and design protocol is presented. The workflow aims at simultaneously optimizing the hydrocarbon recovery, carbon storage volume and project economics using a Pareto-front-based multiple-objective optimization (MOO) scheme. A solution repository containing various optimized development strategies will be structured. Moreover, the proposed workflow will investigate the project economics of the solutions by systematically considering impactive factors such as tax credits, project capital costs, oil prices, etc., and provide comprehensive recommendations to the field operators for decision-making purposes. This work employs data collected from the Farnsworth unit (FWU) in west Texas, US, as a field case to demonstrate the workflow. FWU is characterized as partially depleted oil sands undergoing water-alternative-CO2 (CO2-WAG) injection processes. A compositional numerical reservoir simulation model is established to investigate the fluid transportations dynamic of FWU. The numerical model is validated via a rigorous history-matching study using 55-year of primary and secondary (water flooding) recovery data, and 8-year of ternary recovery (CO2-WAG) data. It is worth emphasizing that the history-matched model successfully incorporates eight relative permeability curves to various spatial regions of the field. Such relative permeability curves are measured via laboratory investigations using representative core samples collected from the fields (hydraulic flow units). The history matched numerical model can be used to forecast the hydrocarbon production and CO2 storage volume using different CO2-WAG designs. In order to obtain finer optimization solutions, the field operational parameters, such as water injection rate, gas injection period, water injection periods, production well specifications, etc. of each individual well are considered as control parameters. In this way, the field operators can get detailed guidance to operate each individual well. However, the imposing of MOO requires computationally intensive procedures by totally relying on the high-fidelity numerical simulator, which engages the motivation to employ machine-learning-based proxies in the workflow. In this work, supported vector machine regression (SVR) combined with the Gaussian kernel is utilized to mimic the high-fidelity numerical model. The hyper-parameters of the SVR are optimized using Bayesian Optimization to achieve a better generalization performance. The SVR couples with Multi-objective Particle Swarm Optimization (MOPSO) protocol to structure the Pareto-front solution repository. To further eliminate the uncertainties introduced by the proxy error margins, a self-adapting scheme is integrated into the workflow to justify the Pareto-front solutions. This scheme will automatically add new sampling data to the training dataset for surrogate model development, making the optimization results more correct. Furthermore, this paper will carry comprehensive techno-eco-assessments of the optimized solutions considering the vital economic factors including the carbon capture and transporting costs, field operational cost, tax credits, oil price, etc. With the help of the proxy models, fast uncertainty analysis can be conducted to obtain stochastic results of the project net present value, rate of return and payback period. Field operators can make their decisions to design CO2-WAG projects based on both technical and economical perspectives.",
        "DOI": "NA",
        "affiliation_name": "Chongqing University of Science and Technology",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Great SCO<inf>2</inf>T! Rapid tool for geologic carbon sequestration science, engineering, and economics",
        "paper_author": "Middleton R.S.",
        "publication": "15th Greenhouse Gas Control Technologies Conference 2021, GHGT 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "CO2 capture and storage (CCS) technology is likely to be widely deployed in coming decades in response to major climate and economic drivers: CCS is a central part of every major climate policy that limits global warming to 2°C or less, and is eligible for significant CO2 tax credits in the United States. These drivers are likely to stimulate capture, transport, and storage of hundreds of millions or billions of tonnes of CO2 annually. A key part of the CCS puzzle will be identifying and characterizing suitable site-scale geologic storage sites for vast amounts of CO2 (Figure 1). We recently developed a new approach to rapidly characterize the physical and economic performance of geologic storage reservoirs using a fast-running, open-source tool called SCO2T (Sequestration of CO2 Tool, pronounced “Scott”). SCO2T can rapidly screen hundreds of thousands of reservoirs, perform sensitivity and uncertainty analyses, and link sequestration engineering (injection rates, reservoir capacities, plume dimensions) to sequestration economics (total costs derived from more than 70 separate economic inputs). SCO2T has been further developed and commercialized by CARBON SOLUTIONS LLC (CARBON SOLUTIONS) to include new and advanced features such as supply-curve generation, dynamic injection and storage over multiple time periods, and monitoring and post-injection site care (PISC) costs. The new software is called SCO2TPRO",
        "DOI": "NA",
        "affiliation_name": "Indiana University Bloomington",
        "affiliation_city": "Bloomington",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Data Analytics in Power Markets",
        "paper_author": "Chen Q.",
        "publication": "Data Analytics in Power Markets",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "This book aims to solve some key problems in the decision and optimization procedure for power market organizers and participants in data-driven approaches. It begins with an overview of the power market data and analyzes on their characteristics and importance for market clearing. Then, the first part of the book discusses the essential problem of bus load forecasting from the perspective of market organizers. The related works include load uncertainty modeling, bus load bad data correction, and monthly load forecasting. The following part of the book answers how much information can be obtained from public data in locational marginal price(LMP)-based markets. It introduces topics such as congestion identification, componential price forecasting, quantifying the impact of forecasting error, and financial transmission right investment. The final part of the book answers how to model the complex market bidding behaviors. Specific works include pattern extraction, aggregated supply curve forecasting, market simulation, and reward function identification in bidding. These methods are especially useful for market organizers to understand the bidding behaviors of market participants and make essential policies. It will benefit and inspire researchers, graduate students, and engineers in the related fields.",
        "DOI": "10.1007/978-981-16-4975-2",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "AI: UBI Income Portfolio Adjustment to Technological Transformation",
        "paper_author": "Przegalinska A.K.",
        "publication": "Frontiers in Human Dynamics",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Positive and normative claims that artificial intelligence (AI) will or should lead to adoption of a universal basic income policy (UBI) remain insufficiently empirically grounded to merit serious consideration. Long-term trends in individual/familial income portfolio adjustment (IPA) to business, economic, and technological change (BETC) point to continued incremental changes in the ways that individuals/families achieve life goals, not a fundamental structural break necessitating radical policy changes that may not be desirable in any event. Moreover, if AI proves a more rapid disruptor than anticipated, UBI-like payments can be made quickly, as recent bailouts and fiscal stimuli demonstrate.",
        "DOI": "10.3389/fhumd.2021.725516",
        "affiliation_name": "Kozminski University",
        "affiliation_city": "Warsaw",
        "affiliation_country": "Poland"
    },
    {
        "paper_title": "Unitarism vs. Individuality and a New Digital Agenda: The Power of Decentralized Web",
        "paper_author": "Lauterbach A.",
        "publication": "Frontiers in Human Dynamics",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Discussions around Covid-19 apps and models demonstrated that primary challenges for AI and data science focused on governance and ethics. Personal information was involved in building data sets. It was unclear how this information could be utilized in large scale models to provide predictions and insights while observing privacy requirements. Most people expected a lot from technology but were unwilling to sacrifice part of their privacy for building it. Conversely, regulators and policy makers require AI and data science practitioners to ensure optimal public health, national security while avoiding these privacy-related struggles. Their choices vary largely from country to country and are driven more by cultural aspects, and less by machine learning capabilities. The question is whether current ways to design technology and work with data sets are sustainable and lead to a good outcome for individuals and their communities. At the same time Covid-19 made it obvious that economies and societies cannot succeed without far-reaching digital policies, touching every aspect of how we provide and receive education, live, and work. Most regions, businesses and individuals struggled to benefit from competitive capabilities modern data technologies could bring. This opinion paper suggests how Germany and Europe can rethink their digital policy while recognizing the value of data, introducing Data IDs for consumers and businesses, committing to support innovation in decentralized data technologies, introducing concepts of Data Trusts and compulsory education around data starting from the early school age. Besides, it discusses advantages of data-tokens to shape a new ecosystem for decentralized data exchange. Furthermore, it emphasizes the necessity to develop and promote technologies to work with small data sets and handle data in compliance with privacy regulations, keeping in mind costs for the environment while bidding on big data and large-scale machine learning models. Finally, innovation as an integral part of any data scientist's job will be called for.",
        "DOI": "10.3389/fhumd.2021.626299",
        "affiliation_name": "XU Exponential University of Applied Sciences",
        "affiliation_city": "Potsdam",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "On Assessing Trustworthy AI in Healthcare. Machine Learning as a Supportive Tool to Recognize Cardiac Arrest in Emergency Calls",
        "paper_author": "Zicari R.V.",
        "publication": "Frontiers in Human Dynamics",
        "citied_by": "33",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial Intelligence (AI) has the potential to greatly improve the delivery of healthcare and other services that advance population health and wellbeing. However, the use of AI in healthcare also brings potential risks that may cause unintended harm. To guide future developments in AI, the High-Level Expert Group on AI set up by the European Commission (EC), recently published ethics guidelines for what it terms “trustworthy” AI. These guidelines are aimed at a variety of stakeholders, especially guiding practitioners toward more ethical and more robust applications of AI. In line with efforts of the EC, AI ethics scholarship focuses increasingly on converting abstract principles into actionable recommendations. However, the interpretation, relevance, and implementation of trustworthy AI depend on the domain and the context in which the AI system is used. The main contribution of this paper is to demonstrate how to use the general AI HLEG trustworthy AI guidelines in practice in the healthcare domain. To this end, we present a best practice of assessing the use of machine learning as a supportive tool to recognize cardiac arrest in emergency calls. The AI system under assessment is currently in use in the city of Copenhagen in Denmark. The assessment is accomplished by an independent team composed of philosophers, policy makers, social scientists, technical, legal, and medical experts. By leveraging an interdisciplinary team, we aim to expose the complex trade-offs and the necessity for such thorough human review when tackling socio-technical applications of AI in healthcare. For the assessment, we use a process to assess trustworthy AI, called 1Z-Inspection® to identify specific challenges and potential ethical trade-offs when we consider AI in practice.",
        "DOI": "10.3389/fhumd.2021.673104",
        "affiliation_name": "Berliner Institut für Gesundheitsforschung",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Freight train scheduling via decentralised multi-agent deep reinforcement learning",
        "paper_author": "Bretas A.M.C.",
        "publication": "Proceedings of the International Congress on Modelling and Simulation, MODSIM",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Rail traffic planning and scheduling problems have been challenging academy and industry for a few decades. Specifically, problems in the short term and real-time horizons deal with simultaneous decision-making of trains, stations and terminals. Approaches focused on decentralised decision-making have been successful in delivering real-world committed solutions. This work focuses on decentralised real-time decision-making in a closed freight rail network and applies multi-agent deep reinforcement learning (MADRL) to find efficient timetables. We apply the MADRL model to solve the traffic decisions arising in the Hunter Valley Coal Chain (HVCC) in New South Wales, Australia. The approach uses the same simulation model currently in use for capacity planning of the system, thus allowing tests with real data. The environment is modelled as a decentralised, partially observed Markov decision process (dec-POMDP), where the train, load point, and dump station agents decide upon train movements based on local observations. The observations follow a novel state encoding strategy for rail traffic management composed of nine layers. We benefit from this strategy to apply a decentralised execution with a centralised learning approach through proximal policy optimisation. The experiments revealed a significant performance improvement for the ten instances tested, which reproduce the challenges faced in the HVCC operations. The approach is suitable for varied levels of rail network complexity, generating efficient solutions without scaling issues. The MADRL outperformed the heuristic in use by HVCC's simulation model and a high-performance genetic algorithm in all instances, reaching performance improvements of up to 72.00% and 47.42%, respectively. Therefore, the framework with the MADRL and the simulation model allows its application with real world instances in an efficient and reliable way. These results show the method's consistency and draw a safe path towards a decentralised rail traffic management system.",
        "DOI": "NA",
        "affiliation_name": "The University of Newcastle, Australia",
        "affiliation_city": "Callaghan",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Profiling and Discriminating of Containerized ML Applications in Digital Data Marketplaces (DDM)",
        "paper_author": "Zhang L.",
        "publication": "International Conference on Information Systems Security and Privacy",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "A Digital Data Marketplace (DDM) facilitates secure and trustworthy data sharing among multiple parties. For instance, training a machine learning (ML) model using data from multiple parties normally contributes to higher prediction accuracy. It is crucial to enforce the data usage policies during the execution stage. In this paper, we propose a methodology to distinguish programs running inside containers by monitoring system calls sequence externally. To support container portability and the necessity of retraining ML models, we also investigate the stability of the proposed methodology in 7 typical containerized ML applications over different execution platform OSs and training data sets. The results show our proposed methodology can distinguish between applications over various configurations with an average classification accuracy of 93.85%, therefore it can be integrated as an enforcement component in DDM infrastructures.",
        "DOI": "10.5220/0010254105080515",
        "affiliation_name": "Universiteit van Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "7th International Conference on Information Systems Security and Privacy, ICISSP 2021",
        "paper_author": "NA",
        "publication": "International Conference on Information Systems Security and Privacy",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 86 papers. The special focus in this conference is on Information Systems Security and Privacy. The topics include: Mobile Robots: An Overview of Data and Security; Automatically Extracting Business Level Access Control Requirements from BPMN Models to Align RBAC Policies; protecting Privacy during a Pandemic Outbreak; enhanced Information Management in Inter-organisational Planning for Critical Infrastructure Protection: Case and Framework; model-based Threat and Risk Assessment for Systems Design; utilizing Keystroke Dynamics as Additional Security Measure to Protect Account Recovery Mechanism; towards Collaborative Cyber Threat Intelligence for Security Management; A Secure Network Scanner Architecture for Asset Management in Strongly Segmented ICS Networks; Canopy: A Learning-based Approach for Automatic Low-and-Slow DDoS Mitigation; Remote WebAuthn: FIDO2 Authentication for Less Accessible Devices; on Security Analysis of Periodic Systems: Expressiveness and Complexity; predicting Security Program Effectiveness in Bring-Your-Own-Device Deployment in Organizations; automatic Detection of Cyber Security Events from Turkish Twitter Stream and Newspaper Data; active Directory Kerberoasting Attack: Detection using Machine Learning Techniques; field Studies on the Impact of Cryptographic Signatures and Encryption on Phishing Emails; improvement of Secure Multi-Party Multiplication of (K, n) Threshold Secret Sharing using Only N = k Servers; towards a Formalisation of Expert’s Knowledge for an Automatic Construction of a Vulnerability Model of a Cyberphysical System; a Novel Simplified Framework to Secure IoT Communications; linking Biometric Voice Identity with Self-monitoring Health Data as a Temporal-spatial Event Stored in a Mobile Device; DLP-Visor: A Hypervisor-based Data Leakage Prevention System; An Analytic Attack against ARX Addition Exploiting Standard Side-channel Leakage.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Redefining Safety in Light of Human-Robot Interaction: A Critical Review of Current Standards and Regulations",
        "paper_author": "Martinetti A.",
        "publication": "Frontiers in Chemical Engineering",
        "citied_by": "44",
        "cover_date": "2021-01-01",
        "Abstract": "Policymakers need to consider the impacts that robots and artificial intelligence (AI) technologies have on humans beyond physical safety. Traditionally, the definition of safety has been interpreted to exclusively apply to risks that have a physical impact on persons’ safety, such as, among others, mechanical or chemical risks. However, the current understanding is that the integration of AI in cyber-physical systems such as robots, thus increasing interconnectivity with several devices and cloud services, and influencing the growing human-robot interaction challenges how safety is currently conceptualised rather narrowly. Thus, to address safety comprehensively, AI demands a broader understanding of safety, extending beyond physical interaction, but covering aspects such as cybersecurity, and mental health. Moreover, the expanding use of machine learning techniques will more frequently demand evolving safety mechanisms to safeguard the substantial modifications taking place over time as robots embed more AI features. In this sense, our contribution brings forward the different dimensions of the concept of safety, including interaction (physical and social), psychosocial, cybersecurity, temporal, and societal. These dimensions aim to help policy and standard makers redefine the concept of safety in light of robots and AI’s increasing capabilities, including human-robot interactions, cybersecurity, and machine learning.",
        "DOI": "10.3389/fceng.2021.666237",
        "affiliation_name": "Universiteit Twente",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Fostering Progressive Experiential Learning Approach to Make Engineering Students Future Ready",
        "paper_author": "Rathi S.",
        "publication": "Journal of Engineering Education Transformations",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "With the increasing rise in competitiveness and the rate at which technologies are growing, Engineering Education is facing challenge in equipping its students with the potential to deal with real life, complex problems and providing innovative solution for them. Educators report that the teaching process requires new pedagogical approach in fostering its students the skills required by the new globalized world. It is envisaged that engineering education needs shift in Teaching Learning Process (TLP) from Teacher-Centric approach to Learner-Centric environment. The traditional teaching approach may not provide students with the required skills and life-long learning. The student is not able to retain knowledge after exams. Due to the advancement in technology and exposure to the Internet, students are having many sources of information and learning centers. Due to this, students are drifted from the lecture-based teaching learning process towards the technology driven education. To meet the requirements of rapid changes and developments in technology, the biggest challenge is to use of knowledge into the recent teaching learning process, to produce professional engineers, who are globally accepted, skillful and industry ready. Today’s demand to implement innovative teaching methodologies and initiatives towards student professional development with a holistic approach. Experiential learning (EL) or Learning by doing will begin a modern perspective towards teaching-learning process. The National Education Policy (NEP) 2020 emphasis more on experiential learning to help students to apply their knowledge in real world situation. This paper emphases on how EL helps to improve engineering student’s academic performance and overall development with global acceptance through hands-on laboratory experiments based on design and development (DnD), Professional Skill (PS), Project Based Learning (PBL) and Multidisciplinary Projects. Student’s survey was conducted, and Prediction model is designed to measure the outcome of these activities. This paper attempts to get a hands-on experience of concepts which will enable students to think out-of-box and become a competent engineer. Experimental results showed that Logistic Regression performs better than Support Vector Machine to predict the outcome of Experiential Learning. Logistic Regression provides 83.87 % of Accuracy, 83.33 % of Precision and 95.23 % of Recall.",
        "DOI": "10.16920/jeet/2022/v35is3/22146",
        "affiliation_name": "Thakur college of Engineering and Technology",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India"
    },
    {
        "paper_title": "On the Optimal Allocation of Resources for a Marketing Campaign",
        "paper_author": "Hosein P.",
        "publication": "International Conference on Operations Research and Enterprise Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Many companies and institutions, such as banks, typically have a wide range of products that they make available to customers. However, such products must be marketed to their customers, especially when the product is new. Phone calls, emails, postal mail, and online advertisements are among the ways companies can market products to specific customers. However, the cost incurred during marketing increases with every contact made. Phone calls are the most personal means of targeted marketing but also the most costly. In telemarketing, a company can make multiple calls to a single customer with each call incurring a human resource cost. Such calls may or may not be able to persuade a customer to subscribe to the service or product. Some customers might subscribe after the first call. Some customers might require several calls to convince them. Other customers might never be persuaded. In light of limited resources, to maximize return, a company would need to determine which customers to contact and how many attempts to make for a customer. In this paper, we present a mathematical model for this problem in which, given a marketing budget of calls, one can determine a policy for selecting customers to target along with the optimal number of calls to use for each selected customer. We illustrate our model using a Portuguese banking dataset and show that our model can achieve significantly higher levels of success performance.",
        "DOI": "10.5220/0010232001690176",
        "affiliation_name": "The University of the West Indies, St. Augustine Campus",
        "affiliation_city": "St Augustine",
        "affiliation_country": "Trinidad and Tobago"
    },
    {
        "paper_title": "Machine Learning and Optimization for Predictive Maintenance based on Predicting Failure in the Next Five Days",
        "paper_author": "Ouda E.",
        "publication": "International Conference on Operations Research and Enterprise Systems",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This study proposes a framework to predict machine failures using sensor data and optimize predictive/corrective maintenance schedule. Using historical data, machine learning (ML) models are trained to predict the failure probabilities for the next five days. Multiple algorithms, including feature extraction techniques,selections, and ML models (both regression and classification based) are compared. The machine learning models’ output is fed to an optimization model to propose an optimized maintenance policy, and we demonstrate how prediction models can help increase system reliability at lower costs.",
        "DOI": "10.5220/0010247401920199",
        "affiliation_name": "Khalifa University of Science and Technology",
        "affiliation_city": "Abu Dhabi",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "ThriftyDAgger: Budget-Aware Novelty and Risk Gating for Interactive Imitation Learning",
        "paper_author": "Hoque R.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "28",
        "cover_date": "2021-01-01",
        "Abstract": "Effective robot learning often requires online human feedback and interventions that can cost significant human time, giving rise to the central challenge in interactive imitation learning: is it possible to control the timing and length of interventions to both facilitate learning and limit burden on the human supervisor? This paper presents ThriftyDAgger, an algorithm for actively querying a human supervisor given a desired budget of human interventions. ThriftyDAgger uses a learned switching policy to solicit interventions only at states that are sufficiently (1) novel, where the robot policy has no reference behavior to imitate, or (2) risky, where the robot has low confidence in task completion. To detect the latter, we introduce a novel metric for estimating risk under the current robot policy. Experiments in simulation and on a physical cable routing experiment suggest that ThriftyDAgger’s intervention criteria balances task performance and supervisor burden more effectively than prior algorithms. ThriftyDAgger can also be applied at execution time, where it achieves a 100% success rate on both the simulation and physical tasks. A user study (N = 10) in which users control a three-robot fleet while also performing a concentration task suggests that ThriftyDAgger increases human and robot performance by 58% and 80% respectively compared to the next best algorithm while reducing supervisor burden. See https://tinyurl.com/thrifty-dagger for supplementary material.",
        "DOI": "NA",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multimodal Trajectory Prediction Conditioned on Lane-Graph Traversals",
        "paper_author": "Deo N.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "84",
        "cover_date": "2021-01-01",
        "Abstract": "Accurately predicting the future motion of surrounding vehicles requires reasoning about the inherent uncertainty in driving behavior. This uncertainty can be loosely decoupled into lateral (e.g., keeping lane, turning) and longitudinal (e.g., accelerating, braking). We present a novel method that combines learned discrete policy rollouts with a focused decoder on subsets of the lane graph. The policy rollouts explore different goals given current observations, ensuring that the model captures lateral variability. Longitudinal variability is captured by our latent variable model decoder that is conditioned on various subsets of the lane graph. Our model achieves state-of-the-art performance on the nuScenes motion prediction dataset, and qualitatively demonstrates excellent scene compliance. Detailed ablations highlight the importance of the policy rollouts and the decoder architecture.",
        "DOI": "NA",
        "affiliation_name": "University of California, San Diego",
        "affiliation_city": "La Jolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Safe Driving via Expert Guided Policy Optimization",
        "paper_author": "Peng Z.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "23",
        "cover_date": "2021-01-01",
        "Abstract": "When learning common skills like driving, beginners usually have domain experts standing by to ensure the safety of the learning process. We formulate such learning scheme under the Expert-in-the-loop Reinforcement Learning where a guardian is introduced to safeguard the exploration of the learning agent. While allowing the sufficient exploration in the uncertain environment, the guardian intervenes under dangerous situations and demonstrates the correct actions to avoid potential accidents. Thus ERL enables both exploration and expert’s partial demonstration as two training sources. Following such a setting, we develop a novel Expert Guided Policy Optimization (EGPO) method which integrates the guardian in the loop of reinforcement learning. The guardian is composed of an expert policy to generate demonstration and a switch function to decide when to intervene. Particularly, a constrained optimization technique is used to tackle the trivial solution that the agent deliberately behaves dangerously to deceive the expert into taking over. Offline RL technique is further used to learn from the partial demonstration generated by the expert. Safe driving experiments show that our method achieves superior training and test-time safety, outperforms baselines with a substantial margin in sample efficiency, and preserves the generalizabiliy to unseen environments in test-time. Demo video and source code are available at: https://decisionforce.github.io/EGPO/.",
        "DOI": "NA",
        "affiliation_name": "SenseTime Group Limited",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Urban Driver: Learning to Drive from Real-world Demonstrations Using Policy Gradients",
        "paper_author": "Scheel O.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "44",
        "cover_date": "2021-01-01",
        "Abstract": "In this work we are the first to present an offline policy gradient method for learning imitative policies for complex urban driving from a large corpus of real-world demonstrations. This is achieved by building a differentiable data-driven simulator on top of perception outputs and high-fidelity HD maps of the area. It allows us to synthesize new driving experiences from existing demonstrations using mid-level representations. Using this simulator we then train a policy network in closed-loop employing policy gradients. We train our proposed method on 100 hours of expert demonstrations on urban roads and show that it learns complex driving policies that generalize well and can perform a variety of driving maneuvers. We demonstrate this in simulation as well as deploy our model to self-driving vehicles in the real-world. Our method outperforms previously demonstrated state-of-the-art for urban driving scenarios – all this without the need for complex state perturbations or collecting additional on-policy data during training. We make code and data publicly available.",
        "DOI": "NA",
        "affiliation_name": "Level 5",
        "affiliation_city": null,
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Task-Driven Out-of-Distribution Detection with Statistical Guarantees for Robot Learning",
        "paper_author": "Farid A.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "Our goal is to perform out-of-distribution (OOD) detection, i.e., to detect when a robot is operating in environments that are drawn from a different distribution than the environments used to train the robot. We leverage Probably Approximately Correct (PAC)-Bayes theory in order to train a policy with a guaranteed bound on performance on the training distribution. Our key idea for OOD detection then relies on the following intuition: violation of the performance bound on test environments provides evidence that the robot is operating OOD. We formalize this via statistical techniques based on p-values and concentration inequalities. The resulting approach (i) provides guaranteed confidence bounds on OOD detection, and (ii) is task-driven and sensitive only to changes that impact the robot’s performance. We demonstrate our approach on a simulated example of grasping objects with unfamiliar poses or shapes. We also present both simulation and hardware experiments for a drone performing vision-based obstacle avoidance in unfamiliar environments (including wind disturbances and different obstacle densities). Our examples demonstrate that we can perform task-driven OOD detection within just a handful of trials. Comparisons with baselines also demonstrate the advantages of our approach in terms of providing statistical guarantees and being insensitive to task-irrelevant distribution shifts.",
        "DOI": "NA",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Rapid Exploration for Open-World Navigation with Latent Goal Models",
        "paper_author": "Shah D.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "21",
        "cover_date": "2021-01-01",
        "Abstract": "We describe a robotic learning system for autonomous exploration and navigation in diverse, open-world environments. At the core of our method is a learned latent variable model of distances and actions, along with a non-parametric topological memory of images. We use an information bottleneck to regularize the learned policy, giving us (i) a compact visual representation of goals, (ii) improved generalization capabilities, and (iii) a mechanism for sampling feasible goals for exploration. Trained on a large offline dataset of prior experience, the model acquires a representation of visual goals that is robust to task-irrelevant distractors. We demonstrate our method on a mobile ground robot in open-world exploration scenarios. Given an image of a goal that is up to 80 meters away, our method leverages its representation to explore and discover the goal in under 20 minutes, even amidst previously-unseen obstacles and weather conditions.",
        "DOI": "NA",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "FabricFlowNet: Bimanual Cloth Manipulation with a Flow-based Policy",
        "paper_author": "Weng T.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "45",
        "cover_date": "2021-01-01",
        "Abstract": "We address the problem of goal-directed cloth manipulation, a challenging task due to the deformability of cloth. Our insight is that optical flow, a technique normally used for motion estimation in video, can also provide an effective representation for corresponding cloth poses across observation and goal images. We introduce FabricFlowNet (FFN), a cloth manipulation policy that leverages flow as both an input and as an action representation to improve performance. FabricFlowNet also elegantly switches between dual-arm and single-arm actions based on the desired goal. We show that FabricFlowNet significantly outperforms state-of-the-art model-free and model-based cloth manipulation policies. We also present real-world experiments on a bimanual system, demonstrating effective sim-to-real transfer. Finally, we show that our method generalizes when trained on a single square cloth to other cloth shapes, such as T-shirts and rectangular cloths. Video and other supplementary materials are available at: https://sites.google.com/view/fabricflownet.",
        "DOI": "NA",
        "affiliation_name": "The Robotics Institute",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Error-Aware Imitation Learning from Teleoperation Data for Mobile Manipulation",
        "paper_author": "Wong J.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "19",
        "cover_date": "2021-01-01",
        "Abstract": "In mobile manipulation (MM), robots can both navigate within and interact with their environment and are thus able to complete many more tasks than robots only capable of navigation or manipulation. In this work, we explore how to apply imitation learning (IL) to learn continuous visuo-motor policies for MM tasks. Much prior work has shown that IL can train visuo-motor policies for either manipulation or navigation domains, but few works have applied IL to the MM domain. Doing this is challenging for two reasons: on the data side, current interfaces make collecting high-quality human demonstrations difficult, and on the learning side, policies trained on limited data can suffer from covariate shift when deployed. To address these problems, we first propose MOBILE MANIPULATION ROBOTURK (MOMART), a novel teleoperation framework allowing simultaneous navigation and manipulation of mobile manipulators, and collect a first-of-its-kind large scale dataset in a realistic simulated kitchen setting. We then propose a learned error detection system to address covariate shift by detecting when an agent is in a potential failure state. We train performant IL policies and error detectors from this data, and achieve over 45% task success rate and 85% error detection success rate across multiple multi-stage tasks when trained on expert data. Additional results and video at https://sites.google.com/view/il-for-mm/home.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning Feasibility to Imitate Demonstrators with Different Dynamics",
        "paper_author": "Cao Z.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The goal of learning from demonstrations is to learn a policy for an agent (imitator) by mimicking the behavior in the demonstrations. Prior works on learning from demonstrations assume that the demonstrations are collected by a demonstrator that has the same dynamics as the imitator. However, in many real-world applications, this assumption is limiting — to improve the problem of lack of data in robotics, we would like to be able to leverage demonstrations collected from agents with different dynamics. This can be challenging as the demonstrations might not even be feasible for the imitator. Our insight is that we can learn a feasibility metric that captures the likelihood of a demonstration being feasible by the imitator. We develop a feasibility MDP (f-MDP) and derive the feasibility score by learning an optimal policy in the f-MDP. Our proposed feasibility measure encourages the imitator to learn from more informative demonstrations, and disregard the far from feasible demonstrations. Our experiments on four simulated environments and on a real robot show that the policy learned with our approach achieves a higher expected return than prior works. We show the videos of the real robot arm experiments on our website.",
        "DOI": "NA",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Co-GAIL: Learning Diverse Strategies for Human-Robot Collaboration",
        "paper_author": "Wang C.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "21",
        "cover_date": "2021-01-01",
        "Abstract": "We present a method for learning human-robot collaboration policy from human-human collaboration demonstrations. An effective robot assistant must learn to handle diverse human behaviors shown in the demonstrations and be robust when the humans adjust their strategies during online task execution. Our method co-optimizes a human policy and a robot policy in an interactive learning process: the human policy learns to generate diverse and plausible collaborative behaviors from demonstrations while the robot policy learns to assist by estimating the unobserved latent strategy of its human collaborator. Across a 2D strategy game, a human-robot handover task, and a multi-step collaborative manipulation task, our method outperforms the alternatives in both simulated evaluations and when executing the tasks with a real human operator in-the-loop. Supplementary materials and videos at https://sites.google.com/view/cogail/home.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "CLIPORT: What and Where Pathways for Robotic Manipulation",
        "paper_author": "Shridhar M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "191",
        "cover_date": "2021-01-01",
        "Abstract": "How can we imbue robots with the ability to manipulate objects precisely but also to reason about them in terms of abstract concepts? Recent works in manipulation have shown that end-to-end networks can learn dexterous skills that require precise spatial reasoning, but these methods often fail to generalize to new goals or quickly learn transferable concepts across tasks. In parallel, there has been great progress in learning generalizable semantic representations for vision and language by training on large-scale internet data, however these representations lack the spatial understanding necessary for fine-grained manipulation. To this end, we propose a framework that combines the best of both worlds: a two-stream architecture with semantic and spatial pathways for vision-based manipulation. Specifically, we present CLIPORT, a language-conditioned imitation-learning agent that combines the broad semantic understanding (what) of CLIP [1] with the spatial precision (where) of Transporter [2]. Our end-to-end framework is capable of solving a variety of language-specified tabletop tasks from packing unseen objects to folding cloths, all without any explicit representations of object poses, instance segmentations, memory, symbolic states, or syntactic structures. Experiments in simulated and real-world settings show that our approach is data efficient in few-shot settings and generalizes effectively to seen and unseen semantic concepts. We even learn one multi-task policy for 10 simulated and 9 real-world tasks that is better or comparable to single-task policies.",
        "DOI": "NA",
        "affiliation_name": "NVIDIA",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Broadly-Exploring, Local-Policy Trees for Long-Horizon Task Planning",
        "paper_author": "Ichter B.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Long-horizon planning in realistic environments requires the ability to reason over sequential tasks in high-dimensional state spaces with complex dynamics. Classical motion planning algorithms, such as rapidly-exploring random trees, are capable of efficiently exploring large state spaces and computing long-horizon, sequential plans. However, these algorithms are generally challenged with complex, stochastic, and high-dimensional state spaces as well as in the presence of small, topologically complex goal regions, which naturally emerge in tasks that interact with the environment. Machine learning offers a promising solution for its ability to learn general policies that can handle complex interactions and high-dimensional observations. However, these policies are generally limited in horizon length. Our approach, Broadly-Exploring, Local-policy Trees (BELT), merges these two approaches to leverage the strengths of both through a task-conditioned, model-based tree search. BELT uses an RRT-inspired tree search to efficiently explore the state space. Locally, the exploration is guided by a task-conditioned, learned policy capable of performing general short-horizon tasks. This task space can be quite general and abstract; its only requirements are to be sampleable and to well-cover the space of useful tasks. This search is aided by a task-conditioned model that temporally extends dynamics propagation to allow long-horizon search and sequential reasoning over tasks. BELT is demonstrated experimentally to be able to plan long-horizon, sequential trajectories with a goal conditioned policy and generate plans that are robust.",
        "DOI": "NA",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Geometry-aware Bayesian Optimization in Robotics using Riemannian Matérn Kernels",
        "paper_author": "Jaquier N.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "Bayesian optimization is a data-efficient technique which can be used for control parameter tuning, parametric policy adaptation, and structure design in robotics. Many of these problems require optimization of functions defined on non-Euclidean domains like spheres, rotation groups, or spaces of positive-definite matrices. To do so, one must place a Gaussian process prior, or equivalently define a kernel, on the space of interest. Effective kernels typically reflect the geometry of the spaces they are defined on, but designing them is generally nontrivial. Recent work on the Riemannian Matérn kernels, based on stochastic partial differential equations and spectral theory of the Laplace–Beltrami operator, offers promising avenues towards constructing such geometry-aware kernels. In this paper, we study techniques for implementing these kernels on manifolds of interest in robotics, demonstrate their performance on a set of artificial benchmark functions, and illustrate geometry-aware Bayesian optimization for a variety of robotic applications, covering orientation control, manipulability optimization, and motion planning, while showing its improved performance.",
        "DOI": "NA",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Waking up to marginalization: Public value failures in artificial intelligence and data science",
        "paper_author": "White T.M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Data science education is increasingly becoming an integral part of many educational structures, both informal and formal. Much of the attention has been on the application of AI principles and techniques, especially machine learning, natural language processing and predictive analytics. While AI is only one phase in the data science ecosystem, we must embrace a fuller range of job roles that help manage AI algorithms and systems | from the AI innovators and architects (in CS, Math and Statistics) to the AI technicians and specialists (in CS, IT and IS). Also, it's important that we better understand the current state of the low participation and representation of minoritized groups that further sties the accessibility and inclusion efforts. However, how we learn and what we learn is highly dependent on who we are as learners. In this paper, we examine demographic disparities by race/ethnicity and gender within the information systems educational infrastructure from an evaluative perspective. More specifically, we adopt intersectional methods and apply the theory of public value failure to identify learning gaps in the fast-growing field of data science. National datasets of Master's and Doctoral graduate students in IS, CS, Math and Statistics are used to create an \\institutional parity score\" which calculates field-specific representation by race/ethnicity and gender in data science related fields. We conclude by showcasing bias creep including the situational exclusion of individuals from access to the broader information economy, be it access to technologies and data or access to participate in the data workforce or data enabled-economic activity. Policy recommendations are suggested to curb and reduce this marginalization within in-formation systems and related disciplines.",
        "DOI": "NA",
        "affiliation_name": "Berry College",
        "affiliation_city": "Mount Berry",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Forecasting municipal solid waste generation in Tianjin based on long and short term memory neural network model",
        "paper_author": "Liang X.",
        "publication": "International Journal of Environment and Pollution",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Accurately forecasting urban waste collection volume is of great significance for formulating waste treatment policies. This study focuses on Tianjin and constructs a prediction model based on the long short-Term memory neural network (LSTM) model, using seven factors as input indicators affecting the generation of urban domestic waste, including natural gas, artificial gas, liquefied petroleum gas, water supply, population, gross domestic product (GDP), and total social retail sales. The experimental results demonstrate that the LSTM model established in this study is accurate in predicting waste volume, with a mean absolute percentage error (MAPE) of 9.27. Furthermore, by predicting the future trend of waste generation under different scenarios, it is found that municipal waste generation in Tianjin will be between 2.3918 MT and 5.1340 MT during 2019-2023. Finally, this study proposes relevant suggestions to deal with the increase in the amount of municipal solid waste.",
        "DOI": "10.1504/IJEP.2021.132008",
        "affiliation_name": "Tianjin University of Technology",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Learning to be Multimodal: Co-evolving Sensory Modalities and Sensor Properties",
        "paper_author": "Antonova R.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Making a single sensory modality precise and robust enough to get human-level performance and autonomy could be very expensive or intractable. Fusing information from multiple sensory modalities is promising – for example, recent works showed benefits from combining vision with haptic sensors or with audio data. Learning-based methods facilitate faster progress in this field by removing the need for manual feature engineering. However, the sensor properties and the choice of sensory modalities is still usually done manually. Our blue-sky view is that we could simulate/emulate sensors with various properties, then infer which properties and combinations of sensors yield the best learning outcomes. This view would incentivize the development of novel, affordable sensors that can make a noticeable impact on the performance, robustness and ease of training classifiers, models and policies for robotics. This would motivate making hardware that provides signals complementary to the existing ones. As a result: we can significantly expand the realm of applicability of the learning-based approaches.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Comparison of Machine Learners on an ABA Experiment Format of the Cart-Pole Task",
        "paper_author": "Eberding L.M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Current approaches to online learning focus primarily on reinforcement learning (RL) - algorithms that learn through feedback from experience. While most current RL algorithms have shown good results in learning to perform tasks for which they were specifically designed, most of them lack a level of generalization needed to use existing knowledge to handle novel situations - a property referred to as autonomous transfer learning. Situations encountered by such systems which were not present during the training phase can lead to critical failure. In the present research we analyzed the autonomous transfer learning capabilities of five different machine learning approaches - i.e. an Actor-Critic, a Q-Learner, a Policy Gradient Learner, a Double-Deep Q-Learner, and OpenNARS for Applications. Following a classic ABA experimental format, the learners were all trained on the well-known cart-pole task in phase A-1, before strategic changes to the task were introduced in phase B, consisting of inverting the direction of control of the cart (move-left command moved the cart to the right and vice versa), as well as the introduction of noise. All analyzed learners show an extreme performance drop when the action command is inverted in phase B, resulting in long (re-)training periods trying to reach A1 performance. Most learners do not reach initial A1 performance levels in phase B, some falling very far from them. Furthermore, previously learned knowledge is not retained during the re-training, resulting in an even larger performance drop when the task is changed back to the original settings in phase A2. Only one learner (NARS) reached comparable performance in A1 and A2, demonstrating retention of, and return to, priorly-acquired knowledge.",
        "DOI": "NA",
        "affiliation_name": "Reykjavík University",
        "affiliation_city": "Reykjavik",
        "affiliation_country": "Iceland"
    },
    {
        "paper_title": "No-Regret Learning with High-Probability in Adversarial Markov Decision Processes",
        "paper_author": "Ghasemi M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "In a variety of problems, a decision-maker is unaware of the loss function associated with a task, yet it has to minimize this unknown loss in order to accomplish the task. Furthermore, the decision-maker’s task may evolve, resulting in a varying loss function. In this setting, we explore sequential decision-making problems modeled by adversarial Markov decision processes, where the loss function may arbitrarily change at every time step. We consider the bandit feedback scenario, where the agent observes only the loss corresponding to its actions. We propose an algorithm, called online relative-entropy policy search with implicit exploration, that achieves a sublinear regret not only in expectation but, more importantly, with high probability. In particular, we prove that by employing an optimistically biased loss estimator, the proposed algorithm achieves a regret of Õ((T|A||S|)3 2 √τ), where |S| is the number of states, |A| is the number of actions, τ is the mixing time, and T is the time horizon. To our knowledge, the proposed algorithm is the first scheme that enjoys such high-probability regret bounds for general adversarial Markov decision processes under the presence of bandit feedback.",
        "DOI": "NA",
        "affiliation_name": "Oden Institute for Computational Engineering and Sciences",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Competitive Policy Optimization",
        "paper_author": "Prajapat M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "A core challenge in policy optimization in competitive Markov decision processes is the design of efficient optimization methods with desirable convergence and stability properties. We propose competitive policy optimization (COPO), a novel policy gradient approach that exploits the game-theoretic nature of competitive games to derive policy updates. Motivated by the competitive gradient optimization method, we derive a bilinear approximation of the game objective. In contrast, off-the-shelf policy gradient methods utilize only linear approximations, and hence do not capture players’ interactions. We instantiate COPO in two ways: (i) competitive policy gradient, and (ii) trust-region competitive policy optimization. We theoretically study these methods, and empirically investigate their behavior on a set of comprehensive, yet challenging, competitive games. We observe that they provide stable optimization, convergence to sophisticated strategies, and higher scores when played against baseline policy gradient methods.",
        "DOI": "NA",
        "affiliation_name": "California Institute of Technology",
        "affiliation_city": "Pasadena",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Stochastic Model for Sunk Cost Bias",
        "paper_author": "Kleinberg J.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "We present a novel model for capturing the behavior of an agent exhibiting sunk-cost bias in a stochastic environment. Agents exhibiting sunk-cost bias take into account the effort they have already spent on an endeavor when they evaluate whether to continue or abandon it. We model planning tasks in which an agent with this type of bias tries to reach a designated goal. Our model structures this problem as a type of Markov decision process: loosely speaking, the agent traverses a directed acyclic graph with probabilistic transitions, paying costs for its actions as it tries to reach a target node containing a specified reward. The agent’s sunk cost bias is modeled by a cost that it incurs for abandoning the traversal: if the agent decides to stop traversing the graph, it incurs a cost of λ ·Csunk, where λ ≥ 0 is a parameter that captures the extent of the bias and Csunk is the sum of costs already invested. We analyze the behavior of two types of agents: naive agents that are unaware of their bias, and sophisticated agents that are aware of it. Since optimal (bias-free) behavior in this problem can involve abandoning the traversal before reaching the goal, the bias exhibited by these types of agents can result in sub-optimal behavior by shifting their decisions about abandonment. We show that in contrast to optimal agents, it is computationally hard to compute the optimal policy for a sophisticated agent. Our main results quantify the loss exhibited by these two types of agents with respect to an optimal agent. We present both general and topology-specific bounds.",
        "DOI": "NA",
        "affiliation_name": "Cornell Ann S. Bowers College of Computing and Information Science",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Nonmyopic Approach to Cost-Constrained Bayesian Optimization",
        "paper_author": "Lee E.H.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Bayesian optimization (BO) is a popular method for optimizing expensive-to-evaluate black-box functions. BO budgets are typically given in iterations, which implicitly assumes each evaluation has the same cost. In fact, in many BO applications, evaluation costs vary significantly in different regions of the search space. In hyperparameter optimization, the time spent on neural network training increases with layer size; in clinical trials, the monetary cost of drug compounds vary; and in optimal control, control actions have differing complexities. Cost-constrained BO measures convergence with alternative cost metrics such as time, money, or energy, for which the sample efficiency of standard BO methods is ill-suited. For cost-constrained BO, cost efficiency is far more important than sample efficiency. In this paper, we formulate cost-constrained BO as a constrained Markov decision process (CMDP), and develop an efficient rollout approximation to the optimal CMDP policy that takes both the cost and future iterations into account. We validate our method on a collection of hyperparameter optimization problems as well as a sensor set selection application.",
        "DOI": "NA",
        "affiliation_name": "Facebook",
        "affiliation_city": null,
        "affiliation_country": null
    },
    {
        "paper_title": "Bandits with Partially Observable Confounded Data",
        "paper_author": "Tennenholtz G.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "We study linear contextual bandits with access to a large, confounded, offline dataset that was sampled from some fixed policy. We show that this problem is closely related to a variant of the bandit problem with side information. We construct a linear bandit algorithm that takes advantage of the projected information, and prove regret bounds. Our results demonstrate the ability to take advantage of confounded offline data. Particularly, we prove regret bounds that improve current bounds by a factor related to the visible dimensionality of the contexts in the data. Our results indicate that confounded offline data can significantly improve online learning algorithms. Finally, we demonstrate various characteristics of our approach through synthetic simulations.",
        "DOI": "NA",
        "affiliation_name": "NVIDIA",
        "affiliation_city": "Santa Clara",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Explaining Fast Improvement in Online Imitation Learning",
        "paper_author": "Yan X.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Online Imitation Learning (IL) is an algorithmic framework that leverages interactions with expert policies for efficient policy optimization. Here policies are optimized by performing online learning on a sequence of loss functions that encourage the learner to mimic expert actions. If the online learning algorithm has no regret, then the agent can provably learn an expert-like policy. Online IL has demonstrated empirical successes in many applications and interestingly, its policy improvement speed observed in practice is usually much faster than existing theory suggests. In this work, we provide an explanation of this phenomenon. Let ξ denote the policy class bias and assume the online IL loss functions are convex, smooth, and non-negative. We prove that, after N rounds of online IL with stochastic feedback, the policy improves in Õ(1/N + pξ/N) in both expectation and high probability. In other words, we show that adopting a sufficiently expressive policy class in online IL has two benefits: both the policy improvement speed increases and the performance bias decreases.",
        "DOI": "NA",
        "affiliation_name": "Aurora Innovation, Inc.",
        "affiliation_city": "Palo Alto",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning in Multi-Player Stochastic Games",
        "paper_author": "Brown W.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "We consider the problem of simultaneous learning in stochastic games with many players in the finite-horizon setting. While the typical target solution for a stochastic game is a Nash equilibrium, this is intractable with many players. We instead focus on variants of correlated equilibria, such as those studied for extensive-form games. We begin with a hardness result for the adversarial MDP problem: even for a horizon of 3, obtaining sublinear regret against the best non-stationary policy is NP-hard when both rewards and transitions are adversarial. This implies that convergence to even the weakest natural solution concept—normal-form coarse correlated equilibrium—is not possible via black-box reduction to a no-regret algorithm even in stochastic games with constant horizon (unless NP ⊆ BPP). Instead, we turn to a different target: algorithms which generate an equilibrium when they are used by all players. Our main result is algorithm which generates an extensive-form correlated equilibrium, whose runtime is exponential in the horizon but polynomial in all other parameters. We give a similar algorithm which is polynomial in all parameters for “fast-mixing” stochastic games. We also show a method for efficiently reaching normal-form coarse correlated equilibria in “single-controller” stochastic games which follows the traditional no-regret approach. When shared randomness is available, the two generative algorithms can be extended to give simultaneous regret bounds and converge in the traditional sense.",
        "DOI": "NA",
        "affiliation_name": "The Fu Foundation School of Engineering and Applied Science",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multi-Task and Meta-Learning with Sparse Linear Bandits",
        "paper_author": "Cella L.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Motivated by recent developments on meta-learning with linear contextual bandit tasks, we study the benefit of feature learning in both the multi-task and meta-learning settings. We focus on the case that the task weight vectors are jointly sparse, i.e. they share the same small set of predictive features. Starting from previous work on standard linear regression with the group-lasso estimator we provide novel oracle-inequalities for this estimator when samples are collected by a bandit policy. Subsequently, building on a recent lasso-bandit policy, we investigate its group-lasso variant and analyze its regret bound. We specialize the proposed policy to the multi-task and meta-learning settings, demonstrating its theoretical advantage. We also point out a deficiency in the state-of-the-art lower bound and observe that our method has a smaller upper bound. Preliminary experiments confirm the effectiveness of our approach in practice.",
        "DOI": "NA",
        "affiliation_name": "UCL Engineering",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "When is Particle Filtering Efficient for Planning in Partially Observed Linear Dynamical Systems?",
        "paper_author": "Du S.S.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Particle filtering is a popular method for inferring latent states in stochastic dynamical systems, whose theoretical properties have been well studied in machine learning and statistics communities. In many control problems, e.g., partially observed linear dynamical systems (POLDS), oftentimes the inferred latent state is further used for planning at each step. This paper initiates a rigorous study on the efficiency of particle filtering for sequential planning, and gives the first particle complexity bounds. Though errors in past actions may affect the future, we are able to bound the number of particles needed so that the long-run reward of the policy based on particle filtering is close to that based on exact inference. In particular, we show that, in stable systems, polynomially many particles suffice. Key in our proof is a coupling of the ideal sequence based on the exact planning and the sequence generated by approximate planning based on particle filtering. We believe this technique can be useful in other sequential decision-making problems.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Adaptivity in Adaptive Submodularity",
        "paper_author": "Esfandiari H.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "Adaptive sequential decision making is one of the central challenges in machine learning and artificial intelligence. In such problems, the goal is to design an interactive policy that plans for an action to take, from a finite set of n actions, given some partial observations. It has been shown that in many applications such as active learning, robotics, sequential experimental design, and active detection, the utility function satisfies adaptive submodularity, a notion that generalizes the notion of diminishing returns to policies. In this paper, we revisit the power of adaptivity in maximizing an adaptive monotone submodular function. We propose an efficient semi adaptive policy that with O(log n × log k) adaptive rounds1 of observations can achieve an almost tight 1 - 1/e - ε approximation guarantee with respect to an optimal policy that carries out k actions in a fully sequential manner. To complement our results, we also show that it is impossible to achieve a constant factor approximation with o(log n) adaptive rounds. We also extend our result to the case of adaptive stochastic minimum cost coverage where the goal is to reach a desired utility Q with the cheapest policy. We first prove the long-standing conjecture by Golovin and Krause [24] and show that the greedy policy achieves the asymptotically tight logarithmic approximation guarantee. We then propose a semi adaptive policy that provides the same guarantee in polylogarithmic adaptive rounds through a similar information-parallelism scheme. Our results shrink the adaptivity gap in adaptive submodular maximization by an exponential factor.",
        "DOI": "NA",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "The Last-Iterate Convergence Rate of Optimistic Mirror Descent in Stochastic Variational Inequalities",
        "paper_author": "Azizian W.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, we analyze the local convergence rate of optimistic mirror descent methods in stochastic variational inequalities, a class of optimization problems with important applications to learning theory and machine learning. Our analysis reveals an intricate relation between the algorithm’s rate of convergence and the local geometry induced by the method’s underlying Bregman function. We quantify this relation by means of the Legendre exponent, a notion that we introduce to measure the growth rate of the Bregman divergence relative to the ambient norm near a solution. We show that this exponent determines both the optimal step-size policy of the algorithm and the optimal rates attained, explaining in this way the differences observed for some popular Bregman functions (Euclidean projection, negative entropy, fractional power, etc.).",
        "DOI": "NA",
        "affiliation_name": "Département d'Informatique de l'ENS",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "On the Linear Convergence of Policy Gradient Methods for Finite MDPs",
        "paper_author": "Bhandari J.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "28",
        "cover_date": "2021-01-01",
        "Abstract": "We revisit the finite time analysis of policy gradient methods in the one of the simplest settings: finite state and action MDPs with a policy class consisting of all stochastic policies and with exact gradient evaluations. There has been some recent work viewing this setting as an instance of smooth non-linear optimization problems and showing sub-linear convergence rates with small step-sizes. Here, we take a different perspective based on connections with policy iteration and show that many variants of policy gradient methods succeed with large step-sizes and attain a linear rate of convergence.",
        "DOI": "NA",
        "affiliation_name": "Columbia University",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Developing Strategies for Onchocerciasis Elimination Mapping and Surveillance Through The Diagnostic Network Optimization Approach",
        "paper_author": "Albert H.",
        "publication": "Frontiers in Tropical Diseases",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Background: Onchocerciasis (river blindness) is a filarial disease targeted for elimination of transmission. However, challenges exist to the implementation of effective diagnostic and surveillance strategies at various stages of elimination programs. To address these challenges, we used a network data analytics approach to identify optimal diagnostic scenarios for onchocerciasis elimination mapping (OEM). Methods: The diagnostic network optimization (DNO) method was used to model the implementation of the old Ov16 rapid diagnostic test (RDT) and of new RDTs in development for OEM under different testing strategy scenarios with varying testing locations, test performance and disease prevalence. Environmental suitability scores (ESS) based on machine learning algorithms were developed to identify areas at risk of transmission and used to select sites for OEM in Bandundu region in the Democratic Republic of Congo (DRC) and Uige province in Angola. Test sensitivity and specificity ranges were obtained from the literature for the existing RDT, and from characteristics defined in the target product profile for the new RDTs. Sourcing and transportation policies were defined, and costing information was obtained from onchocerciasis programs. Various scenarios were created to test various state configurations. The actual demand scenarios represented the disease prevalence at IUs according to the ESS, while the counterfactual scenarios (conducted only in the DRC) are based on adapted prevalence estimates to generate prevalence close to the statistical decision thresholds (5% and 2%), to account for variability in field observations. The number of correctly classified implementation units (IUs) per scenario were estimated and key cost drivers were identified. Results: In both Bandundu and Uige, the sites selected based on ESS had high predicted onchocerciasis prevalence >10%. Thus, in the actual demand scenarios in both Bandundu and Uige, the old Ov16 RDT correctly classified all 13 and 11 IUs, respectively, as requiring CDTi. In the counterfactual scenarios in Bandundu, the new RDTs with higher specificity correctly classified IUs more cost effectively. The new RDT with highest specificity (99.8%) correctly classified all 13 IUs. However, very high specificity (e.g., 99.8%) when coupled with imperfect sensitivity, can result in many false negative results (missing decisions to start MDA) at the 5% statistical decision threshold (the decision rule to start MDA). This effect can be negated by reducing the statistical decision threshold to 2%. Across all scenarios, the need for second stage sampling significantly drove program costs upwards. The best performing testing strategies with new RDTs were more expensive than testing with existing tests due to need for second stage sampling, but this was offset by the cost of incorrect classification of IUs. Conclusion: The new RDTs modelled added most value in areas with variable disease prevalence, with most benefit in IUs that are near the statistical decision thresholds. Based on the evaluations in this study, DNO could be used to guide the development of new RDTs based on defined sensitivities and specificities. While test sensitivity is a minor driver of whether an IU is identified as positive, higher specificities are essential. Further, these models could be used to explore the development and optimization of new tools for other neglected tropical diseases.",
        "DOI": "10.3389/fitd.2021.707752",
        "affiliation_name": "Ministry of Health Kinshasa",
        "affiliation_city": "Kinshasa",
        "affiliation_country": "Democratic Republic Congo"
    },
    {
        "paper_title": "MOOR: Model-based Offline Reinforcement Learning for Sustainable Fishery Management",
        "paper_author": "Ju J.",
        "publication": "Proceedings of the International Congress on Modelling and Simulation, MODSIM",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Fisheries play multi-faceted roles in our society, economy, and environment, and the management decisions often involve competing driving forces. The need to account for multiple and possibly objectives make sustainable fishery management a highly challenging task. This is further compounded by the large amount of uncertainties present in the problem: in particular, our knowledge of the fishery system is limited, and the state of the fishery system is not directly observable. The Partially Observable Markov Decision Processes (POMDPs) - a general principled framework for sequential decision making for partially observable environments - is well-suited for sustainable fishery management: it is able to account for the long-term effect of actions, and it can conveniently take uncertainties into account. A few recent works have explored the potential of using POMDPs for sustainable fishery management. In this paper, we leverage recent advances in two sub-fields of machine learning, namely, deep learning and reinforcement learning, to develop a novel approach for sustainable fishery management using POMDPs. We first propose an offline reinforcement learning approach for sustainable fishery management. While typical reinforcement learning approaches learn an optimal policy by directly interacting with the environment, offline reinforcement learning approaches learn an optimal policy using a dataset of past interactions with the environment. The use of past data instead of direct interventions is a highly desirable feature for fishery management - this has been exploited in the literature of management strategy evaluation too. We believe this perspective will allow us to tap into recent advances in offline reinforcement learning. Our second contribution is a new algorithm, MOOR, which stands for MOdel-based Offline Reinforcement learning algorithm for sustainable fishery management. MOOR first learns a POMDP fishery dynamics model using catch and effort data, and then solves the POMDP using a state-of-the-art solver. In the model learning step, we view the POMDP fishery dynamics model as a recurrent neural net (RNN), and leverage RNN learning techniques to learn the model. This presents some new challenges, but we show that these can be overcome with a few tricks to yield a very effective learning algorithm. Finally, MOOR demonstrates strong performance in preliminary simulation studies. The learned models are generally very similar to the true models. In addition, the management policies obtained using the learned models perform similarly as the optimal management policies for the true models. While previous POMDP studies for fishery management evaluate policy performance in the learned model, we evaluate the policy in the true model, thus our results suggest that it is possible to develop a POMDP approach that can be robust against mild model learning error. Moreover, although this paper focuses on fisheries applications, the approach is general enough for other problems where the dynamics are nonlinear, though further research are needed to understand the extent and efficiency of the method on other domains. Our source code will be made available after the publication of the work.",
        "DOI": "NA",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Model Performance Scaling with Multiple Data Sources",
        "paper_author": "Hashimoto T.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Real-world machine learning systems are often trained using a mix of data sources with varying cost and quality. Understanding how the size and composition of a training dataset affect model performance is critical for advancing our understanding of generalization, as well as designing more effective data collection policies. We show that there is a simple scaling law that predicts the loss incurred by a model even under varying dataset composition. Our work expands recent observations of scaling laws for log-linear generalization error in the i.i.d setting and uses this to cast model performance prediction as a learning problem. Using the theory of optimal experimental design, we derive a simple rational function approximation to generalization error that can be fitted using a few model training runs. Our approach can achieve highly accurate (r2 ≈.9) predictions of model performance under substantial extrapolation in two different standard supervised learning tasks and is accurate (r2 ≈.83) on more challenging machine translation and question answering tasks where many baselines achieve worse-than-random performance.",
        "DOI": "NA",
        "affiliation_name": "Microsoft Semantic Machines",
        "affiliation_city": null,
        "affiliation_country": null
    },
    {
        "paper_title": "Accelerate CNNs from Three Dimensions: A Comprehensive Pruning Framework",
        "paper_author": "Wang W.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "41",
        "cover_date": "2021-01-01",
        "Abstract": "Most neural network pruning methods, such as filter-level and layer-level prunings, prune the network model along one dimension (depth, width, or resolution) solely to meet a computational budget. However, such a pruning policy often leads to excessive reduction of that dimension, thus inducing a huge accuracy loss. To alleviate this issue, we argue that pruning should be conducted along three dimensions comprehensively. For this purpose, our pruning framework formulates pruning as an optimization problem. Specifically, it first casts the relationships between a certain model's accuracy and depth/width/resolution into a polynomial regression and then maximizes the polynomial to acquire the optimal values for the three dimensions. Finally, the model is pruned along the three optimal dimensions accordingly. In this framework, since collecting too much data for training the regression is very time-costly, we propose two approaches to lower the cost: 1) specializing the polynomial to ensure an accurate regression even with less training data; 2) employing iterative pruning and fine-tuning to collect the data faster. Extensive experiments show that our proposed algorithm surpasses state-of-the-art pruning algorithms and even neural architecture search-based algorithms.",
        "DOI": "NA",
        "affiliation_name": "State Key Lab of CAD&amp;CG, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "KD3A: Unsupervised Multi-Source Decentralized Domain Adaptation via Knowledge Distillation",
        "paper_author": "Feng H.Z.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "57",
        "cover_date": "2021-01-01",
        "Abstract": "Conventional unsupervised multi-source domain adaptation (UMDA) methods assume all source domains can be accessed directly. However, this assumption neglects the privacy-preserving policy, where all the data and computations must be kept decentralized. There exist three challenges in this scenario: (1) Minimizing the domain distance requires the pairwise calculation of the data from source and target domains, while the data on the source domain is not available. (2) The communication cost and privacy security limit the application of existing UMDA methods, such as the domain adversarial training. (3) Since users cannot govern the data quality, the irrelevant or malicious source domains are more likely to appear, which causes negative transfer. To address the above problems, we propose a privacy-preserving UMDA paradigm named Knowledge Distillation based Decentralized Domain Adaptation (KD3A), which performs domain adaptation through the knowledge distillation on models from different source domains. The extensive experiments show that KD3A significantly outperforms state-of-the-art UMDA approaches. Moreover, the KD3A is robust to the negative transfer and brings a 100× reduction of communication cost compared with other decentralized UMDA methods.",
        "DOI": "NA",
        "affiliation_name": "State Key Lab of CAD&amp;CG, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Model Distillation for Revenue Optimization: Interpretable Personalized Pricing",
        "paper_author": "Biggs M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "19",
        "cover_date": "2021-01-01",
        "Abstract": "Data-driven pricing strategies are becoming increasingly common, where customers are offered a personalized price based on features that are predictive of their valuation of a product. It is desirable for this pricing policy to be simple and interpretable, so it can be verified, checked for fairness, and easily implemented. However, efforts to incorporate machine learning into a pricing framework often lead to complex pricing policies which are not interpretable, resulting in slow adoption in practice. We present a customized, prescriptive tree-based algorithm that distills knowledge from a complex black-box machine learning algorithm, segments customers with similar valuations and prescribes prices in such a way that maximizes revenue while maintaining interpretability. We quantify the regret of a resulting policy and demonstrate its efficacy in applications with both synthetic and real-world datasets.",
        "DOI": "NA",
        "affiliation_name": "Darden School of Business",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Policy Gradient Bayesian Robust Optimization for Imitation Learning",
        "paper_author": "Javed Z.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "The difficulty in specifying rewards for many real-world problems has led to an increased focus on learning rewards from human feedback, such as demonstrations. However, there are often many different reward functions that explain the human feedback, leaving agents with uncertainty over what the true reward function is. While most policy optimization approaches handle this uncertainty by optimizing for expected performance, many applications demand risk-averse behavior. We derive a novel policy gradient-style robust optimization approach, PG-BROIL, that optimizes a soft-robust objective that balances expected performance and risk. To the best of our knowledge, PG-BROIL is the first policy optimization algorithm robust to a distribution of reward hypotheses which can scale to continuous MDPs. Results suggest that PG-BROIL can produce a family of behaviors ranging from risk-neutral to risk-averse and outperforms state-of-the-art imitation learning algorithms when learning from ambiguous demonstrations by hedging against uncertainty, rather than seeking to uniquely identify the demonstrator's reward function.",
        "DOI": "NA",
        "affiliation_name": "College of Engineering and Physical Sciences",
        "affiliation_city": "Durham",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Improved Regret Bound and Experience Replay in Regularized Policy Iteration",
        "paper_author": "Lazić N.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "In this work, we study algorithms for learning in infinite-horizon undiscounted Markov decision processes (MDPs) with function approximation. We first show that the regret analysis of the POLITEX algorithm (a version of regularized policy iteration) can be sharpened from O(T3/4) to O(√T) under nearly identical assumptions, and instantiate the bound with linear function approximation. Our result provides the first high-probability O(√T) regret bound for a computationally efficient algorithm in this setting. The exact implementation of POLITEX with neural network function approximation is inefficient in terms of memory and computation. Since our analysis suggests that we need to approximate the average of the action-value functions of past policies well, we propose a simple efficient implementation where we train a single Q-function on a replay buffer with past data. We show that this often leads to superior performance over other implementation choices, especially in terms of wall-clock time. Our work also provides a novel theoretical justification for using experience replay within policy iteration algorithms.",
        "DOI": "NA",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Leveraging Non-uniformity in First-order Non-convex Optimization",
        "paper_author": "Mei J.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "18",
        "cover_date": "2021-01-01",
        "Abstract": "Classical global convergence results for first-order methods rely on uniform smoothness and the Łojasiewicz inequality. Motivated by properties of objective functions that arise in machine learning, we propose a non-uniform refinement of these notions, leading to Non-uniform Smoothness (NS) and Non-uniform Łojasiewicz inequality (NŁ). The new definitions inspire new geometry-aware first-order methods that are able to converge to global optimality faster than the classical Ω(1/t2) lower bounds. To illustrate the power of these geometry-aware methods and their corresponding non-uniform analysis, we consider two important problems in machine learning: policy gradient optimization in reinforcement learning (PG), and generalized linear model training in supervised learning (GLM). For PG, we find that normalizing the gradient ascent method can accelerate convergence to O(e−c·t) (where c > 0) while incurring less overhead than existing algorithms. For GLM, we show that geometry-aware normalized gradient descent can also achieve a linear convergence rate, which significantly improves the best known results. We additionally show that the proposed geometry-aware gradient descent methods escape landscape plateaus faster than standard gradient descent. Experimental results are used to illustrate and complement the theoretical findings.",
        "DOI": "NA",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Off-Policy Confidence Sequences",
        "paper_author": "Karampatziakis N.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "We develop confidence bounds that hold uniformly over time for off-policy evaluation in the contextual bandit setting. These confidence sequences are based on recent ideas from martingale analysis and are non-asymptotic, non-parametric, and valid at arbitrary stopping times. We provide algorithms for computing these confidence sequences that strike a good balance between computational and statistical efficiency. We empirically demonstrate the tightness of our approach in terms of failure probability and width and apply it to the “gated deployment” problem of safely upgrading a production contextual bandit system.",
        "DOI": "NA",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multi-Agent Training beyond Zero-Sum with Correlated Equilibrium Meta-Solvers",
        "paper_author": "Marris L.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "23",
        "cover_date": "2021-01-01",
        "Abstract": "Two-player, constant-sum games are well studied in the literature, but there has been limited progress outside of this setting. We propose Joint Policy-Space Response Oracles (JPSRO), an algorithm for training agents in n-player, general-sum extensive form games, which provably converges to an equilibrium. We further suggest correlated equilibria (CE) as promising meta-solvers, and propose a novel solution concept Maximum Gini Correlated Equilibrium (MGCE), a principled and computationally efficient family of solutions for solving the correlated equilibrium selection problem. We conduct several experiments using CE meta-solvers for JPSRO and demonstrate convergence on n-player, general-sum games.",
        "DOI": "NA",
        "affiliation_name": "Université Gustave Eiffel",
        "affiliation_city": "Marne-la-Vallee",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Hyperparameter Selection for Imitation Learning",
        "paper_author": "Hussenot L.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "We address the issue of tuning hyperparameters (HPs) for imitation learning algorithms in the context of continuous-control, when the underlying reward function of the demonstrating expert cannot be observed at any time. The vast literature in imitation learning mostly considers this reward function to be available for HP selection, but this is not a realistic setting. Indeed, would this reward function be available, it could then directly be used for policy training and imitation would not be necessary. To tackle this mostly ignored problem, we propose a number of possible proxies to the external reward. We evaluate them in an extensive empirical study (more than 10'000 agents across 9 environments) and make practical recommendations for selecting HPs. Our results show that while imitation learning algorithms are sensitive to HP choices, it is often possible to select good enough HPs through a proxy to the reward function.",
        "DOI": "NA",
        "affiliation_name": "Université de Lille",
        "affiliation_city": "Lille",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Towards Open Ad Hoc Teamwork Using Graph-based Policy Learning",
        "paper_author": "Rahman A.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "31",
        "cover_date": "2021-01-01",
        "Abstract": "Ad hoc teamwork is the challenging problem of designing an autonomous agent which can adapt quickly to collaborate with teammates without prior coordination mechanisms, including joint training. Prior work in this area has focused on closed teams in which the number of agents is fixed. In this work, we consider open teams by allowing agents with different fixed policies to enter and leave the environment without prior notification. Our solution builds on graph neural networks to learn agent models and joint-action value models under varying team compositions. We contribute a novel action-value computation that integrates the agent model and joint-action value model to produce action-value estimates. We empirically demonstrate that our approach successfully models the effects other agents have on the learner, leading to policies that robustly adapt to dynamic team compositions and significantly outperform several alternative methods.",
        "DOI": "NA",
        "affiliation_name": "The University of Edinburgh",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Muesli: Combining Improvements in Policy Optimization",
        "paper_author": "Hessel M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "24",
        "cover_date": "2021-01-01",
        "Abstract": "We propose a novel policy update that combines regularized policy optimization with model learning as an auxiliary loss. The update (henceforth Muesli) matches MuZero's state-of-the-art performance on Atari. Notably, Muesli does so without using deep search: it acts directly with a policy network and has computation speed comparable to model-free baselines. The Atari results are complemented by extensive ablations, and by additional results on continuous control and 9x9 Go.",
        "DOI": "NA",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Data-efficient Hindsight Off-policy Option Learning",
        "paper_author": "Wulfmeier M.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "20",
        "cover_date": "2021-01-01",
        "Abstract": "We introduce Hindsight Off-policy Options (HO2), a data-efficient option learning algorithm. Given any trajectory, HO2 infers likely option choices and backpropagates through the dynamic programming inference procedure to robustly train all policy components off-policy and end-to-end. The approach outperforms existing option learning methods on common benchmarks. To better understand the option framework and disentangle benefits from both temporal and action abstraction, we evaluate ablations with flat policies and mixture policies with comparable optimization. The results highlight the importance of both types of abstraction as well as off-policy training and trust-region constraints, particularly in challenging, simulated 3D robot manipulation tasks from raw pixel inputs. Finally, we intuitively adapt the inference step to investigate the effect of increased temporal abstraction on training with pre-trained options and from scratch.",
        "DOI": "NA",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Lightweight Inspection of Data Preprocessing in Native Machine Learning Pipelines",
        "paper_author": "Grafberger S.",
        "publication": "11th Annual Conference on Innovative Data Systems Research, CIDR 2021",
        "citied_by": "17",
        "cover_date": "2021-01-01",
        "Abstract": "Machine Learning (ML) is increasingly used to automate impactful decisions, and the risks arising from this wide-spread use are garnering attention from policy makers, scientists, and the media. ML applications are often very brittle with respect to their input data, which leads to concerns about their reliability, accountability, and fairness. In this paper we discuss such hard-to-identify data issues and describe mlinspect, a library that enables lightweight lineage-based inspection of ML preprocessing pipelines. The key idea is to extract a directed acyclic graph representation of the dataflow from ML preprocessing pipelines in Python, and to use this representation to automatically instrument the code with predefined inspections based on a lightweight annotation propagation approach. In contrast to existing work, mlinspect operates on declarative abstractions of popular data science libraries like estimator/transformer pipelines and does not require manual code instrumentation. We discuss the design and implementation of the mlinspect prototype, and give a complex end-to-end example that illustrates its functionality.",
        "DOI": "NA",
        "affiliation_name": "New York University",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Asian Conference on Machine Learning, ACML 2021",
        "paper_author": "NA",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 114 papers. The topics discussed include: vector transport free Riemannian LBFGS for optimization on symmetric positive definite matrix manifolds; understanding how over-parametrization leads to acceleration: a case of learning a single teacher neuron; hybrid estimation for open-ended questions with early-age students’ block-based programming answers; the power of factorial powers: new parameter settings for (stochastic) optimization; local aggressive adversarial attacks on 3D point cloud; fairness constraint of fuzzy C-means clustering improves clustering fairness; meta-model-based meta-policy optimization; an aligned subgraph kernel based on discrete-time quantum walk; encoder-decoder-based image transformation approach for integrating precipitation forecasts; a mutual information regularization for adversarial training; quaternion graph neural networks; sinusoidal flow: a fast invertible autoregressive flow; iterative deep model compression and acceleration in the frequency domain; and penalty method for inversion-free deep bilevel optimization.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Research and development for increased application of data science in sustainability analysis",
        "paper_author": "Dunn J.B.",
        "publication": "Data Science Applied to Sustainability Analysis",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "This chapter summarizes research needs in developing and enhancing data sets, data sources, and data science methods for applying data science to the broad field of sustainability. Overall, while there is a great need to develop environmental science, manufacturing and technology systems, and societal systems data at greater spatial and temporal resolution, there is also a need to consider what sustainability questions can be addressed by creative use of the data sets currently available. Furthermore, advances in data science remain foundational to realizing the potential of many techniques (including machine learning, artificial intelligence) to enhancing environmental and societal sustainability. Advances in explainable AI, edge computing, and applying the advantages of the 5G technology that is on the horizon are all required. Importantly, engagement of multiple disciplines - particularly computer science - along with multiple science and engineering disciplines will be foundational to bringing the power of data science methods to bear on the pressing sustainability challenges.",
        "DOI": "10.1016/B978-0-12-817976-5.00014-0",
        "affiliation_name": "Robert R. McCormick School of Engineering and Applied Science",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Soil Organic Carbon: Past, Present, and Future Research",
        "paper_author": "Chappell E.",
        "publication": "Soil Science: Fundamentals to Recent Advances",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Maintaining soil health is critical to meet agricultural production demands. Soil health is the capability of soil to function as a living system within an ecosystem, to support production, to maintain or enhance water and air quality, and to promote plant/animal health. Soil organic carbon (SOC) is the backbone of soil health. Intensive agricultural management has led to a reduction of SOC globally. Scientific communities, along with the policy makers and different stakeholders, have been putting enormous efforts in improving and maintaining SOC stocks in the quest of achieving agricultural sustainability to meet the demand of ever-increasing population. Also, the potential of soil to sequester carbon as a climate change mitigation strategy, has led climate and soil scientists in performing ground-breaking research focusing on SOC. Thus, this book chapter focuses on the importance of SOC on soil health, strategies to improve it, the past and ongoing research on SOC, and the future direction of estimating SOC.",
        "DOI": "10.1007/978-981-16-0917-6_3",
        "affiliation_name": "Ontario Agricultural College",
        "affiliation_city": "Guelph",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Learning-based feedforward augmentation for steady state rejection of residual dynamics on a nanometer-accurate planar actuator system",
        "paper_author": "Proimadis I.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Growing demands in the semiconductor industry result in the need for enhanced performance of lithographic equipment. However, position tracking accuracy of high precision mechatronics is often limited by the presence of disturbance sources, which originate from unmodelled or unforeseen deterministic environmental effects. To negate the effects of these disturbances, a learning based feedforward controller is employed, where the underlying control policy is estimated from experimental data based on Gaussian Process regression. The proposed approach exploits the property of including prior knowledge on the expected steady state behaviour of residual dynamics in terms of kernel selection. Corresponding hyper-parameters are optimized using the maximization of the marginalized likelihood. Consequently, the learned function is employed as augmentation of the currently employed rigid body feedforward controller. The effectiveness of the augmentation is experimentally validated on a magnetically levitated planar motor stage. The results of this paper demonstrate the benefits and possibilities of machine-learning based approaches for compensation of static effects, which originate from residual dynamics, such that position tracking performance for moving-magnet planar motor actuators is improved.",
        "DOI": "NA",
        "affiliation_name": "Technische Universiteit Eindhoven",
        "affiliation_city": "Eindhoven",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Revenue-Incentive Tradeoffs in Dynamic Reserve Pricing",
        "paper_author": "Deng Y.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Online advertisements are primarily sold via repeated auctions with reserve prices. In this paper, we study how to set reserves to boost revenue based on the historical bids of strategic buyers, while controlling the impact of such a policy on the incentive compatibility of the repeated auctions. Adopting an incentive compatibility metric which quantifies the incentives to shade bids, we propose a novel class of dynamic reserve pricing policies and provide analytical tradeoffs between their revenue performance and bid-shading incentives. The policies are inspired by the exponential mechanism from the literature on differential privacy, but our study uncovers mechanisms with significantly better revenue-incentive tradeoffs than the exponential mechanism in practice. We further empirically evaluate the tradeoffs on synthetic data as well as real ad auction data from a major ad exchange to verify and support our theoretical findings.",
        "DOI": "NA",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Connected and Autonomous Vehicles: Priorities for Policy and Planning",
        "paper_author": "Nikitas A.",
        "publication": "International Encyclopedia of Transportation: Volume 1-7",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Connected and Autonomous Vehicles (CAVs) is a paradigm-shifting mobility technology that will redefine the urban landscapes of the future by employing the immense capabilities of Artificial Intelligence, Machine Learning and wireless connectivity. Despite great technological breakthroughs orchestrated by the automotive industry and millions of autopiloted road miles traveled in segregated environments and living lab conditions the road to a full-scale implementation is significantly longer and harder that many might anticipate. This is because CAVs is not a simple techno-fix but rather a complex piece of a diverse socio-technical transition to an unprecedented smart mobility paradigm that still needs to prioritize people over machines. Policy and planning need to be seriously reviewed, redesigned and rebranded to incorporate effectively CAVs before these can fulfill their destiny as genuine game-changers in hopefully improving the standard of mobility provision. This paper provides a roadmap of the opportunities and challenges that reflect and affect the policy and planning of CAVs highlighting 10 priority areas namely: technology; legislation; crisis and employment ethics; infrastructure and land use; integration; traffic safety; cyber security and privacy; business models; traffic congestion and travel behavior; and finally acceptability, trust and customer readiness.",
        "DOI": "10.1016/B978-0-08-102671-7.10636-0",
        "affiliation_name": "Huddersfield Business School",
        "affiliation_city": "Huddersfield",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "On Relations Between Education and Machines",
        "paper_author": "Liu F.",
        "publication": "Educational Research in China: Articles from Educational Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "In the data era when the Fourth Industrial Revolution is quickly progressing, the pedagogy must consider the relations between education and machines as an intermediary when studying the relationship between education and humanity, as well as the relationship between education and social development. The subject should be based on ontology and axiology, as machines and their evolution have become a part of human and societal development. Machines become integral to teaching and learning; meanwhile, the reform of the educational structure relies on a revolution of artificial intelligence (AI) technologies. Schools are becoming a new type of social organization that connects everything when the development of machines and education limit one another. Such changes entail reforms of pedagogy as well as the promotion of a new concept of education. There should be a theoretical system supported by data and information, and a policy system consisting of artificial intelligence and education.",
        "DOI": "10.1007/978-981-16-1520-7_3",
        "affiliation_name": "Renmin University of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Future of the aging brain: Bridging the gap between research and policy",
        "paper_author": "Di Luca M.",
        "publication": "Aging Brain",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "NA",
        "DOI": "10.1016/j.nbas.2020.100002",
        "affiliation_name": "Università degli Studi di Milano",
        "affiliation_city": "Milan",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Incidence of Arterial Hypertension in People With Periodontitis and Characterization of the Oral and Subgingival Microbiome: A Study Protocol",
        "paper_author": "Martínez-García M.",
        "publication": "Frontiers in Cardiovascular Medicine",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Cardiovascular diseases are the leading cause of morbidity and mortality worldwide. High blood pressure in particular, continues to increase throughout the global population at an increasingly fast pace. The relationship between arterial hypertension and periodontitis has been recently discussed in the context of its origins and implications. Particularly relevant is the role of the periodontal microbiome linked to persistent local and systemic inflammation, along with other risk factors and social determinants of health. The present protocol will investigate/assess the association between periodontal disease and its microbiome on the onset of hypertension, within a cohort from Mexico City. One thousand two hundred twelve participants will be studied during a 60-month period. Studies will include analysis of periodontal conditions, sampling and sequencing of the salivary and subgingival microbiome, interviews on nutritional and lifestyle habits, social determinants of health, blood pressure and anthropometric measurements. Statistical associations and several classic epidemiology and machine learning approaches will be performed to analyze the data. Implications for the generation of public policy—by early public health interventions or epidemiological surveillance approaches—and for the population empowerment—via the establishment of primary prevention recommendations, highlighting the relationship between oral and cardiovascular health—will be considered. This latter set of interventions will be supported by a carefully planned science communication and health promotion strategy. This study has been registered and approved by the Research and Ethics Committee of the School of Dentistry, Universidad Nacional Autónoma de México (CIE/0308/05/2019) and the National Institute of Genomic Medicine (CEI/2020/12). The umbrella cohort was approved by the Institutional Bioethics Committee of the National Institute of Cardiology-Ignacio Chavez (INC-ICh) under code 13-802.",
        "DOI": "10.3389/fcvm.2021.763293",
        "affiliation_name": "Instituto Nacional de Geriatría",
        "affiliation_city": "Mexico",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Combining Process Tracing and Policy Capturing Techniques for Judgment Analysis in an Anti-Submarine Warfare Simulation",
        "paper_author": "Labonté K.",
        "publication": "Proceedings of the Human Factors and Ergonomics Society",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The Cognitive Shadow is a prototype decision support tool that can notify users when they deviate from their usual judgment pattern. Expert decision policies are learned automatically online while performing one’s task using a combination of machine learning algorithms. This study investigated whether combining this system with the use of a process tracing technique could improve its ability to model human decision policies. Participants played the role of anti-submarine warfare commanders and rated the likelihood of detecting a submarine in different ocean areas based on their environmental characteristics. In the process tracing condition, participants were asked to reveal only the information deemed necessary, and only that information was sent to the system for model training. In the control condition, all the available information was sent to the system with each decision. Results showed that process tracing data improved the model’s ability to predict human decisions compared to the control condition.",
        "DOI": "10.1177/1071181321651113",
        "affiliation_name": "Université Laval",
        "affiliation_city": "Quebec",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A Study on the Application of Deep Learning Models for Real-time Defect Detection in the Manufacturing Process - Cases of Defect detection in the Label Printing Process -",
        "paper_author": "Son J.H.",
        "publication": "Palpu Chongi Gisul/Journal of Korea Technical Association of the Pulp and Paper Industry",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The global smart manufacturing market is growing rapidly as developed countries (Germany, USA, Japan) as well as late comers such as China are now recognizing the importance of “smart manufacturing” and promoting active policies to foster related ecosystems. Policies to revitalize manufacturing through the convergence of cutting-edge ICT and manufacturing technology are already in progress. Some such policies include Industry 4.0, the Advanced Manufacturing Partnership of the United States, Japan’s Industrial Revitalization Plan, and China’s Made in China 2025. As a result of the gradual shift from product standardization to product customization, the importance of machine vision in manufacturing has also been increasing. However, it is difficult to develop a standard machine vision method because there are different specifications for meeting the individual demands of different manufacturing industries. Moreover, it is difficult to apply such a standard machine vision method to artificial intelligence because defective data for learning in the manufacturing industry are not frequently generated and stored. Therefore, it is conducted manually or visually inspected by workers. This study applies the primary feature of matching models for a label printing process to efficiently detect defects with high performance and applies a deep learning model to maximize performance. Our proposed method achieved an accuracy of 97% with a feature matching model and 99.8% accuracy with the deep learning model.",
        "DOI": "10.7584/JKTAPPI.2021.10.53.5.74",
        "affiliation_name": "Yonsei University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Using Machine Learning Techniques to Explore Extra-Role Security Behavior",
        "paper_author": "Frank M.",
        "publication": "42nd International Conference on Information Systems, ICIS 2021 TREOs: \"Building Sustainability and Resilience with IS: A Call for Action\"",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Many contemporary organizations pit on information security policy compliance to combat information security threats originating from their own workforce. However, recent findings suggest that employees’ adherence to security rules and regulations alone is insufficient to protect organizational assets. Instead, extra-role security behavior – actions that go beyond what is specified in policies and are beneficial to the firms – is needed. So far, research with regard to extra-role security behavior is meager, in particular concerning contextual determinants influencing whether employees exhibit prosocial behaviors or not. Hence, this paper uses predictive modeling, or more precisely supervised machine learning, to classify employees according to their likelihood of exhibiting extra-role security behaviors. Results indicate that informational, social, and task context factors significantly impact the performance of extra-role security behavior.",
        "DOI": "NA",
        "affiliation_name": "Goethe-Universität Frankfurt am Main",
        "affiliation_city": "Frankfurt am Main",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Artificial Intelligence Strategies and Their Impact on Economic Stability: Conceptual Framework",
        "paper_author": "Serova E.",
        "publication": "3rd European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Understanding the exceptional role of intelligent technologies and systems in the new digital economy has given rise to a new technological race - artificial intelligence. In emerging markets, artificial intelligence and intelligent technologies are, in fact, an integral part of cutting-edge management systems. They add to the globalization of business by providing quick access to employees, customers, and partners worldwide, as well as coordinating global interaction between companies at different stages of the value chain. It does not mean that intelligent technologies and systems simply increase the efficiency of a company's operations; they can be considered as a key intangible asset. The AI strategy is defined as a set of coordinated policies that have a clear objective of maximizing the potential benefits and minimizing the potential costs of AI for the economy and society. In the past few years, two dozen countries have launched their national strategies in the field of artificial intelligence. Many countries have already developed their AI strategy at the official level during the last 3 years. The main goal of this paper is the analysis of the emerging market multinational enterprises (EMNEs) AI strategies to support the emergent economy and identify key AI strategies development directions. The research is based on the analysis of large volumes of information, the author's own experience, and literature review that includes the latest findings in this field. Research Methodology includes a systematic approach, comparative analysis, case-study, and modeling. The problem the author considers here is: How can we reduce the impact of risks and uncertainty on the economic stability with the help of AI and how the emerging market multinational enterprises (EMNEs)' AI Strategies have already been successfully using the AI Strategies in the past fifteen years? The findings of the research are based on providing a framework for assessing the role of EMNEs' AI strategy and Machine Learning model for EMNE's strategy selection.",
        "DOI": "10.34190/EAIR.21.021",
        "affiliation_name": "HSE University",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Comparing Physics Effects through Reinforcement Learning in the ARORA Simulator",
        "paper_author": "Thomas T.",
        "publication": "European Modeling and Simulation Symposium, EMSS",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "By testing various physics levels for training autonomous-vehicle navigation using a deep deterministic policy gradient algorithm, the present study fills a lack of research on the impact of physics levels for vehicle behaviour, specifically for reinforcement-learning algorithms. Measures from a PointGoal Navigation task were investigated: simulator run-time, training steps, and agent effectiveness through the Success weighted by (normalised inverse) Path Length (SPL) measure. Training and testing occurred in the novel simulator ARORA, or A Realistic Open environment for Rapid Agent training. The goal of ARORA is to provide a high-fidelity, open-source platform for simulation, using physics-based movement, vehicle modelling, and a continuous action space within a large-scale geospecific city environment. Using four physics levels, or models, to create four different curriculum conditions for training, the SPL was highest for the condition using all physics levels defined for the experiment, with two conditions returning zero values. Future researchers should consider providing adequate support when training complex-physics vehicle models. The run-time results revealed a benefit for experimental machines with a better CPU, at least for the vector-only observations we employed.",
        "DOI": "10.46354/i3m.2021.emss.015",
        "affiliation_name": "University of Central Florida",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Challenges of Adversarial Image Augmentations",
        "paper_author": "Blaas A.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Image augmentations applied during training are crucial for the generalization performance of image classifiers. Therefore, a large body of research has focused on finding the optimal augmentation policy for a given task. Yet, RandAugment [2], a simple random augmentation policy, has recently been shown to outperform existing sophisticated policies. Only Adversarial AutoAugment (AdvAA) [11], an approach based on the idea of adversarial training, has shown to be better than RandAugment. In this paper, we show that random augmentations are still competitive compared to an optimal adversarial approach, as well as to simple curricula, and conjecture that the success of AdvAA is due to the stochasticity of the policy controller network, which introduces a mild form of curriculum.",
        "DOI": "NA",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Overview of data science and sustainability analysis",
        "paper_author": "Balaprakash P.",
        "publication": "Data Science Applied to Sustainability Analysis",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Globally, challenges related to sustainability abound, including improving air and water quality, reducing food and water consumption, decreasing waste, enhancing energy efficiency and the share of renewable energy, and conserving ecologically valuable lands. One of the most pressing sustainability-related challenges is reducing greenhouse gas emissions that contribute to climate change while developing environmentally-sound adaptation strategies. Simultaneously, advancing the societal aspect of sustainability is critical, but challenging as large portions of the world’s population live below the International Poverty Line. Data science, including different statistical machine learning techniques, is a tool that will see increasing use in efforts to tackle sustainability challenges. Leveraging the growing volumes of data such as satellite imagery, continuous sensor data from industrial processes, social media data, and data from environmental sensors, requires such techniques. This book provides case studies and examples at the intersection of data science and sustainability in the areas of environmental quality and sustainability, energy and water, sustainable systems analysis, and society and policy.",
        "DOI": "10.1016/B978-0-12-817976-5.00001-2",
        "affiliation_name": "Robert R. McCormick School of Engineering and Applied Science",
        "affiliation_city": "Evanston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Obstacles Avoidance of Self-driving Vehicle using Deep Reinforcement Learning",
        "paper_author": "Radwan M.O.",
        "publication": "31st International Conference on Computer Theory and Applications, ICCTA 2021 - Proceedings",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Nowadays, there exist different self-driving vehicle functions that allow the vehicle to perform certain actions by itself while the driver is only monitoring it. However, it is difficult in real world to acquire training data for self-driving artificial intelligence algorithms because there are a lot of risks and the need of labeled data. This paper proposes a method to collect training data from Unity game engine's Machine Learning Toolkit (ML-Agents Toolkit). With this toolkit, Unity allows its users to incorporate Reinforcement Learning (RL) algorithms to train a learning agent. The aim of this paper is to search for the best RL algorithm in order to train the self-driving vehicle to avoid obstacles in a 3D environment. For all study cases, the learning was done by using the two RL learning algorithms Proximal Policy Optimization algorithm (PPO) and Soft Actor-Critic (SAC) algorithm, both using single-instance and multi-instance training. In the data collection from virtual environment to learn, two types of sensors in comparison had been experimented using camera sensors and Light Detection and Ranging (LiDaR) sensors. The results of the research show the advantages and limitations of the used learning algorithms for learning behaviors, the importance of the demonstration provided for the learning algorithms. Experimental results for applying the virtual driving data to drive a vehicle shows the effectiveness of the proposed methodology.",
        "DOI": "10.1109/ICCTA54562.2021.9916640",
        "affiliation_name": "College of Computing and Information Technology",
        "affiliation_city": "Alexandria",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Strength Through Diversity: Robust Behavior Learning via Mixture Policies",
        "paper_author": "Seyde T.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Efficiency in robot learning is highly dependent on hyperparameters. Robot morphology and task structure differ widely and finding the optimal setting typically requires sequential or parallel repetition of experiments, strongly increasing the interaction count. We propose a training method that only relies on a single trial by enabling agents to select and combine controller designs conditioned on the task. Our Hyperparameter Mixture Policies (HMPs) feature diverse sub-policies that vary in distribution types and parameterization, reducing the impact of design choices and unlocking synergies between low-level components. We demonstrate strong performance on continuous control tasks, including a simulated ANYmal robot, showing that HMPs yield robust, data-efficient learning.2",
        "DOI": "NA",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A Gaussian Process Approach for Predictive Maintenance",
        "paper_author": "Zeng J.",
        "publication": "Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "With the wide application of sensing technologies, predicting the remaining useful life (RUL) of assets through machine learning algorithms becomes possible, and the predicted RUL can further guide maintenance decision making. Amongst machine learning algorithms, deep learning can provide high-precision RUL predictions and has become a prevalent approach. However, most of deep learning approaches only predict the expected RUL, which is insufficient in practice. In this paper, we propose a Gaussian process (GP) approach to predict the expected RUL and estimate the associated variance. To realize a complete framework of PdM, enabled by the predicted RUL distribution, a dynamic reliability-oriented maintenance policy is obtained, and several metrics are proposed to evaluate the performance. The overall approach is tested on the C-MAPSS dataset.",
        "DOI": "10.1109/QRS-C55045.2021.00113",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Curious SDN for network attack mitigation",
        "paper_author": "Zolotukhin M.",
        "publication": "Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The increasing number of connected IoT devices in recent years has led to a significant growth in the volume of cyber attack instances. Since the IoT devices include home automation sensors, medical equipment, vehicular sensors, nuclear reactors and life-critical real-time sensing devices, lack of security in IoT can pose a risk to human lives. In this study, we focus on the problem of attack detection and mitigation with the help of recently emerging reinforcement machine learning which has already demonstrated excellent suitability for several cyber security applications. In particular, we are implementing an intelligent agent which manipulates network security policies depending on the current state of the environment. These manipulations include pushing software-defined networking flows to the network controller as well as adjusting detection sensitivity of security appliances used for intrusion and anomaly detection. To encourage the environment exploration, the agent is provided with an intrinsic curiosity reward signal based on how hard it is for the agent to predict the consequences of its own actions. We evaluate the resulting framework against several attack scenarios using realistic network traffic datasets and the simulation results confirmed the viability of the approach proposed.",
        "DOI": "10.1109/QRS-C55045.2021.00096",
        "affiliation_name": "University of Jyväskylä",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Big Data Analysis on Global Community Formation and Isolation: Sustainability and Flow of Commodities, Money, and Humans",
        "paper_author": "Ikeda Y.",
        "publication": "Big Data Analysis on Global Community Formation and Isolation: Sustainability and Flow of Commodities, Money, and Humans",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "In this book, the authors analyze big data on global interdependence caused by the flows of commodities, money, and people, using a network science approach to obtain differing views of globalization and to clarify the facts on isolation of communities. Globalization reduces international economic inequality, i.e., it allows emerging countries to catch up while it increases relative poverty in some advanced countries. How should this trade-off between international and domestic inequalities be resolved? At the same time, the reduction of biocultural diversity caused by globalization needs to be avoided. What kind of change is required in local communities to conserve biocultural diversity? On the issue of commodity flow, research results of the supply-chain network, isolation in industry, and resource flows and stocks are presented in this book. For monetary flow, ownership networks, value-added networks, and profit shifting were studied; and regarding the flow of people, linkage of ethnic groups, immigrant assimilation, and refugees were examined. Based on the resulting view of globalization and isolation, the development of the isolation index using machine learning is discussed. Finally, recommendations for evidence-based policymaking in the United Nations are considered.",
        "DOI": "10.1007/978-981-15-4944-1",
        "affiliation_name": "Graduate School of Advanced Integrated Studies in Human Survivability",
        "affiliation_city": "Kyoto",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Self-Supervised Learning of Long-Horizon Manipulation Tasks with Finite-State Task Machines",
        "paper_author": "Liang J.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "We consider the problem of a robot learning to manipulate unknown objects while using them to perform a complex task that is composed of several sub-tasks. The robot receives 6D poses of the objects along with their semantic labels, and executes nonprehensile actions on them. The robot does not receive any feedback regarding the task until the end of an episode, where a binary reward indicates success or failure in performing the task. Moreover, certain attributes of objects cannot be always observed, so the robot needs to learn to remember pertinent past actions that it executed. We propose to solve this problem by simultaneously learning a low-level control policy and a high-level finite-state task machine that keeps track of the progress made by the robot in solving the various sub-tasks and guides the low-level policy. Several experiments in simulation clearly show that the proposed approach is efficient at solving complex robotic tasks without any supervision.",
        "DOI": "NA",
        "affiliation_name": "Robotics Lab",
        "affiliation_city": "New Brunswick",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning Matching Representations for Individualized Organ Transplantation Allocation",
        "paper_author": "Xu C.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Organ transplantation is often the last resort for treating end-stage illness, but the probability of a successful transplantation depends greatly on compatibility between donors and recipients. Current medical practice relies on coarse rules for donor-recipient matching, but is short of domain knowledge regarding the complex factors underlying organ compatibility. In this paper, we formulate the problem of learning data-driven rules for organ matching using observational data for organ allocations and transplant outcomes. This problem departs from the standard supervised learning setup in that it involves matching the two feature spaces (i.e., donors and recipients), and requires estimating transplant outcomes under counterfactual matches not observed in the data. To address these problems, we propose a model based on representation learning to predict donor-recipient compatibility; our model learns representations that cluster donor features, and applies donor-invariant transformations to recipient features to predict outcomes for a given donor-recipient feature instance. Experiments on semi-synthetic and real-world datasets show that our model outperforms state-of-art allocation methods and policies executed by human experts.",
        "DOI": "NA",
        "affiliation_name": "The Alan Turing Institute",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Detection of Money Laundering in Bitcoin Transactions",
        "paper_author": "Al Badawi A.",
        "publication": "IET Conference Proceedings",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "Combating Money laundering through cryptocurrencies has become a more challenging task due to the inherent anonymity of cryptocurrency transactions and the absence of centralized control authorities to apply known defensive laws and policies such as Know Your Customer (KYC) and Know Your Business (KYB) measures. This has led to an increase in number of cybercrimes that involve cryptocurrency as a payment method for illicit acts and a way to hide sources of dirty money. Therefore, researchers have been discovering new anti-money laundry detection and prevention techniques to combat these cybercrimes. In this work, we present an efficient anti-money laundry system that analyzes the transactions of cryptocurrency to learn data patterns that can identify licit and illicit transactions. Our system utilizes known machine learning mechanisms such as shallow neural networks and decision trees to construct the classification models. Without loss of generality, we evaluate our system on a recent bitcoin anti-money laundry dataset, the elliptic dataset, and use the classification accuracy as a performance indicator. Our analysis shows that shallow neural networks and decision trees achieve classification accuracy capped at 89.9% and 93.4%, respectively.",
        "DOI": "10.1049/icp.2022.0387",
        "affiliation_name": "Rabdan Academy",
        "affiliation_city": "Abu Dhabi",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Empowering the One Health approach and health resilience with digital technologies across OECD countries: the case of COVID-19 pandemic",
        "paper_author": "Papadopoulou P.",
        "publication": "Artificial Intelligence and Big Data Analytics for Smart Healthcare",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "The coronavirus disease 2019 (COVID-19) pandemic has already led to a dramatic loss of human life and has negatively affected the well-being of people, including numerous sectors such as health, work, economy, culture, as well as education. This kind of disruption not only has raised many concerns but it has also forced humans to interdisciplinary collaborations to fast find smart solutions if not an effective therapy and/or successful vaccines. Digital transformation is a main driver toward finding smart solutions often based on artificial intelligence and information communication technologies such as big data analytics and machine learning, combined with mainly the recent advancements in molecular biology, bioinformatics, and pharmacology as well as in areas related to health-care policies. This chapter examines ways of empowering the One Health approach and health resilience with digital technologies across Organisation for Economic Co-operation and Development countries using as a case study the COVID-19 pandemic. It also offers smart solutions and a framework on digital technologies that strengthen health systems, as illustrated by the fast deployment of various digital tools and resilient solutions that have allowed countries to better detect and prevent the spread of the disease and to effectively respond to the pandemic.",
        "DOI": "10.1016/B978-0-12-822060-3.00012-7",
        "affiliation_name": "Effat University",
        "affiliation_city": "Jeddah",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Artificial Intelligence and Big Data Analytics for Smart Healthcare",
        "paper_author": "Lytras M.D.",
        "publication": "Artificial Intelligence and Big Data Analytics for Smart Healthcare",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial Intelligence and Big Data Analytics for Smart Healthcare serves as a key reference for practitioners and experts involved in healthcare as they strive to enhance the value added of healthcare and develop more sustainable healthcare systems. It brings together insights from emerging sophisticated information and communication technologies such as big data analytics, artificial intelligence, machine learning, data science, medical intelligence, and, by dwelling on their current and prospective applications, highlights managerial and policymaking challenges they may generate. The book is split into five sections: big data infrastructure, framework and design for smart healthcare; signal processing techniques for smart healthcare applications; business analytics (descriptive, diagnostic, predictive and prescriptive) for smart healthcare; emerging tools and techniques for smart healthcare; and challenges (security, privacy, and policy) in big data for smart healthcare. The content is carefully developed to be understandable to different members of healthcare chain to leverage collaborations with researchers and industry.",
        "DOI": "10.1016/C2019-0-03287-6",
        "affiliation_name": "Effat University",
        "affiliation_city": "Jeddah",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Deeply-Debiased Off-Policy Interval Estimation",
        "paper_author": "Shi C.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "18",
        "cover_date": "2021-01-01",
        "Abstract": "Off-policy evaluation learns a target policy's value with a historical dataset generated by a different behavior policy. In addition to a point estimate, many applications would benefit significantly from having a confidence interval (CI) that quantifies the uncertainty of the point estimate. In this paper, we propose a novel deeply-debiasing procedure to construct an efficient, robust, and flexible CI on a target policy's value. Our method is justified by theoretical results and numerical experiments. A Python implementation of the proposed procedure is available at https://github.com/RunzheStat/D2OPE.",
        "DOI": "NA",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Stabilization of Imbalance between the Naira and the Dollar Using Game Theory and Machine Learning Techniques",
        "paper_author": "Aliyu G.",
        "publication": "Industry 4.0 Technologies for Business Excellence: Frameworks, Practices, and Applications",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The instability of Naira against foreign currencies has been a major setback sabotaging the revival process of stabilizing the country’s economy. This is coming because of the high importation of goods that necessitated having an exchange of Naira with other foreign currencies, particularly the Dollar. Nigerian economy solely relies on the exportation of crude oil. However, Nigeria imports refined petroleum products for internal consumption, which requires the use of billions of dollars. Moreover, there is no strike balance between what import from and export to foreign countries. The stabilization of Nigeria will help strengthen the country’s economy by making the right policy decision. Such a decision encompasses the domestic refining of crude oil and exploration of other means such as the Industrial Revolution, Agricultural Sector, and Information Technology & Computing, among others. Because of fluctuation of Naira, foreign investors are scared of coming to invest. Moreover, even some citizens they rather invest outside Nigeria than to invest locally. This paper proposes the conceptual model using Game Theory and Machine Learning to address the aforementioned challenges. The game theory will be used to resolve the conflict between the Naira and other foreign currencies for the stability of Naira and machine learning to build a model that will predict the possibility of appreciation or depreciation of Naira based on the government’s policy put in place.",
        "DOI": "10.1201/9781003140474-9",
        "affiliation_name": "American University of Nigeria",
        "affiliation_city": "Yola",
        "affiliation_country": "Nigeria"
    },
    {
        "paper_title": "Recent Advances in Land Surface Phenology Estimation with Multispectral Sensing",
        "paper_author": "Soubry I.",
        "publication": "International Conference on Geographical Information Systems Theory, Applications and Management, GISTAM - Proceedings",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Vegetation phenology refers to changes in seasonal patterns of vegetation cycles, such as flowering and leaf fall, influenced by annual and seasonal fluctuations of biotic and abiotic drivers. Information about phenology is crucial for unravelling the underlying biological processes across vegetation communities in space and time. It is also important for ecosystem and resources management, conservation, restoration, policy and decision-making on local, national, and global scales. Numerous approaches to register Land Surface Phenology (LSP) appeared since Earth Observation from space became possible a few decades ago. This paper attempts to capture current progress and new capacities that arose with the advent of the free data policy, the Sentinel-era, new multispectral satellite sensors, cloud computing, and machine learning in LSP for natural and semi-natural environments. Spaceborne sensors' capacity to capture LSP, data fusion, and synergies are discussed. Information about retrieval methods through open-source tools and global LSP products and phenology networks are presented.",
        "DOI": "10.5220/0010555801340145",
        "affiliation_name": "Centre for Research and Technology-Hellas",
        "affiliation_city": "Thessaloniki",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "Emerging Trends in Transport Demand Modeling in the Transition Toward Shared Mobility and Autonomy",
        "paper_author": "Franco P.",
        "publication": "International Encyclopedia of Transportation: Volume 1-7",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Multimodality and attitudes toward sharing will affect how people travel in the future. Shared mobility has the potential to enable the Mobility as a Service (MaaS) vision, however, there is a lack of understanding around the drivers allowing people to share and no best practice is available to assess the performance of the services and their impact on public transport. New methodologies are emerging to consider the end-to-end users’ journey, multimodality, shared mobility and autonomous services. Moreover, the role of big data and new data sources, integrated with data fusion processes and machine learning, have increased the spatial and temporal granularity of next generation demand models. This chapter will explore how demand models are changing in the transition towards flexibility and autonomy and the new methodologies to include new big data sources in the development of large-scale demand models for supporting urban and rural mobility policy interventions.",
        "DOI": "10.1016/B978-0-08-102671-7.10769-9",
        "affiliation_name": "Connected Places Catapult",
        "affiliation_city": "Milton Keynes",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Reward Prediction for Representation Learning and Reward Shaping",
        "paper_author": "Hlynsson H.D.",
        "publication": "ICETE International Conference on E-Business and Telecommunication Networks (International Joint Conference on Computational Intelligence)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "One of the fundamental challenges in reinforcement learning (RL) is the one of data efficiency: modern algorithms require a very large number of training samples, especially compared to humans, for solving environments with high-dimensional observations. The severity of this problem is increased when the reward signal is sparse. In this work, we propose learning a state representation in a self-supervised manner for reward prediction. The reward predictor learns to estimate either a raw or a smoothed version of the true reward signal in an environment with a single terminating goal state. We augment the training of out-of-the-box RL agents in single-goal environments with visual inputs by shaping the reward using our reward predictor during policy learning. Using our representation for preprocessing high-dimensional observations, as well as using the predictor for reward shaping, is shown to facilitate faster learning of Actor Critic using Kronecker-factored Trust Region and Proximal Policy Optimization.",
        "DOI": "NA",
        "affiliation_name": "Ruhr-Universitat Bochum",
        "affiliation_city": "Bochum",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Revisiting the Weaknesses of Reinforcement Learning for Neural Machine Translation",
        "paper_author": "Kiegeland S.",
        "publication": "NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference",
        "citied_by": "24",
        "cover_date": "2021-01-01",
        "Abstract": "Policy gradient algorithms have found wide adoption in NLP, but have recently become subject to criticism, doubting their suitability for NMT. Choshen et al. (2020) identify multiple weaknesses and suspect that their success is determined by the shape of output distributions rather than the reward. In this paper, we revisit these claims and study them under a wider range of configurations. Our experiments on in-domain and cross-domain adaptation reveal the importance of exploration and reward scaling, and provide empirical counter-evidence to these claims.",
        "DOI": "NA",
        "affiliation_name": "Universität Heidelberg",
        "affiliation_city": "Heidelberg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Modeling Cyber Physical Systems with Learning Enabled Components using Hybrid Predicate Transition Nets",
        "paper_author": "He X.",
        "publication": "Proceedings - 2021 21st International Conference on Software Quality, Reliability and Security Companion, QRS-C 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Cyber-physical systems (CPSs) are ubiquitous ranging from smart household appliances to drones and self-driving cars, and are becoming increasingly important in the functioning of our society. In recent years, learning enabled components (LECs) built using machine learning approaches are increasingly used in CPSs to perform autonomous tasks to deal with uncertain and unfamiliar environments. In this paper, an approach for formally modeling CPSs with LECs is presented. Hybrid predicate transition nets are used to model LECs built using deep neural nets and reinforcement learning. Specifically, a method for modeling deep neural nets and their training using hybrid predicate transition nets is developed. Additionally, generic hybrid predicate transition net structures are designed to model reinforcement learning based on neural fitted Q-learning. The expressive power of hybrid predicate transition nets supports all commonly used activation and cost/reward functions in deep neural nets and reinforcement learning. The operational semantics of hybrid predicate transition nets enables the online and offline training of deep neural nets as well as online and offline policy update in reinforcement learning. Furthermore, hybrid predicate transition nets are used to model the overall CPS with LECs through the Simplex architecture. These results (1) provide an executable symbolic representation combining logic and algebraic definitions for two major machine learning approaches, and (2) contribute a systematic and unified framework to study CPSs with LECs. The modeling method is demonstrated using a vehicle benchmark problem.",
        "DOI": "10.1109/QRS-C55045.2021.00164",
        "affiliation_name": "Florida International University",
        "affiliation_city": "Miami",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Churn Prediction of Employees Using Machine Learning Techniques",
        "paper_author": "Bandyopadhyay N.",
        "publication": "Tehnicki Glasnik",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Employees are considered as the most valuable assets of any organization. Various policies have been introduced by the HR professionals to create a good working environment for them, but still, the rate of employees quitting the Technology Industry is quite high. Often the reason behind their early attrition could be due to company-related or personal issues, such as No satisfaction at the workplace, Fewer opportunities for learning, Undue Workload, Less Encouragement, and many others. This paper aims in discussing a structured way for predicting the churn rate of the employees by implementing various Classification techniques like SVM, Random Forest classifier, and Naives Bayes classifier. The performance of the classifiers was compared using metrics like Confusion Matrix, Recall, False Positive Rate, and Accuracy to determine the best model for the churn prediction. We found that among the models, the Random Forest classifier proved to be the best model for IT employee churn prediction. A Correlation Matrix was generated in the form of a heatmap to identify the important features that might impact the attrition rate.",
        "DOI": "10.31803/tg-20210204181812",
        "affiliation_name": "Symbiosis Centre for Information Technology",
        "affiliation_city": "Pune",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Non-monotone Adaptive Submodular Meta-Learning",
        "paper_author": "Tang S.",
        "publication": "SIAM Conference on Applied and Computational Discrete Algorithms, ACDA 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "The core idea of meta-learning is to leverage prior experience to design solutions that can be quickly adapted to new, unseen tasks. Most of existing studies consider the case where the feasible parameter space is continuous. Recently, [1] develops the framework of a discrete variant of meta-learning, called submodular meta-learning, and they treat each task as a discrete optimization problem, i.e., they intend to select a group of items that maximizes the average expected utility of all tasks. Motivated by their framework, we consider the submodular meta-learning problem under the adaptive setting. In particular, we assume that each item has a random state, which is drawn from some known prior distribution. One must select an item before observing its realized state. Given a task, the utility function is defined over items and states. Our goal is to adaptively select a group items, each selection is based on the feedback from the past, to maximize the average expected utility of all tasks. Following the framework of standard meta-learning, we propose an effective policy that is composed of two stages: We first pre-compute an initial set of items, called initial solution set, based on previously visited tasks, then, once a new task is revealed, we add more items to the initial solution set to complete the selection process. We show that our policy achieves a 1/32 approximation ratio if the utility function of each task is adaptive submodular. Our policy enjoys the benefits of providing a personalized solution to each task while reducing the computation cost at test time.",
        "DOI": "NA",
        "affiliation_name": "Erik Jonsson School of Engineering and Computer Science",
        "affiliation_city": "Richardson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Guided Imitation of Task and Motion Planning",
        "paper_author": "McDonald M.J.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "9",
        "cover_date": "2021-01-01",
        "Abstract": "While modern policy optimization methods can do complex manipulation from sensory data, they struggle on problems with extended time horizons and multiple sub-goals. On the other hand, task and motion planning (TAMP) methods scale to long horizons but they are computationally expensive and need to precisely track world state. We propose a method that draws on the strength of both methods: we train a policy to imitate a TAMP solver’s output. This produces a feed-forward policy that can accomplish multi-step tasks from sensory data. First, we build an asynchronous distributed TAMP solver that can produce supervision data fast enough for imitation learning. Then, we propose a hierarchical policy architecture that lets us use partially trained control policies to speed up the TAMP solver. In robotic manipulation tasks with 7-DoF joint control, the partially trained policies reduce the time needed for planning by a factor of up to 2.6. Among these tasks, we can learn a policy that solves the RoboSuite 4-object pick-place task 88% of the time from object pose observations and a policy that solves the RoboDesk 9-goal benchmark 79% of the time from RGB images (averaged across the 9 disparate tasks).",
        "DOI": "NA",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Digital Finance in Europe: Law, Regulation, and Governance",
        "paper_author": "Avgouleas E.",
        "publication": "Digital Finance in Europe: Law, Regulation, and Governance",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Global finance is in the middle of a radical transformation fueled by innovative financial technologies. The coronavirus pandemic has accelerated the digitization of retail financial services in Europe. Institutional interest and digital asset markets are also growing blurring the boundaries between the token economy and traditional finance. Blockchain, AI, quantum computing and decentralised finance (DeFI) are setting the stage for a global battle of business models and philosophies. The post-Brexit EU cannot afford to ignore the promise of digital finance. But the Union is struggling to keep pace with global innovation hubs, particularly when it comes to experimenting with new digital forms of capital raising. Calibrating the EU digital finance strategy is a balancing act that requires a deep understanding of the factors driving the transformation, be they legal, cultural, political or economic, as well as their many implications. The same FinTech inventions that use AI, machine learning and big data to facilitate access to credit may also establish invisible barriers that further social, racial and religious exclusion. The way digital finance actors source, use, and record information presents countless consumer protection concerns. The EU’s strategic response has been years in the making and, finally, in September 2020 the Commission released a Digital Finance Package. This special issue collects contributions from leading scholars who scrutinize the challenges digital finance presents for the EU internal market and financial market regulation from multiple public policy perspectives. Author contributions adopt a critical yet constructive and solutions-oriented approach. They aim to provide policy-relevant research and ideas shedding light on the complexities of the digital finance promise. They also offer solid proposals for reform of EU financial services law. first complete academic analysis of the digitisation of EU finance and its regulation Interdisciplinary (law, economics, and ethics) analysis of the EU Digital Finance Package offers solid proposals for reform of EU financial services law.",
        "DOI": "10.1515/9783110749472",
        "affiliation_name": "The University of Edinburgh",
        "affiliation_city": "Edinburgh",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Deep Reinforcement Learning-based maintenance decision-making for a steel production line",
        "paper_author": "Neto W.F.",
        "publication": "Proceedings of the 31st European Safety and Reliability Conference, ESREL 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "In the 4.0 industry, the adoption of system monitoring technologies provides a large amount of data about the health of the system, which raises a challenge to adopt condition-based maintenance (CBM). Due to its capability to act into the system in real-time based on its embedded condition monitoring equipment, which can help to reduce O&M cost and enhancing the system availability, CBM has become a relevant approach for industry competitiveness. However, to take the advantages of huge data in maintenance decision-making, an important issue to be considered is the large space of states and actions, which is difficult, even impossible, to cope with the traditional maintenance model. To overcome this issue, integrating emerging tools of Machine Learning and Artificial Intelligence into maintenance decision-making and optimization seems to be promising. Therefore, this work proposes a Deep Reinforcement Learning (DRL)-based maintenance optimization for a steel production line, in which the maintenance decisions are made based on the real-time data about the system condition. The production line under study uses metal scrap as the raw material for the steelmaking. Before its usage, the scrap needs to be crushed in a shredder machine, which is the most crucial process. An intermediated buffer is used to keep supplying crushed scrap for the remaining stations when the machine is turned off for maintenance actions. A simulation model is built to simulate the dynamic of the production line. A DRL framework is then built to learn through the interactions with the environment in finding the optimal maintenance policy with lowest maintenance cost. A numerical case study is performed to evaluate the proposed DRL maintenance approach comparing with conventional maintenance policies. As result, the proposed DRL approach shows a better result in terms of cost along with the increase of the system availability.",
        "DOI": "10.3850/978-981-18-2016-8_600-cd",
        "affiliation_name": "Université de Lorraine",
        "affiliation_city": "Nancy",
        "affiliation_country": "France"
    },
    {
        "paper_title": "A Hierarchical Predictive Maintenance Model for Networks",
        "paper_author": "Liang Z.",
        "publication": "Proceedings of the 31st European Safety and Reliability Conference, ESREL 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Nowadays, with the emerging of enabling techniques, such as digital sensing, big data, machine learning techniques, predictive maintenance becomes a prevalent topic in system reliability. The blooming of the related research has already cause multiples paradigm shifts, such as industry 4.0 and digital manufacturing. Could predictive maintenance also shed light on resolving the problem at the network level and bring real value for servicing the macro-characteristics network is an essential question that to be answered. This research aims to design a hierarchical approach that enables scaling-up the effect of predictive maintenance to benefit systemic maintenance, and in turn, serve the network macro-characteristics. The hierarchical model integrates the component, system, network knowledge in a layered fashion. Such that, the model contains both actionable details and macro-characteristics. At the component-level, we model the deterioration process of components as a multi-state multi-path stochastic process. We develop a novel approach for predicting the reaching time of the optimal condition for maintenance, based on the information from inspections. At the system-level, we highlight the heterogeneity of components in the system model. More often than not, practical systems are composited by multiple components whose downtime or failure might have different impacts on system performance. We employ the predicted information from the component-level to construct a group maintenance strategy. Components’ maintenance activities will be actively grouped together for sharing the set-up cost and downtime. Different maintenance strategies may require different costs and result in different system performance. We utilize a genetic algorithm with agglomerative mutation (GA-A) for evaluating and optimizing the group maintenance policies to meet the different requirements of system performances. At the network-level, we consider the network is composed of multiple systems and select the system performance for satisfying the macro-characteristics. In such a way, predictive maintenance at the component level can support the decision making at the system level and subsequently serve the network. The overall approach will be applied to the transportation network. In practice, the transportation network is composited of multiple systems such as bridges, roads, and tunnels, which are composed of components such as concrete decks, wingwalls, and joints. It matches the model description. Moreover, macrocharacteristics, such as connectivity and resilience, have important practical meaning in the transportation network.",
        "DOI": "10.3850/978-981-18-2016-8_336-cd",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Applying Cluster Analysis to Support Failure Management Policy Selection in Asset Management: A Hydropower Plant Case Study",
        "paper_author": "da Silva R.F.",
        "publication": "Proceedings of the 31st European Safety and Reliability Conference, ESREL 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Maximizing the realization of value from physical assets through asset management is a contemporary approach to support the achievement of organizational goals. As consequence, organizations have placed maintenance as a strategic function to deliver business outcomes. The development of appropriate failure management policies for failure prevention is essential but also a challenge for maintenance planning. In this context, this paper proposes a method to support the failure management policy selection in asset management based on the exploratory cluster analysis technique. The proposed method comprised three sections: acquisition of the physical asset performance data, cluster analysis, and selection of the failure management policies. Criticality aspects supported the definition of the criteria and scales for evaluating the performance of physical assets and the composition of the dataset. Then, the distance measure and agglomeration schedule were defined for the application of the cluster analysis. From the set of formed clusters of physical assets, it was assigned an overall failure management policy to each cluster based on their internal homogeneity assessment and the context of the organization. The proposed method is demonstrated through a case study in a maintenance management context of a Brazilian hydroelectric power plant. The results obtained show that the method can support organizations in the selection of appropriate failure management policies according to determined groups of physical assets.",
        "DOI": "10.3850/978-981-18-2016-8_344-cd",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Co-Designing Material-Robot Construction Behaviors: Teaching distributed robotic systems to leverage active bending for light-touch assembly of bamboo bundle structures",
        "paper_author": "Lochnicki G.",
        "publication": "Association for Computer Aided Design in Architecture Annual Conference, ACADIA 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "This paper presents research on designing distributed, robotic construction systems in which robots are taught construction behaviors relative to the elastic bending of natural building materials. Using this behavioral relationship as a driver, the robotic system is developed to deal with the unpredictability of natural materials in construction and further to engage their dynamic characteristics as methods of locomotion and manipulation during the assembly of actively bent structures. Such an approach has the potential to unlock robotic building practice with rapid-renewable materials, whose short crop cycles and small carbon footprints make them particularly important inroads to sustainable construction. The research is conducted through an initial case study in which a mobile robot learns a control policy for elastically bending bamboo bundles into designed configurations using deep reinforcement learning algorithms. This policy is utilized in the process of designing relevant structures, and for the in situ assembly of these designs. These concepts are further investigated through the co-design and physical prototyping of a mobile robot and the construction of bundled bamboo structures. This research demonstrates a shift from an approach of absolute control and predictability to behavior-based methods of assembly. With this, materials and processes that are often considered too labor-intensive or unpredictable can be reintroduced. This reintroduction leads to new insights in architectural design and construction, where design outcome is uniquely tied to the building material and its assembly logic. This highly material-driven approach sets the stage for developing an effective, sustainable, light-touch method of building using natural materials.",
        "DOI": "NA",
        "affiliation_name": "Universität Stuttgart",
        "affiliation_city": "Stuttgart",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Application of artificial intelligence on uncertainty analysis for long-term energy system planning",
        "paper_author": "Li X.",
        "publication": "ECOS 2021 - 34th International Conference on Efficency, Cost, Optimization, Simulation and Environmental Impact of Energy Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Uncertainty of the energy system exerts significant influences on policy-making. Quantification of uncertainty is becoming indispensable for energy planning in long terms. In this paper, we apply artificial intelligence on the uncertainty space generated by Monte Carlo simulation, challenging the conventional way of doing uncertainty analysis by limited scenario analysis in prospective studies. Based upon the Energyscope (ES) model for multi-objective optimization of the energy system, we propose a systematic way of deeply exploring the uncertainty results in order to analyze the distribution and correlationship, in both positive and negative ways, among key technologies in the energy transition to a carbon neutral system. First, we listed over 441 uncertain parameters in ES with corresponding ranges, and carried out Monte-Carlo simulation over 100’000 tests for generating a database of the results. Secondly, we applied several machine learning (ML) methods and compared their performances according to certain criteria, followed by results’ visualization. Thirdly, we focused on the clusters from ML results in order to identify their corresponding features for elucidating the correlation among important factors, and to quantify their impacts on the techno-economic-ecologic objectives. From our results, photovoltaic (PV), biomass and heat pumps appear most promising in the Swiss energy transition, in particular PV which shows the highest reverse-correlation with the mitigation of carbon emission apart from CCS (carbon capture and sequestration). Although this study is based upon Switzerland, this approach is supposed to be replicable in different regions from the authors’ perspective, and would contribute to stakeholders in energy sectors to identify potential opportunities/risks in favor of rational decision-making.",
        "DOI": "NA",
        "affiliation_name": "École Polytechnique Fédérale de Lausanne",
        "affiliation_city": "Lausanne",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Abusive and Threatening Language Detection in Urdu using Boosting based and BERT based models: A Comparative Approach",
        "paper_author": "Das M.",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Online hatred is a growing concern on many social media platforms. To address this issue, different social media platforms have introduced moderation policies for such content. They also employ moderators who can check the posts violating moderation policies and take appropriate action. Academicians in the abusive language research domain also perform various studies to detect such content better. Although there is extensive research in abusive language detection in English, there is a lacuna in abusive language detection in low resource languages like Hindi, Urdu etc. In this FIRE 2021 shared task - “HASOC - Abusive and Threatening language detection in Urdu” the organisers propose an abusive language detection dataset in Urdu along with threatening language detection. In this paper, we explored several machine learning models such as XGboost, LGBM, m-BERT based models for abusive and threatening content detection in Urdu based on the shared task. We observed the Transformer model specifically trained on abusive language dataset in Arabic helps in getting the best performance. Our model came First for both abusive and threatening content detection with an F1score of 0.88 and 0.54, respectively. We have made our code public 1",
        "DOI": "NA",
        "affiliation_name": "Indian Institute of Technology Kharagpur",
        "affiliation_city": "Kharagpur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Travel Time Prediction for Urban Road Based on Machine Learning: Review and Prospect",
        "paper_author": "Zhang L.",
        "publication": "6th International Conference on Transportation Information and Safety: New Infrastructure Construction for Better Transportation, ICTIS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Travel time prediction is an important issue of the development and application of ITS techniques and Advanced Transportation Management Systems. It is important for transportation managers to develop active traffic management policies, for traffic system users to plan reasonable and efficient travel routes, and for the development of theoretical research on traffic flow theory. However, travel time on urban road segments is characterized by drastic fluctuations and randomness due to signal control at intersections, dynamic and uncertainty of traffic demand and a large number of traffic incidents, which greatly increases the difficulty of accurate and robust prediction. At the same time, with the theoretical innovation in machine learning, the rise of high-performance computing and big data technologies, deep learning has gradually evolved from an unachievable concept to complex machine learning models that can surpass many models to achieve accurate prediction and large-scale application deployment. Therefore, more and more researchers are concerned on deep learning theory and applications. The existing shallow learning prediction methods have the characteristics of vulnerability, shallowness, and finiteness. Many shallow learning models are difficult to accurately model sudden traffic events, and incapable of extracting rich features. They often perform well for predictions within a certain period of time, and therefore cannot be utilized to successfully solved the problem of travel time prediction of urban roads. Deep learning methods, however, are good at multi-level feature extraction and can model time-dependent data precisely. However, deep learning also faces the challenges of great training costs and difficulty in hyper-parameter optimization. This paper deeply analyzes the scientific connotation of urban road segments travel time prediction problem and a series of research methods and their applicability, and finally proposes the future research content and development direction.",
        "DOI": "10.1109/ICTIS54573.2021.9798694",
        "affiliation_name": "Ministry of Education of the People's Republic of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Internet of Things (IoT) in Healthcare: Applications, Challenges and Solutions",
        "paper_author": "Mohammadi F.G.",
        "publication": "Proceedings - 2021 International Conference on Computational Science and Computational Intelligence, CSCI 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "In recent years, smart healthcare IoT devices have become ubiquitous, but they mostly work in isolated networks due to their policies. Having these devices connected in a network enables us to perform distributed medical data analysis. However, the presence of diverse IoT devices in terms of technology, structure, and network policy, make it a challenging issue while applying traditional cen-tralized learning algorithms on decentralized data collected from the IoT devices. In this study, we present an extensive review of the state-of-the-art machine learning applications particularly in healthcare, challenging issues in IoT, and corresponding promising solutions.",
        "DOI": "10.1109/CSCI54926.2021.00295",
        "affiliation_name": "University of Georgia School of Computing",
        "affiliation_city": "Athens",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Short Term Prediction of Electrical Load Using Artificial Neural Network with Backpropagation Algorithm",
        "paper_author": "Maulana F.",
        "publication": "Proceedings - 2021 IEEE 7th Information Technology International Seminar, ITIS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial neural network is one of the machine learning algorithms that can perform a regression or classification with supervised learning. In principle, artificial neural network has the same way of working as the system network in the human brain, which has the ability to learn from past experiences. In this paper, it will be proposed to design an artificial neural network model to be able to determine the amount of electrical load generated from a building in Telkom University for the next 7 days. The purpose of predicting this electrical load is to be able to plan of using electrical energy for the future. So that the waste from electrical energy can be minimized by making a prediction of the electrical load made from an artificial neural network model. Prediction of electrical load is done by predicting the last 7 days in January 2020 with training data for 24 days in the same month. The results of the research that has been done during weekend have a larger error than weekdays marked on the 26th has the largest error of 12.123% and the lowest error occurs on the 29th with an error value of 5.737%",
        "DOI": "10.1109/ITIS53497.2021.9791741",
        "affiliation_name": "Telkom University",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "K-Means Clustering Algorithm Analysis on Specific Economic Development Problems in Target Countries",
        "paper_author": "Zhou W.",
        "publication": "Proceedings - 2021 2nd International Conference on Computer Science and Management Technology, ICCSMT 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Most mainstream measures of economic development employ a weighted scoring system under the assumption that each indicator can perfectly substitute each other, which is a strong assumption that may vary from the real world. In this paper, the author uses the K-Means machine learning algorithm to cluster the 195 countries in the world, as an attempt to provide a more holistic view of each country's level of economic development without employing the assumption. With the assistance of silhouette scores, the algorithm created 6 clusters, each with its distinctive properties that future researchers or policy makers can rely upon to generate country-specific views about economic development. Nevertheless, manual inspection of the result discovers the potential problem with the incomplete datasets and the need for a PCA test to reduce dimensions. Considerations of realistic implications also suggest that the standard K-Means clustering might be over-simplifying the complicated nature of some country's economic problems.",
        "DOI": "10.1109/ICCSMT54525.2021.00078",
        "affiliation_name": "University of Virginia",
        "affiliation_city": "Charlottesville",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "AWARE: An IoT powered Smart Band with Multi-Tenancy Cardinality",
        "paper_author": "Khan M.M.",
        "publication": "Proceedings - 2nd International Conference on Computer Science and Engineering: The Effects of the Digital World After Pandemic (EDWAP), IC2SE 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The Pandemic caused due to COVID-19 has overweighed the current healthcare system and made us realize that how unaware we were of our health. Although lots of rational and harsh measured were taken to curb the spread of COVID-19 but still we lost millions of lives. During this pandemic technology played a vital role ranging from the invention of vaccine to remotely monitoring the usage with the help of IoT. Among several emerging technologies wearable smart devices were burgeoning as they are also powered by IoT now. Wearable devices are being used in different scenarios ranging from tracking and monitory infected patients to utilize the data for policy making. Proposed is a framework of an ecosystem \"AWARE\"which comprises of a smart band with advanced PPG and EEG sensors to detect Heart rate, Heart rate Variability, Respiration rate, SpO2, Step and Sleep data. The sensor data will be transferred to the AWARE application on host mobile through BLE and from mobile the user data it will be transferred to AWARE cloud for pre and post processing using Machine Learning algorithms. AWARE can used for monitoring and detection of health anomalies and diseases such as COVID-19 or chronic lifestyle diseases. AWARE works on a multi-Tenancy cardinality framework were the group (i.e., kids, elders, domestic worker) users can share the cloud storage and receive customized notifications. Also, the group manager (i.e., father, employer) will be notified in case of emergencies. Cloud data can be accessed by the users through dashboards. Government authorities can also access user data through APIs. Wearables are widely accepted these days due to its less intrusiveness. Although some professionals are skeptical of these devices, but the advantages are far beyond the minor pitfalls. In fact, several countries have already implemented wearables devices as the primary medium of COVID-19 detection, monitoring.",
        "DOI": "10.1109/IC2SE52832.2021.9791883",
        "affiliation_name": "University of Ha'il",
        "affiliation_city": "Ha'il",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "CAPABILITIES ACCUMULATION AND DEVELOPMENT: What History Tells the Theory",
        "paper_author": "Dosi G.",
        "publication": "The Oxford Handbook of China Innovation",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The chapter analyzes the basic ingredients and processes underlying the “great transformation” from traditional, mostly rural economies to economies driven by industrial activities and advanced services, able to systematically learn, imitate, and innovate. In that transformation, a major driver is the accumulation of knowledge and capabilities. Thus, the chapter addresses the nature of such knowledge and the ways its accumulation co-evolves with the “economic machine”-presiding over income growth and distribution-and with the systems of social relations, institutions, and policies. The latter are crucial in nurturing (or hindering) technological and organizational learning. Even if these vary a lot across historical experiences, all successful episodes have in common fundamental departures from “pure market” prescriptions, but rather shape market signals and the very nature and strategies of economic actors. Finally, in the context of these “historical lessons, \" the chapter focuses on the analogies and specifications of the case of China.",
        "DOI": "10.1093/oxfordhb/9780190900533.013.2",
        "affiliation_name": "Nottingham University Business School China",
        "affiliation_city": "Ningbo",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Efficient Edge Intelligence under Clustering for UAV Swarm Networks",
        "paper_author": "Qu Y.",
        "publication": "Proceedings - 2021 IEEE International Conference on Space-Air-Ground Computing, SAGC 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Unmanned aerial vehicles (UAVs) are expected to be widely used in many critical applications including monitoring, surveillance, urban target tracking, and delivery of goods, from military to civil fields. To realize that, empowering UAV swarm with edge intelligence is becoming appealing and inevitable. Federated learning (FL) as an emerging distributed collaborative machine learning (ML) without letting raw data out, could be suitable for UAV swarm networks but remains largely unexplored. In this paper, we first investigate the problem of efficient Edge Intelligence under Clustering for UAV swarm networks (e-EIC), i.e., how to jointly optimize the computation resource allocation and UAV clustering to minimize the total energy consumption of the UAV swarm for FL, subject to the training accuracy and latency constraints. We decompose the challenging e-EIC problem into two subproblems: computation resource allocation and UAV clustering, and accordingly propose an iterative algorithm based on the optimal policy of the first subproblem and local-search techniques for the second subproblem. Extensive performance evaluations demonstrate that our proposed algorithm can reduce more energy consumption of UAVs than three baseline algorithms, while satisfying the training accuracy and latency constraints.",
        "DOI": "10.1109/SAGC52752.2021.00026",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Accelerating Quadratic Optimization with Reinforcement Learning",
        "paper_author": "Ichnowski J.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "First-order methods for quadratic optimization such as OSQP are widely used for large-scale machine learning and embedded optimal control, where many related problems must be rapidly solved. These methods face two persistent challenges: manual hyperparameter tuning and convergence time to high-accuracy solutions. To address these, we explore how Reinforcement Learning (RL) can learn a policy to tune parameters to accelerate convergence. In experiments with well-known QP benchmarks we find that our RL policy, RLQP, significantly outperforms state-ofthe- art QP solvers by up to 3x. RLQP generalizes surprisingly well to previously unseen problems with varying dimension and structure from different applications, including the QPLIB, Netlib LP and Maros-Mészáros problems. Code, models, and videos are available at https://berkeleyautomation.github.io/rlqp/.",
        "DOI": "NA",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Identifying Substantial Changes for AIP Projects Using RF and SVM",
        "paper_author": "Khalef R.",
        "publication": "Computing in Civil Engineering 2021 - Selected Papers from the ASCE International Conference on Computing in Civil Engineering 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "The budget for the Airport Improvement Program (AIP) in FY21 is $3.35 billion. AIP's contractual guidelines and policies are outlined in Federal Aviation Administration (FAA) 5100.38D. Substantial contractual changes within AIP projects are likely to create risks that can greatly impact cost, time, and quality. To implement improved change management, identification and evaluation of contractual change are essential. Thus, there is a need to create an automated model to identify and evaluate contractual changes in AIP projects. This paper fills this knowledge gap. Using 876 contractual changes made to FAA 5100.38D, the authors utilized an interrelated multi-step methodology. Firstly, the data is prepared, and the changes in the FAA 5100.38D are manually adapted. Secondly, the data is manipulated using NLP techniques. Thirdly, before building the machine learning (ML) models, the data is preprocessed. Finally, hyperparameter tuned random forest (RF) and support vector machine (SVM) ML models are developed to predict contractual substantial changes, and the optimal model is selected and evaluated. Results show that RF presented the optimal hyperparameter tuned model with an AUC value of 0.928. Ultimately, this research presents an AIP decision support tool that predicts substantial contractual changes effectively and efficiently, and thus proactively provides risk assessment for AIP projects.",
        "DOI": "10.1061/9780784483893.174",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Rolla",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Weighted model estimation for offline model-based reinforcement learning",
        "paper_author": "Hishinuma T.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "This paper discusses model estimation in offline model-based reinforcement learning (MBRL), which is important for subsequent policy improvement using an estimated model. From the viewpoint of covariate shift, a natural idea is model estimation weighted by the ratio of the state-action distributions of offline data and real future data. However, estimating such a natural weight is one of the main challenges for off-policy evaluation, which is not easy to use. As an artificial alternative, this paper considers weighting with the state-action distribution ratio of offline data and simulated future data, which can be estimated relatively easily by standard density ratio estimation techniques for supervised learning. Based on the artificial weight, this paper defines a loss function for offline MBRL and presents an algorithm to optimize it. Weighting with the artificial weight is justified as evaluating an upper bound of the policy evaluation error. Numerical experiments demonstrate the effectiveness of weighting with the artificial weight.",
        "DOI": "NA",
        "affiliation_name": "Kyoto University",
        "affiliation_city": "Kyoto",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning",
        "paper_author": "Bibaut A.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Empirical risk minimization (ERM) is the workhorse of machine learning, whether for classification and regression or for off-policy policy learning, but its modelagnostic guarantees can fail when we use adaptively collected data, such as the result of running a contextual bandit algorithm. We study a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first-of-their-kind generalization guarantees and fast convergence rates. Our results are based on a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, we provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, we provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit-collected data. An empirical investigation validates our theory.",
        "DOI": "NA",
        "affiliation_name": "Université Paris Cité",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Robust Generalization despite Distribution Shift via Minimum Discriminating Information",
        "paper_author": "Sutter T.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Training models that perform well under distribution shifts is a central challenge in machine learning. In this paper, we introduce a modeling framework where, in addition to training data, we have partial structural knowledge of the shifted test distribution. We employ the principle of minimum discriminating information to embed the available prior knowledge, and use distributionally robust optimization to account for uncertainty due to the limited samples. By leveraging large deviation results, we obtain explicit generalization bounds with respect to the unknown shifted distribution. Lastly, we demonstrate the versatility of our framework by demonstrating it on two rather distinct applications: (1) training classifiers on systematically biased data and (2) off-policy evaluation in Markov Decision Processes.",
        "DOI": "NA",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A Faster Decentralized Algorithm for Nonconvex Minimax Problems",
        "paper_author": "Xian W.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "29",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, we study the nonconvex-strongly-concave minimax optimization problem on decentralized setting. The minimax problems are attracting increasing attentions because of their popular practical applications such as policy evaluation and adversarial training. As training data become larger, distributed training has been broadly adopted in machine learning tasks. Recent research works show that the decentralized distributed data-parallel training techniques are specially promising, because they can achieve the efficient communications and avoid the bottleneck problem on the central node or the latency of low bandwidth network. However, the decentralized minimax problems were seldom studied in literature and the existing methods suffer from very high gradient complexity. To address this challenge, we propose a new faster decentralized algorithm, named as DM-HSGD, for nonconvex minimax problems by using the variance reduced technique of hybrid stochastic gradient descent. We prove that our DM-HSGD algorithm achieves stochastic first-order oracle (SFO) complexity of O(κ3∊-3) for decentralized stochastic nonconvex-strongly-concave problem to search an ǫ-stationary point, which improves the exiting best theoretical results. Moreover, we also prove that our algorithm achieves linear speedup with respect to the number of workers. Our experiments on decentralized settings show the superior performance of our new algorithm.",
        "DOI": "NA",
        "affiliation_name": "Swanson School of Engineering",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Mobilenet Based CNN Architecture For Detection of Face Masks",
        "paper_author": "Mantri A.",
        "publication": "Proceedings of the 2021 6th International Conference on Computing, Communication and Security, ICCCS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "It has remained to be the cause of misery for millions of businesses and lives throughout 2020 and into 2021 after the outbreak of Coronavirus Disease 2019 (COVID-19). Almost everyone, especially those planning to resume in-person activity, is feeling anxious while the world is recovering from the pandemic and prepares to return to a normal condition. Face masks are proven to be the only prominent way of reducing the risk of transfusion of viral agents, as well as provide a sense of protection. But, due to the negligence and casual attitude of people, strict policies must be enacted. Manual tracking of this policy, while possible, is ineffective and time-consuming. This is where technology plays a critical role and that's why in this paper, we propose a Deep Learning-based system that uses Convolutional Neural Network (CNN) architecture to detect unmasked as well as masked faces and can interface with security cameras installed. This architecture is trained by using 1923 images. It was found that a high rate of accuracy (99.13%) and validation was achieved with the proposed model, more accurate than other models. As a result, safety violations can be tracked, face masks can be encouraged, and safe working conditions can be ensured.",
        "DOI": "10.1109/ICCCS51487.2021.9776347",
        "affiliation_name": "Motilal Nehru National Institute of Technology Allahabad",
        "affiliation_city": "Prayagraj",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Contrastive Reinforcement Learning of Symbolic Reasoning Domains",
        "paper_author": "Poesia G.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "symbolic reasoning, as required in domains such as mathematics and logic, is a key component of human intelligence. Solvers for these domains have important applications, especially to computer-assisted education. But learning to solve symbolic problems is challenging for machine learning algorithms. Existing models either learn from human solutions or use hand-engineered features, making them expensive to apply in new domains. In this paper, we instead consider symbolic domains as simple environments where states and actions are given as unstructured text, and binary rewards indicate whether a problem is solved. This flexible setup makes it easy to specify new domains, but search and planning become challenging. We introduce five environments inspired by the Mathematics Common Core Curriculum, and observe that existing Reinforcement Learning baselines perform poorly. We then present a novel learning algorithm, Contrastive Policy Learning (ConPoLe) that explicitly optimizes the InfoNCE loss, which lower bounds the mutual information between the current state and next states that continue on a path to the solution. ConPoLe successfully solves all four domains. Moreover, problem representations learned by ConPoLe enable accurate prediction of the categories of problems in a real mathematics curriculum. Our results suggest new directions for reinforcement learning in symbolic domains, as well as applications to mathematics education.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Breaking the Linear Iteration Cost Barrier for Some Well-known Conditional Gradient Methods Using MaxIP Data-structures",
        "paper_author": "Xu Z.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "Conditional gradient methods (CGM) are widely used in modern machine learning. CGM's overall running time usually consists of two parts: the number of iterations and the cost of each iteration. Most efforts focus on reducing the number of iterations as a means to reduce the overall running time. In this work, we focus on improving the per iteration cost of CGM. The bottleneck step in most CGM is maximum inner product search (MaxIP), which requires a linear scan over the parameters. In practice, approximate MaxIP data-structures are found to be helpful heuristics. However, theoretically, nothing is known about the combination of approximate MaxIP data-structures and CGM. In this work, we answer this question positively by providing a formal framework to combine the locality sensitive hashing type approximate MaxIP data-structures with CGM algorithms. As a result, we show the first algorithm, where the cost per iteration is sublinear in the number of parameters, for many fundamental optimization algorithms, e.g., Frank-Wolfe, Herding algorithm, and policy gradient.",
        "DOI": "NA",
        "affiliation_name": "Rice University",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Representation Learning for Event-based Visuomotor Policies",
        "paper_author": "Vemprala S.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "Event-based cameras are dynamic vision sensors that provide asynchronous measurements of changes in per-pixel brightness at a microsecond level. This makes them significantly faster than conventional frame-based cameras, and an appealing choice for high-speed navigation. While an interesting sensor modality, this asynchronously streamed event data poses a challenge for machine learning techniques that are more suited for frame-based data. In this paper, we present an event variational autoencoder and show that it is feasible to learn compact representations directly from asynchronous spatiotemporal event data. Furthermore, we show that such pretrained representations can be used for event-based reinforcement learning instead of end-to-end reward driven perception. We validate this framework of learning event-based visuomotor policies by applying it to an obstacle avoidance scenario in simulation. Compared to techniques that treat event data as images, we show that representations learnt from event streams result in faster policy training, adapt to different control capacities, and demonstrate a higher degree of robustness.",
        "DOI": "NA",
        "affiliation_name": "Microsoft Research",
        "affiliation_city": "Redmond",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Medical Dead-ends and Learning to Identify High-risk States and Treatments",
        "paper_author": "Fatemi M.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "27",
        "cover_date": "2021-01-01",
        "Abstract": "Machine learning has successfully framed many sequential decision making problems as either supervised prediction, or optimal decision-making policy identification via reinforcement learning. In data-constrained offline settings, both approaches may fail as they assume fully optimal behavior or rely on exploring alternatives that may not exist. We introduce an inherently different approach that identifies possible “dead-ends” of a state space. We focus on the condition of patients in the intensive care unit, where a “medical dead-end” indicates that a patient will expire, regardless of all potential future treatment sequences. We postulate “treatment security” as avoiding treatments with probability proportional to their chance of leading to dead-ends, present a formal proof, and frame discovery as an RL problem. We then train three independent deep neural models for automated state construction, dead-end discovery and confirmation. Our empirical results discover that dead-ends exist in real clinical data among septic patients, and further reveal gaps between secure treatments and those that were administered.",
        "DOI": "NA",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Advances in Neural Information Processing Systems 34 - 35th Conference on Neural Information Processing Systems, NeurIPS 2021",
        "paper_author": "NA",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 2334 papers. The topics discussed include: greedy and random quasi-newton methods with faster explicit superlinear convergence; towards instance-optimal offline reinforcement learning with pessimism; an online method for a class of distributionally robust optimization with non-convex objectives; understanding negative samples in instance discriminative self-supervised representation learning; MCUNetV2: memory-efficient patch-based inference for tiny deep learning; MCMC variational inference via uncorrected Hamiltonian annealing; unsupervised motion representation learning with capsule autoencoders; coupled segmentation and edge learning via dynamic graph propagation; neural active learning with performance guarantees; an image is worth more than a thousand words: towards disentanglement in the wild; policy optimization in adversarial MDPs: improved exploration via dilated bonuses; improving calibration through the relationship with adversarial robustness; neural rule-execution tracking machine for transformer-based text generation; and risk bounds and calibration for a smart predict-then-optimize method.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Learning A Risk-Aware Trajectory Planner From Demonstrations Using Logic Monitor",
        "paper_author": "Li X.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Risk awareness is an important factor to consider when deploying policies on robots in the real-world. Defining the right set of risk metrics can be difficult. In this work, we use a logic monitor that keeps track of the environmental agents’ behaviors and provides a risk metric that the controlled agent can incorporate during planning. We introduce LogicRiskNet, a learning structure that can be constructed from temporal logic formulas describing rules governing a safe agent’s behaviors. The network’s parameters can be learned from demonstration data. By using temporal logic, the network provides an interpretable architecture that can explain what risk metrics are important to the human. We integrate LogicRiskNet in an inverse optimal control (IOC) framework and show that we can learn to generate trajectory plans that accurately mimic the expert’s risk handling behaviors solely from demonstration data. We evaluate our method on a real-world driving dataset.",
        "DOI": "NA",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Multi-Step Budgeted Bayesian Optimization with Unknown Evaluation Costs",
        "paper_author": "Astudillo R.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Bayesian optimization (BO) is a sample-efficient approach to optimizing costly-toevaluate black-box functions. Most BO methods ignore how evaluation costs may vary over the optimization domain. However, these costs can be highly heterogeneous and are often unknown in advance. This occurs in many practical settings, such as hyperparameter tuning of machine learning algorithms or physics-based simulation optimization. Moreover, those few existing methods that acknowledge cost heterogeneity do not naturally accommodate a budget constraint on the total evaluation cost. This combination of unknown costs and a budget constraint introduces a new dimension to the exploration-exploitation trade-off, where learning about the cost incurs a cost itself. Existing methods do not reason about the various trade-offs of this problem in a principled way, leading often to poor performance. We formalize this claim by proving that the expected improvement and the expected improvement per unit of cost, arguably the two most widely used acquisition functions in practice, can be arbitrarily inferior with respect to the optimal non-myopic policy. To overcome the shortcomings of existing approaches, we propose the budgeted multi-step expected improvement, a non-myopic acquisition function that generalizes classical expected improvement to the setting of heterogeneous and unknown evaluation costs. Finally, we show that our acquisition function outperforms existing methods in a variety of synthetic and real problems.",
        "DOI": "NA",
        "affiliation_name": "Cornell University",
        "affiliation_city": "Ithaca",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Wireless Coexistence Standards: Challenges, and Intelligent Solutions",
        "paper_author": "Chew D.",
        "publication": "Wireless Coexistence: Standards, Challenges, and Intelligent Solutions",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Wireless Coexistence: Standards, Challenges, and Intelligent Solutions delivers a thorough exploration of wireless ecosystems sharing the spectrum, including the multiple standards and key requirements driving the current state of wireless technology. The book surveys several standards, including IEEE 802.22, 802.15.2, and 802.19.1 and expands upon recent advances in machine learning and artificial intelligence to demonstrate how these technologies might be used to meet or exceed the challenges of wireless coexistence. The text discusses cognitive radio in the context of spectrum coexistence and provides a comparison and assessment of using artificial intelligence in place of, or in addition to, current techniques. It also considers applications to communication theory, learning algorithms for passive wireless coexistence strategies, spectrum situational awareness, and active wireless coexistence strategies. With the necessity of spectrum sharing and the scarcity of unused spectrum on the rise, the standardization of wireless coexistence becomes more important with each passing day. Readers will learn about the challenges posed by shrinking wireless real estate and from the inclusion of topics like: A thorough introduction to the concept of, and motivation for, wireless coexistence, including congestion and interference, policies, and regulations An exploration of different wireless coexistence standards, including the need for standardization and various protocols, including 802.22, 802.15.2, 802.19.1, P1900, and 3GPP Release 13/14 LAA A discussion of the applications of communication theory, including primary user strategies, primary multi-user protocols, and successive interference cancellation A treatment of concepts in learning algorithms Perfect for scientists, researchers, engineers, developers, educators, and administrators working in the area of wireless networks, Wireless Coexistence: Standards, Challenges, and Intelligent Solutions will also earn a place in the libraries of graduate students studying wireless networks and seeking a one-stop reference for subjects related to wireless coexistence standards.",
        "DOI": "10.1002/9781119584230",
        "affiliation_name": "Johns Hopkins University Applied Physics Laboratory",
        "affiliation_city": "Laurel",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Comparison of Machine Learning Algorithms for Air Pollution Monitoring System",
        "paper_author": "Sethi T.",
        "publication": "AI and IoT-Based Intelligent Automation in Robotics",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Today, air pollution is one of the topics that needs to be addressed with new, bold and effective techniques in order to control pollution levels. Recently, there has been a rapid rise in the amount of dangerous pollutants released into the air such as sulfur dioxide, nitrogen dioxide, particulate matter 2.5 (PM2.5) and particulate matter 10 (PM10), ammonia and ozone. The increase in pollutants has mainly been due to human activities. In this chapter, data has been captured and collected by the Open Government Data (OGD) Platform India, which has been released under the National Data Sharing and Accessibility Policy (NDSAP) and various extensive open sources. The main purpose of this data is to compare the different machine learning algorithms and check their accuracy for the pollution detection systems. The algorithms used are multiple linear regression (MLR), random forest regression (RFR), decision tree regression (DTR), support vector regression (SVR) and extreme gradient boosting (XGBoost).",
        "DOI": "10.1002/9781119711230.ch19",
        "affiliation_name": "Netaji Subhas University of Technology",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Surplus Intelligence?",
        "paper_author": "Hope W.",
        "publication": "Political Economy of Communication",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "After Eric Hobsbawm’s short 20th century 1914–1991, the lineaments of global capitalism took shape—transnational corporations with multiple supply chains and subcontracted workforces, worldspanning financial institutions, instruments and flows alongside supranational and international neoliberal policy regimes. These developments initially depended on information-communication infrastructures arising from inter-networked computing and the early internet. They built upon the 19th and 20th-century advancements of telegraph/telephony, mass media and transport technologies. Similarly, the early internet presaged and enabled the subsequent growth of social media platforms, multifunctional smartphones and other portable devices. Extraordinary volumes of text, image, video, audio and assorted data could be created and communicated in real-time. These are partial manifestations of a larger and deeper manifold—artificial intelligence. At the time of writing, the AI acronym and its surrounding nomenclature—algorithms, machine learning, robotics, humanoids, post-human—pervades corporate culture, mass media, websites, journalism, academic disciplines, branches of literature and artistic expression. How, then, should AI be defined? What are its component features?",
        "DOI": "NA",
        "affiliation_name": "Auckland University of Technology",
        "affiliation_city": "Auckland",
        "affiliation_country": "New Zealand"
    },
    {
        "paper_title": "Automated damage localization for lightweight plates",
        "paper_author": "Tavares A.",
        "publication": "International Conference on Structural Health Monitoring of Intelligent Infrastructure: Transferring Research into Practice, SHMII",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The industrial application of lightweight materials is increasing across many industries such as the automotive, the aerospace and the renewable energy sector. This growth brings new challenges for efficient and reliable damage detection. The advancements of both Machine Learning (ML) algorithms and Non-Destructive Testing (NDT) techniques offer the correct setting to successfully tackle these challenges. In this work, an automated modal analysis procedure is combined with ML algorithms in order to achieve an automatic procedure for damage localization. It is based on clustering techniques associated to the Local Defect Resonance (LDR) concept, which looks at the high frequency vibrations to get a localized resonant activation of the defects. The measurements were carried out using a Scanning Laser Doppler Vibrometer (SLDV), which provides a quick and efficient way of obtaining full-field vibration measurements into high-frequency bands. Results obtained for lightweight plates of different materials will be presented.",
        "DOI": "NA",
        "affiliation_name": "Siemens Digital Industries Software",
        "affiliation_city": "Plano",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Embracing the future of the policy sciences: Big data in pedagogy and practice",
        "paper_author": "Goyal N.",
        "publication": "The Future of the Policy Sciences",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Although the emergence of Big Data provides an opportunity to synthesize and mobilize ever greater amounts of policy-relevant knowledge, it has not received adequate attention in studies of policy pedagogy and practice. In this chapter, we highlight the relevance of Big Data to policy analysis, policy implementation, and policy studies through a discussion of basic machine learning techniques and an illustration of their application in the case of better understanding policy response to COVID-19. Subsequently - based on a bibliometric review of nearly 2, 500 publications on big data in public policy and content analysis of course titles and descriptions in 122 programs worldwide - we make an evidence-informed appeal to increase the uptake of big data in policy research as well as teaching. We conclude that appropriate engagement with the big data phenomenon can help the policy sciences remain relevant and move a step closer to integrating policy research, pedagogy, and practice.",
        "DOI": "10.4337/9781800376489.00009",
        "affiliation_name": "Faculteit Techniek, Bestuur en Management, TU Delft",
        "affiliation_city": "Delft",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "2021 IEEE 2nd International Conference on Technology, Engineering, Management for Societal Impact using Marketing, Entrepreneurship and Talent, TEMSMET 2021",
        "paper_author": "NA",
        "publication": "2021 IEEE 2nd International Conference on Technology, Engineering, Management for Societal Impact using Marketing, Entrepreneurship and Talent, TEMSMET 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 37 papers. The topics discussed include: bearing health condition monitoring using time-domain acoustic signal features; multi source device policy management; anti-abduction device for women, children and elderly; context-based email ranking system for enterprise; a review on student performance prediction using educational data mining and artificial intelligence; the role of resilience and human rights in the green and digital transformation of supply chain; from the word-of-mouth to social impact: a bibliometric analysis of social media marketing; a novel application of neuromarketing for designing user interface mockups to enhance user experience in software development; predictive analysis for calculation of crop yield using datamining and machine learning; and utilizing an integrated feature selection technique in ovarian cancer to solve classification problem.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A General Theory Of Multiarmed Bandit Processes With Constrained Arm Switches",
        "paper_author": "Bao W.",
        "publication": "SIAM Journal on Control and Optimization",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This paper develops a general theory on optimal allocation of multiarmed bandit (MAB) processes subject to arm switching constraints formulated as a general random time set. A Gittins index is constructed for each single arm, and the optimality of the corresponding Gittins index policy is proved. The constrained MAB model and the Gittins index policy established in this paper subsume those for MAB processes in continuous time, integer time, semi-Markovian, as well as general discrete time settings. Consequently, the new theory covers the classical MAB models as special cases and also applies to many other situations that have not yet been studied in the literature. While the proof of the optimality of the Gittins index policy benefits from ideas in the existing theory of MAB processes in continuous time, new techniques are introduced which drastically simplify the proof.",
        "DOI": "10.1137/19M1282386",
        "affiliation_name": "The Chinese University of Hong Kong, Shenzhen",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Inverse Reinforcement Learning with Explicit Policy Estimates",
        "paper_author": "Sanghvi N.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Various methods for solving the inverse reinforcement learning (IRL) problem have been developed independently in machine learning and economics. In particular, the method of Maximum Causal Entropy IRL is based on the perspective of entropy maximization, while related advances in the field of economics instead assume the existence of unobserved action shocks to explain expert behavior (Nested Fixed Point Algorithm, Conditional Choice Probability method, Nested Pseudo-Likelihood Algorithm). In this work, we make previously unknown connections between these related methods from both fields. We achieve this by showing that they all belong to a class of optimization problems, characterized by a common form of the objective, the associated policy and the objective gradient. We demonstrate key computational and algorithmic differences which arise between the methods due to an approximation of the optimal soft value function, and describe how this leads to more efficient algorithms. Using insights which emerge from our study of this class of optimization problems, we identify various problem scenarios and investigate each method’s suitability for these problems.",
        "DOI": "10.1609/aaai.v35i11.17141",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Automated Reasoning and Learning for Automated Payroll Management",
        "paper_author": "Dumančić S.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "While payroll management is a crucial aspect of any business venture, anticipating the future financial impact of changes to the payroll policy is a challenging task due to the complexity of tax legislation. The goal of this work is to automatically explore potential payroll policies and find the optimal set of policies that satisfies the user's needs. To achieve this goal, we overcome two major challenges. First, we translate the tax legislative knowledge into a formal representation flexible enough to support a variety of scenarios in payroll calculations. Second, the legal knowledge is further compiled into a set of constraints from which a constraint solver can find the optimal policy. Furthermore, payroll computation is performed on an individual basis which might be expensive for companies with a large number of employees. To make the optimisation more efficient, we integrate it with a machine learning model that learns from the previous optimisation runs and speeds up the optimisation engine. The results of this work have been deployed by a social insurance fund.",
        "DOI": "10.1609/aaai.v35i17.17774",
        "affiliation_name": "KU Leuven",
        "affiliation_city": "Leuven",
        "affiliation_country": "Belgium"
    },
    {
        "paper_title": "Artificial Intelligence and Machine Learning for Autonomous Agents that Learn to Plan and Operate in Unpredictable Dynamic Environments",
        "paper_author": "Lamanna L.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "My research activity focuses on the integration of acting, learning and planning. The main objective is to build a system that is capable to learn how to plan and act in an unknown, dynamic and complex environment. The only knowledge the agent has about the environment is provided by a set of sensor observations which returns continuous measures on the environment. On the learning side, I'm interested in developing algorithms that allow an artificial agent to learn an abstract model of the dynamics of the environment (either an explicit model like a deterministic finite state machine or a model described in a language to express planning domains). The type of abstract model is specified by means of discrete state variables rather than continuous variables representing agent observations. In addition to learning the abstract model, I'm interested in learning probabilistic (generative) models that connects the abstract model with the perceptions of the agents. On the acting and planning side, the artificial agent does not rely on a prior set of execution traces, it rather decides online how to act by means of state-of-art planners. With its own experience, it enriches the planner knowledge, as well as the learned model of the environment. On the learning part, the agent applies techniques for dynamic probabilistic clustering of perceptions in a set of abstract states, neural network for learning transition models, and inductive reasoning for learning action model descriptions. Notice that this is different from Reinforcement Learning where the focus is to learn a policy for achieving a goal, we are interested in learning an abstract model of the environment. We do not have a reward function that encodes the goal to be reached. Indeed in this work an agent does not necessarily need to reach a goal.",
        "DOI": "10.1609/aaai.v35i18.17856",
        "affiliation_name": "Bruno Kessler Foundation",
        "affiliation_city": "Trento",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Visual Tracking via Hierarchical Deep Reinforcement Learning",
        "paper_author": "Zhang D.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "30",
        "cover_date": "2021-01-01",
        "Abstract": "Visual tracking has achieved great progress due to numerous different algorithms. However, deep trackers based on classification or Siamese network still have their specific limitations. In this work, we show how to teach machines to track a generic object in videos like humans, who can use a few search steps to perform tracking. By constructing a Markov decision process in Deep Reinforcement Learning (DRL), our agents can learn to determine hierarchical decisions on tracking mode and motion estimation. To be specific, our Hierarchical DRL framework is composed of a Siamese-based observation network which models the motion information of an arbitrary target, a policy network for mode switch and an actor-critic network for box regression. This tracking strategy is more in line with human behavior paradigm, and is effective and efficient to cope with fast motion, background clutter and large deformations. Extensive experiments on the GOT-10k, OTB-100, UAV-123, VOT and LaSOT tracking benchmarks, demonstrate that the proposed tracker achieves state-of-the-art performance while running in real-time.",
        "DOI": "10.1609/aaai.v35i4.16443",
        "affiliation_name": "Shanghai Jiao Tong University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An introduction to flexible methods for policy evaluation",
        "paper_author": "Huber M.",
        "publication": "Handbook of Research Methods and Applications in Empirical Microeconomics",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "This chapter covers different approaches to policy evaluation for assessing the causal effect of a treatment or intervention on an outcome of interest. Starting with the experimental evaluation of a randomized treatment, it then reviews evaluation methods based on selection on observables (assuming a quasi-random treatment given observed covariates), instrumental variables (inducing a quasi-random shift in the treatment), difference-in-differences and changes-in-changes (exploiting changes in outcomes over time), as well as regression discontinuities and kinks (using changes in the treatment assignment at some threshold of a running variable). The chapter discusses methods particularly suited for data with many observations for a flexible (i.e. semi- or nonparametric) modeling of treatment effects, and/or many (i.e. high dimensional) observed covariates by applying machine learning to select and control for covariates in a data-driven way. These methods can tackle confounding by controlling, for instance, for factors jointly affecting the treatment and the outcome, and can discern learning effect heterogeneities across subgroups defined upon observable covariates, enabling the targeting of those groups for which the treatment is most effective.",
        "DOI": "10.4337/9781788976480.00010",
        "affiliation_name": "University of Fribourg",
        "affiliation_city": "Fribourg",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "GOOGLE EARTH ENGINE FOR LANDSAT IMAGE PROCESSING AND MONITORING LAND USE/ LAND COVER CHANGES IN THE JOHOR RIVER BASIN, MALAYSIA",
        "paper_author": "Kang C.S.",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Johor River Basin (JRB), located in the state of Johor in southern Peninsular Malaysia is an important ecosystem providing freshwater and supporting people of the rapidly developing Johor and Singapore. Land use and land cover (LULC) of JRB is changing rapidly due to high economic activities and increasing population in the zone. A 30-years LULC analysis of JRB was conducted in this study by comparing two machine learning classification algorithms, i.e., Support Vector Machine (SVM) and Random Forest (RF) using Google Earth Engine (GEE) as the processing platform. While cloud cover is always a significant issue over the tropical region, the big data and cloud processing capabilities of GEE can provide advantages to generate cloudless Landsat image composites from multiple scenes. The classification results showed high accuracy of 87% and Kappa value above 0.84 respectively. The LULC classification results can serve as the base map for further studies, including the river morphology change analysis, the ecosystem services analysis; and support hydrology modelling, land use policy making, and water resources management.",
        "DOI": "10.1109/IGARSS47720.2021.9554768",
        "affiliation_name": "Centre for Environmental Sustainability and Water Security",
        "affiliation_city": "Johor Bahru",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Remote Sensing Predicts Long-term Indicators of Governance, Stability, and Well-being",
        "paper_author": "Irvine J.M.",
        "publication": "Proceedings - Applied Imagery Pattern Recognition Workshop",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Understanding a region's socio-economic conditions can inform the development of policies in both the public and private sectors. Commercial satellite imagery provides a potential avenue for abstracting socio-economic context in a quick and relatively inexpensive manner. Satellite images contain infrastructural and agricultural information that, in a previous study focused on Afghanistan and Botswana, provided a useful for characterizing regional socio-economic information. Previous studies have compared survey responses to imagery feature, using supervised machine learning models. Building on previous work, this study explores long-term assessments of a country. As with previous studies, image features extracted from commercial imagery form the explanatory variables for our models. In this case, however, we seek to predict annual indicators of conditions for a country as assessed by the World Bank. The models relate imagery-derived features to indicators of Political Stability, Control of Corruption, Rule of Law, Government Effectiveness, Voice and Accountability, and Gross Domestic Product using data from multiple countries.",
        "DOI": "10.1109/AIPR52630.2021.9762189",
        "affiliation_name": "Charles Stark Draper Lab Inc",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "24th International Conference on Business Information Systems, BIS 2021",
        "paper_author": "NA",
        "publication": "Business Information Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 33 papers. The special focus in this conference is on Business Information Systems. The topics include: Post-Brexit power of European Union from the world trade network analysis; towards a Guideline Affording Overarching Knowledge Building in Data Analysis Projects; optimization-based Business Process Model Matching; database-less Extraction of Event Logs from Redo Logs; towards a Concept for Building a Big Data Architecture with Microservices; execution of Multi-Perspective Declarative Process Models using Complex Event Processing; exploring Potential Impacts of Self-Sovereign Identity on Smart Service Systems An Analysis of Electric Vehicle Charging Services; domain-specific Event Abstraction; ontological Modeling of the State Economic Development Policy for Cultural Industries; Semantic Representation of Domain Knowledge for Professional VR Training; mapping of ImageNet and Wikidata for Knowledge Graphs Enabled Computer Vision; contextual Personality-aware Recommender System Versus Big Data Recommender System; generating a Condensed Representation for Positive and Negative Association Rules A Condensed Representation for Association Rules; supporting an Expert-centric Process of New Product Introduction with Statistical Machine Learning; Evaluating the New AI and Data Driven Insurance Business Models for Incumbents and Disruptors: Is there Convergence?; evaluation of Deep Learning Instance Segmentation models for Pig Precision Livestock Farming; text-Aware Predictive Monitoring of Business Processes; predicting E-commerce Item Sales with Web Environment Temporal Background; social Media Crisis Communication Model for Building Public Resilience: A Preliminary Study; stream Processing Tools for Analyzing Objects in Motion Sending High-Volume Location Data; enterprise-Wide Metadata Management An Industry Case on the Current State and Challenges.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "The Utility of Explainable AI in Ad Hoc Human-Machine Teaming",
        "paper_author": "Paleja R.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "37",
        "cover_date": "2021-01-01",
        "Abstract": "Recent advances in machine learning have led to growing interest in Explainable AI (xAI) to enable humans to gain insight into the decision-making of machine learning models. Despite this recent interest, the utility of xAI techniques has not yet been characterized in human-machine teaming. Importantly, xAI offers the promise of enhancing team situational awareness (SA) and shared mental model development, which are the key characteristics of effective human-machine teams. Rapidly developing such mental models is especially critical in ad hoc human-machine teaming, where agents do not have a priori knowledge of others' decision-making strategies. In this paper, we present two novel human-subject experiments quantifying the benefits of deploying xAI techniques within a human-machine teaming scenario. First, we show that xAI techniques can support SA (p < 0.05). Second, we examine how different SA levels induced via a collaborative AI policy abstraction affect ad hoc human-machine teaming performance. Importantly, we find that the benefits of xAI are not universal, as there is a strong dependence on the composition of the human-machine team. Novices benefit from xAI providing increased SA (p < 0.05) but are susceptible to cognitive overhead (p < 0.05). On the other hand, expert performance degrades with the addition of xAI-based support (p < 0.05), indicating that the cost of paying attention to the xAI outweighs the benefits obtained from being provided additional information to enhance SA. Our results demonstrate that researchers must deliberately design and deploy the right xAI techniques in the right scenario by carefully considering human-machine team composition and how the xAI method augments SA.",
        "DOI": "NA",
        "affiliation_name": "Lincoln Laboratory",
        "affiliation_city": "Lexington",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using Machine Learning Method to Qualify and Evaluate the Regional Economy",
        "paper_author": "Lu J.",
        "publication": "Proceedings - 2021 International Conference on Computer, Blockchain and Financial Development, CBFD 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "As the economic lifeline of Southwest China, Sichuan Province has contributed to Chinese sustainable economic development, the most prominent Chengdu. Chengdu-Chongqing area has been pivotal in China's regional development plate. In the 14th Five-Year Plan of China, the implementation of the Chengdu-Chongqing double cities economic circle is emphasized from different aspects. This policy can directly stimulate the regional economy, thus driving the economic development of Sichuan. Accordingly, the study takes the GDP in 2018 of 21 cities of Sichuan province as the dependent variable. Except for the traditional financial method or model, the study adopts one of the Machine Learning methods, Principal Component Analysis (PCA), to compare the development level of 21 cities horizontally and vertically. Meanwhile, within the Machine Learning method, the new model's sampling accuracy is 0.803, and the first two principal components could interpret 91.206% of the total variance. Therefore, the study evaluates, analyzes the results of new ranks of 21 cities, exploring the possibility of coordinated economic development of Sichuan province under the background of the construction of twins \"Chengdu-Chongqing economic circle.\"Hopefully, the consequence of research provides a theoretical reference for the policy implementation.",
        "DOI": "10.1109/CBFD52659.2021.00062",
        "affiliation_name": "Wenzhou-Kean University",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Learning and Analyzing Generation Order for Undirected Sequence Models",
        "paper_author": "Jiang Y.",
        "publication": "Findings of the Association for Computational Linguistics, Findings of ACL: EMNLP 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Undirected neural sequence models have achieved performance competitive with the state-of-the-art directed sequence models that generate monotonically from left to right in machine translation tasks. In this work, we train a policy that learns the generation order for a pre-trained, undirected translation model via reinforcement learning. We show that the translations decoded by our learned orders achieve higher BLEU scores than the outputs decoded from left to right or decoded by the learned order from Mansimov et al. (2019) on the WMT'14 German-English translation task. On examples with a maximum source and target length of 30 from De-En and WMT'16 English-Romanian tasks, our learned order outperforms all heuristic generation orders on three out of four language pairs. We next carefully analyze the learned order patterns via qualitative and quantitative analysis. We show that our policy generally follows an outer-to-inner order, predicting the left-most and right-most positions first, and then moving toward the middle while skipping less important words at the beginning. Furthermore, the policy usually predicts positions for a single syntactic constituent structure in consecutive steps. We believe our findings could provide more insights on the mechanism of undirected generation models and encourage further research in this direction.",
        "DOI": "10.18653/v1/2021.findings-emnlp.298",
        "affiliation_name": "The University of North Carolina at Chapel Hill",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Research on China's Primary Industry: Evidence From Regional Analysis Based on SVM and Moran's Index",
        "paper_author": "Jiang S.",
        "publication": "Proceedings of 2021 7th IEEE International Conference on Cloud Computing and Intelligence Systems, CCIS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "With advanced technology and efficient policy management in China's primary industry, productivity has increased significantly. This article aims to use machine learning and Moran's I to analyze the current situation of China's primary industry from a regional perspective. Principal component analysis and Lagrange polynomial interpolation are used for data pre-processing. Classification result from the support vector machine reveals that there exist boundaries between each region based on the features of the primary industry. Our results show that fishery and forestry show positive spatial correlations in the Moran's I scatter diagram, while animal husbandry and farming show negative spatial correlations, and regional agriculture development can improve China's primary industry in the long run.",
        "DOI": "10.1109/CCIS53392.2021.9754653",
        "affiliation_name": "Wenzhou-Kean University",
        "affiliation_city": "Wenzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Evolutionary Approach for AutoAugment Using the Thermodynamical Genetic Algorithm",
        "paper_author": "Terauchi A.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Data augmentation is one of the most effective ways to stabilize learning by improving the generalization of machine-learning models. In recent years, automatic data augmentation methods, such as AutoAugment or Fast AutoAugment have been attracting attention; and these methods improved the results of image classification and object detection tasks. However, several problems remain. Most notably, a larger training dataset requires higher computational costs. When searching with a small dataset in an attempt to determine the data augmentation approach, the true data space and sampling data space do not fully correspond with each other, thereby causing the generalization performance to deteriorate. Moreover, in the existing automatic augmentation methods, the search phase is often dominated by an exceptional sub-policy, which results in a loss of diversity of transformations. In this study, we solved these problems by introducing evolutionary computation to previous methods. As mentioned earlier, maintaining diversity of transformations is essential. Therefore, we adopted the thermodynamical genetic algorithm (TDGA), which can control the population diversity with a specific genetic operator, known as the thermodynamical selection rule. To confirm the effectiveness of the proposed method, computational experiments were conducted using two benchmark datasets, CIFAR-10 and SVHN, as examples. The experimental results show that the proposed method can obtain various useful augmentation sub-policies for the problems while reducing the computational cost.",
        "DOI": "10.1609/aaai.v35i11.17184",
        "affiliation_name": "Osaka Metropolitan University",
        "affiliation_city": "Osaka",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Study on Machine-Learning Algorithms in Crop Yield Predictions specific to Indian Agricultural Contexts",
        "paper_author": "Sharma S.K.",
        "publication": "2021 International Conference on Computational Performance Evaluation, ComPE 2021",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "Prior and well-grounded produces evaluation is vital in quantifying a well and financial assessment at the field level for discovering agricultural commodity strategic action plans for import-export policies and increasing farmer incomes. Crop production projections are performed utilizing machine learning algorithms to estimate a higher crop yield, which is one of the most difficult challenges in the agriculture business. Because of the growing importance of agricultural yield prediction, this article takes an in-depth look at how Machine Learning (ML) approaches may be utilized to forecast crop production. The present state of agricultural yield worldwide is discussed first, followed by a brief introduction of extensively utilized features and forecasting procedures. Forecasting crop yields is a serious issue in agriculture, plus there is a large dataset that makes it arduous for farmers to select seeds and forecast yields. In today's circumstances, since the extension in population, agricultural production must be raised simultaneously to fulfill people's wants. This paper is a detailed study of various aspects of crop yielding in India using machine learning techniques and artificial intelligence.",
        "DOI": "10.1109/ComPE53109.2021.9752260",
        "affiliation_name": "Sri Karan Narendra Agriculture University, Jobner",
        "affiliation_city": "Jaipur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Deep learning offering resilience from trending cyber-attacks, a review",
        "paper_author": "Khanday S.A.",
        "publication": "2021 International Conference on Computational Performance Evaluation, ComPE 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "During the Covid-19 pandemic world has witnessed the rise of cyber-attacks, especially during the Lockdown time course announced by the countries throughout the world, when almost every aspect of life changed the routine from offline to online. Protecting and securing information resources during pandemics has been a top priority for the modern computing world, with databases, banking, E-commerce and mailing services, etc. being the eye-catching credentials to the attackers. Apart from cryptography, machine learning and deep learning can offer an enormous amount of help in testing, training, and extracting negligible information from the data sets. Deep learning and machine learning have many methods and models in the account to detect and classify the different versions of cyber-attacks occasionally, from the datasets. Some of the most common deep learning methods inspired by the neural networks are Recurrent Neural Networks, Convolutional Neural Networks, Deep Belief Networks, Deep Boltzman Networks, Autoencoders, and Stacked Auto-encoders. Also counting machine learning algorithms into the account, there is a vast variety of algorithms that are meant to perform classification and regression. The survey will provide some of the most important deep learning and machine learning architectures used for Cyber-security and can offer protective services against cyber-attacks. The paper is a survey about various categories of cyber-attacks with a timeline of different attacks that took place in India and some of the other countries in the world. The final section of the report is about what deep learning methods can offer for developing and improving the security policies and examining vulnerabilities of an information system.",
        "DOI": "10.1109/ComPE53109.2021.9752099",
        "affiliation_name": "Sharda University",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Deep Reinforcement Learning Based Adaptive Controller of DC Electric Drive for Reduced Torque and Current Ripples",
        "paper_author": "Anugula R.",
        "publication": "2021 IEEE International Conference on Technology, Research, and Innovation for Betterment of Society, TRIBES 2021",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial Intelligence and Machine Learning-based intelligent control algorithms are replacing traditional control algorithms due to their adopting and self-learning capabilities. The DC-DC Buck converter fed DC motor has a wide variety of applications from household appliances to industry level. Conventionally, the proportional-integral controller is widely used to optimally control the speed of DC-DC Buck converter fed DC Motor but the performance deteriorates for parameters changes which lead to increase ripples in torque and current. The demanding task is to control the electric drives for mitigated ripple content in speed operation. This work proposes a new adaptive controller based on deep reinforcement learning (DRL) to mitigate those problems. The simulation results are illustrating that the Deep Deterministic Policy Gradient (DDPG) algorithm performs superior to the PI controller under parameter changes and also proving that the DDPG making the system stable where the PI fails to stabilize it for a wider range of parameter changes.",
        "DOI": "10.1109/TRIBES52498.2021.9751630",
        "affiliation_name": "National Institute of Technology Andhra Pradesh",
        "affiliation_city": "Tadepalligudam",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Land cover classification: a comparative analysis of clustering techniques using Sentinel-2 data",
        "paper_author": "Sharma M.",
        "publication": "International Journal of Sustainable Agricultural Management and Informatics",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "Automated land use land cover (LULC) classification may provide an authentic database of information to the policy makers in various fields like agro-climatic zone planning, waste land inventory projects, vegetation cover analysis, etc. It has a tremendous potential to contribute towards effective policy formulation. This article considers various unsupervised machine learning techniques: K-means, FCM, SOM, meanshift, GMM and HMM for land cover (LC) classification of Sentinel-2 data in the context of Assam, India. These models showed good performance in distinguishing vegetation cover area from the rest of the regions. K-means and FCM showed better performance in comparison to all the considered models. Meanshift correctly classified the continuous stretch of vegetation in study area 2. However, it misclassified between the vegetation and fallow land in study area 1. Similarly, in identifying built-up areas for study area 2 SOM covered the maximum but misclassified severely with other classes in study area 1.",
        "DOI": "10.1504/IJSAMI.2021.122008",
        "affiliation_name": "The Assam Royal Global University",
        "affiliation_city": "Guwahati",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Self-Control and Beliefs Surrounding Others’ Cooperation Predict Own Health-Protective Behaviors and Support for COVID-19 Government Regulations: Evidence from Two European Countries",
        "paper_author": "Kukowski C.",
        "publication": "Social Psychological Bulletin",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "In the current pandemic, both self-regulated health-protective behavior and government-imposed regulations are needed for successful outbreak mitigation. Going forward, researchers and decision-makers must therefore understand the factors contributing to individuals’ engagement in health-protective behavior, and their support for government regulations. Integrating knowledge from the literatures on self-control and cooperation, we explore an informed selection of potential predictors of individuals’ health-protective behaviors as well as their support for government regulations during the COVID-19 pandemic. Aiming for a conceptual replication in two European countries, we collected data in Switzerland (N = 352) and the UK before (N = 212) and during lockdown (n = 132) and conducted supervised machine learning for variable selection, followed by OLS regression, cross-sectionally and, in the UK sample, across time. Results showed that personal importance of outbreak mitigation and beliefs surrounding others’ cooperation are associated with both health-protective behavior and support for government regulations. Further, Swiss participants high in trait self-control engaged in health-protective behavior more often. Interestingly, perceived risk, age, and political orientation consistently displayed nonsignificant weak to zero associations with both health-protective behavior and support. Together, these findings highlight the contribution of self-control theories in explaining COVID-19-relevant outcomes, and underscore the importance of contextualizing self-control within the cooperative social context.",
        "DOI": "10.32872/spb.4391",
        "affiliation_name": "Universität Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland"
    },
    {
        "paper_title": "Asynchronous Advantage Actor-Critic (A3C) Learning for Cognitive Network Security",
        "paper_author": "Muhati E.",
        "publication": "Proceedings - 2021 3rd IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications, TPS-ISA 2021",
        "citied_by": "14",
        "cover_date": "2021-01-01",
        "Abstract": "Undoubtedly, the recent implacable, widespread, and intricate cyber-attacks demand cognitive cyber-defense techniques. Although machine learning (ML) and artificial intel-ligence (AI) algorithms are extensively applied for enhanced network security, existing AI-based agents are impeded by incongruous shifts in actionable intelligence. For instance, the low-cost network data extraction prerequisites are crucial for AI-based network security research, yet seldom. Seemingly, there is increased urgency for unconstrained network data access to improve cyber-AI efficiency in unfamiliar threat scenarios. While host-based attacks can be detected from the analysis of extracted data, network-based attacks require adaptive network traffic ex-amination. This paper proposes an automated network scanning and data-mining technique through open-source service discovery tools for deep reinforcement learning (DRL) based cognitive network intrusion detection system (NIDS). Our proposed DRL-NIDS is developed using an asynchronous advantage actor-critic (A3C) AI method that demonstrates improved results compared to related works. We combine the best parts of predicting both the value and the optimal policy functions in extensive experimentation with 3 datasets, namely UNSW-NB15, AWID, and NSL-KDD. Our experiment shows degraded performance from other state-of-the-art DRL-based NIDS, while our proposed A3C-NIDS achieves a 98.68% accuracy with the least false alarm rate.",
        "DOI": "10.1109/TPSISA52974.2021.00012",
        "affiliation_name": "College of Engineering and Architecture",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Artificial Intelligence in Internal Audit and Risk Assessment",
        "paper_author": "Kahyaoglu S.B.",
        "publication": "Contributions to Finance and Accounting",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "In this study, the effects of artificial intelligence applications, which have gained importance recently, on internal audit and risk assessment are analyzed. Internal audit and risk assessment are critical for the early detection of risks that arise in the processes of businesses that are becoming more complex and exposed to external factors due to digitalization. With the internet of things that are generally accepted all over the world, there are significant differences in the way businesses do business. This situation also forces companies to differentiate internal audit and risk assessment, which is a strategic and integral element of management processes. In this context, this study focuses on the challenges and opportunities faced by internal audit and risk assessment because of digitalization, big data analysis and artificial intelligence applications depending on the rapidly developing digital work environments. Accordingly, the study includes in-depth analysis to contribute to the particularly relevant literature and to develop policy recommendations for audit and risk management professionals.",
        "DOI": "10.1007/978-3-030-72624-9_8",
        "affiliation_name": "Izmir Bakircay University",
        "affiliation_city": "Izmir",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "Online Symbolic Learning of Policies for Explainable Security",
        "paper_author": "Drozdov A.",
        "publication": "Proceedings - 2021 3rd IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications, TPS-ISA 2021",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Statistical Machine Learning (ML) has been proved to be an invaluable tool in many areas including privacy and security. On the other hand, recent advances in the field of Symbolic Learning have included novel scalable algorithms that learn highly accurate classifiers encoded as logic programs. In this paper we advocate adding Symbolic Learning to the security and privacy ML toolset. Through an example in anomaly detection, we present a framework for developing systems capable of performing symbolic-based learning of security policies. Our framework, called Online Learning of Anomaly detection Policies from Historical data (OLAPH), uses a symbolic learning system and a domain-specific function for scoring candidate rules to guide the learning process towards the best policies for anomaly detection. The learned policies are fully explainable since the underlying symbolic learning system is inherently explainable: there is a one-to-one mapping between the learned symbolic rules and the anomaly detection policies. The online feature of OLAPH uses a notion of policy confidence to decide when to relearn the policy and what data to relearn the policy from. OLAPH has been evaluated on a dataset of network requests from a commercial security provider, and shown to have a strong anomaly detection performance in addition to the usability and explainability benefits induced by its symbolic learning approach.",
        "DOI": "10.1109/TPSISA52974.2021.00030",
        "affiliation_name": "Universitat Pompeu Fabra Barcelona",
        "affiliation_city": "Barcelona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "MACHINE LEARNING, MARKET MANIPULATION, AND COLLUSION ON CAPITAL MARKETS: WHY THE “BLACK BOX” MATTERS",
        "paper_author": "Azzutti A.",
        "publication": "University of Pennsylvania Journal of International Law",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "This Article offers a novel perspective on the implications of increasingly autonomous and “black box” algorithms, within the ramification of algorithmic trading, for the integrity of capital markets. Artificial intelligence (AI) and particularly its subfield of machine learning (ML) methods have gained immense popularity among the great public and achieved tremendous success in many real-life applications by leading to vast efficiency gains. In the financial trading domain, ML can augment human capabilities in price prediction, dynamic portfolio optimization, and other financial decision-making tasks. However, thanks to constant progress in the ML technology, the prospect of increasingly capable and autonomous agents to delegate operational tasks and even decision-making is now beyond mere imagination, thus opening up the possibility for approximating (truly) autonomous trading agents anytime soon. Given these spectacular developments, this Article argues that such autonomous algorithmic traders may involve significant risks to market integrity, independent from their human experts, thanks to self-learning capabilities offered by state-of-the-art and innovative ML methods. Using the proprietary trading industry as a case study, we explore emerging threats to the application of established market abuse laws in the event of algorithmic market abuse, by taking an interdisciplinary stance between financial regulation, law and economics, and computational finance. Specifically, our analysis focuses on two emerging market abuse risks by autonomous algorithms: market manipulation and “tacit” collusion. We explore their likelihood to arise in global capital markets and evaluate related social harm as forms of market failures. With these new risks in mind, this Article questions the adequacy of existing regulatory frameworks and enforcement mechanisms, as well as current legal rules on the governance of algorithmic trading, to cope with increasingly autonomous and ubiquitous algorithmic trading systems. We demonstrate how the “black box” nature of specific ML-powered algorithmic trading strategies can subvert existing market abuse laws, which are based upon traditional liability concepts and tests (such as “intent” and “causation”). We conclude by addressing the shortcomings of the present legal framework and develop a number of guiding principles to assist legal and policy reform in the spirit of promoting and safeguarding market integrity and safety.",
        "DOI": "NA",
        "affiliation_name": "Universität Hamburg",
        "affiliation_city": "Hamburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Measuring Consumption Changes in Rural Villages based on Satellite Image Data - A Case Study for Thailand and Vietnam",
        "paper_author": "Wolk F.",
        "publication": "Proceedings - 2021 17th International Conference on Mobility, Sensing and Networking, MSN 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Obtaining accurate and timely estimates of socioeconomic status at fine geographical resolutions is essential for global sustainable development and the fight against poverty. However, data related to local socio-economic dynamics in rural villages is often either unavailable or outdated. To fill this gap, predicting local economic well-being with satellite imagery and machine learning has shown promising results. While state-of-the-art analyses currently mostly focus on predicting the levels of socio-economic status, finding temporal changes in rural villages' economic well-being is essential for tracking the impacts of public policies (targeting e.g., poverty alleviation or access to various public services). In this paper, we propose an approach that utilizes pixel-wise differences in satellite images to classify temporal changes in average and median consumption expenditures (and income) in rural villages in Thailand and Vietnam between 2007 and 2017. We can distinguish between 'Decline', 'Stagnation' and 'Growth' in these outcomes with an F1 score of 58.8% using a Logistic Regression model. Regression-based approaches achieve an R2 of up to 32.5% when predicting actual changes in these outcomes. Our approach demonstrates the feasibility of satellite-based estimates for measuring changes in local socio-economic dynamics.",
        "DOI": "10.1109/MSN53354.2021.00092",
        "affiliation_name": "Georg-August-Universität Göttingen",
        "affiliation_city": "Gottingen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Intelligent IDS Chaining for Network Attack Mitigation in SDN",
        "paper_author": "Zolotukhin M.",
        "publication": "Proceedings - 2021 17th International Conference on Mobility, Sensing and Networking, MSN 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Recently emerging software-defined networking allows for centralized control of the network behavior enabling quick reactions to security threats, granular traffic filtering, and dynamic security policies deployment making it the most promising solution for today's networking security challenges. Software-defined networking coupled with network function virtualization extends conventional security mechanisms such as authentication and authorization, traffic filtering and firewalls, encryption protocols and anomaly-based detection with traffic isolation, centralized visibility, dynamic flow control, host and routing obfuscation, and security network programmability. Virtualized security network functions may have different effects on security benefit and service quality, thus, their composition has a great impact on performance variance. In this study, we focus on solving the problem of optimal security function chaining with the help of reinforcement machine learning. In particular, we design an intelligent defense system as a reinforcement learning agent which observes the current network state and mitigates the threat by redirecting network traffic flows and reconfiguring virtual security appliances. Furthermore, we test the resulting system prototype against a couple of network attack classes using realistic network traffic datasets.",
        "DOI": "10.1109/MSN53354.2021.00123",
        "affiliation_name": "University of Jyväskylä",
        "affiliation_city": "Jyvaskyla",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "On the Prediction of Automobile Insurance Claims: The Personalization versus Confidence Trade-off",
        "paper_author": "Hosein P.",
        "publication": "2021 IEEE International Conference on Technology Management, Operations and Decisions, ICTMOD 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "In order to determine an appropriate auto insurance policy premium one needs to take into account the risk associated with the drivers and cars on the policy. The premium is then typically a combination of the administrative and other costs required to support this customer, the profit margin desired by the provider (which in turn depends on the competition) and finally on the expected claims to be made on this policy based on risk. Given multiple features of the policy (age and gender of drivers, value of car, etc.) one can potentially provide personalized insurance policies based specifically on these policy features. However, as the level of personalization increases, the quantity of data available for predicting individual claim rates (the average total claim value per year) decreases and hence the robustness of the estimate decreases. The optimal level of personalization will depend on the number of samples and attributes as well as factors such as the variance of the claim rate for different attributes and the variation of the claim rate across categories of each attribute. We formulate a mathematical model for this trade-off and demonstrate how one can obtain the optimal choice. We demonstrate using illustrative examples as well as with data from an automobile insurance company.",
        "DOI": "10.1109/ICTMOD52902.2021.9739635",
        "affiliation_name": "The University of the West Indies, St. Augustine Campus",
        "affiliation_city": "St Augustine",
        "affiliation_country": "Trinidad and Tobago"
    },
    {
        "paper_title": "Supporting Impaired People with a Following Robotic Assistant by means of End-to-End Visual Target Navigation and Reinforcement Learning Approaches",
        "paper_author": "Dat N.N.",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "24",
        "cover_date": "2021-01-01",
        "Abstract": "We present an improvement in visual object tracking and navigation for mobile robot implementing the advantage actor-critic (A2C) reinforcement learning architecture on top of the Gym-Gazebo framework. This work provides an easier way to integrate reinforcement learning algorithms for navigation and object tracking tasks in robotics field. We train the convolutional-recurrent model employed for the policy estimation in an end-to-end manner. The robot is able to follow a simulated human walking in an indoor environment by using the sequence of images provided by the robot camera. The input of the algorithm is acquired and processed directly in ROS-Gazebo environment. The policy learned by the robot agent proved to generalize well also in an environment with different size and shape with respect to the training one. Moreover, the policy allows the robot to avoid obstacles while following the tracking target. Thanks to these improvements, we can straightforwardly apply the tracking system in a real world robot for a person following task in indoor environments.",
        "DOI": "NA",
        "affiliation_name": "Sapienza Università di Roma",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Social factors influencing household waste management",
        "paper_author": "Bishnoi M.M.",
        "publication": "Emerging Trends to Approaching Zero Waste: Environmental and Social Perspectives",
        "citied_by": "9",
        "cover_date": "2021-01-01",
        "Abstract": "The unprecedented growth in the world’s population, urbanization, and industrialization has led to a surge in the inclusive urban waste. Even though, densely populated urban areas record low recyclables rates. There is an urgent need to improve recycling performance to recover the resources, diverting the waste from going to landfills or incinerators, and raising community awareness about the social and economic importance of waste as a resource. Poignant toward a circular economy needs the active contribution of the community in waste management and segregation of garbage at home. In creating and enlightening the municipal solid waste management structures, considerate basic social aspects to impacting household behavior is generally undervalued but of extreme significance. This chapter aims to support experts and legislators to plan forthcoming policies and interventions to encourage household waste segregation. A general summary of the leading societal aspects persuading household recycling behavior and critical inspiration drivers for behavior change is discussed; it also demonstrates global good practices and recommendations for municipal zones, especially to highly populated. The overall influence of this chapter is in the encouragement of social behavior and green techniques via decreasing contaminants, protecting, resourcing, and recycling.",
        "DOI": "10.1016/B978-0-323-85403-0.00008-6",
        "affiliation_name": "Amity University",
        "affiliation_city": "Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Active Feature Acquisition with Generative Surrogate Models",
        "paper_author": "Li Y.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "22",
        "cover_date": "2021-01-01",
        "Abstract": "Many real-world situations allow for the acquisition of additional relevant information when making an assessment with limited or uncertain data. However, traditional ML approaches either require all features to be acquired beforehand or regard part of them as missing data that cannot be acquired. In this work, we consider models that perform active feature acquisition (AFA) and query the environment for unobserved features to improve the prediction assessments at evaluation time. Our work reformulates the Markov decision process (MDP) that underlies the AFA problem as a generative modeling task and optimizes a policy via a novel model-based approach. We propose learning a generative surrogate model (GSM) that captures the dependencies among input features to assess potential information gain from acquisitions. The GSM is leveraged to provide intermediate rewards and auxiliary information to aid the agent navigate a complicated high-dimensional action space and sparse rewards. Furthermore, we extend AFA in a task we coin active instance recognition (AIR) for the unsupervised case where the target variables are the unobserved features themselves and the goal is to collect information for a particular instance in a cost-efficient way. Empirical results demonstrate that our approach achieves considerably better performance than previous state of the art methods on both supervised and unsupervised tasks.",
        "DOI": "NA",
        "affiliation_name": "The University of North Carolina at Chapel Hill",
        "affiliation_city": "Chapel Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Innovating Educational Policies with Machine Learning in the Covid-19 Pandemic",
        "paper_author": "Shuja J.",
        "publication": "Future of Educational Innovation Workshop Series - Machine Learning-Driven Digital Technologies for Educational Innovation Workshop 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Education, business, industry, and health services have changed course suddenly with the unforeseen outbreak and spread of the COVID-19 pandemic. Governments issued strict procedures and rules mandating social distancing, banning large gatherings, and closing businesses and educational institutions to limit the virus' propagation. As a result, most educational activities migrated to online or hybrid teaching modalities, challenging the assumptions of conventional teaching and affecting teaching quality. Nevertheless, machine learning techniques can provide valuable insights to guide educational policies in the Covid-19 pandemic. The two main issues of higher education are: (a) what should be the mode of instruction in the ongoing health crisis? What are the health risks associated with on-campus education? And (b) if the mode of instruction is online or hybrid, what are the effects of online sessions on existing on-campus and country-wide network facilities? What are the solutions for network resource optimization? To answer these questions, we turned our attention to innovative machine learning techniques that have impacted every field of science and technology. We advance the idea of applying machine learning clustering techniques to form student communities in an edge network that can be facilitated with multicast routing to limit network congestion. Moreover, we propose and utilize machine learning classifiers to sort a person's risk based on their social distance from their contacts.",
        "DOI": "10.1109/IEEECONF53024.2021.9733754",
        "affiliation_name": "COMSATS University Islamabad, Abbottabad Campus",
        "affiliation_city": "Abbottabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Towards Tight Bounds on the Sample Complexity of Average-reward MDPs",
        "paper_author": "Jin Y.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "We prove new upper and lower bounds for sample complexity of finding an ∊-optimal policy of an infinite-horizon average-reward Markov decision process (MDP) given access to a generative model. When the mixing time of the probability transition matrix of all policies is at most tmix, we provide an algorithm that solves the problem using Õ(tmix∊-3) (oblivious) samples per state-action pair. Further, we provide a lower bound showing that a linear dependence on tmix is necessary in the worst case for any algorithm which computes oblivious samples. We obtain our results by establishing connections between infinite-horizon average-reward MDPs and discounted MDPs of possible further utility.",
        "DOI": "NA",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Cyborg: the new subject formed by man-machine convergence in digital educational space",
        "paper_author": "Wu J.",
        "publication": "Proceedings - 2021 2nd International Conference on Information Science and Education, ICISE-IE 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Compared with the traditional school classroom, the network classroom has changed a lot, not only a change in teaching methods and teacher-student interaction, but also a highly media convergence of people and media, which produce a new subject in classroom, cyborg. The new subject comes from the change of classroom environment, realizing through three steps: \"the fusion of virtual and real space\", \"the unclear boundary between public and private\", which leads to \"the difficulty of role conversion\". Cyborg has new behavior logic, which lead to the deconstructing in views of teacher-student, curriculum, teaching, and finally, the traditional pedagogy. As a result, the managers of education system and educators should realize the turning of subject in classroom, formulating better and suitable policies.",
        "DOI": "10.1109/ICISE-IE53922.2021.00175",
        "affiliation_name": "Communication University of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "COVID-19 Influence: A General Analysis using Machine Learning Methods",
        "paper_author": "Chen Y.",
        "publication": "Proceedings - 2021 3rd International Conference on Machine Learning, Big Data and Business Intelligence, MLBDBI 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, we mainly investigate how COVID-19 affects society in multiple ways, such as infected, death, and recovered population, air and ground transportation, and unemployment rate in specific countries. This is important to study since it can help the government create a specific policy to minimize the negative influence of COVID-19 on our society as a whole. Recent works focus on the prevention of COVID-19 and the efficiency of specific immunization. However, the influence of COVID-19 in a specific area of society, such as transportation, has not been paid enough attention to. We first used K-means to find similarities between countries, then we grouped all nations by their continents and used bar plots to visualize how each continent performs. Then, we used matplotlib to visualize the influence of pandemics on air transportation and ground transportation of the U.S. Finally. We create an interactive visualization that investigates the unemployment rate in specific countries, such as China, the United States, Japan, the United Kingdom, and Canada, during the pandemic period. Our methods show all those continents, including Africa, Asia, Australia/Oceania, Europe, North America, and South America, can be divided into five clusters according to the test percentage, and South America represents the highest death percentage. Europe has both the highest test and infected percentage. For both air transportation and inbound ground transportation, revenue and numbers of transportation dropped dramatically at the beginning of April 2020, which is the outbreak of COVID-19 in the U.S. Similarly, the unemployment rate for North America suddenly boost.",
        "DOI": "10.1109/MLBDBI54094.2021.00060",
        "affiliation_name": "Shanghai Ocean University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Energy Internet: A Novel Green Roadmap for Meeting the Global Energy Demand",
        "paper_author": "Xue Z.",
        "publication": "5th IEEE Conference on Energy Internet and Energy System Integration: Energy Internet for Carbon Neutrality, EI2 2021",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "Energy Internet has caught an attention of the global academic community, and it is being implemented actively. This paper describes the basic features and the key structure of Energy Internet, proposes a hierarchical model, and presents key technologies, such as distributed energy storage technology, energy router technology, big data technology and blockchain, etc. It also summarizes the evolving status of Energy Internet in the US, Germany, Japan, and China. Based on the analysis, the viable implementing measurements are suggested for accelerating the realization of Energy Internet, i.e. designing a comprehensive plan for the Energy Internet based on the prevailing conditions and facts of each country, formulating related standards and policies for Energy Internet, encouraging the development of related enterprises and demonstration projects, and promoting new technologies for Energy Internet.",
        "DOI": "10.1109/EI252483.2021.9713467",
        "affiliation_name": "North China Electric Power University (Baoding)",
        "affiliation_city": "Baoding",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Applying Machine Learning Approach to Start-up Success Prediction",
        "paper_author": "Piskunova O.",
        "publication": "Scientific Horizons",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Predicting the success of a new venture has always been a topical issue for both investors and researchers. Nowadays, it has become even more relevant concerning start-ups-young innovative and technology enterprises aimed at scaling their businesses. The purpose of this study is to create a model for predicting start-ups' success based on their descriptive characteristics. A model that connects such start-up features as the period from foundation to the first financing, the area of activity, type, and amount of the first financing round, business model, and applied technologies, with the start-up investment success, which refers to re-investment, has been developed using data from the Dealroom platform on statistics of start-ups activity and their description. The final sample included 123 start-ups that are founded or operate in Ukraine. Three machine learning algorithms are compared: Logistic Regression, Decision Tree, and Random Forest. Acceptable results were obtained in terms of Accuracy, Sensitivity, and F-score, despite the limited data. The best model concerning start-up success prediction is determined by a Decision Tree, with an average effectiveness of 61%, 55%, and 52%, respectively. The AUC level for the Decision Tree achieved 58%, which is lower than the Logistic Regression and Random Forest scores (65%). But the last models had done so well by better predicting start-up failures, while more practical is the ability to predict their success. All models showed an acceptable level of AUC to confirm with confidence their effectiveness. The decision support system for the investment object can be helpful for entrepreneurs, venture analysts, or politicians who can use the built models to predict the success of a start-up. This forecast, in turn, can be used to drive better investment decisions and develop relevant economic policies to improve the overall start-up ecosystem",
        "DOI": "10.48077/scihor.24(11).2021.72-84",
        "affiliation_name": "Kyiv National Economic University named after Vadym Hetman",
        "affiliation_city": "Kyiv",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "Network Security Policy Automation: Enterprise Use Cases and Methodologies",
        "paper_author": "Zarny M.",
        "publication": "Research Anthology on Recent Trends, Tools, and Implications of Computer Programming",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Network security policy automation enables enterprise security teams to keep pace with increasingly dynamic changes in on-premises and public/hybrid cloud environments. This chapter discusses the most common use cases for policy automation in the enterprise, and new automation methodologies to address them by taking the reader step-by-step through sample use cases. It also looks into how emerging automation solutions are using big data, artificial intelligence, and machine learning technologies to further accelerate network security policy automation and improve application and network security in the process.",
        "DOI": "10.4018/978-1-6684-3694-3.ch006",
        "affiliation_name": "vArmour Networks",
        "affiliation_city": null,
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning model to predict electricity demand and thermal generation during the pandemic",
        "paper_author": "Jiang R.",
        "publication": "Proceeding - 2021 China Automation Congress, CAC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Owing to the global lockdown caused by the pandemic of COVID-19, the electricity demand is greatly affected, and the electricity market is also constantly fluctuating. During the pandemic period, the prediction of electricity demand is crucial to the economy and power dispatching. In this study, we combine the pandemic data and government anti-pandemic policies data to predict the electricity demand of the Contiguous United States by using the artificial neural network and recurrent neural network. In addition, the linear regression method is used to forecast the thermal generation with total generation data. Some experiments have developed to verify the effectiveness of the model. Then the model is used to forecast electricity demand and thermal generation under different policies and pandemic development, and the result were analyzed.",
        "DOI": "10.1109/CAC53003.2021.9727468",
        "affiliation_name": "Chongqing University",
        "affiliation_city": "Chongqing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Adversarial Learning-Based Automatic Evaluator for Image Captioning",
        "paper_author": "Ma Q.",
        "publication": "Proceeding - 2021 China Automation Congress, CAC 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Image captioning imitates the process of humans describing the visual world using natural language. Evaluating image captioning remains a challenging task. Current methods mainly focus on the similarity between the generated description and reference texts, despite the direct relevance of the caption and the corresponding image. In this paper, we propose an adversarial learning-based evaluator. The evaluator is designed on Conditional Generative Adversarial Networks and trained with Proximal Policy Optimization. Since it directly works on the relationship between images and descriptions, our model takes advantage of references of other similar images in the dataset. It gives more reliable judgment than state-of-the-art methods, taking variability of natural language into consideration for better evaluation.",
        "DOI": "10.1109/CAC53003.2021.9728653",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Preparing with predictions: Forecasting epidemics with artificial intelligence",
        "paper_author": "DeCaprio D.",
        "publication": "Leveraging Artificial Intelligence in Global Epidemics",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "In the early phases of an epidemic response, our success will largely be dictated by our preparedness. Our ability to forecast likely scenarios is crucial in cases where responses must be made quickly and with limited information.",
        "DOI": "10.1016/B978-0-323-89777-8.00009-9",
        "affiliation_name": "Inc",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Harnessing big data to strengthen evidence-informed precise public health response",
        "paper_author": "Asokan G.V.",
        "publication": "Big Data in Psychiatry and Neurology",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "A recent estimate suggests that more than 60% of the global burden of disease was attributable to noncommunicable diseases; 28% of communicable, maternal, neonatal, and nutritional diseases; and around 10% of injuries. Among the infectious diseases, the frequency of emerging and reemerging pathogens mostly due to zoonoses appears more quickly than before and causes epidemics. Data on disease burden, research on intervention effectiveness, and estimates of the resultant health benefits for the population are key to inform public health response. On a population perspective, the success of precision public health response relies on contributions from health informatics, big data, and genomics to prevent disease and improve health care. Precision public health is a technology driven using big data for a more precise description, and analyses of individuals and population groups for improving the overall health of populations. In the 21st century of the digital world, the policy makers are inspired by the continuous and rapid data transformation. The Big data and digital transformation of public health systems forms the bases for research and action. The big data revolution is envisaged to overcome the barriers in the existing traditional surveillance systems and improve the granularity and timeliness of available epidemiological information, with hybrid systems augmenting rather than supplanting traditional surveillance systems. By leveraging the volume of health data and the technologies like big data, machine learning, internet of things (IoT), and artificial intelligence (AI) would augment public health response strategies. Further, the big data and AI-based infectious disease surveillance algorithms captured and analyzed in real time, aid and signal early infectious disease detection, contact tracing, and predicts the course of a pandemic. However, dealing with massive multinomics of big data that is not a priori can be challenging; nevertheless, the benefits in the public health sector are numerous. It has provided opportunities to understand public health in depth and respond with precision.",
        "DOI": "10.1016/B978-0-12-822884-5.00003-9",
        "affiliation_name": "University of Bahrain",
        "affiliation_city": "Zallaq",
        "affiliation_country": "Bahrain"
    },
    {
        "paper_title": "Monitoring, Predicting, and Optimizing Energy Consumptions: A Goal Toward Global Sustainability",
        "paper_author": "Cardoso P.J.S.",
        "publication": "Research Anthology on Clean Energy Management and Solutions",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Energy consumption and, consequently, the associated costs (e.g., environmental and monetary) concern most individuals, companies, and institutions. Platforms for the monitoring, predicting, and optimizing energy consumption are an important asset that can contribute to the awareness about the ongoing usage levels, but also to an effective reduction of these levels. A solution is to leave the decisions to smart system, supported for instance in machine learning and optimization algorithms. This chapter involves those aspects and the related fields with emphasis in the prediction of energy consumption to optimize its usage policies.",
        "DOI": "10.4018/978-1-7998-9152-9.ch002",
        "affiliation_name": "Universidade do Algarve",
        "affiliation_city": "Faro",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Metamorphosis of Industrial IoT using Deep Leaning",
        "paper_author": "Biswas A.",
        "publication": "Signals and Communication Technology",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Smart production is the technical progression of the global moratorium's (IIoT) Industrial Things Internet. Currently, the (IoT) Internet of Things is the omnipresent adoption of a shared environment with diverse entities; for example, share erudition in a full spectrum of device implementations worldwide. This chapter acknowledges the key developments in Industrial IoT Access Control and analyzes a new authorization system and process flexibility customized to IIoT. Precisely the kind of protocols and applications in Industrial IoT networks and computers, preceding access control is difficult. Well, industry creates efficiency; nevertheless, there are multiple activities in industries that are also labor-intensive and ineffective manually. For example, nowadays, in a warehouse or out in the market, inventory of quality management is only automated for an insignificant excess of goods so creating such automation makes economic sense. The basic design of deep learning is that the computer learns from past data, knowledge data, observations it advances, and can forecast new unknown scenarios with any technical headways by artificial neural networks. The Deep Learning (DL) approach appears in the form of a widespread manner that helps IIoT machines accessible and cost-friendly with vast quantities of quality inspection materials. To accomplish these goals, it requires to review the current access control mechanism and architecture and audit IIoT’s access control responsibilities using DL. Using anomaly detection, deep learning will predict and determine when processes are likely to malfunction, scheduling the control and maintaining the whole process going much smoother and more effectively. The IIoT program measures efficiency more reliably through DL approach due to the vast number of Big databases at low cost by cloud storage. The core components of IoT’s protection and privacy are access management and Authentication infrastructure, honesty, availability and secrecy are the key safety attributes that suit inefficient access control. Authentication, Authorization, and Accountability (AAA) are three full access control features. These AAA involve phases of a collection of rules (security and regulation), model implementation, structure, policy execution, and compliance of the prescribed protocol. The Industrial Internet of Things must fulfill the duty (policy, model, mechanism) to fulfill the goal. Using a Deep learning mechanism, the OS will decide depending on the protection label scheme. Access management mechanisms identify users by checking deep-learning multifactor authentication. It needs several users to authenticate and approve the required level to reach the next execution. This chapter contains four separate access control models that explain numerous protection and regulation phrases. If the trained model is able, it can access power over IIoT applications effectively, making sense and cost-friendly. Deep learning techniques are on the various levels of non-linear and processing units extracting illuminating elements, combining the controlled and unsupervised neural networking system. It converges on securing Industrial IoT application.",
        "DOI": "10.1007/978-981-16-6186-0_1",
        "affiliation_name": "Tartu Ülikool",
        "affiliation_city": "Tartu",
        "affiliation_country": "Estonia"
    },
    {
        "paper_title": "Enabling Intelligent Onboard Guidance, Navigation, and Control Using Near-Term Flight Hardware.",
        "paper_author": "Wilson C.",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Future space missions will require various technological advancements to meet more stringent and challenging requirements. Next generation guidance, navigation, and control systems must safely operate autonomously in hazardous and uncertain environments. While the focus of these developments is often on flight software, spacecraft hardware also creates computational limitations for the algorithms which run onboard. Here we look at the feasibility of implementing intelligent control onboard a spacecraft. Intelligent control methods combine theories from automatic control, artificial intelligence, and operations research to derive control systems capable of handling substantial uncertainties. This has clear benefits for operating in unknown space environments. However, most modern intelligent systems require substantial computational power which is not available onboard spacecraft. Recent advancements in single board computers have created much physically lighter and less power-intensive processors which are suitable for spaceflight and purpose built for machine learning. In this study we implement a reinforcement learning based controller on NVIDIA Jetson Nano hardware. We apply this controller to a powered descent guidance problem using a simulated Mars landing environment. The initial offline approach used to derive the controller has two steps. First, optimal trajectories and guidance laws are calculated using nominal environment conditions. These are then used to initialise a reinforcement learning agent which learns a control policy that copes with environmental uncertainties. In this case the control policy is parameterised as a neural network which can also update its weights online from real time observations. Online updates use a novel method of weight updates called Extreme Q-Learning Machine to tune the output weights of the neural network in operation. We show that this control system can be deployed on hardware which is sufficiently light, in terms of power and mass, to be used onboard spacecraft. This demonstrates the potential for intelligent controllers to be used on flight suitable hardware.",
        "DOI": "NA",
        "affiliation_name": "University of Strathclyde",
        "affiliation_city": "Glasgow",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Accessible Decision Support Systems Utilizing the Environment-Vulnerability-Decision-Technology modelling framework",
        "paper_author": "Lombardo S.",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The Environment-Vulnerability-Decision-Technology (EVDT) integrated modelling framework developed by the Space Enabled Research Group at MIT considers the interactions between the environment, societal impact, human decision-making, and technology design to support decision-making. Local leaders in coastal communities in Pekalongan, Indonesia and the Yurok tribal community in California face societal challenges and related decisions regarding the planting of mangroves to improve coastal resilience versus other man-made techniques to mitigate flooding, and the monitoring and protection of indigenous natural resources. The EVDT framework is being applied to develop accessible, web-based Decision Support Systems (DSS) utilizing integrated modelling and Earth Observation (EO) satellite data to support decision-makers seeking to address complex societal challenges at the intersection of environmental factors, socioeconomic factors, and technology investments. DSS provide a value-added product to aid leaders in addressing decisions by helping them understand complex relationships between these factors, adapt to changes within the community, and address the needs of multiple stakeholders. The EVDT framework is being utilized to develop DSS that output descriptive and predictive models for decision-makers. These models will allow decision-makers to examine historical data from environmental and socioeconomic domains and explore their relationships under varying simulated conditions to evaluate policies or technological investments. These DSS make extensive use of EO observation data as inputs to environmental and socioeconomic analyses that employ cloud computing and will use machine learning algorithms to classify features of interest in the satellite data. These models can be employed by local leaders to analyse societal challenges at the intersection of environmental and socioeconomic domains such as assessing the impact of flood mitigation interventions in Pekalongan, Indonesia, or balancing revenue, resilience, and cultural values in the forest management practices of the Yurok Tribe. This work details the EVDT framework and provides an overview of applications of EVDT to the development of DSS for use in sustainable development situations at the intersection of multiple domains. Prototype versions of DSS employing cloud computing techniques in remote sensing analyses and integrated models are presented. Efforts to integrate local collaborators in coastal and indigenous communities into the DSS development process to improve DSS utility and value are also discussed. Planned efforts for quantitative assessment of DSS by relevant end-users are also touched upon.",
        "DOI": "NA",
        "affiliation_name": "Massachusetts Institute of Technology",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Ask&amp;Confirm: Active Detail Enriching for Cross-Modal Retrieval with Partial Query",
        "paper_author": "Cai G.",
        "publication": "Proceedings of the IEEE International Conference on Computer Vision",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "Text-based image retrieval has seen considerable progress in recent years. However, the performance of existing methods suffers in real life since the user is likely to provide an incomplete description of an image, which often leads to results filled with false positives that fit the incomplete description. In this work, we introduce the partial-query problem and extensively analyze its influence on text-based image retrieval. Previous interactive methods tackle the problem by passively receiving users' feedback to supplement the incomplete query iteratively, which is time-consuming and requires heavy user effort. Instead, we propose a novel retrieval framework that conducts the interactive process in an Ask-and-Confirm fashion, where AI actively searches for discriminative details missing in the current query, and users only need to confirm AI's proposal. Specifically, we propose an object-based interaction to make the interactive retrieval more user-friendly and present a reinforcement-learning-based policy to search for discriminative objects. Furthermore, since fully-supervised training is often infeasible due to the difficulty of obtaining human-machine dialog data, we present a weakly-supervised training strategy that needs no human-annotated dialogs other than a text-image dataset. Experiments show that our framework significantly improves the performance of text-based image retrieval. Code is available at https://github.com/CuthbertCai/Ask-Confirm.",
        "DOI": "10.1109/ICCV48922.2021.00185",
        "affiliation_name": "Tencent",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Review on Security and Privacy Concern in IoT Health Care",
        "paper_author": "Chatterjee J.",
        "publication": "Studies in Big Data",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Internet of things (IoT) is one of the most optimistic technologies that have remarkably changed the concept of the healthcare industry which offers a huge added value in the identification of diseases and monitoring the patient remotely. The research community and the public sector are very much focused on this application domain to develop various e-health regulations and policies. However, IoT-based healthcare systems suffer from several security issues that are varied from other domains in terms of methodologies, motivations, and consequences, due to the complexity of the environment and the nature of the deployed devices. The expansion of healthcare IoT devices, along with the absence of network segmentation, inadequate access controls, and dependency on legacy systems has widen attack area for cybercriminals to exploit or steal personally identifiable information (PII) and protected health information (PHI) without interrupting healthcare information transmission processes. Predicting attacks quantitatively may reduce the risk of fraudulent data; different approaches were noticed to identify and predict the IoT intrusions such as network metric based and machine learning approach. This work will review the related security models to identify the approaches of intrusion detection and prediction related to IoT devices as well as software connected in healthcare systems. This provides an overview of the most recent threats and security issues for IoT-based healthcare systems that may affect the efficient and effective functioning of such infrastructures.",
        "DOI": "10.1007/978-981-15-4112-4_12",
        "affiliation_name": "Supreme Knowledge Foundation Group of Institutions",
        "affiliation_city": "Chandannagar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "uTakeCare: Unlock full decentralization of personal data for a respectful decontainment in the context of COVID-19: Toward a digitally empowered anonymous citizenship",
        "paper_author": "Amour L.",
        "publication": "Data Science for COVID-19 Volume 1: Computational Perspectives",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "To control coronavirus disease 2019 (COVID-19), most countries have opted for a containment policy. When a decision of decontainment has to be taken, a question emerges regarding the digital strategy to adopt: Should we track citizens? All of them or only persons who contracted COVID-19? Should we take measures to protect elderly people or people suffering from co-morbidities? Many applications and approaches have been proposed to ensure public safety in the context of COVID-19. In this chapter, we will start by making an inventory of these applications, discuss strategies and technologies adopted, and categorize them. Thereafter we will present an approach consisting in calculating a vulnerability score to propose a solution for protecting people at risk. Then, we will detail the architecture of “uTakeCare, \" an open-source application that we have implemented, as well as the method used to calculate the vulnerability score. This method is based on a belief function theory and machine learning techniques. Finally, we will discuss the ethical and legal issues of this application and the methods to be used to address them (e.g., zero-knowledge proof, smart contracts, etc.) as a way to complement general data protection regulation (roadmap to develop personal data) requirements with ethics-by-design and self-sovereign identity solutions.",
        "DOI": "10.1016/B978-0-12-824536-1.00028-9",
        "affiliation_name": "Université Paris Cité",
        "affiliation_city": "Paris",
        "affiliation_country": "France"
    },
    {
        "paper_title": "A Comparative Study of Machine Learning Algorithms to Predict Road Accident Severity",
        "paper_author": "Ahmed S.",
        "publication": "Proceedings - 2021 20th International Conference on Ubiquitous Computing and Communications, 2021 20th International Conference on Computer and Information Technology, 2021 4th International Conference on Data Science and Computational Intelligence and 2021 11th International Conference on Smart Computing, Networking, and Services, IUCC/CIT/DSCI/SmartCNS 2021",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "Road accidents is a global issue that cause deaths and injuries besides other direct and indirect losses. Countries and international organisations have designed technologies, systems, and policies to prevent accidents the use of big traffic data and artificial intelligence may help develop a promising solution to predict or reduce the risk of road accidents. Most existing studies examine the impact of road geometry, environment, and weather parameters on road accidents. However, human factors such as alcohol, drug, age, and gender are often ignored when determining accident severity. In this work, we considered various contributing factors and their impact on the prediction of the severity of accidents. For this, we studied a set of single and ensemble mode machine learning (ML) methods and compared their performance in terms of prediction accuracy, precision, recall, F1 score, area under the receiver operator characteristic (AUROC). This research considered the road accident severity prediction as a classification problem that can classify the intensity of an accident in two categories: (i) binary classification (e.g. grievous and non-grievous), and (ii) multiclass classification (fatal, serious, minor, and non-injury). Our results show that Random Forest (RF) outperformed other methods' like logistic regression (LR), K-nearest neighbor (KNN), naive Bayes (NB), extreme gradient boosting (XGBoost), and adaptive boosting (AdaBoost) (e.g., 86.64% for binary and 67.67% for multiclass classification) in both single and ensemble ML methods in comparison to other methods considered in this research. LR, KNN, and NB are single mode ML methods that show similar performance to each other for both binary and multiclass classification. Compared to single mode, ensemble ML methods can predict the severity of accident more accurately with the order of RF, XGBoost, and Adaboost the findings from this study can help to gain insights into the accident contributing factors and the severity of injuries as a result.",
        "DOI": "10.1109/IUCC-CIT-DSCI-SmartCNS55181.2021.00069",
        "affiliation_name": "University of Alberta",
        "affiliation_city": "Edmonton",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A Machine Learning Approach to Identify Customer Attrition for a Long Time Business Planning",
        "paper_author": "Aashiqur Reza D.S.A.",
        "publication": "2021 5th International Conference on Electrical Information and Communication Technology, EICT 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Customer attrition is one of the most important studies to be made by any company. A company nowadays entirely relies on the customer. If a customer leaves the service of a particular company, it indicates some lack in the company's services. On the other hand, for a long-Term business policy, a company or an organization needs to focus on those customers who are less likely to decline the company's services in the future. The phenomenon of a customer leaving or reducing the services they had been taking is called customer attrition. For a long-Term business, it's essential to analyze the customer attrition rate and its reasons. In this study, a machine learning approach to customer attrition has been proposed, and an introduction of supervised learning in this area has been analyzed. Studies were made by applying different classifiers to predict customer attrition. The results show that the random forest model can predict customer attrition 96% accurately, better than any other model considered in this study. Not only in accuracy, but the random forest also performed pretty well in other statistics like sensitivity, specificity, and area under the curve. These results confirmed that though data was not balanced (massive difference in both classes for response variable), the random forest model has not picked the standard results only and made the prediction very effective.",
        "DOI": "10.1109/EICT54103.2021.9733713",
        "affiliation_name": "Noakhali Science and Technology University",
        "affiliation_city": "Noakhali",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Proceedings - 2021 IEEE 4th International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2021",
        "paper_author": "NA",
        "publication": "Proceedings - 2021 IEEE 4th International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 23 papers. The topics discussed include: increased robustness of object detection on aerial image datasets using simulated imagery; transfer learning operators for process-oriented cases; privacy-preserving sharing of industrial maintenance reports in industry 4.0; towards intelligent legal advisors for document retrieval and question-answering in German legal documents; controlled query evaluation over ontologies through policies with numerical restrictions; cross-lingual timeline summarization; integrating a general search agent into an imperative programming language; exploring the roles of social media data to identify the locations and severity of road traffic accidents; robustness of Bayesian neural networks to white-box adversarial attacks; a machine learning predictive model to classify severity of breast cancer based on mammographic mass dataset; a machine learning predictive model to classify severity of breast cancer based on mammographic mass dataset; and a survey on state-of-the-art techniques for knowledge graphs construction and challenges ahead.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Using Deep Reinforcement Learning to Evade Web Application Firewalls",
        "paper_author": "Hemmati M.",
        "publication": "Proceedings of 18th International ISC Conference on Information Security and Cryptology, ISCISC 2021",
        "citied_by": "9",
        "cover_date": "2021-01-01",
        "Abstract": "Web application firewalls (WAF) are the last line of defense in protecting web applications from application layer security threats like SQL injection and cross-site scripting. Currently, most evasion techniques from WAFs are still developed manually. In this work, we propose a solution, which automatically scans the WAFs to find payloads through which the WAFs can be bypassed. Our solution finds out rules defects, which can be further used in rule tuning for rule-based WAFs. Also, it can enrich the machine learning-based dataset for retraining. To this purpose, we provide a framework based on reinforcement learning with an environment compatible with OpenAI gym toolset standards, employed for training agents to implement WAF evasion tasks. The framework acts as an adversary and exploits a set of mutation operators to mutate the malicious payload syntactically without affecting the original semantics. We use Q-learning and proximal policy optimization algorithms with the deep neural network. Our solution is successful in evading signature-based and machine learning-based WAFs.",
        "DOI": "10.1109/ISCISC53448.2021.9720473",
        "affiliation_name": "Malek Ashtar University of Technology",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "The application of artificial intelligence technology in the communication engineering industry",
        "paper_author": "Nan Z.",
        "publication": "Proceedings - 2021 International Conference on Networking, Communications and Information Technology, NetCIT 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "With the development of innovative technologies such as big data and machine learning, artificial intelligence technology has become more and more mature and widely used in many fields of social life, which has greatly promoted social progress and brought challenges in the field of security. This paper summarizes the development and policy background of artificial intelligence technology, introduces the status quo of standardization, and discusses the application of artificial intelligence in the field of communication security on the basis of the analysis of artificial intelligence technology applied to the field of communication.",
        "DOI": "10.1109/NetCIT54147.2021.00057",
        "affiliation_name": "Tianjin University of Technology",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Graph Neural Network for Credit Card Fraud Detection",
        "paper_author": "Liu G.J.",
        "publication": "2021 International Conference on Cyber-Physical Social Intelligence, ICCSI 2021",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "With the rapid development of network payment, events of electronic transaction fraud take place often and result in lots of losses to customers and merchants. Therefore, transaction fraud detection is very important, and many detection methods have been studied and applied based on big data and machine learning. Some focused on the relationship of transactions, some on the relationship of original transaction features, and some on the dynamic changes of behaviours of users. However, there is few method to comprehensively characterise them. Hence, we design a weighted multiple graph called Transaction Graph (TG), and use Graph Neural Network (GNN) and TG to train a detection model so that the above characters can be represented comprehensively and thus the detection performance is enhanced obviously. We first construct a group of rules that are represented by a group of logical propositions and used to describe some transaction characters, and assign different weights for these rules to reflect their different importances. In our TG, a node corresponds to a transaction record. If two records satisfy a rule, then the two nodes corresponding to the two records are connected by an edge whose weight is equal to the weight of the rule. Based on our TG, we propose a new sampling policy which can sample neighbour nodes with more useful information. Additionally, we propose a new attention mechanism for GNN in order to decrease the interference of abnormal samples and increase influence of normal ones. Our experiments on a big dataset of real transactions illustrate the advantages of our method compared with some state-of-the-art ones.",
        "DOI": "10.1109/ICCSI53130.2021.9736204",
        "affiliation_name": "Tongji University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Insurance Reserve Prediction: Opportunities and Challenges",
        "paper_author": "Taha A.",
        "publication": "Proceedings - 2021 International Conference on Computational Science and Computational Intelligence, CSCI 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Predicting claims' reserve is a critical challenge for insurers and has dramatic consequences on their managerial, financial and underwriting decisions. The insurers' capital and their underwriting capacity of further business are impacted by inaccurate reserve estimates. Increasing premium rates and adjusting the underwriting policy decisions may balance the impact of unexpected claims, but will have a negative impact on their business opportunities. To address this, several papers focusing on the prediction of insurance reserve have been published in the literature. In this paper, we provide a comprehensive review of the research on the insurance reserve prediction techniques in economics and actuarial science literature as well as machine learning and computer science literature. Moreover, we classify these techniques into different approaches based on the prediction mechanism they use in estimation. For each approach, we survey reserve prediction methods, and then show the similarities and differences among them. In addition, the review is armed with a discussion on the challenges and the future opportunities.",
        "DOI": "10.1109/CSCI54926.2021.00120",
        "affiliation_name": "Technological University Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "A real-time intrusion detection system based on OC-SVM for containerized applications",
        "paper_author": "Zhang L.",
        "publication": "Proceedings - 2021 IEEE 24th International Conference on Computational Science and Engineering, CSE 2021",
        "citied_by": "14",
        "cover_date": "2021-01-01",
        "Abstract": "A Digital Data Marketplace (DDM) is a digital infrastructure to facilitate policy-governed data sharing in a secure and trustworthy manner with container-based virtualization technologies. An intrusion detection systems (IDS) is essential to enforce the policies. We propose a real-time intrusion detection system that monitors and analyzes the Linux-kernel system calls of a running container. We adopt the One-Class Support Vector Machine (OC-SVM) to detect anomalies. The training data of the OC-SVM algorithm is collected and sanitized in a secure environment. We evaluate the detection capability of our proposed system against modern attacks, e.g. Machine Learning (ML) adversarial attacks, with a customized attack dataset. In addition, we investigate the influence of various feature extraction methods, kernel functions and segmentation length with four metrics. Our experimental results show that we can achieve a low FPR, with a worst case of 0.12, and a TPR of 1 for most attacks, when we adopt the term-frequency feature extraction method and we choose segmentation length of 30000. Furthermore, the optimal kernel functions depend on the concrete application being examined.",
        "DOI": "10.1109/CSE53436.2021.00029",
        "affiliation_name": "Universiteit van Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "DECISION TREE BASED CLASSIFICATION and HABITAT SUITABILITY PREDICTION of MIGRATORY BIRD: A CASE STUDY of Vanellus gregarious",
        "paper_author": "Kumar V.",
        "publication": "42nd Asian Conference on Remote Sensing, ACRS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Habitat of any species can be defined as the biotic and abiotic components present in an area that supports the survival and reproduction of the species[15]. If these factors are altered due to any of the natural or anthropogenic reasons, the habitat becomes unsuitable for their survival. As a result of which, they either need to get adapted to the changes or find another suitable habitat. This is the key reason of migration observed in the migratory birds, i.e., when the conditions at their native sites becomes unfavorable for feeding, breeding or nesting, the birds migrate towards the regions with suitable climatic conditions. In this paper, the Vanellus gregarious (Socialbe lapwing) is considered for a case study, which is a winter migrant to India from Russia and Europe to analyze the prime environmental factors that constitutes the habitat of this species. The habitat is mainly influenced by ecological components like bioclimatic variables which includes temperature, precipitation and other climatic information, vegetation type or NDVI. The study is carried out by generating a set of decision rules considering the above components as parameters. The values from each component are used with the occurrences data of species from GBIF to derive rules. Further these set of rules are used as a knowledge classifier in decision tree for classification of suitable habitat. Decision tree is considered as one of the most user-friendly machine learning models because they make no linearity assumptions and automatically discover interactions among attributes. Each migratory birds have its own attributes as environment envelopes which provides different decision rules for classification. Such models can be used to analyze the spatio-temporal migration patterns. Also it can be helpful to understand species distribution, population dynamics and can guide in conservation or policy decisions for protecting threatened and endangered species.",
        "DOI": "NA",
        "affiliation_name": "Birla Institute of Technology, Mesra",
        "affiliation_city": "Ranchi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Cybersecurity Trends and New Challenges for the Space Sector",
        "paper_author": "Scalia T.",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Referring to the definition provided by the International Telecommunication Union, cybersecurity is the collection of tools, policies, security concepts, security safeguards, guidelines, risk management approaches, actions, training, best practices, assurance and technologies that can be used to protect the cyber environment and organisation and user’s assets. Having such a large collection defining cybersecurity justifies the large variety and heterogeneity of competences, going from technical skills (e.g. threat intelligence, malware analysis, security operations, etc.) to nontechnical skills (e.g. cyber risk management, governance, education, etc.), required to be prepared against cyber threats. With the increasing number of connected satellite networks, information security has become a top priority for government regulators and companies in the space industry. The lack of specific cybersecurity requirements for the space assets needs to be addressed in order to reduce the potential vulnerability of space-based infrastructures. The growing concern requiring the identification and deployment of relevant cybersecurity measures and solutions in the space sector, is also reflected in the new release of the ESA Technology Tree (v 4.0 - April 2020), which has included new technological areas, such as Machine Learning Techniques (MLT) and Artificial Intelligence (AI) in On-board Data Subsystems, and AI and Data Security in the Space System Software domain. Furthermore, the ‘Quantum Technologies’ have now been detailed in a dedicated technological group. In our paper, we examine the above-mentioned complexity of the cybersecurity field in the space sector, by reviewing both the scientific literature and the worldwide patents. We combined the ESA Technology Tree, with the state-of-the-art in cybersecurity taxonomies (e.g. JRC, ENISA, etc.) developed to facilitate the categorization of cybersecurity competencies. By using specific keywords, we analysed patent and scientific publication data for the period 2010 - 2020. We identified the global trends, the International Patent Classification (IPC), the geographic distribution, the top assignees and funding sponsors, etc. Patent and literature indicators, integrated with market information, provided a clear evaluation of the related technology trends and readiness levels of cybersecurity in the space domain.",
        "DOI": "NA",
        "affiliation_name": "Agenzia Spaziale Italiana",
        "affiliation_city": "Rome",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Vehicle Detection from UAV Remote Sensing Images Using Deep Learning",
        "paper_author": "Tan L.",
        "publication": "42nd Asian Conference on Remote Sensing, ACRS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "With the development of the city, the number of vehicles in the city is constantly increasing, a large number of vehicles not only increase traffic congestion, but also contribute to the frequent occurrence of traffic accidents, and the public recreational space in the residential area also becomes more and more crowded because of the increase of vehicles. For this problem, the temporal and spatial resolution of satellite remote sensing data are difficult to meet the requirements of urban vehicle information monitoring, while the installation of a large number of fixed cameras is costly and there are many monitoring blind spots. The remote sensing monitoring by UAV can meet this demand with low cost. In this paper, we use UAV to take low-altitude photographs of some stations, highways, neighborhoods in Shanghai and parking lots in Inner Mongolia Autonomous Region to obtain aerial remote sensing images with centimeter-level resolution. In order to obtain higher quality research data, different flight parameters are set during the flight photography process, taking into account the characteristics of the study area and flight management policies. To increase the robustness of the model, different levels of image enhancement are done on the samples before training. Then single target extraction of vehicles in UAV images is performed using the Unet convolutional neural network technique of deep learning. The model training parameters are continuously adjusted during the training process to get the best training results and obtain 99% ultra-high accuracy. Through controlled experiments, it can be seen that the recognition effect of deep learning on vehicles is much better than that of traditional machine learning methods. This experiment shows that the method of this paper is effective and real-time, and can provide a valuable technical means for urban traffic and community management.",
        "DOI": "NA",
        "affiliation_name": "Shanghai Normal University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Methodological innovation/Adaptation for systematic reviews for space medicine",
        "paper_author": "Nasser M.",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Systematic collection, evaluation and synthesis of evidence to inform practice and policy and guide future research has become increasingly essential for conducting the best science. Over the past several decades systematic methodologies for conducting these tasks have been proven to have advantages over non-systematic approaches. Policy makers and clinicians increasingly rely on what are called systematic reviews (SR) to inform policy and practices. Systematic reviews are also used to structure and inform future research, and some funding agencies require that applications to fund new research are accompanied by systematic reviews as these reviews help to reducing avoidable research waste. Methods: We conducted three systematic reviews and currently have a fourth one ongoing - the topics ranged from rehabilitation of astronauts to managing symptoms of ionised radiation and sex differences on the impact of ionised radiation. We have developed new methodology and adapted existing SR methods to address the complexity of questions in space medicine. Results: The methodological innovation areas we identified and developed new approaches for include: - Developing guidance on databases covering space medicine literature and data to develop best practices for space medicine search strategies - Developing and piloting a generalisability checklist for studies conducted in simulation environments, to rate their relevance to space missions - Developing and piloting checklists for quality assessment of in-vitro mechanistic studies to improve their synthesis with animal and human studies to answer complex research questions - Piloting an approach to prioritise outcome measures to inform the step-wise analysis of large amounts of data, to improve responsivity of the evidence synthesis to inform operational procedures - Developing machine learning algorithms to automate steps of the systematic review process e.g. screening and data extraction to increase the speed to conduct the review. Conclusion: The increase in the number, and diversity, of studies conducted in space medicine across different contexts, methods or approaches makes it more difficult to draw conclusions using traditional literature review and scientific consensus. To develop more systematic approaches to synthesize literature, we need to develop new methods to address the existing biases and meta-biases in the literature. This will optimise how we aggregate and evaluate space medicine evidence to inform best practices in space missions.",
        "DOI": "NA",
        "affiliation_name": "Berliner Institut für Gesundheitsforschung",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Vida Decision Support System: An International, Collaborative Project for COVID-19 Management with Integrated Modeling",
        "paper_author": "Reid J.B.",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The Vida Decision Support System (Vida) is an application of the Environment-Vulnerability-Decision-Technology (EVDT) integrated modeling framework specifically aimed at COVID-19 impact and response analysis. The development of Vida has been an international collaboration involving multidisciplinary teams of academics, government officials (including public health, economics, environmental, and demographic data collection officials), and others from six states: Angola, Brazil, Chile, Indonesia, Mexico, and the United States. These collaborators have been involved with the identification of decision support needs, the surfacing and creation of relevant data products, and the evaluation of prototypes, with the vision of creating an openly available online platform that integrates earth observation instruments (Landsat, VIIRs, Planet Lab's PlanetScope, NASA's Socioeconomic Data and Applications Center, etc.) with in-situ data sources (COVID-19 case data, local demographic data, policy histories, mobile device-based mobility indices, etc.). Vida both visualizes historical data of relevance to decision-makers and simulates possible future scenarios. The modeling techniques used include system dynamics for public health, EO-based change detection and machine learning for environmental analysis, and discrete-event simulation of policy changes and impacts. In addition to the direct object of this collaboration (the development of Vida), collaborators have also benefited from sharing individual COVID-19-related insights with the network and from considering COVID-19 response in a more integrated fashion. This work outlines the Vida Decision Support System concept and the EVDT framework on which it is based. The international team is using Vida to evaluate the outcomes in several large cities regarding COVID cases, environmental changes, economic changes and policy decisions. It provides an overview of the overlapping and diverging needs and data sources of each of the collaborating teams, as well as how each of those teams have contributed to the development of Vida. The current state of the Vida prototypes and plans for future development will be presented. Additionally, this work will discuss the lessons learned from this development process and their relevance to other integrated applications.",
        "DOI": "NA",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Reference Architecture for On-Premises Chatbots in Banks and Public Institutions Guidance on Technologies, Information Security and Data Protection",
        "paper_author": "Koch C.",
        "publication": "Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Chatbots have the potential to significantly increase the efficiency of banks and public institutions. Both sectors, however, are subject to special regulations and restrictions in areas such as information security and data protection. The policies of these organizations therefore, in some cases, reject the use of cloud and proprietary products because in their view they lack transparency. As a result, the implementation of chatbots in banks and public institutions often focuses on open-source and on-premises solutions; however, there are hardly any scientific guidelines on how to implement these systems. Our paper aims to close this research gap. The article proposes a reference architecture for chatbots in banks and public institutions that are a.) based on open-source software and b.) are hosted on-premises. The framework is validated by case studies at TeamBank AG and the German Federal Employment Agency. Even if our architecture is designed for these specific industries, it may also add value in other sectors - as chatbots are expected to become increasingly important for the practical application of artificial intelligence in enterprises.",
        "DOI": "NA",
        "affiliation_name": "Universität Potsdam",
        "affiliation_city": "Potsdam",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Motion planning strategy of free-floating space robot based on deep reinforcement learning to capture non-cooperative target",
        "paper_author": "Ouyang Y.",
        "publication": "Proceedings of the International Astronautical Congress, IAC",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Recently, the free-floating space robot with uncontrollable base position and posture, which may reduce fuel cost and extend on-orbit life, has attracted more attention. However, the dynamic coupling between the robot arm and the base increase the difficulty of dynamic modeling of free-floating space robots. In addition, the work environment of space robot is complex, and the work objects are generally non-cooperative targets. Under such conditions, the usage of traditional motion planning methods will increase the amount of calculation and reduce the robustness. With the continuous development of machine learning, intelligent algorithms are also widely used in space engineering. Therefore, a new intelligent motion planning method based on deep reinforcement learning is proposed to meet robustness of free-floating space robot operations. This paper uses deep deterministic policy gradient algorithm (DDPG) to solve the motion planning problem of free-floating space robot in the process of capturing non-cooperative targets. Firstly, the dynamic analysis of the single-Arm six-degree-of-freedom free-floating space robot is completed and the virtual simulation environment is established. Secondly, for the capture task of space robots, an interactive solution framework of \"actor-critic\" is established, and the corresponding neural network is built and connected. At the same time, the state and action of the agent for training are designed, and the reward function is designed according to the capture task requirements of the robotic arm. Finally, using the designed depth deterministic policy gradient algorithm, the free-floating space robot capture task motion planning is trained and analyzed in the established virtual simulation environment to verify the effectiveness of the method. The simulation results show that space robot after training can obtain correct task decisions according to its state, thereby complete the motion planning of the capture task. Simultaneously, once the training is completed, the strategy output action only needs to calculate forward propagation process of the neural network, which enables motion planning in real-Time, indicating that the method has good adaptability and intelligence.",
        "DOI": "NA",
        "affiliation_name": "Northwestern Polytechnical University",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Document Level Hierarchical Transformer",
        "paper_author": "Zaidi N.",
        "publication": "ALTA 2021 - Proceedings of the 19th Workshop of the Australasian Language Technology Association",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Generating long and coherent text is an important and challenging task encompassing many application areas such as summarization, document level machine translation and story generation. Despite the success in modeling intrasentence coherence, existing long text generation models (e.g., BART and GPT-3) still struggle to maintain a coherent event sequence throughout the generated text. We conjecture that this is because of the difficulty for the model to revise, replace or revoke any part that has been generated by the model. In this chapter, we present a novel semi-autoregressive document generation model capable of revising and editing the generated text. Building on recent models by (Gu et al., 2019; Xu and Carpuat, 2020), we propose document generation as a hierarchical Markov decision process with a two level hierarchy, where the high and low level editing programs generate and refine the document. We train our model using imitation learning and introduce roll-in policy such that each policy learns on the output of applying the previous action. Experiments applying the proposed approach convey various insights on the problems of long text generation using our model. We suggest various remedies such as using distilled dataset, designing better attention mechanisms and using autoregressive models as a low level program.",
        "DOI": "NA",
        "affiliation_name": "University of Melbourne",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "2021 International Conference on Forensics, Analytics, Big Data, Security, FABS 2021",
        "paper_author": "NA",
        "publication": "2021 International Conference on Forensics, Analytics, Big Data, Security, FABS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 49 papers. The topics discussed include: myocardial blood flow quantification for evaluation of coronary artery disease; analysis of mental illness using twitter data; track mendacity broadcast using natural language processing; online aid for detecting brain tumor and tuberculosis using deep learning; real time alert system to prevent car accident; evaluation of performance for big data security using advanced cryptography policy; emotion mining from speech in the Covid-19 era: an exploratory study; perception system in autonomous vehicle: a study on contemporary and forthcoming technologies for object detection in autonomous vehicles; raspberry pi forensic investigation and evidence preservation using blockchain; and classification of attention deficit hyperactivity disorder using machine learning.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Implementation of Long Short Term Memory Model in Forecasting Internet Service Sales",
        "paper_author": "Winarno P.A.",
        "publication": "Proceedings - 3rd International Conference on Informatics, Multimedia, Cyber, and Information System, ICIMCIS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Competition in providing internet services in Indonesia is getting tougher. Market demand that is increasingly complicated to predict makes companies have to work more to satisfy customers. The application of forecasting methods for client needs can be a solution. Machine Learning-based forecasting with the Long Short Term Memory (LSTM) method can be one way of making forecasts. The output of this research is the forecasting of the price of the service product which is expected to make the company take policies to take actions that can minimize losses for the client and the company. In this study, the author will use the Long Short Term Memory (LSTM) method to predict the price of internet services at the Hypernet Indodata company using time series data. The data used is internet service sales in 2016-2018 obtained from PT. Hypernet Indodata. The results obtained in this study resulted in a Root Mean Square Error (RMSE) value of 8.7463 and a Mean Absolute Percentage Error (MAPE) of 4.167% indicating that the LSTM model already has the right configuration and is successful in predicting service prices quite well.",
        "DOI": "10.1109/ICIMCIS53775.2021.9699207",
        "affiliation_name": "University of Pembangunan Nasional Veteran Jakarta",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Unlocking the Public Perception of COVID-19 Vaccination Process on Social Media",
        "paper_author": "El-Deeb R.",
        "publication": "Proceedings - 2021 IEEE 10th International Conference on Intelligent Computing and Information Systems, ICICIS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Vaccines are efficient invented weapons to save millions of lives during the global pandemics such as COVID19. The public attitudes to COVID-19 vaccination process should be studied carefully in order to understand the society's opinions and concerns toward it, and to take the appropriate plans by the public health authorities accordingly. The availability of accurate information during the pandemic, its reported sources and their confidentiality play a key role on the public reported opinions toward the vaccination topic. The society used the social media extensively during the pandemic and quarantine periods to track the COVID-19 news and follow the updates of the vaccines' development process. In this study, we focused on revealing the public attitudes of the COVID-19 vaccination process on twitter as a social media platform using machine learning. The tweets are collected and preprocessed for features extraction and reduction step and the K-means clustering algorithm is used to group the vaccines related tweets in order to use the Amazon Comprehend module for sentiment analysis. Most of the reported opinions that discussed the vaccines efficiency, safety, and the governments distribution plans and the policies to secure the doses for their residents were neutral. The second largest group has negative opinions according to the inaccurate information about vaccines development process, their side effects, and unsuccessful reported trials of vaccines production during different pandemic periods. Our study highlighted the urgent need for interactive communications with the society from different cultural and educational backgrounds in order to increase the vaccination awareness and validate its related news. The deliverable speech of the health care decision makers should simplify the vaccines related scientific terms, address the community concerns, and make the vaccination distribution plans publicly available for their underlying communities.",
        "DOI": "10.1109/ICICIS52592.2021.9694202",
        "affiliation_name": "Mansoura University",
        "affiliation_city": "Mansoura",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Meta Navigator: Search for a Good Adaptation Policy for Few-shot Learning",
        "paper_author": "Zhang C.",
        "publication": "Proceedings of the IEEE International Conference on Computer Vision",
        "citied_by": "34",
        "cover_date": "2021-01-01",
        "Abstract": "Few-shot learning aims to adapt knowledge learned from previous tasks to novel tasks with only a limited amount of labeled data. Research literature on few-shot learning exhibits great diversity, while different algorithms often excel at different few-shot learning scenarios. It is therefore tricky to decide which learning strategies to use under different task conditions. Inspired by the recent success in Automated Machine Learning literature (AutoML), in this paper, we present Meta Navigator, a framework that attempts to solve the aforementioned limitation in few-shot learning by seeking a higher-level strategy and proffer to automate the selection from various few-shot learning designs. The goal of our work is to search for good parameter adaptation policies that are applied to different stages in the network for few-shot classification. We present a search space that covers many popular few-shot learning algorithms in the literature, and develop a differentiable searching and decoding algorithm based on meta-learning that supports gradient-based optimization. We demonstrate the effectiveness of our searching-based method on multiple benchmark datasets. Extensive experiments show that our approach significantly outperforms baselines and demonstrates performance advantages over many state-of-the-art methods.",
        "DOI": "10.1109/ICCV48922.2021.00930",
        "affiliation_name": "ByteDance Ltd.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "International Conference on Electrical, Computer, and Energy Technologies, ICECET 2021",
        "paper_author": "NA",
        "publication": "International Conference on Electrical, Computer, and Energy Technologies, ICECET 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 399 papers. The topics discussed include: human-robot interaction using mixed reality; enhancing LSTM for sequential image classification by modifying data aggregation; inertia emulation in low inertia power systems considering frequency measurement effects; classification and detection of chronic kidney disease (CKD) using machine learning algorithms; tuning of multi-input multi-output proportional-integral-derivative controller based on improved linearly and chaotic inertia weight particle swarm optimization; inside and out: a platform to characterize stratification in horizontal electric water heaters; energy cooperative transmission policy for energy harvesting tags; a predictive model for power consumption estimation using machine learning; classification method of motor EEG signals based on EMD and refined composite multi-scale entropy; evaluation and training system of pc operation for elderly, using gazing point and mouse operation; generalized distribution energy systems optimal operation by network flow models; development of motion game for elderly based on sensory stimulus presentation; and perceived levels of ethical responsibilities for a software engineer: computing academics' perspective.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A Generative Framework for Simultaneous Machine Translation",
        "paper_author": "Miao Y.",
        "publication": "EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings",
        "citied_by": "23",
        "cover_date": "2021-01-01",
        "Abstract": "We propose a generative framework for simultaneous machine translation. Conventional approaches use a fixed number of source words to translate or learn dynamic policies for the number of source words by reinforcement learning. Here we formulate simultaneous translation as a structural sequence-to-sequence learning problem. A latent variable is introduced to model read or translate actions at every time step, which is then integrated out to consider all the possible translation policies. A re-parameterised Poisson prior is used to regularise the policies which allows the model to explicitly balance translation quality and latency. The experiments demonstrate the effectiveness and robustness of the generative framework, which achieves the best BLEU scores given different average translation latencies on benchmark datasets.",
        "DOI": "10.18653/v1/2021.emnlp-main.536",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "An Improved Approach for Inverse Kinematics and Motion Planning of an Industrial Robot Manipulator with Reinforcement Learning",
        "paper_author": "Weber J.",
        "publication": "Proceedings - 2021 5th IEEE International Conference on Robotic Computing, IRC 2021",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Robot manipulators have become very popular in many application areas in the last decades. Typically, simplified robot models are used to apply machine learning algorithms, so the particular challenges of using real robots are not taken into account (e.g., joint angle constraints). This work contributes a new approach for controlling manipulators that solves both the inverse kinematics problem and the path planning problem.The paper uses a Deep Deterministic Policy Gradient (DDPG) agent to learn the motion of a robot manipulator designed for industrial use. It introduces a new state space to reliably learn general motions with user-selectable start and target positions with a high success rate. A new reward function improves the robot's path to the target position. In addition, the learned motions result in densely occupied paths, so that the presented learning approach can also be used for path planning of robot manipulators.The new approach outperforms other learned state-of-the-art approaches for solving both the problems of inverse kinematics and of path planning of arm-like robots in terms of success rate and mean error. The approach was applied to a physical robot device and can be easily transferred to other path planning problems.",
        "DOI": "10.1109/IRC52146.2021.00009",
        "affiliation_name": "Hochschule für Angewandte Wissenschaften Würzburg-Schweinfurt",
        "affiliation_city": "Wurzburg",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Translation-based Supervision for Policy Generation in Simultaneous Neural Machine Translation",
        "paper_author": "Alinejad A.",
        "publication": "EMNLP 2021 - 2021 Conference on Empirical Methods in Natural Language Processing, Proceedings",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "In simultaneous machine translation, finding an agent with the optimal action sequence of reads and writes that maintain a high level of translation quality while minimizing the average lag in producing target tokens remains an extremely challenging problem. We propose a novel supervised learning approach for training an agent that can detect the minimum number of reads required for generating each target token by comparing simultaneous translations against full-sentence translations during training to generate oracle action sequences. These oracle sequences can then be used to train a supervised model for action generation at inference time. Our approach provides an alternative to current heuristic methods in simultaneous translation by introducing a new training objective, which is easier to train than previous attempts at training the agent using reinforcement learning techniques for this task. Our experimental results show that our novel training method for action generation produces much higher quality translations while minimizing the average lag in simultaneous translation.",
        "DOI": "10.18653/v1/2021.emnlp-main.130",
        "affiliation_name": "Simon Fraser University",
        "affiliation_city": "Burnaby",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Federated learning-based intrusion detection in SDN-enabled IIoT networks",
        "paper_author": "Duy P.T.",
        "publication": "Proceedings - 2021 8th NAFOSTED Conference on Information and Computer Science, NICS 2021",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "Witnessing the explosion in the number of Internet of Things (IoTs) in industries, Software Defined Networking (SDN) is considered as a flexible, efficient, and programmable approach for network management and security policy enforcement. Particularly, it is more suitable in the context of industrial Internet of Things (IIoT) network comprising heterogeneous devices. Meanwhile, the demand of ensuring cyber threat resistance has more become the serious concern from both academia and industry due to incidents, cyberattacks, personal data breaches reported recently. Many intrusion detection systems (IDS) leverage the advances in machine learning (ML) to build the more efficient attack detector against the unknown malicious actions in the network. Such an approach requires gathering a large amount of network traffic for model training in a centralized platform. It obviously violates the data privacy protection since the network traffic is sensitive information if accessed and used by a third party. To take advantage of private network data from various sources for mutually training detection model, federated learning (FL) is recently introduced as a solution that can address the problem of violating data privacy for ML-based cybersecurity solution during training phase. Thus, this work introduces the FL approach for IDS to facilitate the privacy preserving in model training while collaboratively maintaining the efficiency of attack detection in IIoT context with the leverage of SDN.",
        "DOI": "10.1109/NICS54270.2021.9701525",
        "affiliation_name": "VNUHCM - University of Information Technology",
        "affiliation_city": "Ho Chi Minh City",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Automated Analysis of Pakistani Websites' Compliance with GDPR and Pakistan Data Protection Act",
        "paper_author": "Asif M.",
        "publication": "Proceedings - 2021 International Conference on Frontiers of Information Technology, FIT 2021",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "Privacy policies inform users about how their data is collected, stored, used and shared by organizations. However, users do not read these policies as they are lengthy and difficult to comprehend. This suggests the need for automated techniques for summarizing a privacy policy for the user. This paper presents an effort towards automated analysis of Pakistani websites' privacy policies' compliance with the General Data Protection Regulation and Pakistan Data Protection Act. We compiled a labelled dataset of privacy policies from 120 Pakistani websites belonging to 5 sectors. Four machine learning classifiers were used on this dataset, among which, the Support Vector Machine showed a high accuracy of 97.7% in determining compliance. Our work lays the foundation for developing a tool to automatically analyse the privacy policy of a Pakistani website and check its compliance with GDPR and Pakistan Data Protection Act.",
        "DOI": "10.1109/FIT53504.2021.00051",
        "affiliation_name": "National University of Sciences and Technology",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "Covid-19 Data Analysis using Machine Learning",
        "paper_author": "Bhardwaj A.",
        "publication": "Proceedings - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The COVID-19 epidemic began in Wuhan, China and has now expanded to the majority of a world's nations. The propagation of a pandemic is primarily determined according to each country's policies and social responsibilities. As per the WHO, the attack rate for 23 June 2020 is estimated to be between 1.4 and 2.5. In comparison to industrialized nations, India's position is rather manageable. It would be fascinating to learn about the facts and data surrounding corona cases throughout India. On world meters, many forms of data are provided. We aimed to assess similar information for India and created several predictions on the impacted rate, daily new cases, and daily total completed cases, among others. COVID-19 has cruelly stopped everything within civilization. An examination of COVID-19 records to determine which age groups are the most affected by the virus. Various Machine learning is used to develop predictive model. Algorithms as well as their related performance data are calculated and analysed. Regressor Random Forest and Random Forest The classification algorithm beat all other machine learning algorithm. such as Support Vector Machine, KNN+, Neighbourhood Component Analysis, decision tree classification, and Gaussian Classifier naive Bayesian, Multi linear Regression, various Logistic Classifiers based on the regression technique and the Extreme Gradient Boosting algorithm.",
        "DOI": "10.1109/ICAC3N53548.2021.9725367",
        "affiliation_name": "Galgotias College of Engineering &amp; Technology",
        "affiliation_city": "Greater Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Electronic News Sentiment Analysis Application to New Normal Policy during the Covid-19 Pandemic Using Fasttext and Machine Learning",
        "paper_author": "Aluna R.P.",
        "publication": "2021 International Conference on Artificial Intelligence and Big Data Analytics, ICAIBDA 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The new phase in handling COVID-19 in Indonesia, called New Normal, gives various public perspectives regarding this policy. This study aims to analyze public sentiment towards the New Normal policy through an electronic news comment column. This study uses text data in the form of comments were collected from electronic news media sites, namely www.detik.com and www.kompas.com, and taken from the comments column on Instagram social media, namely the @detikcom account. Also, use FastText method to extract features by converting data into vector values and using three classification methods, Naive Bayes (NB), Support Vector Machine (SVM), and Multilayer Perceptron (MLP). This study conducted a hyperparameter test to obtain the most optimal model. Testing the hyperparameters from FastText produces an optimal model with dimensions of 250, window size 8, epoch 1.000, and a learning rate of 0,0025. Hyperparameter testing was also carried out on the SVM and MLP classifiers. Hyperparameter testing of the SVM and MLP classifiers produces the most optimal model with the SVM method using the RBF kernel, C of 1.000, gamma of 10. In contrast, the MLP method uses the relu activation function, hidden size layer (250,250), adam optimizer, alpha 0,0001, and adaptive learning rate. The classification model was evaluated using K-fold cross-validation to produce an average f1score. The result is for the NB method 72,25% f1score, for the SVM method 92,21% f1score, and for the MLP method 90,75% f1score.",
        "DOI": "10.1109/ICAIBDA53487.2021.9689756",
        "affiliation_name": "Universitas Padjadjaran",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "An overview of artificial intelligence and big data analytics for smart healthcare: requirements, applications, and challenges",
        "paper_author": "Chui K.T.",
        "publication": "Artificial Intelligence and Big Data Analytics for Smart Healthcare",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "Health is our number one priority that is the foundation that we build our life. When traditional sensor networks have been migrated to Internet of things, humans and sensing devices are communicated and linked with internet. Quintillions bytes of data have been generated by humans every day. The ever-increasing ageing population has brought smart healthcare, as one of the crucial and promising visions of smart city and sustainability, relies heavily on the deployment of artificial intelligence (AI) and big data analytics (BDA) to improve the quality of life. The basic requirements for smart healthcare are first discussed. Five selected key applications are reviewed to demonstrate the effectiveness of AI and BDA models. For smart healthcare to be truly functional, emerging challenges in large-scale open health-care data, technology transfer, public acceptance in AI- and BDA-based applications, and policy establishment are receiving much attention.",
        "DOI": "10.1016/B978-0-12-822060-3.00015-2",
        "affiliation_name": "Effat University",
        "affiliation_city": "Jeddah",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "2021 International Conference on Artificial Intelligence and Big Data Analytics, ICAIBDA 2021",
        "paper_author": "NA",
        "publication": "2021 International Conference on Artificial Intelligence and Big Data Analytics, ICAIBDA 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 62 papers. The topics discussed include: AdaBoost support vector machine method for human activity recognition; sentiment classification against the public activity restrictions policy in Jakarta using machine learning models; automatic text summarization with categorization on online news about Indonesian public figures using fuzzy logic method; sentiment analysis of YouTube video comments with the topic of Starlink mission using long short term memory; Indonesian food price prediction with adaptive neuro fuzzy inference system; forecasting inflation in Indonesia using long short term memory; face recognition using fisherface and support vector machine method; stroke risk prediction model using machine learning; and sentiment classification against the public activity restrictions policy in Jakarta using machine learning models.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Sentiment Classification Against the Public Activity Restrictions Policy in Jakarta Using Machine Learning Models",
        "paper_author": "Dennis D.",
        "publication": "2021 International Conference on Artificial Intelligence and Big Data Analytics, ICAIBDA 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "To stop the spread of the COVID-19, the Indonesian government implemented community activities restrictions enforcement (in Indonesian language: Pemberlakuan Pembatasan Kegiatan Masyarakat or PPKM) starting from January 2021. The term PPKM applied are PPKM Mikro (in Indonesian language) or Micro PPKM, PPKM Darurat (in Indonesian language) or Emergency PPKM, and PPKM Level 1-4 or Level 1-4 PPKM. On the other hand, the existing research mostly used Twitter as the data source to do sentiment classification. Therefore, we aimed to classify social media comments on Facebook and YouTube on Level 1-4 PPKM policy in Jakarta. We used \"PPKM Jakarta\"as the keyword topic in August - September 2021 when Level 1-4 PPKM was ongoing. In addition, we compared datasets composition, machine learning models, and features extraction. Random Forest, Naive Bayes, and Logistic Regression were performed as the machine learning models due to they were the top three models on the previous research. We extracted word unigram, word bigram, character trigram, and character quadrigram as the feature extraction. The highest average F-measure was obtained with a 79.6% score of the Logistic Regression model using character quadrigram extraction. We found that comments from Facebook and YouTube were dominated by neutral sentiment (49.8%) with this setup. It means the people of Jakarta started to trust the government in handling the COVID-19 pandemic. Through word cloud analysis, it is recommended that social assistance be reviewed for those directly affected.",
        "DOI": "10.1109/ICAIBDA53487.2021.9689761",
        "affiliation_name": "Telkom University",
        "affiliation_city": "Bandung",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Review on Machine Learning Techniques for International Trade Trends Prediction",
        "paper_author": "Gupta V.",
        "publication": "Proceedings - 2021 3rd International Conference on Advances in Computing, Communication Control and Networking, ICAC3N 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Now days, analyzing the past trend and make future predictions has become an important aspect for every field to growth. By analyzing the economic trends and knowing the future value of important economic variables makes a country more efficient in country's economic planning and developing policies. This can be achieved by increased application of machine learning more effectively and accurately. In recent years, Machine Learning techniques have been suggested as alternative approach to traditional statistical methods by many authors in the field of economics. As international trade policies critically affects employment and wages of a country that is important aspect for growth of a country, for policy makers all across the world, predicting future patterns of international trade is a top priority. This paper presented a literature review of the works where machine-learning techniques have been used in international trade trends prediction. The findings reveal that there is a growing interest in developing machine learning models for economic forecasting in comparison to conventional statistical methods.",
        "DOI": "10.1109/ICAC3N53548.2021.9725585",
        "affiliation_name": "Indira Gandhi Delhi Technical University for Women",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Learning to Synthesize Programs as Interpretable and Generalizable Policies",
        "paper_author": "Trivedi D.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "35",
        "cover_date": "2021-01-01",
        "Abstract": "Recently, deep reinforcement learning (DRL) methods have achieved impressive performance on tasks in a variety of domains. However, neural network policies produced with DRL methods are not human-interpretable and often have difficulty generalizing to novel scenarios. To address these issues, prior works explore learning programmatic policies that are more interpretable and structured for generalization. Yet, these works either employ limited policy representations (e.g. decision trees, state machines, or predefined program templates) or require stronger supervision (e.g. input/output state pairs or expert demonstrations). We present a framework that instead learns to synthesize a program, which details the procedure to solve a task in a flexible and expressive manner, solely from reward signals. To alleviate the difficulty of learning to compose programs to induce the desired agent behavior from scratch, we propose to first learn a program embedding space that continuously parameterizes diverse behaviors in an unsupervised manner and then search over the learned program embedding space to yield a program that maximizes the return for a given task. Experimental results demonstrate that the proposed framework not only learns to reliably synthesize task-solving programs but also outperforms DRL and program synthesis baselines while producing interpretable and more generalizable policies. We also justify the necessity of the proposed two-stage learning scheme as well as analyze various methods for learning the program embedding. Website at https://clvrai.com/leaps.",
        "DOI": "NA",
        "affiliation_name": "University of Southern California",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Monitoring of epidemiological restrictions during the pandemic for the sustainability of public transport system",
        "paper_author": "Patlins A.",
        "publication": "2021 IEEE 62nd International Scientific Conference on Power and Electrical Engineering of Riga Technical University, RTUCON 2021 - Proceedings",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "In this article, a system which combines computer vision with electrical devices for enrichment is proposed in order to prevent risks that can occur in the future and contribute to reducing the spread of COVID-19 and other contagious infections that can happen in the future as well. According to the researches related to the current pandemic situation (COVID-19), the policies that should be taken are clear such as social distancing and wearing masks, but due to many reasons depending on human behaviors, people lose their attention to keep the rules. This system will help to prevent these risks. In this work, occupations that contact many people daily, but not under the control, sterilized area, and not affordable to work from home were considered as well as the target objects in our system. Contribution in this research work is to develop an expanded monitoring system which helps to prevent and reduce risk of the pandemic continuing currently and can occur in future by combining computer vision with electrical sensors to increase its efficiency. Machine learning based image recognition techniques were used to detect and monitor specified actions. In order to increase its functionality and efficiency, thermal sensors, camera, and microphones were deployed as well. Therefore, IoT was used for collecting the data result from monitoring for future applications.",
        "DOI": "10.1109/RTUCON53541.2021.9711698",
        "affiliation_name": "National University of Mongolia",
        "affiliation_city": "Ulaanbaatar",
        "affiliation_country": "Mongolia"
    },
    {
        "paper_title": "A Wireless Communication System of IoT Based on UAV",
        "paper_author": "Zhang Y.",
        "publication": "Proceedings - International Symposium on Parallel Architectures, Algorithms and Programming, PAAP",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, we focus on a wireless communication system of the internet of things (IoT) based on unmanned aerial vehicle (UAV). Compared with the ground IoT communication platform, the low altitude UAV wireless communication system has the advantages of flexible deployment, low cost and better communication channel quality brought by short range sight connection. In the absence of ground IoT infrastructure, deploying unmanned aerial vehicle base station (UAV-BS) can provide very efficient wireless communication services. With the expansion of UAV application scenarios, its intelligent requirements are also increasing. Therefore, the work of this paper expects that UAV-BS can independently complete tasks such as 3D hovering and trajectory planning. In this paper, the deep deterministic policy gradient (DDPG) algorithm and genetic algorithm in machine learning are used to train the UAV-BS. We study the influence of different parameters involved in the UAV communication network on the system performance, and verify that the network system with DDPG and genetic algorithm proposed by us has the best performance.",
        "DOI": "10.1109/PAAP54281.2021.9720479",
        "affiliation_name": "Ltd.",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The Use of Arabic Language COVID-19 Tweets Analysis in IoT Applications",
        "paper_author": "Alderazi F.",
        "publication": "2021 IEEE Global Conference on Artificial Intelligence and Internet of Things, GCAIoT 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Social media platforms have become one of the most powerful tools for organizations and individuals to publish news and express thoughts or feelings. With the increasingly enormous number of internet users in Saudi Arabia, the need raised to analyze Arabic posts. Since the emergence of COVID-19 in the latest 2019, it lefts economies and businesses counting the cost while governments fight the spread of the virus with new compartmentalization measures. Keeping in view the importance of quick and timely data analysis and sharing for policy actions, Artificial intelligence (AI) has played a crucial role in facilitating the exchange of views and information between scientists and decision-makers during the Coronavirus pandemic, and they continue to do so. This work mined to these content-related tweets to see how people's feelings and expressions are changing. The results of this analysis can be used with integration with several IoT technologies to reduce the impact of covid-19 and drive new decisions in this field. For this goal, we proposed a Machine Learning (ML) models that can classify both of the sentiment and topic of Modern Standard Arabic (MSA) tweets and achieve high accuracy results.",
        "DOI": "10.1109/GCAIoT53516.2021.9693080",
        "affiliation_name": "King Faisal University",
        "affiliation_city": "Al-Ahsa",
        "affiliation_country": "Saudi Arabia"
    },
    {
        "paper_title": "Developing Adaptive Team Coaching in GIFT: A Data-Driven Approach",
        "paper_author": "Spain R.D.",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "A critical step towards leveraging machine learning to create models for adaptive team-based coaching is collecting a large corpus of training data that can serve as a source for inducing data-driven coaching policies. In this paper we describe ongoing work using the Generalized Intelligent Framework for Tutoring (GIFT) to build reinforcement learning (RL) based coaching policies for promoting team performance in the domain of crew gunnery training. We describe our approach towards collecting a corpus of multimodal training data including video, communication, and simulation-trace data from U.S. Army gunnery crews who are completing simulation-based training exercises to prepare for crew gunnery qualification and sustainment. The dataset will be used to induce data-driven coaching policies for promoting individual and crew gunnery performance. We are using a component of GIFT called GIFT Data Collector to collect multimodal training data from simulation-based training stations as U.S. Army gunnery crews complete their assigned training exercises using the Virtual Battlespace 3 (VBS3) simulation platform. We discuss the data analysis pipeline that the team is developing to support data formatting, cleaning, filtering, and feature extraction processes that will be used to induce coaching policies. We also discuss how we plan to utilize multimodal training data, including crew communication logs, to iteratively refine the domain assessment model to support individual and team performance analysis and state classification. We conclude with a discussion of our upcoming research activities that aim to evaluate the acceptance and effectiveness of the coaching policies in an empirical study.",
        "DOI": "NA",
        "affiliation_name": "NC State University",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "2QoSM: A Q-Learner QoS Manager for Application-Guided Power-Aware Systems",
        "paper_author": "Giardino M.J.",
        "publication": "Proceedings - 2021 IEEE 14th International Symposium on Embedded Multicore/Many-Core Systems-on-Chip, MCSoC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "This paper describes the design and performance of Q-learning-based quality-of-service manager (2QoSM) for compute-aware applications (CAAs) as part of platform-agnostic resource management framework. CAAs and hardware are able to share metrics of performance with the 2QoSM and the 2QoSM can attempt to reconfigure CAAs and hardware to meet performance targets. This enables many co-design benefits while allowing for policy and platform portability. The use of Q-Learning allows online generation of the power management policy without requiring details about system state or actions, and can meet different goals including error, power minimization, or a combination of both. 2QoSM, evaluated using an embedded MCSoC controlling a mobile robot, reduces power compared to the Linux on-demand governor by 38.7-42.6% and a situation-aware governor by 4.0-10.2%. An error-minimization policy obtained a reduction in path-following error of 4.6-8.9%.",
        "DOI": "10.1109/MCSoC51149.2021.00040",
        "affiliation_name": "The George W. Woodruff School of Mechanical Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Dynamic Planning and Learning under Recovering Rewards",
        "paper_author": "Simchi-Levi D.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Motivated by emerging applications such as live-streaming e-commerce, promotions and recommendations, we introduce a general class of multiarmed bandit problems that have the following two features: (i) the decision maker can pull and collect rewards from at most K out of N different arms in each time period; (ii) the expected reward of an arm immediately drops after it is pulled, and then non-parametrically recovers as the idle time increases. With the objective of maximizing expected cumulative rewards over T time periods, we propose, construct and prove performance guarantees for a class of “Purely Periodic Policies”. For the offline problem when all model parameters are known, our proposed policy obtains an approximation ratio that is at the order of 1 − O(1/√K), which is asymptotically optimal when K grows to infinity. For the online problem when the model parameters are unknown and need to be learned, we design an Upper Confidence Bound (UCB) based policy that approximately has Oe(N√T) regret against the offline benchmark. Our framework and policy design may have the potential to be adapted into other offline planning and online learning applications with non-stationary and recovering rewards.",
        "DOI": "NA",
        "affiliation_name": "UC Berkeley’s Industrial Engineering and Operations Research Department",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "CAMLIS 2021 - Proceedings of the Conference on Applied Machine Learning in Information Security",
        "paper_author": "NA",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 9 papers. The topics discussed include: BETH dataset: real cybersecurity data for unsupervised anomaly detection research; SOREL-20M: a large scale benchmark dataset for malicious pe detection; heated alert triage (HeAT): network-agnostic extraction of cyber-attack campaigns; an analysis of C/C++ datasets for machine learning-assisted software vulnerability detection; rank-1 similarity matrix decomposition for modeling changes in antivirus consensus through time; adversarial attacks on deep algorithmic trading policies; clear-road: extraction of temporally co-occurring yet rare critical alerts; using undocumented hardware performance counters to detect spectre-style attacks; and Kipple: towards accessible, robust malware classification.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "LUSH: Lightweight Framework for User-level Scheduling in Heterogeneous Multicores",
        "paper_author": "Xu V.M.L.",
        "publication": "Proceedings - 2021 IEEE 14th International Symposium on Embedded Multicore/Many-Core Systems-on-Chip, MCSoC 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "As heterogeneous multicore systems become a standard in computing devices, there is an increasing need for intelligent and adaptive resource allocation schemes to achieve a balance between performance and energy consumption. To support this growing need, researchers have explored a plethora of techniques to guide OS scheduling policies, including machine learning, statistical regression and custom heuristics. Such techniques have been enabled by the abundance of low-level performance counters, and have proven effective in characterizing applications as well as predicting power and performance. However, most works require and develop custom infrastructures. In this paper we present LUSH, a Lightweight Framework for User-level Scheduling in Heterogeneous Multicores that allows for users to develop their own customized scheduling policies, without requiring root privileges. LUSH contributes the following to the state-of-the-art: (1) a mechanism for monitoring application runtime behavior using performance counters, (2) a mechanism for exporting kernel data to user-level at a user-defined period; and (3) a parameterized and flexible interface for developing, deploying, and evaluating novel algorithms applied to OS scheduling policies. The framework presented in this paper serves as a foundation for exploring advanced and intelligent techniques for resource management in heterogeneous systems.",
        "DOI": "10.1109/MCSoC51149.2021.00065",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "On Proximal Policy Optimization's Heavy-tailed Gradients",
        "paper_author": "Garg S.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Modern policy gradient algorithms such as Proximal Policy Optimization (PPO) rely on an arsenal of heuristics, including loss clipping and gradient clipping, to ensure successful learning. These heuristics are reminiscent of techniques from robust statistics, commonly used for estimation in outlier-rich (“heavy-tailed”) regimes. In this paper, we present a detailed empirical study to characterize the heavy-tailed nature of the gradients of the PPO surrogate reward function. We demonstrate that the gradients, especially for the actor network, exhibit pronounced heavy-tailedness and that it increases as the agent's policy diverges from the behavioral policy (i.e., as the agent goes further off policy). Further examination implicates the likelihood ratios and advantages in the surrogate reward as the main sources of the observed heavy-tailedness. We then highlight issues arising due to the heavy-tailed nature of the gradients. In this light, we study the effects of the standard PPO clipping heuristics, demonstrating that these tricks primarily serve to offset heavy-tailedness in gradients. Thus motivated, we propose incorporating GMOM, a high-dimensional robust estimator, into PPO as a substitute for three clipping tricks. Despite requiring less hyperparameter tuning, our method matches the performance of PPO (with all heuristics enabled) on a battery of MuJoCo continuous control tasks.",
        "DOI": "NA",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Parametrized Quantum Policies for Reinforcement Learning",
        "paper_author": "Jerbi S.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "68",
        "cover_date": "2021-01-01",
        "Abstract": "With the advent of real-world quantum computing, the idea that parametrized quantum computations can be used as hypothesis families in a quantum-classical machine learning system is gaining increasing traction. Such hybrid systems have already shown the potential to tackle real-world tasks in supervised and generative learning, and recent works have established their provable advantages in special artificial tasks. Yet, in the case of reinforcement learning, which is arguably most challenging and where learning boosts would be extremely valuable, no proposal has been successful in solving even standard benchmarking tasks, nor in showing a theoretical learning advantage over classical algorithms. In this work, we achieve both. We propose a hybrid quantum-classical reinforcement learning model using very few qubits, which we show can be effectively trained to solve several standard benchmarking environments. Moreover, we demonstrate, and formally prove, the ability of parametrized quantum circuits to solve certain learning tasks that are intractable to classical models, including current state-of-art deep neural networks, under the widely-believed classical hardness of the discrete logarithm problem.",
        "DOI": "NA",
        "affiliation_name": "Universiteit Leiden",
        "affiliation_city": "Leiden",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Meta-feature Extraction Strategies for Active Anomaly Detection",
        "paper_author": "Angiulli F.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Active Learning is a machine learning scenario in which methods are trained by iteratively submitting a query to a human expert and then taking into account his feedback for the following computations. The application of such paradigm to the anomaly detection task takes the name of Active Anomaly Detection (AAD). Reinforcement Learning describes a family of algorithms that aim to teach an agent to determine a policy to deal with external factors, and are based on the maximization of a reward function. Recently some AAD methods, based on the training of a meta-policy with Deep Reinforcement Learning have been very successful because, after the training, the methods simply work on a small number of meta-features that can be directly applied to any new dataset without further tuning. For these approaches a central question is the selection of good meta-features: actually, the most common choice is to define these meta-features in terms of the distances with the points that the expert has already labelled as either anomaly or normal. In this work we explore different strategies for selecting effective meta-features. Specifically, we take into account both direct and reverse nearest-neighbor rankings in order to build meta-features, since they are less sensitive to the specific distance distribution characterizing the training data, and experiment the combination also with related base detectors. The experiments show that there are scenarios in which our approach offers advantages over the standard technique.",
        "DOI": "10.1007/978-3-030-91608-4_40",
        "affiliation_name": "Università della Calabria",
        "affiliation_city": "Rende",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Proceedings - 2021 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE 2021",
        "paper_author": "NA",
        "publication": "Proceedings - 2021 IEEE/ACM Conference on Connected Health: Applications, Systems and Engineering Technologies, CHASE 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 37 papers. The topics discussed include: machine learning prediction of TBI from mobility, gait and balance patterns; improve image-based skin cancer diagnosis with generative self-supervised learning; RT-ACL: identification of high-risk youth patients and their most significant risk factors to reduce anterior cruciate ligament reinjury risk; detection and analysis of interrupted behaviors by public policy interventions during COVID-19; information extraction from patient care reports for intelligent emergency medical services; high-confidence data programming for evaluating suppression of physiological alarms; EDA-based data stream pattern analysis and peak detection algorithm for substance users; and sensor-based human activity recognition for elderly in-patients with a Luong self-attention network.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "DDPER: DECENTRALIZED DISTRIBUTED PRIORITIZED EXPERIENCE REPLAY",
        "paper_author": "Liu S.",
        "publication": "Proceedings - IEEE International Conference on Multimedia and Expo",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "In off-policy reinforcement learning, prioritized experience replay plays an important role. However, the centralized prioritized experience replay becomes the bottleneck for efficient training. We propose to approximate the centralized prioritized experience replay in a distributed and decentralized way under certain mild assumptions. To be specific, each actor stores samples in its local replay in the same way as prioritized experience replay, the learner fetches a batch of samples from these replays following a certain strategy. We implement a Deep Q-Learning off-policy algorithm upon the proposed framework. The comparison experiments are performed on a commonly used subset of the Atari-57 learning environment. The experimental results show that the proposed framework speeds up training as the number of actors increases. With the same algorithm and hyper-parameter settings, the proposed framework with 16 actors achieves superior performance that Ape-X with 32 and even more actors does.",
        "DOI": "10.1109/ICME51207.2021.9428188",
        "affiliation_name": "National Key Laboratory for Parallel and Distributed Processing",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "TEMPORAL DIFFERENCE LEARNING MODEL FOR TCP END-TO-END CONGESTION CONTROL IN HETEROGENEOUS WIRELESS NETWORKS",
        "paper_author": "Pradeep R.",
        "publication": "2021 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Conventional TCP end-to-end Congestion Control approaches cannot be applied directly to heterogeneous wireless networks as TCP is unable to distinguish the reason for the packet loss. The high error rates in wireless networks are due to interference or frame collisions caused by multiple simultaneous transmissions resulting in throughput degradation. There exist several ML approaches towards congestion control but neither the supervised nor the unsupervised learning techniques are suitable for learning the optimal policy. Therefore, a model is to be developed that predicts the optimal congestion window by interacting with the environment dynamically. To address these challenges, we propose a reinforcement learning model to dynamically adjust the congestion window using the Actor-Critic method and Temporal Difference learning. From the experiments, it is evident that the proposed learning model achieves 40% more throughput than the existing techniques while maintaining low transmission latency.",
        "DOI": "10.1109/ICCCNT51525.2021.9579892",
        "affiliation_name": "National Institute of Technology Calicut",
        "affiliation_city": "Kozhikode",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Kavach: A Machine Learning based approach for enhancing the attack detection capability of firewalls",
        "paper_author": "Aswal K.",
        "publication": "2021 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Firewalls were created with the objective of allowing or restricting outside access to particular network resources for an organization. Firewalls are currently capable of enforcing network security policies, logging internet activity, and securing an organization's exposure to outside threats. With the meteoric rise of artificial intelligence, the attack vectors are being modified to bypass traditional firewalls. Hence, a poorly configured firewall can easily be brought down and expose the very resources it has been designed to protect. With the adaptations of the attack vectors, firewalls too must be enhanced to counter these attacks dynamically. This can be done with the help of extensive analysis of various payloads and network traffic. Machine learning algorithms are used to classify the payloads as malicious or not and proceed accordingly. Based on this classification, the rule sets are updated in the firewall to block the next generation of payloads. Thus our proof of concept proved that the incorporation of machine and deep learning algorithms to dynamically analyze the network traffic by detecting attack vectors and updating the firewall rules increases the detection capabilities of the firewall.",
        "DOI": "10.1109/ICCCNT51525.2021.9579836",
        "affiliation_name": "Amrita Vishwa Vidyapeetham",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Dream to Explore: 5-HT2a as Adaptive Temperature Parameter for Sophisticated Affective Inference",
        "paper_author": "Safron A.",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Relative to other neuromodulators, serotonin (5-HT) has received far less attention in machine learning and active inference. We will review prior work interpreting 5-HT1a signaling as an uncertainty parameter with opponency to dopamine. We will then discuss how 5-HT2a receptors may promote more exploratory policy selection by enhancing imaginative planning (as sophisticated affective inference). Finally, we will briefly comment on how qualitatively different effects may be observed across low and high levels of 5-HT2a signaling, where the latter may help agents to change self-adversarial policies and break free of maladaptive absorbing states in POMDPs.",
        "DOI": "10.1007/978-3-030-93736-2_56",
        "affiliation_name": "Johns Hopkins University School of Medicine",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Stochastic Observation Prediction for Efficient Reinforcement Learning in Robotics",
        "paper_author": "Wang S.",
        "publication": "Proceedings - 4th International Conference on Multimedia Information Processing and Retrieval, MIPR 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Although the recent progress of deep learning has enabled reinforcement learning (RL) algorithms to achieve human-level performance in retro video games within a short training time, the application of real-world robotics remains limited. The conventional RL procedure requires agents to interact with the environment. Meanwhile, the interactions with the physical world can not be easily parallelized or accelerated as in other tasks. Moreover, the gap between the real world and simulation makes it harder to transfer the policy trained in simulators to physical robots. Thus, we propose a model-based method to mitigate the interaction overheads for real-world robotic tasks. In particular, our model incorporates an autoencoder, a recurrent network, and a generative network to make stochastic predictions of observations. We conduct the experiments on a collision avoidance task for disc-like robots and show that the generative model can serve as a virtual RL environment. Our method has the benefit of lower interaction overheads as inference of deep neural networks on GPUs is faster than observing the transitions in the real environment, and it can replace the real RL environment with limited rollout length.",
        "DOI": "10.1109/MIPR51284.2021.00027",
        "affiliation_name": "The University of Tokyo",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Character Animation Using Reinforcement Learning and Imitation Learning Algorithms",
        "paper_author": "Tahmid T.",
        "publication": "2021 Joint 10th International Conference on Informatics, Electronics and Vision, ICIEV 2021 and 2021 5th International Conference on Imaging, Vision and Pattern Recognition, icIVPR 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Real-time character animation for gaming and film industries is challenging and achieving production-ready quality requires a huge amount of time and resources. Animation through marker-based motion capture is quite a tiresome process that requires costly motion-capture suits, multiple cameras, and a large database. In this paper, we propose a model that aims to generate real-time character animation for biped locomotion in Unity ML(Machine Learning) agents using RL(Reinforcement learning) and IL(Imitation learning) algorithms. We first evaluate the training process with solely the state-of-the-art RL algorithm, PPO(Proximal Policy Optimization). Then we analyze the combination of IL algorithms BC(Behavioral Cloning) and GAIL(Generative Adversarial Imitation Learning) in conjunction with PPO. We further discuss the comparison between the two training results and show that our model can generate animations in real-time avoiding all the tedious work and large databases. We demonstrate that our approach is effortlessly easy to implement while maintaining the quality of the animation. Contribution - A novel approach that makes the implementation more simpler and easy to use while maintaining the quality of the animation.",
        "DOI": "10.1109/ICIEVICIVPR52578.2021.9564143",
        "affiliation_name": "BRAC University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Improving Smart Waste Collection Using AutoML",
        "paper_author": "Teixeira S.",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The production and management of urban waste is a growing challenge and a consequence of our day-to-day resources and activities. According to the Portuguese Environment Agency, in 2019, Portugal produced 1% more tons compared to 2018. The proper management of this waste can be co-substantiated by existing policies, namely, national legislation and the Strategic Plan for Urban Waste. Those policies assess and support the amount of waste processed, allowing the recovery of materials. Among the solutions for waste management is the selective collection of waste. We improve the possibility of manage the smart waste collection of Paper, Plastic, and Glass packaging from corporate customers who joined a recycling program. We have data collected since 2017 until 2020. The main objective of this work is to increase the system’s predictive performance, without any loss for citizens, but with improvement in the collection management. We analyze two types of problems: (i) the presence or absence of containers; and (ii) the prediction of the number of containers by type of waste. To carry out the analysis, we applied three machine learning algorithms: XGBoost, Random Forest, and Rpart. Additionally, we also use AutoML for XGBoost and Random Forest algorithms. The results show that with AutoML, generally, it is possible to obtain better results for classifying the presence or absence of containers by type of waste and predict the number of containers.",
        "DOI": "10.1007/978-3-030-93733-1_20",
        "affiliation_name": "Institute for Systems and Computer Engineering, Technology and Science",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Sensor Fusion for Context Analysis in Social Media COVID-19 Data",
        "paper_author": "Smith G.Y.",
        "publication": "Proceedings of the IEEE National Aerospace Electronics Conference, NAECON",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Growing surge of misinformation among COVID-19 can post great hindrance to truth, it can magnify distrust in policy makers and/or degrade authorities' credibility, and it can even harm public health. Classification of textual context on social media data relating COVID-19 is an effective tool to combat misinformation on social media platforms. We leveraged Twitter data in developing classification methods to detect misinformation and to identify tweet sentiment. Six fusion-based classification models were built fusing three classical machine learning algorithms: multinomial naïve Bayes, logistic regression, and support vector classifier. The best performing models were selected to detect misinformation and to classify sentiment on tweets that were created during early outbreak of COVID-19 pandemic and the fifth month into pandemic. We found that majority of the public held positive sentiment toward all six types of misinformation news on Twitter social media platform. Except political or biased news, general public expressed more positively toward unreliable, conspiracy, clickbait, unreliable with political/biased, and clickbait with political/biased news later in the summer month than earlier during the outbreak. The results provide decision or policy makers valuable knowledge gain in public opinion towards various types of misinformation spreading over social media.",
        "DOI": "10.1109/NAECON49338.2021.9696396",
        "affiliation_name": "Air Force Institute of Technology",
        "affiliation_city": "Dayton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Real-Time Edge Classification: Optimal Offloading under Token Bucket Constraints",
        "paper_author": "Chakrabarti A.",
        "publication": "6th ACM/IEEE Symposium on Edge Computing, SEC 2021",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "We consider an edge-computing setting where machine learning-based algorithms are used for real-time classification of inputs acquired by devices, e.g., cameras. Computational resources on the devices are constrained, and therefore only capable of running machine learning models of limited accuracy. A subset of inputs can be offloaded to the edge for processing by a more accurate but resource-intensive machine learning model. Both models process inputs with low-latency, but offloading incurs network delays. To manage these delays and meet application deadlines, a token bucket constrains transmissions from the device. We introduce a Markov Decision Process-based framework to make offload decisions under such constraints. Decisions are based on the local model's confidence and the token bucket state, with the goal of minimizing a specified error measure for the application. We extend the approach to configurations involving multiple devices connected to the same access switch to realize the benefits of a shared token bucket. We evaluate and analyze the policies derived using our framework on the standard ImageNet image classification benchmark.",
        "DOI": "10.1145/3453142.3492329",
        "affiliation_name": "McKelvey School of Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Sentiment analysis, opinion mining and topic modelling of epics and novels using machine learning techniques",
        "paper_author": "Raj P. M. K.",
        "publication": "Materials Today: Proceedings",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Sentiment analysis systems can collect and automatically structure unstructured information by collecting public views of services, products, policy, brands, etc. This information is of major value in the fields of marketing analysis, public relations, product reviews, net promoter evaluations, customer feedback and client reviews. Literary works, on the other hand, are less susceptible to computational analysis because there are no immediate commercial incentives. However, similar techniques can be used to evaluate literary work, comprehend the underlying social network, and obtain or validate literary work. This project is about analyzing the book's characters and predicting their characteristics and relationships with one another. A lot of human effort is expended during the adaptation of a novel/book in any form, which is inconvenient and undesirable. Furthermore, the human brain has a tendency to overlook a number of minor details about the events/characters in the book. The scenario described above can frequently result in inaccuracies in the adaptation's plot. As a result, the project is an innovation that aims to aid in the easy and accurate adaptation of a book, making the process much simpler and precise. Machine learning (supervised and unattended) and lexical approaches include the current sentiment analysis techniques. The model's goal is to scan the massive amounts of text in the book. Following digitization, the model will display interesting ideas derived from the given book using a combination of natural language processing, feelings and emotions analysis, and social network analysis methodology.",
        "DOI": "10.1016/j.matpr.2021.06.001",
        "affiliation_name": "Ramaiah Institute of Technology",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "On Scheduling a Photolithograhy Toolset Based on a Deep Reinforcement Learning Approach with Action Filter",
        "paper_author": "Kim T.",
        "publication": "Proceedings - Winter Simulation Conference",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Production scheduling of semiconductor manufacturing tools is a challenging problem due to the complexity of the equipment and systems in modern wafer fabs. In our study, we focus on the photolithography toolset and consider it as a non-identical parallel machine scheduling problem with random lot arrivals and auxiliary resource constraints. The proposed methodology strives to learn a near optimal scheduling policy by incorporating WIP, masks, and the tardiness of jobs. An Action Filter (AF) is proposed as a methodology to eliminate illogical actions and speed the learning process of agents. The proposed model was evaluated in a simulation environment inspired by practical photolithography scheduling problems across various settings with reticle and qualification constraints. Our experiments demonstrated improved performance compared to typical rule-based strategies. Relative to our learning methods, weighted shortest processing time (WSPT) and apparent tardiness cost with setups (ATCS) rules perform 28% and 32% worse for weighted tardiness, respectively.",
        "DOI": "10.1109/WSC52266.2021.9715450",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "ScottishFold: CatBoost-Enabled Lightweight Autonomous Smart Home Device Classification",
        "paper_author": "Hohum T.",
        "publication": "2021 IEEE Globecom Workshops, GC Wkshps 2021 - Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Massive deployed IoT devices in smart homes pose security management challenges due to different hardware and firmware. To address these challenges, an automated IoT-device-type identification has been used as the first step in autonomous networks in which IoT security policy is automatically managed. Although machine-learning-based traffic patterns were proven high accuracy on a prediction while heavy on preprocessing, we argue that good stability and less computational cost should be considered. We focus on constructing an IoT-device-type classification based on the common features extracted from the network traffic. Inspired by the categorical boosting algorithm, we propose ScottishFold, a classification model, that is constructed from the dirty categorical IoT traffic features with less preprocessing. ScottishFold can classify the IoT device type from a single packet (either a signaling handshake or a data packet) that makes the classification process light. We boost the classification accuracy by integrating a machine reasoning approach into the classification process. The experimental results confirm the effectiveness and robustness of our proposed technique.",
        "DOI": "10.1109/GCWkshps52748.2021.9681958",
        "affiliation_name": "Thailand National Electronics and Computer Technology Center",
        "affiliation_city": "Pathum Thani",
        "affiliation_country": "Thailand"
    },
    {
        "paper_title": "Tailored neural networks for learning optimal value functions in MPC",
        "paper_author": "Teichrib D.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Learning-based predictive control is a promising alternative to optimization-based MPC. However, efficiently learning the optimal control policy, the optimal value function, or the Q-function requires suitable function approximators. Often, artificial neural networks (ANN) are considered but choosing a suitable topology is also non-trivial. Against this background, it has recently been shown that tailored ANN allow, in principle, to exactly describe the optimal control policy in linear MPC by exploiting its piecewise affine structure. In this paper, we provide a similar result for representing the optimal value function and the Q-function that are both known to be piecewise quadratic for linear MPC.",
        "DOI": "10.1109/CDC45484.2021.9683528",
        "affiliation_name": "Technische Universität Dortmund",
        "affiliation_city": "Dortmund",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Barrier Function-based Safe Reinforcement Learning for Emergency Control of Power Systems",
        "paper_author": "Vu T.L.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "Under voltage load shedding has been considered as a standard and effective measure to recover the voltage stability of the electric power grid under emergency and severe conditions. However, this scheme usually trips a massive amount of load which can be unnecessary and harmful to customers. Recently, deep reinforcement learning (RL) has been regarded and adopted as a promising approach that can significantly reduce the amount of load shedding. However, like most existing machine learning (ML)-based control techniques, RL control usually cannot guarantee the safety of the systems under control. In this paper, we introduce a novel safe RL method for emergency load shedding of power systems, that can enhance the safe voltage recovery of the electric power grid after experiencing faults. Unlike the standard RL method, the safe RL method has a reward function consisting of a Barrier function that goes to minus infinity when the system state goes to the safety bounds. Consequently, the optimal control policy, that maximizes the reward function, can render the power system to avoid the safety bounds. This method is general and can be applied to other safety-critical control problems. Numerical simulations on the 39-bus IEEE benchmark is performed to demonstrate the effectiveness of the proposed safe RL emergency control, as well as its adaptive capability to faults not seen in the training.",
        "DOI": "10.1109/CDC45484.2021.9683573",
        "affiliation_name": "Pacific Northwest National Laboratory",
        "affiliation_city": "Richland",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "GEO-ETHICS IN SLUM MAPPING",
        "paper_author": "Owusu M.",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Earth Observation (EO) to produce policy-driven information on slums has been receiving increasing attention amongst experts. However, the geo-ethical concerns associated with making slum information publicly available are commonly neglected among the EO community. This study analysed the geo-ethics in terms of technology, product, and application-level using topic-focused interviews in the Greater Accra Region, Ghana. We identified that potential users have little knowledge of machine learning-based slum mapping methods, which implies the need for technology and product documentation to improve the acceptability and usability of EO data. We observed an application mismatch among institutions. While NGOs and research institutions required data for pro-poor initiatives, most government institutions needed data for slum eradication. Such mismatches require a rethinking of how slum data should be made public. We present a guide to disseminate information to users in support of developing a global slum data repository.",
        "DOI": "10.1109/IGARSS47720.2021.9553570",
        "affiliation_name": "Faculty of Geo-Information Science and Earth Observation – ITC",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Optimal Scheduling of Energy Storage for Power System with Capability of Sensing Short-Term Future PV Power Production",
        "paper_author": "Nengroo S.H.",
        "publication": "2021 11th International Conference on Power and Energy Systems, ICPES 2021",
        "citied_by": "9",
        "cover_date": "2021-01-01",
        "Abstract": "Constant rise in energy consumption that comes with the population growth and introduction of new technologies has posed critical issues such as efficient energy management on the consumer side. That has elevated the importance of the use of renewable energy sources, particularly photovoltaic (PV) system and wind turbine. This work models and discusses design options based on the hybrid power system of grid and battery storage. The effects of installed capacity on renewable penetration (RP) and cost of electricity (COE) are investigated for each modality. For successful operation of hybrid power system and electricity trading in power market, accurate predictions of PV power production and load demand are taken into account. A machine learning (ML) model is introduced for scheduling, and predicting variations of the PV power production and load demand. Fitness of the ML model shows, when employing a linear regression model, the mean squared error (MSE) of 0.000012, root mean square error (RMSE) of 0.003560 and R2 of 0.999379. Using predicted PV power production and load demand, reduction of electricity cost is 37.5 % when PV and utility grid are utilized, and is 43.06% when PV, utility grid, and storage system are utilized.",
        "DOI": "10.1109/ICPES53652.2021.9683905",
        "affiliation_name": "Korea Advanced Institute of Science and Technology",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Impact of Digitization on the Pharmacy Practice settings on the international landscape",
        "paper_author": "Chan A.H.Y.",
        "publication": "Pharma Times",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "NA",
        "DOI": "NA",
        "affiliation_name": "Commonwealth Pharmacists Association",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A Generative Machine Learning Approach to Policy Optimization in Pursuit-Evasion Games",
        "paper_author": "Navabi S.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "We consider a pursuit-evasion game [1] played between two agents, 'Blue' (the pursuer) and 'Red' (the evader), over T time steps. Red aims to attack Blue's territory. Blue's objective is to intercept Red at time T and thereby limit the success of Red's attack. Blue must plan its pursuit trajectory by choosing parameters that determine its course of movement (speed and angle in our setup) such that it intercepts Red at time T. We show that Blue's path-planning problem in pursuing Red, can be posed as a sequential decision making problem under uncertainty. Blue's unawareness of Red's action policy renders the analytic dynamic programming approach intractable for finding the optimal action policy for Blue. In this work, we are interested in exploring data-driven approaches to the policy optimization problem that Blue faces. We apply generative machine learning (ML) approaches to learn optimal action policies for Blue. This highlights the ability of generative ML model to learn the relevant implicit representations for the dynamics of simulated pursuit-evasion games. We demonstrate the effectiveness of our modeling approach via extensive statistical assessments. This work can be viewed as a preliminary step towards further adoption of generative modeling approaches for addressing policy optimization problems that arise in the context of multi-agent learning and planning [2].",
        "DOI": "10.1109/CDC45484.2021.9683630",
        "affiliation_name": "USC Viterbi School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "TREE SPECIES MAPPING IN TROPICAL FORESTS USING HYPERSPECTRAL REMOTE SENSING AND MACHINE LEARNING",
        "paper_author": "Badola A.",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Tree species-level information is essential for effective forest management, conservation, policy development, and utilization. The availability of hyperspectral data creates new possibilities for species mapping. This study mapped tropical tree species in Shimoga, Karnataka, India by using the Airborne Visible and Infrared Imaging Spectrometer - Next Generation (AVIRIS-NG) hyperspectral data. Species mapping was performed by modifying the Random forest (RF) classifier using Principal Component Analysis (PCA) to transform the variables at each node into another space. The performance of PCA-based Rotation Random Forest (RoRF), was then compared with RF and Support Vector Machine (SVM), where RoRF outperformed both of them. A total of 20 tropical tree species were classified, highlighting the potential of the AVIRIS-NG data for species-level classification.",
        "DOI": "10.1109/IGARSS47720.2021.9553549",
        "affiliation_name": "Universiteit Twente",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "MONITORING THREATENED IRISH HABITATS USING MULTI-TEMPORAL MULTI-SPECTRAL AERIAL IMAGERY AND CONVOLUTIONAL NEURAL NETWORKS",
        "paper_author": "Perez-Carabaza S.",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The monitoring of threatened habitats is a key objective of European environmental policy. Due to the high cost of current field-based habitat mapping techniques there is a strong research interest in proposing solutions that reduce the cost of habitat monitoring through increasing their level of automation. Our work is motivated by the opportunities that recent advances in machine learning and Unmanned Aerial Vehicles (UAVs) offer to the habitat monitoring problem. In this paper, a deep learning based solution is proposed to classify four priority Irish habitats types present in the Maharees (Ireland) using UAV aerial imagery. The proposed method employs Convolutional Neural Networks (CNNs) to classify multi-temporal multi-spectral images of the study area corresponding to three different dates in 2020, obtaining an overall classification accuracy of 93%. A comparison of the proposed method with a multi-spectral 2D-CNN model demonstrates the advantage of including temporal information enabled by the proposed multi-temporal multi-spectral CNN model.",
        "DOI": "10.1109/IGARSS47720.2021.9553472",
        "affiliation_name": "University College Dublin",
        "affiliation_city": "Dublin",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Neural Network Verification in Control",
        "paper_author": "Everett M.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Learning-based methods could provide solutions to many of the long-standing challenges in control. However, the neural networks (NNs) commonly used in modern learning approaches present substantial challenges for analyzing the resulting control systems' safety properties. Fortunately, a new body of literature could provide tractable methods for analysis and verification of these high dimensional, highly nonlinear representations. This tutorial first introduces and unifies recent techniques (many of which originated in the computer vision and machine learning communities) for verifying robustness properties of NNs. The techniques are then extended to provide formal guarantees of neural feedback loops (e.g., closed-loop system with NN control policy). The provided tools are shown to enable closed-loop reachability analysis and robust deep reinforcement learning.Software-https://github.com/mit-acl/nn_robustness_analysis",
        "DOI": "10.1109/CDC45484.2021.9683154",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Backfilling HPC Jobs with a Multimodal-Aware Predictor",
        "paper_author": "Lamar K.",
        "publication": "Proceedings - IEEE International Conference on Cluster Computing, ICCC",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "Job scheduling aims to minimize the turnaround time on the submitted jobs while catering to the resource constraints of High Performance Computing (HPC) systems. The challenge with scheduling is that it must honor job requirements and priorities while actual job run times are unknown. Although approaches have been proposed that use classification techniques or machine learning to predict job run times for scheduling purposes, these approaches do not provide a technique for reducing underprediction, which has a negative impact on scheduling quality. A common cause of underprediction is that the distribution of the duration for a job class is multimodal, causing the average job duration to fall below the expected duration of longer jobs. In this work, we propose the Top Percent predictor, which uses a hierarchical classification scheme to provide better accuracy for job run time predictions than the user-requested time. Our predictor addresses multimodal job distributions by making a prediction that is higher than a specified percentage of the observed job run times. We integrate the Top Percent predictor into scheduling algorithms and evaluate the performance using schedule quality metrics found in literature. To accommodate the user policies of HPC systems, we propose priority metrics that account for job flow time, job resource requirements, and job priority. The experiments demonstrate that the Top Percent predictor outperforms the related approaches when evaluated using our proposed priority metrics.",
        "DOI": "10.1109/Cluster48925.2021.00093",
        "affiliation_name": "College of Engineering and Computer Science",
        "affiliation_city": "Orlando",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Student Risk Assessment: Predicting Undergraduate Student Graduation Probability Using Logistic Regression, SVM, and ANN",
        "paper_author": "Ong D.P.",
        "publication": "IEEE Region 10 Annual International Conference, Proceedings/TENCON",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Understanding how different factors affect the performance of a student in the university setting is important in policy making and providing a better environment for learning. Existing studies on student graduation rates typically employ the use of machine learning methods to correlate a student's profile and their chances of graduation. Building on the success of these methods for Western institutions, we used Logistic Regression, Support Vector Machines, and Neural Networks to build models that use available student data to predict their graduation chances. The results show that all three models are good at predicting graduation outcome, with the logistic regression model yielding slightly higher scores in classification accuracy (80.67 %) and class separation (ROC-AUC score of 83.02%). We also found that including as little as four post-matriculation factors increases the model performances significantly. Hence, the models can be used to perform student risk assessment and develop plans to increase a student's chances of graduation.",
        "DOI": "10.1109/TENCON54134.2021.9707322",
        "affiliation_name": "University of the Philippines Diliman",
        "affiliation_city": "Quezon City",
        "affiliation_country": "Philippines"
    },
    {
        "paper_title": "THE CHALLENGES OF FORENSIC GENEALOGY: DIRTY DATA, ELECTRONIC EVIDENCE, AND PRIVACY CONCERNS",
        "paper_author": "Ramjee D.",
        "publication": "Denver Law Review",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "While forensic genealogy continues to gain popularity as a law enforcement tool for solving cold cases, discrepancies in testing and evidentiary standards, as well as ethical and privacy issues, continue to plague the practice. This Article examines the investigatory role of genetic information and the various methods by which genetic information can be collected, used, or shared, including by law enforcement. In the era of Big Data, we must understand the limitations posed by the reliability and accuracy of information included in private and publicly available genealogy databases and how those limitations compete with the desire to implement valid machine learning algorithms in the fields of criminology and law. Realizing that advancements in science often outpace regulatory legislation, this Article addresses ways in which private and publicly available genealogy services can safeguard genetic information, including associated identifying metadata. Furthermore, this Article sets forth policy recommendations that consider the importance of enhancing investigative techniques while ensuring appropriate evidentiary standards and Fourth Amendment protections.",
        "DOI": "NA",
        "affiliation_name": "American University",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "QSpark: Distributed Execution of Batch Streaming Analytics in Spark Platform",
        "paper_author": "Hoseinyfarahabady M.R.",
        "publication": "2021 IEEE 20th International Symposium on Network Computing and Applications, NCA 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "A significant portion of research work in the past decade has been devoted on developing resource allocation and task scheduling solutions for large-scale data processing platforms. Such algorithms are designed to facilitate deployment of data analytic applications across either conventional cluster computing systems or modern virtualized data-centers. The main reason for such a huge research effort stems from the fact that even a slight improvement in the performance of such platforms can bring a considerable monetary savings for vendors, especially for modern data processing engines that are designed solely to perform high throughput or/and low-latency computations over massive-scale batch or streaming data. A challenging question to be yet answered in such a context is to design an effective resource allocation solution that can prevent low resource utilization while meeting the enforced performance level (such as 99-th latency percentile) in circumstances where contention among applications to obtain the capacity of shared resources is a non negligible performance-limiting parameter. This paper proposes a resource controller system, called QSpark, to cope with the problem of (i) low performance (i.e., resource utilization in the batch mode and p-99 response time in the streaming mode), and (ii) the shared resource interference among collocated applications in a multi-tenancy modern Spark platform. The proposed solution leverages a set of controlling mechanisms for dynamic partitioning of the allocation of computing resources, in a way that it can fulfill the QoS re-quirements of latency-critical data processing applications, while enhancing the throughput for all working nodes without reaching their saturation points. Through extensive experiments in our in-house Spark cluster, we compared the achieved performance of proposed solution against the default Spark resource allocation policy for a variety of Machine Learning (ML), Artificial Intelligence (AI), and Deep Learning (DL) applications. Experimental results show the effectiveness of the proposed solution by reducing the p-99 latency of high priority applications by 32 % during the burst traffic periods (for both batch and stream modes), while it can enhance the QoS satisfaction level by 65 % for applications with the highest priority (compared with the results of default Spark resource allocation strategy).",
        "DOI": "10.1109/NCA53618.2021.9685833",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Targeted VAE: Variational and targeted learning for causal inference",
        "paper_author": "Vowels M.J.",
        "publication": "Proceedings - 2021 IEEE International Conference on Smart Data Services, SMDS 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Undertaking causal inference with observational data is incredibly useful across a wide range of tasks including the development of medical treatments, advertisements and marketing, and policy making. There are two significant challenges associated with undertaking causal inference using observational data: treatment assignment heterogeneity (i.e., differences between the treated and untreated groups), and an absence of counterfactual data (i.e., not knowing what would have happened if an individual who did get treatment, were instead to have not been treated). We address these two challenges by combining structured inference and targeted learning. In terms of structure, we factorize the joint distribution into risk, confounding, instrumental, and miscellaneous factors, and in terms of targeted learning, we apply a regularizer derived from the influence curve in order to reduce residual bias. An ablation study is undertaken, and an evaluation on benchmark datasets demonstrates that TVAE has competitive and state of the art performance across.",
        "DOI": "10.1109/SMDS53860.2021.00027",
        "affiliation_name": "University of Surrey",
        "affiliation_city": "Guildford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Assessing Eurosystem Policy Rules by Applying Deep Learning Approach",
        "paper_author": "Juneja J.A.",
        "publication": "Proceedings - 20th IEEE International Conference on Machine Learning and Applications, ICMLA 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Researchers working on maximum likelihood estimation (MLE) of dynamic term structure models report facing numerous computational challenges when attempting optimization. This has initiated our research on the usage of machine learning methods specific to the sub-field of deep learning for developing optimization models that can overcome the computational issues. In this work, we use these advances to design an algorithm framework reliant upon an unsupervised neural network to conduct MLE of a macro-finance model to assess the impact of changes in key variables influencing monetary policy on a single interest rate associated with a policy rule that governs all nineteen states comprising the euro area. Then, we investigate the dynamic nature of these effects by training the variables as predictors of yield convergence to a single interest rate (i.e., signal response) and use the resultant trained machine learning model to generate interest rate predictions. Finally, we group the predictions into clusters using density-based spatial clustering of applications with noise algorithm. The results we get suggest that proper training of key policy indicators (i.e., predictors) can yield convergence to a single interest rate (i.e., signal). However, our findings also indicate a strong disparity in variation in the coefficients driving the reaction of the signal to predictors across the member states, which suggests that achieving such a convergence in practice may be a challenge.",
        "DOI": "10.1109/ICMLA52953.2021.00281",
        "affiliation_name": "Fowler College of Business",
        "affiliation_city": "San Diego",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Physics-constrained Automatic Feature Engineering for Predictive Modeling in Materials Science",
        "paper_author": "Xiang Z.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "Automatic Feature Engineering (AFE) aims to extract useful knowledge for interpretable predictions given data for the machine learning tasks. Here, we develop AFE to extract dependency relationships that can be interpreted with functional formulas to discover physics meaning or new hypotheses for the problems of interest. We focus on materials science applications, where interpretable predictive modeling may provide principled understanding of materials systems and guide new materials discovery. It is often computationally prohibitive to exhaust all the potential relationships to construct and search the whole feature space to identify interpretable and predictive features. We develop and evaluate new AFE strategies by exploring a feature generation tree (FGT) with deep Q-network (DQN) for scalable and efficient exploration policies. The developed DQN-based AFE strategies are benchmarked with the existing AFE methods on several materials science datasets.",
        "DOI": "10.1609/aaai.v35i12.17247",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "College Station",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Active and Participatory User Contribution to Inclusive Design for Net Zero Homes in the United Arab Emirates",
        "paper_author": "Kamath S.S.",
        "publication": "ZEMCH International Conference",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "United Arab Emirates (UAE) National Agenda, National Legal Framework & Policies, and Technology leads in multidisciplinary topics such as Human Computer Interaction (HCI), Ergonomics of human-system interaction, Housing Models such as Solar Decathlon Middle East (SDME), has led to short-term and long-term Strategies and Initiatives for Energy by the Electricity and Water Authorities of the UAE Government. There are various Operational, Infrastructure and Economic, usually heuristic impediments, not to mention the nascent nature of the HCI and User Experience/User Interface (UX/UI) work in this area that must be considered. The aim, objective and focus of the research below is garnering the above information and relating it together by identifying the missing inclusivity elements, local legalities, and partners. This is required for effectively deploying User Behavior/Engagement to promote User Empowerment and Participatory Governance for the active and participatory contribution of Inclusive Design -to meet Societal requirements in context with Net Zero Energy Building (nZEB) and Housing, for meeting the ZEMCH Objectives of Inclusive and sustainable Built Environments in UAE. The results sdrawn indicates that User Behavior and Engagement is the key to success for Cost to Benefit percolation and Return on Investments, thereby promoting User Empowerment through Inclusive Design for All (Age-Friendly, Disabled Friendly, and Special Needs Friendly). Using Computer Science and Engineering in UX and UI Design, HCI, Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL), and Internet of Things (IoT) seems the best way forward to the success of all such Engagements and Empowerments. Municipal Questionnaire(s) when combined with applied UX Methodology for Inclusive Housings, interpret/result in Inclusive Designs. Potential improvements and further design and development requirements for success can be related to the emerging fields of technology and aiming them to make Users Contribute towards making nZEB and Housing Inclusive and Livable.",
        "DOI": "NA",
        "affiliation_name": "Manipal Academy of Higher Education, Dubai Campus",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Adaptive Prior-Dependent Correction Enhanced Reinforcement Learning for Natural Language Generation",
        "paper_author": "Cheng W.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Natural language generation (NLG) is an important task with various applications like neural machine translation (NMT) and image captioning. Since deep-learning-based methods have issues of exposure bias and loss inconsistency, reinforcement learning (RL) is widely adopted in NLG tasks recently. But most RL-based methods ignore the deviation ignorance issue, which means the model fails to understand the extent of token-level deviation well. It leads to semantic incorrectness and hampers the agent to perform well. To address the issue, we propose a technique called adaptive prior-dependent correction (APDC) to enhance RL. It leverages the distribution generated by computing the distances between the ground truth and all other words to correct the agent's stochastic policy. Additionally, some techniques on RL are explored to coordinate RL with APDC, which requires a reward estimation at every time step. We find that the RL-based NLG tasks are a special case in RL, where the state transition is deterministic and the afterstate value equals the Q-value at every time step. To utilize such prior knowledge, we estimate the advantage function with the difference of the Q-values which can be estimated by Monte Carlo rollouts. Experiments show that, on three tasks of NLG (NMT, image captioning, abstractive text summarization), our method consistently outperforms the state-of-the-art RL-based approaches on different frequentlyused metrics.",
        "DOI": "10.1609/aaai.v35i14.17504",
        "affiliation_name": "JD.com, Inc.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Solving the Lunar Lander Problem using Reinforcement Learning",
        "paper_author": "Sadavarte R.S.",
        "publication": "CSITSS 2021 - 2021 5th International Conference on Computational Systems and Information Technology for Sustainable Solutions, Proceedings",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Reinforcement Learning is an area of machine learning concerned with enabling an agent to solve a problem with feedback with the end goal to maximize some form of cumulative long-term reward. In this paper, two different Reinforcement Learning techniques from the value-based technique and policy gradient based method headers are implemented and analyzed. The algorithms chosen under these headers are Deep Q Learning and Policy Gradient respectively. The environment in which the comparison is done is OpenAI Gym's LunarLander environment. A comparative analysis of the two techniques is then performed in order to understand the differences in a deterministic episodic state space. Both of these algorithms are model free, that is, they can be applied irrespective of the environment and do not need to have any knowledge about the exact details of the environment itself, hence the comparison can be extended to any other environment that shares these characteristics.",
        "DOI": "10.1109/CSITSS54238.2021.9682970",
        "affiliation_name": "R.V.College of Engineering",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "2021 International Conference on Decision Aid Sciences and Application, DASA 2021",
        "paper_author": "NA",
        "publication": "2021 International Conference on Decision Aid Sciences and Application, DASA 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 212 papers. The topics discussed include: does information system aids decision making approach? the case of jury management system; bus voltage sensitivity index based approach against voltage collapse in distribution systems; hempcrete as a sustainable building material: a review; literature survey on adaptive virtual machine scheduling strategy to optimize load balancing in cloud environment; detection of corona virus disease using a novel machine learning approach; fuzzy intuitionist approach for resistance to change analysis in a digital transformation process; green human resource practices on pro-environmental behavior of workers: case of Pakistani construction industry; a multi-agent model to calculate risk on vehicle-pedestrian interaction; data security in healthcare using blockchain technology; strategic model for it investment decision for indian higher education institution in context of national education policy 2020; and decision support system for the application of lean healthcare in stock management in health facilities.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Transformer-Based Bidirectional Encoder Representations for Emotion Detection from Text",
        "paper_author": "Kumar J.A.",
        "publication": "2021 IEEE Symposium Series on Computational Intelligence, SSCI 2021 - Proceedings",
        "citied_by": "9",
        "cover_date": "2021-01-01",
        "Abstract": "Social media influences internet users to share their sentiments, feelings, or emotions about entities. In particular, sentiment analysis classifies a text into positive, negative, or neutral. It does not capture the state of mind of an individual like happiness, anger, and fear. Therefore, emotion detection plays an important role in user-generated content for capturing the state of mind. Moreover, researchers adopted traditional machine learning and deep learning models to capture emotions from the text. Recently, transformers-based architectures achieve better results in various natural language processing tasks. Therefore, we propose a transformer-based emotion detection system, which uses context-dependent features and a one-cycle learning rate policy for a better understanding of emotions from the text. We evaluate the proposed emotion detection model using error matrix, learning curve, precision, recall, F1-score, and their micro and macro averages. Our results indicate that the system achieves a 6 % accuracy over existing models.",
        "DOI": "10.1109/SSCI50451.2021.9660152",
        "affiliation_name": "School of Computer Science and Engineering",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore"
    },
    {
        "paper_title": "Trading Agent for the Indian Stock Market scenario using Actor-Critic based Reinforcement Learning",
        "paper_author": "Vishal M.",
        "publication": "CSITSS 2021 - 2021 5th International Conference on Computational Systems and Information Technology for Sustainable Solutions, Proceedings",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "Financial trading is about buying, holding, and selling securities in the hope of making a profit. Automation is a trending area in the engineering domain that can help maximize the outcome of interest. Machine learning approaches like reinforcement learning have a great potential to solve automation in certain business domains, thereby maximizing the work outcome. Reinforcement learning has the sole objective of attaining maximum profit or reward in the given environment where the agent acts. Hence, the proposed work deals with leveraging the state of the art Actor-Critic Reinforcement learning algorithms like Proximal Policy optimization (PPO), Deep Deterministic Policy Gradient (DDPG), Advantage Actor Critic (A2C), and Twin Delayed DDPG (TD3) in developing a trading agent which can make decisions based on the trading environment whether the stock has to be bought, sold or held at the given instant in the Indian Stock Market scenario.",
        "DOI": "10.1109/CSITSS54238.2021.9683467",
        "affiliation_name": "R.V.College of Engineering",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Family Expenditure and Income Analysis using Machine Learning algorithms",
        "paper_author": "Sri Y.B.",
        "publication": "2021 2nd International Conference on Smart Technologies in Computing, Electrical and Electronics, ICSTCEE 2021 - Proceedings",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Expenditure analysis should be done by every household to manage all the expenses of the family. Income prediction gives an overview of the income earned by the household to manage all the family's financial needs. Based on the expenses and other required data from the user, the system will predict the user's annual income to meet the expenses. The predicted annual income can be used by the government for initiating policies for the poor people. This prediction task is performed using Decision Tree and Random Forest Regression algorithms, as the data used for this model is continuous. Our proposed Random Forest model predicts with an accuracy of 74.35%. Based on accuracy metrics, our model is compared with Decision Tree, accuracy of 48%. Clearly, the our proposed model is more suitable for classifying than the Decision Tree model. As decision trees are best suitable for predictions based on non-linear data, we cannot depend on a single decision tree for the prediction of income. Bagging technique-based Random forest Regression is made use for the prediction of the income.",
        "DOI": "10.1109/ICSTCEE54422.2021.9708583",
        "affiliation_name": "Velagapudi Ramakrishna Siddhartha Engineering College",
        "affiliation_city": "Vijayawada",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Object Shape Error Correction using Deep Reinforcement Learning for Multi-Station Assembly Systems",
        "paper_author": "Sinha S.",
        "publication": "IEEE International Conference on Industrial Informatics (INDIN)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The paper proposes a novel approach, Object Shape Error Correction (OSEC), to determine corrective action in order to mitigate root cause(s) (RCs) of dimensional and geometric product shape errors. It leverages Deep Deterministic Policy Gradient (DDPG) algorithm to learn optimal process parameters update policies based on high dimensional state estimates of multi-station assembly systems (MAS). These policies can be interpreted in engineering terms as sequential corrective adjustments of process parameters that are necessary to mitigate RCs of product shape errors. The approach has the capability to estimate adjustments of process parameters related to fixturing and joining while simultaneously accounting for (i) RC uncertainty estimation, (ii) Key Performance Indicator (KPI) improvement, (iii) MAS design architecture; and, (iv) MAS inherent stochasticity. In addition, the OSEC methodology leverages a reward function parameterized by user interpretable functional coefficients for optimal tradeoff involving various corrections requirements. Benchmarking using an industrial, automotive cross-member assembly system demonstrates a 40% increase in the effectiveness of corrective actions when compared to current approaches.",
        "DOI": "10.1109/INDIN45523.2021.9557359",
        "affiliation_name": "University of Warwick",
        "affiliation_city": "Coventry",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Complex and Entangled Public Policy: Here Be Dragons",
        "paper_author": "Devereaux A.",
        "publication": "Studies in Public Choice",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The tools and concepts of the emerging field of complexity science—like agent-based modeling, network theory, and machine learning—can offer powerful insights to economists and crafters of public policy. Complexity science enables us to explicitly model relationships between individuals and institutions, asymmetric information and influence, the emergence of unplanned emergent social orders, and dynamically adaptive individuals. In the last few decades the tools of complexity science have been applied to the problem of public goods provision, correcting hypothesized behavioral biases, and raising the efficiency of policy implementation. These analyses often lack public choice perspectives, which may complicate and even obviate their findings when the designer becomes entangled with the complex structures in his models. Furthermore, there remains a good deal of work to be done to harmonize traditional public choice work with the tools and insights of complexity science. Uncharted waters must eventually be charted; we hope to begin in such a way that avoids the worst of the dragons.",
        "DOI": "10.1007/978-3-030-56088-1_4",
        "affiliation_name": "Wichita State University",
        "affiliation_city": "Wichita",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Composite Adversarial Attacks",
        "paper_author": "Mao X.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "31",
        "cover_date": "2021-01-01",
        "Abstract": "Adversarial attack is a technique for deceiving Machine Learning (ML) models, which provides a way to evaluate the adversarial robustness. In practice, attack algorithms are artificially selected and tuned by human experts to break a ML system. However, manual selection of attackers tends to be sub-optimal, leading to a mistakenly assessment of model security. In this paper, a new procedure called Composite Adversarial Attack (CAA) is proposed for automatically searching the best combination of attack algorithms and their hyper-parameters from a candidate pool of 32 base attackers. We design a search space where attack policy is represented as an attacking sequence, i.e., the output of the previous attacker is used as the initialization input for successors. Multiobjective NSGA-II genetic algorithm is adopted for finding the strongest attack policy with minimum complexity. The experimental result shows CAA beats 10 top attackers on 11 diverse defenses with less elapsed time (6 × faster than AutoAttack), and achieves the new state-of-the-art on l∞, l2 and unrestricted adversarial attacks.",
        "DOI": "10.1609/aaai.v35i10.17075",
        "affiliation_name": "Alibaba Group Holding Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A reinforcement learning model for virtual machines consolidation in cloud data center",
        "paper_author": "Chou Q.",
        "publication": "Proceedings - 2021 6th International Conference on Automation, Control and Robotics Engineering, CACRE 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Energy consumption in data center is currently the main focus of many large-scale enterprises and cloud service providers. Dynamic virtual machine (VM) consolidation technologies are widely used to improve resource utilization of data centers and reduce energy. They try to identify the poorly utilized physical hosts and make the most of the resources. Then idle hosts can be switched to sleep or active mode, meanwhile considering the real-time fluctuation of service workload. In this paper, we propose a Reinforcement Learning (RL) based Virtual Machine Consolidation (RL-VMC) framework with an application to the cloud data center operation. The RL-VMC method uses an agent corresponding to a VM planner to interact with the environment, which encapsulates the data center running state, and learns the optimal policy to determine the migration mapping from VMs to physical hosts. Specifically, we adopt the on-policy method State-Action-Reward-State-Action (SARSA) in RL-VMC, which learns from experience to get the optimal VMs migration strategy and manage the host power mode as well. Additionally, we use the PBRS technology to speed up the convergence of the RL-VMC. Experimental results show that the RL-VMC method can adapt to the dynamic workload maintaining an improved balance between energy consumption and Service Level Agreements (SLA).",
        "DOI": "10.1109/CACRE52464.2021.9501288",
        "affiliation_name": "Lenovo Group, China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Image Representation of a City and Its Taxi Fleet for End-To-End Learning of Rebalancing Policies",
        "paper_author": "Gächter J.",
        "publication": "Proceedings - IEEE International Conference on Robotics and Automation",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "In recent years, mobility on demand has experienced a major revival due to various ride-hailing companies entering the market. Competing in this field requires an efficient operation. Therefore, the applied policy, which cares for vehicle-to-customer assignment and vehicle repositioning, has to achieve good customer service and minimize cost while trying to keep the impact on the environment as low as possible. A promising approach is to coordinate the control of the entire fleet, which is foreseen to become even easier with the possibility of autonomous vehicles in mind. Anticipating future demand requires a good understanding of the spatiotemporal distributions of request origins and destinations, and the resulting imbalance between vehicle demand and availability. This results from a multitude of topological, demographic, and social effects, which are almost impossible to sufficiently capture in a handcrafted model of reasonable complexity. This can be circumvented by leveraging machine learning approaches. In this paper, an image-like representation of the city and its fleet's state is introduced. It is comprehensive and intuitive to use as input to convolutional neural networks, which in the past have already been proven to capture spatial relationships very well. This allows operating on realistic, full-sized traffic networks without greatly increasing the number of parameters the neural network has to learn and, hence, keeps the training effort low. Additionally, this state is combined with a similarly constructed repositioning action, reflecting a 2D distribution of a well-performing operational policy. This approach allows replacement of complex, handcrafted mathematical models by a single, compact, auto-encoder-like neural network.",
        "DOI": "10.1109/ICRA48506.2021.9561552",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Microgrids: Design, Challenges, and Prospects",
        "paper_author": "Narejo G.B.",
        "publication": "Microgrids: Design, Challenges, and Prospects",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "This book addresses the needs of researchers on the fundamental level as well as those with more advanced knowledge of microgrids and their evolution. This book covers newly emerging trends in fields such as computer science, energy, electrical engineering, and electronics and brings the reader current on the newly emerging fields that play an important role in the power infrastructure. Microgrids: Design, Challenges, and Prospects provides knowledge on decision making for newly evolving trends in microgrid design. It discusses techniques on how to improve the existing power quality and reduce load shedding and power imbalances. The book presents the emerging fields such as data science, machine learning, AI, and IT that now play an important role in microgrid design. The readership includes: researchers, academia, practicing engineers, consumers, power companies, and policy makers located across the globe.",
        "DOI": "10.1201/9781003121626",
        "affiliation_name": "Kalinga Institute of Industrial Technology, Bhubaneswar",
        "affiliation_city": "Bhubaneswar",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Addressing the Long-term Impact of ML Decisions via Policy Regret",
        "paper_author": "Lindner D.",
        "publication": "IJCAI International Joint Conference on Artificial Intelligence",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Machine Learning (ML) increasingly informs the allocation of opportunities to individuals and communities in areas such as lending, education, employment, and beyond. Such decisions often impact their subjects' future characteristics and capabilities in an a priori unknown fashion. The decision-maker, therefore, faces exploration-exploitation dilemmas akin to those in multi-armed bandits. Following prior work, we model communities as arms. To capture the long-term effects of ML-based allocation decisions, we study a setting in which the reward from each arm evolves every time the decision-maker pulls that arm. We focus on reward functions that are initially increasing in the number of pulls but may become (and remain) decreasing after a certain point. We argue that an acceptable sequential allocation of opportunities must take an arm's potential for growth into account. We capture these considerations through the notion of policy regret, a much stronger notion than the often-studied external regret, and present an algorithm with provably sub-linear policy regret for sufficiently long time horizons. We empirically compare our algorithm with several baselines and find that it consistently outperforms them, in particular for long time horizons.",
        "DOI": "10.24963/ijcai.2021/75",
        "affiliation_name": "Carnegie Mellon University",
        "affiliation_city": "Pittsburgh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Artificial Intelligence-Based Cost Reduction for Customer Retention Management in the Indian Life Insurance Industry",
        "paper_author": "Thawakar S.",
        "publication": "Springer Proceedings in Business and Economics",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Customer retention, measured as percentage policies renewed every year (persistency ratio), is one of the most important metrics for any life insurer. Due to several factors, including complexity of life insurance products, gap in understanding the importance of policy renewals and lack of appropriate engagement with the customers, higher lapsation rates for life insurance policies have been observed globally, specifically in India. Typically for a life insurance company, policy renewal premiums drive close to 60–70% revenue and retaining customers for a period of more than 6–7 years is critical to business profitability. Customer retention operations primarily include engaging with customers through telephonic renewal calls or other mediums to pay renewal premiums on time. With close to 70% of total policies present in the premium renewal base, tracking, scheduling, execution of customer retentions calls and campaigns contribute to a major cost head for life insurers. In this paper, the authors present an advanced analytic solution to effectively manage customer retention costs and improve the overall persistency. The paper demonstrates the use of several machine learning and deep learning neural network-based models to classify the customers based on propensity of not paying renewal premiums on time. The study includes a comparative analysis of model performance with the deep learning neural network model showing the highest performance. The propensity scores were used to create a solution driving differentiated retention strategy, matching customer segment with appropriate renewal efforts to reduce customer retention cost and improve persistency.",
        "DOI": "10.1007/978-981-33-6656-5_6",
        "affiliation_name": "Centre of Excellence in Nanotechnology",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Control of Shared Production Buffers: A Reinforcement Learning Approach",
        "paper_author": "Krippendorff N.",
        "publication": "2021 IEEE International Conference on Industrial Engineering and Engineering Management, IEEM 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "We consider a buffer control problem arising in stochastic flow lines with shared production buffers. Buffer control relies on decision rules which determine transfers of items between buffers and machines at the release or completion times of parts on the different production stages. We devise a conceptual model of the problem for a basic scenario with one central buffer and explain how general system configurations and a tactical buffer allocation problem can be modeled within this framework. Assuming that the flow line can be represented as a Markovian production system, we provide a formulation as a continuous-time Markov decision problem admitting an optimal stationary policy. By applying a uniformization approach from literature, the Markov decision problem is discretized in time and thus amenable to standard algorithms. We propose a simple Q-learning implementation of reinforcement learning converging to an optimal stationary policy and validate the approach in a numerical experiment with a small toy problem.",
        "DOI": "10.1109/IEEM50564.2021.9673034",
        "affiliation_name": "Technische Universität Clausthal",
        "affiliation_city": "Clausthal-Zellerfeld",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Adaptive Biometric Cloud Facial Aging Template Policy - A Time Point Analysis",
        "paper_author": "Graham T.",
        "publication": "Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper we use Facenet, an open-source machine learning cloud platform to verify biometric facial templates created with the ones already enrolled. Our efforts seek to determine if, for different sample images of different ages when evaluated against our pattern matching algorithm, the template policy changes with the aged images. Whilst our approach may hold true for small data set changes that the template policy does not see any anomalies, all other things being equal, as in the results in the current paper, we argue that the template policy could change if we explore the concerns over a large continuous data set as our next step and treated as independent work to this current paper.",
        "DOI": "10.1109/BigData52589.2021.9671408",
        "affiliation_name": "University of Technology Kingston",
        "affiliation_city": "Kingston",
        "affiliation_country": "Jamaica"
    },
    {
        "paper_title": "Applying Machine Learning to Analyze Anti-Vaccination on Tweets",
        "paper_author": "Taeb M.",
        "publication": "Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Inspection of Anti-COVID vaccination tweets can be useful for many such analyses, and extraction of relevant information about opinion expressed on Twitter. This study proposes an analytical framework for analyzing tweets (COVID Vaccine, especially the Anti- COVID Vaccine) to identify and categorize fine-grained details about the COVID19 disaster such as affected individuals, public feelings towards the vaccine and reopening of business, polarity of public opinions on the vaccine and services provided, discussed topic changing over temporal dimension, and different clustering algorithms. In this project, we have analyzed COVID -Vaccine related tweets and Anti-Vaccine tweets, performed sentiment analysis and Topic modeling, and compared various models' behavior based on different configuration and training datasets. The result of this work will help policy makers and data scientists to identify the best approach for twitter sentiment analysis and topic modeling as well as providing feedback on people attitude and opinion on COVID-19 vaccine.",
        "DOI": "10.1109/BigData52589.2021.9671647",
        "affiliation_name": "Florida Agricultural and Mechanical University",
        "affiliation_city": "Tallahassee",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "To Reduce Healthcare Workload: Identify Critical Sepsis Progression Moments through Deep Reinforcement Learning",
        "paper_author": "Ju S.",
        "publication": "Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Healthcare systems are struggling with increasing workloads that adversely affect quality of care and patient outcomes. When clinical practitioners have to make countless medical decisions, they may not always able to make them consistently or spend time on them. In this work, we formulate clinical decision making as a reinforcement learning (RL) problem and propose a human-controlled machine-assisted (HC-MA) decision making framework whereby we can simultaneously give clinical practitioners (the humans) control over the decision-making process while supporting effective decision-making. In our HC-MA framework, the role of the RL agent is to nudge clinicians only if they make suboptimal decisions at critical moments. This framework is supported by a general Critical Deep RL (Critical-DRL) approach, which uses Long-Short Term Rewards (LSTRs) and Critical Deep Q-learning Networks (CriQNs). Critical-DRL's effectiveness has been evaluated in both a GridWorld game and real-world datasets from two medical systems: a large health system in the northeast of USA, referred as NEMed and Mayo Clinic in Rochester, Minnesota, USA for septic patient treatment. We found that our Critical-DRL approach, by which decisions are made at critical junctures, is as effective as a fully executed DRL policy and moreover, it enables us to identify the critical moments in the septic treatment process, thus greatly reducing burden on medical decision-makers by allowing them to make critical clinical decisions without negatively impacting outcomes.",
        "DOI": "10.1109/BigData52589.2021.9671407",
        "affiliation_name": "NC State College of Engineering",
        "affiliation_city": "Raleigh",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "2nd International Conference on Research on National Brand and Private Label Marketing, NB and PL 2015",
        "paper_author": "NA",
        "publication": "Springer Proceedings in Business and Economics",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 21 papers. The special focus in this conference is on Research on National Brand and Private Label Marketing. The topics include: Industry and Size Effect in the Relation Between Corporate Material and Financial Decisions: Findings from the EU Countries; technology Level and Financial Constraints of Public Listed Companies; differences in Use of Credit Products Between the Old and New Member States of the European Union; diversified Risky Financial Assets in Portfolios of Risk-Averse Households: What Determines Their Occurrence?; financial Behavior: Preliminary Survey Results; Does Withholding Tax Reduce International Income-Shifting by FDI?; the Relationship Between Trading Volume and Returns Volatility on Warsaw Stock Exchange; factors Influencing Individual Investor Participation in Stock Market; Model Risk of VaR and ES Using Monte Carlo: Study on Financial Institutions from Paris and Frankfurt Stock Exchanges; tick Size Reduction and Liquidity Dimensions: Evidence from an Emerging Market; cryptocurrency Portfolio Construction Using Machine Learning Models; development Factors of Blockchain Technology Within Banking Sector; does Competition Matter for the Effects of Macroprudential Policy on Bank Asset Growth?.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Hidden Workforce: Analysis on Recognizing Unpaid Domestic Work Through Social Determinants",
        "paper_author": "Hicks J.",
        "publication": "Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The United Nations collects data at gigabyte scale from the member countries for sustainable development goals, and recognizes the impact big data collection has on opportunities and risks for sustainable development. The United Nations (UN) Sustainable Development Goals (SDG) open data hub provided a dataset that details the proportion of time spent on unpaid domestic chores and care work world wide. This primary dataset is only a portion of the data available related to the research area. This data contains many related variables, such as the population's age, sex, and location metrics. In an effort to better understand the impact of unpaid domestic work, the dataset was analyzed in conjunction with another dataset from the UN Statistics Division that details the rate of divorce/separation in the world population. Our analysis included methods such as principal component analysis, the k-means clustering algorithm, the random forest clustering algorithm, and implementing a neural network. The principal components were clustered using the k-means algorithm to cluster the variables in a manner that explains the variance present in the dataset. The analysis found that age, sex, and location demographics are key variables that explain the diverse variation between countries and the percentage of time spent on unpaid domestic work.Machine learning algorithms enabled the confirmation of this relationship. Using the key variables identified, a random forest of decision trees and a neural network were generated to classify the percentage of time spent on unpaid domestic work. Similarly, the random forest algorithm and a neural network were also implemented to classify geographical regions. These models were compared to determine the strength of the relationship between age, sex, location metrics, the percentage of time spent, and geographical regions.The analysis detailed in this work strives to identify the social factors that classify the percentage of time spent on unpaid domestic work in accordance with the UN SDG 5.4, which is to recognize and value unpaid care and domestic work through the provision of public services, infrastructure, and social protection policies and the promotion of shared responsibility within the household and the family as nationally appropriate.",
        "DOI": "10.1109/BigData52589.2021.9671872",
        "affiliation_name": "Rensselaer Polytechnic Institute",
        "affiliation_city": "Troy",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Preventing Traffic Accidents Through Machine Learning Predictive Models",
        "paper_author": "Bedane T.T.",
        "publication": "2021 International Conference on Information and Communication Technology for Development for Africa, ICT4DA 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Road Traffic Accidents (RTA) are a serious issue of societies resulting in huge losses at the economic and social levels and responsible for millions of deaths and injuries every year in the world. For instance, in Ethiopia, the number of deaths due to traffic accidents is increasing from one year to another. Addis Ababa is one of the popular and known cities that encounter a high number of RTAs due to the increasing number of vehicles and population. The main objective of this paper is to apply machine learning algorithms to predict the accident severity and identify the major causes of accidents in crowded cities (application of Addis Ababa city). The required data are collected from Addis Ababa city police departments and 12316 records of the accident are used for data analysis. We applied seven machine learning classification algorithms (Logistic Regression, Naive Bayes, Decision Tree, Support Vector Machine, K Nearest Neighbor, Random Forest, and AdaBoost) for predicting accident severity and compared the performance to choose the best model. We applied random undersampling and SMOTE oversampling techniques to handle the class imbalance nature of the dependent features and Principal Component Analysis (PCA) for dimension reduction. The experimental result shows that Random Forest achieved a 93.76% F1 score with SMOTE over-sampled data set and about 18% feature size reduction. Moreover, light condition, driving experience, age band of the driver, type of road lane, and types of junctions are identified as major determinant factors of the accident. According to this study, these are major factors to RTA and need to be considered in the design of infrastructure, regulations and policies to reduce accidents.",
        "DOI": "10.1109/ICT4DA53266.2021.9672249",
        "affiliation_name": "Sri Sri University",
        "affiliation_city": "Cuttack",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Application of Machine Learning and Government Finance Statistics for macroeconomic signal mining to analyze recessionary trends and score policy effectiveness",
        "paper_author": "Vuppalapati C.",
        "publication": "Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "The budget speech is part of the democratic process that is presented annually to members of the parliament and addressed to Speaker of the house. Budget speech includes details of annual financial statements or financial plans of the government, containing details of revenue and expenditure in the past, along with the estimated spending and projections for the following year. Speech, additionally, consists of new policies and / or reforms announced to address fiscal macroeconomic issues. It takes, importantly, years to witness effectiveness of policies, especially in agriculture and infrastructure sectors. In this research paper, we propose an innovative Machine Learning framework that scores effectiveness of agricultural policies through binning language processing statements with key macroeconomic performance multiclass-multilabel-indicators that are regressed from government finance statistics and macroeconomic time series data. Finally, the paper presents budget speech prototype solution as well as its application for analyzing 2021 Indian budget speech.",
        "DOI": "10.1109/BigData52589.2021.9672025",
        "affiliation_name": "San Jose State University",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Efficient Reinforced Feature Selection via Early Stopping Traverse Strategy",
        "paper_author": "Liu K.",
        "publication": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, we propose a single-agent Monte Carlo based reinforced feature selection (MCRFS) method, as well as two efficiency improvement strategies, i.e., early stopping (ES) strategy and reward-level interactive (RI) strategy. Feature selection is one of the most important technologies in data prepossessing, aiming to find the optimal feature subset for a given downstream machine learning task. Enormous research has been done to improve its effectiveness and efficiency. Recently, the multi-agent reinforced feature selection (MARFS) has achieved great success in improving the performance of feature selection. However, MARFS suffers from the heavy burden of computational cost, which greatly limits its application in real-world scenarios. In this paper, we propose an efficient reinforcement feature selection method, which uses one agent to traverse the whole feature set, and decides to select or not select each feature one by one. Specifically, we first develop one behavior policy and use it to traverse the feature set and generate training data. And then, we evaluate the target policy based on the training data and improve the target policy by Bellman equation. Besides, we conduct the importance sampling in an incremental way, and propose an early stopping strategy to improve the training efficiency by the removal of skew data. In the early stopping strategy, the behavior policy stops traversing with a probability inversely proportional to the importance sampling weight. In addition, we propose a reward-level interactive strategy to improve the training efficiency via reward-level external advice. Finally, we design extensive experiments on real-world data to demonstrate the superiority of the proposed method.",
        "DOI": "10.1109/ICDM51629.2021.00051",
        "affiliation_name": "Alibaba Group Holding Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Mobile Robot Path Planning Method Based on Safe Pathfinding Guidance",
        "paper_author": "Bie T.",
        "publication": "Proceedings of the 33rd Chinese Control and Decision Conference, CCDC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The problem of path planning in the field of robot navigation is now a major research hot spot. On the premise of ensuring that the robot can successfully navigate to the target point, the safety of the path also needs to be considered. In order to find a safer path, a safe pathfinding path planning method is proposed, which introduces two safety parameters that affect the path selection: hazard coefficient and movement coefficient. After defining two security parameters, design an appropriate reward function and use A2C algorithm and PPO algorithm to guide the robot to conduct reinforcement learning. The experiment will be conducted on a two-dimensional grid map containing various obstacles. By conducting comparative experiments, it is verified that the safety pathfinding method proposed in this paper is feasible and reasonable, and can enable the robot to choose a safer road instead of a faster road when planning the path.",
        "DOI": "10.1109/CCDC52312.2021.9601697",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Global Convolutional Neural Processes",
        "paper_author": "Wang X.",
        "publication": "Proceedings - IEEE International Conference on Data Mining, ICDM",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "The ability to deal with uncertainty in machine learning models has become equally, if not more, crucial to their predictive ability itself. For instance, during the pandemic, governmental policies and personal decisions are constantly made around uncertainties. Targeting this, Neural Process Families (NPFs) have recently shone a light on prediction with uncertainties by bridging Gaussian processes and neural networks. Latent neural process, a member of NPF, is believed to be capable of modelling the uncertainty on certain points (local uncertainty) as well as the general function priors (global uncertainties). Nonetheless, some critical questions remain unresolved, such as a formal definition of global uncertainties, the causality behind global uncertainties, and the manipulation of global uncertainties for generative models. Regarding this, we build a member GloBal Convolutional Neural Process(GBCoNP) that achieves the SOTA log-likelihood in latent NPFs. It designs a global uncertainty representation p(z), which is an aggregation on a discretized input space. The causal effect between the degree of global uncertainty and the intra-task diversity is discussed. The learnt prior is analyzed on a variety of scenarios, including 1D, 2D, and a newly proposed spatial-temporal COVID dataset. Our manipulation of the global uncertainty not only achieves generating the desired samples to tackle few-shot learning, but also enables the probability evaluation on the functional priors.",
        "DOI": "10.1109/ICDM51629.2021.00081",
        "affiliation_name": "The University of Queensland",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Multi-Site Best Practice Discovery: From Free Text to Standardized Concepts to Clinical Decisions",
        "paper_author": "Lee E.K.",
        "publication": "Proceedings - 2021 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "This study establishes interoperability among electronic medical records from 800 clinical sites and uses machine learning for best practice discovery. A novel extraction-mapping algorithm is designed that accurately extracts, summarizes, and maps free text and content to concise structured medical concepts. Multiple concepts are mapped, including patient diagnoses, laboratory results, medications, and procedures, which allow shared characterization and hierarchical comparison. In addition, clinical and decision processes are established. These integrated data can be accessed through a secure web-based portal. A classification machine learning model (DAMIP) is then leveraged to establish predictive rules by uncovering relatively small subsets of discriminatory features that can predict the quality of treatment outcomes. We demonstrate system usability by analyzing treatment outcome for cardiovascular diseases, diabetes, hypertension, and chronic kidney disease. DAMIP yields good blind prediction accuracies of 89% - 97%. Moreover, for each disease the best practice was only used at fewer than 5% of the clinical sites, offering an excellent opportunity for knowledge sharing and rapid learning. Our findings also led to implementation of a new treatment policy for chronic kidney disease management. This resulting policy offers a better outcome for patients, saves lives, improves the quality of life for patients, and reduces 35% of treatment costs. Thus, this work has critical health practice implications. Through data-driven interoperability and predictive analytics, we have established and identified practice characteristics that result in good outcomes. The system is scalable and generalizable to different hospital settings and health conditions.",
        "DOI": "10.1109/BIBM52615.2021.9669414",
        "affiliation_name": "Medical University of South Carolina",
        "affiliation_city": "Charleston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Automatic Identification of Student's Cognitive Style from Online Laboratory Experimentation using Machine Learning Techniques",
        "paper_author": "Yousef A.M.F.",
        "publication": "2021 IEEE 12th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2021",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "Online learning has emerged as powerful learning methods for the transformation from traditional education to open learning through smart learning platforms due to Covid-19 pandemic. Despite its effectiveness, many studies have indicated the necessity of linking online learning methods with the cognitive learning styles of students. The level of students always improves if the teaching methods and educational interventions are appropriate to the cognitive style of each student individually. Currently, psychological measures are used to assess students' cognitive styles, but about the application in virtual environment, the matter becomes complicated. The main goal of this study is to provide an efficient solution based on machine learning techniques to automatically identify the students' cognitive styles by analyzing their mouse interaction behaviors while carrying out online laboratory experiments. This will help in the design of an effective online laboratory experimentation system that is able to individualize the experiment instructions and feedback according to the identified cognitive style of each student. The results reveal that the KNN and SVM classifiers have a good accuracy in predicting most cognitive learning styles. In comparison to KNN, the enlarged studies ensemble the KNN, linear regression, neural network, and SVM reveal a 13% increase in overall total RMS error. We believe that this finding will enable educators and policy makers to predict distinct cognitive types in the assessment of students when they interact with online experiments. We believe that integrating deep learning algorithms with a greater emphasis on mouse location traces will improve the accuracy of our classifiers' predictions.",
        "DOI": "10.1109/UEMCON53757.2021.9666516",
        "affiliation_name": "Faculty of Specific Education",
        "affiliation_city": "Fayoum",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Device Identification for IoT Security",
        "paper_author": "Roemsri P.",
        "publication": "2021 6th International Conference on Signal and Image Processing, ICSIP 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "IoT (Internet of things) devices have become integral parts of our everyday life to function especially in smart homes/offices/cities. However, their huge varieties and scales make it hard to manage the security and the quality of services of IoT networks with generic policies. Furthermore, IoT devices owned by employees can unknowingly endanger the security and integrity of the network from other IoT entities they are connected to. Fortunately, IoT devices of the same type tend to have similar vulnerabilities making attack prevention more manageable. Thus, identifying the device types is crucial for IoT security. This paper presents an approach to building a classifier to identify different types of IoT devices using various machine learning techniques. While most existing empirical studies use network traffic data, we use communication protocol data. The paper describes the data collection/treatment, the experiments using four machine learning techniques and compares our proposed approach with an existing work based on the Jaccard similarity measure. The results show that both approaches have competitive accuracy of up to 99% but the Jaccard approach does not scale well (e.g., about 1000 times more than the training time of our approach).",
        "DOI": "10.1109/ICSIP52628.2021.9688598",
        "affiliation_name": "Edward E. Whitacre Jr. College of Engineering",
        "affiliation_city": "Lubbock",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Research on Automated Reinforcement Learning: Based on Tree-structured Parzen Estimators and Median Pruning",
        "paper_author": "Wang Z.",
        "publication": "Proceedings of the 33rd Chinese Control and Decision Conference, CCDC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Tuning the hyper parameters of machine learning algorithm is regarded as a boring and difficult challenge to the researcher in the artificial intelligence domain. However, with the rapidly development of computer clusters and GPU processors, the automated machine learning algorithm have been proposed to solve this problem. In this paper, an automated reinforcement learning method has been proposed by focusing on the automated hyper parameters tuning of the reinforcement learning, a relatively new branch of machine learning which is more suitable to the motion control. For reducing the amount of calculations and finding the optimization solution more quickly, an open automated optimization framework have been proposed by combing the tree-structured Parzen estimators based Bayesian optimization and median pruning algorithm. A specific simulation has been given based on the deep deterministic policy gradient case to show the effectiveness and practicability of the proposed method.",
        "DOI": "10.1109/CCDC52312.2021.9601578",
        "affiliation_name": "Beijing Aerospace Automatic Control Institute",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "An Adaptive Dynamic Programming Algorithm Based on ITF-OELM for Discrete-Time Systems",
        "paper_author": "Zhang X.",
        "publication": "Proceedings of the 33rd Chinese Control and Decision Conference, CCDC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Adaptive dynamic programming (ADP) is a kind of intelligent control method, and it is a non-model-based method that can directly approximate the optimal control policy via online learning. The gradient algorithm is usually used to update weights of action networks and critic networks, however it is clear that gradient descent-based learning methods are generally very slow due to improper learning steps or may easily converge to local minimum. In this paper, in order to overcome those disadvantages of gradient descent-based learning methods, a novel ADP algorithm based on initial-training-free online extreme learning machine (ITF-OELM), in which the critic network link weights of hidden nodes to output nodes can be obtained by least squares instead of gradient algorithm, is introduced. Finally, the ADP algorithm based on ITF-OELM is tested on a discrete time torsional pendulum system, and simulation results indicate that this algorithm makes the system converge in a shorter time compared with the ADP based on gradient algorithm.",
        "DOI": "10.1109/CCDC52312.2021.9601954",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Model-Based Exploration Policy in Deep Q-Network",
        "paper_author": "Li S.",
        "publication": "2021 International Conference on Digital Society and Intelligent Systems, DSInS 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Reinforcement learning has successfully been used in many applications and achieved prodigious performance (such as video games), and DQN is a well-known algorithm in RL. However, there are some disadvantages in practical applications, and the exploration and exploitation dilemma is one of them. To solve this problem, common strategies about exploration like ϵ-greedy have risen. Unfortunately, there are sample inefficient and ineffective because of the uncertainty of later exploration. In this paper, we propose a model-based exploration method that learns the state transition model to explore. Using the training rules of machine learning, we can train the state transition model networks to improve exploration efficiency and sample efficiency. We compare our algorithm with ϵ-greedy on the Deep Q-Networks (DQN) algorithm and apply it to the Atari 2600 games. Our algorithm outperforms the decaying ϵ-greedy strategy when we evaluate our algorithm across 14 Atari games in the Arcade Learning Environment (ALE).",
        "DOI": "10.1109/DSInS54396.2021.9670573",
        "affiliation_name": "Southern University of Science and Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Comparative analysis of machine learning approaches to analyze and predict the COVID-19 outbreak",
        "paper_author": "Naeem M.",
        "publication": "PeerJ Computer Science",
        "citied_by": "21",
        "cover_date": "2021-01-01",
        "Abstract": "Background: Forecasting the time of forthcoming pandemic reduces the impact of diseases by taking precautionary steps such as public health messaging and raising the consciousness of doctors. With the continuous and rapid increase in the cumulative incidence of COVID-19, statistical and outbreak prediction models including various machine learning (ML) models are being used by the research community to track and predict the trend of the epidemic, and also in developing appropriate strategies to combat and manage its spread. Methods: In this paper, we present a comparative analysis of various ML approaches including Support Vector Machine, Random Forest, K-Nearest Neighbor and Artificial Neural Network in predicting the COVID-19 outbreak in the epidemiological domain. We first apply the autoregressive distributed lag (ARDL) method to identify and model the short and long-run relationships of the time-series COVID-19 datasets. That is, we determine the lags between a response variable and its respective explanatory time series variables as independent variables. Then, the resulting significant variables concerning their lags are used in the regression model selected by the ARDL for predicting and forecasting the trend of the epidemic. Results: Statistical measures—Root Mean Square Error (RMSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE) and Symmetric Mean Absolute Percentage Error (SMAPE)—are used for model accuracy. The values of MAPE for the best-selected models for confirmed, recovered and deaths cases are 0.003, 0.006 and 0.115, respectively, which falls under the category of highly accurate forecasts. In addition, we computed 15 days ahead forecast for the daily deaths, recovered, and confirm patients and the cases fluctuated across time in all aspects. Besides, the results reveal the advantages of ML algorithms for supporting the decision-making of evolving short-term policies.",
        "DOI": "10.7717/PEERJ-CS.746",
        "affiliation_name": "Abdul Wali Khan University Mardan",
        "affiliation_city": "Mardan",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "2021 IEEE Conference on Telecommunications, Optics and Computer Science, TOCS 2021",
        "paper_author": "NA",
        "publication": "2021 IEEE Conference on Telecommunications, Optics and Computer Science, TOCS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 228 papers. The topics discussed include: construction and research of recommendation model based on deep learning; construction of information system of ideology education for college students based on association rules mining; the application of digital simulation technology in optimization of pipeline assembly for the core module of space station; research on the key agreement scheme between car and cloud server based on certificateless; machine reading comprehension of high-tech industry policies: a new dataset and Chinese pre-trained language model; travel route planning through simulated annealing algorithm and model data; and kinematic to kinematic positioning method based on sliding-window epoch-difference.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Regional Rural Economic Forecasting Based on Single Exponential Smoothing Model with Outlier points",
        "paper_author": "Jing L.",
        "publication": "2021 IEEE Conference on Telecommunications, Optics and Computer Science, TOCS 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The article addresses the problem that the traditional single exponential smoothing model (SES) is disturbed by outliers in the time series and is not easy to find, and searches for outliers and removes them with the help of subsets, to construct a single exponential smoothing model (SESO) based on outliers, and takes Guangxi Fangchenggang as an example to forecast the primary industry and rural residents' disposable income The results show that the SESO model has high prediction accuracy and credible results The SESO model can make predictions of regional rural economy-related indicators well; corresponding policies are proposed for the characteristics of rural economic changes in Fangchenggang, Guangxi.",
        "DOI": "10.1109/TOCS53301.2021.9688826",
        "affiliation_name": "Nanning University",
        "affiliation_city": "Nanning",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Design and Analysis of a ChatBot with IPL First Inning Score Prediction",
        "paper_author": "Suresh K.",
        "publication": "2021 International Conference on Advancements in Electrical, Electronics, Communication, Computing and Automation, ICAECA 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "A chat bot aims to make conversations with human and machine both. The use of chat bots has emerged rapidly in many fields, including marketing, support systems, education, health care, cultural heritage, and entertainment. The machine is equipped with the information to identify the sentences and make the decision itself as a response to the question. Response policy compares the input sentence from the user. We have integrated our Chat bot with IPL first inning score prediction. In this paper, details of the last decade IPL seasons from 2008-2017 are used for prediction. Six machine learning techniques are used for prediction and their performance is analyzed. The result shows that the prediction accuracy of Random Forest is better than all other models.",
        "DOI": "10.1109/ICAECA52838.2021.9675645",
        "affiliation_name": "Manav Rachna International Institute of Research and Studies",
        "affiliation_city": "Faridabad",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Maintenance Practice Performance Assessment of Hydraulic Machinery: West Balkan Meta-Statistics and Energy-Based Maintenance Paradigm",
        "paper_author": "Orosnjak M.",
        "publication": "2021 5th International Conference on System Reliability and Safety, ICSRS 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "As a consequence of accepting the Green Deal initiative, sustainable maintenance attracted significant attention. However, observation of low market intelligence and lack of sustainable goal-oriented practice has been reported. The article proposes the Energy-Based Maintenance (EBM) paradigm to fulfil the needs of sustainable manufacturing philosophy. The EBM implicitly consists of two concepts: Functional Productiveness (FPC) and Comparative Functional Dynamics (CFD). Namely, the core of FPC is to propose a new view in understanding the nature of functionality by delineating static (maintenance) events (e.g., total failure, stoppage, etc.) from dynamic (process) events (e.g., quasi-faults, leakage, degradation). The CFD uses FPC and dynamic (process) events and acts as a catalyst in reducing noise in feature extraction by comparing system dynamics and energy consumption. Demonstration on a case study of proposed EBM practice is conducted and used as a measure of comparison with traditional maintenance practices (policies). However, the results show a reduction in oil waste and energy consumption at the cost of increasing inspection and stoppages.",
        "DOI": "10.1109/ICSRS53853.2021.9660739",
        "affiliation_name": "University of Novi Sad",
        "affiliation_city": "Novi Sad",
        "affiliation_country": "Serbia"
    },
    {
        "paper_title": "Risk scenario-based value estimation of Bitcoin",
        "paper_author": "Cai C.",
        "publication": "Procedia Computer Science",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The wild swings in Bitcoin's valuation keep attracting authorities' and policy-makers interest. Thus at present, many researchers are focus on analyzing and forecasting. The existing studies on Bitcoin price prediction are mainly in two ways: (1) study how economic factors, market and investor sentiment indicators influence Bitcoin price; (2) apply machine learning and artificial neural networks to predict the value of Bitcoin. This paper aims to implement a scenario analysis method to generate various hypothetical events and then determine their effects on the value of Bitcoin price. Scenario analysis is normally used to measure financial risk. In this paper, we propose a method that combines scenario analysis with historical data. We further aim to find the correlations among scenarios and examine the relationship between the significant shocks and Bitcoin prices. Our findings suggest that what-if analysis is a good way to measure the risk exposure of Bitcoin. The method can also be used for worse-scenario analysis to check how Bitcoin performs during crisis periods.",
        "DOI": "10.1016/j.procs.2022.01.152",
        "affiliation_name": "Institutes of Science and Development",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Predicting Quality of Life using Machine Learning: case of World Happiness Index",
        "paper_author": "Jannani A.",
        "publication": "2021 4th International Symposium on Advanced Electrical and Communication Technologies, ISAECT 2021",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "Quality of life (QoL) is a very interesting topic, especially for policy makers and people that are interested in general state of citizen, and it can be seen in very different ways and from various perspectives. Across times the assessment of QoL had taken several shapes and sizes but with only one single purpose, which is, to assess the state of well-being of an individual, a group of people or the welfare of a region or a nation. With the introduction of data science tools and machine learning algorithms, peoples are able to observe the evolution of a country, governments can evaluate the effectiveness of country-level programs and analyze main factors contributing to this evolution and its impacts and thereby make better decisions. We especially focus on world happiness index, which is an international QoL index developed by the United Nations Sustainable Development Solutions Network. In this work, we are interested in well-being prediction systems based on machine-learning algorithms. For this purpose, we made a comparative study to explore the potential of the most used machine-learning algorithms on data of The World Happiness Report (WHR). The experiment results showed that regression algorithms achieved an R squared of 0.8954 and RMSE = 0.0656, Lasso Regression, Multiple Linear Regression and LSTM were the best performing algorithms for predicting the QoL indicator for the year 2021.",
        "DOI": "10.1109/ISAECT53699.2021.9668429",
        "affiliation_name": "Faculté des Sciences Ben M’Sick",
        "affiliation_city": "Casablanca",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Forecasting short-term tourism demand with a decomposition-ensemble strategy",
        "paper_author": "Feng Y.",
        "publication": "Procedia Computer Science",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Tourism demand forecasting has very important reference value for all stakeholders including government policy makers, scenic area managers and tourists. However, most of the current researches only focus on the medium and long-term tourism demand forecasting, and pay less attention to the short-term demand fluctuations. Considering that short-term tourism demand usually has the characteristics of high volatility, nonlinearity, and unstability, this paper introduces the decomposition-ensemble strategy and the classic machine learning algorithm at the same time, and proposes the SSA-SVR model to predict the daily passenger flow volume data of the Mt. Siguniang Scenic Area, a desired result has been achieved.",
        "DOI": "10.1016/j.procs.2022.01.110",
        "affiliation_name": "Institutes of Science and Development",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Stochastic Optimal Control via Hilbert Space Embeddings of Distributions",
        "paper_author": "Thorpe A.J.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Kernel embeddings of distributions have recently gained significant attention in the machine learning community as a data-driven technique for representing probability distributions. Broadly, these techniques enable efficient computation of expectations by representing integral operators as elements in a reproducing kernel Hilbert space. We apply these techniques to the area of stochastic optimal control theory and present a method to compute approximately optimal policies for stochastic systems with arbitrary disturbances. Our approach reduces the optimization problem to a linear program, which can easily be solved via the Lagrangian dual, without resorting to gradient-based optimization algorithms. We focus on discrete-time dynamic programming, and demonstrate our proposed approach on a linear regulation problem, and on a nonlinear target tracking problem. This approach is broadly applicable to a wide variety of optimal control problems, and provides a means of working with stochastic systems in a data-driven setting.",
        "DOI": "10.1109/CDC45484.2021.9682801",
        "affiliation_name": "University of New Mexico School of Engineering",
        "affiliation_city": "Albuquerque",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Using Machine Learning to Analyze and Predict the Relations Between Cardiovascular Disease Incidence, Extreme Temperature and Air Pollution",
        "paper_author": "Lin Y.C.",
        "publication": "3rd IEEE Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability, ECBIOS 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Due to climate change, there have been many studies on the relationship between environmental factors and diseases in recent years. Due to the characteristics of multivariable, nonlinear, sequential, continuous, and delayed effects of meteorological data, we used the Long Short-Term Memory (LSTM) model of machine learning and the dataset from National Health Insurance Research Database (NHIRD) to establish a model predicting the trend of cardiovascular disease (CVD) incidence from 2009 to 2013. The best mean absolute percentage error (MAPE) was 10.98%. This predictive model helps medical institutions make appropriate medical decisions about human resource management and material scheduling, benefit clinical health education, disease prevention, as well as provide suggestions for epidemiology, environmental health, and national health policies.",
        "DOI": "10.1109/ECBIOS51820.2021.9510479",
        "affiliation_name": "Tunghai University",
        "affiliation_city": "Taichung",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Vision-based Learning: A Novel Machine Learning Method based on Convolutional Neural Networks and Spiking Neural Networks",
        "paper_author": "Azimirad V.",
        "publication": "9th RSI International Conference on Robotics and Mechatronics, ICRoM 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "The aim of this study is to autonomously control a Non-holonomic Mobile Robot using novel learning-based control approaches. A Spiking Neural Network (SNN) is modeled and developed to perform the decision making in the robot. A camera captures pictures from the environment and transfers them to the Convolutional Neural Network (CNN) to extract the image features. The extracted features are subsequently given to a Multi Layer Perceptron (MLP) neural network to perform the task of image classification. The results of the object recognition carried out by the image classifier unit are then given to the SNN for decision making and extracting the optimal policy based on the current states of the environment where the agent resides. The extracted policy is given to the agent to perform an action. The result of the action either results in a positive outcome or a negative outcome. The feedback of the policy execution (outcome) is given to the SNN as reward or punishment to optimize the policy extraction.",
        "DOI": "10.1109/ICRoM54204.2021.9663521",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Houghton",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Data Driven Control of Interacting Two Tank Hybrid System using Deep Reinforcement Learning",
        "paper_author": "Jones D.M.",
        "publication": "2021 IEEE 6th International Conference on Computing, Communication and Automation, ICCCA 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "This paper investigates the use of a Deep Neural Network based Reinforcement Learning(RL) algorithm applied to a non-linear system for the design of a controller. It aims to augment the large amounts of data that we possess along with the already known dynamics of the non-linear hybrid tank system for effective control of the liquid level. Control systems represent a non-linear optimization problem, and Machine Learning helps to achieve non-linear optimization using large amounts of data. This document demonstrates the use of Deep Deterministic Policy Gradient (DDPG), an off-policy based actor-critic methodology of reinforcement learning, which is efficient in solving problems where states and actions lie in continuous spaces instead of discrete spaces. The test bench on which RL is being applied is a Multi-Input Multi-Output (MIMO) system called the Interacting Two Tank Hybrid System, with the aim of controlling the liquid levels in the two tanks. In Deep Reinforcement Learning, we are implementing the policy of the agent by means of deep neural networks. The idea behind using the neural network architectures for reinforcement learning is that we want reward signals obtained to strengthen the connection that leads to a good policy. Moreover, these deep neural networks are unique in their ability to represent complex functions if we give them ample amounts of data.",
        "DOI": "10.1109/ICCCA52192.2021.9666405",
        "affiliation_name": "National Institute of Technology Calicut",
        "affiliation_city": "Kozhikode",
        "affiliation_country": "India"
    },
    {
        "paper_title": "FaaSRank: Learning to Schedule Functions in Serverless Platforms",
        "paper_author": "Yu H.",
        "publication": "Proceedings - 2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems, ACSOS 2021",
        "citied_by": "33",
        "cover_date": "2021-01-01",
        "Abstract": "Current serverless Function-as-a-Service (FaaS) platforms generally use simple, classic scheduling algorithms for distributing function invocations while ignoring FaaS characteristics such as rapid changes in resource utilization and the freeze-thaw life cycle. In this paper, we present FaaSRank, a function scheduler for serverless FaaS platforms based on information monitored from servers and functions. FaaSRank automatically learns scheduling policies through experience using reinforcement learning (RL) and neural networks supported by our novel Score-Rank-Select architecture. We implemented FaaSRank in Apache OpenWhisk, an open source FaaS platform, and evaluated performance against other baseline schedulers including OpenWhisk's default scheduler on two 13-node OpenWhisk clusters. For training and evaluation, we adapted real-world serverless workload traces provided by Microsoft Azure. For the duration of test workloads, FaaSRank sustained on average a lower number of inflight invocations 59.62 % and 70.43 % as measured on two clusters respectively. We also demonstrate the generalizability of FaaSRank for any workload. When trained using a composite of 50 episodes each for 10 distinct random workloads, FaaSRank reduced average function completion time by 23.05% compared to OpenWhisk's default scheduler.",
        "DOI": "10.1109/ACSOS52086.2021.00023",
        "affiliation_name": "University of Washington",
        "affiliation_city": "Charlotte Hill",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Intelligent Method of Predicting the Discount Rate Trend",
        "paper_author": "Koziuk V.",
        "publication": "Proceedings of the 11th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications, IDAACS 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The predictability of National Bank of Ukraine (NBU) monetary policy is an important point to gain credibility as an inflation targeter. Basing on the theoretical and empirical literature the direct tool-expert expectations about up-coming interest rates decision - was chosen as approach on quantitative assessment of NBU's predictability. It is found that generally economic agents do not make a systematic mistake in interest rates expectations. But, predictability is an imperfect that is normal for emerging market countries. Some asymmetries in predictability across interest rates cycle is found. However, economic uncertainty is taken in similar way between experts and policy-makers meaning that transparency policy is generally effective. An intelligent method for predicting the discount rate trend has been developed, based on machine learning methods: ARIMA, LSTM and Prophet. Conducted RMSE Errors, trend: bond rate - ARIMA = 8.15, LSTM =6.39 and Prophet =4.15; expert assessment of the bond rate - ARIMA =8.18, LSTM =7.01 and Prophet = 5.99.",
        "DOI": "10.1109/IDAACS53288.2021.9660835",
        "affiliation_name": "West Ukrainian National University",
        "affiliation_city": "Ternopil",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "Machine Learning-Based Automated Tool to Detect Sinhala Hate Speech in Images",
        "paper_author": "Silva E.",
        "publication": "Proceedings of 6th International Conference on Information Technology Research: Digital Resilience and Reinvention, ICITR 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Social media platforms have emerged rapidly with technological advancements. Facebook, the most widely used social media platform has been the primary reason for the spread of hatred in Sri Lanka in the recent past. When a post with Sinhala hate content is reported on Facebook, it is translated to the English language before the review of the moderators. In most instances, the translated content has a different context compared to the original post. This results in concluding that the reported post does not violate the established policies and guidelines concerning hate content. Hence, an effective approach needs to be in place to address the aforementioned problem. This research project proposes a solution through an automated tool that is capable of detecting hate content presented in Sinhala phrases extracted from Facebook posts/memes. The tool accepts an image that contains Sinhala texts, extracts the text using a Convolutional Neural Network (CNN) model, preprocesses the text using Natural Language Processing (NLP) techniques, analyzes the preprocessed text to identify hate intensity level and finally classifies the text into four main domains named Political, Race, Religion and Gender using a text classification model.",
        "DOI": "10.1109/ICITR54349.2021.9657453",
        "affiliation_name": "University of Moratuwa",
        "affiliation_city": "Moratuwa",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Artificial Intelligence Applications to Solve Solar Power Problems",
        "paper_author": "Zatsarinnaya Y.",
        "publication": "Proceedings - ICOECS 2021: 2021 International Conference on Electrotechnical Complexes and Systems",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The large-scale introduction of renewable energy sources throughout the world continues to grow and becomes more and more economically attractive. This makes the energy of the Sun a demanded energy resource not only for use in the construction of plants, but also in households. However, the use of solar energy is associated with great difficulties in predicting the generation of electricity due to its dependence on meteorological conditions, and there is an acute issue of forecasting the generation of solar power plants into the existing grid. One approach to solving this complex problem is the use of machine learning algorithms. With a correctly selected training model, such algorithms are capable of predicting the amount of electricity generation for the day ahead with high accuracy (up to 95%). In this article, the authors propose a solution to the urgent problem of predicting energy generation from solar power plants using machine learning systems.",
        "DOI": "10.1109/ICOECS52783.2021.9657328",
        "affiliation_name": "Kazan National Research Technological University",
        "affiliation_city": "Kazan",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "A Meta Reinforcement Learning-based Approach for Self-Adaptive System",
        "paper_author": "Zhang M.",
        "publication": "Proceedings - 2021 IEEE International Conference on Autonomic Computing and Self-Organizing Systems, ACSOS 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "A self-learning adaptive system (SLAS) uses machine learning to enable and enhance its adaptability. Such systems are expected to perform well in dynamic environments. For learning high-performance adaptation policy, some assumptions must be made on the environment-system dynamics when information about the real situation is incomplete. However, these assumptions cannot be expected to be always correct, and yet it is difficult to enumerate all possible assumptions. This leads to the problem of incomplete-information learning. We consider this problem as multiple model problem in terms of finding the adaptation policy that can cope with multiple models of environment-system dynamics. This paper proposes a novel approach to engineering the online adaptation of SLAS. It separates three concerns that are related to the adaptation policy and presents the modeling and synthesis process, with the goal of achieving higher model construction efficiency. In addition, it designs a meta-reinforcement learning algorithm for learning the meta policy over the multiple models, so that the meta policy can quickly adapt to the real environment-system dynamics. At last, it reports the case study on a robotic system to evaluate the adaptability of the approach.",
        "DOI": "10.1109/ACSOS52086.2021.00024",
        "affiliation_name": "Waseda University",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Forecasting and Analysis of Train Delays and Impact of Weather Data using Machine Learning",
        "paper_author": "Sajan G.V.",
        "publication": "2021 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021",
        "citied_by": "21",
        "cover_date": "2021-01-01",
        "Abstract": "The Railway transit is one of the dominant means of transport all over the world. But people who use the railway transport system are usually affected by the train being delayed from it's usual schedule. This study focuses on forecasting the train delay in India from the available historical data. India has the fourth largest railway network in the world, conveying in excess of eight billion travelers each year. Nonetheless, the passengers usually experience inconvenience because almost all the time, the trains do not run as per the scheduled time. The delay stems from various factors like severe weather conditions, seasonal requirements, railway policies, technical issues, delays accumulated from preceding trains, etc and this imposes considerable costs on railways as well as the travelers. Due to this reason, people are forced to look for an alternate option to travel. Therefore, forecasting delays of trains play an important role in the railway transit. It could help attract more people as they could plan their journey accordingly and it could also help the authority to minimize future delays. An effective supervised machine learning regression algorithm could be useful for estimating train delays and obtaining accurate results. Our main contribution in this paper is the study of the impact of weather on the train running status. As we progress, the various factors of weather like temperature, rainfall, wind, etc are incorporated and analyzed in detail. So in this paper, the main focus is identifying a regression algorithm that can accurately predict train delays by considering the weather conditions as well. We have used 6 different regression models (ridge, lasso, elastic-net, SVR, Gradient Boosting, and XGB Regression) and we have also tried to calibrate the hyperparameters of each regression algorithms to get the most accurate results.",
        "DOI": "10.1109/ICCCNT51525.2021.9580176",
        "affiliation_name": "Amrita School of Engineering, Coimbatore",
        "affiliation_city": "Coimbatore",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Network Flow Generation Based on Reinforcement Learning Powered Generative Adversarial Network",
        "paper_author": "Li J.",
        "publication": "Proceedings of 2021 7th IEEE International Conference on Network Intelligence and Digital Content, IC-NIDC 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Mining anomalies and special events from massive network flows based on machine learning and deep learning is a promising approach for network management. However, it is difficult to build labeled network flow data sets for training machine learning and deep learning models. In this paper, we propose a novel reinforcement learning (RL) powered generative adversarial network (GAN) model named NF-GAN for network flow generation. The generator of NF-GAN is designed as a stochastic policy model to generate labeled network flow data. In terms of the discriminator, a check reward is integrated into the network reward to capture the correlations among attributes. Experiment results demonstrate that the majority of the generated flows conform to the strict network protocols of the standard OSI stack, and the success rate of network flows generation achieves 99.96%. To the best of our knowledge, this is the first time of applying RL powered GAN on network flow generation tasks.",
        "DOI": "10.1109/IC-NIDC54101.2021.9660491",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Automated Reinforcement Learning Based on Parameter Sharing Network Architecture Search",
        "paper_author": "Wang Z.",
        "publication": "2021 6th International Conference on Robotics and Automation Engineering, ICRAE 2021",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "The performance of machine learning depends on the choice of hyperparameters to a great extent. Only by choosing the appropriate hyperparameters can we learn the desired learning results. At present, the end-to-end learning algorithm is widely concerned in the academic circles, and realizes the agile design from the demand end to the execution end at the design task level, which can dramatically reduce the complexity of the design. However, there are still a large number of hyperparameters, which need to be tuned manually, increasing the difficulty of machine learning application. Thus, with the continuous development of high-performance parallel computing, automated machine learning method arises. In this paper, aiming at the automatic design of the hyperparameter, the neural network architecture of deep reinforcement learning in the field of motion control, LSTM recurrent neural network topology generation algorithm, parameter sharing based fast reinforcement learning and evaluation mechanism, and graph generator parameter learning algorithm based on policy gradient are combined. An automated search and optimization framework of neural network architecture in the deep reinforcement learning is proposed, realizing the automated generation of network architecture. Finally, the effectiveness of the proposed approach is verified by taking the lunar lander landing control problem as an example.",
        "DOI": "10.1109/ICRAE53653.2021.9657793",
        "affiliation_name": "Beijing Aerospace Automatic Control Institute",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Ethical Artificial Intelligence in the European Union Context: Visualization for Policymaking and Decision Processes",
        "paper_author": "Ljubenkov D.",
        "publication": "14th CMI International Conference - Critical ICT Infrastructures and Platforms, CMI 2021 - Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Based on its success with the standardized Global System for Mobile Communications (GSM) telephony in the 1990s and the General Data Protection Regulation (GDPR) in the 2010s, the European Union (EU) is putting a lot of effort in regulating Artificial Intelligence (AI) and its widespread usage. A term of ethical AI has emerged, and numerous national, European and global guidelines have recently been published, in the hope of creating a unified framework set to be used and implemented across EU and the globe. However, a highly convoluted nature of legislative procedures regarding emerging technologies makes it increasingly complicated to map out ethical AI properties and guidelines. Hence, a holistic and data-driven approach towards AI policy-making is proposed. In order to help EU policymakers and lawmakers, ethical AI principles of explainability and autonomy will be contextualized and visualized. Data contextualization is achieved using secondary datasets based on the systematic literature review, while data visualization is implemented in a form of a compact digital dashboard, using Python programming language and its associated visualization libraries. Goal of the suggested comprehensive solution is to simplify and streamline future decision processes regarding AI topics exclusively from policymakers' perspective. This will indeed shape Europe's digital future and foster trustworthy strategic leadership regarding AI technologies, which is likely to make EU lead by example and become a globally adopted practice.",
        "DOI": "10.1109/CMI53512.2021.9663855",
        "affiliation_name": "Aalborg University",
        "affiliation_city": "Aalborg",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Non-Intrusive Load Monitoring for High Power Consuming Appliances using Neural Networks",
        "paper_author": "Wickramarachchi W.A.T.",
        "publication": "ICECIE 2021 - 2021 International Conference on Electrical, Control and Instrumentation Engineering, Conference Proceedings",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "The topic of Energy Conservation requires urgent attention worldwide to avoid the impending energy crisis and reduce the impact on the environment through emissions. A crucial step in energy conservation is to motivate individual consumers to reduce their consumption. Itemized energy consumption feedback on each appliance helps users to plan their consumption patterns in an optimum way. Non-intrusive load monitoring is a low-cost and low-maintenance method for identifying consumptions of individual devices from the aggregate data of the mains supply. However, high power-consuming devices with power patterns with varying states are generally difficult to identify, despite them making a huge impact on the overall consumption of a household. Research shows that machine learning techniques are a promising approach for this disaggregation process. This paper focuses on developing data preprocessing methods and neural network algorithms to accurately disaggregate four common household appliances including ones with multistate power patterns.",
        "DOI": "10.1109/ICECIE52348.2021.9664681",
        "affiliation_name": "University of Moratuwa",
        "affiliation_city": "Moratuwa",
        "affiliation_country": "Sri Lanka"
    },
    {
        "paper_title": "Improving multi-goal and target-driven reinforcement learning with supervised auxiliary task",
        "paper_author": "Horita L.R.T.",
        "publication": "2021 20th International Conference on Advanced Robotics, ICAR 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Recent works on Deep Reinforcement Learning (DRL) for episodic multi-goal learning have been using the Universal Value Function Approximation (UVFA) idea to learn a universal policy by taking information from the current and goal states as input. Even though they present good results, there is one aspect that might need more attention: the State Representation Learning (SRL) concept. In machine learning, SRL is not a new subject, and there are many works on it, but it is still not very explored for multi-goal learning. Instead, an end-to-end DRL is commonly adopted to learn state representation implicitly. In simple problems, this approach might be enough, but to others, it can make it harder to learn an optimal policy or lead to overfitting. In light of this, we hypothesize that an auxiliary task closely related to the target policy learning can lead to better results by conditioning the SRL, which is essential to encode the latent state space. Also, motivated by the multi-task learning idea, we propose a framework for simultaneous supervised and reinforcement learning to avoid catastrophic forgetting. Taking the visual-based navigation on a topological urban environment as an instance of the multi-goal learning problem, we use semantic segmentation as the auxiliary task. Based on experimental results, we show that our method accelerates the DRL convergence and allows reaching better policies with higher generalization levels.",
        "DOI": "10.1109/ICAR53236.2021.9659467",
        "affiliation_name": "Universidade de São Paulo",
        "affiliation_city": "Sao Paulo",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "HHFER: A Hybrid Framework for Human Facial Expression Recognition",
        "paper_author": "Tomar A.",
        "publication": "2021 International Conference on Data Analytics for Business and Industry, ICDABI 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Automatic recognition of human facial expressions from images or videos is considered one of the most important tasks in computer vision (CV). Some universal challenges such as dynamic illumination, different face shapes, low-resolution samples, pose variations limit the performance of facial feature recognition by conventional methods. Given these challenges, the research community has paid more attention to deep learning (DL) for automatic and accurate emotion classification. This study addresses a hybrid human facial emotion recognition (HHFER) framework, which works on a DL face-sensitive based feature extraction policy. The proposed framework extracts facial features using a CNN network and classifies them into dedicated emotions through an SVM classifier. The model has been trained on two benchmark RAF-DB and FER2013 datasets with different characteristics for seven emotion categories, for which it achieves an accuracy of 92.80%, 90.85%. Traditional testing and real-time sentiment testing on live videos prove the robustness and scalability of the proposed framework.",
        "DOI": "10.1109/ICDABI53623.2021.9655808",
        "affiliation_name": "Graphic Era Deemed to be University",
        "affiliation_city": "Dehradun",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Training Spaces Fostering machine sensibility for spatial assemblages through wave function collapse and reinforcement learning",
        "paper_author": "Mintrone A.",
        "publication": "Proceedings of the International Conference on Education and Research in Computer Aided Architectural Design in Europe",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "This research explores the integration of Deep Reinforcement Learning (RL) and a Wave Function Collapse (WFC) algorithm for a goal-driven, open-ended generation of architectural spaces. Our approach binds RL to a distributed network of decisions, unfolding through three key steps: the definition of a set of architectural components (tiles) and their connectivity rules, the selection of the tile placement location, which is determined by the WFC, and the choice of which tile to place, which is performed by RL. The act of thinking becomes granular and embedded in an iterative process, distributed among human and non-human cognitions, which constantly negotiate their agency and authorial status. Tools become active agents capable of developing their own sensibility while controlling specific spatial conditions. Establishing an interdependency with the human, that engenders the design patterns and becomes an indispensable prerequisite for the exploration of the generated design space, exceeding human or machinic reach alone.",
        "DOI": "NA",
        "affiliation_name": "Alma Mater Studiorum Università di Bologna",
        "affiliation_city": "Bologna",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "Predicting family physicians based on their practice using machine learning",
        "paper_author": "Garg A.",
        "publication": "Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Significant research has been done in the medical domain using machine learning and clinical data sets. Although there are many interesting and influential clinical research works in the fields of healthcare and health services using machine learning, there is a need to apply machine learning in the field of health human resource planning. This study uses physician billing data and machine learning to identify and classify family physicians with the goal of improving health human resource planning. This research is essential for policy makers because it is important to know the number of family physicians practicing in certain geographical regions for providing timely care. Additionally, this issue becomes particularly important when it comes to serving communities with fewer resources such as the rural areas of Northwestern Ontario, where family physicians need to work to their full scope of practice, provide more services than physicians working in urban areas, to meet the needs of patients. In this study, recursive feature elimination method is used to reduce the number of predictors for the classification problems. As the result of this process, the most important features include physician's rurality, full-time equivalent hours, age, and years of experience. Further, several machine learning models are used to solve binary and multi-class classification problems. Gradient boosting machine learning was the most accurate in predicting family physician practice, with a receiver operating characteristic value, ROC value, of 0.73 and 0.72 for binary and multi-class classification, respectively.",
        "DOI": "10.1109/BigData52589.2021.9671738",
        "affiliation_name": "Lakehead University",
        "affiliation_city": "Thunder Bay",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "DESIGN OF AN AFFORDABLE PROSTHETIC ARM EQUIPPED WITH DEEP LEARNING VISION-BASED MANIPULATION",
        "paper_author": "Imran A.",
        "publication": "ASME International Mechanical Engineering Congress and Exposition, Proceedings (IMECE)",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Many amputees throughout the world are left with limited options to personally own a prosthetic arm due to the expensive cost, mechanical system complexity, and lack of availability. The three main control methods of prosthetic hands are: (1) bodypowered control, (2) extrinsic mechanical control, and (3) myoelectric control. These methods can perform well under a controlled situation but will often break down in clinical and everyday use due to poor robustness, weak adaptability, longterm training, and heavy mental burden during use. This paper lays the complete outline of the design process of an affordable and easily accessible novel prosthetic arm that reduces the cost of prosthetics from $10,000 to $700 on average. The 3D printed prosthetic arm is equipped with a depth camera and closed-loop off-policy deep learning algorithm to help form grasps to the object in view. Current work in reinforcement learning masters only individual skills and is heavily focused on parallel jaw grippers for in-hand manipulation. In order to create generalization which better performs real-world manipulation, the focus is specifically on using the general framework of Markov Decision Process (MDP) through scalable learning with off-policy algorithms such as deep deterministic policy gradient (DDPG) and to study this question in the context of grasping a prosthetic arm. We were able to achieve a 78% grasp success rate on previously unseen objects and generalize across multiple objects for manipulation tasks.",
        "DOI": "10.1115/IMECE2021-68714",
        "affiliation_name": "San Jose State University",
        "affiliation_city": "San Jose",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Exploiting Learned Policies in Focal Search",
        "paper_author": "Araneda P.",
        "publication": "14th International Symposium on Combinatorial Search, SoCS 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Recent machine-learning approaches to deterministic search and domain-independent planning employ policy learning to speed up search. Unfortunately, when attempting to solve a search problem by successively applying a policy, no guarantees can be given on solution quality. The problem of how to effectively use a learned policy within a bounded-suboptimal search algorithm remains largely as an open question. In this paper, we propose various ways in which such policies can be integrated into Focal Search, assuming that the policy is a neural network classifier. Furthermore, we provide mathematical foundations for some of the resulting algorithms. To evaluate the resulting algorithms over a number of policies with varying accuracy, we use synthetic policies which can be generated for a target accuracy for problems where the search space can be held in memory. We evaluate our focal search variants over three benchmark domains using our synthetic approach, and on the 15-puzzle using a neural network learned using 1.5 million examples. We observe that Discrepancy Focal Search, which we show expands the node which maximizes an approximation of the probability that its corresponding path is a prefix of an optimal path, obtains, in general, the best results in terms of runtime and solution quality.",
        "DOI": "NA",
        "affiliation_name": "Instituto Milenio Fundamentos de los Datos",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile"
    },
    {
        "paper_title": "Exploiting Learned Policies and Learned Heuristics in Bounded-Suboptimal Search",
        "paper_author": "Greco M.",
        "publication": "14th International Symposium on Combinatorial Search, SoCS 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Machine Learning (ML) has made significant progress to perform different tasks, such as image classification, speech recognition, and natural language processing, mainly driven by deep learning. Also, ML algorithms, through learning policies or heuristics estimates, have demonstrated potential for solving deterministic problems that would usually be solved using search techniques. Nevertheless, in solving a search problem with purely learning techniques, it is not possible to deliver guarantees regarding the quality of the solution. This research explores how a learned policy or heuristic can be integrated with a bounded-suboptimal search algorithm using Focal Search, sorting the FOCAL list using the concept of discrepancies to speed up the search. On the experimental side, we train a simple neural network as a learned policy and the DeepCubeA as a learned heuristic for the 15-puzzle domain. The results show that a learned policy or heuristic can reduce, at least, one order of magnitude, the expansions than WA* with the same bound and deliver better solution quality.",
        "DOI": "10.1609/socs.v12i1.18589",
        "affiliation_name": "Pontificia Universidad Católica de Chile",
        "affiliation_city": "Santiago",
        "affiliation_country": "Chile"
    },
    {
        "paper_title": "END-TO-END LEARNING FOR OFF-ROAD, DEFORMABLE TERRAIN NAVIGATION USING THE CHRONO OPEN-SOURCE SIMULATION PLATFORM",
        "paper_author": "Benatti S.",
        "publication": "Proceedings of the 20th International and 9th Americas Conference of the International Society for Terrain-Vehicle Systems, ISTVS 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "This contribution (i) describes an open source, physics-based simulation infrastructure that can be used to learn and test control policies in off-road navigation; and (ii) demonstrates the use of the simulation platform in an endto- end learning exercise that relies on simulated sensor data fusion (camera, GPS, and IMU). For (i), the 0.5 million lines of open source code support vehicle dynamics (wheeled/tracked vehicles, rovers), deformable & non-deformable terrains, and virtual sensing. The library has a Python API for interfacing with existing Machine Learning frameworks. For (ii), we use a Gator off-road vehicle to demonstrate how a policy learned on non-deformable terrain performs when used in hilly conditions while navigating around a course of randomly placed obstacles on deformable terrain. The hilly terrain covers an 80 × 80m patch and the soil can be controlled by the user to assume various behavior, e.g., non-deformable, deformable hard (siltlike), deformable soft (snow-like), etc. To the best of our knowledge, there is no other open source, physics-based engine that can be used to simulate off-road mobility of autonomous agents operating on deformable terrains. The results reported herein can be reproduced with models and data available in a public repository [1]. Animations associated with the tests run are available online [2].",
        "DOI": "NA",
        "affiliation_name": "UW-Madison College of Engineering",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine learning for causal inference: Estimating heterogeneous treatment effects",
        "paper_author": "Shah V.",
        "publication": "Handbook of Research Methods and Applications in Empirical Microeconomics",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "This chapter presents some of the recent developments in the machine learning literature for estimating heterogeneous treatment effects. The focus is on the variation in treatment effects for population subgroups based on their observed characteristics. Three algorithms, the X-learner, the R-learner, and causal forests are presented and illustrated using an empirical case study of a policy impact evaluation of a national health insurance programme in Indonesia.",
        "DOI": "NA",
        "affiliation_name": "University of York",
        "affiliation_city": "York",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Application of Artificial Neural Network (ANN) and Support Vector Machine (SVM) for Government Policy Recommendations to Allow People to Do Activities Without Masks",
        "paper_author": "Cross Sihombing D.J.",
        "publication": "Proceedings - 2021 IEEE 5th International Conference on Information Technology, Information Systems and Electrical Engineering: Applying Data Science and Artificial Intelligence Technologies for Global Challenges During Pandemic Era, ICITISEE 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The Covid-19 pandemic that has hit the world, including Indonesia, has affected various aspects of life. This has also led to various new policies by the Indonesian government to limit the spread of Covid-19, one of which is the use of masks while on the move. This study aims to apply machine learning to government policy recommendations in allowing people to move without masks. The method used in this research is SVM (Support Vector Machine) for classification and ANN (Artificial Neural Network) for forecasting. The results of this study are MSE (Mean Squared Error) of 4.62 and MAE (Mean Absolute Error) of 0.97, and this study predicts the Covid-19 pandemic will decrease in February 2022 but will tend to rise again in March 2022. Next, in April 2022, cases will decrease. Based on the study results, the implementation of the policy can be carried out in April 2022 regarding community activities without masks.",
        "DOI": "10.1109/ICITISEE53823.2021.9655965",
        "affiliation_name": "Universitas Katolik Indonesia Atma Jaya",
        "affiliation_city": "Jakarta",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Proceedings of WORKS 2021: 16th Workshop on Workflows in Support of Large-Scale Science, Held in conjunction with SC 2021: The International Conference for High Performance Computing, Networking, Storage and Analysis",
        "paper_author": "NA",
        "publication": "Proceedings of WORKS 2021: 16th Workshop on Workflows in Support of Large-Scale Science, Held in conjunction with SC 2021: The International Conference for High Performance Computing, Networking, Storage and Analysis",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 11 papers. The topics discussed include: a recommender system for scientific datasets and analysis pipelines; intelligent resource provisioning for scientific workflows and HPC; not all tasks are created equal: adaptive resource allocation for heterogeneous tasks in dynamic workflows; dynamic heterogeneous task specification and execution for in situ workflows; an adaptive elasticity policy for staging based in-situ processing; the benefits of prefetching for large-scale cloud-based neuroimaging analysis workflows; a performance characterization of scientific machine learning workflows; science capsule: towards sharing and reproducibility of scientific workflows; and emerging frameworks for advancing scientific workflows research, development, and education.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Integrating support vector machine and cellular automata for modelling land cover change in the tropical rainforest under equatorial climate in Ghana",
        "paper_author": "Nyamekye C.",
        "publication": "Current Research in Environmental Sustainability",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Unsustainable anthropogenic activities such as indiscriminate logging of trees, mineral exploitation, conversion of forest into agricultural lands are known to cause major environmental changes, thereby triggering a chain of irreversible forest depletion. This has called an urgent need by government and private agencies to institute policies and programs to curtail the destruction of the ecosystem due to the pressure on the available land. In this study, the Land use/land cover changes between the period of 1986 and 2020 in the tropical rainforest of Ghana was considered. A combination of machine learning and Markov chain approach was adopted to project future LULC for 2040 and 2060.The results showed that area covered by Open Forest declined from 21,531.87 km2 to 14,518.82 km2 and Dense Forest also declined from 14,313 km2 to 8202.98 km2 over a period of 34 years. The CA-Markov model was used to predict the future land use land cover, and it was observed that the total forest cover could decline to 15,551.79 km2 in 2040 and further decrease to 13,401.79 km2 in 2060. It was also found that settlement, mining and agricultural land, which is be driven by rapid population increase, has contributed significantly to the rapid declining forest cover. The results of this study have demonstrated the impact of unsustainable use of natural resources in these three regions. It also highlights the need for concerted effort to develop comprehensive environmental policies to encapsulate sustainable conversion and utilisation of natural resources by focusing on water-energy-food nexus.",
        "DOI": "10.1016/j.crsust.2021.100052",
        "affiliation_name": "Koforidua Technical University",
        "affiliation_city": "Koforidua",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Real-Time COVID-19 Infection Risk Assessment and Mitigation based on Public-Domain Data",
        "paper_author": "Cheng A.M.K.",
        "publication": "Proceedings of UrgentHPC 2021: 3rd International Workshop on HPC for Urgent Decision Making, Held in conjunction with SC 2021: The International Conference for High Performance Computing, Networking, Storage and Analysis",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "A number of models have been developed to predict the spreads of the COVID-19 pandemic and how non-pharmaceutical interventions (NPIs) such as social distancing, facial coverings, and business and school closures can contain this pandemic. Evolutionary artificial intelligence (AI) approaches have recently been proposed to automatically determine the most effective interventions by generating a large number of candidate strategies customized for different countries and locales and evaluating them with predictive models. These epidemiological models and advanced AI techniques assist policy makers by providing them with strategies in balancing the need to contain the pandemic and the need to minimize their economic impact as well as educating the general public about ways to reduce the chance of infection. However, they do not advise an individual citizen at a specific moment and location on taking the best course of actions to accomplish a task such as grocery shopping while minimizing infection.Therefore, this paper describes a new project aiming to develop a mobile-phone-deployable, real-time COVID-19 infection risk assessment and mitigation (RT-CIRAM) system which analyzes up-to-date data from multiple open sources leveraging urgent HPC/cloud computing, coupled with time-critical scheduling and routing techniques. Implementation of a RT-CIRAM prototype is underway, and it will be made available to the public. Facing the increasing spread of the more contagious Delta (B.1.617.2) and Delta Plus (AY.4.2) variants, this personal system will be especially useful for individual citizen to reduce her/his infection risk despite increasing vaccination rates while contributing to containing the spread of the current and future pandemics.",
        "DOI": "10.1109/UrgentHPC54802.2021.00009",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Houston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Educational Artificial Intelligence (EAI) Connotation, Key Technology and Application Trend-Interpretation and analysis of the two reports entitled 'Preparing for the Future of Artificial Intelligence' and 'The National Artificial Intelligence Research and Development Strategic Plan'",
        "paper_author": "Ganga X.",
        "publication": "Proceedings - 2021 International Conference on Intelligent Computing, Automation and Applications, ICAA 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "In order to further the application,research and development of artificial intelligence (AI), The Office of Science and Technology Policy of the White House released two reports commissioned 'Preparation for the Future of Artificial Intelligence' and 'The National Artificial Intelligence Research and Development Strategic Plan' in October 2016. According to the reports, AI has been playing a growing role in every area of society, among which education is an important one. Educational artistic intelligence (EAI) is a new field which combinations AI with learning science. Current, the key technologies of EAI are knowledge representation, machine learning, deep learning, natural language processing, intelligent agent, affective computing, etc. The development of EAI in education focuses on the intelligent tutor and assistant, intelligent evaluation, learning partner, data mining, learning analysis, etc.On this account, there is a urgent need to strengthen the training of the workforce of EAI at all levels, in accordance with the rapid development of AI.",
        "DOI": "10.1109/ICAA53760.2021.00046",
        "affiliation_name": "Nanchang Institute of Technology",
        "affiliation_city": "Nanchang",
        "affiliation_country": "China"
    },
    {
        "paper_title": "NavTuner: Learning a Scene-Sensitive Family of Navigation Policies",
        "paper_author": "Ma H.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The advent of deep learning has inspired research into end-to-end learning for a variety of problem domains in robotics. For navigation, the resulting methods may not have the generalization properties desired let alone match the performance of traditional methods. Instead of learning a navigation policy, we explore learning an adaptive policy in the parameter space of an existing navigation module. Having adaptive parameters provides the navigation module with a family of policies that can be dynamically reconfigured based on the local scene structure and addresses the common assertion in machine learning that engineered solutions are inflexible. Of the methods tested, reinforcement learning (RL) is shown to provide a significant performance boost to a modern navigation method through reduced sensitivity of its success rate to environmental clutter. The outcomes indicate that RL as a meta-policy learner, or dynamic parameter tuner, effectively robustifies algorithms sensitive to external, measurable nuisance factors.",
        "DOI": "10.1109/IROS51168.2021.9636185",
        "affiliation_name": "College of Computing",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Design and Experimental Learning of Swimming Gaits for a Magnetic, Modular, Undulatory Robot",
        "paper_author": "Deng H.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Here we developed an experimental platform with a magnetic, modular, undulatory robot (μBot) for studying fish-inspired underwater locomotion. This platform will enable us to systematically explore the relationship between body morphology, swimming gaits, and swimming performance via reinforcement learning methods. The μBot was designed to be easily modifiable in morphology, compact in size, easy to be controlled and inexpensive. The experimental platform also included a towing tank and a motion tracking system for real-time measurement of the μBot kinematics. The swimming gaits of μBot were generated by a central pattern generator (CPG), which outputs voltage signals to μBot's magnetic actuators. The CPG parameters were learned experimentally using the parameter exploring policy gradient (PGPE) method to maximize swimming speed. In the experiments, two μBot designs with the same body morphology but different caudal-fin shapes were tested. Results showed that swimming gaits with back-propagating traveling waves can be learned experimentally via PGPE, while the shape of the caudal fins had moderate influences on the learned gaits and the swimming speed. Furthermore, robot swimming speed was sensitive to the undulating frequency and the voltage magnitude of the last three posterior actuators. In contrast, swimming gaits and speed were relatively invariant to the variances within the inter-module connection weights of CPG and the voltage applied to the anterior actuator.",
        "DOI": "10.1109/IROS51168.2021.9636100",
        "affiliation_name": "Penn State College of Engineering",
        "affiliation_city": "University Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Hierarchical Framework for Quadruped Locomotion Based on Reinforcement Learning",
        "paper_author": "Tan W.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "17",
        "cover_date": "2021-01-01",
        "Abstract": "Quadruped locomotion is a challenging task for learning-based algorithms. It requires tedious manual tuning and is difficult to deploy in reality due to the reality gap. In this paper, we propose a quadruped robot learning system for agile locomotion which does not require any pre-training and works well in various real-world terrains. We introduce a hierarchical learning framework that uses reinforcement learning as the high-level policy to adjust the low-level trajectory generator for better adaptability to the terrain. We compact the observation and action space of the reinforcement learning to deploy it on a host computer in reality. Besides, we design a trajectory generator guided by robot posture, which can generate adaptive foot trajectory to interact with the environment. Experimental results show that our system can be easily deployed in reality while only trained in simulation, and also has the advantages of fast convergence and good terrain adaptability. The supplementary video demonstration is available at https://vsislab.github.io/hfql/.",
        "DOI": "10.1109/IROS51168.2021.9636757",
        "affiliation_name": "Tencent",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Exploration of Public Emotion Dynamics in Japan from Twitter Data during COVID-19",
        "paper_author": "Bashar M.K.",
        "publication": "ICIIBMS 2021 - 6th International Conference on Intelligent Informatics and Biomedical Sciences",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The COVID-19 has affected human lives in many ways throughout the globe. Several recent studies indicated that it has greatly impacted people's income. Many people have become jobless and many business entities have already closed especially in the travelling, tourism, entertainment, and restaurant sectors. Anecdotal evidences suggest that the pandemic has severely affected mental health issues. However, systematic studies for tracking public worries towards health and economy due COVID-19, regarded as hWorry and eWorry, over time are still lacking. In this study, several supervised machine learning models have been applied to a collection of public tweets to explore the mentioned worries. Experimental analysis with a set of 4072 tweets spanning six-month from January 2020 to June 2020 have discriminated tweets into hWorry and eWorry classes with 61% accuracy. By applying a lexicon-based approach to the classified tweets, our approach reveals how the four selected emotions, i.e., fear, anger, sadness, and trust propagated over time. While the fear and trust emotions showed dominant temporal patterns in both classes, the average anger and sadness emotions were stronger in the e Worry class as compared to those in the h Worry class suggesting the necessity of more viable economic policies to overcome corona calamity.",
        "DOI": "10.1109/ICIIBMS52876.2021.9651600",
        "affiliation_name": "The Tokyo Foundation for Policy Research",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Research on Diagnostic Test and Treatment for Higher Education System",
        "paper_author": "Yang Y.",
        "publication": "2021 IEEE 3rd International Conference on Frontiers Technology of Information and Computer, ICFTIC 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This paper proposes a method to build machine learning models based on data analysis, which aims at providing strategies to evaluate the health and sustainability of the higher education system and the improvement measures correspondingly. Initially, the Key Performance Indicators (KPIs) method is used to judge the performance and operation status of the national higher education system. Factor Analysis is used to test collinearity and reduce dimension of these indicators, and the main indexes in BACKGROUND, INPUT, PROCESS, OUTPUT and utilization rate are screened out. Data Envelopment Analysis (DEA) is used to establish a higher education evaluation system suitable for countries and regions, and the scores of Germany's higher education system are calculated in five dimensions respectively. Secondly, by using Markov Chain Model for prediction, the periodic changing rule of German educational reform is gained. Combined with the knowledge of management policy, the time arrangement of the specific implementation of policies is obtained. Due to the advantages of DEA in evaluating the relative effectiveness of multi-input and multi-output systems, an improved GP-DEA model is constructed, based on C2R of DEA method and a target programming model is built, to quantify the effectiveness Finally, a sensitivity analysis is done, illustrating that this model has high efficiency and only has a small impact on its performance if the model hypothesis has a small deviation.",
        "DOI": "10.1109/ICFTIC54370.2021.9647318",
        "affiliation_name": "The University of Arizona",
        "affiliation_city": "Tucson",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reinforcement Learning Control of a Forestry Crane Manipulator",
        "paper_author": "Andersson J.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "19",
        "cover_date": "2021-01-01",
        "Abstract": "Forestry machines are heavy vehicles performing complex manipulation tasks in unstructured production forest environments. Together with the complex dynamics of the onboard hydraulically actuated cranes, the rough forest terrains have posed a particular challenge in forestry automation. In this study, the feasibility of applying reinforcement learning control to forestry crane manipulators is investigated in a simulated environment. Our results show that it is possible to learn successful actuator-space control policies for energy efficient log grasping by invoking a simple curriculum in a deep reinforcement learning setup. Given the pose of the selected logs, our best control policy reaches a grasping success rate of 97%. Including an energy-optimization goal in the reward function, the energy consumption is significantly reduced compared to control policies learned without incentive for energy optimization, while the increase in cycle time is marginal. The energy-optimization effects can be observed in the overall smoother motion and acceleration profiles during crane manipulation.",
        "DOI": "10.1109/IROS51168.2021.9636219",
        "affiliation_name": "Umeå Universitet",
        "affiliation_city": "Umea",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Risk Averse Bayesian Reward Learning for Autonomous Navigation from Human Demonstration",
        "paper_author": "Ellis C.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Traditional imitation learning provides a set of methods and algorithms to learn a reward function or policy from expert demonstrations. Learning from demonstration has been shown to be advantageous for navigation tasks as it allows for machine learning non-experts to quickly provide information needed to learn complex traversal behaviors. However, a minimal set of demonstrations is unlikely to capture all relevant information needed to achieve the desired behavior in every possible future operational environment. Due to distributional shift among environments, a robot may encounter features that were rarely or never observed during training for which the appropriate reward value is uncertain, leading to undesired outcomes. This paper proposes a Bayesian technique which quantifies uncertainty over the weights of a linear reward function given a dataset of minimal human demonstrations to operate safely in dynamic environments. This uncertainty is quantified and incorporated into a risk averse set of weights used to generate cost maps for planning. Experiments in a 3-D environment with a simulated robot show that our proposed algorithm enables a robot to avoid dangerous terrain completely in two out of three test scenarios and accumulates a lower amount of risk than related approaches in all scenarios without requiring any additional demonstrations.",
        "DOI": "10.1109/IROS51168.2021.9635835",
        "affiliation_name": "College of Engineering at UMass Dartmouth",
        "affiliation_city": "Dartmouth",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Learning to Design and Construct Bridge without Blueprint",
        "paper_author": "Li Y.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Autonomous assembly has been a desired functionality of many intelligent robot systems. We study a new challenging assembly task, designing and constructing a bridge without a blueprint. In this task, the robot needs to first design a feasible bridge architecture for arbitrarily wide cliffs and then manipulate the blocks reliably to construct a stable bridge according to the proposed design. In this paper, we propose a bi-level approach to tackle this task. At the high level, the system learns a bridge blueprint policy in a physical simulator using deep reinforcement learning and curriculum learning. A policy is represented as an attention-based neural network with object-centric input, which enables generalization to different number of blocks and cliff widths. For low-level control, we implement a motion-planning-based policy for real-robot motion control, which can be directly combined with a trained blueprint policy for real-world bridge construction without tuning. In our field study, our bi-level robot system demonstrates the capability of manipulating blocks to construct a diverse set of bridges with different architectures.",
        "DOI": "10.1109/IROS51168.2021.9636280",
        "affiliation_name": "ByteDance Ltd.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Comparison of Deep Reinforcement Learning Algorithms in Data Center Cooling Management: A Case Study",
        "paper_author": "Hua T.",
        "publication": "Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The growth in scale and power density of Data Centers (DC) poses serious challenges to the cooling management. Recently, there are many studies using machine learning to solve the cooling management problems. However, a comprehensive comparative study is still missing. In this work, we compare the performance of various Deep Reinforcement Learning (DRL) algorithms, including Deep-Q Networks (DQN), Deep Deterministic Policy Gradient (DDPG), and Branching Dueling Q-Network (BDQ), using the Active Ventilation Tiles (AVTs) control problem in raised-floor DC as an example. In particular, we design two multiagent algorithms based on DQN and three critic architectures for DDPG. Simulations based on real world workload show that DDPG provides the best performance over the considered algorithms.",
        "DOI": "10.1109/SMC52423.2021.9659100",
        "affiliation_name": "Xi'an Jiaotong-Liverpool University",
        "affiliation_city": "Suzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "SOLO: Search Online, Learn Offline for Combinatorial Optimization Problems",
        "paper_author": "Oren J.",
        "publication": "14th International Symposium on Combinatorial Search, SoCS 2021",
        "citied_by": "18",
        "cover_date": "2021-01-01",
        "Abstract": "We study combinatorial problems with real world applications such as machine scheduling, routing, and assignment. We propose a method that combines Reinforcement Learning (RL) and planning. This method can equally be applied to both the offline, as well as online, variants of the combinatorial problem, in which the problem components (e.g., jobs in scheduling problems) are not known in advance, but rather arrive during the decision-making process. Our solution is quite generic, scalable, and leverages distributional knowledge of the problem parameters. We frame the solution process as an MDP, and take a Deep Q-Learning approach wherein states are represented as graphs, thereby allowing our trained policies to deal with arbitrary changes in a principled manner. Though learned policies work well in expectation, small deviations can have substantial negative effects in combinatorial settings. We mitigate these drawbacks by employing our graph-convolutional policies as non-optimal heuristics in a compatible search algorithm, Monte Carlo Tree Search, to significantly improve overall performance. We demonstrate our method on two problems: Machine Scheduling and Capacitated Vehicle Routing. We show that our method outperforms custom-tailored mathematical solvers, state of the art learning-based algorithms, and common heuristics, both in computation time and performance.",
        "DOI": "NA",
        "affiliation_name": "Technion - Israel Institute of Technology",
        "affiliation_city": "Haifa",
        "affiliation_country": "Israel"
    },
    {
        "paper_title": "SoccerKicks: A Dataset of 3D dead ball kicks reference movements for humanoid robots",
        "paper_author": "Lessa N.M.",
        "publication": "Conference Proceedings - IEEE International Conference on Systems, Man and Cybernetics",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The possibility of robots imitating reference movements performed by experts recently emerged in the Machine Learning context. Based on Deep Reinforcement Learning (DRL), this process focuses on observing a reference movement policy and its adaptation to a robot with a similar body scheme. In the humanoid robots domain, the massive availability of videos on the internet holds the potential to provide reference movements for virtually any task performed by humans. However, 3D pose estimation algorithms based on videos are currently subject to failure due to several practical situations (poor image framing, low video quality, joints occlusions and mismatch, and so on) and typically require applying a complex methodology. This paper presents SoccerKicks, a new dataset that provides 3D reference movements of humans performing dead ball kicks (penalty and foul) obtained from reference videos suitable for use in the robotics soccer domain. In this work we describe: i) the methodology adopted for the videos selection; ii) the algorithms chosen to perform the 2D and 3D pose estimation based on the videos; iii) the evaluation of the algorithms performance; iv) the annotation on these videos and the reference movements provided. Our dataset is publicly available at https://github.com/larocs/SoccerKicks.",
        "DOI": "10.1109/SMC52423.2021.9658787",
        "affiliation_name": "Universidade Estadual de Campinas",
        "affiliation_city": "Campinas",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "When is Particle Filtering Efficient for Planning in Partially Observed Linear Dynamical Systems?",
        "paper_author": "Du S.S.",
        "publication": "37th Conference on Uncertainty in Artificial Intelligence, UAI 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Particle filtering is a popular method for inferring latent states in stochastic dynamical systems, whose theoretical properties have been well studied in machine learning and statistics communities. In many control problems, e.g., partially observed linear dynamical systems (POLDS), oftentimes the inferred latent state is further used for planning at each step. This paper initiates a rigorous study on the efficiency of particle filtering for sequential planning, and gives the first particle complexity bounds. Though errors in past actions may affect the future, we are able to bound the number of particles needed so that the long-run reward of the policy based on particle filtering is close to that based on exact inference. In particular, we show that, in stable systems, polynomially many particles suffice. Key in our proof is a coupling of the ideal sequence based on the exact planning and the sequence generated by approximate planning based on particle filtering. We believe this technique can be useful in other sequential decision-making problems.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Model-free Deep Reinforcement Learning Approach for Robotic Manipulators Path Planning",
        "paper_author": "Liu W.",
        "publication": "International Conference on Control, Automation and Systems",
        "citied_by": "9",
        "cover_date": "2021-01-01",
        "Abstract": "Path planning problems have attracted much attention in robotic fields such as manipulators. In this paper, a model-free off-policy actor critic based deep reinforcement learning method is proposed to solve the classical path planning problem of a UR5 robot arm. Unlike standard path planning methods, the reward design of the proposed method contains smoothness reward, which assures smooth trajectory of the UR5 robot arm when accomplishing path planning tasks. Additionally, the proposed method does not rely on any model while the standard path planning method is model-based. The proposed method not only guarantees that the joint angle of the UR5 robotic arm lies within the allowable range each time when it reaches the random target point, but also ensures that the joint angle of the UR5 robotic arm is always within the allowable range during the entire episode of training. A standard path planning method was implemented in Robot Operating System (ROS) and the proposed method was applied in CoppeliaSim to validate the feasibility. It can be inferred from the experiment that the training with the proposed method is successful.",
        "DOI": "10.23919/ICCAS52745.2021.9649802",
        "affiliation_name": "The University of Manchester",
        "affiliation_city": "Manchester",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "WIRE: Resource-efficient Scaling with Online Prediction for DAG-based Workflows",
        "paper_author": "Xie B.",
        "publication": "Proceedings - IEEE International Conference on Cluster Computing, ICCC",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "This paper introduces WIRE that manages resources for the DAG-based workflows on IaaS clouds. WIRE predicts and plans resources over the MAPE (Monitor-AnalyzePlan-Execute) loops to: 1) Estimate task performance with online data, 2) Conduct simulations to predict the upcoming loads based on online estimates and workflow DAGs, 3) Apply a resource-steering policy to size cloud instance pools for the maximal parallelism that is consistent with low cost. We implement WIRE on Pegasus WMS/HTCondor and evaluate its performance on the ExoGENI network cloud. The results show that WIRE attains low resource cost with the performance that is typically within a factor of two of optimal.",
        "DOI": "10.1109/Cluster48925.2021.00025",
        "affiliation_name": "Qatar Computing Research Institute",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar"
    },
    {
        "paper_title": "Deep Reinforcement Learning based Planning for Urban Self-driving with Demonstration and Depth Completion",
        "paper_author": "Wang C.",
        "publication": "International Conference on Control, Automation and Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Research shows major interests in urban self-driving in recent years, both perception and motion planning considered to be significant topics. Current techniques of decision making for driving policy are modular and hand designed, which is expensive and inefficient. With the development of machine learning, learning-based approaches have become a mainstream research direction. However, the performance in urban driving scenarios is far from satisfaction due to the brittle convergence property of deep reinforcement learning and debased observation. To solve these problems, this paper proposed a learning-based method with deep reinforcement learning (DRL) and imitation learning (IL), and additionally a novel depth completion model for better perception. Our framework is built upon Soft Actor-Critic algorithm and introducing an update method that value function, Q-function and policy network all learn from the expert data. To tackle the observation problem, we proposed a reconstruction restraint deep fusion depth completion network which can predict the integrated and precise depth map of the environment with our own novel pre-processed datasets. In experiment, our autonomous driving agent transfer smooth from IL to DRL in training, and outperformed state-of-art methods in urban challenging scenes and still competing compared to our model with groundtruth input.",
        "DOI": "10.23919/ICCAS52745.2021.9650055",
        "affiliation_name": "City, University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "You Are What You Eat: Predictive Model of Eating Habits and Health Outcomes",
        "paper_author": "Chi X.",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Overweight/obesity and associated chronic disease have become a major global challenge for overall well-beings. This research adopts a large-scale purchase data set (including foods’ corresponding energy and nutrition) of 420 million pieces collected from 1.6 million users of 411 Tesco supermarkets in London [7, 8], and the health data published by the local government of the same area (including child overweight and obesity [9], and adult diabetes [10]). Spearman correlation is used to identify the linear relationship between supermarket purchase data and health outcomes. Linear regression model is further utilized to explore the relationship between food consumption (total energy and fat energy, saturated fat energy, sugar energy, protein energy, carbohydrate energy, fiber energy, energy density and nutrition diversity) and first grade children (5–6 years old) overweight and obesity, sixth grade children (10–11 years old) overweight and obesity, and estimated adult diabetes prevalence. Finally, the research uses machine learning models to predict the health outcome. The research results show that the food consumption data is related to children overweight and obesity and adult diabetes with statistics significance. Machines learning models can efficiently predict the incidence of children overweight and obesity and adult diabetes. Random forest model performed the best regarding first grade children overweight and obesity with an accuracy score of 0.73, and adult diabetes with an accuracy rate of 0.86. Logistics regression and gradient boosting model performed the best predicting sixth grade children overweight and obesity with an accuracy score of 0.89. The research conducted in this paper is beneficial for the government to inquire citizens’ health conditions through the new data source of big supermarkets. Also, the government could promote or discourage the consumption of some food through issuing related policy to improve citizens’ health conditions. Food companies could also develop new products that are beneficial for people’s health based on the information discovered within the research, leading to a lower rate of chronic diseases such as diabetes among citizens.",
        "DOI": "10.1007/978-981-16-8885-0_21",
        "affiliation_name": "Shanghai Pinghe School",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Reward Machines for Vision-Based Robotic Manipulation",
        "paper_author": "Camacho A.",
        "publication": "Proceedings - IEEE International Conference on Robotics and Automation",
        "citied_by": "17",
        "cover_date": "2021-01-01",
        "Abstract": "Deep Q learning (DQN) has enabled robot agents to accomplish vision based tasks that seemed out of reach. Despite recent success stories, there are still several sources of computational complexity that challenge the performance of DQN. We place the focus on vision manipulation tasks, where the correct action selection is often predicated on a small number of pixels. We observe that in some of these tasks DQN does not converge to the optimal Q function, and their values do not separate well optimal and suboptimal actions. In consequence, the policies obtained with DQN tend to be brittle and manifest a low success rate, especially in long horizon tasks. In this work we show the benefits of Reward Machines (RMs) for Deep Q learning (DQRM) in vision based robot manipulation tasks. Reward machines decompose the task at an abstract level, inform the agent about their current stage along task completion, and guide them via dense rewards. We show that RMs help DQN learn the optimal Q values in each abstract state. Their policies are more robust, manifest higher success rate, and are learned with fewer training steps compared with DQN. The benefits of RMs are more evident in long-horizon tasks, where we show that DQRM is able to learn good-quality policies with six times times fewer training steps than DQN, even when this is equipped with dense reward shaping.",
        "DOI": "10.1109/ICRA48506.2021.9561927",
        "affiliation_name": "Google LLC",
        "affiliation_city": "Mountain View",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Detecting DDoS Attacks on SDN Data Plane with Machine Learning",
        "paper_author": "Carvalho R.N.",
        "publication": "Proceedings - 2021 9th International Symposium on Computing and Networking Workshops, CANDARW 2021",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "Distributed denial of service (DDoS) attacks challenge software-defined networks (SDN), primarily due to vulnerabilities present in the separation between the control and data planes. The control plane maintains continuous communication with the data plane switches to direct traffic according to forwarding policies. Although the literature presents various solutions to detect DDoS attacks, most of them concentrate on the control plane. The controller facilitates automated network management, making it easier to integrate and administer applications. On the other hand, the development of security solutions on the control plane imposes an additional load on the controller's duties. As an alternative to this problem, the research community proposed security solutions adapted to work on the data plane. However, due to the complexity of acting in this layer, the proposed solutions are restricted to statistical analysis of the network flow. This work proposes DataPlane-ML, a machine learning (ML) solution that acts on the data plane to detect DDoS attacks. To realize the use of ML techniques at the data plane, DataPlane-ML makes use of white box switches enhanced with P4 constructs to handle input flow and ML libraries to run ML models. This strategy allows the use of ML techniques on the data plane to provide more elaborated solutions that operate close to the input flow, reducing the impact on the SDN controller. The proposed DataPlane-ML was evaluated using the KNN, SVM and RF algorithms to detect DDoS attacks on real network traces. The experimental results show that DataPlane-ML is ≈23% faster than statistical-based solutions while providing better accuracy and similar CPU usage.",
        "DOI": "10.1109/CANDARW53999.2021.00030",
        "affiliation_name": "Universidade de Brasília",
        "affiliation_city": "Brasilia",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "Robust Feedback Motion Policy Design Using Reinforcement Learning on a 3D Digit Bipedal Robot",
        "paper_author": "Castillo G.A.",
        "publication": "IEEE International Conference on Intelligent Robots and Systems",
        "citied_by": "47",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, a hierarchical and robust framework for learning bipedal locomotion is presented and successfully implemented on the 3D biped robot Digit built by Agility Robotics. We propose a cascade-structure controller that combines the learning process with intuitive feedback regulations. This design allows the framework to realize robust and stable walking with a reduced-dimensional state and action spaces of the policy, significantly simplifying the design and increasing the sampling efficiency of the learning method. The inclusion of feedback regulation into the framework improves the robustness of the learned walking gait and ensures the success of the sim-to-real transfer of the proposed controller with minimal tuning. We specifically present a learning pipeline that considers hardware-feasible initial poses of the robot within the learning process to ensure the initial state of the learning is replicated as close as possible to the initial state of the robot in hardware experiments. Finally, we demonstrate the feasibility of our method by successfully transferring the learned policy in simulation to the Digit robot hardware, realizing sustained walking gaits under external force disturbances and challenging terrains not incurred during the training process. To the best of our knowledge, this is the first time a learning-based policy is transferred successfully to the Digit robot in hardware experiments.",
        "DOI": "10.1109/IROS51168.2021.9636467",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Columbus",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application development for music recommendation system using deep deterministic policy gradient",
        "paper_author": "Kamble R.S.",
        "publication": "20th International Conferences on WWW/Internet 2021 and Applied Computing 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Recommendation Systems works as an information filtering system which helps to feed and recommend content personalized for the taste of the user. From the use in e-commerce to generic advertisement, recommender systems are proven to be highly effective and go-to solution for personalized content promotion. This project aims to develop and design a Machine Learning model which can be integrated into an Android application to help recommend music for the app user. For this purpose, a Deep Deterministic Policy Gradient model was used along with an underlying architecture for designing the android application which contains playlist of the user's songs and considering the likes and dislikes from the user, the app with the help of the ML model helps suggest user an additional array of songs.",
        "DOI": "NA",
        "affiliation_name": "Birla Institute of Technology and Science, Pilani – Dubai Campus",
        "affiliation_city": "Dubai",
        "affiliation_country": "United Arab Emirates"
    },
    {
        "paper_title": "Towards Change Detection in Privacy Policies with Natural Language Processing",
        "paper_author": "Adhikari A.",
        "publication": "2021 18th International Conference on Privacy, Security and Trust, PST 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Privacy policies notify users about the privacy practices of websites, mobile apps, and other products and services. However, users rarely read them and struggle to understand their contents. Due to the complicated nature of these documents, it gets even harder to understand and take note of any changes of interest or concern when the policies are changed or revised. With advances in machine learning and natural language processing, tools that can automatically annotate sentences of policies have been developed. These annotations can help a user identify and understand relevant parts of a privacy policy. In this paper, we present our attempt to further such annotations by also detecting the important changes that occurred across sentences. Using supervised machine learning models, word-embedding, similarity matching, and structural analysis of sentences, we present a process that takes two different versions of a privacy policy as input, matches the sentences of one version to another based on semantic similarity, and identifies relevant changes between two matched sentences. We present the results and insights of applying our approach on 79 privacy policies manually downloaded from Facebook, WhatsApp, Twitter, Google, LinkedIn and Snapchat, ranging between the period of 1999 to 2020.",
        "DOI": "10.1109/PST52912.2021.9647767",
        "affiliation_name": "Daniel Felix Ritchie School of Engineering &amp; Computer Science",
        "affiliation_city": "Denver",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "20th International Conferences on WWW/Internet 2021 and Applied Computing 2021",
        "paper_author": "NA",
        "publication": "20th International Conferences on WWW/Internet 2021 and Applied Computing 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 33 papers. The topics discussed include: assessing the inconsistency in online news; DIALOGBOOK2: an improvement of e-portfolio system for international communication learning; cost reduction estimation method of a software vulnerability management tool; optimizing the performance of telecommunication bulk export using a machine learning closed loop system based on historic performance; application development for music recommendation system using deep deterministic policy gradient; in other words: a naive approach to text spinning; and evaluation of named entity recognition for the German e-commerce domain.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "MetaREVEAL: RL-based Meta-learning from Learning Curves",
        "paper_author": "Nguyen M.H.",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This paper addresses a cornerstone of Automated Machine Learning: the problem of rapidly uncovering which machine learning algorithm performs best on a new dataset. Our approach leverages performances of such algorithms on datasets to which they have been previously exposed, i.e., implementing a form of meta-learning. More specifically, the problem is cast as a REVEAL Reinforcement Learning (RL) game: the meta-learning problem is wrapped into a RL environment in which an agent can start, pause, or resume training various machine learning algorithms to progressively “reveal” their learning curves. The learned policy is then applied to quickly uncover the best algorithm on a new dataset. While other similar approaches, such as Freeze-Thaw, were proposed in the past, using Bayesian optimization, our methodology is, to the best of our knowledge, the first that trains a RL agent to do this task on previous datasets. Using real and artificial data, we show that our new RL-based meta-learning paradigm outperforms Free-Thaw and other baseline methods, with respect to the Area under the Learning curve metric, a form of evaluation of Any-time learning (i.e., the capability of interrupting the algorithm at any time while obtaining good performance).",
        "DOI": "NA",
        "affiliation_name": "CentraleSupélec",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France"
    },
    {
        "paper_title": "AÇAI: Ascent Similarity Caching with Approximate Indexes",
        "paper_author": "Salem T.S.",
        "publication": "2021 33rd International Teletraffic Congress, ITC 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Similarity search is a key operation in multimedia retrieval systems and recommender systems, and it will play an important role also for future machine learning and augmented reality applications. When these systems need to serve large objects with tight delay constraints, edge servers close to the end-user can operate as similarity caches to speed up the retrieval. In this paper we present AÇAI, a new similarity caching policy which improves on the state of the art by using (i) an (approximate) index for the whole catalog to decide which objects to serve locally and which to retrieve from the remote server, and (ii) a mirror ascent algorithm to update the set of local objects with strong guarantees even when the request process does not exhibit any statistical regularity.",
        "DOI": "NA",
        "affiliation_name": "Université Côte d'Azur",
        "affiliation_city": "Nice",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Proceedings of the 30th International Conference of the International Association for Management of Technology, IAMOT 2021 - MOT for the World of the Future",
        "paper_author": "NA",
        "publication": "Proceedings of the 30th International Conference of the International Association for Management of Technology, IAMOT 2021 - MOT for the World of the Future",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 116 papers. The topics discussed include: world of the future … the new world order post COVID-19; antecedents and mediating role of digital transformation in improving firm performance; a text classification analysis of technology and innovation management publications using supervised machine learning; developing a note-taking and note-making system for Sepedi language; a bibliometric approach to support redefining management of technology for the post-digital world; developing the renewable energy sector in South Africa; the use of local content requirements to support photovoltaic module manufacture; and text mining for clustering the national digital transformation policies: positioning turkey’s digital roadmap.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "A new supervision model of environmental accounting information disclosure based on machine learning theory",
        "paper_author": "Zeng M.",
        "publication": "Proceedings - 2021 International Conference on E-Commerce and E-Management, ICECEM 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "With the frequent occurrence of environmental problems, the state has introduced a series of policies and measures to strengthen the supervision of listed companies, but at the same time, there is also a 'marginal ball' phenomenon: for example, enterprises disclose environmental accounting information data is incomplete, in an attempt to escape government control. With machine learning theory to assist government regulation, the level of environmental accounting information disclosure can be improved to a greater extent, and a new regulatory model of 'government +' can be formed.",
        "DOI": "10.1109/ICECEM54757.2021.00120",
        "affiliation_name": "Lanzhou University of Technology",
        "affiliation_city": "Lanzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Heterogeneous Flow Scheduling using Deep Reinforcement Learning in Partially Observable NFV Environment",
        "paper_author": "Lin C.J.",
        "publication": "Proceedings - 2021 International Conference on Networking and Network Applications, NaNA 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Deep Reinforcement Learning (DRL) has yielded proficient controllers for complex tasks. DRL trains machine learning models for decision making to maximize rewards in uncertain environments such as network function virtualization (NFV). However, when facing limited information, agents often have difficulties making decisions at some decision point. In a real-world NFV environment, we may have incomplete information about network flow patterns. Compared with complete information feedback, it increases the difficulty to predict an optimal policy since important state information is missing. In this paper, we formulate a Partially Observable Markov Decision Process (POMDP) with a partially unknown NFV system. To address the shortcomings in real-world NFV, we conduct an extensive simulation to investigate the effects of adding recurrency to a Proximal Policy optimization (PPO2) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM or adding stacked frames as input. The results show that RL based schedulers using stacking a history of frames in the PPO2's input layer can easily adapt at evaluation time if the quality of observations changes.",
        "DOI": "10.1109/NaNA53684.2021.00081",
        "affiliation_name": "Francis College of Engineering",
        "affiliation_city": "Lowell",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Mixed-Method Design Approach for Empirically Based Selection of Unbiased Data Annotators",
        "paper_author": "Thakur G.",
        "publication": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Implicit bias embedded in the annotated data is by far the greatest impediment in the effectual use of supervised machine learning models in tasks involving race, ethics, and geopolitical polarization. For societal good and demonstrable positive impact on wider society, it is paramount to carefully select data annotators and rigorously validate the annotation process. Current approaches to selecting annotators are not sufficiently grounded in scientific principles and are limited at the policy-guidance level, thereby rendering them unusable for machine learning practitioners. This work proposes a new approach based on the mixed-methods design that is functional, adaptable, and simpler to implement in selecting unbiased annotators for any machine learning problem. By demonstrating it on a real-world geopolitical problem, we also identified and ranked key inane profile characteristics towards an empirically-based selection of unbiased data annotators.",
        "DOI": "NA",
        "affiliation_name": "Oak Ridge National Laboratory",
        "affiliation_city": "Oak Ridge",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "AI-enabled Predictive Maintenance of Wind Generators",
        "paper_author": "Mammadov E.",
        "publication": "Proceedings of 2021 IEEE PES Innovative Smart Grid Technologies Europe: Smart Grids: Toward a Carbon-Free Future, ISGT Europe 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Recent policies have led to the development and deployment of renewable energy sources, introducing new operational challenges. Among those, is the problem of extended downtime of RES, such as wind turbines. In this context, it is important to minimize the downtime of renewable assets by an optimal maintenance strategy via early fault detection. As a Supervisory Control and Data Acquisition (SCADA) system is an integrated part of any production facility and collects large amounts of data, machine learning techniques can be used to detect the underlying failure patterns and notify customers of the abnormal behaviour. Thus, in this work, a novel framework based on machine learning algorithms for fault prediction of wind farm generators is presented for an actual customer. The proposed fault prognosis methodology is tested and validated using historical data from a wind farm in Summerside, Prince Edward Island, Canada, and models are evaluated based on appropriate metrics. The results demonstrate the ability of the proposed methodology to predict wind generator failures with a precision as high as 83%, and the viability of the proposed methodology for optimizing predictive maintenance strategies.",
        "DOI": "10.1109/ISGTEurope52324.2021.9640162",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Data openness for efficient e-governance in the age of big data",
        "paper_author": "Alaoui S.S.",
        "publication": "International Journal of Cloud Computing",
        "citied_by": "30",
        "cover_date": "2021-01-01",
        "Abstract": "The data revolution in recent years has led governments around the world to realise the different benefits of communicating and opening data over their information and communication technologies (ICTs) in behalf of their citizens. Indeed, the need for data openness is vitally important for governments, research community and businesses, especially in the era of big data, which characterised by the increase in volume of structured and unstructured data, the speed at which data is generated and collected and the variety of data sources; this is known as the three Vs. Therefore, big data has changed the ways governments manage and support their policies towards their digital data and tend to make it more open and accessible. This 'open data' movement has been adopted by several countries thanks to its multiple benefits in different domains to uncover hidden patterns and improve e-governance effectiveness in terms of cost, productivity and innovation. Through using machine learning algorithms, this paper demonstrates that governments applying open policies are the same as those who get a high score in terms of Human Development Index. To fulfil paper's objectives, the powerful statistical tool named 'IBM SPSS Statistics' is used to accomplish the entire analytical process.",
        "DOI": "10.1504/IJCC.2021.120391",
        "affiliation_name": "Université Moulay Ismaïl",
        "affiliation_city": "Meknes",
        "affiliation_country": "Morocco"
    },
    {
        "paper_title": "Geology still matters – Unconventional petroleum system disappointments and failures",
        "paper_author": "Katz B.",
        "publication": "Unconventional Resources",
        "citied_by": "36",
        "cover_date": "2021-01-01",
        "Abstract": "Machine learning and factory drilling approaches have increased efficiency and improved the commerciality in many tight plays. However, not all the original resource estimates and potential opportunities have, been confirmed by the drill-bit. Although some of the commercial disappointments have been a result of policy decisions, more often they are due to partial or complete failure of the unconventional petroleum system and/or the hydrocarbon phase encountered. Studies have demonstrated that not all mudrocks are organic-rich, contain the appropriate kerogen type, have achieved the appropriate level of thermal maturity, have suitable unconventional reservoir properties, are able to retain hydrocarbons, or have the necessary resource density to be a viable tight rock target. An overview of six shale plays in this study (the Longmaxi Shale of China, the Silurian shales of eastern Europe, the Cambay Shale of India, the Barnett Shale in northeast Texas, the Eagle Ford Shale of South Texas, and the Waltman Shale of Wyoming) represent the diversity of potential geologic problems. It becomes apparent that, just as in the case of conventional exploration, successful unconventional exploration and development requires a full assessment of the petroleum system. Absence or limited effectiveness of one or more elements (i.e., source rock presence, quality, and thermal maturity, reservoir presence and quality, and retention) of the petroleum system is a primary driver for mismatch between resource expectations and results.",
        "DOI": "10.1016/j.uncres.2021.12.001",
        "affiliation_name": "Chevron Corporation",
        "affiliation_city": "San Ramon",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Reward Response Game in the Federated Learning System",
        "paper_author": "Jiang S.",
        "publication": "Proceedings - 2021 IEEE 18th International Conference on Mobile Ad Hoc and Smart Systems, MASS 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "The emergence of federated learning and the increasingly powerful mobile devices lead to a mobile-crowd machine learning paradigm. In this paper, we consider a mobile-crowd federated learning system that includes a central server and a set of mobile devices. As the model requester, the server motivates all devices to train an accurate model by paying them based on their individual contributions. Each participating device needs to balance between the training rewards and costs for profit maximization. A Stackelberg game is proposed to model interactions between the server and devices. To match with reality, our model takes the training deadline and the device-side upload time into consideration. Based on different definitions of individual contribution, two reward policies, i.e., the size-based policy and accuracy-based policy, are compared. The existence and uniqueness of Stackelberg equilibrium (SE) under both definitions are analyzed, according to which algorithms are proposed to achieve the corresponding SE(s). We show that there is a lower bound of 0.5 on the price of anarchy in the proposed game. We extend our model by considering the uncertainty in the upload time, where each device's upload time is subject to a normal distribution due to its unstable channel. Numerical evaluations are presented to verify the proposed models.",
        "DOI": "10.1109/MASS52906.2021.00024",
        "affiliation_name": "Department of Computer and Information Sciences",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Gaussian Process based Deep Dyna-Q Approach for Dialogue Policy Learning",
        "paper_author": "Wu G.",
        "publication": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Applying reinforcement learning to dialogue policy learning requires prohibitively large rounds of human-machine interactions. To improve the learning performance, the Deep Dyna-Q framework with a world model that imitates real users is widely used in recent years. Unfortunately, how to build an effective world model and how to evaluate the experiences generated by the world model efficiently have not been well studied. In order to further improve the effectiveness and efficiency of dialogue policy learning, we present a novel Gaussian Process based Deep Dyna-Q approach in this paper. The Gaussian Process model, which is analytically tractable and fits for small-sample problems, is introduced to build the world model. In addition, we design a highly efficient Kullback-Leibler divergence based discriminator to evaluate the quality of experiences generated by the world model. Extensive experiments validate the effectiveness and robustness of our proposed approach. The task-completion success rate can be improved by about 20% with fewer human-machine interactions.",
        "DOI": "NA",
        "affiliation_name": "Shenzhen Institute of Advanced Technology",
        "affiliation_city": "Shenzhen",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Better Chinese Sentence Segmentation with Reinforcement Learning",
        "paper_author": "Srinivasan S.",
        "publication": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "A long-standing challenge in Chinese-English machine translation is that sentence boundaries are ambiguous in Chinese orthography, but inferring good splits is necessary for obtaining high quality translations. To solve this, we use reinforcement learning to train a segmentation policy that splits Chinese texts into segments that can be independently translated so as to maximise the overall translation quality. We compare to a variety of segmentation strategies and find that our approach improves the baseline BLEU score on the WMT2020 Chinese-English news translation task by +0.3 BLEU overall and improves the score on input segments that contain more than 60 words by +3 BLEU.",
        "DOI": "NA",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Classification of Faults in Power System with Probabilistic Neural Networks: An Imbalanced Learning Approach",
        "paper_author": "Mukherjee D.",
        "publication": "IEEE Region 10 Humanitarian Technology Conference, R10-HTC",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Modern day power grids with its inherent operating characteristics are susceptible to faults. Grid operators must detect as well as classify the current system operating conditions like normal or faulty from the current raw sets of measurement data available at supervisory control and data acquisition (SCADA) system. With the rapid deployment of micro PMUs, faults are detected from the raw measurements in real time, but their classification still possess a challenging task. This paper focuses on a diligent comparison between several deep and machine learning techniques for classifying faults in real time. In real life scenarios, line to ground (L-G) faults being the most frequent one while three phase to ground (LLL-G) faults being rare, an imbalanced dataset is generally developed for supervised learning approach leading to biased classification of faults. In order to alleviate this current concern, data oversampling policy over the imbalanced dataset based on synthetic minority oversampling technique (SMOTE) is proposed. The dataset used in this work is derived from the Drexel University's Reconfigurable Distribution Automation and Control (RDAC) software/hardware laboratory.",
        "DOI": "10.1109/R10-HTC53172.2021.9641580",
        "affiliation_name": "National Institute of Technology, Arunachal Pradesh",
        "affiliation_city": "Yupia",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Low-Level Control of a Quadrotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)",
        "paper_author": "Shehab M.",
        "publication": "CCE 2021 - 2021 18th International Conference on Electrical Engineering, Computing Science and Automatic Control",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "Unmanned Aerial Vehicles (UAVs) like Quadrotors are inherently under-Actuated and unstable systems. The mechanical complexity and non-linearity of such systems make it a difficult task to control the flight of the mentioned systems. However, due to recent advancements in the fields of data science and machine learning, new algorithms for flight stabilization and trajectory control were developed using Deep Reinforcement Learning. This paper presents two low-level Quadrotor controllers based on the same algorithm. The first designed controller aims to stabilize the Quadrotor at a certain preset point given any random initial position. The second is to track any target position given in the 3D space. Twin Delayed Deep Deterministic Policy Gradient (TD3) is used to train the agents to achieve the required tasks. This method is an off-policy Actor-Critic based method. It was used as it does not require a system model and works on environments with continuous action and state spaces. The superb performance of the trained policies is demonstrated in a simulation to illustrate the effectiveness of the proposed controllers.",
        "DOI": "10.1109/CCE53527.2021.9633086",
        "affiliation_name": "Faculty of Engineering and Materials Science",
        "affiliation_city": "New Cairo",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Analysis of Mental Health During the Covid-19 Pandemic in Indonesia using Twitter Data",
        "paper_author": "Fatimah N.",
        "publication": "Proceedings - 2021 8th International Conference on Advanced Informatics: Concepts, Theory, and Application, ICAICTA 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Covid-19, which has infected Indonesia, has had a significant impact on Indonesia in various sectors and has a direct psychological impact on the entire community, such as a fear attack, anxiety, stress, and depression. Not being able to meet friends, study and work from home, the existence of the PSBB policy, the large number of news and hoaxes about Covid-19, and worrying about being infected are some of the factors that can cause psychological problems. At this time, social media was helpful to get the latest information, share various content, tell stories, and express opinions or thoughts. This study will conduct a classification and analysis related to mental health during the pandemic using tweets shared by Indonesian users and then compare the algorithms, which are Naïve Bayes, SVM, Logistic Regression, and Random Forest. From the labeling process, 612 tweets indicate psychological problems, and 168 tweets indicate anxiety problems. This study succeeded in building two classification models to detect psychological problems and anxiety problems. Model 1 was built using the Naïve Bayes because Naïve Bayes algorithm has the highest results of all evaluations with 74.36% accuracy, 74.28% precision, 74.35% recall, and 74.30% f1-score. While model 2 was built using SVM algorithm because SVM has the highest score for accuracy with 76.42%, precision with 74.91%, and f1-score with 75.19%.",
        "DOI": "10.1109/ICAICTA53211.2021.9640265",
        "affiliation_name": "Universitas Indonesia",
        "affiliation_city": "Depok",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Application of Artificial Intelligence in Predicting Groundwater Contaminants",
        "paper_author": "Singh S.K.",
        "publication": "Water Pollution and Management Practices",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "This study presents a critical review of the application of artificial intelligence (AI) in developing prediction models of globally concerning groundwater contaminants, including arsenic, fluoride, and nitrate. Groundwater is arsenic-contaminated in 109 countries, fluoride-contaminated in 84, and nitrate-polluted in 60. Cumulatively, these groundwater contaminations adversely impact the lives of more than 300 million of these countries’ inhabitants. Twenty-four countries have problems with all three contaminants. Fifty-nine countries have issues with arsenic and fluoride in their groundwater, and 63 have at least two groundwater-contamination problems. An array of AI techniques, including machine learning (ML) and deep learning (DL), has been applied in developing arsenic-, fluoride-, and nitrate-prediction models, the most frequently used models being logistic regressions and random forests. We recommend developing such prediction models with substantially larger datasets and meaningful, statistically significant predictors. Considering that contamination is highly regional, it is also advisable to develop local prediction models and evaluate at least several robust and relevant algorithms when it comes to final model selection. Hybrid ML-DL models could be especially useful, considering the many-dimensional nature of environmental data. Environmental scientists should also be trained in various AI techniques. AI prediction models can be used as a decision-support system and to create proactive environmental-management policies.",
        "DOI": "10.1007/978-981-15-8358-2_4",
        "affiliation_name": "Duy Tan University",
        "affiliation_city": "Da Nang",
        "affiliation_country": "Viet Nam"
    },
    {
        "paper_title": "Sentiment Analysis of Face-to-face Learning during Covid-19 Pandemic using Twitter Data",
        "paper_author": "Kanugrahan G.",
        "publication": "Proceedings - 2021 8th International Conference on Advanced Informatics: Concepts, Theory, and Application, ICAICTA 2021",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Covid-19 pandemic has massive impacts on the activity of human in the world, including in Indonesia. To reduce the transmission of the virus, Indonesian government issues a policy to restrict daily public activities, affecting key national sectors, such as education systems. All learning activities are switched from the conventional face-to-face mode to being remote via the use of the Internet. After the pandemic begins to subside, the government then plans to reopen all schools and to allow face-to-face learning. However, this decision has sparked controversy in the social media, including Twitter. This paper describes a methodology to perform sentiment analysis on a collection of tweets that are in connection with the restart of the face-to-face learning mode. In particular, our experiments using hand-crafted features based on the tweets demonstrate that data-driven models are useful for automatic sentiment orientation classification on Twitter data. The best model achieved in this study has 69,1% accuracy, 68.6% precision, 69.1% recall, and 67,8% F1-Score. This result is achieved by using unigram, Support Vector Machine, and tweet + number of words (count) feature combinations.",
        "DOI": "10.1109/ICAICTA53211.2021.9640282",
        "affiliation_name": "Universitas Indonesia",
        "affiliation_city": "Depok",
        "affiliation_country": "Indonesia"
    },
    {
        "paper_title": "Smart healthcare systems using big data",
        "paper_author": "Chakraborty C.",
        "publication": "Demystifying Big Data, Machine Learning, and Deep Learning for Healthcare Analytics",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The health sector generates a large amount of medical data related to patient care, patient security, medical data privacy, drugs, and treatment effectiveness. This encourages researchers to pay attention to health analytics to develop effective medical policies and standards. Medical data are big data, so cost-effective intelligent solutions are required for complex health-related problems that further assist doctors or health practitioners in decision making and removing old medical practices that are on the verge of being obsolete. Complete, accurate, correct, and structured data are required to highlight current drawbacks in health practices and to accommodate new policies and procedures to upgrade healthcare services. This chapter explores various studies for the use of big data analytics in health science along with the application of big data tools and techniques in the biomedical sector. Notable rudimentary subdomains in intelligent computing for enhancing health services are big data analytics, bioinformatics, data mining, machine learning, and computer vision. The presented research work may further be utilized by health practitioners or researchers to explore the area of big data analytics in medical science in the direction of disease prediction, drug suggestion, treatment effectiveness, and online health monitoring.",
        "DOI": "10.1016/B978-0-12-821633-0.00009-X",
        "affiliation_name": "Jaypee Institute of Information Technology",
        "affiliation_city": "Noida",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Machine Learning Methods for Local Motion Planning: A Study of End-to-End vs. Parameter Learning",
        "paper_author": "Xu Z.",
        "publication": "2021 IEEE International Symposium on Safety, Security, and Rescue Robotics, SSRR 2021",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "While decades of research efforts have been devoted to developing classical autonomous navigation systems to move robots from one point to another in a collision-free manner, machine learning approaches to navigation have been recently proposed to learn navigation behaviors from data. Two representative paradigms are end-to-end learning (directly from perception to motion) and parameter learning (from perception to parameters used by a classical underlying planner). These two types of methods are believed to have complementary pros and cons: Parameter learning is expected to be robust to different scenarios, have provable guarantees, and exhibit explainable behaviors; end-to-end learning does not require extensive engineering and has the potential to outperform approaches that rely on classical systems. However, these beliefs have not been verified through real-world experiments in a comprehensive way. In this paper, we report on an extensive study to compare end-to-end and parameter learning for local motion planners in a large suite of simulated and physical experiments. In particular, we test the performance of end-to-end motion policies, which directly compute raw motor commands, and parameter policies, which compute parameters to be used by classical planners, with different inputs (e.g., raw sensor data, costmaps), and provide an analysis of the results.",
        "DOI": "10.1109/SSRR53300.2021.9597689",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Austin",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Intrusion Detection and Mitigation Framework for SDN Controlled IoTs Network",
        "paper_author": "Zaheer A.",
        "publication": "HONET 2021 - IEEE 18th International Conference on Smart Communities: Improving Quality of Life using ICT, IoT and AI",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Software Define Networking technology have great potential to mitigate security challenges in Internet of Things network. This paper presents a framework to control intrusion inside the Internet of Things (IoT) network after detecting it with an Intrusion Detection System (IDS). The IDS detects intrusions by examining hosts logs and network traffic. The intrusion detection approaches for proposed frame work are signature based, anomaly based and machine learning based. Proposed frame work takes advantage of Software Define Networking (SDN) controller to enforce new security policies and reconfiguration of firewall and other devices in IoT network to mitigate intrusions.",
        "DOI": "10.1109/HONET53078.2021.9615458",
        "affiliation_name": "Capital University of Science &amp; Technology",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan"
    },
    {
        "paper_title": "A Policy Iteration Approach for Flock Motion Control",
        "paper_author": "Qu S.",
        "publication": "IEEE International Symposium on Robotic and Sensors Environments, ROSE 2021 - Proceedings",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The flocking motion control is concerned with managing the possible conflicts between local and team objectives of multi-agent systems. The overall control process guides the agents while monitoring the flock-cohesiveness and localization. The underlying mechanisms may degrade due to overlooking the unmodeled uncertainties associated with the flock dynamics and formation. On another side, the efficiencies of the various control designs rely on how quickly they can adapt to different dynamic situations in real-time. An online model-free policy iteration mechanism is developed here to guide a flock of agents to follow an independent command generator over a time-varying graph topology. The strength of connectivity between any two agents or the graph edge weight is decided using a position adjacency dependent function. An online recursive least squares approach is adopted to tune the guidance strategies without knowing the dynamics of the agents or those of the command generator. It is compared with another reinforcement learning approach from the literature which is based on a value iteration technique. The simulation results of the policy iteration mechanism revealed fast learning and convergence behaviors with less computational effort.",
        "DOI": "10.1109/ROSE52750.2021.9611776",
        "affiliation_name": "University of Ottawa",
        "affiliation_city": "Ottawa",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Inverse Reinforcement Learning with Natural Language Goals",
        "paper_author": "Zhou L.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "Humans generally use natural language (NL) to communicate task requirements to each other. Ideally, NL should also be usable for communicating goals to autonomous machines (e.g., robots) to minimize friction in task specification. However, understanding and mapping NL goals to sequences of states and actions is challenging. Specifically, existing work along these lines has encountered difficulty in generalizing learned policies to new NL goals and environments. In this paper, we propose a novel adversarial inverse reinforcement learning algorithm to learn a language-conditioned policy and reward function. To improve generalization of the learned policy and reward function, we use a variational goal generator to relabel trajectories and sample diverse goals during training. Our algorithm outperforms multiple baselines by a large margin on a vision-based NL instruction following dataset (Room-2Room), demonstrating a promising advance in enabling the use of NL instructions in specifying agent goals.",
        "DOI": "10.1609/aaai.v35i12.17326",
        "affiliation_name": "Amazon.com, Inc.",
        "affiliation_city": "Seattle",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "ICT-PEP 2021 - International Conference on Technology and Policy in Energy and Electric Power: Emerging Energy Sustainability, Smart Grid, and Microgrid Technologies for Future Power System, Proceedings",
        "paper_author": "NA",
        "publication": "ICT-PEP 2021 - International Conference on Technology and Policy in Energy and Electric Power: Emerging Energy Sustainability, Smart Grid, and Microgrid Technologies for Future Power System, Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 77 papers. The topics discussed include: maximum expansion of a generation based on transmission absorption capability; implementation of voltage control in single-phase full bridge inverter using one-leg plus hysteresis controller; comparative boiler performance, fuel cost and emission characteristic of co-firing palm kernel shell with coal on circulating fluidized bed boiler: an experimental study; influence of battery energy storage system on system stability in isolated power system; predicting the power of a wind turbine with machine learning-based approaches from wind direction and speed data; and coordination and security assessment of distribution feeder with intermittent renewable generation.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Omnidirectional Mobile Robot Path Finding Using Deep Deterministic Policy Gradient for Real Robot Control",
        "paper_author": "Ushida Y.",
        "publication": "2021 IEEE 10th Global Conference on Consumer Electronics, GCCE 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Recently, workers are in short supply in the distribution industry. Therefore, the objective of this study is to develop an autonomous mobile robot that can search for a path to the goal while avoiding static and dynamic obstacles to support workers in a warehouse. In this study, we apply five learning types in a hybrid static and dynamic environment in a simulation environment as a preparation for learning in an actual machine and verify the effectiveness of these learning methods.",
        "DOI": "10.1109/GCCE53005.2021.9621943",
        "affiliation_name": "Nagoya Institute of Technology",
        "affiliation_city": "Nagoya",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Question Answering-based Socio-economic Indicator Extraction",
        "paper_author": "Xu C.",
        "publication": "Proceedings - 2021 7th International Conference on Big Data and Information Analytics, BigDIA 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Socio-economic indicators are important statistical data used to monitor and evaluate the development of economy and society. They are of great value to policy makers of government, organizations and enterprises. Previous methods to measure socio-economic conditions are through data collecting or large-scale surveys by manpower. Over recent years, with the quick development of Internet, a huge amount of online text becomes available and contains clues of socio-economic indicators. As a result, rule-based methods and traditional machine learning methods are emerging to extract indicators more effectively but they require too much prior domain knowledge and feature engineering. Recently, deep learning approaches are dominating in Natural Language Processing (NLP) and formulating NLP tasks as machine reading comprehension (MRC) problems has been proven to be effective. Therefore, we propose a RoBERTa-based model that treats indicator extraction as a question answering (QA) task. By answering questions customized for indicator elements which are the components of the indicator, it transforms extracting indicator elements to identifying and extracting answer spans from the given contexts. Experiments show that it outperforms other deep learning baselines.",
        "DOI": "10.1109/BigDIA53151.2021.9619686",
        "affiliation_name": "National University of Defense Technology China",
        "affiliation_city": "Changsha",
        "affiliation_country": "China"
    },
    {
        "paper_title": "The MIT Supercloud Dataset",
        "paper_author": "Samsi S.",
        "publication": "2021 IEEE High Performance Extreme Computing Conference, HPEC 2021",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial intelligence (AI) and Machine learning (ML) workloads are an increasingly larger share of the compute workloads in traditional High-Performance Computing (HPC) centers and commercial cloud systems. This has led to changes in deployment approaches of HPC clusters and the commercial cloud, as well as a new focus on approaches to optimized resource usage, allocations and deployment of new AI frameworks, and capabilities such as Jupyter notebooks to enable rapid prototyping and deployment. With these changes, there is a need to better understand cluster/datacenter operations with the goal of developing improved scheduling policies, identifying inefficiencies in resource utilization, energy/power consumption, failure prediction, and identifying policy violations. In this paper we introduce the MIT Supercloud Dataset which aims to foster innovative AI/ML approaches to the analysis of large scale HPC and datacenter/cloud operations. We provide detailed monitoring logs from the MIT Supercloud system, which include CPU and GPU usage by jobs, memory usage, file system logs, and physical monitoring data. This paper discusses the details of the dataset, collection methodology, data availability, and discusses potential challenge problems being developed using this data. Datasets and future challenge announcements will be available via https://dcc.mit.edu.",
        "DOI": "10.1109/HPEC49654.2021.9622850",
        "affiliation_name": "Northeastern University",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Agentless Insurance Model Based on Modern Artificial Intelligence",
        "paper_author": "Sinha K.P.",
        "publication": "Proceedings - 2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science, IRI 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Since past couple of years, Agents have been a crucial part of the financial sector, primarily focusing on the Auto Insurance sector, whose key responsibilities are centered around finding new prospective customers and maintaining a relationship with existing customers. But with every other company streamlining their business processes with the latest Technology, Insurance Industry is not too far behind. Currently, Insurance Industry has dived and started exploring the online space. Prospective customers can now get online insurance quotes, chat with an online robot and even purchase an Insurance policy online. Digitalization, Automation, and Streamlining are key buzzwords in every type of business sector. Given the above trends, Insurance Agents seem to be an unnecessary expense. In this paper, we propose an Artificial-Intelligence driven approach that eliminates the need for a human Insurance Agent that will ultimately reduce the overall cost for the end customer. As part of our contribution to the above problem statement, we have proposed a Software Application where four Statistical Models are deployed. These Models are tasked with determining prospective customers who will likely buy an Insurance Policy, identifying customers who are likely to cancel a policy so that we can provide them with something better, identifying customers submitting fraudulent insurance claims and finally a Recommendation System Model to recommend updates to current policy to existing policy of Customers. In our Experimentation Results, we identified a cluster of customers who were most likely to buy a product using an Unsupervised Statistical Machine Learning model.",
        "DOI": "10.1109/IRI51335.2021.00013",
        "affiliation_name": "Illinois State University",
        "affiliation_city": "Chicago",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Building an AI Model on ECG Data for Identifying Burnout/Stressed Healthcare Workers Involved in Covid-19 Management",
        "paper_author": "Mahajan A.",
        "publication": "2021 4th International Conference on Electrical, Computer and Communication Technologies, ICECCT 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "An electrocardiogram (ECG) is used to monitor electrical activity of the heart. ECG data with 12 leads can help in detecting various cardiac (heart) problems. One of the significant factors that contribute to various cardiac diseases is work/personal stress. Use of various machine and deep learning approaches to analyse ECG data has yielded promising results in the field of predictive and diagnostic healthcare with less human error or bias. In our study, 10sec of 500Hz, 12-lead ECG samples were collected from the healthcare workers, who were involved directly or indirectly in taking care of COVID-19 patients. The present study was designed to determine whether Healthcare workers were stressed by using only ECG as input to a deep learning model. To the best of our knowledge, no earlier ECG based study has been carried out to identify stressed persons among the healthcare workers who are giving support to COVID-19 patients. In this study, ECG data of healthcare workers giving services to COVID-19 patients is utilized. This data was collected from four tertiary academic care centres of India. A modified version of AlexNet is utilized on this data that is able to identify a stressed healthcare worker with 99.397% accuracy and 99.411% AUC score. Successful deployment of such systems can help governments and hospital administrations make appropriate policy decisions during pandemics.",
        "DOI": "10.1109/ICECCT52121.2021.9616635",
        "affiliation_name": "Indraprastha Institute of Information Technology, Delhi",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Multi-agent Learning based Anti-jamming Communications Against Cognitive Jammers",
        "paper_author": "Jayaweera M.N.",
        "publication": "2021 30th Wireless and Optical Communications Conference, WOCC 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "This paper proposes a spectrum-agile cognitive radio (CR) which may withstand, or outperform, a sophisticated jammer that adapts to the radio's channel selections. The spectrum co-existence of the CR and the jammer is modeled as a non-cooperative stochastic game and game-theoretic learning is allowed for both to learn effective policies in response to each other's actions. The CR is designed to use Win-or-Learn-Fast Policy Hill Climbing (WoLF-PHC) Reinforcement Learning to make better future channel selection decisions. A cognitive jammer (CJ) that time-interweaves jamming and sensing and uses No-regret Learning (NRL) to zero-in on channels containing signals is also developed. Both protocols were implemented on USRP software-defined radios. Over-the-air (OTA) tests showed that the developed CR performed 68% better than a legacy radio against the cognitive jammer. Similarly, the CJ performed 39% better than a non-learning jammer against the CR.",
        "DOI": "10.1109/WOCC53213.2021.9603201",
        "affiliation_name": "La Cueva H. S.",
        "affiliation_city": "Albuquerque",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Reinforcement Learning for Automated Energy Efficient Mobile Network Performance Tuning",
        "paper_author": "Corcoran D.",
        "publication": "Proceedings of the 2021 17th International Conference on Network and Service Management: Smart Management for Future Networks and Services, CNSM 2021",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Modern mobile networks are increasingly complex from a resource management perspective, with diverse combinations of software, infrastructure elements and services that need to be configured and tuned for correct and efficient operation. It is well accepted in the communications community that appropriately dimensioned, efficient and reliable configurations of systems like 5G or indeed its predecessor 4G is a massive technical challenge. One promising avenue is the application of machine learning methods to apply a data-driven and continuous learning approach to automated system performance tuning. We demonstrate the effectiveness of policy-gradient reinforcement learning as a way to learn and apply complex interleaving patterns of radio resource block usage in 4G and 5G, in order to automate the reduction of cell edge interference. We show that our method can increase overall spectral efficiency up to 25% and increase the overall system energy efficiency up to 50% in very challenging scenarios by learning how to do more with less system resources. We also introduce a flexible phased and continuous learning approach that can be used to train a bootstrap model in a simulated environment after which the model is transferred to a live system for continuous contextual learning.",
        "DOI": "10.23919/CNSM52442.2021.9615550",
        "affiliation_name": "RISE Research Institutes of Sweden AB",
        "affiliation_city": "Gothenburg",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Forecasting temperature anomalies of planet Earth: A Comparative Analysis of AI Models",
        "paper_author": "Panda A.",
        "publication": "2021 9th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions), ICRITO 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Natural disasters are growing more severe than ever before. Therefore, monitoring and analyzing variations in the temperature of planet Earth is essential to raise public awareness on climate change. This paper provides insight into the annual variations in temperature of planet Earth from 1901 to 2020 using various Artificial Intelligence learning models such as LSTM, GRU, SARIMAX. Post investigation suggested that Machine Learning model, SARIMAX outperforms the Deep RNN models such as LSTM and GRU variants for predicting Earth's temperature. The results of the study can be utilized for forecasting the average temperature over the next few decades. It can also be employed for policy decisions by the concerned authorities to mitigate the adverse effects of rising Earth temperature.",
        "DOI": "10.1109/ICRITO51393.2021.9596567",
        "affiliation_name": "Acharya Narendra Dev College",
        "affiliation_city": "New Delhi",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Proximal Policy Optimization with Relative Pearson Divergence",
        "paper_author": "Kobayashi T.",
        "publication": "Proceedings - IEEE International Conference on Robotics and Automation",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "The recent remarkable progress of deep reinforcement learning (DRL) stands on regularization of policy for stable and efficient learning. A popular method, named proximal policy optimization (PPO), has been introduced for this purpose. PPO clips density ratio of the latest and baseline policies with a threshold, while its minimization target is unclear. As another problem of PPO, the symmetric threshold is given numerically while the density ratio itself is in asymmetric domain, thereby causing unbalanced regularization of the policy. This paper therefore proposes a new variant of PPO by considering a regularization problem of relative Pearson (RPE) divergence, so-called PPO-RPE. This regularization yields the clear minimization target, which constrains the latest policy to the baseline one. Through its analysis, the intuitive threshold-based design consistent with the asymmetry of the threshold and the domain of density ratio can be derived. Through four benchmark tasks, PPO-RPE performed as well as or better than the conventional methods in terms of the task performance by the learned policy.",
        "DOI": "10.1109/ICRA48506.2021.9560856",
        "affiliation_name": "Nara Institute of Science and Technology",
        "affiliation_city": "Ikoma",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Big Data Analysis on Twitter for 2017 Turkey Referendum: TRefendum",
        "paper_author": "Savas S.",
        "publication": "ISMSIT 2021 - 5th International Symposium on Multidisciplinary Studies and Innovative Technologies, Proceedings",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Social media platforms have taken their place among the most effective communication tools to keep the pulse of society, guide society, and set the agenda. Twitter is one of the leading social media websites that affect the masses. It is used effectively in the field of politics as well as in technology, sports, art, health, entertainment, and many other fields. Both political parties and party leaders use Twitter effectively. It is not possible to analyze the data on this platform, where huge amounts of data are shared per second, with classical methods. Making data-based decisions by analyzing the data here and drawing a roadmap for the future is one of the most important issues for policymakers. Big data techniques, natural language processing techniques, and even machine learning techniques come into play here. In this study, an application to big data analysis on social media data was carried out on the example of Turkey's referendum in 2017, and the potential of studies in this field was exemplified. The results of the study have been promising in order to be able to expand and make more in-depth studies.",
        "DOI": "10.1109/ISMSIT52890.2021.9604608",
        "affiliation_name": "Çankiri Karatekin Üniversitesi",
        "affiliation_city": "Cankiri",
        "affiliation_country": "Türkiye"
    },
    {
        "paper_title": "User-centred privacy inference detection for smart home devices",
        "paper_author": "Kounoudes A.D.",
        "publication": "Proceedings - 2021 IEEE SmartWorld, Ubiquitous Intelligence and Computing, Advanced and Trusted Computing, Scalable Computing and Communications, Internet of People, and Smart City Innovations, SmartWorld/ScalCom/UIC/ATC/IoP/SCI 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "In the smart home, vast amounts of data are being collected via various interconnected devices. Although this assists in improving the quality of life at home, often the user is not aware of the details concerning data collection apart from the information available on the provider privacy policy. It is however important to put the user inside this loop of information, so that she is well informed on possible uses of the data and the potential risks that this may entail. Previous works have identified user activity inside the smart home and have pointed out privacy threats. In this work, we go one step further by offering data inference techniques and giving this information back to the user. We use a number of machine learning techniques to draw conclusions about the user routines or activities and we inform the user about our findings concerning data inferences through a dedicated web application. Our aim is toward user-centred privacy and is a proof of concept that can be reused by smart home and Internet of Things service providers in general in order to improve the services offered to the end-users. Our results indicate that a large number of data inferences are possible by using a combination of techniques.",
        "DOI": "10.1109/SWC50871.2021.00037",
        "affiliation_name": "SignalGeneriX Ltd.",
        "affiliation_city": "Limassol",
        "affiliation_country": "Cyprus"
    },
    {
        "paper_title": "Sentiment Analysis of Bangladesh-specific COVID-19 Tweets using Deep Neural Network",
        "paper_author": "Islam M.N.",
        "publication": "ITMS 2021 - 2021 62nd International Scientific Conference on Information Technology and Management Science of Riga Technical University, Proceedings",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Nowadays, social media became a tracker of the COVID-19 disease which reflects the status of the COVID-19 outbreak in the world. Although it is important to know the impact of COVID-19 on the sentiment of mass people for the government and the policymakers in order to address peoples' needs and take emergent decisions during such crisis time, not many studies have been conducted regarding this issue. Moreover, very few studies were conducted on sentiment analysis during the COVID-19 pandemic in the context of Bangladesh. The purpose of this study is to estimate the impact of the COVID-19 outbreak on the sentiment of the Bangladeshi people through a machine learning approach. To achieve this goal, COVID-19 tweets were collected over a specific period and then build a deep learning classifier, having an average area under the curve (AUC) of 0.76. The study analyzes the spread and estimates various public emotions during the outbreak. And reveals that a significant number (55%) of people had negative sentiment regarding COVID-19, whereas, 38% and 7% of people had positive and neutral sentiment respectively. This study also found that people's involvement with social media increases as the number of active COVID-19 cases increases. Moreover, this study identified people's sentiment towards some important concerns regarding the COVID-19 pandemic.",
        "DOI": "10.1109/ITMS52826.2021.9615331",
        "affiliation_name": "Military Institute of Science and Technology",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Design of AoI-Aware 5G Uplink Scheduler Using Reinforcement Learning",
        "paper_author": "Wu C.C.",
        "publication": "Proceedings - 2021 IEEE 4th 5G World Forum, 5GWF 2021",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "Age of Information (AoI) reflects the time that is elapsed from the generation of a packet by a 5G user equipment (UE) to the reception of the packet by a controller. A design of an AoI-aware radio resource scheduler for UEs via reinforcement learning is proposed in this paper. In this paper, we consider a remote control environment in which a number of UEs are transmitting time-sensitive measurements to a remote controller. We consider the AoI minimization problem and formulate the problem as a trade-off between minimizing the sum of the expected AoI of all UEs and maximizing the throughput of the network. Inspired by the success of machine learning in solving large networking problems at low complexity, we develop a reinforcement learning-based method to solve the formulated problem. We used the state-of-the-art proximal policy optimization algorithm to solve this problem. Our simulation results show that the proposed algorithm outperforms the considered baselines in terms of minimizing the expected AoI while maintaining the network throughput.",
        "DOI": "10.1109/5GWF52925.2021.00038",
        "affiliation_name": "Aalborg University",
        "affiliation_city": "Aalborg",
        "affiliation_country": "Denmark"
    },
    {
        "paper_title": "Energy-Efficient Techniques for UAVs in Communication-based Applications",
        "paper_author": "Osman A.",
        "publication": "2021 26th International Conference on Automation and Computing: System Intelligence through Automation and Computing, ICAC 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Unmanned Aerial Vehicles (UAVs), which are at the forefront of cutting-edge technology, have unmatched potential for pioneering applications in a wide range of disciplines. In particular, in the field of cognitive radio (CR), which is a key aspect in the implementation of the new 5G telecommunication technology. The integration between the drone and CR consolidates the drone's capabilities at the heart of the remarkably promising Internet-of-Things (IoT) technology supported by CR. The highly dynamic network topologies, weakly networked communication links, reliable line-of-sight (LOS) communication links, and orbital or flight paths are characteristic features of UAV communication compared to terrestrial wireless networks. Nevertheless, the implementation of this system is constrained by several severe challenges, such as energy efficiency, battery power limitation, spectrum handover, propagation channel modeling, routing protocols, security policy, and delay setbacks. In this paper, we consider the impact of energy scarcity faced by the UAV in various CR applications. We also analyze the impact of energy scarcity on communication-based applications and present the general problem of battery limitation. Finally, we give an overview and comparison between recent solutions proposed by researchers both in the field of communication and based on batteries, and consider possible future directions according to the state of the art, such as novel Graph Signal Processing (GSP) and machine learning (ML).",
        "DOI": "10.23919/ICAC50006.2021.9594202",
        "affiliation_name": "Università di Trento",
        "affiliation_city": "Trento",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "QoA4ML - A Framework for Supporting Contracts in Machine Learning Services",
        "paper_author": "Truong H.L.",
        "publication": "Proceedings - 2021 IEEE International Conference on Web Services, ICWS 2021",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Important service-level constraints in machine learning (ML) services must be communicated and agreed among relevant stakeholders. Due to the lack of studies and support, it is unclear which and how ML-specific attributes and constraints should be specified and assured in service contracts for ML services. This paper examines service contracts in the three stakeholders engagement model of ML services. We identify key ML-specific attributes that should be specified and monitored for the ML service provider, ML consumer and ML infrastructure provider. Based on that, we propose QoA4ML (Quality of Analytics for ML) as a framework to support ML-specific service contracts. QoA4ML includes an ML-specific service contract specification, monitoring utilities and a contract observability service. To illustrate the usefulness of QoA4ML, we present real-world examples for contract terms and policies, monitoring and contract evaluation with dynamic ML services in predictive maintenance.",
        "DOI": "10.1109/ICWS53863.2021.00066",
        "affiliation_name": "Aalto University",
        "affiliation_city": "Espoo",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Flow Scheduling in a Heterogeneous NFV Environment using Reinforcement Learning",
        "paper_author": "Lin C.J.",
        "publication": "2021 IEEE International Conference on Networking, Architecture and Storage, NAS 2021 - Proceedings",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Network function virtualization (NFV) allows net-work functions executed on general-purpose servers or virtual machines (VMs) instead of proprietary hardware, greatly improving the flexibility and scalability of network services. Recent trends in using programmable accelerators to speed up NFV performance introduce challenges in flow scheduling in a dynamic NFV environment. Reinforcement learning (RL) trains machine learning models for decision making to maximize returns in uncertain environments such as NFV. In this paper, we study the allocation of heterogeneous processors (CPUs and FPGAs) to minimize the delays of flows in the system. We conduct extensive simulations to evaluate the performance of reinforcement learning based scheduling algorithms such as Advantage Actor Critic (A2C), Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO), and compare with greedy policies. The results show that RL based schedulers can effectively learn from past experiences and converge to the optimal greedy policy. We also analyze in-depth how the policies lead to different processor utilization and flow processing time, and provide insights into these policies.",
        "DOI": "10.1109/NAS51552.2021.9605395",
        "affiliation_name": "Francis College of Engineering",
        "affiliation_city": "Lowell",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Life science and its implications for society-(in addition to COVID-19)",
        "paper_author": "Antani S.",
        "publication": "International Symposium on Technology and Society, Proceedings",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "This multidisciplinary panel of experts in medicine considers the applications and impacts of technological innovations like Artificial Intelligence, automation, and the Internet of Things, focusing especially on addressing global health challenges, particularly for the post-COVID-19 pandemic era, including in developing nations and underserved populations. Panelists will discuss the opportunities and challenges of telemedicine, cybercare, homecare, treating noncommunicable diseases and preventing communicable diseases, as well as the development of reliable policy and standards for privacy and security of digital innovations.",
        "DOI": "10.1109/ISTAS52410.2021.9629200",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Photonic Quantum Policy Learning in OpenAI Gym",
        "paper_author": "Nagy D.",
        "publication": "Proceedings - 2021 IEEE International Conference on Quantum Computing and Engineering, QCE 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "In recent years, near-term noisy intermediate scale quantum (NISQ) computing devices have become available. One of the most promising application areas to leverage such NISQ quantum computer prototypes is quantum machine learning. While quantum neural networks are widely studied for supervised learning, quantum reinforcement learning is still just an emerging field of this area. To solve a classical continuous control problem, we used continuous-variable quantum machine learning. We introduce proximal policy optimization for photonic variational quantum agents and also study the effect of the data re-uploading. We present performance assessment via empirical study using Strawberry Fields, a photonic simulator Fock backend and a hybrid training framework connected to an OpenAI Gym environment and TensorFlow. For the restricted CartPole problem, the two variations of the photonic policy learning achieve comparable performance levels and a faster convergence than the baseline classical neural network of same number of trainable parameters.",
        "DOI": "10.1109/QCE52317.2021.00028",
        "affiliation_name": "Ericsson Hungary Ltd.",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "Deep Learning Models for Automated Identification of Scheduling Policies",
        "paper_author": "Chen Y.",
        "publication": "Proceedings - IEEE Computer Society's Annual International Symposium on Modeling, Analysis, and Simulation of Computer and Telecommunications Systems, MASCOTS",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Queueing network models are commonly used as performance models of distributed software applications and service-based systems. Although several methods exist for learning their parameters, such as demand estimation methods, little research has been carried out in the literature on automatically identifying scheduling policies from empirical datasets. Scheduling policies and their parameters have an impact on the model's stationary distribution in general, thus their correct determination is important for model accuracy. They are particularly relevant for correctly estimating percentiles and higher-order moments of performance indexes such as response times. We propose a deep learning technique based on transformer models - a common technique in natural language processing, to address the lack of methods for this parameter identification problem. From a sample path of the joint network state, or an aggregate thereof, our approach can classify the scheduling policy of the stations in a queueing network. We show that the transformer model delivers good-classification precision and recall, improving significantly over support vector machines or simpler recurrent neural networks.",
        "DOI": "10.1109/MASCOTS53633.2021.9614298",
        "affiliation_name": "Imperial College London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Automatic Parameter Tuning for Big Data Pipelines with Deep Reinforcement Learning",
        "paper_author": "Sagaama H.",
        "publication": "Proceedings - IEEE Symposium on Computers and Communications",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Tuning big data frameworks is a very important task to get the best performance for a given application. However, these frameworks are rarely used individually, they generally constitute a pipeline, each having a different role. This makes tuning big data pipelines an important yet difficult task given the size of the search space. Moreover, we have to consider the interaction between these frameworks when tuning the configuration parameters of the big data pipeline. A trade-off is then required to achieve the best end-to-end performance. Machine learning based methods have shown great success in automatic tuning systems, but they rely on a large number of high quality learning examples that are rather difficult to obtain. In this context, we propose to use a deep reinforcement learning algorithm, namely Twin Delayed Deep Deterministic Policy Gradient, TD3, to tune a fraud detection big data pipeline. We show through the conducted experiments that the TD3 agent improves the overall performance of the pipeline by up to 63% with only 200 training steps, outperforming the random search on the high-dimensional search space.",
        "DOI": "10.1109/ISCC53001.2021.9631440",
        "affiliation_name": "R&amp;D Department",
        "affiliation_city": "Tunis",
        "affiliation_country": "Tunisia"
    },
    {
        "paper_title": "Healthy memory aging - the benefits of regular daily activities increase with age",
        "paper_author": "Krakovska O.",
        "publication": "Aging",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "As the number of older adults increases, so does the pressure on health care systems due to age-related disorders. Attempts to reduce cognitive decline have focused on individual interventions such as exercise or diet, with limited success. This study adopted a different approach by investigating the impact of combined daily activities on memory decline. We used data from the National Institute of Aging’s Health and Retirement Study to explore two new questions: does combining activities affect memory decline, and if yes, does this impact change across the lifespan? We created a new machine learning model using 33 daily activities and involving 3210 participants. Our results showed that the effect of combined activities on memory decline was stronger than any individual activity’s impact. Moreover, this effect increased with age, whereas the importance of historical factors such as education, and baseline memory decreased. The present findings point out the importance of selecting multiple, diverse activities for older adults as they age. These results could have a significant impact on aging health policies promoting new programs such as social prescribing",
        "DOI": "10.18632/aging.203753",
        "affiliation_name": "Simon Fraser University",
        "affiliation_city": "Burnaby",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "WHY RESAMPLING OUTPERFORMS REWEIGHTING FOR CORRECTING SAMPLING BIAS WITH STOCHASTIC GRADIENTS",
        "paper_author": "An J.",
        "publication": "ICLR 2021 - 9th International Conference on Learning Representations",
        "citied_by": "14",
        "cover_date": "2021-01-01",
        "Abstract": "A data set sampled from a certain population is biased if the subgroups of the population are sampled at proportions that are significantly different from their underlying proportions. Training machine learning models on biased data sets requires correction techniques to compensate for the bias. We consider two commonly-used techniques, resampling and reweighting, that rebalance the proportions of the subgroups to maintain the desired objective function. Though statistically equivalent, it has been observed that resampling outperforms reweighting when combined with stochastic gradient algorithms. By analyzing illustrative examples, we explain the reason behind this phenomenon using tools from dynamical stability and stochastic asymptotics. We also present experiments from regression, classification, and off-policy prediction to demonstrate that this is a general phenomenon. We argue that it is imperative to consider the objective function design and the optimization algorithm together while addressing the sampling bias.",
        "DOI": "NA",
        "affiliation_name": "Stanford University",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Regional Migration in Russia: Dynamics, Features, Expectations",
        "paper_author": "Borisova L.",
        "publication": "Proceedings of 2021 14th International Conference Management of Large-Scale System Development, MLSD 2021",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The paper examines the new features and dynamics of internal migration processes in the Russian Federation at the present time (2015-2020). The results of a comparative statistical study on the regions of Russia are presented. In the context of global integration, citizens of all countries, including Russia, have the opportunity to study and analyze in more detail issues related to the financial, economic, social, labor and other policies of various regions and states, and other aspects of life. Therefore, there was a desire, and sometimes a need to change the place of their further residence (both within the country and abroad). At present, internal migration should be considered as a global social phenomenon, a powerful source of demographic improvement. Various aspects of migration processes that are currently observed are studied by many authors. This is understandable: in the life of any state, population migration plays an important role, affecting all spheres of life of the peoples of the countries. Migration processes for Russia are one of the main factors that determine the socio-economic development of modern Russian society, its demographic well-being. Internal migration of the population affects the socio-economic relations in the country, solves the issues of labor and employment of the population, as it allows millions of Russians to find new jobs. Issues of population migration should be regularly monitored and analyzed in order to correctly determine the reserves and plan the growth of the country's population on this basis, and to rationally and responsibly conduct the state's migration policy. The paper examines the new features and dynamics of internal migration processes in the Russian Federation at the present time (2015-2020). The results of a comparative statistical study on the regions of Russia are presented.",
        "DOI": "10.1109/MLSD52249.2021.9600231",
        "affiliation_name": "Financial University under the Government of the Russian Federation",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Joint Optimization of the Production Scheduling, Maintenance Activities, and Inventory Level for a Degrading Flexible Job-Shop Manufacturing System",
        "paper_author": "Sharifi M.",
        "publication": "Proceedings - Annual Reliability and Maintainability Symposium",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, we consider a degrading flexible job-shop manufacturing system and optimize jointly optimize scheduling, maintenance and inventory. In this production system, we are given n jobs of different routings and processing times, which need to be scheduled on m machines with varying processing power, and each job can be processed on all machines. The machines may fail due to the deterioration or the random breakdown of their tools. We model the condition of the machines' tools as a discrete multi-state degradation process using a continuous-time Markov chain. We assume that the transitions between the machines' tools deterioration states follow an exponential distribution.We aim to simultaneously optimize jobs' sequencing, maintenance planning, as well as the level of the machines' tool inventory at the beginning of the mission horizon. The objective is to minimize the total cost of the production system. The machines' tools are subject to several failures during the jobs' processing and are replaced after a failure.Failure of the machines' tools may damage the product (job) quality, and then, this product (job) needs to be reprocessed from the beginning after a tool replacement. At the beginning of each job's processing, based on the maintenance policy, a machine's tool may be inspected or not. If the tool is inspected, it may be replaced based on a pre-defined state-based threshold. Due to the available budget constraint, we should order the machines' redundant tool(s) at the beginning of the production's mission horizon.We present a mathematical model that minimizes the total production cost. The production cost includes inspection cost, maintenance cost, the penalty for exceeding a pre-defined threshold for the job completion time, and the cost of purchasing the redundant tools. Since the considered production scheduling problem is NP-Hard in the strong sense, we used a Genetic Algorithm (GA) and Teaching-Learning-Based Optimization (TLBO) algorithm to solve the presented model.",
        "DOI": "10.1109/RAMS48097.2021.9605799",
        "affiliation_name": "Toronto Metropolitan University",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "A low-cost and low-burden secure solution to track small-scale fisheries",
        "paper_author": "Tassetti A.N.",
        "publication": "2021 IEEE International Workshop on Metrology for the Sea: Learning to Measure Sea Health Parameters, MetroSea 2021 - Proceedings",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "During the last decade accurate spatial and quantitative information of industrial fisheries have been increasingly given using tracking technologies and machine learning analytical algorithms. However, in most small-scale fisheries, lack of spatial data has been a recurrent bottleneck as Vessel Monitoring System and Automatic Identification System, developed for vessels longer than 12 and 15 m in length respectively, have little applicability in these contexts. It follows that small-scale vessels (< 12 m in length) remain untracked and largely unregulated, even though they account for most of the fishing fleet in operation in the Mediterranean Sea. As such, the tracking of small-scale fleets tends to require the use of novel and low cost solutions that could be addressed by small vessels often without dedicated electrical systems. In this paper we propose a scalable architecture that makes use of a low-cost LoRaWAN/cellular network to acquire and process positioning data from small-scale vessels; preliminary results of a first installation of the prototype are presented, as well as the data collected. The emergence of a such low-cost and open source technology coupled to artificial intelligence could open new opportunities for equipping small-scale vessels, collecting their trajectory data and estimating their fishing effort (information which has historically not been present). It enables a new monitoring strategy that could effectively include small-scale fleets and support the design of new policies oriented to inform coastal resource and fisheries management, and cross-border marine spatial planning.",
        "DOI": "10.1109/MetroSea52177.2021.9611622",
        "affiliation_name": "Università Politecnica delle Marche",
        "affiliation_city": "Ancona",
        "affiliation_country": "Italy"
    },
    {
        "paper_title": "A Survey on Explainable Artificial Intelligence Techniques and Challenges",
        "paper_author": "Hanif A.",
        "publication": "Proceedings - IEEE International Enterprise Distributed Object Computing Workshop, EDOCW",
        "citied_by": "40",
        "cover_date": "2021-01-01",
        "Abstract": "In the last decade, the world has envisioned tremendous growth in technology with improved accessibility of data, cloud-computing resources, and the evolution of machine learning (ML) algorithms. The intelligent system has achieved significant performance with this growth. The state-of-the-art performance of these algorithms in various domains has increased the popularity of artificial intelligence (AI). However, alongside these achievements, the non-transparency, inscrutability and inability to expound and interpret the majority of the state-of-the-art techniques are considered an ethical issue. These flaws in AI algorithms impede the acceptance of complex ML models in a variety of fields such as medical, banking and finance, security, and education. These shortcomings have prompted many concerns about the security and safety of ML system users. These systems must be transparent, according to the current regulations and policies, in order to meet the right to explanation. Due to a lack of trust in existing ML-based systems, explainable artificial intelligence (XAI)-based methods are gaining popularity. Although neither the domain nor the methods are novel, they are gaining popularity due to their ability to unbox the black box. The explainable AI methods are of varying strengths, and they are capable of providing insights to the system. These insights can be ranging from a single feature explanation to the interpretability of sophisticated ML architecture. In this paper, we present a survey of known techniques in the field of XAI. Moreover, we suggest future research routes for developing AI systems that can be responsible. We emphasize the necessity of human knowledge-oriented systems for adopting AI in real-world applications with trust and high fidelity.",
        "DOI": "10.1109/EDOCW52865.2021.00036",
        "affiliation_name": "Macquarie University",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "User Scheduling for Federated Learning Through Over-the-Air Computation",
        "paper_author": "Ma X.",
        "publication": "IEEE Vehicular Technology Conference",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "A new machine learning (ML) technique termed as federated learning (FL) aims to preserve data at the edge devices and to only exchange ML model parameters in the learning process. FL not only reduces the communication needs but also helps to protect the local privacy. Although FL has these advantages, it can still experience large communication latency when there are massive edge devices connected to the central parameter server (PS) and/or millions of model parameters involved in the learning process. Over-the-air computation (AirComp) is capable of computing while transmitting data by allowing multiple devices to send data simultaneously by using analog modulation. To achieve good performance in FL through AirComp, user scheduling plays a critical role. In this paper, we investigate and compare different user scheduling policies, which are based on various criteria such as wireless channel conditions and the significance of model updates. Receiver beamforming is applied to minimize the mean-square-error (MSE) of the distortion of function aggregation result via AirComp. Simulation results show that scheduling based on the significance of model updates has smaller fluctuations in the training process while scheduling based on channel condition has the advantage on energy efficiency.",
        "DOI": "10.1109/VTC2021-Fall52928.2021.9625544",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Logan",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Automated Intelligent Healing in Cloud-Scale Data Centers",
        "paper_author": "Li R.",
        "publication": "Proceedings of the IEEE Symposium on Reliable Distributed Systems",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Modern cloud-scale data centers necessitate self-healing (i.e., the automation of detecting and repairing component failures) to support reliable and scalable cloud services in the face of prevalent failures. Traditional policy-based self-healing solutions rely on expert knowledge to define the proper policies for choosing repair actions, and hence are error-prone and non-scalable in practical deployment. We propose AIHS, an automated intelligent healing system that applies machine learning to achieve scalable self-healing in cloud-scale data centers. AIHS is designed as a full-fledged, general pipeline that supports various machine learning models for predicting accurate repair actions based on raw monitoring logs. We conduct extensive trace-driven and production experiments, and show that AIHS achieves higher prediction accuracy than current self-healing solutions and successfully fixes 92.4% of the total of 33.7 million production failures over seven months. AIHS also reduces 51% of unavailable time of each failed server on average compared to policy-based self-healing. AIHS is now deployed in production cloud-scale data centers at Alibaba with a total of 600 K servers. We open-source a Python prototype that reproduces the self-healing pipeline of AIHS for public validation.",
        "DOI": "10.1109/SRDS53918.2021.00032",
        "affiliation_name": "Alibaba Group Holding Limited",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Trustworthy Hardware Design with Logic Locking",
        "paper_author": "Sisejkovic D.",
        "publication": "IEEE/IFIP International Conference on VLSI and System-on-Chip, VLSI-SoC",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "As the designated root of trust, hardware is undoubtedly the most critical layer to security in modern electronic systems. Protecting its integrity throughout the integrated circuit supply chain is of paramount importance. Logic locking has become a prominent tool to safeguard hardware against malicious design modifications. In this work, we introduce a comprehensive logic-locking framework that enables locking schemes for complex hardware designs. We further introduce new concepts in security metrics, locking policies, and attacks. Finally, we showcase the applicability of the framework through MiG-V-the first logic-locked processor available on the market.",
        "DOI": "10.1109/VLSI-SoC53125.2021.9606998",
        "affiliation_name": "Rheinisch-Westfälische Technische Hochschule Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Shared Situation Awareness in the Globalised World",
        "paper_author": "Cincalova S.",
        "publication": "Proceedings of the 17th European Conference on Management, Leadership and Governance, ECMLG 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Well-developed and properly implemented concept of situation awareness (SA) improves decision-making at all levels of governance and management, especially when it comes to risky or emergent scenarios. The importance of SA increases with the level of uncertainty and dynamism of the surrounding environment, as well as with the number of external collaborators. The general complexity of such problems is high, and it is difficult to structure them in a directly applicable and interpretable way. Therefore, our goal was to discover whether it is possible to reasonably simplify, systemise and incorporate specific aspects of national and global dynamics into SA of both independent and collaborating organizations in order to formulate viable policies and plan development indicators with respect to external changes. As the main result, this paper suggests a conceptual design of a qualitative model of organizational SA, composed of two major components, data, and knowledge. It internalizes the four key aspects of national performance, accompanied by two distinct resources of global changes. This input information was initially identified in terms of disjoint, internally well-structured and mutually unrelated national indexes, for which the historical time-series data were available. Adopted datasets were processed with supervised and unsupervised machine learning techniques, which discovered the most influential general and country-specific predictors of external and global changes. These variables and identified relational patterns served as a foundation for designing a qualitative dynamic model of SA in the form of a Causal loop diagram. Because of the predictive nature of the proposed model, its adopters can either directly follow its suggestions or continuously share their own indicators of quantitative availability and qualitative willingness towards external partners. Related comparative analyses of typical scenarios can discover possible asymmetric bottlenecks caused by national specifics and global disturbances, which could prematurely harm otherwise smooth bilateral collaboration.",
        "DOI": "NA",
        "affiliation_name": "Prague University of Economics and Business",
        "affiliation_city": "Prague",
        "affiliation_country": "Czech Republic"
    },
    {
        "paper_title": "Smart-mDAG: An Intelligent Scheduling Method for Multi-DAG Jobs",
        "paper_author": "Zhu Y.",
        "publication": "International Conference on ICT Convergence",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Job scheduling is a fundamental problem in cloud data center, which plays an essential role in the makespan, resource utilization and maintenance of scheduling security, it has received widespread attention. With the rapid increase of jobs' amount, higher requirements are put forward for scheduling efficiency and makespan. Meantime dependencies between tasks are closely related to makespan and throughput, and these dependent tasks form multiple DAG structures. Heuristic algorithms have limitation on adjusting the scheduling policy according to diverse dependencies, thus resulting the extension of makespan. In this paper, we propose an intelligent scheduling method for multi-DAG jobs using deep reinforcement learning, called Smart-mDAG. It is a job-specific scheduling method that adjusts the scheduling policy based on diverse dependencies to minimize the makespan. Firstly, we convert dependencies to numeric form through a feature extraction module to obtain the dependent information from the DAG. Secondly, we use cascaded neural networks to implement the fusion of scheduling information, so we can obtain the fitness between machines and tasks. With Alibaba Cluster Data V2018, we evaluate the performance of Smart-mDAG on a five-machines small cluster. The result shows that compared to control algorithms, Smart-mDAG can shorten the makespan for 70% jobs, and the optimal makespan of single job can be decreased to 65% of the past.",
        "DOI": "10.1109/ICTC52510.2021.9621176",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Entrepreneurship and Leadership in Higher Education to Develop the Needed 21st Century Skills",
        "paper_author": "Dieguez T.",
        "publication": "Proceedings of the 17th European Conference on Management, Leadership and Governance, ECMLG 2021",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "We are going through perhaps the greatest crisis of our lives, where the pace of decision making, and the adoption of new public policies may indelibly condition individual and collective futures. Among other megatrends, Covid-19's impact on the digital world will facilitate the trend towards osmosis between real and virtual, human, machine and nature, public and private. The migration of all economic activities to digital, for safety and business survival reasons, will require adaptation and transition models to the new digital reality. The acceleration of digital transformation in hardware and software infrastructures will also lead to remodelling and innovate in all socio-economic, labour, and educational activities. The trend towards skills and qualifications will become more imperative. Higher Education Institutions can have a central role in developing the needed skills with their students, providing digital skills as well as pedagogical policies that stimulates them, specially focused on leadership, critical thinking, and creativity. This research aims to understand what the perceptions of the demand for digital workforce competencies are. It also intends to comprehend how those competencies are linked with entrepreneurship and leadership. After a literature review, data are presented and discussed, as well as conclusions and future potential research directions.",
        "DOI": "NA",
        "affiliation_name": "Instituto Politécnico do Cávado e do Ave",
        "affiliation_city": "Barcelos",
        "affiliation_country": "Portugal"
    },
    {
        "paper_title": "Carle's Game: An Open-Ended Challenge in Exploratory Machine Creativity",
        "paper_author": "Tyrell Davis Q.",
        "publication": "IEEE Conference on Computatonal Intelligence and Games, CIG",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This paper is both an introduction and an invitation. It is an introduction to CARLE, a Life-like cellular automata simulator and reinforcement learning environment. It is also an invitation to Carle's Game, a challenge in open-ended machine exploration and creativity. Inducing machine agents to excel at creating interesting patterns across multiple cellular automata universes is a substantial challenge, and approaching this challenge is likely to require contributions from the fields of artificial life, AI, machine learning, and complexity, at multiple levels of interest. Carle's Game is based on machine agent interaction with CARLE, a Cellular Automata Reinforcement Learning Environment. CARLE is flexible, capable of simulating any of the 262,144 different rules defining Life-like cellular automaton universes. CARLE is also fast and can simulate automata universes at a rate of tens of thousands of steps per second through a combination of vectorization and GPU acceleration. Finally, CARLE is simple. Compared to high-fidelity physics simulators and video games designed for human players, CARLE's two-dimensional grid world offers a discrete, deterministic, and atomic universal playground, despite its complexity. In combination with CARLE, Carle's game offers an initial set of agent policies, learning and meta-learning algorithms, and reward wrappers that can be tailored to encourage exploration or specific tasks.",
        "DOI": "10.1109/CoG52621.2021.9619011",
        "affiliation_name": "Wyoming",
        "affiliation_city": null,
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A competition-based pricing strategy in Cloud markets using regret minimisation techniques",
        "paper_author": "Ghasemi S.",
        "publication": "International Journal of Grid and Utility Computing",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Cloud computing as a fairly new commercial paradigm, widely investigated by different researchers, and already has a great range of challenges. Pricing is a major problem in the Cloud computing marketplace, as providers are competing to attract more customers without knowing the pricing policies of each other. To overcome this lack of knowledge, we model their competition by an incomplete-information game. Considering the issue, this work proposes a pricing policy related to the regret minimisation algorithm and applies it to the considered incomplete-information game. Based on the competition-based marketplace of the Cloud, providers update the distribution of their strategies using the experienced regret. The idea of iteratively applying the algorithm for updating probabilities of strategies causes the regret to be minimised faster. The experimental results show much more increase in profits of the providers in comparison with other pricing policies. Besides, the efficiency of a variety of regret minimisation techniques in a simulated marketplace of Cloud are discussed which have not been observed in the studied literature. Moreover, return on investment of providers in considered organisations is studied and promising results appeared.",
        "DOI": "10.1504/IJGUC.2021.120121",
        "affiliation_name": "Islamic Azad University, Sepidan Branch",
        "affiliation_city": "Sepidan",
        "affiliation_country": "Iran"
    },
    {
        "paper_title": "Device Scheduling and Update Aggregation Policies for Asynchronous Federated Learning",
        "paper_author": "Hu C.H.",
        "publication": "IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC",
        "citied_by": "21",
        "cover_date": "2021-01-01",
        "Abstract": "Federated Learning (FL) is a newly emerged decentralized machine learning (ML) framework that combines on-device local training with server-based model synchronization to train a centralized ML model over distributed nodes. In this paper, we propose an asynchronous FL framework with periodic aggregation to eliminate the straggler issue in FL systems. For the proposed model, we investigate several device scheduling and update aggregation policies and compare their performances when the devices have heterogeneous computation capabilities and training data distributions. From the simulation results, we conclude that the scheduling and aggregation design for asynchronous FL can be rather different from the synchronous case. For example, a norm-based significance-aware scheduling policy might not be efficient in an asynchronous FL setting, and an appropriate \"age-aware\"weighting design for the model aggregation can greatly improve the learning performance of such systems.",
        "DOI": "10.1109/SPAWC51858.2021.9593194",
        "affiliation_name": "Linköpings Universitet",
        "affiliation_city": "Linkoping",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Automated Aircraft Stall Recovery using Reinforcement Learning and Supervised Learning Techniques",
        "paper_author": "Singh Tomar D.",
        "publication": "AIAA/IEEE Digital Avionics Systems Conference - Proceedings",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Despite the on-board automation and protection systems of modern commercial aircraft, aerodynamic stall events are still a possible occurrence. This paper proposes Machine Learning algorithms - based on Reinforcement Learning and Supervised Learning - to automatically recover an aircraft from two types of aerodynamic stall: unaccelerated wings level (1G) stall and a stall during a turn. The algorithms were tested by exposing them to 105 simulated stall scenarios with different initial conditions (including altitude, bank angle and wind speed) and an acceptable stall recovery was achieved in 85.7% of the test cases. The overall recovery time increased with an increase in altitude, with the best and worst recovery times obtained at 10,000ft and 30,000ft respectively. Further work will focus on improving the performance of the algorithms such as by reducing the time to recover from a stall, decreasing the altitude loss and training the algorithms over a larger range of altitudes, up to cruise level.",
        "DOI": "10.1109/DASC52595.2021.9594316",
        "affiliation_name": "L-Università ta' Malta",
        "affiliation_city": "Msida",
        "affiliation_country": "Malta"
    },
    {
        "paper_title": "Adaptive UAV Swarm Mission Planning by Temporal Difference Learning",
        "paper_author": "Gopalakrishnan S.K.",
        "publication": "AIAA/IEEE Digital Avionics Systems Conference - Proceedings",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "The prevalence of Unmanned Aerial Vehicles (UAVs) in precision agriculture has been growing rapidly. This paper tackles the UAV global mission planning problem by incorporating a greater capacity for human-machine teaming in the architecture of a flexibly autonomous, near-fully-distributed Mission Management System for UAV swarms. Subsequently, the two problems of global mission planning are solved simultaneously using an integrated solution. This consists of a geometric clustering algorithm which prioritizes the minimization of overall mission time, and an off-policy, model-free Temporal Difference Learning global agent capable of learning about an initially unknown mission environment through simulations. The latter component makes the solution adaptive to missions with different requirements.",
        "DOI": "10.1109/DASC52595.2021.9594300",
        "affiliation_name": "Cranfield University",
        "affiliation_city": "Cranfield",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "A machine learning approach to identify correlates of current e-cigarette use in Canada",
        "paper_author": "Fu R.",
        "publication": "Exploration of Medicine",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Aim: Popularity of electronic cigarettes (i.e. e-cigarettes) is soaring in Canada. Understanding person-level correlates of current e-cigarette use (vaping) is crucial to guide tobacco policy, but prior studies have not fully identified these correlates due to model overfitting caused by multicollinearity. This study addressed this issue by using classification tree, a machine learning algorithm. Methods: This population-based cross-sectional study used the Canadian Tobacco, Alcohol, and Drugs Survey (CTADS) from 2017 that targeted residents aged 15 or older. Forty-six person-level characteristics were first screened in a logistic mixed-effects regression procedure for their strength in predicting vaper type (current vs. former vaper) among people who reported to have ever vaped. A 9:1 ratio was used to randomly split the data into a training set and a validation set. A classification tree model was developed using the cross-validation method on the training set using the selected predictors and assessed on the validation set using sensitivity, specificity and accuracy. Results: Of the 3,059 people with an experience of vaping, the average age was 24.4 years (standard deviation = 11.0), with 41.9% of them being female and 8.5% of them being aboriginal. There were 556 (18.2%) current vapers. The classification tree model performed relatively well and suggested attraction to e-cigarette flavors was the most important correlate of current vaping, followed by young age (< 18) and believing vaping to be less harmful to oneself than cigarette smoking. Conclusions: People who vape due to flavors are associated with very high risk of becoming current vapers. The findings of this study provide evidence that supports the ongoing ban on flavored vaping products in the US and suggests a similar regulatory intervention may be effective in Canada.",
        "DOI": "10.37349/emed.2021.00033",
        "affiliation_name": "Institute of Health Policy, Management and Evaluation",
        "affiliation_city": "Toronto",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Device Scheduling and Resource Allocation for Federated Learning under Delay and Energy Constraints",
        "paper_author": "Shi W.",
        "publication": "IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Federated Learning (FL) is an emerging technique to enhance edge intelligence, where mobile devices train machine learning models collaboratively with their local data. Limited energy on devices and scarce wireless bandwidth can notably impact the convergence of FL over wireless networks, and thus device scheduling and resource allocation are critical. In this paper, we propose a joint device scheduling and resource allocation scheme to maximize the model accuracy under total training delay and device energy budgets. Since FL consists of multiple training rounds, there is an inherent trade-off between per-round delay, per-round energy consumption, and the total number of rounds. To find solution, we decouple the accuracy maximization problem into two sub-problems. First, given a scheduling policy, the bandwidth allocation and local computing frequency are jointly optimized to maximize the number of rounds that can be conducted. Then, a device scheduling policy is proposed to balance the trade-off between the per-round energy and delay cost and the number of rounds, with the ultimate goal of accuracy optimization. Experiments on various learning tasks and datasets show that the proposed scheme can greatly improve the convergence rate of resource-constrained FL.",
        "DOI": "10.1109/SPAWC51858.2021.9593178",
        "affiliation_name": "Beijing National Research Center for Information Science and Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Exploring Deep Neural Network Capability for Intrusion Detection Using Different Mobile Phones Platforms",
        "paper_author": "Alharbi N.F.",
        "publication": "International Journal of Computing and Digital Systems",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Network intrusion activities started since the network typologies become available for public, the target devices were computers, servers, switches, routers and so on, but with the fever of smartphones spreading among the public, these smartphones have become a target for hacker attacks. Network Intrusion Detection System (IDS) is a device, software or both used by network administrator to monitor the network security and recognize any malicious activity or organization's network policy violation. Deep neural network is the famous technology in deep learning where it is an artificial neural network with multiple hidden layers, and it simulates the human brain and it's the central nervous system in thinking and detecting pattern. Mobile phones are widely used today, with different platforms which known now as smartphones, these smartphones belong to many manufacturing and require operating system. This research explores deep neural networks capability for intrusion detection using different mobile phones platforms, the research experiments five deep neural networks approaches, Fully Connected Deep Neural Networks (FCDNN), Convolutional Neural Networks (CNN), Convolutional Neural Networks followed by Fully Connected Neural Networks (CNN&FCDNN), Convolutional Neural Networks followed by Fully Connected Neural Networks and then followed by Convolution Neural Network (CNN&FCDNN&CNN), and finally Fully Connected Deep Neural Networks followed by Convolution Neural Networks (FCDNN&CNN).Two data sets have been used for testing the approaches, Android data set and NSL-KDD data set. The proposed approaches have been compared with each other's and also compared with traditional Machine Learning (ML) approaches. The results show that CNN&FCDNN&CNN is the best deep learning approach where it achieved accuracy of 0.863 and 0.997 for the two data sets Android and NSL-KDD respectively. The accuracy results also show that the best approach is the random forest where it achieved 0.88 and 0.998 for Android and NSL-KDD data sets respectively. Deep neural networks show that they are good machine learning candidates for problems similar to mobile phones intrusion detection systems.",
        "DOI": "10.12785/ijcds/1001123",
        "affiliation_name": "University of Bahrain",
        "affiliation_city": "Zallaq",
        "affiliation_country": "Bahrain"
    },
    {
        "paper_title": "Applying natural language processing to automatically assess student conceptual understanding from textual responses",
        "paper_author": "Somers R.",
        "publication": "Australasian Journal of Educational Technology",
        "citied_by": "19",
        "cover_date": "2021-01-01",
        "Abstract": "In this study, we applied natural language processing (NLP) techniques, within an educational environment, to evaluate their usefulness for automated assessment of students’ conceptual understanding from their short answer responses. Assessing understanding provides insight into and feedback on students’ conceptual understanding, which is often overlooked in automated grading. Students and educators benefit from automated formative assessment, especially in online education and large cohorts, by providing insights into conceptual understanding as and when required. We selected the ELECTRA-small, RoBERTa-base, XLNet-base and ALBERT-base-v2 NLP machine learning models to determine the free-text validity of students’ justification and the level of confidence in their responses. These two pieces of information provide key insights into students’ conceptual understanding and the nature of their understanding. We developed a free-text validity ensemble using high performance NLP models to assess the validity of students’ justification with accuracies ranging from 91.46% to 98.66%. In addition, we proposed a general, non-question-specific confidence-in-response model that can categorise a response as high or low confidence with accuracies ranging from 93.07% to 99.46%. With the strong performance of these models being applicable to small data sets, there is a great opportunity for educators to implement these techniques within their own classes. Implications for practice or policy: · Students’ conceptual understanding can be accurately and automatically extracted from their short answer responses using NLP to assess the level and nature of their understanding. Educators and students can receive feedback on conceptual understanding as and when required through the automated assessment of conceptual understanding, without the overhead of traditional formative assessment. Educators can implement accurate automated assessment of conceptual understanding models with fewer than 100 student responses for their short response questions.",
        "DOI": "10.14742/ajet.7121",
        "affiliation_name": "Queensland University of Technology",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Advanced Machine Learning Algorithms for House Price Prediction: Case Study in Kuala Lumpur",
        "paper_author": "Abdul-Rahman S.",
        "publication": "International Journal of Advanced Computer Science and Applications",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "House price is affected significantly by several factors and determining a reasonable house price involves a calculative process. This paper proposes advanced machine learning (ML) approaches for house price prediction. Two recent advanced ML algorithms, namely LightGBM and XGBoost were compared with two traditional approaches: multiple regression analysis and ridge regression. This study utilizes a secondary dataset called ‘Property Listing in Kuala Lumpur’, gathered from Kaggle and Google Map, containing 21984 observations with 11 variables, including a target variable. The performance of the ML models was evaluated using mean absolute error (MAE), root mean square error (RMSE), and adjusted r-squared value. The findings revealed that the house price prediction model based on XGBoost showed the highest performance by generating the lowest MAE and RMSE, and the closest adjusted r-squared value to one, consistently outperformed other ML models. A new dataset which consists of 1300 samples was deployed at the model deployment stage. It was found that the percentage of the variance between the actual and predicted price was relatively small, which indicated that this model is reliable and acceptable. This study can greatly assist in predicting future house prices and the establishment of real estate policies.",
        "DOI": "10.14569/IJACSA.2021.0121291",
        "affiliation_name": "Petronas",
        "affiliation_city": "Kuala Lumpur",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Kernel Temporal Difference based Reinforcement Learning for Brain Machine Interfaces",
        "paper_author": "Shen X.",
        "publication": "Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Brain-machine interfaces (BMIs) enable people with disabilities to control external devices with their motor intentions through a decoder. Compared with supervised learning, reinforcement learning (RL) is more promising for the disabled because it can assist them to learn without actual limb movement. Current RL decoders deal with tasks with immediate reward delivery. But for tasks where the reward is only given by the end of the trial, existing RL methods may take a long time to train and are prone to becoming trapped in the local minima. In this paper, we propose to embed temporal difference method (TD) into Quantized Attention-Gated Kernel Reinforcement Learning (QAGKRL) to solve this temporal credit assignment problem. This algorithm utilizes a kernel network to ensure the global linear structure and adopts a softmax policy to efficiently explore the state-action mapping through TD error. We simulate a center-out task where the agent needs several steps to first reach a periphery target and then return to the center to get the external reward. Our proposed algorithm is tested on simulated data and compared with two state-of-the-art models. We find that introducing the TD method to QAGKRL achieves a prediction accuracy of 96.2% ± 0.77% (mean ± std), which is significantly better the other two methods.Clinical Relevance - This paper proposes a novel kernel temporal difference RL method for the multi-step task with delayed reward delivery, which potentially enables BMI online continuous decoding.",
        "DOI": "10.1109/EMBC46164.2021.9631086",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong"
    },
    {
        "paper_title": "Towards inference delivery networks: Distributing machine learning with optimality guarantees",
        "paper_author": "Salem T.S.",
        "publication": "2021 19th Mediterranean Communication and Computer Networking Conference, MedComNet 2021",
        "citied_by": "13",
        "cover_date": "2021-01-01",
        "Abstract": "We present the novel idea of inference delivery networks (IDN), networks of computing nodes that coordinate to satisfy inference requests achieving the best trade-off between latency and accuracy. IDNs bridge the dichotomy between device and cloud execution by integrating inference delivery at the various tiers of the infrastructure continuum (access, edge, regional data center, cloud). We propose a distributed dynamic policy for ML model allocation in an IDN by which each node periodically updates its local set of inference models based on requests observed during the recent past plus limited information exchange with its neighbor nodes. Our policy offers strong performance guarantees in an adversarial setting and shows improvements over greedy heuristics with similar complexity in realistic scenarios.",
        "DOI": "10.1109/MEDCOMNET52149.2021.9501272",
        "affiliation_name": "Institut Polytechnique de Paris",
        "affiliation_city": "Palaiseau",
        "affiliation_country": "France"
    },
    {
        "paper_title": "10th International Conference on Frontier Computing, FC 2020",
        "paper_author": "NA",
        "publication": "Lecture Notes in Electrical Engineering",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 300 papers. The special focus in this conference is on Frontier Computing. The topics include: Dynamic Modeling and Control Method of Manipulator Based on Model Recognition; design of Programmable Soft Starter Control System; power Load Forecasting Model Based on Improved Parallel Fuzzy Kernel Clustering Algorithm; The Prototype System of Support Vector Machine (SVM) Based on Big Data International Shipping Index Prediction; big Data Technology in Computer Information System; target Recognition and Grab Location Based on Machine Vision and Deep Learning; point Cloud Data Self-adaptive Partition and Triangular Surface Reconstruction; application of Information Platform in Smart Logistics System; trace Car Based on Super Capacitor; Comparison of Influenza Disease Prediction Using ARIMA and LSTM Models for Central Taiwan; online Teaching Platform in Vocational College English Education; application of Adaptable College English Innovation Teaching in the Network Environment; problems and Countermeasures of Information Technology in College English Teaching; brief Analysis of Indian Cybersecurity Policy; advantages and Disadvantages of India and America in Cybersecurity Cooperation; new Model of Educational Information Service in the Era of Big Data; exploration on the Construction of Wisdom Teaching of Universities in the “Internet +” Era; on the Scalability Analysis of Computing-Offloading Edge Computing; Theoretical Basis of P and NP Problem; Electrical Control and PLC Application Technology; the Design and Implementation of Dynamic Costume Projection System; automatic Control Technology and Integrated Design of Electromechanical Control System; evolution and Frontiers Visualization Analysis of International Cooperation in Vaccine R&D; application Analysis of Computer-Aided Design in Clothing Design Teaching.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Developing Machine Learning and Statistical Tools to Evaluate the Accessibility of Public Health Advice on Infectious Diseases among Vulnerable People",
        "paper_author": "Xie W.",
        "publication": "Computational Intelligence and Neuroscience",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Background. From Ebola, Zika, to the latest COVID-19 pandemic, outbreaks of highly infectious diseases continue to reveal severe consequences of social and health inequalities. People from low socioeconomic and educational backgrounds as well as low health literacy tend to be affected by the uncertainty, complexity, volatility, and progressiveness of public health crises and emergencies. A key lesson that governments have taken from the ongoing coronavirus pandemic is the importance of developing and disseminating highly accessible, actionable, inclusive, coherent public health advice, which represent a critical tool to help people with diverse cultural, educational backgrounds and varying abilities to effectively implement health policies at the grassroots level. Objective. We aimed to translate the best practices of accessible, inclusive public health advice (purposefully designed for people with low socioeconomic and educational background, health literacy levels, limited English proficiency, and cognitive/functional impairments) on COVID-19 from health authorities in English-speaking multicultural countries (USA, Australia, and UK) to adaptive tools for the evaluation of the accessibility of public health advice in other languages. Methods. We developed an optimised Bayesian classifier to produce probabilistic prediction of the accessibility of official health advice among vulnerable people including migrants and foreigners living in China. We developed an adaptive statistical formula for the rapid evaluation of the accessibility of health advice among vulnerable people in China. Results. Our study provides needed research tools to fill in a persistent gap in Chinese public health research on accessible, inclusive communication of infectious diseases' prevention and management. For the probabilistic prediction, using the optimised Bayesian machine learning classifier (GNB), the largest positive likelihood ratio (LR+) 16.685 (95% confidence interval: 4.35, 64.04) was identified when the probability threshold was set at 0.2 (sensitivity: 0.98; specificity: 0.94). Conclusion. Effective communication of health risks through accessible, inclusive, actionable public advice represents a powerful tool to reduce health inequalities amidst health crises and emergencies. Our study translated the best-practice public health advice developed during the pandemic into intuitive machine learning classifiers for health authorities to develop evidence-based guidelines of accessible health advice. In addition, we developed adaptive statistical tools for frontline health professionals to assess accessibility of public health advice for people from non-English speaking backgrounds.",
        "DOI": "10.1155/2021/1916690",
        "affiliation_name": "The University of Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "A Generalized Method for Sentiment Analysis across Different Sources",
        "paper_author": "Ashir A.M.",
        "publication": "Applied Computational Intelligence and Soft Computing",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Sentiment analysis is widely used in a variety of applications such as online opinion gathering for policy directives in government, monitoring of customers, and staff satisfactions in corporate bodies, in politics and security structures for public tension monitoring, and so on. In recent times, the field met with new set of challenges where new algorithms have to contend with highly unstructured sources for sentiment expressions emanating from online social media fora. In this study, a rule and lexical-based procedure is proposed together with unsupervised machine learning to implement sentiment analysis with an improved generalization ability across different sources. To deal with sources devoid of syntactic and grammatical structure, the approach incorporates a ruled-based technique for emoticon detection, word contraction expansion, noise removal, and lexicon-based text preprocessing using lexical features such as part of speech (POS), stop words, and lemmatization for local context analysis. A text is broken into number of tokens with each representing a sentence and then lexicon-dependent features are extracted from each token. The features are merged together using a combining function for a given text before being used to train a machine learning classifier. The proposed combining functions leverage on averaging and information gain concepts. Experimental results with different machine leaning classifiers indicate that improved performance with great deal of generalization capacity across both structured and nonstructured sources can be realized. The finding shows that carefully designed lexical features reinforce learning process in unsupervised learning more than using word embeddings alone as the features. Obtained experimental results from movie review dataset (recall = 74.9%, precision = 70.9%, F1-score = 72.9%, and accuracy = 72.0%) and twitter samples' datasets (recall = 93.4%, precision = 89.5%, F1-score = 91.4%, and accuracy = 91.1%) show the efficacy of the proposed approach in comparison with other state-of-the-art research studies.",
        "DOI": "10.1155/2021/2529984",
        "affiliation_name": "Tishk International University",
        "affiliation_city": "Erbil",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "What Drives Financial Sector Development in Africa? Insights from Machine Learning",
        "paper_author": "Ofori I.K.",
        "publication": "Applied Artificial Intelligence",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "This study uses machine learning techniques to identify the key drivers of financial development in Africa. To this end, four regularization techniques–the Standard lasso, Adaptive lasso, the minimum Schwarz Bayesian information criterion lasso, and the Elasticnet– are trained based on a dataset containing 86 covariates of financial development for the period 1990 - 2019. The results show that variables such as cell phones, economic globalization, institutional effectiveness, and literacy are crucial for financial sector development in Africa. Evidence from the Partialing-out lasso instrumental variable regression reveals that while inflation and agricultural sector employment suppress financial sector development, cell phones and institutional effectiveness are remarkable in spurring financial sector development in Africa. Policy recommendations are provided in line with the rise in globalization, and technological progress in Africa.",
        "DOI": "10.1080/08839514.2021.1999597",
        "affiliation_name": "University of Professional Studies, Accra",
        "affiliation_city": "Accra",
        "affiliation_country": "Ghana"
    },
    {
        "paper_title": "Construction of Innovation and Entrepreneurship Platform Based on Deep Learning Algorithm",
        "paper_author": "Li J.",
        "publication": "Scientific Programming",
        "citied_by": "8",
        "cover_date": "2021-01-01",
        "Abstract": "As the national economy has entered a stage of rapid development, the national economy and social development have also ushered in the \"14th Five-Year Plan,\"and the country has also issued support policies to encourage and guide college students to start their own businesses. Therefore, the establishment of an innovation and entrepreneurship platform has a significant impact on China's economy. This gives college students great support and help in starting a business. The theory of deep learning algorithms originated from the development of artificial neural networks and is another important field of machine learning. As the computing power of computers has been greatly improved, especially the computing power of GPU can quickly train deep neural networks, deep learning algorithms have become an important research direction. The deep learning algorithm is a nonlinear network structure and a standard modeling method in the field of machine learning. After modeling various templates, they can be identified and implemented. This article uses a combination of theoretical research and empirical research, based on the views and research content of some scholars in recent years, and introduces the basic framework and research content of this article. Then, deep learning algorithms are used to analyze the experimental data. Data analysis is performed, and relevant concepts of deep learning algorithms are combined. This article focuses on exploring the construction of an IAE (innovation and entrepreneurship) education platform and making full use of the role of deep learning algorithms to realize the construction of innovation and entrepreneurship platforms. Traditional methods need to extract features through manual design, then perform feature classification, and finally realize the function of recognition. The deep learning algorithm has strong data image processing capabilities and can quickly process large-scale data. Research data show that 49.5% of college students and 35.2% of undergraduates expressed their interest in entrepreneurship. Entrepreneurship is a good choice to relieve employment pressure.",
        "DOI": "10.1155/2021/1833979",
        "affiliation_name": "Harbin University",
        "affiliation_city": "Harbin",
        "affiliation_country": "China"
    },
    {
        "paper_title": "A Deep Neural Network-Based Multi-Label Classifier for SLA Violation Prediction in a Latency Sensitive NFV Application",
        "paper_author": "Jalodia N.",
        "publication": "IEEE Open Journal of the Communications Society",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Recent advancements in the domain of Network Function Virtualization (NFV), and rollout of next-generation networks have necessitated the requirement for the upkeep of latency-critical application architectures in future networks and communications. While Cloud service providers recognize the evolving mission-critical requirements in latency sensitive verticals such as autonomous driving, multimedia, gaming, telecommunications, and virtual reality, there is a wide gap to bridge the Quality of Service (QoS) constraints for the end-user experience. Most latency-critical services are over-provisioned on all fronts to offer reliability, which is inefficient towards scalability in the long run. To address this, we propose a strategy to model frequent violations on the application level as a multi-output target to enable more complex decision-making in the management of virtualised communication networks. In this work, we utilize data from a real-world deployment to configure and draft a realistic set of Service Level Objectives (SLOs) for a voice based NFV application, and develop a deep neural network based multi-label classification methodology to identify and predict multiple categories of SLO breaches associated with an application state. With this, we aim to gain granular SLA and SLO violation insights, enabling us to study and mitigate their impact and inform precision in drafting proactive scaling policies. We further compare the performance against a set of multi-label compatible machine learning classifiers, and address class imbalance in a multi-label setup. We perform a comprehensive evaluation to assess the performance on example-based, label-based and ranking-based measures, and demonstrate the suitability of deep learning in such a use-case.",
        "DOI": "10.1109/OJCOMS.2021.3122844",
        "affiliation_name": "South East Technological University",
        "affiliation_city": "Waterford",
        "affiliation_country": "Ireland"
    },
    {
        "paper_title": "Scaling UPF Instances in 5G/6G Core with Deep Reinforcement Learning",
        "paper_author": "Nguyen H.T.",
        "publication": "IEEE Access",
        "citied_by": "29",
        "cover_date": "2021-01-01",
        "Abstract": "In the 5G core and the upcoming 6G core, the User Plane Function (UPF) is responsible for the transportation of data from and to subscribers in Protocol Data Unit (PDU) sessions. The UPF is generally implemented in software and packed into either a virtual machine or container that can be launched as a UPF instance with a specific resource requirement in a cluster. To save resource consumption needed for UPF instances, the number of initiated UPF instances should depend on the number of PDU sessions required by customers, which is often controlled by a scaling algorithm. In this paper, we investigate the application of Deep Reinforcement Learning (DRL) for scaling UPF instances that are packed in the containers of the Kubernetes container-orchestration framework. We propose an approach with the formulation of a threshold-based reward function and adapt the proximal policy optimization (PPO) algorithm. Also, we apply a support vector machine (SVM) classifier to cope with a problem when the agent suggests an unwanted action due to the stochastic policy. Extensive numerical results show that our approach outperforms Kubernetes's built-in Horizontal Pod Autoscaler (HPA). DRL could save 2.7-3.8% of the average number of Pods, while SVM could achieve 0.7-4.5% saving compared to HPA.",
        "DOI": "10.1109/ACCESS.2021.3135315",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "A Python package for performing penalized maximum likelihood estimation of conditional logit models using Kernel Logistic Regression",
        "paper_author": "Martín-Baos J.Á.",
        "publication": "Transportation Research Procedia",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "In the last few years, the success of Machine Learning (ML) algorithms has led to the extension of their applications to areas such as transport planning. One of the main tasks within transport planning is the analysis of transport demand. To do so, it is necessary to analyse the way in which users make their decisions about the trips they make and, therefore, be able to predict the number of passengers on the transport network in relation to respect to interventions made on the transport system. Consequently, transport policies and plans can be evaluated according to the behaviour of the passengers. Discrete choice models based on random utility maximization have been developed over the last four decades, becoming the canonical tool for transport demand analysis. Nowadays, the use of ML methods could provide an alternative to discrete choice models, as they reduce the need for the analyst to specify the functional expression of these models and achieve a higher level of accuracy in their predictions. A Python software package called PyKernelLogit was developed to apply a ML method called Kernel Logistic Regression (KLR) to the problem of predicting the transport demand. This package allows the user to specify a set of models using KLR and the estimation of those using a Penalized Maximum Likelihood Estimation procedure. Moreover, this tool also provides a set of indicators for goodness of fit and the application of model validation techniques. Finally, it allows to obtain the willingness to pay or value of time indicators commonly used in transport planning.",
        "DOI": "10.1016/j.trpro.2021.11.009",
        "affiliation_name": "Universidad de Castilla-La Mancha",
        "affiliation_city": "Ciudad Real",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "MLE-Guided Parameter Search for Task Loss Minimization in Neural Sequence Modeling",
        "paper_author": "Welleck S.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Neural autoregressive sequence models are used to generate sequences in a variety of natural language processing (NLP) tasks, where they are evaluated according to sequence-level task losses. These models are typically trained with maximum likelihood estimation, which ignores the task loss, yet empirically performs well as a surrogate objective. Typical approaches to directly optimizing the task loss such as policy gradient and minimum risk training are based around sampling in the sequence space to obtain candidate update directions that are scored based on the loss of a single sequence. In this paper, we develop an alternative method based on random search in the parameter space that leverages access to the maximum likelihood gradient. We propose maximum likelihood guided parameter search (MGS), which samples from a distribution over update directions that is a mixture of random search around the current parameters and around the maximum likelihood gradient, with each direction weighted by its improvement in the task loss. MGS shifts sampling to the parameter space, and scores candidates using losses that are pooled from multiple sequences. Our experiments show that MGS is capable of optimizing sequence-level losses, with substantial reductions in repetition and non-termination in sequence completion, and similar improvements to those of minimum risk training in machine translation.",
        "DOI": "10.1609/aaai.v35i16.17652",
        "affiliation_name": "New York University",
        "affiliation_city": "New York",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Short-Term Solar Photovoltaic Power Optimized Prediction Interval Model Based on FOS-ELM Algorithm",
        "paper_author": "Ramkumar G.",
        "publication": "International Journal of Photoenergy",
        "citied_by": "48",
        "cover_date": "2021-01-01",
        "Abstract": "Solar energy conversion efficiency has improved by the advancement technology of photovoltaic (PV) and the involvement of administrations worldwide. However, environmental conditions influence PV power output, resulting in randomness and intermittency. These characteristics may be harmful to the power scheme. As a conclusion, precise and timely power forecast information is essential for the power networks to engage solar energy. To lessen the negative impact of PV electricity usage, the offered short-term solar photovoltaic (PV) power estimate design is based on an online sequential extreme learning machine with a forgetting mechanism (FOS-ELM) under this study. This approach can replace existing knowledge with new information on a continuous basis. The variance of model uncertainty is computed in the first stage by using a learning algorithm to provide predictable PV power estimations. Stage two entails creating a one-of-a-kind PI based on cost function to enhance the ELM limitations and quantify noise uncertainty in respect of variance. As per findings, this approach does have the benefits of short training duration and better reliability. This technique can assist the energy dispatching unit list producing strategies while also providing temporal and spatial compensation and integrated power regulation, which are crucial for the stability and security of energy systems and also their continuous optimization.",
        "DOI": "10.1155/2021/3981456",
        "affiliation_name": "MAHSA University",
        "affiliation_city": "Kuala Langat",
        "affiliation_country": "Malaysia"
    },
    {
        "paper_title": "Guest Editorial: Special Issue on Artificial Intelligence in E-Healthcare and M-Healthcare",
        "paper_author": "Li X.",
        "publication": "Journal of Healthcare Engineering",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "NA",
        "DOI": "10.1155/2021/9857089",
        "affiliation_name": "City University of Macau",
        "affiliation_city": "Taipa",
        "affiliation_country": "Macao"
    },
    {
        "paper_title": "Task-aware verifiable RNN-based policies for partially observable Markov decision processes",
        "paper_author": "Carr S.",
        "publication": "Journal of Artificial Intelligence Research",
        "citied_by": "14",
        "cover_date": "2021-01-01",
        "Abstract": "Partially observable Markov decision processes (POMDPs) are models for sequential decision-making under uncertainty and incomplete information. Machine learning methods typically train recurrent neural networks (RNN) as effective representations of POMDP policies that can efficiently process sequential data. However, it is hard to verify whether the POMDP driven by such RNN-based policies satisfies safety constraints, for instance, given by temporal logic specifications. We propose a novel method that combines techniques from machine learning with the field of formal methods: training an RNN-based policy and then automatically extracting a so-called finite-state controller (FSC) from the RNN. Such FSCs offer a convenient way to verify temporal logic constraints. Implemented on a POMDP, they induce a Markov chain, and probabilistic verification methods can efficiently check whether this induced Markov chain satisfies a temporal logic specification. Using such methods, if the Markov chain does not satisfy the specification, a byproduct of verification is diagnostic information about the states in the POMDP that are critical for the specification. The method exploits this diagnostic information to either adjust the complexity of the extracted FSC or improve the policy by performing focused retraining of the RNN. The method synthesizes policies that satisfy temporal logic specifications for POMDPs with up to millions of states, which are three orders of magnitude larger than comparable approaches.",
        "DOI": "10.1613/JAIR.1.12963",
        "affiliation_name": "Radboud Universiteit",
        "affiliation_city": "Nijmegen",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "No-Press Diplomacy from Scratch",
        "paper_author": "Bakhtin A.",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "Prior AI successes in complex games have largely focused on settings with at most hundreds of actions at each decision point. In contrast, Diplomacy is a game with more than 1020 possible actions per turn. Previous attempts to address games with large branching factors, such as Diplomacy, StarCraft, and Dota, used human data to bootstrap the policy or used handcrafted reward shaping. In this paper, we describe an algorithm for action exploration and equilibrium approximation in games with combinatorial action spaces. This algorithm simultaneously performs value iteration while learning a policy proposal network. A double oracle step is used to explore additional actions to add to the policy proposals. At each state, the target state value and policy for the model training are computed via an equilibrium search procedure. Using this algorithm, we train an agent, DORA, completely from scratch for a popular two-player variant of Diplomacy and show that it achieves superhuman performance. Additionally, we extend our methods to full-scale no-press Diplomacy and for the first time train an agent from scratch with no human data. We present evidence that this agent plays a strategy that is incompatible with human-data bootstrapped agents. This presents the first strong evidence of multiple equilibria in Diplomacy and suggests that self play alone may be insufficient for achieving superhuman performance in Diplomacy.",
        "DOI": "NA",
        "affiliation_name": "Facebook Research",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "EXTRACTING URBAN DEPRIVATION INDICATORS USING SUPERSPECTRAL VERY-HIGH-RESOLUTION SATELLITE IMAGERY",
        "paper_author": "Georganos S.",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Most research pertaining to mapping deprived urban areas is limited to locating and delineating deprived area’s extents within and across cities. In this work, we go beyond and characterize deprived areas by utilizing a wide suit of remotely sensed predictors to map the intra-urban distribution of land cover (LC) in deprived communities in Nairobi, Kenya. We assess the contribution of WorldView-3 (WV-3) multispectral and shortwave infrared bands for the task of deprived urban areas land cover classification at a very-high-resolution scale. Our results highlight the potential of WV-3 to accurately map the LC while the potential of intra-urban transferability was shown to be satisfactory. Moreover, feature selection dramatically decreased the computational complexity of the LC models with no losses in classification accuracy. We propose a set of indicators such as the density of garbage piles to be extracted at an aggregated grid level. This aggregation helps characterize urban deprivation at a fine scale and assist local authorities and stakeholders in implementing evidence-based policy making.",
        "DOI": "10.1109/IGARSS47720.2021.9554849",
        "affiliation_name": "Universidad de Navarra",
        "affiliation_city": "Pamplona",
        "affiliation_country": "Spain"
    },
    {
        "paper_title": "Weather-Driven Predictive Control of a Battery Storage for Improved Microgrid Resilience",
        "paper_author": "Gutierrez-Rojas D.",
        "publication": "IEEE Access",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "This paper aims to introduce a predictive weather-based control policy for the microgrid energy management to improve the resilience of the microgrid. This policy relies on the application of machine learning models for the prediction of microgrid load demand and solar production and supply interruption in the upstream distribution network. The predictions serve as an input to multiobjective chance constraint optimization that balances the microgrid resilience and economic objectives based on the probability of a supply interruption. The interruption predictions are made with a decision-tree-based model that can predict an upcoming interruption in the distribution network with 78% of the maximum accuracy. The case study microgrid consisting of several customers, solar photovoltaic generation, and battery storage is applied to cluster areas located in Finland. Overall, the developed control policy shows an improvement in the daily resilience of the microgrid in regard to an interruption in the main grid when compared with economic dispatch only.",
        "DOI": "10.1109/ACCESS.2021.3133490",
        "affiliation_name": "Itä-Suomen yliopisto",
        "affiliation_city": "Kuopio",
        "affiliation_country": "Finland"
    },
    {
        "paper_title": "Population Studies at 75 years: An empirical review",
        "paper_author": "Mills M.C.",
        "publication": "Population Studies",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Population Studies advances research on fertility, mortality, family, migration, methods, policy, and beyond, yet it lacks a recent, rigorous review. We examine all papers published between 1947 and 2020 (N = 1,901) and their authors, using natural language processing, social network analysis, and mixed methods that combine unsupervised machine learning with qualitative coding. After providing a brief history, we map the evolution in authorship and papers towards shorter, multi-authored papers, also finding that females comprise 33.5 per cent of authorship across the period under study, with varied sex ratios across topics. Most papers examine fertility, mortality, and family, studying groups and change, but topics vary over time. Children are rarely studied, and research on women focuses on family planning, fertility decline, and unions, whereas key domains for research on men are migration, historical demography (war, famine), and employment. Research on Africa and Asia focuses on family planning, with work on fertility decline concentrated on North America and Europe, consistent with theories of demographic transition. Our resulting discussion identifies future directions for demographic research.",
        "DOI": "10.1080/00324728.2021.1996624",
        "affiliation_name": "University of Oxford",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Covid-19 mobility restrictions: impacts on urban air quality and health",
        "paper_author": "Mohajeri N.",
        "publication": "Buildings and Cities",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "In 2020, Covid-19-related mobility restrictions resulted in the most extensive human-made air-quality changes ever recorded. The changes in mobility are quantified in terms of outdoor air pollution (concentrations of PM2.5 and NO2 ) and the associated health impacts in four UK cities (Greater London, Cardiff, Edinburgh and Belfast). After applying a weather-corrected machine learning (ML) technique, all four cities show NO2 and PM2.5 concentration anomalies in 2020 when compared with the ML-predicted values for that year. The NO2 anomalies are –21% for Greater London, –19% for Cardiff, –27% for Belfast and –41% for Edinburgh. The PM2.5 anomalies are 7% for Greater London, –1% for Cardiff, –15% for Edinburgh, –14% for Belfast. All the negative anomalies, which indicate air pollution at a lower level than expected from the weather conditions, are attributable to the mobility restrictions imposed by the Covid-19 lockdowns. Spearman rank-order correlations show a significant correlation between the lowering of NO2 levels and reduction in public transport (p < 0.05) and driving (p < 0.05), which is associated with a decline in NO2-attributable mortality. These positive effects of the mobility restrictions on public health can be used to evaluate policies for improved outdoor air quality.",
        "DOI": "10.5334/bc.124",
        "affiliation_name": "The Bartlett Faculty of the Built Environment",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Incentivizing Truthfulness Through Audits in Strategic Classification",
        "paper_author": "Estonrell A.",
        "publication": "35th AAAI Conference on Artificial Intelligence, AAAI 2021",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "In many societal resource allocation domains, machine learning methods are increasingly used to either score or rank agents in order to decide which ones should receive either resources (e.g., homeless services) or scrutiny (e.g., child welfare investigations) from social services agencies. An agency’s scoring function typically operates on a feature vector that contains a combination of self-reported features and information available to the agency about individuals or households. This can create incentives for agents to misrepresent their self-reported features in order to receive resources or avoid scrutiny, but agencies may be able to selectively audit agents to verify the veracity of their reports. We study the problem of optimal auditing of agents in such settings. When decisions are made using a threshold on an agent’s score, the optimal audit policy has a surprisingly simple structure, uniformly auditing all agents who could benefit from lying. While this policy can, in general be hard to compute because of the difficulty of identifying the set of agents who could benefit from lying given a complete set of reported types, we also present necessary and sufficient conditions under which it is tractable. We show that the scarce resource setting is more difficult, and exhibit an approximately optimal audit policy in this case. In addition, we show that in either setting verifying whether it is possible to incentivize exact truthfulness is hard even to approximate. However, we also exhibit sufficient conditions for solving this problem optimally, and for obtaining good approximations.",
        "DOI": "10.1609/aaai.v35i6.16674",
        "affiliation_name": "College of Engineering and Computing",
        "affiliation_city": "Fairfax",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application Based Cigarette Detection on Social Media Platforms Using Machine Learning Algorithms",
        "paper_author": "Hashmi M.U.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Cigarette and e-cigarette advertisements often portray positive images of smoking behaviour, especially amongst younger generations. It portrays a lifestyle in which smoking cigarettes or e-cigarettes are normal and an important part of human lives. Images of cigarette smoking on social media platforms have played an influential role in encouraging people to smoke. There is a growing need of advanced mathematical models and machine learning techniques to monitor the portrayal of cigarette and e-cigarette use on social media platforms, as well as other harmful products to human health. In this study, we have annotated a set of 1,333 smoking images collected from a wide array of communication media. In addition, we evaluated three state-of-the-art segmentation algorithms including Mask R-CNN, Cascade Mask-R-CNN and Hybrid Task Cascade (HTC) by using the MMDetection framework to detect smoking images within our annotated dataset. The study plays an important role towards developing a practical monitoring system, which can inform policy actions to restrict unhealthy advertisements on social media and other related platforms. Finally, our evaluation results show that Mask R-CNN outperforms Cascade Mask RCNN and HTC in terms of Average Precision and Average Recall.",
        "DOI": "10.1007/978-3-030-91387-8_5",
        "affiliation_name": "Deakin University",
        "affiliation_city": "Geelong",
        "affiliation_country": "Australia"
    },
    {
        "paper_title": "Machine learning approach to COVID-19 epidemic process simulation using polynomial regression model",
        "paper_author": "Kapusta D.",
        "publication": "CEUR Workshop Proceedings",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The article presents an approach to modeling epidemic processes based on machine learning. A model is built based on the polynomial regression method. The simulation results allow us to calculate the predicted incidence of coronavirus infection in a certain area. The model has been shown to be accurate enough for use in public health policy-making settings. The disadvantage of using machine learning methods is the impossibility of identifying factors affecting the dynamics of the epidemic process. But, due to their high accuracy, such models can be used in an ensemble with agent-based and compartment models.",
        "DOI": "NA",
        "affiliation_name": "National Aerospace University “Kharkiv Aviation Institute”",
        "affiliation_city": "Kharkiv",
        "affiliation_country": "Ukraine"
    },
    {
        "paper_title": "Semantic detection of targeted attacks using doc2vec embedding",
        "paper_author": "El-Rahmany M.S.",
        "publication": "Journal of Communications Software and Systems",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The targeted attack is one of the social engineering attacks. The detection of this type of attack is considered a challenge as it depends on semantic extraction of the intent of the attacker. However, previous research has primarily relies on the Natural Language Processing or Word Embedding techniques that lack the context of the attacker's text message. Based on Sentence Embedding and machine learning approaches, this paper introduces a model for semantic detection of targeted attacks. This model has the advantage of encoding relevant information, which helps to improve the performance of the multi-class classification process. Messages will be categorized based on the type of security rule that the attacker has violated. The suggested model was tested using a dialogue dataset taken from phone calls, which was manually categorized into four categories. The text is pre-processed using natural language processing techniques, and the semantic features are extracted as Sentence Embedding vectors that are augmented with security policy sentences. Machine Learning algorithms are applied to classify text messages. The experimental results show that sentence embeddings with doc2vec achieved high prediction accuracy 96.8%. So, it outperformed the method applied to the same dialog dataset.",
        "DOI": "10.24138/jcomss-2021-0113",
        "affiliation_name": "Faculty of Computers and Artificial Intelligence",
        "affiliation_city": "Helwan",
        "affiliation_country": "Egypt"
    },
    {
        "paper_title": "Tree-based machine learning algorithms in the Internet of Things environment for multivariate flood status prediction",
        "paper_author": "Aswad F.M.",
        "publication": "Journal of Intelligent Systems",
        "citied_by": "37",
        "cover_date": "2021-01-01",
        "Abstract": "Floods are one of the most common natural disasters in the world that affect all aspects of life, including human beings, agriculture, industry, and education. Research for developing models of flood predictions has been ongoing for the past few years. These models are proposed and built-in proportion for risk reduction, policy proposition, loss of human lives, and property damages associated with floods. However, flood status prediction is a complex process and demands extensive analyses on the factors leading to the occurrence of flooding. Consequently, this research proposes an Internet of Things-based flood status prediction (IoT-FSP) model that is used to facilitate the prediction of the rivers flood situation. The IoT-FSP model applies the Internet of Things architecture to facilitate the flood data acquisition process and three machine learning (ML) algorithms, which are Decision Tree (DT), Decision Jungle, and Random Forest, for the flood prediction process. The IoT-FSP model is implemented in MATLAB and Simulink as development platforms. The results show that the IoT-FSP model successfully performs the data acquisition and prediction tasks and achieves an average accuracy of 85.72% for the three-fold cross-validation results. The research finding shows that the DT scores the highest accuracy of 93.22%, precision of 92.85, and recall of 92.81 among the three ML algorithms. The ability of the ML algorithm to handle multivariate outputs of 13 different flood textual statuses provides the means of manifesting explainable artificial intelligence and enables the IoT-FSP model to act as an early warning and flood monitoring system.",
        "DOI": "10.1515/jisys-2021-0179",
        "affiliation_name": "University of Bilad Alrafidain",
        "affiliation_city": "Baqubah",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "IFAC-PapersOnLine",
        "paper_author": "NA",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 29 papers. The topics discussed include: a novel machine learning approach for epilepsy diagnosis using EEG signals based on correlation dimension; a dynamic behavior of hyperglycemia model based on reaction-diffusion cellular nonlinear networks (RDCNN); macroeconomic model with monetary and fiscal policy and externality: nonlinear dynamics, optimization and control; jump resonance in electromechanical systems; managing expert knowledge in water network expansion project implementation; complexity of a Bertrand duopoly game with homogeneous expectations, quadratic cost functions and chaos control; the influence of individual natural frequency on the emergence of synchronous motion in coupled metronomes; and on synchronization of unidirectionally coupled multi-scroll systems: dynamic vs static interconnections.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Real-time energy optimization of hybrid electric vehicle in connected environment based on deep reinforcement learning",
        "paper_author": "He W.",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "In this paper, a real-time control method of hybrid electric vehicle is proposed based on rule-based speed planning and deep deterministic policy gradient (DDPG) energy management algorithm. This method can optimize fuel economy in real time based on all traffic information in a connected environment, and satisfy the constraints of driving safety and driving time. The results show that the proposed deep reinforcement learning algorithm DDPG can achieve lower fuel consumption. In addition, the proposed speed planning algorithm will not violate traffic rules and has good results.",
        "DOI": "10.1016/j.ifacol.2021.10.160",
        "affiliation_name": "Beijing Institute of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Enabling adaptable industry 4.0 automation with a modular deep reinforcement learning framework",
        "paper_author": "Raziei Z.",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Industry 4.0 envisions adaptable and resilient manufacturing and logistics operations capable of handling dynamic changes or deviations in operations using intelligent sensing and computation technologies. Recent advances in artificial intelligence and collaborative robotics have created unprecedented opportunities to fully automate a variety of industrial tasks such as material handling, assembly, machine tending, and inspection, among other. With the rapidly growing interest in the vision of lot-size-of-one, a fundamental and challenging question remains open: How can robots leverage the knowledge of previously-learned tasks to expedite their learning on new tasks? We tackle this problem by developing and testing a novel deep reinforcement learning framework with task modularization to enhance adaptability of collaborative robots in performing a multitude of simulated tasks. The framework is built upon the actor-critic method and the notion of task modularity, and is compared against the Soft Actor-Critic (SAC) algorithm as a baseline. Numerical experiments on the Meta-World dataset prove the ability of the proposed framework in improving the adaptability and efficiency of collaborative robots to new tasks through task modularization and transfer of policies from previously-learned task modules.",
        "DOI": "10.1016/j.ifacol.2021.08.168",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Boston",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Mechanism of citizen evaluation of policy using machine self-learning",
        "paper_author": "Tsyganov V.V.",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Public policy is designed to influence society. In turn, members of society - citizens should evaluate this policy so that society can control it. According to the concept of digital society, policy evaluation is based on artificial intelligence solutions, primarily machine learning. In addition, when monitoring politics by society, it is necessary to take into account the human factor. The article discusses theoretical and practical issues that arise when a citizen applies the machine learning procedure to determine alternative evaluations - ratings of a politician. In conditions of uncertainty, it is assumed that this politician knows his ability to meet the needs of society better than the citizen. Using this knowledge, the politician can manipulate own activities in order to get higher ratings today and in the future. Such undesirable activity can lead to the failure to use the available opportunities in which the citizen and society as a whole are interested. To solve this problem in conditions of uncertainty, a mechanism for citizen evaluation of politician is proposed. This mechanism includes the procedure of machine learning of dichotomy and the formation of alternative ratings of a politician. Sufficient conditions have been found for the synthesis of such a mechanism in which a politician fully uses the existing opportunities in the interests of the citizen and society as a whole. The functioning of this mechanism is illustrated by the example of an evaluation of the national policy on vaccination against COVID-19 in the UK. Such a mechanism encourages the politician to use all available opportunities in the public interest. The developed mechanism can be used by any citizen for permanent evaluation of policy using machine self-learning. For this, for example, such mechanism can be implemented as an application on a smart phone.",
        "DOI": "10.1016/j.ifacol.2021.10.428",
        "affiliation_name": "V. A. Trapeznikov Institute of Control Sciences, Russian Academy of Sciences",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "The road to ai literacy education: From pedagogical needs to tangible game design",
        "paper_author": "Zammit M.",
        "publication": "Proceedings of the European Conference on Games-based Learning",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "The advancement of artificial intelligence (AI) and its increased use in everyday life have exacerbated the need to understand its underlying processes, and to raise awareness about its shortcomings and faults. Consequently there has been an increased effort to teach basic concepts of AI and machine learning (ML) from an early age. Digital games have been shown to be effective as teaching and learning tools, and there are ongoing efforts to increase AI literacy through educational digital games. To this effect, this work describes the process followed to extrapolate the design of such an educational game directly from the pedagogical needs emerging from stakeholders. Seven focus groups and workshops were conducted in Greece, Malta and Norway, with 55 teachers, researchers, practitioners and policy-makers, and 22 primary and secondary education students in total. These workshops identified seven goals which informed the design of a game for AI literacy called ArtBot. The game design process and the final interface and gameplay loop of ArtBot are explained in relation to these goals. The game was subsequently deployed across a variety of platforms, to enable dissemination to a broad audience in classrooms and elsewhere. The game was part of the tools developed in the framework of the LearnML Erasmus+ project. A preliminary online survey was used to gauge how well the game was received by teachers and students, with an overall positive result. A longer-term data collection of the game usage statistics has been initiated and will be analysed over the course of the game dissemination.",
        "DOI": "10.34190/GBL.21.155",
        "affiliation_name": "L-Università ta' Malta",
        "affiliation_city": "Msida",
        "affiliation_country": "Malta"
    },
    {
        "paper_title": "The role of economic freedom in interpreting corruption perception",
        "paper_author": "Yangin G.",
        "publication": "International and Multidisciplinary Journal of Social Sciences",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "The main purpose of the study is to examine the nexus between corruption and economic freedom to determine the most influencing factors to be focused on to reduce corruption. With this aim, two different machine learning algorithms are performed to find out the single effect, two-way, and three-way interaction effects of factors affecting corruption. As a result of the analysis, tax burden, government integrity, and government spending are the main indicators to be focused on to improve corruption steadily. Besides, critical thresholds of the tax burden, government integrity, and government spending are 83.3, 50.9, and 40.6, respectively. Since there are a limited number of studies to predict corruption by machine learning algorithms in the extant literature, this research provides highly detailed information to policy-makers where they can focus on reducing corruption perception.",
        "DOI": "10.17583/rimcis.7109",
        "affiliation_name": "Yıldız Teknik Üniversitesi",
        "affiliation_city": "Istanbul",
        "affiliation_country": "Turkey"
    },
    {
        "paper_title": "A machine learning-based framework for data mining and optimization of a production system",
        "paper_author": "Koulinas G.",
        "publication": "Procedia Manufacturing",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "In the present paper, we performed several decision tree algorithms to classify instances and represent the most efficient policies depicted by a hybrid reinforcement learning algorithm and treat a complex production, maintenance and quality control optimization problem within a degrading manufacturing and remanufacturing system. The constructed decision trees contained of nodes, which represent its independent variables, and leaves that stand for the set of function values. All optimization parameters and optimal policies found by the hybrid reinforcement learning algorithm, used as the training set for the trees algorithms. After the construction of each tree, the resulting rule used to treat the optimization problem and the performance of each rule compared. In addition, for the best performing trees algorithms, further investigation performed for the impact of their parameters to its rule effectivity.",
        "DOI": "10.1016/j.promfg.2021.10.059",
        "affiliation_name": "Democritus University of Thrace",
        "affiliation_city": "Komotini",
        "affiliation_country": "Greece"
    },
    {
        "paper_title": "On differential drive robot learning convex policy with application to path-tracking",
        "paper_author": "Ribeiro A.M.",
        "publication": "IFAC-PapersOnLine",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "This paper presents an experimental validation of a learning convex policy for path-tracking on a differential drive robot. An online implementation of the convex control policy (COCP) is provided in the ROS environment using the CVXGEN package that runs on the on-board computer in a real-time application. The control policies are trained in an off-board computer considering a stochastic kinematic description of the robot and using an approximate gradient method for a given cost-to-go metric function. The policy is validated through simulation and experimental evaluation. In addition, to certify the training efficacy, the experiment is also evaluated using the untuned policy. A discussion regarding trajectory errors is presented as well as final considerations for the solver and real-time concerns.",
        "DOI": "10.1016/j.ifacol.2021.10.002",
        "affiliation_name": "Universidade Estadual de Campinas",
        "affiliation_city": "Campinas",
        "affiliation_country": "Brazil"
    },
    {
        "paper_title": "A Prediction-Based Cache Replacement Policy for Flash Storage",
        "paper_author": "Pham V.N.",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Replacement algorithms in most disk-based operating systems focus on optimizing memory hit counts. For flash storage, such algorithms would incur high replacement costs in terms of time and energy consumption because writing dirty pages to flash memory is costly. Thus, this work proposes an intelligent approach for efficiently balancing the trade-off between cache replacement costs and cache hit rate performance. Our logistic regression-based approach predicts future reference probabilities of pages in the cache to identify candidate pages for eviction. To ascertain our superiority of the proposed system, we conducted rigorous simulations based on online transaction processing workload traces. Simulation results shows that our approach outperforms state-of-the-art methods.",
        "DOI": "10.1007/978-981-16-8062-5_10",
        "affiliation_name": "SKKU College of Information and Communication Engineering",
        "affiliation_city": "Suwon",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Location-Aware and Budget-Constrained Service Brokering in Multi-Cloud via Deep Reinforcement Learning",
        "paper_author": "Shi T.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "Multi-cloud makes it possible to effectively utilize various cloud services provided by multiple cloud providers at different locations. To process the requests for latency-sensitive applications, cloud brokers must select proper cloud services in multi-cloud to minimize the network latency without running into the risk of over-spending. The problem of location-aware and budget-constrained service brokering in multi-cloud demands a machine learning approach to handle the highly dynamic requests. In this paper, we apply deep reinforcement learning to solve the problem. The proposed algorithm, named DeepBroker, can dynamically and adaptively select virtual machines in multi-cloud for new arriving requests at a global scale. Specifically, DeepBroker trains brokering policies by employing a deep Q-network combined with the newly designed state extractor and action executor. To ensure financial viability, we introduce a penalty-based reward function to prevent over-budget situations. Evaluation based on real-world datasets shows that DeepBroker can significantly outperform several commonly used heuristic-based algorithms in terms of network latency minimization and budget satisfaction.",
        "DOI": "10.1007/978-3-030-91431-8_52",
        "affiliation_name": "Technische Universität Clausthal",
        "affiliation_city": "Clausthal-Zellerfeld",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Using Data Science Approach to Explore Online Public Opinion: Strategic and War Risk Perceptions on the Internet",
        "paper_author": "Fu W.C.",
        "publication": "Mass Communication Research",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "The U.S. cross-Strait strategy is a focal indicator for influencing the status of Taiwan-China relationships. With U.S. armed force activities around Taiwan increasing, this research examines the influence of American Asia-Pacific strategies toward Taiwan on Taiwanese war risk perceptions and responses from the media. Believing that online responses by Taiwanese represent part of public opinion, we take an online public opinion mining approach to explore the topic modeling of online discussions over this issue. When discussing U.S. armed force activities around the Taiwan Strait, the findings show five major topics that Taiwan’s netizens focus on:(1) Taiwan-Sino-U.S. game;(2) activities for seeking independence;(3) strategic evaluation;(4) risk of war, and (5) policy on freedom of navigation. This article contributes to artificial intelligence, machine learning, and corpus approaches to present national strategic studies that previously mostly used constructed approaches. Regarding the theoretical applications, we provide a new research approach for risk communication on strategies studies, extending its theoretical scope to national strategic studies. Moreover, we demonstrate that online public opinion toward risk perceptions and military activities of the government can address the vital issue of public support toward national defense strategies. We also found that U.S. military activities influence Taiwanese people’s perception of war risk and negative emotions expressed online. This means that their online emotions significantly influence their propensity to support public policies. They also tend to confirm their negative feelings toward the PLA’s military activities.",
        "DOI": "10.30386/MCR.202109.0020",
        "affiliation_name": "National Defense University Taiwan",
        "affiliation_city": "Taoyuan",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "Sentiment classification for employees reviews using regression vectorstochastic gradient descent classifier (RV-SGDC)",
        "paper_author": "Gaye B.",
        "publication": "PeerJ Computer Science",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "The satisfaction of employees is very important for any organization to make sufficient progress in production and to achieve its goals. Organizations try to keep their employees satisfied by making their policies according to employees' demands which help to create a good environment for the collective. For this reason, it is beneficial for organizations to perform staff satisfaction surveys to be analyzed, allowing them to gauge the levels of satisfaction among employees. Sentiment analysis is an approach that can assist in this regard as it categorizes sentiments of reviews into positive and negative results. In this study, we perform experiments for the world's big six companies and classify their employees' reviews based on their sentiments. For this, we proposed an approach using lexicon-based and machine learning based techniques. Firstly, we extracted the sentiments of employees from text reviews and labeled the dataset as positive and negative using TextBlob. Then we proposed a hybrid/voting model named Regression Vector-Stochastic Gradient Descent Classifier (RV-SGDC) for sentiment classification. RV-SGDC is a combination of logistic regression, support vector machines, and stochastic gradient descent. We combined these models under a majority voting criteria. We also used other machine learning models in the performance comparison of RV-SGDC. Further, three feature extraction techniques: term frequency-inverse document frequency (TF-IDF), bag of words, and global vectors are used to train learning models. We evaluated the performance of all models in terms of accuracy, precision, recall, and F1 score. The results revealed that RV-SGDC outperforms with a 0.97 accuracy score using the TF-IDF feature due to its hybrid architecture. Subjects Algorithms and Analysis of Algorithms, Artificial Intelligence, Data Mining and Machine Learning, Natural Language and Speech",
        "DOI": "10.7717/peerj-cs.712",
        "affiliation_name": "University of Science and Technology Beijing",
        "affiliation_city": "Beijing",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Daily traffic count imputation for bicycle and pedestrian traffic: Comparing existing methods with machine learning approaches",
        "paper_author": "Roll J.",
        "publication": "Transportation Research Record",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Monitoring nonmotorized traffic is becoming increasingly common practice at local and state departments of transportation. These travel activity data are necessary to monitor the system and track progress toward active transportation policy and program goals. A common problem is that permanent count site data are often missing, making those sites less useful. Being able to accurately estimate those missing data records functionally increases the amount of data available to use by themselves as metrics for monitoring traffic but also makes available more data for factoring short-term sites. Using nonmotorized traffic counts from several cities in Oregon, this research compared the ability of day-of-year (DOY) factors, a statistical model, and machine learning algorithms to accurately impute daily traffic records for annual traffic estimation. Based on exhaustive cross-validation experiments using data not missing at random scenarios, this research concluded that random forest and DOY factor approaches could be used to impute daily counts for nonmotorized traffic but each approach comes with tradeoffs. Though for many missing data scenarios random forest performed best, this method is complicated to estimate and apply. DOY factor-based methods are simpler to create and apply, and though more accurate in scenarios with significant amounts of missing data, they were less flexible given the need for data from neighboring count sites. Negative binomial regression was also found to work well in scenarios with moderate to low amounts of missing data. This work can inform nonmotorized traffic count programs needing vetted solutions for traffic data imputation.",
        "DOI": "10.1177/03611981211027161",
        "affiliation_name": "Oregon Department of Transportation",
        "affiliation_city": "Salem",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Machine Learning Algorithm for Analysing Infant Mortality in Bangladesh",
        "paper_author": "Rahman A.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "The study aims to investigate the potential predictors associated with infant mortality in Bangladesh through machine learning (ML) algorithm. Data on infant mortality of 26145 children were extracted from the latest Bangladesh Demographic and Health Survey 2017–18. The Boruta algorithm was used to extract important features of infant mortality. We adapted decision tree, random forest, support vector machine and logistic regression approaches to explore predictors of infant mortality. Performances of these techniques were evaluated via parameters of confusion matrix and receiver operating characteristics curve. The proportion of infant mortality was 9.7% (2523 out of 26145). Age at first marriage, age at first birth, birth interval, place of residence, administrative division, religion, education of parents, body mass index, gender of child, children ever born, exposure of media, wealth index, birth order, occupation of mother, toilet facility and cooking fuel were selected as significant features of predicting infant mortality. Overall, the random forest (accuracy = 0.893, precision = 0.715, sensitivity = 0.339, specificity = 0.979, F1-score = 0.460, area under the curve: AUC = 0.6613) perfectly and authentically predicted the infant mortality compared with other ML techniques, including individual and interaction effects of predictors. The significant predictors may help the policy-makers, stakeholders and mothers to take initiatives against infant mortality by improving awareness, community-based educational programs and public health interventions.",
        "DOI": "10.1007/978-3-030-90885-0_19",
        "affiliation_name": "Jahangirnagar University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Assessing and predicting mobility improvement of integrating bike-sharing into multimodal public transport systems",
        "paper_author": "Kapuku C.",
        "publication": "Transportation Research Record",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "New shared mobility services have become increasingly common in many cities and shown potential to address urban transportation challenges. This study aims to analyze the mobility performance of integrating bike-sharing into multimodal transport systems and develop a machine learning model to predict the performance of intermodal trips with bike-sharing compared with those without bike-sharing for a given trip using transit smart card data and bike-sharing GPS data from the city of Seoul. The results suggest that using bike-sharing in the intermodal trips where it performs better than buses could enhance the mobility performance by providing up to 34% savings in travel time per trip compared with the scenarios in which bus is used exclusively for the trips and up to 33% savings when bike-sharing trips are used exclusively. The results of the machine learning models suggest that the random forest classifier outperformed three other classifiers with an accuracy of 90% in predicting the performance of bike-sharing and intermodal transit trips. Further analysis and applications of the mobility performance of bike-sharing in Seoul are presented and discussed.",
        "DOI": "10.1177/03611981211045071",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Imputing parking usage on sparsely monitored areas within amsterdam through the application of machine learning",
        "paper_author": "Schmidt J.",
        "publication": "Transportation Research Record",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Effective parking policy is essential for cities to reduce the demand their road networks experience and to combat their carbon footprints. Existing research in the application of machine learning to understand parking behavior assumes that cities have prohibitively expensive stationary parking sensors installed, while no research has yet attempted to use machine learning to impute for parking behavior using mobile probe data of sparsely monitored areas. To this end, this paper shows that it is indeed feasible to impute parking pressure (occupation as a percentage). Gradient boosted trees were found to perform the best with an R2 score of 0.20 and root mean squared error (RMSE) score of 0.087. This paper also found that three unique parking occupancy patterns exist in Amsterdam and that this information, in combination with neighborhood characteristics, has an impact on imputation under certain conditions.",
        "DOI": "10.1177/03611981211017141",
        "affiliation_name": "Vrije Universiteit Amsterdam",
        "affiliation_city": "Amsterdam",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Automatic data acquisition for deep learning",
        "paper_author": "Liu J.",
        "publication": "Proceedings of the VLDB Endowment",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "Deep learning (DL) has widespread applications and has revolutionized many industries. Although automated machine learning (AutoML) can help us away from coding for DL models, the acquisition of lots of high-quality data for model training remains a main bottleneck for many DL projects, simply because it requires high human cost. Despite many works on weak supervision (i.e., adding weak labels to seen data) and data augmentation (i.e., generating more data based on seen data), automatically acquiring training data, via smartly searching a pool of training data collected from open ML benchmarks and data markets, is not explored. In this demonstration, we demonstrate a new system, automatic data acquisition (AutoData), which automatically searches training data from a heterogeneous data repository and interacts with AutoML. It faces two main challenges. (1) How to search high-quality data from a large repository for a given DL task? (2) How does AutoData interact with AutoML to guide the search? To address these challenges, we propose a reinforcement learning (RL)-based framework in AutoData to guide the iterative search process. AutoData encodes current training data and feedbacks of AutoML, learns a policy to search fresh data, and trains in iterations. We demonstrate with two real-life scenarios, image classification and relational data prediction, showing that AutoData can select high-quality data to improve the model.",
        "DOI": "10.14778/3476311.3476333",
        "affiliation_name": "Qatar Computing Research Institute",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar"
    },
    {
        "paper_title": "Demo of marius: A system for large-scale graph embeddings",
        "paper_author": "Xie A.",
        "publication": "Proceedings of the VLDB Endowment",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Graph embeddings have emerged as the de facto representation for modern machine learning over graph data structures. The goal of graph embedding models is to convert high-dimensional sparse graphs into low-dimensional, dense and continuous vector spaces that preserve the graph structure properties. However, learning a graph embedding model is a resource intensive process, and existing solutions rely on expensive distributed computation to scale training to instances that do not fit in GPU memory. This demonstration showcases Marius: a new open-source engine for learning graph embedding models over billion-edge graphs on a single machine. Marius is built around a recently-introduced architecture for machine learning over graphs that utilizes pipelining and a novel data replacement policy to maximize GPU utilization and exploit the entire memory hierarchy (including disk, CPU, and GPU mem-ory) to scale to large instances. The audience will experience how to develop, train, and deploy graph embedding models using Marius’ configuration-driven programming model. Moreover, the audience will have the opportunity to explore Marius’ deployments on applications including link-prediction on WikiKG90M and reasoning queries on a paleobiology knowledge graph. Marius is available as open source software at https://marius-project.org.",
        "DOI": "10.14778/3476311.3476338",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Analysis of the regulatory, legal, and medical conditions for the prescription of mobile health applications in the united states, the european union, and france",
        "paper_author": "Hassanaly P.",
        "publication": "Medical Devices: Evidence and Research",
        "citied_by": "11",
        "cover_date": "2021-01-01",
        "Abstract": "Introduction: Mobile health (mHealth) is now considered an important approach to extend traditional health services and to meet the growing medical needs. The prescribability of mHealth applications is a complex problem because it depends on a large number of factors and concerns a wide range of disciplines and actors in the industrial, health, normative, and regulatory domains. Objective: Our study correlated data from the scientific literature with data on regulatory developments in the United States, the European Union, and France with the aim of identifying the conditions for the prescription of mHealth applications. Methods: The search method adopted was the systematic literature review process by Brereton et al. All empirical evidence from the relevant fields of study was gathered and then evaluated to answer our predefined research questions. The WoS and PubMed databases were queried for the period between 1 January 1975 and 30 November 2020. A total of 165 articles (15 with a direct focus and 150 with an indirect focus on mHealth prescribing) were analyzed/cross-referenced. The ScienceDirect database was consulted to complement the collected data when needed. Data published by international and national regulatory bodies were analyzed in light of the scientific data obtained from the WoS, PubMed, and ScienceDirect databases. Results: The International Medical Device Regulators Forum has ensured the international structuring of the regulatory field in collaboration with participating countries. The creation and updating of databases have allowed the tracking of medical device versions/upgrades and incidents. The regulatory organizations of the United States, the European Union, and France are currently consulting healthcare personnel, manufacturers, and patients to establish evaluation criteria for usability and quality of instructions for use that take into consideration patients’ level of literacy. These organizations are also providing support to manufacturers who wish to file marketing applications. Marketing, privacy, and cybersecurity measures are evolving with developments in technology and state cooperation policies. The prescription of mHealth applications will gain social acceptance only if consistency and coordination are ensured at all stages of the process: from pre-design, through verification of medical effectiveness, to ethical consideration during data collection and use, and on to marketing. Conclusion: The conditions for mHealth prescribability include the adaptation of international regulation by the different states, the state provision of marketing support, and the evaluation of mHealth applications. For mHealth to gain social acceptance, increased collaboration among physicians, manufacturers, and “information technology stakeholders” is needed. Once this is achieved, MHealth can become the cornerstone of successful health care reform.",
        "DOI": "10.2147/MDER.S328996",
        "affiliation_name": "Sciences Economiques et Sociales de la Santé et Traitement de l'Information Médicale",
        "affiliation_city": "Marseille",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Data augmentation for ml-driven data preparation and integration",
        "paper_author": "Li Y.",
        "publication": "Proceedings of the VLDB Endowment",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "In recent years, we have witnessed the development of novel data augmentation (DA) techniques for creating additional training data needed by machine learning based solutions. In this tutorial, we will provide a comprehensive overview of techniques developed by the data management community for data preparation and data integration. In addition to surveying task-specific DA operators that leverage rules, transformations, and external knowledge for creating additional training data, we also explore the advanced DA techniques such as interpolation, conditional generation, and DA policy learning. Finally, we describe the connection between DA and other machine learning paradigms such as active learning, pre-training, and weakly-supervised learning. We hope that this discussion can shed light on future research directions for a holistic data augmentation framework for high-quality dataset creation.",
        "DOI": "10.14778/3476311.3476403",
        "affiliation_name": "Facebook Research",
        "affiliation_city": "Menlo Park",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "SQL Injections and Reinforcement Learning: An Empirical Evaluation of the Role of Action Structure",
        "paper_author": "Del Verme M.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Penetration testing is a central problem in computer security, and recently, the application of machine learning techniques to this topic has gathered momentum. In this paper, we consider the problem of exploiting SQL injection vulnerabilities, and we represent it as a capture-the-flag scenario in which an attacker can submit strings to an input form with the aim of obtaining a flag token representing private information. We then model the attacker as a reinforcement learning agent that interacts with the server to learn an optimal policy leading to an exploit. We compare two agents: a simpler structured agent that relies on significant a priori knowledge and uses high-level actions; and a structureless agent that has limited a priori knowledge and generates SQL statements. The comparison showcases the feasibility of developing agents that rely on less ad-hoc modeling and illustrates a possible direction to develop agents that may have wide applicability.",
        "DOI": "10.1007/978-3-030-91625-1_6",
        "affiliation_name": "Montreal Institute for Learning Algorithms",
        "affiliation_city": "Montreal",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Machine-Learning-Based Control of Perturbed and Heated Channel Flows",
        "paper_author": "Rüttgers M.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "A reinforcement learning algorithm is coupled to a thermal lattice-Boltzmann method to control flow through a two-dimensional heated channel narrowed by a bump. The algorithm is allowed to change the disturbance factor of the bump and receives feedback in terms of the pressure loss and temperature increase between the inflow and outflow region of the channel. It is trained to modify the bump such that both fluid mechanical properties are rated equally important. After a modification, a new simulation is initialized using the modified geometry and the flow field computed in the previous run. The thermal lattice-Boltzmann method is validated for a fully developed isothermal channel flow. After 265 simulations, the trained algorithm predicts an averaged disturbance factor that deviates by less than 1 % from the reference solution obtained from 3,400 numerical simulations using a parameter sweep over the disturbance factor. The error is reduced to less than 0.1 % after 1,450 simulations. A comparison of the temperature, pressure, and streamwise velocity distributions of the reference solution with the solution after 1,450 simulations along the line of the maximum velocity component in streamwise direction shows only negligible differences. The presented method is hence a valid method for avoiding expensive parameter space explorations and promises to be effective in supporting shape optimizations for more complex configurations, e.g., in finding optimal nasal cavity shapes.",
        "DOI": "10.1007/978-3-030-90539-2_1",
        "affiliation_name": "Rheinisch-Westfälische Technische Hochschule Aachen",
        "affiliation_city": "Aachen",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Securing cloud from attacks: Machine learning based intrusion detection in cloud sensor networks",
        "paper_author": "Varghese M.",
        "publication": "Ad-Hoc and Sensor Wireless Networks",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "“Intrusion Detection System (IDS) is the most commonly used mechanism to detect attacks on cloud sensor networks. An IDS is a type of security system designed to automatically alert administrators when someone or something is trying to compromise information system through malicious activities or through security policy violations in cloud”. This paper aims to establish a new IDS model, based on Machine Learning (ML) technology in cloud networks. It consists of two phases, namely feature extraction and classification. During the feature extraction phase, the central tendency features, as well as proposed ordinal features, are extracted. The lower, as well as higher order statistical features are then subjected to classification process, which is processed using the “Deep Convolutional Neural Network (DCNN)” framework. The major contribution is to optimally tune the weight of DCNN using a hybrid algorithm that ensures a better detection rate. For optimization purposes, this work deploys the hybridized concepts of both the “Monarch Butterfly Optimization (MBO) and Moth Search Algorithm (MSA) algorithm” together termed as BM-MSA. Finally, the proposed method provided better outcomes when compared with other traditional methods.",
        "DOI": "NA",
        "affiliation_name": "Noorul Islam University",
        "affiliation_city": "Kanyakumari",
        "affiliation_country": "India"
    },
    {
        "paper_title": "AI, on the Law of the Elephant: Toward Understanding Artificial Intelligence",
        "paper_author": "de Siles E.L.",
        "publication": "Buffalo Law Review",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Machine learning and other artificial intelligence (AI) systems are changing our world in profound, exponentially rapid, and likely irreversible ways. Although AI may be harnessed for great good, it is capable of and is doing great harm at scale to people, communities, societies, and democratic institutions. The dearth of AI governance leaves unchecked AI's potentially existential risks. Whether sounding urgent alarm or merely jumping on the bandwagon, law scholars, law students, and lawyers at bar are contributing volumes of AI policy and legislative proposals, commentaries, doctrinal theories, and calls to corporate and international organizations for ethical AI leadership. Unfortunately, erroneous, incomplete, and overly simplistic treatments of AI technology undermine the utility of a significant portion of that literature. Moreover, many of those treatments are piecemeal, and those gaps produce barriers to the proper legal understanding of AI. Profound concerns exist about AI and the actual and potential crises of societal, democratic, and individual harm that it causes or may cause in future. On the whole, the legal community is not currently equal to the task of addressing those concerns, lacking sufficient AI knowledge and technological competence, despite ethical mandates for diligence and competence. As a result, law and policy debates and subsequent actions may be fundamentally flawed or produce devastating unintended consequences because they relied upon erroneous, uninformed, or misconceived understandings of AI technologies, inputs, and processes. Like the elephant in the ancient Jain parable, the wise ones may conceive of only a fraction of the AI creature and some more or less blindly. Now more than ever, lawyers need to be able to see around critically important corners. The general lack of understanding about AI technology robs the legal profession of that foresight. This state of affairs also raises significant ethical concerns. Worse, it undermines lawyers' power, authority, and legitimacy to bring forward truly valid, meaningful ideas and solutions to prevent AI from becoming humanity's apex predator. This Article responds with several descriptive and theoretical contributions. As to its descriptive contributions, it aims to correct and augment the record about AI, particularly machine learning and its underlying technologies and processes. It endeavors to present a concisely and accessibly stated foundational, but sufficiently comprehensive, single-source explanation. The Article draws extensively from the scientific and technical literatures and undertakes an important interdisciplinary translational process by which to map the AI technical lexicon to legal terms of art and constructions in patent and other cases. Because their understanding is foundational, the Article drills down on three principal AI inputs: data, including data curation; statistical models; and algorithms. It then engages in illustrative issue-spotting within these AI factual frames, sketching out some of the many legal implications associated with those vital understandings. Toward its theoretical contributions, the Article presents two conceptual sortings of AI and introduces a systems- and process-engineering-inspired taxonomy of AI. First, it categorizes AI by the degree of human involvement in and, conversely, the degree of AI autonomy in AI-mediated decision-making. Second, it conceptualizes AI as being static or dynamic. Those distinctions are vital to AI's potential for harm, meaningful accountability, and, ultimately, the proper prioritization of AI governance efforts. Third, the Article briefly introduces a taxonomy that conceptualizes AI as a human-machine enterprise made up of series of processes. By perceiving “the whole of the AI elephant,” the role of human decision-making and its limits may be understood, and the human-machine enterprise that is AI and its constituent processes may be deconstructed, comprehended, and framed for subsequent scholarship, doctrinal and procedural analyses, and law and policy developments. With these, the Article hopes to help inform and empower lawyers to improve the security, justness, and well-being of people in the increasingly algorithmic world.",
        "DOI": "NA",
        "affiliation_name": "Howard University",
        "affiliation_city": "Washington, D.C.",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "SimGAN: Hybrid Simulator Identification for Domain Adaptation via Adversarial Reinforcement Learning",
        "paper_author": "Jiang Y.",
        "publication": "Proceedings - IEEE International Conference on Robotics and Automation",
        "citied_by": "37",
        "cover_date": "2021-01-01",
        "Abstract": "As learning-based approaches progress towards automating robot controllers design, transferring learned policies to new domains with different dynamics (e.g. sim-to-real transfer) still demands manual effort. This paper introduces SimGAN, a framework to tackle domain adaptation by identifying a hybrid physics simulator to match the simulated trajectories to the ones from the target domain, using a learned discriminative loss to address the limitations associated with manual loss design. Our hybrid simulator combines neural networks and traditional physics simulation to balance expressiveness and generalizability, and alleviates the need for a carefully selected parameter set in System ID. Once the hybrid simulator is identified via adversarial reinforcement learning, it can be used to refine policies for the target domain, without the need to interleave data collection and policy refinement. We show that our approach outperforms multiple strong baselines on six robotic locomotion tasks for domain adaptation.",
        "DOI": "10.1109/ICRA48506.2021.9561731",
        "affiliation_name": "Stanford Engineering",
        "affiliation_city": "Stanford",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Hybrid Cryptographic Model Using AES and RSA for Sensitive Data Privacy Preserving",
        "paper_author": "Basapur S.B.",
        "publication": "Webology",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "In the present scenario, big data is facing many challenges regarding the data privacy and data security. Nowadays, new laws and regulations like GDPR is required for companies to define privacy policies complying with the preferences of their users. This type of regulations prevents the disclosure of sensitive data of users, even if occurs accidentally. In this research, a hybrid cryptographic model based on AES and RSA is proposed to identify and mask the sensitive data to identify many threats to information confidentiality. A hybrid cryptography algorithm in the context of masking is proposed to effectively transfer big data through the cloud. The hybrid algorithm is created by combining more than one algorithm. This algorithm enables the user to select the data to be masked and encrypted. For protecting data stored in the cloud, the proposed hybrid algorithm includes RSA and AES. Along with these algorithms, the multilayer perceptron neural network is used for key generation and key exchange. A credit card client’s dataset from the UCI machine learning repository is used for the evaluation. From the dataset the sensitive attributes are selected using the depth first search (DFS) technique. The sender encrypts the data using the RSA algorithm and a key to create masked data using public key. The AES algorithm is used to encrypt the RSA key. The encrypted key and masked data are then sent to the receiver. To decrypt the RSA key, the receiver uses the AES decryption. Finally, the decrypted RSA key is used by the receiver to translate the masked data back to the original data with private key. The proposed model obtained the overall accuracy of 95.23% accuracy and an average computational time of 300 nano secs.",
        "DOI": "10.14704/WEB/V18SI05/WEB18219",
        "affiliation_name": "University Visvesvaraya College of Engineering",
        "affiliation_city": "Bengaluru",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Data-driven inferences of agency-level risk and response communication on COVID-19 through social media-based interactions",
        "paper_author": "Ahmed M.A.",
        "publication": "Journal of Emergency Management",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "Risk perception and risk averting behaviors of public agencies in the emergence and spread of COVID-19 can be retrieved through online social media (Twitter), and such interactions can be echoed in other information outlets. This study collected time-sensitive online social media data and analyzed patterns of health risk communication of public health and emergency agencies in the emergence and spread of novel coronavirus using data-driven methods. The major focus is toward understanding how policy-making agencies communicate risk and response information through social media during a pandemic and influence community response-ie, timing of lockdown, timing of reopening, etc.-and disease outbreak indicators-ie, number of confirmed cases and number of deaths. Twitter data of six major public organizations (1,000-4,500 tweets per organization) are collected from February 21, 2020 to June 6, 2020. Several machine learning algorithms, including dynamic topic model and sentiment analysis, are applied over time to identify the topic dynamics over the specific timeline of the pandemic. Organizations emphasized on various topics-eg, importance of wearing face mask, home quarantine, understanding the symptoms, social distancing and contact tracing, emerging community transmission, lack of personal protective equipment, COVID-19 testing and medical supplies, effect of tobacco, pandemic stress management, increasing hospitalization rate, upcoming hurricane season, use of convalescent plasma for COVID-19 treatment, maintaining hygiene, and the role of healthcare podcast in different timeline. The findings can benefit emergency management, policymakers, and public health agencies to identify targeted information dissemination policies for public with diverse needs based on how local, federal, and international agencies reacted to COVID-19.",
        "DOI": "10.5055/jem.0589",
        "affiliation_name": "FIU College of Engineering and Computing",
        "affiliation_city": "Miami",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Improved machine learning algorithms for optimizing coherent pulse stacking amplification",
        "paper_author": "Du W.",
        "publication": "Optics InfoBase Conference Papers",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "We apply momentum stochastic parallel gradient descent (MSPGD) and policy gradient algorithms to optimize coherent pulse stacking (CPS), and demonstrate their increased effectiveness compared to traditionally used stochastic parallel gradient descent (SPGD) algorithm.",
        "DOI": "NA",
        "affiliation_name": "University of Michigan, Ann Arbor",
        "affiliation_city": "Ann Arbor",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Effectiveness of family policy in Russia: Evidence-based approach",
        "paper_author": "Kapoguzov E.A.",
        "publication": "Terra Economicus",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Family policy in Russia, is based on a “narrow” demographic interpretation that neglects policy effectiveness and impact of state support on fertility indicators. This gap can be addressed using the evidence-based approach, which embraces both the influence of public policies on fertility, and human capital. The paper discusses the theoretical underpinnings of policy based on the Becker-Barreau and Baldrin-Jones concepts. We show the importance of incorporating “Big Data” into family policy analysis to address the problem of data completeness and analytical information for family policy needs. We rely on A. Sagradov’s ideas about quantitative determination of population reproduction patterns with non-demographic processes, including institutional changes and transformation of economic mechanisms of family policy. We estimated the demographic result per unit of budget expenditures in Russia (based on empirical data from EMISS and the Federal Treasury for 86 regions from 2011 to 2021, with a breakdown by months). The “random forest” method is used to identify the key factors influencing the results of the machine learning model, and to demonstrate the significance of parameters for assessing the socio-economic effectiveness of family policy in Russia. The research findings indirectly confirm the pro-natalist nature of family policy in Russia, the effectiveness of which is ensured by economic mechanisms of direct cash payments to the population. The paper concludes with a discussion of the prospects for using an evidence-based approach to family policy in Russia.",
        "DOI": "10.18522/2073-6606-2021-19-3-20-36",
        "affiliation_name": "Institute of Economics and Industrial Engineering of the Siberian Branch of the RAS",
        "affiliation_city": "Novosibirsk",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Argumentation schemes: From genetics to international relations to environmental science policy to AI ethics",
        "paper_author": "Green N.L.",
        "publication": "Argument and Computation",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Argumentation schemes have played a key role in our research projects on computational models of natural argument over the last decade. The catalogue of schemes in Walton, Reed and Macagno's 2008 book, Argumentation Schemes, served as our starting point for analysis of the naturally occurring arguments in written text, i.e., text in different genres having different types of author, audience, and subject domain (genetics, international relations, environmental science policy, AI ethics), for different argument goals, and for different possible future applications. We would often first attempt to analyze the arguments in our corpora in terms of those schemes, then adapt schemes as needed for the goals of the project, and in some cases implement them for use in computational models. Among computational researchers, the main interest in argumentation schemes has been for use in argument mining by applying machine learning methods to existing argument corpora. In contrast, a primary goal of our research has been to learn more about written arguments themselves in various contemporary fields. Our approach has been to manually analyze semantics, discourse structure, argumentation, and rhetoric in texts. Another goal has been to create sharable digital corpora containing the results of our studies. Our approach has been to define argument schemes for use by human corpus annotators or for use in logic programs for argument mining. The third goal is to design useful computer applications based upon our studies, such as argument diagramming systems that provide argument schemes as building blocks. This paper describes each of the various projects: the methods, the argument schemes that were identified, and how they were used. Then a synthesis of the results is given with a discussion of open issues.",
        "DOI": "10.3233/AAC-210551",
        "affiliation_name": "The University of North Carolina at Greensboro",
        "affiliation_city": "Greensboro",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "GRIDDED URBAN DEPRIVATION PROBABILITY FROM OPEN OPTICAL IMAGERY AND DUAL-POL SAR DATA",
        "paper_author": "Vanhuysse S.",
        "publication": "International Geoscience and Remote Sensing Symposium (IGARSS)",
        "citied_by": "10",
        "cover_date": "2021-01-01",
        "Abstract": "With rapid urbanization leading to the proliferation of deprived urban areas (often referred to as “slums”) in sub-Saharan Africa, there is a growing number of city dwellers living in inadequate housing conditions and being exposed to multiple hazards. In this context, Earth Observation has the potential for filling gaps in spatial data availability and thereby support evidence-based policy making. We assess the potential of free open-source software, open dual-pol SAR and optical imagery (Sentinel-1 and Sentinel-2), and open global datasets for producing accurate city-scale maps of areas having morphological characteristics of deprivation. Implementing a grid-based machine learning approach, we evaluate different combinations of spectral and spatial Sentinel features, and features from global data. The results show that a high accuracy can be reached with the best combinations. Since publishing maps with hard labels (e.g., deprived vs. non-deprived areas) could raise ethical concerns or even lead to misuses, the output is provided as gridded morphological deprivation probability maps.",
        "DOI": "10.1109/IGARSS47720.2021.9554231",
        "affiliation_name": "Faculty of Geo-Information Science and Earth Observation – ITC",
        "affiliation_city": "Enschede",
        "affiliation_country": "Netherlands"
    },
    {
        "paper_title": "Multivariable regression and gradient boosting algorithms for energy prediction in the radial-axial ring rolling (rarr) process",
        "paper_author": "Mirandola I.",
        "publication": "ESAFORM 2021 - 24th International Conference on Material Forming",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Energy prediction and starvation have become an essential part of process planning for the XXI century manufacturing industry due to cost-saving policies and environmental regulations. To this aim, the research presented in this paper details how machine learning-based algorithms can be an effective way to predict and minimize the energy consumptions in the widely spread radial-axial ring rolling (RARR) process. To analyze this bulk metal forming process, 380 numerical simulations have been developed using the commercial SW Simufact Forming 15 and considering three largely utilized materials, the 42CrMo4 steel, the IN 718 superalloy, and the AA6082 aluminum alloy. To create the database for both multi-variable regression and machine learning models, ring outer diameters ranging from 650 mm to 2000 mm and various process conditions including different sets of tool speeds and initial temperatures have been considered. For the case of the multi-variable regression model, to account for all the cross-influences between all the parameters, a second-order function including 26 parameters has been developed, resulting in a reasonable average accuracy (94 %) but also in an impractical huge equation. On the other hand, the machine learning model based on the Gradient Boosting (GB) approach allows obtaining a similar accuracy (96 %) but its compact form allows a more practical utilization and its training can be expanded almost indefinitely, by adding more results from both numerical simulations and experiments. The proposed approach allows to quickly and precisely predict the energy consumption in the RARR process and can be extended to other manufacturing processes.",
        "DOI": "10.25518/esaform21.3775",
        "affiliation_name": "Sogang University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea"
    },
    {
        "paper_title": "Lattice: A Vision for Machine Learning, Data Engineering, and Policy Considerations for Digital Agriculture at Scale",
        "paper_author": "Chaterji S.",
        "publication": "IEEE Open Journal of the Computer Society",
        "citied_by": "24",
        "cover_date": "2021-01-01",
        "Abstract": "Digital agriculture, with the incorporation of Internet-of-Things (IoT)-based technologies, presents the ability to control a system at multiple levels (individual, local, regional, and global) and generates tools that allow for improved decision making and higher productivity. Recent advances in IoT hardware, e.g., networks of heterogeneous embedded devices, and software, e.g., lightweight computer vision algorithms and cloud optimization solutions, make it possible to efficiently process data from diverse sources in a connected (smart) farm. By interconnecting these IoT devices, often across large geographical distances, it is possible to collect data at different time scales, including in near real-time (i.e., with delays of only a few tens of seconds). This data can then be used for actionable insights, e.g., precise applications of soil supplements and reduced environmental footprint. Through LATTICE, we present an integrated vision for IoT solutions, data processing, and actionable analytics for digital agriculture. We couple this with discussion of economics and policy considerations that will underlie adoption of such IoT and ML technologies. Our paper starts off with the types of datasets in typical field operations, followed by the lifecycle for the data and storage, cloud and edge analytics, and fast information-retrieval solutions. We discuss what algorithms are proving to be most impactful in this space, e.g., approximate data analytics and on-device/in-network processing. We conclude by discussing analytics for alternative agriculture for generation of biofuels and policy challenges in the implementation of digital agriculture in the wild.",
        "DOI": "10.1109/OJCS.2021.3085846",
        "affiliation_name": "Microsoft Research",
        "affiliation_city": "Redmond",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Carbon price prediction for China's ETS pilots using variational mode decomposition and optimized extreme learning machine",
        "paper_author": "Chai S.",
        "publication": "Annals of Operations Research",
        "citied_by": "23",
        "cover_date": "2021-01-01",
        "Abstract": "With the national goal of “carbon peak by 2030 and carbon neutral by 2060 in China”, studies on carbon prices of China’s Emissions Trading System (ETS) pilots have shown growing interest in the related fields. Carbon price fluctuations reflect the scarcity of carbon resources, and accurate prediction can improve carbon asset management capabilities. Therefore, in order to clarify the dynamics of carbon markets and assign carbon emissions allocation rationally, we propose a hybrid feature-driven forecasting model with the framework of decomposition-reconstruction-prediction-ensemble. In this paper, the non-stationary, nonlinear and chaotic characteristics of carbon prices in China’s ETS pilots have been verified, and then the prediction model is built based on the tested features. Firstly, the original carbon price series are decomposed by Variational Mode Decomposition (VMD), and then reconstructed by Sample Entropy (SE). Next, Extreme Learning Machine (ELM) optimized by Particle Swarm Optimization (PSO) is conducted to predict the subsequences. Lastly, the forecasting series of every subseries are summed to obtain the final results. The empirical results based on carbon prices of China’s ETS pilots proved that the proposed model performs more efficiently than the current benchmark models. As carbon prices are expected to increase across all ETS during the post-COVID-19 recovery stage, the new prediction model will be useful for improving the guiding principles of the existing government policies including the likely introductions of Border Carbon Adjustment (BCA) in the EU and the US, and governing the large global public companies to deliver their “net zero” commitments.",
        "DOI": "10.1007/s10479-021-04392-7",
        "affiliation_name": "Dalian University of Technology",
        "affiliation_city": "Dalian",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Human-aware reinforcement learning for fault recovery using contextual gaussian processes",
        "paper_author": "McGuire S.",
        "publication": "Journal of Aerospace Information Systems",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "This work addresses the iterated nonstationary assistant selection problem, in which over the course of repeated interactions on a mission, an autonomous robot experiencing a fault must select a single human from among a group of assistants to restore it to operation. The assistants in our problem have a level of performance that changes as a function of their experience solving the problem. Our approach uses reinforcement learning via a multi-arm bandit formulation to learn about the capabilities of each potential human assistant and decide which human to task. This study, which is built on our past work, evaluates the potential for a Gaussian-process-based machine learning method to effectively model the complex dynamics associated with human learning and forgetting. Application of our method in simulation shows that our method is capable of tracking performance of human-like dynamics for learning and forgetting. Using a novel selection policy called the proficiency window, it is shown that our technique can outperform baseline selection strategies while providing guarantees on human use. Our work offers an effective potential alternative to dedicated human supervisors, with application to any human–robot system where a set of humans is responsible for overseeing autonomous robot operations.",
        "DOI": "10.2514/1.I010921",
        "affiliation_name": "University of California, Santa Cruz",
        "affiliation_city": "Santa Cruz",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Application of Deep Learning in Satellite Image-based Land Cover Mapping in Africa Challenges, Emerging Solutions and Prospects: A Review",
        "paper_author": "Lynda N.O.",
        "publication": "International Journal of Advanced Computer Science and Applications",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Deep Learning Networks (DLN), in particular, Convolutional Neural Networks (CNN) has achieved state-of-the-art results in various computer vision tasks including automatic land cover classification from satellite images. However, despite its remarkable performance and broad use in developed countries, using this advanced machine learning algorithm has remained a huge challenge in developing continents such as Africa. This is because the necessary tools, techniques, and technical skills needed to utilize DL networks are very scarce or expensive. Recently, new approaches to satellite image-based land cover classification with DL have yielded significant breakthroughs, offering novel opportunities for its further development and application. This can be taken advantage of in low resources continents such as Africa. This paper aims to review some of these notable challenges to the application of DL for satellite image-based classification tasks in developing continents. Then, review the emerging solutions as well as the prospects of their use. Harnessing the power of satellite data and deep learning for land cover mapping will help many of the developing continents make informed policies and decisions to address some of its most pressing challenges including urban and regional planning, environmental protection and management, agricultural development, forest management and disaster and risks mitigation.",
        "DOI": "10.14569/IJACSA.2021.0120948",
        "affiliation_name": "Nile University of Nigeria",
        "affiliation_city": "Abuja",
        "affiliation_country": "Nigeria"
    },
    {
        "paper_title": "Adaptive Sampling for Best Policy Identification in Markov Decision Processes",
        "paper_author": "Al Marjani A.",
        "publication": "Proceedings of Machine Learning Research",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "We investigate the problem of best-policy identification in discounted Markov Decision Processes (MDPs) when the learner has access to a generative model. The objective is to devise a learning algorithm returning the best policy as early as possible. We first derive a problem-specific lower bound of the sample complexity satisfied by any learning algorithm. This lower bound corresponds to an optimal sample allocation that solves a non-convex program, and hence, is hard to exploit in the design of efficient algorithms. We then provide a simple and tight upper bound of the sample complexity lower bound, whose corresponding nearly-optimal sample allocation becomes explicit. The upper bound depends on specific functionals of the MDP such as the sub-optimality gaps and the variance of the next-state value function, and thus really captures the hardness of the MDP. Finally, we devise KLB-TS (KL Ball Track-and-Stop), an algorithm tracking this nearly-optimal allocation, and provide asymptotic guarantees for its sample complexity (both almost surely and in expectation). The advantages of KLB-TS against state-of-the-art algorithms are discussed and illustrated numerically.",
        "DOI": "NA",
        "affiliation_name": "Unité de Mathématiques Pures et Appliquées de l'ENS de Lyon",
        "affiliation_city": "Lyon",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Vision-based reinforcement learning for lane-tracking control",
        "paper_author": "Kalapos A.",
        "publication": "Acta IMEKO",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "The present study focused on vision-based end-to-end reinforcement learning in relation to vehicle control problems such as lane following and collision avoidance. The controller policy presented in this paper is able to control a small-scale robot to follow the right-hand lane of a real two-lane road, although its training has only been carried out in a simulation. This model, realised by a simple, convolutional network, relies on images of a forward-facing monocular camera and generates continuous actions that directly control the vehicle. To train this policy, proximal policy optimization was used, and to achieve the generalisation capability required for real performance, domain randomisation was used. A thorough analysis of the trained policy was conducted by measuring multiple performance metrics and comparing these to baselines that rely on other methods. To assess the quality of the simulation-to-reality transfer learning process and the performance of the controller in the real world, simple metrics were measured on a real track and compared with results from a matching simulation. Further analysis was carried out by visualising salient object maps.",
        "DOI": "10.21014/ACTA_IMEKO.V10I3.1020",
        "affiliation_name": "Budapest University of Technology and Economics",
        "affiliation_city": "Budapest",
        "affiliation_country": "Hungary"
    },
    {
        "paper_title": "Better Effectiveness of Multi-Integrated Neural Networks: Take Stock Big Data as an Example",
        "paper_author": "Lu H.L.",
        "publication": "Wireless Communications and Mobile Computing",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "With the development of big data, in the financial market, the stock price prediction has many research directions from the perspective of big data. The classical time series prediction model cannot adapt to the high-latitude information of stock data in the era of big data. The development of deep learning provides a new idea for high-latitude stock data prediction. Four neural network models and three integrated learning models form different strategy sets, and the opening price of the next timestamp is predicted by backtracking information over the past 15 days with the characteristics of 12 indexes of the stock. The experimental results show that the prediction effect of the integration model based on the average weight policy and stacking policy is better than that of the single neural network, and the integration model based on stacking policy is expected to have the highest prediction accuracy and the minimum expected error. The accuracy was 80.2%, and the mean square error was 0.024. Compared with the single model, the accuracy is increased by 2%7%, and the error is reduced by 0.010.03. The innovation of this article lies in the traditional machine learning thinking is applied to deep learning, as an individual with a variety of neural network to study, through the integration of learning strategies, fusion for the integration model, the experimental results show that the effect of the integrated model is better than that of a single model, to improve the robustness and accuracy of the model; the performance of the integrated model is more stable. For the utilization of big data resources, the integrated model of neural network has better prediction effect.",
        "DOI": "10.1155/2021/3938409",
        "affiliation_name": "Zhengzhou University",
        "affiliation_city": "Zhengzhou",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Benchmarking statistical modelling approaches with multi-source remote sensing data for millet yield monitoring: a case study of the groundnut basin in central Senegal",
        "paper_author": "Gbodjo Y.J.E.",
        "publication": "International Journal of Remote Sensing",
        "citied_by": "5",
        "cover_date": "2021-01-01",
        "Abstract": "In Sub-Saharan Africa, smallholder farms play a key role in agriculture, occupying most of the agricultural land. Design policies for increasing smallholder productivity remains a safe way to establish sustainable food systems and boost local economies. However, efforts are still needed in order to achieve accurate and timely monitoring in smallholder farming systems. With the advent of modern Earth Observation programmes such as the Sentinel satellites, which provide quasi-synchronous and high-resolution multi-source information over any area of the continental surfaces, new opportunities are opened up to accurately map crop yields in smallholder farming systems. This study intends to estimate and forecast millet yields in central Senegal, making the use of multi-source (synthetic-aperture radar (SAR) and optical) image time series and state-of-the-art machine learning models. A Random Forest (RF) model explained up to 50% of the millet yield variability, while deep learning models such as Convolutional Neural Network (CNN) showed promise results but performed lower. We also found that the concatenation of SAR polarizations and vegetation indices improved our crop yield modelling, but such improvement was tightly related to the modelling approach, namely RF and CNN. Using RF to forecast millet yields, we achieved stable and satisfactory accuracy 2 weeks before the harvest period.",
        "DOI": "10.1080/01431161.2021.1993465",
        "affiliation_name": "Université de Montpellier",
        "affiliation_city": "Montpellier",
        "affiliation_country": "France"
    },
    {
        "paper_title": "Rosella: A Self-Driving Distributed Scheduler for Heterogeneous Clusters",
        "paper_author": "Wu Q.",
        "publication": "Proceedings - 2021 17th International Conference on Mobility, Sensing and Networking, MSN 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Large-scale interactive web services and advanced AI applications make sophisticated decisions in real-time, based on executing a massive amount of computation tasks on thousands of servers. Task schedulers, which often operate in heterogeneous and volatile environments, require high throughput, i.e., scheduling millions of tasks per second, and low latency, i.e., incurring minimal scheduling delays for millisecond-level tasks. Scheduling is further complicated by other users' workloads in a shared system, other background activities, and the diverse hardware configurations inside datacenters.We present Rosella, a new self-driving, distributed approach for task scheduling in heterogeneous clusters. Rosella automatically learns the compute environment and adjusts its scheduling policy in real-time. The solution provides high throughput and low latency simultaneously because it runs in parallel on multiple machines with minimum coordination and only performs simple operations for each scheduling decision. Our learning module monitors total system load and uses the information to dynamically determine optimal estimation strategy for the backends' compute-power. Rosella generalizes power-of-two-choice algorithms to handle heterogeneous workers, reducing the max queue length of O(logn) obtained by prior algorithms to O(logn). We evaluate Rosella with a variety of workloads on a 32-node AWS cluster. Experimental results show that Rosella significantly reduces task response time, and adapts to environment changes quickly.",
        "DOI": "10.1109/MSN53354.2021.00073",
        "affiliation_name": "William Mary",
        "affiliation_city": "Willaimsbrg",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "A Hybrid Deep Learning Technique for Personality Trait Classification from Text",
        "paper_author": "Ahmad H.",
        "publication": "IEEE Access",
        "citied_by": "46",
        "cover_date": "2021-01-01",
        "Abstract": "Recently, Cognitive-based Sentiment Analysis with emphasis on automatic detection of user behaviour, such as personality traits, based on online social media text has gained a lot of attention. However, most of the existing works are based on conventional techniques, which are not sufficient to get promising results. In this research work, we propose a hybrid Deep Learning-based model, namely Convolutional Neural Network concatenated with Long Short-Term Memory, to show the effectiveness of the proposed model for 8 important personality traits (Introversion-Extroversion, Intuition-Sensing, Thinking-Feeling, Judging-Perceiving). We implemented our experimental evaluations on the benchmark dataset to accomplish the personality trait classification task. Evaluations of the datasets have shown better results, which demonstrates that the proposed model can effectively classify the user's personality traits as compared to the state-of-the-art techniques. Finally, we evaluate the effectiveness of our approach through statistical analysis. With the knowledge obtained from this research, organizations are capable of making their decisions regarding the recruitment of personals in an efficient way. Moreover, they can implement the information obtained from this research as best practices for the selection, management, and optimization of their policies, services, and products.",
        "DOI": "10.1109/ACCESS.2021.3121791",
        "affiliation_name": "Univerzita J. Selyeho",
        "affiliation_city": "Komarom",
        "affiliation_country": "Slovakia"
    },
    {
        "paper_title": "The Ethics of AI in Health Care: A Mapping Review",
        "paper_author": "Morley J.",
        "publication": "Philosophical Studies Series",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched (Scopus, Google Scholar, Philpapers, Web of Science, Pub Med), in April 2019, to support the following research question: “how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be ‘ethically mindful?’”. A series of screening stages were carried out—for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)—yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. This article contributes to the debate on AI in health care by offering a comprehensive analysis of the relevant literature, focusing on the ethical implications for individuals, interpersonal relationships, groups, institutions, societies and the health sector as a whole. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new ‘AI winter’ could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care.",
        "DOI": "10.1007/978-3-030-81907-1_18",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Artificial Intelligence Crime: An Interdisciplinary Analysis of Foreseeable Threats and Solutions",
        "paper_author": "King T.C.",
        "publication": "Philosophical Studies Series",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "Artificial Intelligence (AI) research and regulation seek to balance the benefits of innovation against any potential harms and disruption. However, one unintended consequence of the recent surge in AI research is the potential re-orientation of AI technologies to facilitate criminal acts, term in this article AI-Crime (AIC). AIC is theoretically feasible thanks to published experiments in automating fraud targeted at social media users, as well as demonstrations of AI-driven manipulation of simulated markets. However, because AIC is still a relatively young and inherently interdisciplinary area—spanning socio-legal studies to formal science—there is little certainty of what an AIC future might look like. This article offers the first systematic, interdisciplinary literature analysis of the foreseeable threats of AIC, providing ethicists, policy-makers, and law enforcement organisations with a synthesis of the current problems, and a possible solution space.",
        "DOI": "10.1007/978-3-030-81907-1_13",
        "affiliation_name": "Oxford Social Sciences Division",
        "affiliation_city": "Oxford",
        "affiliation_country": "United Kingdom"
    },
    {
        "paper_title": "Reinforcement Learning Approach for Dynamic Pricing",
        "paper_author": "Balashov M.",
        "publication": "Studies on Entrepreneurship, Structural Change and Industrial Dynamics",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "With the introduction of digital technologies, it becomes easier for customers to compare prices and choose the product that is most profitable for them, this leads to instability of demand, which means that there is a need for market players to review pricing policies in favor of one that could take into account the characteristics of producer’s resources and current demand status. Dynamic pricing seems to be an adequate solution to the problem, as it is adaptive to customer expectations. In addition, with the digitalization of the economy, unique opportunities arise for using this apparatus. The purpose of this study is to evaluate the possibility of applying the concept of dynamic pricing to traditional retail. The goal of solving the dynamic pricing problem in the framework of this study is to maximize profits from the sale of a specific associated product at an automatic gas station. To solve this problem, the authors propose using machine learning approaches that adapt to the external environment, one of which is reinforcement learning (RL). At the same time, an approach is proposed to restore the demand surface for subsequent training of the agent.",
        "DOI": "10.1007/978-3-030-59959-1_8",
        "affiliation_name": "Saint Petersburg National Research University of Information Technologies, Mechanics and Optics University ITMO",
        "affiliation_city": "Saint Petersburg",
        "affiliation_country": "Russian Federation"
    },
    {
        "paper_title": "Reinforcement Learning Based Production Control of Semi-automated Manufacturing Systems",
        "paper_author": "Overbeck L.",
        "publication": "Procedia CIRP",
        "citied_by": "16",
        "cover_date": "2021-01-01",
        "Abstract": "In an environment which is marked by an increasing speed of changes, industrial companies have to be able to quickly adapt to new market demands and innovative technologies. This leads to a need for continuous adaption of existing production systems and the optimization of their production control. To tackle this problem digitalization of production systems has become essential for new and existing systems. Digital twins based on simulations of real production systems allow the simplification of analysis processes and, thus, a better understanding of the systems, which leads to broad optimization possibilities. In parallel, machine learning methods can be integrated to process the numerical data and discover new production control strategies. In this work, these two methods are combined to derive a production control logic in a semi-automated production system based on the chaku-chaku principle. A reinforcement learning method is integrated into the digital twin to autonomously learn a superior production control logic for the distribution of tasks between the different workers on a production line. By analyzing the influence of different reward shaping and hyper-parameter optimization on the quality and stability of the results obtained, the use of a well-configured policy-based algorithm enables an efficient management of the workers and the deduction of an optimal production control logic for the production system. The algorithm manages to define a control logic that leads to an increase in productivity while having a stable task assignment so that a transfer to daily business is possible. The approach is validated in the digital twin of a real assembly line of an automotive supplier. The results obtained suggest a new approach to optimizing production control in production lines. Production control shall be centered directly on the workers' routines and controlled by artificial intelligence infused with a global overview of the entire production system.",
        "DOI": "10.1016/j.procir.2021.10.027",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany"
    },
    {
        "paper_title": "Meta-Optimization of Bias-Variance Trade-Off in Stochastic Model Learning",
        "paper_author": "Aotani T.",
        "publication": "IEEE Access",
        "citied_by": "12",
        "cover_date": "2021-01-01",
        "Abstract": "Model-based reinforcement learning is expected to be a method that can safely acquire the optimal policy under real-world conditions by using a stochastic dynamics model for planning. Since the stochastic dynamics model of the real world is generally unknown, a method for learning from state transition data is necessary. However, model learning suffers from the problem of bias-variance trade-off. Conventional model learning can be formulated as a minimization problem of expected loss. Failure to consider higher-order statistics for loss would lead to fatal errors in long-term model prediction. Although various methods have been proposed to explicitly handle bias and variance, this paper first formulates a new loss function, especially for sequential training of the deep neural networks. To explicitly consider the bias-variance trade-off, a new multi-objective optimization problem with the augmented weighted Tchebycheff scalarization, is proposed. In this problem, the bias-variance trade-off can be balanced by adjusting a weight hyperparameter, although its optimal value is task-dependent and unknown. We additionally propose a general-purpose and efficient meta-optimization method for hyperparameter(s). According to the validation result on each epoch, the proposed meta-optimization can adjust the hyperparameter(s) towards the preferred solution simultaneously with model learning. In our case, the proposed meta-optimization enables the bias-variance trade-off to be balanced for maximizing the long-term prediction ability. Actually, the proposed method was applied to two simulation environments with uncertainty, and the numerical results showed that the well-balanced bias and variance of the stochastic model suitable for the long-term prediction can be achieved.",
        "DOI": "10.1109/ACCESS.2021.3125000",
        "affiliation_name": "Nara Institute of Science and Technology",
        "affiliation_city": "Ikoma",
        "affiliation_country": "Japan"
    },
    {
        "paper_title": "Prediction of patient willingness to recommend hospital: A machine learning-based exploratory study",
        "paper_author": "Vyas P.",
        "publication": "27th Annual Americas Conference on Information Systems, AMCIS 2021",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "Health organizations are diligently working to achieve the zenith in service outcome and furtherance of patient satisfaction by embracing patient-centric policies. Patient recommendation is a critical indicator of patient satisfaction and hospital service quality. Evidence suggests that patient recommendation is the most valuable form of marketing. However, hospitals often encounter patients' unwillingness to recommend them. Prior studies mainly rely on patient survey data to determine factors that impact patients' willingness to recommend hospitals. Our study aims to identify factors that are not readily available in the patient surveys but have significant impact on hospital recommendation. Our proposed Machine Learning (ML) based model has incorporated multidimensional approach by identifying various affecting factors related to diverse hospital services for predicting the patient willingness to recommend the hospital. These factors will help providers to ameliorate quality of their services and implement more proactive measures that elevate hospital recommendations. Our results have shown that Random Forest (RF) to be the best technique for the prediction of hospital recommendation with a 0.08 RMSE and 0.59 adjusted R2. We have found that ED throughput, preventive care, and patient satisfaction related factors play a crucial role in influencing the patient's decision to recommend the hospital.",
        "DOI": "NA",
        "affiliation_name": "Dakota State University",
        "affiliation_city": "Madison",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Dual Water Choices: The Assessment of the Influential Factors on Water Sources Choices Using Unsupervised Machine Learning Market Basket Analysis",
        "paper_author": "Tiyasha T.",
        "publication": "IEEE Access",
        "citied_by": "15",
        "cover_date": "2021-01-01",
        "Abstract": "An unsupervised machine learning model of association rule known as market basket analysis is proposed in this study to analyze the influence of various socio-economic factors on the choice of the water source. Data of 51 socio-economic factors collected from 295 individuals living in 65 households in Ambo city in the Oromia region of Ethiopians were used for this purpose. The results revealed (i) 64% of the family preferred multiple water sources (i.e., public tap and river water), (ii) the water was collected females in 92% of the households, and (iii) majority of people preferred bathing and laundering in the river (support = 32% and confidence = 87%). Direct utilization of river water is not a preferable choice for the user since it may lead to severe health issues and cause water pollution from bathing and laundering. Education and monthly income have a significant impact on the choices of water sources. Local management authorities can improve sanitation and public health management using the results obtained in the study. The paper only gives a glimpse of the important factors that should be considered for improving the way of life for the underdeveloped areas of the world using advanced machine learning techniques.",
        "DOI": "10.1109/ACCESS.2021.3124817",
        "affiliation_name": "Al-Ayen Iraqi University, AUIQ",
        "affiliation_city": "An Nasiriyah",
        "affiliation_country": "Iraq"
    },
    {
        "paper_title": "Modeling of landscape change and tele-coupling in local socioecological systems: A simulation of land use change and recreational activities in Southern Idaho, United States",
        "paper_author": "Huang L.",
        "publication": "Simulation Series",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The modeling of landscape change and socio-ecological systems (SES) tends to ignore the interactions across distance and boundaries. To fill the gap, this research analyzes landscape change by considering the tele-coupling effects at the local scale between Owyhee county and Treasure Valley in Idaho, United States. The spatial distribution of recreational activities in Owyhee county are modeled by Integrated Valuation of Ecosystem Services and Tradeoffs (InVEST). Land use and cover change (LUCC) are simulated using Multi-Layer Perceptron Neural Network (MLPNN). Results show that the tele-coupling effects have significant impacts on the nature-based recreation in Owyhee county. With the tele-coupling effects, MLPNN has achieved a high overall accuracy and kappa coefficient in LUCC. The findings suggest that the tele-coupling effects should be incorporated into the modeling of landscape change and SES. This study also provides policy implications for land management and stakeholder involvement in accommodating landscape change.",
        "DOI": "NA",
        "affiliation_name": "University of Idaho",
        "affiliation_city": "Moscow",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "20th Mexican International Conference on Artificial Intelligence, MICAI 2021",
        "paper_author": "NA",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 58 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Supervised Learning Approach for Section Title Detection in PDF Scientific Articles; towards a Pareto Front Shape Invariant Multi-Objective Evolutionary Algorithm Using Pair-Potential Functions; mexican Stock Return Prediction with Differential Evolution for Hyperparameter Tuning; COVID-19 on the Time, Countries Deaths Monitoring and Comparison Dealing with the Pandemic; Facing a Pandemic: A COVID-19 Time Series Analysis of Vaccine Impact; continual Learning for Multi-camera Relocalisation; urban Perception: Can We Understand Why a Street Is Safe?; real Time Distraction Detection by Facial Attributes Recognition; artificial Organic Networks Approach Applied to the Index Tracking Problem; touchless Fingerphoto Extraction Based on Deep Learning and Image Processing Algorithms; A Preview; performance Evaluation of Artificial Neural Networks Applied in the Classification of Emotions; Deep Learning Architectures Applied to Mosquito Count Regressions in US Datasets; DBSCAN Parameter Selection Based on K-NN; a Machine Learning Approach for Modeling Safety Stock Optimization Equation in the Cosmetics and Beauty Industry; comparing Machine Learning Based Segmentation Models on Jet Fire Radiation Zones; finding Significant Features for Few-Shot Learning Using Dimensionality Reduction; identifying Optimal Clusters in Purchase Transaction Data; Endowing the MIA Cloud Autoscaler with Adaptive Evolutionary and Particle Swarm Multi-Objective Optimization Algorithms; linear Structures Identification in Images Using Scale Space Radon Transform and Multiscale Image Hessian; machine Learning Algorithms Based on the Classification of Motor Imagination Signals Acquired with an Electroencephalogram; causal Based Action Selection Policy for Reinforcement Learning; seasonality Atlas of Solar Radiation in Mexico; preface.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "20th Mexican International Conference on Artificial Intelligence, MICAI 2021",
        "paper_author": "NA",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 58 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Supervised Learning Approach for Section Title Detection in PDF Scientific Articles; towards a Pareto Front Shape Invariant Multi-Objective Evolutionary Algorithm Using Pair-Potential Functions; mexican Stock Return Prediction with Differential Evolution for Hyperparameter Tuning; COVID-19 on the Time, Countries Deaths Monitoring and Comparison Dealing with the Pandemic; Facing a Pandemic: A COVID-19 Time Series Analysis of Vaccine Impact; continual Learning for Multi-camera Relocalisation; urban Perception: Can We Understand Why a Street Is Safe?; real Time Distraction Detection by Facial Attributes Recognition; artificial Organic Networks Approach Applied to the Index Tracking Problem; touchless Fingerphoto Extraction Based on Deep Learning and Image Processing Algorithms; A Preview; performance Evaluation of Artificial Neural Networks Applied in the Classification of Emotions; Deep Learning Architectures Applied to Mosquito Count Regressions in US Datasets; DBSCAN Parameter Selection Based on K-NN; a Machine Learning Approach for Modeling Safety Stock Optimization Equation in the Cosmetics and Beauty Industry; comparing Machine Learning Based Segmentation Models on Jet Fire Radiation Zones; finding Significant Features for Few-Shot Learning Using Dimensionality Reduction; identifying Optimal Clusters in Purchase Transaction Data; Endowing the MIA Cloud Autoscaler with Adaptive Evolutionary and Particle Swarm Multi-Objective Optimization Algorithms; linear Structures Identification in Images Using Scale Space Radon Transform and Multiscale Image Hessian; machine Learning Algorithms Based on the Classification of Motor Imagination Signals Acquired with an Electroencephalogram; causal Based Action Selection Policy for Reinforcement Learning; seasonality Atlas of Solar Radiation in Mexico; preface.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Predicting the Death of Road Accidents in Bangladesh Using Machine Learning Algorithms",
        "paper_author": "Siddik M.A.B.",
        "publication": "Communications in Computer and Information Science",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Road accidents are now a common occurrence in our country. Every year thousands of people die in these accidents and thousands of people are crippled and cursed. Recently the level of road accidents has increased drastically. In this research paper, the authors discuss previous road accident history profoundly and predict death by applying the machine learning algorithm to get appropriate accuracy in Bangladesh. In this study, we had applied four classification models such as Decision Tree, K-Nearest Neighbors (KNN), Naïve Bayes and Logistic Regression to predict the death of road accidents in Bangladesh. The model was constructed, trained, and tested using the data from “Prothom Alo” newspaper, from which we collected 1237 road crash incidents. This research would be helpful for the policymakers and stakeholders related to the road to take the future steps with the highest accuracy of 88% in the Decision tree algorithm.",
        "DOI": "10.1007/978-3-030-88244-0_16",
        "affiliation_name": "Daffodil International University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh"
    },
    {
        "paper_title": "Research and Implementation of the Text Matching Algorithm in the Field of Housing Law and Policy Based on Deep Learning",
        "paper_author": "Xu Y.",
        "publication": "Complexity",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "Machine learning enables machines to learn rules from a large amount of data input from the outside world through algorithms, so as to identify and judge. It is the main task of the government to further emphasize the importance of improving the housing security mechanism, expand the proportion of affordable housing, increase financial investment, improve the construction quality of affordable housing, and ensure fair distribution. It can be seen that the legal system of housing security is essentially a system to solve the social problems brought by housing marketization, and it is an important part of the whole national housing system. More and more attention has been paid to solving the housing difficulties of low- and middle-income people and establishing a housing security legal system suitable for China's national conditions and development stage. Aiming at the deep learning problem, a text matching algorithm suitable for the field of housing law and policy is proposed. Classifier based on matching algorithm is a promising classification technology. The research on the legal system of housing security is in the exploratory stage, involving various theoretical and practical research studies. Compare the improved depth learning algorithm with the general algorithm, so as to clearly understand the advantages and disadvantages of the improved depth learning algorithm and depth learning algorithm. This paper introduces the practical application of the deep learning model and fast learning algorithm in detail. Creatively put forward to transform it into an independent public law basis or into an independent savings system.",
        "DOI": "10.1155/2021/3165600",
        "affiliation_name": "East China University of Political Science and Law",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Causal Based Action Selection Policy for Reinforcement Learning",
        "paper_author": "Feliciano-Avelino I.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Reinforcement learning (RL) is the de facto learning by interaction paradigm within machine learning. One of the intrinsic challenges of RL is the trade-off between exploration and exploitation. To solve this problem, in this paper, we propose to improve the reinforcement learning exploration process with an agent that can exploit causal relationships of the world. A causal graphical model is used to restrict the search space by reducing the actions that an agent can take through graph queries that check which variables are direct causes of the variables of interest. Our main contributions are a framework to represent causal information and an algorithm to guide the action selection process of a reinforcement learning agent, by querying the causal graph. We test our approach on discrete and continuous domains and show that using the causal structure in the Q-learning action selection step, leads to higher jump-start reward and stability. Furthermore, it is also shown that a better performance is obtained even with partial and spurious relationships in the causal graphical model.",
        "DOI": "10.1007/978-3-030-89817-5_16",
        "affiliation_name": "Instituto Nacional de Astrofisica Optica y Electronica",
        "affiliation_city": "Puebla",
        "affiliation_country": "Mexico"
    },
    {
        "paper_title": "Predicting at-risk university students based on their e-book reading behaviours by using machine learning classifiers",
        "paper_author": "Chen C.H.",
        "publication": "Australasian Journal of Educational Technology",
        "citied_by": "29",
        "cover_date": "2021-01-01",
        "Abstract": "Providing early predictions of academic performance is necessary for identifying at-risk students and subsequently providing them with timely intervention for critical factors affecting their academic performance. Although e-book systems are often used to provide students with teaching/learning materials in university courses, seldom has research made the early prediction based on their online reading behaviours by implementing machine learning classifiers. This study explored to what extent university students’ academic achievement can be predicted, based on their reading behaviours in an e-book supported course, using the classifiers. It further investigated which of the features extracted from the reading logs influence the predictions. The participants were 100 first-year undergraduates enrolled in a compulsory course at a university in Taiwan. The results suggest that logistic regression Gaussian naïve Bayes, supports vector classification, decision trees, and random forests, and neural networks achieved moderate prediction performance with accuracy, precision, and recall metrics. Furthermore, the Bayes classifier identified almost all at-risk students. Additionally, student online reading behaviours affecting the prediction models included: turning pages, going back to previous pages and jumping to other pages, adding/deleting markers, and editing/removing memos. These behaviours were significantly positively correlated to academic achievement and should be encouraged during courses supported by e-books. Implications for practice or policy: • For identifying at-risk students, educators could prioritise using Gaussian naïve Bayes in an e-book supported course, as it shows almost perfect recall performance. • Assessors could give priority to logistic regression and neural networks in this context because they have stable achievement prediction performance with different evaluation metrics. • The prediction models are strongly affected by student online reading behaviours, in particular by locating/returning to relevant pages and modifying markers.",
        "DOI": "10.14742/ajet.6116",
        "affiliation_name": "Asia University",
        "affiliation_city": "Taichung",
        "affiliation_country": "Taiwan"
    },
    {
        "paper_title": "3rd International Conference on Science of Cyber Security, SciSec 2021",
        "paper_author": "NA",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 18 papers. The special focus in this conference is on Science of Cyber Security. The topics include: An Event-Based Parameter Switching Method for Controlling Cybersecurity Dynamics; dismantling Interdependent Networks Based on Supra-Laplacian Energy; simulations of Event-Based Cyber Dynamics via Adversarial Machine Learning; stochastic Simulation Techniques for Inference and Sensitivity Analysis of Bayesian Attack Graphs; multi-granularity Mobile Encrypted Traffic Classification Based on Fusion Features; Caps-LSTM: A Novel Hierarchical Encrypted VPN Network Traffic Identification Using CapsNet and LSTM; SARR: A Cybersecurity Metrics and Quantification Framework (Keynote); a Data-Free Approach for Targeted Universal Adversarial Perturbation; a Multi-level Elastic Encryption Protection Model; preface; DWT-DQFT-Based Color Image Blind Watermark with QR Decomposition; using Chinese Natural Language to Configure Authorization Policies in Attribute-Based Access Control System; protecting Data Privacy in Federated Learning Combining Differential Privacy and Weak Encryption; a New Method for Inferring Ground-Truth Labels and Malware Detector Effectiveness Metrics; botnet Detection Based on Multilateral Attribute Graph; mining Trojan Detection Based on Multi-dimensional Static Features.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Sentiment Nowcasting During the COVID-19 Pandemic",
        "paper_author": "Miliou I.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "In response to the COVID-19 pandemic, governments around the world are taking a wide range of measures. Previous research on COVID-19 has focused on disease spreading, epidemic curves, measures to contain it, confirmed cases, and deaths. In this work, we sought to explore another essential aspect of this pandemic, how do people feel and react to this reality and the impact on their emotional well-being. For that reason, we propose using epidemic indicators and government policy responses to estimate the sentiment, as this is expressed on Twitter. We develop a nowcasting approach that exploits the time series of epidemic indicators and the measures taken in response to the COVID-19 outbreak in the United States of America to predict the public sentiment at a daily frequency. Using machine learning models, we improve the short-term forecasting accuracy of autoregressive models, revealing the value of incorporating the additional data in the predictive models. We then provide explanations to the indicators and measures that drive the predictions for specific dates. Our work provides evidence that data about the way COVID-19 evolves along with the measures taken in response to the COVID-19 outbreak can be used effectively to improve sentiment nowcasting and gain insights into people’s current emotional state.",
        "DOI": "10.1007/978-3-030-88942-5_17",
        "affiliation_name": "Stockholms universitet",
        "affiliation_city": "Stockholm",
        "affiliation_country": "Sweden"
    },
    {
        "paper_title": "Acquiring and processing movement information from various sources using intelligent AI cognitive model for sports activities",
        "paper_author": "Guo Y.",
        "publication": "International Journal of Technology Management",
        "citied_by": "3",
        "cover_date": "2021-01-01",
        "Abstract": "The overarching purpose of this research is to demonstrate the value of artificial intelligence (AI) strategies in sports for utilising weight lifting policies. In specific, the work centred on the use of pattern recognition techniques to test training system exercises conducted for weight lifting policies. To quantify critical displacement and strength, the determinants during workouts has the data acquisitions that have been carried out using optimised force sensors linked with different weight machines. Consequently, certain essential properties such as time intervals or travel rates may be deduced based on the data collected using artificial intelligence (AI) techniques. These parameters have been used to create smart methods that adapt traditional machine learning principles for automatic evaluation of the exercise technique and provide adequate feedback. The obtained modelling results showed good performance and forecast results, which indicated the feasibility and the capacity of AI techniques when automatically measuring performance on weight training equipment has been analysed.",
        "DOI": "10.1504/IJTM.2021.118317",
        "affiliation_name": "Shandong University",
        "affiliation_city": "Jinan",
        "affiliation_country": "China"
    },
    {
        "paper_title": "Using Demographic Pattern Analysis to Predict COVID-19 Fatalities on the US County Level",
        "paper_author": "Mueller K.",
        "publication": "Digital Government: Research and Practice",
        "citied_by": "7",
        "cover_date": "2021-01-01",
        "Abstract": "Unlike pandemics in the past, COVID-19 has hit us in the midst of the information age. We have built vast capabilities to collect and store data of any kind that can be analyzed in myriad ways to help us mitigate the impact of this catastrophic disease. Specifically for COVID-19, data analysis can help local governments to plan the allocation of testing kits, testing stations, and primary care units, and it can help them in setting guidelines for residents, such as the need for social distancing, the use of face masks, and when to open local businesses that enable human contact. Further, it can also lead to a better understanding of pandemics in general and so inform policy makers on the regional and national level. All of this can save both cost and lives. In this article, we show the results of an ongoing study we conducted using a prominent regularly updated dataset. We used a pattern mining engine we developed to find specific characteristics of US counties that appear to expose them to higher COVID-19 mortality. Furthermore, we also show that these characteristics can be used to predict future COVID-19 mortality.",
        "DOI": "NA",
        "affiliation_name": "Akai Kaeru Llc",
        "affiliation_city": "Stony Brook",
        "affiliation_country": "United States"
    },
    {
        "paper_title": "Fraud detection in health insurance claims using machine learning and deep learning techniques",
        "paper_author": "Akshatha P.",
        "publication": "12th International Conference on Advances in Computing, Control, and Telecommunication Technologies, ACT 2021",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "A claim is what a doctor or hospital submits to the insurance company so they can get paid. A health insurance claim is a request that a health insurance policyholder submits to the Insurance Company in order to get the services that are covered in their health insurance policy.To tackle the problem of fraud in the medical insurance claims, health insurance companies make use of traditional rule-base models, but these models do not suffice anymore due to several factors such as the large volume of claims to be processed which makes the medical billing process prone to error, slow and sometimes inefficient. Hence there is a need to develop a novel fraud detection model for insurance claims processing. In this paper we are using the power of Machine Learning(ML) and Deep Learning(DL) algorithms to efficiently identify the fraudulent health insurance claims from the healthcare transaction dataset. Here we have considered a data set consisting of both legitimate and fraudulent claims. Initially we have implemented ML algorithms like SVM(Support Vector Machine), Logistic regression and Random forest for detection of anomalies and classification of health insurance claims into legitimate and fraudulent claims. Also DL algorithm MLP (Multilayer perceptron) is implemented. We have measured various metrics like Accuracy, Recall, Precision etc., for evaluating the performance of these ML and DL algorithms. All the models are good, but comparatively MLP has better performance with highest accuracy of 88.6 %. Study is also performed by varying the number of fraudulent records for the initial data set. This model helps in easy detection of the occurrence of fraudulent activities also is capable of fair fraud identification when applied to datasets with different fraud occurrence rates. The model can be used for decreased fraudulent activities in health insurance claims, it can become an efficient and effective application for Insurance clients and companies.",
        "DOI": "NA",
        "affiliation_name": "Siddaganga Institute of Technology",
        "affiliation_city": "Tumkur",
        "affiliation_country": "India"
    },
    {
        "paper_title": "Safe Adaptive Deep Reinforcement Learning for Autonomous Driving in Urban Environments. Additional Filter? How and Where?",
        "paper_author": "Alighanbari S.",
        "publication": "IEEE Access",
        "citied_by": "4",
        "cover_date": "2021-01-01",
        "Abstract": "Autonomous driving (AD) provides a reliable solution for safe driving by replacing human drivers responsible for the majority of accidents. The emergence of Machine Learning, specifically Deep Reinforcement Learning (DRL), and its ability to solve complex games proved its potential to address AD challenges. However, model-free methods still suffer from safety-related issues that can be resolved using safe-DRL approaches. The addition of model-based safety filters to the learning-based algorithms provides safety bounds on their performance and constraint satisfaction. In this paper, we investigate the addition of a safety filter based on Model Predictive Control and show an increase in mean testing episode reward by 110% from -75 mean episode reward during testing for 50 episodes for Deep Deterministic Policy Gradient ( $DDPG$ ) to 7.758. We study the impacts of safety filters (7.758 mean reward), heuristic rules, bounded additive noises (0.49% performance increase comparing to noise-free case), and exploration (3.425 mean reward) on the learning algorithm. We compare the effects of filters in the context of simulated exploration and bounded exploration and prove that bounded exploration results in 9.86% increase in mean reward and 12.95% decrease in std comparing to the other method. Additionally, inspired by Deep Internal Learning and biological mechanisms like brain plasticity, we investigate the idea of using each sample for training only once instead of utilizing stochastic batches which increases the mean testing accumulated reward by 1.87% and leads to the best performance (7.942 mean reward and 0.048 std). Finally, the results demonstrate better automotive results for our proposed method than DDPG. Our proposed method, DDPG with safety filter in bounded exploration and adaptive learning under noisy input conditions, has a success rate of 100% under different traffic densities for the simulation environment used in this paper and our assumptions. The proposed method's automotive results are shown for a braking scenario to avoid collision with other road users.",
        "DOI": "10.1109/ACCESS.2021.3119915",
        "affiliation_name": "University of Waterloo",
        "affiliation_city": "Waterloo",
        "affiliation_country": "Canada"
    },
    {
        "paper_title": "Do machine learning models hold the key to better money demand forecasting?",
        "paper_author": "Ghosh T.",
        "publication": "International Symposia in Economic Theory and Econometrics",
        "citied_by": "1",
        "cover_date": "2021-01-01",
        "Abstract": "Significant evidence in the literature points to money demand instability and therefore inaccurate forecasting. In view of this issue, this chapter seeks to use a method, innovative for money demand literature, that is, the machine learning model to predict money demand. Specifically, this chapter uses Random Forest Regression to predict money demand using monthly data in the Indian context over the period April-1996 to December-2018 using the variables usually used in literature. The chapter finds that in money demand prediction, the Random Forest Regression performs fairly well. The results are also compared to traditional models and it is found that the Random Forest Regression model has the potential to enhance the prediction of money demand over what traditional models predicts.",
        "DOI": "10.1108/S1571-03862021000029A017",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Evaluation of public procurement efficiency of the eu countries using preference learning topsis method",
        "paper_author": "Milosavljevic M.",
        "publication": "Economic Computation and Economic Cybernetics Studies and Research",
        "citied_by": "6",
        "cover_date": "2021-01-01",
        "Abstract": "Holding governments accountable for public procurement efficiency has been high on the agenda of public finance practitioners in the last few decades. The European Commission has developed a set of value-for-money indicators for public procurements within the Single Market Scoreboard. Although this matrix is actively used to rank countries, a number of downsides have been hitherto reported. This paper proposes preference learning (a machine learning method) for criteria weight estimation in combination with Technique for Order Performance by Similarity to Ideal Solution (as a multi criteria decision making technique) to re-evaluate the public procurement performance of the EU countries. This approach can be used for unbiased ex-post evaluations and focus of efforts and resources on critically important public procurement policies.",
        "DOI": "10.24818/18423264/55.3.21.12",
        "affiliation_name": "University of Belgrade",
        "affiliation_city": "Belgrade",
        "affiliation_country": "Serbia"
    },
    {
        "paper_title": "20th International Conference on Artificial Intelligence and Soft Computing, ICAISC 2021",
        "paper_author": "NA",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 90 papers. The special focus in this conference is on Artificial Intelligence and Soft Computing. The topics include: Efficient Recurrent Neural Network Architecture for Musical Style Transfer; Impact of ELM Parameters and Investment Horizon for Currency Exchange Prediction; spectroscopy-Based Prediction of In Vitro Dissolution Profile Using Artificial Neural Networks; possibilistic Classification Learning Based on Contrastive Loss in Learning Vector Quantizer Networks; convolutional Autoencoder Based Textile Defect Detection Under Unconstrained Setting; clustering-Based Adaptive Self-Organizing Map; applying Machine Learning Techniques to Identify Damaged Potatoes; Quantifying the Severity of Common Rust in Maize Using Mask R-CNN; federated Learning Model with Augmentation and Samples Exchange Mechanism; factor Augmented Artificial Neural Network vs Deep Learning for Forecasting Global Liquidity Dynamics; flexible Data Augmentation in Off-Policy Reinforcement Learning; polynomial Neural Forms Using Feedforward Neural Networks for Solving Differential Equations; quantum-Hybrid Neural Vector Quantization – A Mathematical Approach; A Graphic CNN-LSTM Model for Stock Price Predication; applying Convolutional Neural Networks for Stock Market Trends Identification; the Extreme Value Evolving Predictor in Multiple Time Series Learning; towards Synthetic Multivariate Time Series Generation for Flare Forecasting; the Streaming Approach to Training Restricted Boltzmann Machines; abrupt Change Detection by the Nonparametric Approach Based on Orthogonal Series Estimates; Recommendation System for Signal Processing in SHM; integrate-and-Fire Neurons for Low-Powered Pattern Recognition; monitoring of Changes in Data Stream Distribution Using Convolutional Restricted Boltzmann Machines; a Proposal for Hybrid Memories Management Exploring Fuzzy-Based Page Migration Policy; a Learning Automata-Based Approach to Lifetime Optimization in Wireless Sensor Networks.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "20th International Conference on Artificial Intelligence and Soft Computing, ICAISC 2021",
        "paper_author": "NA",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "0",
        "cover_date": "2021-01-01",
        "Abstract": "The proceedings contain 90 papers. The special focus in this conference is on Artificial Intelligence and Soft Computing. The topics include: Efficient Recurrent Neural Network Architecture for Musical Style Transfer; Impact of ELM Parameters and Investment Horizon for Currency Exchange Prediction; spectroscopy-Based Prediction of In Vitro Dissolution Profile Using Artificial Neural Networks; possibilistic Classification Learning Based on Contrastive Loss in Learning Vector Quantizer Networks; convolutional Autoencoder Based Textile Defect Detection Under Unconstrained Setting; clustering-Based Adaptive Self-Organizing Map; applying Machine Learning Techniques to Identify Damaged Potatoes; Quantifying the Severity of Common Rust in Maize Using Mask R-CNN; federated Learning Model with Augmentation and Samples Exchange Mechanism; factor Augmented Artificial Neural Network vs Deep Learning for Forecasting Global Liquidity Dynamics; flexible Data Augmentation in Off-Policy Reinforcement Learning; polynomial Neural Forms Using Feedforward Neural Networks for Solving Differential Equations; quantum-Hybrid Neural Vector Quantization – A Mathematical Approach; A Graphic CNN-LSTM Model for Stock Price Predication; applying Convolutional Neural Networks for Stock Market Trends Identification; the Extreme Value Evolving Predictor in Multiple Time Series Learning; towards Synthetic Multivariate Time Series Generation for Flare Forecasting; the Streaming Approach to Training Restricted Boltzmann Machines; abrupt Change Detection by the Nonparametric Approach Based on Orthogonal Series Estimates; Recommendation System for Signal Processing in SHM; integrate-and-Fire Neurons for Low-Powered Pattern Recognition; monitoring of Changes in Data Stream Distribution Using Convolutional Restricted Boltzmann Machines; a Proposal for Hybrid Memories Management Exploring Fuzzy-Based Page Migration Policy; a Learning Automata-Based Approach to Lifetime Optimization in Wireless Sensor Networks.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA"
    },
    {
        "paper_title": "Factor Augmented Artificial Neural Network vs Deep Learning for Forecasting Global Liquidity Dynamics",
        "paper_author": "Alaminos D.",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "2",
        "cover_date": "2021-01-01",
        "Abstract": "This paper develops a global liquidity prediction model based on financial and macroeconomic information from different geographical areas. The methodology of the Factor Augmented Artificial Neural Network Model is applied to improve the predictive capacity of liquidity models compared to traditional econometric methodologies. This hybrid methodology based on dynamic factor models and neural networks is compared with Deep Learning methodologies such as Deep Recurrent Convolutional Neural Network and Deep Neural Decision Trees, which has recently shown great results. Our results show the superiority of the precision capacity of Factor Augmented Artificial Neural Network Model over the applied Deep Learning methodology, which demonstrates the importance of data treatment in International Macroeconomics and Finance with techniques from the Vector Autoregressive model. Our conclusions also show the importance of the impact of monetary policy, financial stability, and the real activity of the economy in the behavior of liquidity. This work may be useful for those interest groups in public and macroeconomic policy, showing the potential in the combination of conventional statistical methods with the envelope of Machine Learning techniques.",
        "DOI": "10.1007/978-3-030-87986-0_2",
        "affiliation_name": "Universidad Pontificia Comillas",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain"
    }
]