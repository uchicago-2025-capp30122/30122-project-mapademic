[
    {
        "paper_title": "Federated Learning in Mobile Edge Networks: A Comprehensive Survey",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "1667",
        "cover_date": "2020-07-01",
        "Abstract": "In recent years, mobile devices are equipped with increasingly advanced sensing and computing capabilities. Coupled with advancements in Deep Learning (DL), this opens up countless possibilities for meaningful applications, e.g., for medical purposes and in vehicular networks. Traditional cloud-based Machine Learning (ML) approaches require the data to be centralized in a cloud server or data center. However, this results in critical issues related to unacceptable latency and communication inefficiency. To this end, Mobile Edge Computing (MEC) has been proposed to bring intelligence closer to the edge, where data is produced. However, conventional enabling technologies for ML at mobile edge networks still require personal data to be shared with external parties, e.g., edge servers. Recently, in light of increasingly stringent data privacy legislations and growing privacy concerns, the concept of Federated Learning (FL) has been introduced. In FL, end devices use their local data to train an ML model required by the server. The end devices then send the model updates rather than raw data to the server for aggregation. FL can serve as an enabling technology in mobile edge networks since it enables the collaborative training of an ML model and also enables DL for mobile edge network optimization. However, in a large-scale and complex mobile edge network, heterogeneous devices with varying constraints are involved. This raises challenges of communication costs, resource allocation, and privacy and security in the implementation of FL at scale. In this survey, we begin with an introduction to the background and fundamentals of FL. Then, we highlight the aforementioned challenges of FL implementation and review existing solutions. Furthermore, we present the applications of FL for mobile edge network optimization. Finally, we discuss the important challenges and future research directions in FL.",
        "DOI": "10.1109/COMST.2020.2986024",
        "paper_author": "Lim W.Y.B.",
        "affiliation_name": "Nanyang Technological University",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60005510",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Comprehensive Survey on Internet of Things (IoT) Toward 5G Wireless Systems",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "1323",
        "cover_date": "2020-01-01",
        "Abstract": "Recently, wireless technologies have been growing actively all around the world. In the context of wireless technology, fifth-generation (5G) technology has become a most challenging and interesting topic in wireless research. This article provides an overview of the Internet of Things (IoT) in 5G wireless systems. IoT in the 5G system will be a game changer in the future generation. It will open a door for new wireless architecture and smart services. Recent cellular network LTE (4G) will not be sufficient and efficient to meet the demands of multiple device connectivity and high data rate, more bandwidth, low-latency quality of service (QoS), and low interference. To address these challenges, we consider 5G as the most promising technology. We provide a detailed overview of challenges and vision of various communication industries in 5G IoT systems. The different layers in 5G IoT systems are discussed in detail. This article provides a comprehensive review on emerging and enabling technologies related to the 5G system that enables IoT. We consider the technology drivers for 5G wireless technology, such as 5G new radio (NR), multiple-input-multiple-output antenna with the beamformation technology, mm-wave commutation technology, heterogeneous networks (HetNets), the role of augmented reality (AR) in IoT, which are discussed in detail. We also provide a review on low-power wide-area networks (LPWANs), security challenges, and its control measure in the 5G IoT scenario. This article introduces the role of AR in the 5G IoT scenario. This article also discusses the research gaps and future directions. The focus is also on application areas of IoT in 5G systems. We, therefore, outline some of the important research directions in 5G IoT.",
        "DOI": "10.1109/JIOT.2019.2948888",
        "paper_author": "Chettri L.",
        "affiliation_name": "Sikkim Manipal Institute of Technology",
        "affiliation_city": "Rangpo",
        "affiliation_country": "India",
        "affiliation_id": "60106573",
        "affiliation_state": "SK"
    },
    {
        "paper_title": "6G Wireless Communication Systems: Applications, Requirements, Technologies, Challenges, and Research Directions",
        "publication": "IEEE Open Journal of the Communications Society",
        "citied_by": "1150",
        "cover_date": "2020-01-01",
        "Abstract": "The demand for wireless connectivity has grown exponentially over the last few decades. Fifth-generation (5G) communications, with far more features than fourth-generation communications, will soon be deployed worldwide. A new paradigm of wireless communication, the sixth-generation (6G) system, with the full support of artificial intelligence, is expected to be implemented between 2027 and 2030. Beyond 5G, some fundamental issues that need to be addressed are higher system capacity, higher data rate, lower latency, higher security, and improved quality of service (QoS) compared to the 5G system. This paper presents the vision of future 6G wireless communication and its network architecture. This article describes emerging technologies such as artificial intelligence, terahertz communications, wireless optical technology, free-space optical network, blockchain, three-dimensional networking, quantum communications, unmanned aerial vehicles, cell-free communications, integration of wireless information and energy transfer, integrated sensing and communication, integrated access-backhaul networks, dynamic network slicing, holographic beamforming, backscatter communication, intelligent reflecting surface, proactive caching, and big data analytics that can assist the 6G architecture development in guaranteeing the QoS. Besides, expected applications with 6G communication requirements and possible technologies are presented. We also describe potential challenges and research directions for achieving this goal.",
        "DOI": "10.1109/OJCOMS.2020.3010270",
        "paper_author": "Chowdhury M.Z.",
        "affiliation_name": "Khulna University of Engineering and Technology",
        "affiliation_city": "Khulna",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60025301",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Blockchain and Federated Learning for Privacy-Preserved Data Sharing in Industrial IoT",
        "publication": "IEEE Transactions on Industrial Informatics",
        "citied_by": "914",
        "cover_date": "2020-06-01",
        "Abstract": "The rapid increase in the volume of data generated from connected devices in industrial Internet of Things paradigm, opens up new possibilities for enhancing the quality of service for the emerging applications through data sharing. However, security and privacy concerns (e.g., data leakage) are major obstacles for data providers to share their data in wireless networks. The leakage of private data can lead to serious issues beyond financial loss for the providers. In this article, we first design a blockchain empowered secure data sharing architecture for distributed multiple parties. Then, we formulate the data sharing problem into a machine-learning problem by incorporating privacy-preserved federated learning. The privacy of data is well-maintained by sharing the data model instead of revealing the actual data. Finally, we integrate federated learning in the consensus process of permissioned blockchain, so that the computing work for consensus can also be used for federated training. Numerical results derived from real-world datasets show that the proposed data sharing scheme achieves good accuracy, high efficiency, and enhanced security.",
        "DOI": "10.1109/TII.2019.2942190",
        "paper_author": "Lu Y.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Estimated Research and Development Investment Needed to Bring a New Medicine to Market, 2009-2018",
        "publication": "JAMA - Journal of the American Medical Association",
        "citied_by": "887",
        "cover_date": "2020-03-03",
        "Abstract": "Importance: The mean cost of developing a new drug has been the subject of debate, with recent estimates ranging from 314 million to 2.8 billion. Objective: To estimate the research and development investment required to bring a new therapeutic agent to market, using publicly available data. Design and Setting: Data were analyzed on new therapeutic agents approved by the US Food and Drug Administration (FDA) between 2009 and 2018 to estimate the research and development expenditure required to bring a new medicine to market. Data were accessed from the US Securities and Exchange Commission, Drugs@FDA database, and ClinicalTrials.gov, alongside published data on clinical trial success rates. Exposures: Conduct of preclinical and clinical studies of new therapeutic agents. Main Outcomes and Measures: Median and mean research and development spending on new therapeutic agents approved by the FDA, capitalized at a real cost of capital rate (the required rate of return for an investor) of 10.5% per year, with bootstrapped CIs. All amounts were reported in 2018 US dollars. Results: The FDA approved 355 new drugs and biologics over the study period. Research and development expenditures were available for 63 (18%) products, developed by 47 different companies. After accounting for the costs of failed trials, the median capitalized research and development investment to bring a new drug to market was estimated at 985.3 million (95% CI, 683.6 million-1228.9 million), and the mean investment was estimated at 1335.9 million (95% CI, 1042.5 million-1637.5 million) in the base case analysis. Median estimates by therapeutic area (for areas with =5 drugs) ranged from 765.9 million (95% CI, 323.0 million-1473.5 million) for nervous system agents to 2771.6 million (95% CI, 2051.8 million-5366.2 million) for antineoplastic and immunomodulating agents. Data were mainly accessible for smaller firms, orphan drugs, products in certain therapeutic areas, first-in-class drugs, therapeutic agents that received accelerated approval, and products approved between 2014 and 2018. Results varied in sensitivity analyses using different estimates of clinical trial success rates, preclinical expenditures, and cost of capital. Conclusions and Relevance: This study provides an estimate of research and development costs for new therapeutic agents based on publicly available data. Differences from previous studies may reflect the spectrum of products analyzed, the restricted availability of data in the public domain, and differences in underlying assumptions in the cost calculations..",
        "DOI": "10.1001/jama.2020.1166",
        "paper_author": "Wouters O.J.",
        "affiliation_name": "London School of Economics and Political Science",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60003059",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Survey of Machine and Deep Learning Methods for Internet of Things (IoT) Security",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "828",
        "cover_date": "2020-07-01",
        "Abstract": "The Internet of Things (IoT) integrates billions of smart devices that can communicate with one another with minimal human intervention. IoT is one of the fastest developing fields in the history of computing, with an estimated 50 billion devices by the end of 2020. However, the crosscutting nature of IoT systems and the multidisciplinary components involved in the deployment of such systems have introduced new security challenges. Implementing security measures, such as encryption, authentication, access control, network and application security for IoT devices and their inherent vulnerabilities is ineffective. Therefore, existing security methods should be enhanced to effectively secure the IoT ecosystem. Machine learning and deep learning (ML/DL) have advanced considerably over the last few years, and machine intelligence has transitioned from laboratory novelty to practical machinery in several important applications. Consequently, ML/DL methods are important in transforming the security of IoT systems from merely facilitating secure communication between devices to security-based intelligence systems. The goal of this work is to provide a comprehensive survey of ML methods and recent advances in DL methods that can be used to develop enhanced security methods for IoT systems. IoT security threats that are related to inherent or newly introduced threats are presented, and various potential IoT system attack surfaces and the possible threats related to each surface are discussed. We then thoroughly review ML/DL methods for IoT security and present the opportunities, advantages and shortcomings of each method. We discuss the opportunities and challenges involved in applying ML/DL to IoT security. These opportunities and challenges can serve as potential future research directions.",
        "DOI": "10.1109/COMST.2020.2988293",
        "paper_author": "Al-Garadi M.A.",
        "affiliation_name": "Computer Science and Engineering Department, College of Engineering, Qatar University",
        "affiliation_city": "Doha",
        "affiliation_country": "Qatar",
        "affiliation_id": "60197139",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "The k-means algorithm: A comprehensive survey and performance evaluation",
        "publication": "Electronics (Switzerland)",
        "citied_by": "822",
        "cover_date": "2020-08-01",
        "Abstract": "The k-means clustering algorithm is considered one of the most powerful and popular data mining algorithms in the research community. However, despite its popularity, the algorithm has certain limitations, including problems associated with random initialization of the centroids which leads to unexpected convergence. Additionally, such a clustering algorithm requires the number of clusters to be defined beforehand, which is responsible for different cluster shapes and outlier effects. A fundamental problem of the k-means algorithm is its inability to handle various data types. This paper provides a structured and synoptic overview of research conducted on the k-means algorithm to overcome such shortcomings. Variants of the k-means algorithms including their recent developments are discussed, where their effectiveness is investigated based on the experimental analysis of a variety of datasets. The detailed experimental analysis along with a thorough comparison among different k-means clustering algorithms differentiates our work compared to other existing survey papers. Furthermore, it outlines a clear and thorough understanding of the k-means algorithm along with its different research directions.",
        "DOI": "10.3390/electronics9081295",
        "paper_author": "Ahmed M.",
        "affiliation_name": "Edith Cowan University",
        "affiliation_city": "Perth",
        "affiliation_country": "Australia",
        "affiliation_id": "60105210",
        "affiliation_state": "WA"
    },
    {
        "paper_title": "Blockchain-based electronic healthcare record system for healthcare 4.0 applications",
        "publication": "Journal of Information Security and Applications",
        "citied_by": "796",
        "cover_date": "2020-02-01",
        "Abstract": "Modern healthcare systems are characterized as being highly complex and costly. However, this can be reduced through improved health record management, utilization of insurance agencies, and blockchain technology. Blockchain was first introduced to provide distributed records of money-related exchanges that were not dependent on centralized authorities or financial institutions. Breakthroughs in blockchain technology have led to improved transactions involving medical records, insurance billing, and smart contracts, enabling permanent access to and security of data, as well as providing a distributed database of transactions. One significant advantage of using blockchain technology in the healthcare industry is that it can reform the interoperability of healthcare databases, providing increased access to patient medical records, device tracking, prescription databases, and hospital assets, including the complete life cycle of a device within the blockchain infrastructure. Access to patients’ medical histories is essential to correctly prescribe medication, with blockchain being able to dramatically enhance the healthcare services framework. In this paper, several solutions for improving current limitations in healthcare systems using blockchain technology are explored, including frameworks and tools to measure the performance of such systems, e.g., Hyperledger Fabric, Composer, Docker Container, Hyperledger Caliper, and the Wireshark capture engine. Further, this paper proposes an Access Control Policy Algorithm for improving data accessibility between healthcare providers, assisting in the simulation of environments to implement the Hyperledger-based eletronic healthcare record (EHR) sharing system that uses the concept of a chaincode. Performance metrics in blockchain networks, such as latency, throughput, Round Trip Time (RTT). have also been optimized for achieving enhanced results. Compared to traditional EHR systems, which use client-server architecture, the proposed system uses blockchain for improving efficiency and security.",
        "DOI": "10.1016/j.jisa.2019.102407",
        "paper_author": "Tanwar S.",
        "affiliation_name": "Nirma University, Institute of Technology",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India",
        "affiliation_id": "60115002",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Networked control systems: A survey of trends and techniques",
        "publication": "IEEE/CAA Journal of Automatica Sinica",
        "citied_by": "751",
        "cover_date": "2020-01-01",
        "Abstract": "Networked control systems are spatially distributed systems in which the communication between sensors, actuators, and controllers occurs through a shared band-limited digital communication network. Several advantages of the network architectures include reduced system wiring, plug and play devices, increased system agility, and ease of system diagnosis and maintenance. Consequently, networked control is the current trend for industrial automation and has ever-increasing applications in a wide range of areas, such as smart grids, manufacturing systems, process control, automobiles, automated highway systems, and unmanned aerial vehicles. The modelling, analysis, and control of networked control systems have received considerable attention in the last two decades. The control over networks is one of the key research directions for networked control systems. This paper aims at presenting a survey of trends and techniques in networked control systems from the perspective of control over networks, providing a snapshot of five control issues: sampled-data control, quantization control, networked control, event-Triggered control, and security control. Some challenging issues are suggested to direct the future research.",
        "DOI": "10.1109/JAS.2019.1911651",
        "paper_author": "Zhang X.M.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "A Survey of Deep Learning and Its Applications: A New Paradigm to Machine Learning",
        "publication": "Archives of Computational Methods in Engineering",
        "citied_by": "748",
        "cover_date": "2020-09-01",
        "Abstract": "Nowadays, deep learning is a current and a stimulating field of machine learning. Deep learning is the most effective, supervised, time and cost efficient machine learning approach. Deep learning is not a restricted learning approach, but it abides various procedures and topographies which can be applied to an immense speculum of complicated problems. The technique learns the illustrative and differential features in a very stratified way. Deep learning methods have made a significant breakthrough with appreciable performance in a wide variety of applications with useful security tools. It is considered to be the best choice for discovering complex architecture in high-dimensional data by employing back propagation algorithm. As deep learning has made significant advancements and tremendous performance in numerous applications, the widely used domains of deep learning are business, science and government which further includes adaptive testing, biological image classification, computer vision, cancer detection, natural language processing, object detection, face recognition, handwriting recognition, speech recognition, stock market analysis, smart city and many more. This paper focuses on the concepts of deep learning, its basic and advanced architectures, techniques, motivational aspects, characteristics and the limitations. The paper also presents the major differences between the deep learning, classical machine learning and conventional learning approaches and the major challenges ahead. The main intention of this paper is to explore and present chronologically, a comprehensive survey of the major applications of deep learning covering variety of areas, study of the techniques and architectures used and further the contribution of that respective application in the real world. Finally, the paper ends with the conclusion and future aspects.",
        "DOI": "10.1007/s11831-019-09344-w",
        "paper_author": "Dargan S.",
        "affiliation_name": "Maharaja Ranjit Singh Punjab Technical University, Bathinda",
        "affiliation_city": "Bathinda",
        "affiliation_country": "India",
        "affiliation_id": "60113843",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Impact of COVID-19 pandemic on information management research and practice: Transforming education, work and life",
        "publication": "International Journal of Information Management",
        "citied_by": "739",
        "cover_date": "2020-12-01",
        "Abstract": "The COVID-19 pandemic has forced many organisations to undergo significant transformation, rethinking key elements of their business processes and use of technology to maintain operations whilst adhering to a changing landscape of guidelines and new procedures. This study offers a collective insight to many of the key issues and underlying complexities affecting organisations and society from COVID-19, through an information systems and technological perspective. The views of 12 invited subject experts are collated and analysed where each articulate their individual perspectives relating to: online learning, digital strategy, artificial intelligence, information management, social interaction, cyber security, big data, blockchain, privacy, mobile technology and strategy through the lens of the current crisis and impact on these specific areas. The expert perspectives offer timely insight to the range of topics, identifying key issues and recommendations for theory and practice.",
        "DOI": "10.1016/j.ijinfomgt.2020.102211",
        "paper_author": "Dwivedi Y.K.",
        "affiliation_name": "School of Management",
        "affiliation_city": "Swansea",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60170469",
        "affiliation_state": "Wales"
    },
    {
        "paper_title": "An Overview on Edge Computing Research",
        "publication": "IEEE Access",
        "citied_by": "736",
        "cover_date": "2020-01-01",
        "Abstract": "With the rapid development of the Internet of Everything (IoE), the number of smart devices connected to the Internet is increasing, resulting in large-scale data, which has caused problems such as bandwidth load, slow response speed, poor security, and poor privacy in traditional cloud computing models. Traditional cloud computing is no longer sufficient to support the diverse needs of today's intelligent society for data processing, so edge computing technologies have emerged. It is a new computing paradigm for performing calculations at the edge of the network. Unlike cloud computing, it emphasizes closer to the user and closer to the source of the data. At the edge of the network, it is lightweight for local, small-scale data storage and processing. This article mainly reviews the related research and results of edge computing. First, it summarizes the concept of edge computing and compares it with cloud computing. Then summarize the architecture of edge computing, keyword technology, security and privacy protection, and finally summarize the applications of edge computing.",
        "DOI": "10.1109/ACCESS.2020.2991734",
        "paper_author": "Cao K.",
        "affiliation_name": "Shenyang Jianzhu University",
        "affiliation_city": "Shenyang",
        "affiliation_country": "China",
        "affiliation_id": "60014486",
        "affiliation_state": "Liaoning"
    },
    {
        "paper_title": "Inverting gradients - How easy is it to break privacy in federated learning?",
        "publication": "Advances in Neural Information Processing Systems",
        "citied_by": "707",
        "cover_date": "2020-01-01",
        "Abstract": "The idea of federated learning is to collaboratively train a neural network on a server. Each user receives the current weights of the network and in turns sends parameter updates (gradients) based on local data. This protocol has been designed not only to train neural networks data-efficiently, but also to provide privacy benefits for users, as their input data remains on device and only parameter gradients are shared. But how secure is sharing parameter gradients? Previous attacks have provided a false sense of security, by succeeding only in contrived settings - even for a single image. However, by exploiting a magnitude-invariant loss along with optimization strategies based on adversarial attacks, we show that is is actually possible to faithfully reconstruct images at high resolution from the knowledge of their parameter gradients, and demonstrate that such a break of privacy is possible even for trained deep networks. We analyze the effects of architecture as well as parameters on the difficulty of reconstructing an input image and prove that any input to a fully connected layer can be reconstructed analytically independent of the remaining architecture. Finally we discuss settings encountered in practice and show that even aggregating gradients over several iterations or several images does not guarantee the user’s privacy in federated learning applications.",
        "DOI": "NA",
        "paper_author": "Geiping J.",
        "affiliation_name": "Universität Siegen",
        "affiliation_city": "Siegen",
        "affiliation_country": "Germany",
        "affiliation_id": "60024260",
        "affiliation_state": "Nordrhein-Westfalen"
    },
    {
        "paper_title": "Model Compression and Hardware Acceleration for Neural Networks: A Comprehensive Survey",
        "publication": "Proceedings of the IEEE",
        "citied_by": "694",
        "cover_date": "2020-04-01",
        "Abstract": "Domain-specific hardware is becoming a promising topic in the backdrop of improvement slow down for general-purpose processors due to the foreseeable end of Moore's Law. Machine learning, especially deep neural networks (DNNs), has become the most dazzling domain witnessing successful applications in a wide spectrum of artificial intelligence (AI) tasks. The incomparable accuracy of DNNs is achieved by paying the cost of hungry memory consumption and high computational complexity, which greatly impedes their deployment in embedded systems. Therefore, the DNN compression concept was naturally proposed and widely used for memory saving and compute acceleration. In the past few years, a tremendous number of compression techniques have sprung up to pursue a satisfactory tradeoff between processing efficiency and application accuracy. Recently, this wave has spread to the design of neural network accelerators for gaining extremely high performance. However, the amount of related works is incredibly huge and the reported approaches are quite divergent. This research chaos motivates us to provide a comprehensive survey on the recent advances toward the goal of efficient compression and execution of DNNs without significantly compromising accuracy, involving both the high-level algorithms and their applications in hardware design. In this article, we review the mainstream compression approaches such as compact model, tensor decomposition, data quantization, and network sparsification. We explain their compression principles, evaluation metrics, sensitivity analysis, and joint-way use. Then, we answer the question of how to leverage these methods in the design of neural network accelerators and present the state-of-the-art hardware architectures. In the end, we discuss several existing issues such as fair comparison, testing workloads, automatic compression, influence on security, and framework/hardware-level support, and give promising topics in this field and the possible challenges as well. This article attempts to enable readers to quickly build up a big picture of neural network compression and acceleration, clearly evaluate various methods, and confidently get started in the right way.",
        "DOI": "10.1109/JPROC.2020.2976475",
        "paper_author": "Deng B.L.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Modeling the blockchain enabled traceability in agriculture supply chain",
        "publication": "International Journal of Information Management",
        "citied_by": "681",
        "cover_date": "2020-06-01",
        "Abstract": "Blockchain Technology (BT) has led to a disruption in the supply chain by removing the trust related issues. Studies are being conducted worldwide to leverage the benefits provided by BT in improving the performance of the supply chains. The literature reveals BT to offer various benefits leading to improvements in the sustainable performance of the agriculture supply chains (ASC). It is expected that BT will bring a paradigm shift in the way the transactions are carried in the ASC by reducing the high number of intermediaries, delayed payments and high transaction lead times. India, a developing economy, caters to the food security needs of an ever-growing population and faces many challenges affecting ASC sustainability. It is therefore essential to adopt BT in the ASC to leverage the various benefits. In this study, we identify and establish the relationships between the enablers of BT adoption in ASC. Thirteen enablers were identified from the literature and validated by the experts before applying a combined Interpretive Structural Modelling (ISM) and Decision-Making Trial and Evaluation Laboratory (DEMATEL) methodology to envision the complex causal relationships between the identified BT enablers. The findings from the study suggest that, among the identified enablers, traceability was the most significant reason for BT implementation in ASC followed by auditability, immutability, and provenance. The findings of the study will help the practitioners to design the strategies for BT implementation in agriculture, creating a real-time data-driven ASC. The results will also help the policymakers in developing policies for faster implementation of BT ensuring food safety and sustainable ASCs.",
        "DOI": "10.1016/j.ijinfomgt.2019.05.023",
        "paper_author": "Kamble S.S.",
        "affiliation_name": "Indian Institute of Management Mumbai",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60022123",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "FedHealth: A Federated Transfer Learning Framework for Wearable Healthcare",
        "publication": "IEEE Intelligent Systems",
        "citied_by": "663",
        "cover_date": "2020-07-01",
        "Abstract": "With the rapid development of computing technology, wearable devices make it easy to get access to people's health information. Smart healthcare achieves great success by training machine learning models on a large quantity of user personal data. However, there are two critical challenges. First, user data often exist in the form of isolated islands, making it difficult to perform aggregation without compromising privacy security. Second, the models trained on the cloud fail on personalization. In this article, we propose FedHealth, the first federated transfer learning framework for wearable healthcare to tackle these challenges. FedHealth performs data aggregation through federated learning, and then builds relatively personalized models by transfer learning. Wearable activity recognition experiments and real Parkinson's disease auxiliary diagnosis application have evaluated that FedHealth is able to achieve accurate and personalized healthcare without compromising privacy and security. FedHealth is general and extensible in many healthcare applications.",
        "DOI": "10.1109/MIS.2020.2988604",
        "paper_author": "Chen Y.",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60027363",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Comprehensive Survey on Attacks, Security Issues and Blockchain Solutions for IoT and IIoT",
        "publication": "Journal of Network and Computer Applications",
        "citied_by": "655",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, the growing popularity of Internet of Things (IoT) is providing a promising opportunity not only for the development of various home automation systems but also for different industrial applications. By leveraging these benefits, automation is brought about in the industries giving rise to the Industrial Internet of Things (IIoT). IoT is prone to several cyberattacks and needs challenging approaches to achieve the desired security. Moreover, with the emergence of IIoT, the security vulnerabilities posed by it are even more devastating. Therefore, in order to provide a guideline to researchers, this survey primarily attempts to classify the attacks based on the objects of vulnerability. Subsequently, each of the individual attacks is mapped to one or more layers of the generalized IoT/IIoT architecture followed by a discussion on the countermeasures proposed in literature. Some relevant real-life attacks for each of these categories are also discussed. We further discuss the countermeasures proposed for the most relevant security threats in IIoT. A case study on two of the most important industrial IoT applications is also highlighted. Next, we explore the challenges brought by the centralized IoT/IIoT architecture and how blockchain can effectively be used towards addressing such challenges. In this context, we also discuss in detail one IoT specific Blockchain design known as Tangle, its merits and demerits. We further highlight the most relevant Blockchain-based solutions provided in recent times to counter the challenges posed by the traditional cloud-centered applications. The blockchain-related solutions provided in the context of two of the most relevant applications for each of IoT and IIoT is also discussed. Subsequently, we design a taxonomy of the security research areas in IoT/IIoT along with their corresponding solutions. Finally, several open research directions relevant to the focus of this survey are identified.",
        "DOI": "10.1016/j.jnca.2019.102481",
        "paper_author": "Sengupta J.",
        "affiliation_name": "Indian Institute of Engineering Science and Technology, Shibpur",
        "affiliation_city": "Howrah",
        "affiliation_country": "India",
        "affiliation_id": "60000912",
        "affiliation_state": "WB"
    },
    {
        "paper_title": "Soybean yield prediction from UAV using multimodal data fusion and deep learning",
        "publication": "Remote Sensing of Environment",
        "citied_by": "649",
        "cover_date": "2020-02-01",
        "Abstract": "Preharvest crop yield prediction is critical for grain policy making and food security. Early estimation of yield at field or plot scale also contributes to high-throughput plant phenotyping and precision agriculture. New developments in Unmanned Aerial Vehicle (UAV) platforms and sensor technology facilitate cost-effective data collection through simultaneous multi-sensor/multimodal data collection at very high spatial and spectral resolutions. The objective of this study is to evaluate the power of UAV-based multimodal data fusion using RGB, multispectral and thermal sensors to estimate soybean (Glycine max) grain yield within the framework of Deep Neural Network (DNN). RGB, multispectral, and thermal images were collected using a low-cost multi-sensory UAV from a test site in Columbia, Missouri, USA. Multimodal information, such as canopy spectral, structure, thermal and texture features, was extracted and combined to predict crop grain yield using Partial Least Squares Regression (PLSR), Random Forest Regression (RFR), Support Vector Regression (SVR), input-level feature fusion based DNN (DNN-F1) and intermediate-level feature fusion based DNN (DNN-F2). The results can be summarized in three messages: (1) multimodal data fusion improves the yield prediction accuracy and is more adaptable to spatial variations; (2) DNN-based models improve yield prediction model accuracy: the highest accuracy was obtained by DNN-F2 with an R2 of 0.720 and a relative root mean square error (RMSE%) of 15.9%; (3) DNN-based models were less prone to saturation effects, and exhibited more adaptive performance in predicting grain yields across the Dwight, Pana and AG3432 soybean genotypes in our study. Furthermore, DNN-based models demonstrated consistent performance over space with less spatial dependency and variations. This study indicates that multimodal data fusion using low-cost UAV within a DNN framework can provide a relatively accurate and robust estimation of crop yield, and deliver valuable insight for high-throughput phenotyping and crop field management with high spatial precision.",
        "DOI": "10.1016/j.rse.2019.111599",
        "paper_author": "Maimaitijiang M.",
        "affiliation_name": "Saint Louis University School of Science and Engineering",
        "affiliation_city": "St. Louis",
        "affiliation_country": "United States",
        "affiliation_id": "60279432",
        "affiliation_state": "MO"
    },
    {
        "paper_title": "Analysis of Dimensionality Reduction Techniques on Big Data",
        "publication": "IEEE Access",
        "citied_by": "632",
        "cover_date": "2020-01-01",
        "Abstract": "Due to digitization, a huge volume of data is being generated across several sectors such as healthcare, production, sales, IoT devices, Web, organizations. Machine learning algorithms are used to uncover patterns among the attributes of this data. Hence, they can be used to make predictions that can be used by medical practitioners and people at managerial level to make executive decisions. Not all the attributes in the datasets generated are important for training the machine learning algorithms. Some attributes might be irrelevant and some might not affect the outcome of the prediction. Ignoring or removing these irrelevant or less important attributes reduces the burden on machine learning algorithms. In this work two of the prominent dimensionality reduction techniques, Linear Discriminant Analysis (LDA) and Principal Component Analysis (PCA) are investigated on four popular Machine Learning (ML) algorithms, Decision Tree Induction, Support Vector Machine (SVM), Naive Bayes Classifier and Random Forest Classifier using publicly available Cardiotocography (CTG) dataset from University of California and Irvine Machine Learning Repository. The experimentation results prove that PCA outperforms LDA in all the measures. Also, the performance of the classifiers, Decision Tree, Random Forest examined is not affected much by using PCA and LDA.To further analyze the performance of PCA and LDA the eperimentation is carried out on Diabetic Retinopathy (DR) and Intrusion Detection System (IDS) datasets. Experimentation results prove that ML algorithms with PCA produce better results when dimensionality of the datasets is high. When dimensionality of datasets is low it is observed that the ML algorithms without dimensionality reduction yields better results.",
        "DOI": "10.1109/ACCESS.2020.2980942",
        "paper_author": "Reddy G.T.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India",
        "affiliation_id": "60010618",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "A Survey on the Internet of Things (IoT) Forensics: Challenges, Approaches, and Open Issues",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "621",
        "cover_date": "2020-04-01",
        "Abstract": "Today is the era of the Internet of Things (IoT). The recent advances in hardware and information technology have accelerated the deployment of billions of interconnected, smart and adaptive devices in critical infrastructures like health, transportation, environmental control, and home automation. Transferring data over a network without requiring any kind of human-to-computer or human-to-human interaction, brings reliability and convenience to consumers, but also opens a new world of opportunity for intruders, and introduces a whole set of unique and complicated questions to the field of Digital Forensics. Although IoT data could be a rich source of evidence, forensics professionals cope with diverse problems, starting from the huge variety of IoT devices and non-standard formats, to the multi-tenant cloud infrastructure and the resulting multi-jurisdictional litigations. A further challenge is the end-to-end encryption which represents a trade-off between users' right to privacy and the success of the forensics investigation. Due to its volatile nature, digital evidence has to be acquired and analyzed using validated tools and techniques that ensure the maintenance of the Chain of Custody. Therefore, the purpose of this paper is to identify and discuss the main issues involved in the complex process of IoT-based investigations, particularly all legal, privacy and cloud security challenges. Furthermore, this work provides an overview of the past and current theoretical models in the digital forensics science. Special attention is paid to frameworks that aim to extract data in a privacy-preserving manner or secure the evidence integrity using decentralized blockchain-based solutions. In addition, the present paper addresses the ongoing Forensics-as-a-Service (FaaS) paradigm, as well as some promising cross-cutting data reduction and forensics intelligence techniques. Finally, several other research trends and open issues are presented, with emphasis on the need for proactive Forensics Readiness strategies and generally agreed-upon standards.",
        "DOI": "10.1109/COMST.2019.2962586",
        "paper_author": "Stoyanova M.",
        "affiliation_name": "Technische Universität Berlin",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60011604",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "WiFi sensing with channel state information: A survey",
        "publication": "ACM Computing Surveys",
        "citied_by": "621",
        "cover_date": "2020-05-31",
        "Abstract": "With the high demand for wireless data traffic, WiFi networks have experienced very rapid growth, because they provide high throughput and are easy to deploy. Recently, Channel State Information (CSI) measured by WiFi networks is widely used for different sensing purposes. To get a better understanding of existing WiFi sensing technologies and future WiFi sensing trends, this survey gives a comprehensive review of the signal processing techniques, algorithms, applications, and performance results of WiFi sensing with CSI. Different WiFi sensing algorithms and signal processing techniques have their own advantages and limitations and are suitable for different WiFi sensing applications. The survey groups CSI-based WiFi sensing applications into three categories, detection, recognition, and estimation, depending on whether the outputs are binary/multi-class classifications or numerical values. With the development and deployment of new WiFi technologies, there will be more WiFi sensing opportunities wherein the targets may go beyond from humans to environments, animals, and objects. The survey highlights three challenges for WiFi sensing: robustness and generalization, privacy and security, and coexistence of WiFi sensing and networking. Finally, the survey presents three future WiFi sensing trends, i.e., integrating cross-layer network information, multi-device cooperation, and fusion of different sensors, for enhancing existing WiFi sensing capabilities and enabling new WiFi sensing opportunities.",
        "DOI": "10.1145/3310194",
        "paper_author": "Ma Y.",
        "affiliation_name": "William &amp; Mary",
        "affiliation_city": "Williamsburg",
        "affiliation_country": "United States",
        "affiliation_id": "60016114",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Edge Computing in Industrial Internet of Things: Architecture, Advances and Challenges",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "581",
        "cover_date": "2020-10-01",
        "Abstract": "The Industrial Internet of Things (IIoT) is a crucial research field spawned by the Internet of Things (IoT). IIoT links all types of industrial equipment through the network; establishes data acquisition, exchange, and analysis systems; and optimizes processes and services, so as to reduce cost and enhance productivity. The introduction of edge computing in IIoT can significantly reduce the decision-making latency, save bandwidth resources, and to some extent, protect privacy. This paper outlines the research progress concerning edge computing in IIoT. First, the concepts of IIoT and edge computing are discussed, and subsequently, the research progress of edge computing is discussed and summarized in detail. Next, the future architecture from the perspective of edge computing in IIoT is proposed, and its technical progress in routing, task scheduling, data storage and analytics, security, and standardization is analyzed. Furthermore, we discuss the opportunities and challenges of edge computing in IIoT in terms of 5G-based edge communication, load balancing and data offloading, edge intelligence, as well as data sharing security. Finally, we introduce some typical application scenarios of edge computing in IIoT, such as prognostics and health management (PHM), smart grids, manufacturing coordination, intelligent connected vehicles (ICV), and smart logistics.",
        "DOI": "10.1109/COMST.2020.3009103",
        "paper_author": "Qiu T.",
        "affiliation_name": "Tianjin University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60019533",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "VerifyNet: Secure and Verifiable Federated Learning",
        "publication": "IEEE Transactions on Information Forensics and Security",
        "citied_by": "580",
        "cover_date": "2020-01-01",
        "Abstract": "As an emerging training model with neural networks, federated learning has received widespread attention due to its ability to update parameters without collecting users' raw data. However, since adversaries can track and derive participants' privacy from the shared gradients, federated learning is still exposed to various security and privacy threats. In this paper, we consider two major issues in the training process over deep neural networks (DNNs): 1) how to protect user's privacy (i.e., local gradients) in the training process and 2) how to verify the integrity (or correctness) of the aggregated results returned from the server. To solve the above problems, several approaches focusing on secure or privacy-preserving federated learning have been proposed and applied in diverse scenarios. However, it is still an open problem enabling clients to verify whether the cloud server is operating correctly, while guaranteeing user's privacy in the training process. In this paper, we propose VerifyNet, the first privacy-preserving and verifiable federated learning framework. In specific, we first propose a double-masking protocol to guarantee the confidentiality of users' local gradients during the federated learning. Then, the cloud server is required to provide the Proof about the correctness of its aggregated results to each user. We claim that it is impossible that an adversary can deceive users by forging Proof, unless it can solve the NP-hard problem adopted in our model. In addition, VerifyNet is also supportive of users dropping out during the training process. The extensive experiments conducted on real-world data also demonstrate the practical performance of our proposed scheme.",
        "DOI": "10.1109/TIFS.2019.2929409",
        "paper_author": "Xu G.",
        "affiliation_name": "University of Electronic Science and Technology of China",
        "affiliation_city": "Chengdu",
        "affiliation_country": "China",
        "affiliation_id": "60005465",
        "affiliation_state": "Sichuan"
    },
    {
        "paper_title": "Blockchain Empowered Asynchronous Federated Learning for Secure Data Sharing in Internet of Vehicles",
        "publication": "IEEE Transactions on Vehicular Technology",
        "citied_by": "574",
        "cover_date": "2020-04-01",
        "Abstract": "In Internet of Vehicles (IoV), data sharing among vehicles for collaborative analysis can improve the driving experience and service quality. However, the bandwidth, security and privacy issues hinder data providers from participating in the data sharing process. In addition, due to the intermittent and unreliable communications in IoV, the reliability and efficiency of data sharing need to be further enhanced. In this paper, we propose a new architecture based on federated learning to relieve transmission load and address privacy concerns of providers. To enhance the security and reliability of model parameters, we develop a hybrid blockchain architecture which consists of the permissioned blockchain and the local Directed Acyclic Graph (DAG). Moreover, we propose an asynchronous federated learning scheme by adopting Deep Reinforcement Learning (DRL) for node selection to improve the efficiency. The reliability of shared data is also guaranteed by integrating learned models into blockchain and executing a two-stage verification. Numerical results show that the proposed data sharing scheme provides both higher learning accuracy and faster convergence.",
        "DOI": "10.1109/TVT.2020.2973651",
        "paper_author": "Lu Y.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Communications in the 6G Era",
        "publication": "IEEE Access",
        "citied_by": "573",
        "cover_date": "2020-01-01",
        "Abstract": "The focus of wireless research is increasingly shifting toward 6G as 5G deployments get underway. At this juncture, it is essential to establish a vision of future communications to provide guidance for that research. In this paper, we attempt to paint a broad picture of communication needs and technologies in the timeframe of 6G. The future of connectivity is in the creation of digital twin worlds that are a true representation of the physical and biological worlds at every spatial and time instant, unifying our experience across these physical, biological and digital worlds. New themes are likely to emerge that will shape 6G system requirements and technologies, such as: (i) new man-machine interfaces created by a collection of multiple local devices acting in unison; (ii) ubiquitous universal computing distributed among multiple local devices and the cloud; (iii) multi-sensory data fusion to create multi-verse maps and new mixed-reality experiences; and (iv) precision sensing and actuation to control the physical world. With rapid advances in artificial intelligence, it has the potential to become the foundation for the 6G air interface and network, making data, compute and energy the new resources to be exploited for achieving superior performance. In addition, in this paper we discuss the other major technology transformations that are likely to define 6G: (i) cognitive spectrum sharing methods and new spectrum bands; (ii) the integration of localization and sensing capabilities into the system definition, (iii) the achievement of extreme performance requirements on latency and reliability; (iv) new network architecture paradigms involving sub-networks and RAN-Core convergence; and (v) new security and privacy schemes.",
        "DOI": "10.1109/ACCESS.2020.2981745",
        "paper_author": "Viswanathan H.",
        "affiliation_name": "Nokia Bell Labs",
        "affiliation_city": "Murray",
        "affiliation_country": "United States",
        "affiliation_id": "60021378",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Blockchain for Industry 4.0: A comprehensive review",
        "publication": "IEEE Access",
        "citied_by": "559",
        "cover_date": "2020-01-01",
        "Abstract": "Due to the proliferation of ICT during the last few decades, there is an exponential increase in the usage of various smart applications such as smart farming, smart healthcare, supply-chain logistics, business, tourism and hospitality, energy management etc. However, for all the aforementioned applications, security and privacy are major concerns keeping in view of the usage of the open channel, i.e., Internet for data transfer. Although many security solutions and standards have been proposed over the years to enhance the security levels of aforementioned smart applications, but the existing solutions are either based upon the centralized architecture (having single point of failure) or having high computation and communication costs. Moreover, most of the existing security solutions have focussed only on few aspects and fail to address scalability, robustness, data storage, network latency, auditability, immutability, and traceability. To handle the aforementioned issues, blockchain technology can be one of the solutions. Motivated from these facts, in this paper, we present a systematic review of various blockchain-based solutions and their applicability in various Industry 4.0-based applications. Our contributions in this paper are in four fold. Firstly, we explored the current state-of-the-art solutions in the blockchain technology for the smart applications. Then, we illustrated the reference architecture used for the blockchain applicability in various Industry 4.0 applications. Then, merits and demerits of the traditional security solutions are also discussed in comparison to their countermeasures. Finally, we provided a comparison of existing blockchain-based security solutions using various parameters to provide deep insights to the readers about its applicability in various applications.",
        "DOI": "10.1109/ACCESS.2020.2988579",
        "paper_author": "Bodkhe U.",
        "affiliation_name": "Nirma University, Institute of Technology",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India",
        "affiliation_id": "60115002",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Machine learning in additive manufacturing: State-of-the-art and perspectives",
        "publication": "Additive Manufacturing",
        "citied_by": "550",
        "cover_date": "2020-12-01",
        "Abstract": "Additive manufacturing (AM) has emerged as a disruptive digital manufacturing technology. However, its broad adoption in industry is still hindered by high entry barriers of design for additive manufacturing (DfAM), limited materials library, various processing defects, and inconsistent product quality. In recent years, machine learning (ML) has gained increasing attention in AM due to its unprecedented performance in data tasks such as classification, regression and clustering. This article provides a comprehensive review on the state-of-the-art of ML applications in a variety of AM domains. In the DfAM, ML can be leveraged to output new high-performance metamaterials and optimized topological designs. In AM processing, contemporary ML algorithms can help to optimize process parameters, and conduct examination of powder spreading and in-process defect monitoring. On the production of AM, ML is able to assist practitioners in pre-manufacturing planning, and product quality assessment and control. Moreover, there has been an increasing concern about data security in AM as data breaches could occur with the aid of ML techniques. Lastly, it concludes with a section summarizing the main findings from the literature and providing perspectives on some selected interesting applications of ML in research and development of AM.",
        "DOI": "10.1016/j.addma.2020.101538",
        "paper_author": "Wang C.",
        "affiliation_name": "Nanyang Technological University",
        "affiliation_city": "Singapore City",
        "affiliation_country": "Singapore",
        "affiliation_id": "60005510",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Internet of things (IoT) and the energy sector",
        "publication": "Energies",
        "citied_by": "550",
        "cover_date": "2020-01-01",
        "Abstract": "Integration of renewable energy and optimization of energy use are key enablers of sustainable energy transitions and mitigating climate change. Modern technologies such the Internet of Things (IoT) offer a wide number of applications in the energy sector, i.e, in energy supply, transmission and distribution, and demand. IoT can be employed for improving energy efficiency, increasing the share of renewable energy, and reducing environmental impacts of the energy use. This paper reviews the existing literature on the application of IoT in in energy systems, in general, and in the context of smart grids particularly. Furthermore, we discuss enabling technologies of IoT, including cloud computing and different platforms for data analysis. Furthermore, we review challenges of deploying IoT in the energy sector, including privacy and security, with some solutions to these challenges such as blockchain technology. This survey provides energy policy-makers, energy economists, and managers with an overview of the role of IoT in optimization of energy systems.",
        "DOI": "10.3390/en13020494",
        "paper_author": "Motlagh N.H.",
        "affiliation_name": "Helsingin Yliopisto",
        "affiliation_city": "Helsinki",
        "affiliation_country": "Finland",
        "affiliation_id": "60002952",
        "affiliation_state": "Uusimaa"
    },
    {
        "paper_title": "metan: An R package for multi-environment trial analysis",
        "publication": "Methods in Ecology and Evolution",
        "citied_by": "542",
        "cover_date": "2020-06-01",
        "Abstract": "Multi-environment trials (MET) are crucial steps in plant breeding programs that aim at increasing crop productivity to ensure global food security. The analysis of MET data requires the combination of several approaches including data manipulation, visualization and modelling. As new methods are proposed, analysing MET data correctly and completely remains a challenge, often intractable with existing tools. Here we describe the metan R package, a collection of functions that implement a workflow-based approach to (a) check, manipulate and summarize typical MET data; (b) analyse individual environments using both fixed and mixed-effect models; (c) compute parametric and nonparametric stability statistics; (d) implement biometrical models widely used in MET analysis and (e) plot typical MET data quickly. In this paper, we present a summary of the functions implemented in metan and how they integrate into a workflow to explore and analyse MET data. We guide the user along a gentle learning curve and show how adding only a few commands or options at a time, powerful analyses can be implemented. metan offers a flexible, intuitive and richly documented working environment with tools that will facilitate the implementation of a complete analysis of MET datasets.",
        "DOI": "10.1111/2041-210X.13384",
        "paper_author": "Olivoto T.",
        "affiliation_name": "Universidade Federal de Santa Maria",
        "affiliation_city": "Santa Maria",
        "affiliation_country": "Brazil",
        "affiliation_id": "60033356",
        "affiliation_state": "RS"
    },
    {
        "paper_title": "Time to seize the digital evolution: Adoption of blockchain in operations and supply chain management among Malaysian SMEs",
        "publication": "International Journal of Information Management",
        "citied_by": "531",
        "cover_date": "2020-06-01",
        "Abstract": "This study aims to investigate the effects of relative advantage, complexity, upper management support, cost, market dynamics, competitive pressure and regulatory support on blockchain adoption for operations and supply chain management among Small-Medium Enterprises (SMEs) in Malaysia. Unlike existing studies that employed linear models with Technology Acceptance Model or United Theory of Acceptance and Use of Technology that ignores the organisational and environmental factors, we adopted the Technology, Organisation and Environment Framework that covers the technological dimensions of relative advantage and complexity, organisational dimensions of upper management support and cost and environmental dimensions of market dynamics, competitive pressure and regulatory support. Empirical data from 194 SMEs were investigated and ranked using a nonlinear non-compensatory PLS-ANN approach. Competitive pressure, complexity, cost and relative have significant effects on behavioural intention. Market dynamics, regulatory support and upper management support were insignificant predictors. SMEs often lack resources for technological investments but faces same requirements for streamlining business processes to optimise returns and blockchain presents a viable option for SMEs’ sustainability due to its features of immutability, transparency and security that have the potential to revolutionise businesses. This study contributes new knowledge to the literature on factors that affect blockchain adoption and justifications were discussed accordingly.",
        "DOI": "10.1016/j.ijinfomgt.2019.08.005",
        "paper_author": "Wong L.W.",
        "affiliation_name": "Xiamen University Malaysia",
        "affiliation_city": "Sepang",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60278469",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "TFHE: Fast Fully Homomorphic Encryption Over the Torus",
        "publication": "Journal of Cryptology",
        "citied_by": "528",
        "cover_date": "2020-01-01",
        "Abstract": "This work describes a fast fully homomorphic encryption scheme over the torus (TFHE) that revisits, generalizes and improves the fully homomorphic encryption (FHE) based on GSW and its ring variants. The simplest FHE schemes consist in bootstrapped binary gates. In this gate bootstrapping mode, we show that the scheme FHEW of Ducas and Micciancio (Eurocrypt, 2015) can be expressed only in terms of external product between a GSW and an LWE ciphertext. As a consequence of this result and of other optimizations, we decrease the running time of their bootstrapping from 690 to 13 ms single core, using 16 MB bootstrapping key instead of 1 GB, and preserving the security parameter. In leveled homomorphic mode, we propose two methods to manipulate packed data, in order to decrease the ciphertext expansion and to optimize the evaluation of lookup tables and arbitrary functions in RingGSW -based homomorphic schemes. We also extend the automata logic, introduced in Gama et al. (Eurocrypt, 2016), to the efficient leveled evaluation of weighted automata, and present a new homomorphic counter called TBSR , that supports all the elementary operations that occur in a multiplication. These improvements speed up the evaluation of most arithmetic functions in a packed leveled mode, with a noise overhead that remains additive. We finally present a new circuit bootstrapping that converts LWE ciphertexts into low-noise RingGSW ciphertexts in just 137 ms, which makes the leveled mode of TFHE composable and which is fast enough to speed up arithmetic functions, compared to the gate bootstrapping approach. Finally, we provide an alternative practical analysis of LWE based schemes, which directly relates the security parameter to the error rate of LWE and the entropy of the LWE secret key, and we propose concrete parameter sets and timing comparison for all our constructions.",
        "DOI": "10.1007/s00145-019-09319-x",
        "paper_author": "Chillotti I.",
        "affiliation_name": "KU Leuven",
        "affiliation_city": "Leuven",
        "affiliation_country": "Belgium",
        "affiliation_id": "60025063",
        "affiliation_state": "Vlaams-Brabant"
    },
    {
        "paper_title": "HealthFog: An ensemble deep learning based Smart Healthcare System for Automatic Diagnosis of Heart Diseases in integrated IoT and fog computing environments",
        "publication": "Future Generation Computer Systems",
        "citied_by": "527",
        "cover_date": "2020-03-01",
        "Abstract": "Cloud computing provides resources over the Internet and allows a plethora of applications to be deployed to provide services for different industries. The major bottleneck being faced currently in these cloud frameworks is their limited scalability and hence inability to cater to the requirements of centralized Internet of Things (IoT) based compute environments. The main reason for this is that latency-sensitive applications like health monitoring and surveillance systems now require computation over large amounts of data (Big Data) transferred to centralized database and from database to cloud data centers which leads to drop in performance of such systems. The new paradigms of fog and edge computing provide innovative solutions by bringing resources closer to the user and provide low latency and energy efficient solutions for data processing compared to cloud domains. Still, the current fog models have many limitations and focus from a limited perspective on either accuracy of results or reduced response time but not both. We proposed a novel framework called HealthFog for integrating ensemble deep learning in Edge computing devices and deployed it for a real-life application of automatic Heart Disease analysis. HealthFog delivers healthcare as a fog service using IoT devices and efficiently manages the data of heart patients, which comes as user requests. Fog-enabled cloud framework, FogBus is used to deploy and test the performance of the proposed model in terms of power consumption, network bandwidth, latency, jitter, accuracy and execution time. HealthFog is configurable to various operation modes which provide the best Quality of Service or prediction accuracy, as required, in diverse fog computation scenarios and for different user requirements. We released HealthFog as an open source software. The implementation code with experiment scripts and results can be found at the GitHub repository: https://github.com/Cloudslab/HealthFog",
        "DOI": "10.1016/j.future.2019.10.043",
        "paper_author": "Tuli S.",
        "affiliation_name": "School of Computing and Information Systems",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118847",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Data poisoning attacks against federated learning systems",
        "publication": "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)",
        "citied_by": "516",
        "cover_date": "2020-01-01",
        "Abstract": "Federated learning (FL) is an emerging paradigm for distributed training of large-scale deep neural networks in which participants’ data remains on their own devices with only model updates being shared with a central server. However, the distributed nature of FL gives rise to new threats caused by potentially malicious participants. In this paper, we study targeted data poisoning attacks against FL systems in which a malicious subset of the participants aim to poison the global model by sending model updates derived from mislabeled data. We first demonstrate that such data poisoning attacks can cause substantial drops in classification accuracy and recall, even with a small percentage of malicious participants. We additionally show that the attacks can be targeted, i.e., they have a large negative impact only on classes that are under attack. We also study attack longevity in early/late round training, the impact of malicious participant availability, and the relationships between the two. Finally, we propose a defense strategy that can help identify malicious participants in FL to circumvent poisoning attacks, and demonstrate its effectiveness.",
        "DOI": "10.1007/978-3-030-58951-6_24",
        "paper_author": "Tolpegin V.",
        "affiliation_name": "Georgia Institute of Technology",
        "affiliation_city": "Atlanta",
        "affiliation_country": "United States",
        "affiliation_id": "60019647",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "A systematic literature review on machine learning applications for sustainable agriculture supply chain performance",
        "publication": "Computers and Operations Research",
        "citied_by": "511",
        "cover_date": "2020-07-01",
        "Abstract": "Agriculture plays an important role in sustaining all human activities. Major challenges such as overpopulation, competition for resources poses a threat to the food security of the planet. In order to tackle the ever-increasing complex problems in agricultural production systems, advancements in smart farming and precision agriculture offers important tools to address agricultural sustainability challenges. Data analytics hold the key to ensure future food security, food safety, and ecological sustainability. Disruptive information and communication technologies such as machine learning, big data analytics, cloud computing, and blockchain can address several problems such as productivity and yield improvement, water conservation, ensuring soil and plant health, and enhance environmental stewardship. The current study presents a systematic review of machine learning (ML) applications in agricultural supply chains (ASCs). Ninety three research papers were reviewed based on the applications of different ML algorithms in different phases of the ASCs. The study highlights how ASCs can benefit from ML techniques and lead to ASC sustainability. Based on the study findings an ML applications framework for sustainable ASC is proposed. The framework identifies the role of ML algorithms in providing real-time analytic insights for pro-active data-driven decision-making in the ASCs and provides the researchers, practitioners, and policymakers with guidelines on the successful management of ASCs for improved agricultural productivity and sustainability.",
        "DOI": "10.1016/j.cor.2020.104926",
        "paper_author": "Sharma R.",
        "affiliation_name": "Indian Institute of Management Mumbai",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60022123",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "IoT privacy and security: Challenges and solutions",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "503",
        "cover_date": "2020-06-01",
        "Abstract": "Privacy and security are among the significant challenges of the Internet of Things (IoT). Improper device updates, lack of efficient and robust security protocols, user unawareness, and famous active device monitoring are among the challenges that IoT is facing. In this work, we are exploring the background of IoT systems and security measures, and identifying (a) different security and privacy issues, (b) approaches used to secure the components of IoT-based environments and systems, (c) existing security solutions, and (d) the best privacy models necessary and suitable for different layers of IoT driven applications. In this work, we proposed a new IoT layered model: generic and stretched with the privacy and security components and layers identification. The proposed cloud/edge supported IoT system is implemented and evaluated. The lower layer represented by the IoT nodes generated from the Amazon Web Service (AWS) as Virtual Machines. The middle layer (edge) implemented as a Raspberry Pi 4 hardware kit with support of the Greengrass Edge Environment in AWS. We used the cloud-enabled IoT environment in AWS to implement the top layer (the cloud). The security protocols and critical management sessions were between each of these layers to ensure the privacy of the users' information. We implemented security certificates to allow data transfer between the layers of the proposed cloud/edge enabled IoT model. Not only is the proposed system model eliminating possible security vulnerabilities, but it also can be used along with the best security techniques to countermeasure the cybersecurity threats facing each one of the layers; cloud, edge, and IoT.",
        "DOI": "10.3390/APP10124102",
        "paper_author": "Tawalbeh L.",
        "affiliation_name": "Texas A&amp;M University-San Antonio",
        "affiliation_city": "San Antonio",
        "affiliation_country": "United States",
        "affiliation_id": "60159745",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Security of the Internet of Things: Vulnerabilities, Attacks, and Countermeasures",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "502",
        "cover_date": "2020-01-01",
        "Abstract": "Wireless Sensor Networks (WSNs) constitute one of the most promising third-millennium technologies and have wide range of applications in our surrounding environment. The reason behind the vast adoption of WSNs in various applications is that they have tremendously appealing features, e.g., low production cost, low installation cost, unattended network operation, autonomous and longtime operation. WSNs have started to merge with the Internet of Things (IoT) through the introduction of Internet access capability in sensor nodes and sensing ability in Internet-connected devices. Thereby, the IoT is providing access to huge amount of data, collected by the WSNs, over the Internet. Hence, the security of IoT should start with foremost securing WSNs ahead of the other components. However, owing to the absence of a physical line-of-defense, i.e., there is no dedicated infrastructure such as gateways to watch and observe the flowing information in the network, security of WSNs along with IoT is of a big concern to the scientific community. More specifically, for the application areas in which CIA (confidentiality, integrity, availability) has prime importance, WSNs and emerging IoT technology might constitute an open avenue for the attackers. Besides, recent integration and collaboration of WSNs with IoT will open new challenges and problems in terms of security. Hence, this would be a nightmare for the individuals using these systems as well as the security administrators who are managing those networks. Therefore, a detailed review of security attacks towards WSNs and IoT, along with the techniques for prevention, detection, and mitigation of those attacks are provided in this paper. In this text, attacks are categorized and treated into mainly two parts, most or all types of attacks towards WSNs and IoT are investigated under that umbrella: 'Passive Attacks' and 'Active Attacks'. Understanding these attacks and their associated defense mechanisms will help paving a secure path towards the proliferation and public acceptance of IoT technology.",
        "DOI": "10.1109/COMST.2019.2953364",
        "paper_author": "Butun I.",
        "affiliation_name": "Chalmers University of Technology",
        "affiliation_city": "Gothenburg",
        "affiliation_country": "Sweden",
        "affiliation_id": "60000990",
        "affiliation_state": "Vastra Gotaland"
    },
    {
        "paper_title": "A systematic review on imbalanced data challenges in machine learning: Applications and solutions",
        "publication": "ACM Computing Surveys",
        "citied_by": "502",
        "cover_date": "2020-07-31",
        "Abstract": "In machine learning, the data imbalance imposes challenges to perform data analytics in almost all areas of real-world research. The raw primary data often suffers from the skewed perspective of data distribution of one class over the other as in the case of computer vision, information security, marketing, and medical science. The goal of this article is to present a comparative analysis of the approaches from the reference of data pre-processing, algorithmic and hybrid paradigms for contemporary imbalance data analysis techniques, and their comparative study in lieu of different data distribution and their application areas.",
        "DOI": "10.1145/3343440",
        "paper_author": "Kaur H.",
        "affiliation_name": "Thapar Institute of Engineering &amp; Technology",
        "affiliation_city": "Patiala",
        "affiliation_country": "India",
        "affiliation_id": "60001166",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Federated Learning: A Survey on Enabling Technologies, Protocols, and Applications",
        "publication": "IEEE Access",
        "citied_by": "498",
        "cover_date": "2020-01-01",
        "Abstract": "This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different industries has its own set of obstacles. FL is known as collaborative learning, where algorithm(s) get trained across multiple devices or servers with decentralized data samples without having to exchange the actual data. This approach is radically different from other more established techniques such as getting the data samples uploaded to servers or having data in some form of distributed infrastructure. FL on the other hand generates more robust models without sharing data, leading to privacy-preserved solutions with higher security and access privileges to data. This paper starts by providing an overview of FL. Then, it gives an overview of technical details that pertain to FL enabling technologies, protocols, and applications. Compared to other survey papers in the field, our objective is to provide a more thorough summary of the most relevant protocols, platforms, and real-life use-cases of FL to enable data scientists to build better privacy-preserving solutions for industries in critical need of FL. We also provide an overview of key challenges presented in the recent literature and provide a summary of related research work. Moreover, we explore both the challenges and advantages of FL and present detailed service use-cases to illustrate how different architectures and protocols that use FL can fit together to deliver desired results.",
        "DOI": "10.1109/ACCESS.2020.3013541",
        "paper_author": "Aledhari M.",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States",
        "affiliation_id": "60019740",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "Federated Learning",
        "publication": "Synthesis Lectures on Artificial Intelligence and Machine Learning",
        "citied_by": "494",
        "cover_date": "2020-01-01",
        "Abstract": "How is it possible to allow multiple data owners to collaboratively train and use a shared prediction model while keeping all the local training data private Traditional machine learning approaches need to combine all data at one location, typically a data center, which may very well violate the laws on user privacy and data confidentiality. Today, many parts of the world demand that technology companies treat user data carefully according to user-privacy laws. The European Union's General Data Protection Regulation (GDPR) is a prime example. In this book, we describe how federated machine learning addresses this problem with novel solutions combining distributed machine learning, cryptography and security, and incentive mechanism design based on economic principles and game theory. We explain different types of privacy-preserving machine learning solutions and their technological backgrounds, and highlight some representative practical use cases. We show how federated learning can become the foundation of next-generation machine learning that caters to technological and societal needs for responsible AI development and application. Table of Contents: Preface / Acknowledgments / Introduction / Background / Distributed Machine Learning / Horizontal Federated Learning / Vertical Federated Learning / Federated Transfer Learning / Incentive Mechanism Design for Federated Learning / Federated Learning for Vision, Language, and Recommendation / Federated Reinforcement Learning / Selected Applications / Summary and Outlook / Bibliography / Authors' Biographies",
        "DOI": "10.2200/S00960ED2V01Y201910AIM043",
        "paper_author": "Yang Q.",
        "affiliation_name": "Hong Kong University of Science and Technology",
        "affiliation_city": "Hong Kong",
        "affiliation_country": "Hong Kong",
        "affiliation_id": "60008592",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Blockchain for 5G-enabled IoT for industrial automation: A systematic review, solutions, and challenges",
        "publication": "Mechanical Systems and Signal Processing",
        "citied_by": "494",
        "cover_date": "2020-01-01",
        "Abstract": "Internet-of-Things (IoT) has made ubiquitous computing a reality by extending Internet connectivity in various applications deployed across the globe. IoT connect billions of objects together for high speed data transfer especially in 5G-enabled industrial environment during information collection and processing. Most of the issues such as access control mechanism, time to fetch the data from different devices and protocols used may not be applicable infor future applications as these protocols are based upon a centralized architecture. This centralized architecture may have a single point of failure alongwith the computational overhead. So, there is a need for an efficient decentralized access control mechanism for device-to-device (D2D) communication in various industrial sectors IoT-enabled industrial automation. In such an environment, security and privacy preservation are major concerns as most of the solutions are based upon the centralized architecture. To mitigate the aforementioned issues, in this paper, we present an in-depth survey of state-of-the-art proposals having 5G-enabled IoT as a backbone for blockchain-based industrial automation for the applications such as-Smart city, Smart Home, Healthcare 4.0, Smart Agriculture, Autonomous vehicles and Supply chain management. From the existing proposals, it has been observed that blockchain can revolutionize most of the current and future industrial applications in different sectors by providing a fine-grained decentralized access control. Various transactions and database logs can be traced efficiently using blockchain for consistency and preivacy preservation in the aforementiioned industrial sectors. The open issues and challenges of 5G-enabled IoT for blockchain-based Industrial automation are also analyzed in the text. Finally, a comparison of existing proposals with respect to various parameters is presented which allows the end users to select one of the proposals in comparison to its merits over the others.",
        "DOI": "10.1016/j.ymssp.2019.106382",
        "paper_author": "Mistry I.",
        "affiliation_name": "Nirma University, Institute of Technology",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India",
        "affiliation_id": "60115002",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Media Forensics and DeepFakes: An Overview",
        "publication": "IEEE Journal on Selected Topics in Signal Processing",
        "citied_by": "487",
        "cover_date": "2020-08-01",
        "Abstract": "With the rapid progress in recent years, techniques that generate and manipulate multimedia content can now provide a very advanced level of realism. The boundary between real and synthetic media has become very thin. On the one hand, this opens the door to a series of exciting applications in different fields such as creative arts, advertising, film production, and video games. On the other hand, it poses enormous security threats. Software packages freely available on the web allow any individual, without special skills, to create very realistic fake images and videos. These can be used to manipulate public opinion during elections, commit fraud, discredit or blackmail people. Therefore, there is an urgent need for automated tools capable of detecting false multimedia content and avoiding the spread of dangerous false information. This review paper aims to present an analysis of the methods for visual media integrity verification, that is, the detection of manipulated images and videos. Special emphasis will be placed on the emerging phenomenon of deepfakes, fake media created through deep learning tools, and on modern data-driven forensic methods to fight them. The analysis will help highlight the limits of current forensic tools, the most relevant issues, the upcoming challenges, and suggest future directions for research.",
        "DOI": "10.1109/JSTSP.2020.3002101",
        "paper_author": "Verdoliva L.",
        "affiliation_name": "Università degli Studi di Napoli Federico II",
        "affiliation_city": "Naples",
        "affiliation_country": "Italy",
        "affiliation_id": "60017293",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Survey of COVID-19 Contact Tracing Apps",
        "publication": "IEEE Access",
        "citied_by": "481",
        "cover_date": "2020-01-01",
        "Abstract": "The recent outbreak of COVID-19 has taken the world by surprise, forcing lockdowns and straining public health care systems. COVID-19 is known to be a highly infectious virus, and infected individuals do not initially exhibit symptoms, while some remain asymptomatic. Thus, a non-negligible fraction of the population can, at any given time, be a hidden source of transmissions. In response, many governments have shown great interest in smartphone contact tracing apps that help automate the difficult task of tracing all recent contacts of newly identified infected individuals. However, tracing apps have generated much discussion around their key attributes, including system architecture, data management, privacy, security, proximity estimation, and attack vulnerability. In this article, we provide the first comprehensive review of these much-discussed tracing app attributes. We also present an overview of many proposed tracing app examples, some of which have been deployed countrywide, and discuss the concerns users have reported regarding their usage. We close by outlining potential research directions for next-generation app design, which would facilitate improved tracing and security performance, as well as wide adoption by the population at large.",
        "DOI": "10.1109/ACCESS.2020.3010226",
        "paper_author": "Ahmed N.",
        "affiliation_name": "Cooperative Research Centres Australia",
        "affiliation_city": "Canberra",
        "affiliation_country": "Australia",
        "affiliation_id": "60018950",
        "affiliation_state": "ACT"
    },
    {
        "paper_title": "Telemedicine, the current COVID-19 pandemic and the future: a narrative review and perspectives moving forward in the USA",
        "publication": "Family Medicine and Community Health",
        "citied_by": "464",
        "cover_date": "2020-08-01",
        "Abstract": "A narrative review was conducted to examine the current state of the utilisation of telemedicine amid the current COVID-19 pandemic and to evaluate the benefits of continuing telemedicine usage in the future. A literature review was performed for articles related to telemedicine. Databases including PubMed, Google Scholar, Cochrane Library and Ovid MEDLINE were searched. Three reviewers independently performed article selection based on relevance to our topic. We included all articles between 1990 and 2020 related to telemedicine using the following keywords: ‘telemedicine’, ‘telehealth’, ‘policy’, ‘COVID-19’, ‘regulation’, ‘rural’, ‘physical examination’, ‘future’. A total of 60 articles were identified, and through careful selection we narrowed the final number of articles to 42 based on relevance to our topic. Telemedicine has been rapidly evolving over the past several decades. Issues with regulation and reimbursement have prevented its full immersion into the healthcare system. During the current pandemic, Centers for Medicare and Medicaid services have expanded access to telemedicine services. The advantages of telemedicine moving forward include its cost-effectiveness, ability to extend access to specialty services and its potential to help mitigate the looming physician shortage. Disadvantages include lack of available technological resources in certain parts of the country, issues with security of patient data, and challenges in performing the traditional patient examination. It is critically important that changes are made to fully immerse telemedicine services into the healthcare landscape in order to be prepared for future pandemics as well as to reap the benefits of this service in the future.",
        "DOI": "10.1136/fmch-2020-000530",
        "paper_author": "Kichloo A.",
        "affiliation_name": "Central Michigan University College of Medicine",
        "affiliation_city": "Mount Pleasant",
        "affiliation_country": "United States",
        "affiliation_id": "60279402",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Building an efficient intrusion detection system based on feature selection and ensemble classifier",
        "publication": "Computer Networks",
        "citied_by": "463",
        "cover_date": "2020-06-19",
        "Abstract": "Intrusion detection system (IDS) is one of extensively used techniques in a network topology to safeguard the integrity and availability of sensitive assets in the protected systems. Although many supervised and unsupervised learning approaches from the field of machine learning have been used to increase the efficacy of IDSs, it is still a problem for existing intrusion detection algorithms to achieve good performance. First, lots of redundant and irrelevant data in high-dimensional datasets interfere with the classification process of an IDS. Second, an individual classifier may not perform well in the detection of each type of attacks. Third, many models are built for stale datasets, making them less adaptable for novel attacks. Thus, we propose a new intrusion detection framework in this paper, and this framework is based on the feature selection and ensemble learning techniques. In the first step, a heuristic algorithm called CFS-BA is proposed for dimensionality reduction, which selects the optimal subset based on the correlation between features. Then, we introduce an ensemble approach that combines C4.5, Random Forest (RF), and Forest by Penalizing Attributes (Forest PA) algorithms. Finally, voting technique is used to combine the probability distributions of the base learners for attack recognition. The experimental results, using NSL-KDD, AWID, and CIC-IDS2017 datasets, reveal that the proposed CFS-BA-Ensemble method is able to exhibit better performance than other related and state of the art approaches under several metrics.",
        "DOI": "10.1016/j.comnet.2020.107247",
        "paper_author": "Zhou Y.",
        "affiliation_name": "Southeast University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60005244",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "HopSkipJumpAttack: A query-efficient decision-based attack",
        "publication": "Proceedings - IEEE Symposium on Security and Privacy",
        "citied_by": "461",
        "cover_date": "2020-05-01",
        "Abstract": "The goal of a decision-based adversarial attack on a trained model is to generate adversarial examples based solely on observing output labels returned by the targeted model. We develop HopSkipJumpAttack, a family of algorithms based on a novel estimate of the gradient direction using binary information at the decision boundary. The proposed family includes both untargeted and targeted attacks optimized for l and l8 similarity metrics respectively. Theoretical analysis is provided for the proposed algorithms and the gradient direction estimate. Experiments show HopSkipJumpAttack requires significantly fewer model queries than several state-of-the-art decision-based adversarial attacks. It also achieves competitive performance in attacking several widely-used defense mechanisms.",
        "DOI": "10.1109/SP40000.2020.00045",
        "paper_author": "Chen J.",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Effects of temperature and humidity on the daily new cases and new deaths of COVID-19 in 166 countries",
        "publication": "Science of the Total Environment",
        "citied_by": "459",
        "cover_date": "2020-08-10",
        "Abstract": "The coronavirus disease 2019 (COVID-19) pandemic is the defining global health crisis of our time and the greatest challenge facing the world. Meteorological parameters are reportedly crucial factors affecting respiratory infectious disease epidemics; however, the effect of meteorological parameters on COVID-19 remains controversial. This study investigated the effects of temperature and relative humidity on daily new cases and daily new deaths of COVID-19, which has useful implications for policymakers and the public. Daily data on meteorological conditions, new cases and new deaths of COVID-19 were collected for 166 countries (excluding China) as of March 27, 2020. Log-linear generalized additive model was used to analyze the effects of temperature and relative humidity on daily new cases and daily new deaths of COVID-19, with potential confounders controlled for, including wind speed, median age of the national population, Global Health Security Index, Human Development Index and population density. Our findings revealed that temperature and relative humidity were both negatively related to daily new cases and deaths. A 1 °C increase in temperature was associated with a 3.08% (95% CI: 1.53%, 4.63%) reduction in daily new cases and a 1.19% (95% CI: 0.44%, 1.95%) reduction in daily new deaths, whereas a 1% increase in relative humidity was associated with a 0.85% (95% CI: 0.51%, 1.19%) reduction in daily new cases and a 0.51% (95% CI: 0.34%, 0.67%) reduction in daily new deaths. The results remained robust when different lag structures and the sensitivity analysis were used. These findings provide preliminary evidence that the COVID-19 pandemic may be partially suppressed with temperature and humidity increases. However, active measures must be taken to control the source of infection, block transmission and prevent further spread of COVID-19.",
        "DOI": "10.1016/j.scitotenv.2020.139051",
        "paper_author": "Wu Y.",
        "affiliation_name": "Peking University Health Science Center",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60004573",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Qualitative Data Collection in an Era of Social Distancing",
        "publication": "International Journal of Qualitative Methods",
        "citied_by": "457",
        "cover_date": "2020-01-01",
        "Abstract": "Qualitative researchers face unique opportunities and challenges as a result of the disruption of COVID-19. Although the pandemic represents a unique opportunity to study the crisis itself, social distancing mandates are restricting traditional face-to-face investigations of all kinds. In this article, we describe options and resources for researchers who find themselves needing to alter their study designs from face-to-face qualitative data collection to a “socially distant” method. Although technologies are constantly changing, we review the latest videoconferencing services available to researchers and provide guidance on what services might best suit a project’s needs. We describe options for various platforms and applications including information about enhanced security applications for researchers collecting sensitive patient health information. Concerns about these technologies including security of the platform and logistical needs such as computer equipment are also discussed. Special attention is given to ethical issues when transitioning research efforts to online venues.",
        "DOI": "10.1177/1609406920937875",
        "paper_author": "Lobe B.",
        "affiliation_name": "Univerza v Ljubljani",
        "affiliation_city": "Ljubljana",
        "affiliation_country": "Slovenia",
        "affiliation_id": "60031106",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep learning approaches for anomaly-based intrusion detection systems: A survey, taxonomy, and open issues",
        "publication": "Knowledge-Based Systems",
        "citied_by": "452",
        "cover_date": "2020-02-15",
        "Abstract": "The massive growth of data that are transmitted through a variety of devices and communication protocols have raised serious security concerns, which have increased the importance of developing advanced intrusion detection systems (IDSs). Deep learning is an advanced branch of machine learning, composed of multiple layers of neurons that represent the learning process. Deep learning can cope with large-scale data and has shown success in different fields. Therefore, researchers have paid more attention to investigating deep learning for intrusion detection. This survey comprehensively reviews and compares the key previous deep learning-focused cybersecurity surveys. Through an extensive review, this survey provides a novel fine-grained taxonomy that categorizes the current state-of-the-art deep learning-based IDSs with respect to different facets, including input data, detection, deployment, and evaluation strategies. Each facet is further classified according to different criteria. This survey also compares and discusses the related experimental solutions proposed as deep learning-based IDSs. By analysing the experimental studies, this survey discusses the role of deep learning in intrusion detection, the impact of intrusion detection datasets, and the efficiency and effectiveness of the proposed approaches. The findings demonstrate that further effort is required to improve the current state-of-the art. Finally, open research challenges are identified, and future research directions for deep learning-based IDSs are recommended.",
        "DOI": "10.1016/j.knosys.2019.105124",
        "paper_author": "Aldweesh A.",
        "affiliation_name": "King Saud University",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60013183",
        "affiliation_state": "Ar Riyad"
    },
    {
        "paper_title": "From high-touch to high-tech: COVID-19 drives robotics adoption",
        "publication": "Tourism Geographies",
        "citied_by": "450",
        "cover_date": "2020-05-26",
        "Abstract": "Global economic and social life has been severely challenged since the World Health Organization (WHO) declared the COVID-19 disease a pandemic. Travel, tourism and hospitality, in particular, has been massively impacted by the lockdowns used to maintain social distance to manage the disease. Robotics, artificial intelligence, and human-robot interactions have gained an increased presence to help manage the spread of COVID-19 in hospitals, airports, transportation systems, recreation and scenic areas, hotels, restaurants, and communities in general. Humanoid robots, autonomous vehicles, drones, and other intelligent robots are used in many different ways to reduce human contact and the potential spread of the SARS-CoV-2 virus, including delivering materials, disinfecting and sterilizing public spaces, detecting or measuring body temperature, providing safety or security, and comforting and entertaining patients. While controversial in the past due to concerns over job losses and data privacy, the adoption of robotics and artificial intelligence in travel and tourism will likely continue after the COVID-19 pandemic becomes less serious. Tourism scholars should seize this opportunity to develop robotic applications that enhance tourist experiences, the protection of natural and cultural resources, citizen participation in tourism development decision making, and the emergence of new ‘high-touch’ employment opportunities for travel, tourism and hospitality workers.",
        "DOI": "10.1080/14616688.2020.1762118",
        "paper_author": "Zeng Z.",
        "affiliation_name": "Nanjing University",
        "affiliation_city": "Nanjing",
        "affiliation_country": "China",
        "affiliation_id": "60033100",
        "affiliation_state": "Jiangsu"
    },
    {
        "paper_title": "TON-IoT telemetry dataset: A new generation dataset of IoT and IIoT for data-driven intrusion detection systems",
        "publication": "IEEE Access",
        "citied_by": "446",
        "cover_date": "2020-01-01",
        "Abstract": "Although the Internet of Things (IoT) can increase efficiency and productivity through intelligent and remote management, it also increases the risk of cyber-attacks. The potential threats to IoT applications and the need to reduce risk have recently become an interesting research topic. It is crucial that effective Intrusion Detection Systems (IDSs) tailored to IoT applications be developed. Such IDSs require an updated and representative IoT dataset for training and evaluation. However, there is a lack of benchmark IoT and IIoT datasets for assessing IDSs-enabled IoT systems. This paper addresses this issue and proposes a new data-driven IoT/IIoT dataset with the ground truth that incorporates a label feature indicating normal and attack classes, as well as a type feature indicating the sub-classes of attacks targeting IoT/IIoT applications for multi-classification problems. The proposed dataset, which is named TON-IoT, includes Telemetry data of IoT/IIoT services, as well as Operating Systems logs and Network traffic of IoT network, collected from a realistic representation of a medium-scale network at the Cyber Range and IoT Labs at the UNSW Canberra (Australia). This paper also describes the proposed dataset of the Telemetry data of IoT/IIoT services and their characteristics. TON-IoT has various advantages that are currently lacking in the state-of-the-art datasets: i) it has various normal and attack events for different IoT/IIoT services, and ii) it includes heterogeneous data sources. We evaluated the performance of several popular Machine Learning (ML) methods and a Deep Learning model in both binary and multi-class classification problems for intrusion detection purposes using the proposed Telemetry dataset.",
        "DOI": "10.1109/ACCESS.2020.3022862",
        "paper_author": "Alsaedi A.",
        "affiliation_name": "RMIT University",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60011362",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Cybersecurity data science: an overview from machine learning perspective",
        "publication": "Journal of Big Data",
        "citied_by": "427",
        "cover_date": "2020-12-01",
        "Abstract": "In a computing context, cybersecurity is undergoing massive shifts in technology and its operations in recent days, and data science is driving the change. Extracting security incident patterns or insights from cybersecurity data and building corresponding data-driven model, is the key to make a security system automated and intelligent. To understand and analyze the actual phenomena with data, various scientific methods, machine learning techniques, processes, and systems are used, which is commonly known as data science. In this paper, we focus and briefly discuss on cybersecurity data science, where the data is being gathered from relevant cybersecurity sources, and the analytics complement the latest data-driven patterns for providing more effective security solutions. The concept of cybersecurity data science allows making the computing process more actionable and intelligent as compared to traditional ones in the domain of cybersecurity. We then discuss and summarize a number of associated research issues and future directions. Furthermore, we provide a machine learning based multi-layered framework for the purpose of cybersecurity modeling. Overall, our goal is not only to discuss cybersecurity data science and relevant methods but also to focus the applicability towards data-driven intelligent decision making for protecting the systems from cyber-attacks.",
        "DOI": "10.1186/s40537-020-00318-5",
        "paper_author": "Sarker I.H.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "A systematic literature review of blockchain cyber security",
        "publication": "Digital Communications and Networks",
        "citied_by": "426",
        "cover_date": "2020-05-01",
        "Abstract": "Since the publication of Satoshi Nakamoto's white paper on Bitcoin in 2008, blockchain has (slowly) become one of the most frequently discussed methods for securing data storage and transfer through decentralized, trustless, peer-to-peer systems. This research identifies peer-reviewed literature that seeks to utilize blockchain for cyber security purposes and presents a systematic analysis of the most frequently adopted blockchain security applications. Our findings show that the Internet of Things (IoT) lends itself well to novel blockchain applications, as do networks and machine visualization, public-key cryptography, web applications, certification schemes and the secure storage of Personally Identifiable Information (PII). This timely systematic review also sheds light on future directions of research, education and practices in the blockchain and cyber security space, such as security of blockchain in IoT, security of blockchain for AI data, and sidechain security.",
        "DOI": "10.1016/j.dcan.2019.01.005",
        "paper_author": "Taylor P.J.",
        "affiliation_name": "University of Salford",
        "affiliation_city": "Salford",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60008250",
        "affiliation_state": "Greater Manchester"
    },
    {
        "paper_title": "The impact of covid-19 on health behavior, stress, financial and food security among middle to high income canadian families with young children",
        "publication": "Nutrients",
        "citied_by": "425",
        "cover_date": "2020-08-01",
        "Abstract": "The COVID-19 pandemic has disrupted many aspects of daily life. The purpose of this study was to identify how health behaviors, level of stress, financial and food security have been impacted by the pandemic among Canadian families with young children. Parents (mothers, n = 235 and fathers, n = 126) from 254 families participating in an ongoing study completed an online survey that included close and open-ended questions. Descriptive statistics were used to summarize the quantitative data and qualitative responses were analyzed using thematic analysis. More than half of our sample reported that their eating and meal routines have changed since COVID-19; most commonly reported changes were eating more snack foods and spending more time cooking. Screen time increased among 74% of mothers, 61% of fathers, and 87% of children and physical activity decreased among 59% of mothers, 52% of fathers, and 52% of children. Key factors influencing family stress include balancing work with childcare/homeschooling and financial instability. While some unhealthful behaviors appeared to have been exacerbated, other more healthful behaviors also emerged since COVID-19. Research is needed to determine the longer-term impact of the pandemic on behaviors and to identify effective strategies to support families in the post-COVID-19 context.",
        "DOI": "10.3390/nu12082352",
        "paper_author": "Carroll N.",
        "affiliation_name": "University of Guelph",
        "affiliation_city": "Guelph",
        "affiliation_country": "Canada",
        "affiliation_id": "60015881",
        "affiliation_state": "ON"
    },
    {
        "paper_title": "Mapping global urban boundaries from the global artificial impervious area (GAIA) data",
        "publication": "Environmental Research Letters",
        "citied_by": "422",
        "cover_date": "2020-09-01",
        "Abstract": "Urban boundaries, an essential property of cities, are widely used in many urban studies. However, extracting urban boundaries from satellite images is still a great challenge, especially at a global scale and a fine resolution. In this study, we developed an automatic delineation framework to generate a multi-temporal dataset of global urban boundaries (GUB) using 30 m global artificial impervious area (GAIA) data. First, we delineated an initial urban boundary by filling inner non-urban areas of each city. A kernel density estimation approach and cellular-automata based urban growth modeling were jointly used in this step. Second, we improved the initial urban boundaries around urban fringe areas, using a morphological approach by dilating and eroding the derived urban extent. We implemented this delineation on the Google Earth Engine platform and generated a 30 m resolution global urban boundary dataset in seven representative years (i.e. 1990, 1995, 2000, 2005, 2010, 2015, and 2018). Our extracted urban boundaries show a good agreement with results derived from nighttime light data and human interpretation, and they can well delineate the urban extent of cities when compared with high-resolution Google Earth images. The total area of 65 582 GUBs, each of which exceeds 1 km2, is 809 664 km2 in 2018. The impervious surface areas account for approximately 60% of the total. From 1990 to 2018, the proportion of impervious areas in delineated boundaries increased from 53% to 60%, suggesting a compact urban growth over the past decades. We found that the United States has the highest per capita urban area (i.e. more than 900 m2) among the top 10 most urbanized nations in 2018. This dataset provides a physical boundary of urban areas that can be used to study the impact of urbanization on food security, biodiversity, climate change, and urban health. The GUB dataset can be accessed from http://data.ess.tsinghua.edu.cn.",
        "DOI": "10.1088/1748-9326/ab9be3",
        "paper_author": "Li X.",
        "affiliation_name": "Iowa State University",
        "affiliation_city": "Ames",
        "affiliation_country": "United States",
        "affiliation_id": "60004354",
        "affiliation_state": "IA"
    },
    {
        "paper_title": "The Psychological and Social Impact of Covid-19: New Perspectives of Well-Being",
        "publication": "Frontiers in Psychology",
        "citied_by": "419",
        "cover_date": "2020-10-02",
        "Abstract": "The recent Covid-19 pandemic has had significant psychological and social effects on the population. Research has highlighted the impact on psychological well-being of the most exposed groups, including children, college students, and health workers, who are more likely to develop post-traumatic stress disorder, anxiety, depression, and other symptoms of distress. The social distance and the security measures have affected the relationship among people and their perception of empathy toward others. From this perspective, telepsychology and technological devices assume important roles to decrease the negative effects of the pandemic. These tools present benefits that could improve psychological treatment of patients online, such as the possibility to meet from home or from the workplace, saving money and time and maintaining the relationship between therapists and patients. The aim of this paper is to show empirical data from recent studies on the effect of the pandemic and reflect on possible interventions based on technological tools.",
        "DOI": "10.3389/fpsyg.2020.577684",
        "paper_author": "Saladino V.",
        "affiliation_name": "Universita di Cassino e del Lazio Meridionale",
        "affiliation_city": "Cassino",
        "affiliation_country": "Italy",
        "affiliation_id": "60001711",
        "affiliation_state": "FR"
    },
    {
        "paper_title": "In-vehicle network intrusion detection using deep convolutional neural network",
        "publication": "Vehicular Communications",
        "citied_by": "417",
        "cover_date": "2020-01-01",
        "Abstract": "The implementation of electronics in modern vehicles has resulted in an increase in attacks targeting in-vehicle networks; thus, attack detection models have caught the attention of the automotive industry and its researchers. Vehicle network security is an urgent and significant problem because the malfunctioning of vehicles can directly affect human and road safety. The controller area network (CAN), which is used as a de facto standard for in-vehicle networks, does not have sufficient security features, such as message encryption and sender authentication, to protect the network from cyber-attacks. In this paper, we propose an intrusion detection system (IDS) based on a deep convolutional neural network (DCNN) to protect the CAN bus of the vehicle. The DCNN learns the network traffic patterns and detects malicious traffic without hand-designed features. We designed the DCNN model, which was optimized for the data traffic of the CAN bus, to achieve high detection performance while reducing the unnecessary complexity in the architecture of the Inception-ResNet model. We performed an experimental study using the datasets we built with a real vehicle to evaluate our detection system. The experimental results demonstrate that the proposed IDS has significantly low false negative rates and error rates when compared to the conventional machine-learning algorithms.",
        "DOI": "10.1016/j.vehcom.2019.100198",
        "paper_author": "Song H.M.",
        "affiliation_name": "Korea University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60005273",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Differential Privacy Techniques for Cyber Physical Systems: A Survey",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "415",
        "cover_date": "2020-01-01",
        "Abstract": "Modern cyber physical systems (CPSs) has widely being used in our daily lives because of development of information and communication technologies (ICT). With the provision of CPSs, the security and privacy threats associated to these systems are also increasing. Passive attacks are being used by intruders to get access to private information of CPSs. In order to make CPSs data more secure, certain privacy preservation strategies such as encryption, and k-anonymity have been presented in the past. However, with the advances in CPSs architecture, these techniques also need certain modifications. Meanwhile, differential privacy emerged as an efficient technique to protect CPSs data privacy. In this paper, we present a comprehensive survey of differential privacy techniques for CPSs. In particular, we survey the application and implementation of differential privacy in four major applications of CPSs named as energy systems, transportation systems, healthcare and medical systems, and industrial Internet of things (IIoT). Furthermore, we present open issues, challenges, and future research direction for differential privacy techniques for CPSs. This survey can serve as basis for the development of modern differential privacy techniques to address various problems and data privacy scenarios of CPSs.",
        "DOI": "10.1109/COMST.2019.2944748",
        "paper_author": "Hassan M.U.",
        "affiliation_name": "Swinburne University of Technology",
        "affiliation_city": "Hawthorn",
        "affiliation_country": "Australia",
        "affiliation_id": "60030804",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "A Survey on Security and Privacy of 5G Technologies: Potential Solutions, Recent Advancements, and Future Directions",
        "publication": "IEEE Communications Surveys and Tutorials",
        "citied_by": "412",
        "cover_date": "2020-01-01",
        "Abstract": "Security has become the primary concern in many telecommunications industries today as risks can have high consequences. Especially, as the core and enable technologies will be associated with 5G network, the confidential information will move at all layers in future wireless systems. Several incidents revealed that the hazard encountered by an infected wireless network, not only affects the security and privacy concerns, but also impedes the complex dynamics of the communications ecosystem. Consequently, the complexity and strength of security attacks have increased in the recent past making the detection or prevention of sabotage a global challenge. From the security and privacy perspectives, this paper presents a comprehensive detail on the core and enabling technologies, which are used to build the 5G security model; network softwarization security, PHY (Physical) layer security and 5G privacy concerns, among others. Additionally, the paper includes discussion on security monitoring and management of 5G networks. This paper also evaluates the related security measures and standards of core 5G technologies by resorting to different standardization bodies and provide a brief overview of 5G standardization security forces. Furthermore, the key projects of international significance, in line with the security concerns of 5G and beyond are also presented. Finally, a future directions and open challenges section has included to encourage future research.",
        "DOI": "10.1109/COMST.2019.2933899",
        "paper_author": "Khan R.",
        "affiliation_name": "Tomsk Polytechnic University",
        "affiliation_city": "Tomsk",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60024069",
        "affiliation_state": "Tomsk Oblast"
    },
    {
        "paper_title": "Face recognition systems: A survey",
        "publication": "Sensors (Switzerland)",
        "citied_by": "398",
        "cover_date": "2020-01-02",
        "Abstract": "Over the past few decades, interest in theories and algorithms for face recognition has been growing rapidly. Video surveillance, criminal identification, building access control, and unmanned and autonomous vehicles are just a few examples of concrete applications that are gaining attraction among industries. Various techniques are being developed including local, holistic, and hybrid approaches, which provide a face image description using only a few face image features or the whole facial features. The main contribution of this survey is to review some well-known techniques for each approach and to give the taxonomy of their categories. In the paper, a detailed comparison between these techniques is exposed by listing the advantages and the disadvantages of their schemes in terms of robustness, accuracy, complexity, and discrimination. One interesting feature mentioned in the paper is about the database used for face recognition. An overview of the most commonly used databases, including those of supervised and unsupervised learning, is given. Numerical results of the most interesting techniques are given along with the context of experiments and challenges handled by these techniques. Finally, a solid discussion is given in the paper about future directions in terms of techniques to be used for face recognition.",
        "DOI": "10.3390/s20020342",
        "paper_author": "Kortli Y.",
        "affiliation_name": "AI-ED Department",
        "affiliation_city": "Brest",
        "affiliation_country": "France",
        "affiliation_id": "123764670",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A survey on end-edge-cloud orchestrated network computing paradigms: Transparent computing, mobile edge computing, fog computing, and cloudlet",
        "publication": "ACM Computing Surveys",
        "citied_by": "389",
        "cover_date": "2020-11-30",
        "Abstract": "Sending data to the cloud for analysis was a prominent trend during the past decades, driving cloud computing as a dominant computing paradigm. However, the dramatically increasing number of devices and data traffic in the Internet-of-Things (IoT) era are posing significant burdens on the capacity-limited Internet and uncontrollable service delay. It becomes difficult to meet the delay-sensitive and context-aware service requirements of IoT applications by using cloud computing alone. Facing these challenges, computing paradigms are shifting from the centralized cloud computing to distributed edge computing. Several new computing paradigms, including Transparent Computing, Mobile Edge Computing, Fog Computing, and Cloudlet, have emerged to leverage the distributed resources at network edge to provide timely and context-aware services. By integrating end devices, edge servers, and cloud, they form a hierarchical IoT architecture, i.e., End-Edge-Cloud orchestrated architecture to improve the performance of IoT systems. This article presents a comprehensive survey of these emerging computing paradigms from the perspective of end-edge-cloud orchestration. Specifically, we first introduce and compare the architectures and characteristics of different computing paradigms. Then, a comprehensive survey is presented to discuss state-of-the-art research in terms of computation offloading, caching, security, and privacy. Finally, some potential research directions are envisioned for fostering continuous research efforts.",
        "DOI": "10.1145/3362031",
        "paper_author": "Ren J.",
        "affiliation_name": "Central South University",
        "affiliation_city": "Changsha",
        "affiliation_country": "China",
        "affiliation_id": "60017060",
        "affiliation_state": "Hunan"
    },
    {
        "paper_title": "BlockIoTIntelligence: A Blockchain-enabled Intelligent IoT Architecture with Artificial Intelligence",
        "publication": "Future Generation Computer Systems",
        "citied_by": "389",
        "cover_date": "2020-09-01",
        "Abstract": "In the recent year, Internet of Things (IoT) is industrializing in several real-world applications such as smart transportation, smart city to make human life reliable. With the increasing industrialization in IoT, an excessive amount of sensing data is producing from various sensors devices in the Industrial IoT. To analyzes of big data, Artificial Intelligence (AI) plays a significant role as a strong analytic tool and delivers a scalable and accurate analysis of data in real-time. However, the design and development of a useful big data analysis tool using AI have some challenges, such as centralized architecture, security, and privacy, resource constraints, lack of enough training data. Conversely, as an emerging technology, Blockchain supports a decentralized architecture. It provides a secure sharing of data and resources to the various nodes of the IoT network is encouraged to remove centralized control and can overcome the existing challenges in AI. The main goal of our research is to design and develop an IoT architecture with blockchain and AI to support an effective big data analysis. In this paper, we propose a Blockchain-enabled Intelligent IoT Architecture with Artificial Intelligence that provides an efficient way of converging blockchain and AI for IoT with current state-of-the-art techniques and applications. We evaluate the proposed architecture and categorized into two parts: qualitative analysis and quantitative analysis. In qualitative evaluation, we describe how to use AI and Blockchain in IoT applications with “AI-driven Blockchain” and “Blockchain-driven AI.” In quantitative analysis, we present a performance evaluation of the BlockIoTIntelligence architecture to compare existing researches on device, fog, edge and cloud intelligence according to some parameters such as accuracy, latency, security and privacy, computational complexity and energy cost in IoT applications. The evaluation results show that the proposed architecture performance over the existing IoT architectures and mitigate the current challenges.",
        "DOI": "10.1016/j.future.2019.09.002",
        "paper_author": "Singh S.K.",
        "affiliation_name": "Seoul National University of Science and Technology",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60026263",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An effective feature engineering for DNN using hybrid PCA-GWO for intrusion detection in IoMT architecture",
        "publication": "Computer Communications",
        "citied_by": "378",
        "cover_date": "2020-07-01",
        "Abstract": "The entire computing paradigm is changed due to the technological advancements in Information and Communication Technology (ICT). Due to these advancements, various new communication channels are being introduced, out of which the Internet of Things (IoT) plays a significant role. The Internet of Medical Things (IoMT) is a special category of IoT in which the medical devices communicate with each other for sharing sensitive data. These advancements help the healthcare industry to have better contact and care towards their patients. But they too have certain drawbacks since there are so many security and privacy issues like replay, man-in-the-middle, impersonation, privileged-insider, remote hijacking, password guessing, denial of service (DoS) attacks and malware attacks. When the sensitive data is being attacked by any of these attacks, there is a chance of losing the authorized data to the attacker or getting altered due to which the data is not available for the authorized users and customers. Machine learning algorithms are widely used in the Intrusion Detection System (IDS) for detecting and classifying the attacks at the network and host level in a dynamic manner. Many supervised and unsupervised algorithms have been designed by researchers from the area of machine learning and data mining to identify the reliable detection of an anomaly. However, the main challenge in the IDS models are changed in dynamic and random behavior of malicious attacks and designing a scalable solution that can handle this behavior. The rapid change in network behavior and the fast evolution of various attacks paved the way for evaluating various datasets that are generated over the years and to design different dynamic approaches. In this paper, a deep neural network (DNN) is used to develop effective and efficient IDS in the IoMT environment to classify and predict unforeseen cyberattacks. The network parameter are preprocessed, optimized and tuned by hyperparameter selection methods. A comprehensive analysis of experiments in DNN with other machine learning algorithms are compared on the benchmark intrusion detection dataset. Through rigorous testing, it has proved that the proposed DNN model performs better than the existing machine learning approaches with an increase in accuracy by 15% and decreases in time complexity by 32%, which helps in faster alerts to avoid post effects of intrusion in sensitive cloud data storage.",
        "DOI": "10.1016/j.comcom.2020.05.048",
        "paper_author": "Swarna Priya R.M.",
        "affiliation_name": "Vellore Institute of Technology",
        "affiliation_city": "Vellore",
        "affiliation_country": "India",
        "affiliation_id": "60010618",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "IMCFN: Image-based malware classification using fine-tuned convolutional neural network architecture",
        "publication": "Computer Networks",
        "citied_by": "375",
        "cover_date": "2020-04-22",
        "Abstract": "The volume, type, and sophistication of malware is increasing. Deep convolutional neural networks (CNNs) have lately proven their effectiveness in malware binary detection through image classification. In this paper, we propose a novel classifier to detect variants of malware families and improve malware detection using CNN-based deep learning architecture, called IMCFN (Image-based Malware Classification using Fine-tuned Convolutional Neural Network Architecture). Differing from existing solutions, we propose a new method for multiclass classification problems. Our proposed method converts the raw malware binaries into color images that are used by the fine-tuned CNN architecture to detect and identify malware families. Our method previously trained with the ImageNet dataset (≥10 million) and utilized the data augmentation to handle the imbalance dataset during the fine-tuning process. For evaluations, an extensive experiment was conducted using 2 datasets: Malimg malware dataset (9,435 samples), and IoT- android mobile dataset (14,733 malware and 2,486 benign samples). Empirical evidence has shown that the IMCFN stands out among the deep learning models including other CNN models with an accuracy of 98.82% in Malimg malware dataset and more than 97.35% for IoT-android mobile dataset. Furthermore, it demonstrates that colored malware dataset performed better in terms of accuracy than grayscale malware images. We compared the performance of IMCFN with the three architectures VGG16, ResNet50 and Google's InceptionV3. We found that our method can effectively detect hidden code, obfuscated malware and malware family variants with little run-time. Our method is resilient to straight forward obfuscation technique commonly used by hackers to disguise malware such as encryption and packing.",
        "DOI": "10.1016/j.comnet.2020.107138",
        "paper_author": "Vasan D.",
        "affiliation_name": "Tsinghua University",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60025278",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Re-calculating the cost of coccidiosis in chickens",
        "publication": "Veterinary Research",
        "citied_by": "370",
        "cover_date": "2020-09-14",
        "Abstract": "Coccidiosis, caused by Eimeria species parasites, has long been recognised as an economically significant disease of chickens. As the global chicken population continues to grow, and its contribution to food security intensifies, it is increasingly important to assess the impact of diseases that compromise chicken productivity and welfare. In 1999, Williams published one of the most comprehensive estimates for the cost of coccidiosis in chickens, featuring a compartmentalised model for the costs of prophylaxis, treatment and losses, indicating a total cost in excess of £38 million in the United Kingdom (UK) in 1995. In the 25 years since this analysis the global chicken population has doubled and systems of chicken meat and egg production have advanced through improved nutrition, husbandry and selective breeding of chickens, and wider use of anticoccidial vaccines. Using data from industry representatives including veterinarians, farmers, production and health experts, we have updated the Williams model and estimate that coccidiosis in chickens cost the UK £99.2 million in 2016 (range £73.0-£125.5 million). Applying the model to data from Brazil, Egypt, Guatemala, India, New Zealand, Nigeria and the United States resulted in estimates that, when extrapolated by geographical region, indicate a global cost of ~ £10.4 billion at 2016 prices (£7.7-£13.0 billion), equivalent to £0.16/chicken produced. Understanding the economic costs of livestock diseases can be advantageous, providing baselines to evaluate the impact of different husbandry systems and interventions. The updated cost of coccidiosis in chickens will inform debates on the value of chemoprophylaxis and development of novel anticoccidial vaccines.",
        "DOI": "10.1186/s13567-020-00837-2",
        "paper_author": "Blake D.P.",
        "affiliation_name": "Royal Veterinary College University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60026530",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Health security capacities in the context of COVID-19 outbreak: an analysis of International Health Regulations annual report data from 182 countries",
        "publication": "The Lancet",
        "citied_by": "366",
        "cover_date": "2020-03-28",
        "Abstract": "Background: Public health measures to prevent, detect, and respond to events are essential to control public health risks, including infectious disease outbreaks, as highlighted in the International Health Regulations (IHR). In light of the outbreak of 2019 novel coronavirus disease (COVID-19), we aimed to review existing health security capacities against public health risks and events. Methods: We used 18 indicators from the IHR State Party Annual Reporting (SPAR) tool and associated data from national SPAR reports to develop five indices: (1) prevent, (2) detect, (3) respond, (4) enabling function, and (5) operational readiness. We used SPAR 2018 data for all of the indicators and categorised countries into five levels across the indices, in which level 1 indicated the lowest level of national capacity and level 5 the highest. We also analysed data at the regional level (using the six geographical WHO regions). Findings: Of 182 countries, 52 (28%) had prevent capacities at levels 1 or 2, and 60 (33%) had response capacities at levels 1 or 2. 81 (45%) countries had prevent capacities and 78 (43%) had response capacities at levels 4 or 5, indicating that these countries were operationally ready. 138 (76%) countries scored more highly in the detect index than in the other indices. 44 (24%) countries did not have an effective enabling function for public health risks and events, including infectious disease outbreaks (7 [4%] at level 1 and 37 [20%] at level 2). 102 (56%) countries had level 4 or level 5 enabling function capacities in place. 32 (18%) countries had low readiness (2 [1%] at level 1 and 30 [17%] at level 2), and 104 (57%) countries were operationally ready to prevent, detect, and control an outbreak of a novel infectious disease (66 [36%] at level 4 and 38 [21%] at level 5). Interpretation: Countries vary widely in terms of their capacity to prevent, detect, and respond to outbreaks. Half of all countries analysed have strong operational readiness capacities in place, which suggests that an effective response to potential health emergencies could be enabled, including to COVID-19. Findings from local risk assessments are needed to fully understand national readiness capacities in relation to COVID-19. Capacity building and collaboration between countries are needed to strengthen global readiness for outbreak control. Funding: None.",
        "DOI": "10.1016/S0140-6736(20)30553-5",
        "paper_author": "Kandel N.",
        "affiliation_name": "Organisation Mondiale de la Santé",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60027142",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Federated learning for 6G communications: Challenges, methods, and future directions",
        "publication": "China Communications",
        "citied_by": "364",
        "cover_date": "2020-09-01",
        "Abstract": "As the 5G communication networks are being widely deployed worldwide, both industry and academia have started to move beyond 5G and explore 6G communications. It is generally believed that 6G will be established on ubiquitous Artificial Intelligence (AI) to achieve data-driven Machine Learning (ML) solutions in heterogeneous and massive-scale networks. However, traditional ML techniques require centralized data collection and processing by a central server, which is becoming a bottleneck of large-scale implementation in daily life due to significantly increasing privacy concerns. Federated learning, as an emerging distributed AI approach with privacy preservation nature, is particularly attractive for various wireless applications, especially being treated as one of the vital solutions to achieve ubiquitous AI in 6G. In this article, we first introduce the integration of 6G and federated learning and provide potential federated learning applications for 6G. We then describe key technical challenges, the corresponding federated learning methods, and open problems for future research on federated learning in the context of 6G communications.",
        "DOI": "10.23919/JCC.2020.09.009",
        "paper_author": "Liu Y.",
        "affiliation_name": "Heilongjiang University",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60033495",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Nexus between green finance, non-fossil energy use, and carbon intensity: Empirical evidence from China based on a vector error correction model",
        "publication": "Journal of Cleaner Production",
        "citied_by": "361",
        "cover_date": "2020-12-20",
        "Abstract": "Previous studies have considered the effect of financial development on carbon emissions; however, few studies have explored the role of green finance in carbon mitigation. To bridge this gap, the current study constructs a green finance development index based on four indicators: green credit, green securities, green insurance, and green investment. A vector error correction model is used to analyze relationships between the development level of green finance, non-fossil energy consumption, and carbon intensity using data from 2000 to 2018. We find that China's green finance industry developed rapidly, and improvements in the green finance development index, as well as the increasing use of non-fossil energy, contributed to a reduction in carbon intensity. Simultaneously, an increase in carbon intensity inhibited the expansion of non-fossil energy use, impeded the investment flow to green projects, and ultimately led to a deterioration of green finance development. In addition, non-fossil energy consumption in China was primarily influenced by green finance and carbon intensity, with clear policy-driven effects. However, the impacts of green finance policies continually fell short and lacked continuity. This study proposes ways in which to improve the effect of green finance policy implementation, expand the consumption of non-fossil energy, and develop a carbon trading market.",
        "DOI": "10.1016/j.jclepro.2020.122844",
        "paper_author": "Ren X.",
        "affiliation_name": "Shanxi University of Finance and EcoNomics",
        "affiliation_city": "Taiyuan",
        "affiliation_country": "China",
        "affiliation_id": "60026295",
        "affiliation_state": "Shanxi"
    },
    {
        "paper_title": "Wearable health devices in health care: Narrative systematic review",
        "publication": "JMIR mHealth and uHealth",
        "citied_by": "358",
        "cover_date": "2020-11-01",
        "Abstract": "Background: With the rise of mobile medicine, the development of new technologies such as smart sensing, and the popularization of personalized health concepts, the field of smart wearable devices has developed rapidly in recent years. Among them, medical wearable devices have become one of the most promising fields. These intelligent devices not only assist people in pursuing a healthier lifestyle but also provide a constant stream of health care data for disease diagnosis and treatment by actively recording physiological parameters and tracking metabolic status. Therefore, wearable medical devices have the potential to become a mainstay of the future mobile medical market. Objective: Although previous reviews have discussed consumer trends in wearable electronics and the application of wearable technology in recreational and sporting activities, data on broad clinical usefulness are lacking. We aimed to review the current application of wearable devices in health care while highlighting shortcomings for further research. In addition to daily health and safety monitoring, the focus of our work was mainly on the use of wearable devices in clinical practice. Methods: We conducted a narrative review of the use of wearable devices in health care settings by searching papers in PubMed, EMBASE, Scopus, and the Cochrane Library published since October 2015. Potentially relevant papers were then compared to determine their relevance and reviewed independently for inclusion. Results: A total of 82 relevant papers drawn from 960 papers on the subject of wearable devices in health care settings were qualitatively analyzed, and the information was synthesized. Our review shows that the wearable medical devices developed so far have been designed for use on all parts of the human body, including the head, limbs, and torso. These devices can be classified into 4 application areas: (1) health and safety monitoring, (2) chronic disease management, (3) disease diagnosis and treatment, and (4) rehabilitation. However, the wearable medical device industry currently faces several important limitations that prevent further use of wearable technology in medical practice, such as difficulties in achieving user-friendly solutions, security and privacy concerns, the lack of industry standards, and various technical bottlenecks. Conclusions: We predict that with the development of science and technology and the popularization of personalized health concepts, wearable devices will play a greater role in the field of health care and become better integrated into people’s daily lives. However, more research is needed to explore further applications of wearable devices in the medical field. We hope that this review can provide a useful reference for the development of wearable medical devices.",
        "DOI": "10.2196/18907",
        "paper_author": "Lu L.",
        "affiliation_name": "Tongji Medical College of Huazhong University of Science and Technology",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60001193",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Reinforcement learning for building controls: The opportunities and challenges",
        "publication": "Applied Energy",
        "citied_by": "358",
        "cover_date": "2020-07-01",
        "Abstract": "Building controls are becoming more important and complicated due to the dynamic and stochastic energy demand, on-site intermittent energy supply, as well as energy storage, making it difficult for them to be optimized by conventional control techniques. Reinforcement Learning (RL), as an emerging control technique, has attracted growing research interest and demonstrated its potential to enhance building performance while addressing some limitations of other advanced control techniques, such as model predictive control. This study conducted a comprehensive review of existing studies that applied RL for building controls. It provided a detailed breakdown of the existing RL studies that use a specific variation of each major component of the Reinforcement Learning: algorithm, state, action, reward, and environment. We found RL for building controls is still in the research stage with limited applications (11%) in real buildings. Three significant barriers prevent the adoption of RL controllers in actual building controls: (1) the training process is time consuming and data demanding, (2) the control security and robustness need to be enhanced, and (3) the generalization capabilities of RL controllers need to be improved using approaches such as transfer learning. Future research may focus on developing RL controllers that could be used in real buildings, addressing current RL challenges, such as accelerating training and enhancing control robustness, as well as developing an open-source testbed and dataset for performance benchmarking of RL controllers.",
        "DOI": "10.1016/j.apenergy.2020.115036",
        "paper_author": "Wang Z.",
        "affiliation_name": "Lawrence Berkeley National Laboratory",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60007174",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A survey on access control in the age of internet of things",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "358",
        "cover_date": "2020-06-01",
        "Abstract": "With the development of Internet-of-Things (IoT) technology, various types of information, such as social resources and physical resources, are deeply integrated for different comprehensive applications. Social networking, car networking, medical services, video surveillance, and other forms of the IoT information service model gradually change people's daily lives. Facing the vast amounts of IoT information data, the IoT search technology is used to quickly find accurate information to meet the real-time search needs of users. However, IoT search requires using a large amount of user private information, such as personal health information, location information, and social relations information, to provide personalized services. Employing private information from users will encounter security problems if an effective access control mechanism is missing during the IoT search process. An access control mechanism can effectively monitor the access activities of resources and ensure that authorized users access information resources under legitimate conditions. This survey examines the growing literature on access control for an IoT search. Problems and challenges of access control mechanisms are analyzed to facilitate the adoption of access control solutions in real-life settings. This article aims to provide theoretical, methodological, and technical guidance for IoT search access control mechanisms in large-scale dynamic heterogeneous environments. Based on a literature review, we also analyzed the future development direction of access control in the age of IoT.",
        "DOI": "10.1109/JIOT.2020.2969326",
        "paper_author": "Qiu J.",
        "affiliation_name": "Guangzhou University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60025345",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Switching-Like Event-Triggered Control for Networked Control Systems under Malicious Denial of Service Attacks",
        "publication": "IEEE Transactions on Automatic Control",
        "citied_by": "351",
        "cover_date": "2020-09-01",
        "Abstract": "This article investigates the switching-like event-triggered control for networked control systems (NCSs) under the malicious denial of service (DoS) attacks. First, by dividing the DoS attacks into S-interval (DoS-free case) and D-interval (DoS case), a switching-like event-triggered communication scheme (SETC) is well designed to deal with intermittent DoS attacks to improve communication efficiency while keeping the desired control performance. Second, by considering the SETC and NCSs into a unified framework, the studied system is transferred into a time-delay system. Then, under the constraint of the number of maximum allowable data dropouts induced by DoS attacks, a stability criterion and a stabilization criterion are derived, which can be used to estimate the event-triggered communication parameters and obtain the security controller gain simultaneously. Moreover, the derived stabilization criterion can also provide a tradeoff to balance communication efficiency and $H_{\\infty }$ control performance. At last, a networked invert pendulum on a cart is conducted to show the effectiveness of the proposed method.",
        "DOI": "10.1109/TAC.2020.2989773",
        "paper_author": "Peng C.",
        "affiliation_name": "Shanghai University",
        "affiliation_city": "Shanghai",
        "affiliation_country": "China",
        "affiliation_id": "60023813",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A survey on security challenges in cloud computing: issues, threats, and solutions",
        "publication": "Journal of Supercomputing",
        "citied_by": "351",
        "cover_date": "2020-12-01",
        "Abstract": "Cloud computing has gained huge attention over the past decades because of continuously increasing demands. There are several advantages to organizations moving toward cloud-based data storage solutions. These include simplified IT infrastructure and management, remote access from effectively anywhere in the world with a stable Internet connection and the cost efficiencies that cloud computing can bring. The associated security and privacy challenges in cloud require further exploration. Researchers from academia, industry, and standards organizations have provided potential solutions to these challenges in the previously published studies. The narrative review presented in this survey provides cloud security issues and requirements, identified threats, and known vulnerabilities. In fact, this work aims to analyze the different components of cloud computing as well as present security and privacy problems that these systems face. Moreover, this work presents new classification of recent security solutions that exist in this area. Additionally, this survey introduced various types of security threats which are threatening cloud computing services and also discussed open issues and propose future directions. This paper will focus and explore a detailed knowledge about the security challenges that are faced by cloud entities such as cloud service provider, the data owner, and cloud user.",
        "DOI": "10.1007/s11227-020-03213-1",
        "paper_author": "Tabrizchi H.",
        "affiliation_name": "Shahid Bahonar University of Kerman",
        "affiliation_city": "Kerman",
        "affiliation_country": "Iran",
        "affiliation_id": "60031268",
        "affiliation_state": "Kerman"
    },
    {
        "paper_title": "Security and Privacy in Smart Farming: Challenges and Opportunities",
        "publication": "IEEE Access",
        "citied_by": "351",
        "cover_date": "2020-01-01",
        "Abstract": "Internet of Things (IoT) and smart computing technologies have revolutionized every sphere of 21st century humans. IoT technologies and the data driven services they offer were beyond imagination just a decade ago. Now, they surround us and influence a variety of domains such as automobile, smart home, healthcare, etc. In particular, the Agriculture and Farming industries have also embraced this technological intervention. Smart devices are widely used by a range of people from farmers to entrepreneurs. These technologies are used in a variety of ways, from finding real-time status of crops and soil moisture content to deploying drones to assist with tasks such as applying pesticide spray. However, the use of IoT and smart communication technologies introduce a vast exposure to cybersecurity threats and vulnerabilities in smart farming environments. Such cyber attacks have the potential to disrupt the economies of countries that are widely dependent on agriculture. In this paper, we present a holistic study on security and privacy in a smart farming ecosystem. The paper outlines a multi layered architecture relevant to the precision agriculture domain and discusses the security and privacy issues in this dynamic and distributed cyber physical environment. Further more, the paper elaborates on potential cyber attack scenarios and highlights open research challenges and future directions.",
        "DOI": "10.1109/ACCESS.2020.2975142",
        "paper_author": "Gupta M.",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Cookeville",
        "affiliation_country": "United States",
        "affiliation_id": "60279624",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Deep recurrent neural network for IoT intrusion detection system",
        "publication": "Simulation Modelling Practice and Theory",
        "citied_by": "350",
        "cover_date": "2020-05-01",
        "Abstract": "As a results of the large scale development of the Internet of Things (IoT), cloud computing capabilities including networking, data storage, management, and analytics are brought very close to the edge of networks forming Fog computing and enhancing transferring and processing of tremendous amount of data. As the Internet becomes more deeply integrated into our business operations through IoT platform, the desire for reliable and efficient connections increases as well. Fog and Cloud security is a topical issue associated with every data storage, managing or processing paradigm. Attacks once occurred, have ineradicable and disastrous effects on the development of IoT, Fog, Cloud computing. Therefore, many security systems/models have been proposed and/or implemented for the sake of Fog security. Intrusion detection systems are one of the premier choices especially ones that designed using artificial intelligence. In our paper, we presented an artificially full-automated intrusion detection system for Fog security against cyber-attacks. The proposed model uses multi-layered of recurrent neural networks designed to be implemented for Fog computing security that is very close to the end-users and IoT devices. We demonstrated our proposed model using a balanced version of the challenging dataset: NSL-KDD. The performance of our model was measured using a variety of typical metrics, and we add two additional metrics: Mathew correlation and Cohen's Kappa coefficients for deeper insight. where the experimental results and simulations proved the stability and robustness of the proposed model in terms of a variety of performance metrics.",
        "DOI": "10.1016/j.simpat.2019.102031",
        "paper_author": "Almiani M.",
        "affiliation_name": "Al-Hussein Bin Talal University",
        "affiliation_city": "Ma'an",
        "affiliation_country": "Jordan",
        "affiliation_id": "60105841",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An exhaustive survey on security and privacy issues in Healthcare 4.0",
        "publication": "Computer Communications",
        "citied_by": "343",
        "cover_date": "2020-03-01",
        "Abstract": "The healthcare industry has revolutionized from 1.0 to 4.0 where Healthcare 1.0 was more doctor centric and Healthcare 2.0 replaced manual records with electronic healthcare records (EHRs). Healthcare 3.0 was patient-centric and Healthcare 4.0 uses cloud computing (CC), fog computing (FC), Internet of things (IoT), and telehealthcare technologies to share data between various stakeholders. However, framing a secure technique for Healthcare 4.0 has always been a challenging task. An in-secure technique for Healthcare 4.0 may lead to the healthcare data breach where hackers can gain full access to patients’ email accounts, messages, and reports. On the contrary, a secured technique for Healthcare 4.0 can provide satisfaction to all stakeholders, including patients and caregivers. Motivated from these facts, this paper presents an extensive literature review and analysis of state-of-the-art proposals to maintain security and privacy in Healthcare 4.0. We also explored the blockchain-based solution to give insights to both researchers and practitioners communities. Different taxonomies used for exploring various security and privacy issues in Healthcare 4.0 are also presented in a structured manner. Then, the advantages and limitations of various security and privacy techniques are explored and discussed in the paper. Finally, existing challenges and future research directions of security and privacy in Healthcare 4.0 are presented.",
        "DOI": "10.1016/j.comcom.2020.02.018",
        "paper_author": "Hathaliya J.J.",
        "affiliation_name": "Nirma University, Institute of Technology",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India",
        "affiliation_id": "60115002",
        "affiliation_state": "GJ"
    },
    {
        "paper_title": "Immediate impact of stay-at-home orders to control COVID-19 transmission on socioeconomic conditions, food insecurity, mental health, and intimate partner violence in Bangladeshi women and their families: an interrupted time series",
        "publication": "The Lancet Global Health",
        "citied_by": "339",
        "cover_date": "2020-11-01",
        "Abstract": "Background: Stay-at-home orders (lockdowns) have been deployed globally to control COVID-19 transmission, and might impair economic conditions and mental health, and exacerbate risk of food insecurity and intimate partner violence. The effect of lockdowns in low-income and middle-income countries must be understood to ensure safe deployment of these interventions in less affluent settings. We aimed to determine the immediate impact of COVID-19 lockdown orders on women and their families in rural Bangladesh. Methods: An interrupted time series was used to compare data collected from families in Rupganj upazila, rural Bangladesh (randomly selected from participants in a randomised controlled trial), on income, food security, and mental health a median of 1 year and 2 years before the COVID-19 pandemic to data collected during the lockdown. We also assessed women's experiences of intimate partner violence during the pandemic. Results: Between May 19 and June 18, 2020, we randomly selected and invited the mothers of 3016 children to participate in the study, 2424 of whom provided consent. 2414 (99·9%, 95% CI 99·6–99·9) of 2417 mothers were aware of, and adhering to, the stay-at-home advice. 2321 (96·0%, 95·2–96·7) of 2417 mothers reported a reduction in paid work for the family. Median monthly family income fell from US$212 at baseline to $59 during lockdown, and the proportion of families earning less than $1·90 per day rose from five (0·2%, 0·0–0·5) of 2422 to 992 (47·3%, 45·2–49·5) of 2096 (p<0·0001 comparing baseline with lockdown period). Before the pandemic, 136 (5·6%, 4·7–6·6) of 2420 and 65 (2·7%, 2·1–3·4) of 2420 families experienced moderate and severe food insecurity, respectively. This increased to 881 (36·5%, 34·5–38·4) of 2417 and 371 (15·3%, 13·9–16·8) of 2417 during the lockdown; the number of families experiencing any level of food insecurity increased by 51·7% (48·1–55·4; p<0·0001). Mothers' depression and anxiety symptoms increased during the lockdown. Among women experiencing emotional or moderate physical violence, over half reported it had increased since the lockdown. Interpretation: COVID-19 lockdowns present significant economic, psychosocial, and physical risks to the wellbeing of women and their families across economic strata in rural Bangladesh. Beyond supporting only the most socioeconomically deprived, support is needed for all affected families. Funding: National Health and Medical Research Council, Australia.",
        "DOI": "10.1016/S2214-109X(20)30366-1",
        "paper_author": "Hamadani J.D.",
        "affiliation_name": "International Centre for Diarrhoeal Disease Research Bangladesh",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60010123",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Survey on the Internet of Vehicles: Network Architectures and Applications",
        "publication": "IEEE Communications Standards Magazine",
        "citied_by": "339",
        "cover_date": "2020-03-01",
        "Abstract": "The vehicular ad hoc network (VANET) has been widely used as an application of mobile ad hoc networking in the automotive industry. However, in the 5G/B5G era, the Internet of Things as a cutting-edge technology is gradually transforming the current Internet into a fully integrated future Internet. At the same time, it will promote the existing research fields to develop in new directions, such as smart home, smart community, smart health, and intelligent transportation. The VANET needs to accelerate the pace of technological transformation when it has to meet the application requirements of intelligent transportation systems, vehicle automatic control, and intelligent road information service. Based on this context, the Internet of Vehicles (IoV) has come into being, which aims to realize the information exchange between the vehicle and all entities that may be related to it. IoV's goals are to reduce accidents, ease traffic congestion, and provide other information services. At present, IoV has attracted much attention from academia and industry. In order to provide assistance to relevant research, this article designs a new network architecture for the future network with greater data throughput, lower latency, higher security, and massive connectivity. Furthermore, this article explores a comprehensive literature review of the basic information of IoV, including basic VANET technology, several network architectures, and typical application of IoV.",
        "DOI": "10.1109/MCOMSTD.001.1900053",
        "paper_author": "Ji B.",
        "affiliation_name": "Henan University of Science and Technology",
        "affiliation_city": "Luoyang",
        "affiliation_country": "China",
        "affiliation_id": "60073587",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "A feature selection algorithm for intrusion detection system based on Pigeon Inspired Optimizer",
        "publication": "Expert Systems with Applications",
        "citied_by": "337",
        "cover_date": "2020-06-15",
        "Abstract": "Feature selection plays a vital role in building machine learning models. Irrelevant features in data affect the accuracy of the model and increase the training time needed to build the model. Feature selection is an important process to build Intrusion Detection System (IDS). In this paper, a wrapper feature selection algorithm for IDS is proposed. This algorithm uses the pigeon inspired optimizer to utilize the selection process. A new method to binarize a continuous pigeon inspired optimizer is proposed and compared to the traditional way for binarizing continuous swarm intelligent algorithms. The proposed algorithm was evaluated using three popular datasets: KDDCUP99, NLS-KDD and UNSW-NB15. The proposed algorithm outperformed several feature selection algorithms from state-of-the-art related works in terms of TPR, FPR, accuracy, and F-score. Also, the proposed cosine similarity method for binarizing the algorithm has a faster convergence than the sigmoid method.",
        "DOI": "10.1016/j.eswa.2020.113249",
        "paper_author": "Alazzam H.",
        "affiliation_name": "The University of Jordan",
        "affiliation_city": "Amman",
        "affiliation_country": "Jordan",
        "affiliation_id": "60064180",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Software Vulnerability Detection Using Deep Neural Networks: A Survey",
        "publication": "Proceedings of the IEEE",
        "citied_by": "336",
        "cover_date": "2020-10-01",
        "Abstract": "The constantly increasing number of disclosed security vulnerabilities have become an important concern in the software industry and in the field of cybersecurity, suggesting that the current approaches for vulnerability detection demand further improvement. The booming of the open-source software community has made vast amounts of software code available, which allows machine learning and data mining techniques to exploit abundant patterns within software code. Particularly, the recent breakthrough application of deep learning to speech recognition and machine translation has demonstrated the great potential of neural models' capability of understanding natural languages. This has motivated researchers in the software engineering and cybersecurity communities to apply deep learning for learning and understanding vulnerable code patterns and semantics indicative of the characteristics of vulnerable code. In this survey, we review the current literature adopting deep-learning-/neural-network-based approaches for detecting software vulnerabilities, aiming at investigating how the state-of-the-art research leverages neural techniques for learning and understanding code semantics to facilitate vulnerability discovery. We also identify the challenges in this new field and share our views of potential research directions.",
        "DOI": "10.1109/JPROC.2020.2993293",
        "paper_author": "Lin G.",
        "affiliation_name": "Sanming University",
        "affiliation_city": "Sanming",
        "affiliation_country": "China",
        "affiliation_id": "60108789",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Risk assessment: Theory, methods, and applications",
        "publication": "Risk Assessment: Theory, Methods, and Applications",
        "citied_by": "335",
        "cover_date": "2020-01-01",
        "Abstract": "Risk Assessment: Theory, Methods, and Applications remains one of the few textbooks to address current risk analysis and risk assessment with an emphasis on the possibility of sudden, major accidents across various areas of practice—from machinery and manufacturing processes to nuclear power plants and transportation systems. Updated to align with ISO 31000 and other amended standards, this all-new 2nd Edition discusses the main ideas and techniques for assessing risk today. The book begins with an introduction of risk analysis, assessment, and management, and includes a new section on the history of risk analysis. It covers hazards and threats, how to measure and evaluate risk, and risk management. It also adds new sections on risk governance and risk-informed decision making; combining accident theories and criteria for evaluating data sources; and subjective probabilities. The risk assessment process is covered, as are how to establish context; planning and preparing; and identification, analysis, and evaluation of risk. Risk Assessment also offers new coverage of safe job analysis and semi-quantitative methods, and it discusses barrier management and HRA methods for offshore application. Finally, it looks at dynamic risk analysis, security and life-cycle use of risk. Serves as a practical and modern guide to the current applications of risk analysis and assessment, supports key standards, and supplements legislation related to risk analysis Updated and revised to align with ISO 31000 Risk Management and other new standards and includes new chapters on security, dynamic risk analysis, as well as life-cycle use of risk analysis Provides in-depth coverage on hazard identification, methodologically outlining the steps for use of checklists, conducting preliminary hazard analysis, and job safety analysis Presents new coverage on the history of risk analysis, criteria for evaluating data sources, risk-informed decision making, subjective probabilities, semi-quantitative methods, and barrier management Contains more applications and examples, new and revised problems throughout, and detailed appendices that outline key terms and acronyms Supplemented with a book companion website containing Solutions to problems, presentation material and an Instructor Manual Risk Assessment: Theory, Methods, and Applications, Second Edition is ideal for courses on risk analysis/risk assessment and systems engineering at the upper-undergraduate and graduate levels. It is also an excellent reference and resource for engineers, researchers, consultants, and practitioners who carry out risk assessment techniques in their everyday work.",
        "DOI": "10.1002/9781119377351",
        "paper_author": "Rausand M.",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Network Intrusion Detection Combined Hybrid Sampling with Deep Hierarchical Network",
        "publication": "IEEE Access",
        "citied_by": "334",
        "cover_date": "2020-01-01",
        "Abstract": "Intrusion detection system (IDS) plays an important role in network security by discovering and preventing malicious activities. Due to the complex and time-varying network environment, the network intrusion samples are submerged into a large number of normal samples, which leads to insufficient samples for model training and detection results with a high false detection rate. According to the problem of data imbalance, we propose a network intrusion detection algorithm combined hybrid sampling with deep hierarchical network. Firstly, we use the one-side selection (OSS) to reduce the noise samples in majority category, and then increase the minority samples by Synthetic Minority Over-sampling Technique (SMOTE). In this way, a balanced dataset can be established to make the model fully learn the features of minority samples and greatly reduce the model training time. Secondly, we use convolution neural network (CNN) to extract spatial features and Bi-directional long short-term memory (BiLSTM) to extract temporal features, which forms a deep hierarchical network model. The proposed network intrusion detection algorithm was verified by experiments on the NSL-KDD and UNSW-NB15 dataset, and the classification accuracy can achieve 83.58% and 77.16%, respectively.",
        "DOI": "10.1109/ACCESS.2020.2973730",
        "paper_author": "Jiang K.",
        "affiliation_name": "Harbin University of Science and Technology",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "60024758",
        "affiliation_state": "Heilongjiang"
    },
    {
        "paper_title": "Data Security and Privacy Protection for Cloud Storage: A Survey",
        "publication": "IEEE Access",
        "citied_by": "331",
        "cover_date": "2020-01-01",
        "Abstract": "The new development trends including Internet of Things (IoT), smart city, enterprises digital transformation and world's digital economy are at the top of the tide. The continuous growth of data storage pressure drives the rapid development of the entire storage market on account of massive data generated. By providing data storage and management, cloud storage system becomes an indispensable part of the new era. Currently, the governments, enterprises and individual users are actively migrating their data to the cloud. Such a huge amount of data can create magnanimous wealth. However, this increases the possible risk, for instance, unauthorized access, data leakage, sensitive information disclosure and privacy disclosure. Although there are some studies on data security and privacy protection, there is still a lack of systematic surveys on the subject in cloud storage system. In this paper, we make a comprehensive review of the literatures on data security and privacy issues, data encryption technology, and applicable countermeasures in cloud storage system. Specifically, we first make an overview of cloud storage, including definition, classification, architecture and applications. Secondly, we give a detailed analysis on challenges and requirements of data security and privacy protection in cloud storage system. Thirdly, data encryption technologies and protection methods are summarized. Finally, we discuss several open research topics of data security for cloud storage.",
        "DOI": "10.1109/ACCESS.2020.3009876",
        "paper_author": "Yang P.",
        "affiliation_name": "Zhengzhou University",
        "affiliation_city": "Zhengzhou",
        "affiliation_country": "China",
        "affiliation_id": "60018554",
        "affiliation_state": "Henan"
    },
    {
        "paper_title": "Corporate survival in Industry 4.0 era: the enabling role of lean-digitized manufacturing",
        "publication": "Journal of Manufacturing Technology Management",
        "citied_by": "330",
        "cover_date": "2020-01-23",
        "Abstract": "Purpose: The purpose of this paper is to demonstrate how small manufacturing firms can leverage their Information Technology (IT) resources to develop the lean-digitized manufacturing system that offers sustained competitiveness in the Industry 4.0 era. Design/methodology/approach: The study performs an in-depth five years case study of a manufacturing firm, and reports its journey from failure in the implementation of enterprise resource planning to its success in integrating IT-based technology trends of Industry 4.0 with the firm’s core capabilities and competencies while pursuing manufacturing digitization. Findings: Industry 4.0 transition requires the organizational integration of many IT-based modern technologies and the digitization of entire value chains. However, Industry 4.0 transition for smaller manufacturers can begin with digitization of certain areas of operations in support of organizational core strategies. The development of lean-digitized manufacturing system is a viable business strategy for corporate survivability in the Industry 4.0 setting. Research limitations/implications: Although the implementation of lean-digitized manufacturing system is costly and challenging, this manufacturing strategy offers superior corporate competitiveness in the long run. Since this finding is rather limited to the present case study, assessing the business value of lean-digitized manufacturing system in a larger scale research context would be an interesting avenue for future research. Practical implications: Industry 4.0 transition for typical manufacturers should commensurate with their organizational, operational and technical particularities. Digitization of certain operations and processes, when aligned with the firm’s core strategies, capabilities and procedures, can offer superior competitiveness even in Industry 4.0 era, meaning that the strategic plan for successful Industry 4.0 transition is idiosyncratic to each particular manufacturer. Social implications: Manufacturing digitization can have deep social implications as it alters inter- and intra-organizational relationships, causes unemployment among low-skilled workforce, and raises data security and privacy concerns. Manufacturers should take responsibility for their digitization process and steer it in a direction that simultaneously safeguards economic, social and environmental sustainability. Originality/value: The strategic roadmap devised and employed by the case company for managing its digitization process can better reveal what manufacturing digitization, mandated by Industry 4.0, might require of typical manufacturers, and further enable them to better facilitate their digital transformation process.",
        "DOI": "10.1108/JMTM-11-2018-0417",
        "paper_author": "Ghobakhloo M.",
        "affiliation_name": "University of Hormozgan",
        "affiliation_city": "Bandar Abbas",
        "affiliation_country": "Iran",
        "affiliation_id": "60106938",
        "affiliation_state": "Hormozgan"
    },
    {
        "paper_title": "Differentially private asynchronous federated learning for mobile edge computing in urban informatics",
        "publication": "IEEE Transactions on Industrial Informatics",
        "citied_by": "325",
        "cover_date": "2020-03-01",
        "Abstract": "Driven by technologies such as mobile edge computing and 5G, recent years have witnessed the rapid development of urban informatics, where a large amount of data is generated. To cope with the growing data, artificial intelligence algorithms have been widely exploited. Federated learning is a promising paradigm for distributed edge computing, which enables edge nodes to train models locally without transmitting their data to a server. However, the security and privacy concerns of federated learning hinder its wide deployment in urban applications such as vehicular networks. In this article, we propose a differentially private asynchronous federated learning scheme for resource sharing in vehicular networks. To build a secure and robust federated learning scheme, we incorporate local differential privacy into federated learning for protecting the privacy of updated local models. We further propose a random distributed update scheme to get rid of the security threats led by a centralized curator. Moreover, we perform the convergence boosting in our proposed scheme by updates verification and weighted aggregation. We evaluate our scheme on three real-world datasets. Numerical results show the high accuracy and efficiency of our proposed scheme, whereas preserve the data privacy.",
        "DOI": "10.1109/TII.2019.2942179",
        "paper_author": "Lu Y.",
        "affiliation_name": "Beijing University of Posts and Telecommunications",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60016930",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Challenges and opportunities in IoT healthcare systems: a systematic review",
        "publication": "SN Applied Sciences",
        "citied_by": "324",
        "cover_date": "2020-01-01",
        "Abstract": "In this study, the latest research articles which are involved in the Internet of Things (IoT) based healthcare system are analyzed as the IoT is growing enormously in the healthcare systems such as health monitoring, fitness programs, etc. Numerous research has been carried out in the IoT based healthcare system to improve monitoring efficiency. The architecture used in the IoT especially the cloud integrated systems are investigated in this work. The factors such as accuracy and power consumption are the important concern in the IoT, hence the research works which are involved in improving the performance of the IoT based healthcare systems are discussed. Data management methods in the IoT based healthcare system with cloud facilities are also systematically analyzed in this study. The performance of the IoT based healthcare system along with its advantages and limitations are reviewed. Most research works are efficient in detecting several symptoms and can accurately predict the diseases. The IoT based healthcare system designed especially for elders is an efficient solution in monitoring their healthcare issues. Major limitations in the existing systems are high power consumption, availability of fewer resources and security issues due to the utilization of many devices.",
        "DOI": "10.1007/s42452-019-1925-y",
        "paper_author": "Selvaraj S.",
        "affiliation_name": "P. A. College of Engineering and Technology, Pollachi",
        "affiliation_city": "Pollachi",
        "affiliation_country": "India",
        "affiliation_id": "60113913",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "The Challenges and Opportunities in the Digitalization of Companies in a Post-COVID-19 World",
        "publication": "IEEE Engineering Management Review",
        "citied_by": "322",
        "cover_date": "2020-07-01",
        "Abstract": "COVID-19 has caused dramatic effects on the world economy, business activities, and people. But digitization is also helping many companies to adapt and overcome the current situation caused by COVID-19. The growth in the use of technology in the daily lives of people and companies to face this exceptional situation is an evidence of the digital acceleration process. This exploratory study analyzes the impact of digital transformation processes in three business areas: labor and social relations, marketing and sales, and technology. The impact of digitalization is expected to be transversal to each area and will encourage the emergence of new digital products and services based on the principle of flexibility. Additionally, new ways of working will foster the demand for new talent regardless of people's geographical location. Moreover, cybersecurity and privacy will become two key elements that will support the integrated development of the Internet of Things technology solutions, artificial intelligence, big data, and robotics.",
        "DOI": "10.1109/EMR.2020.3013206",
        "paper_author": "Almeida F.",
        "affiliation_name": "Institute for Systems and Computer Engineering, Technology and Science",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60020432",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "A review of remote sensing applications in agriculture for food security: Crop growth and yield, irrigation, and crop losses",
        "publication": "Journal of Hydrology",
        "citied_by": "322",
        "cover_date": "2020-07-01",
        "Abstract": "The global population is expected to reach 9.8 billion by 2050. There is an exponential growth of food production to meet the needs of the growing population. However, the limited land and water resources, climate change, and an increase in extreme events likely to pose a significant threat for achieving the sustainable agriculture goal. Given these challenges, food security is included in the United Nations’ Sustainable Development Goals (SDGs). Since the advent of Sputnik, followed by the Explorer missions, satellite remote sensing is assisting us in collecting the data at global scales. In this work, we review how satellite remote sensing information is utilized to assess and manage agriculture, an important component of ecohydrology. Overall, three critical aspects of agriculture are considered: (a) crop growth and yield through empirical models, physics-based models, and data assimilation in crop models, (b) applications pertaining to irrigation, which include mapping irrigation areas and quantification of irrigation, and (c) crop losses due to pests, diseases, crop lodging, and weeds. The emphasis is on satellite sensors in optical, thermal, microwave, and fluorescence frequencies. We conclude the review with an outlook of challenges and recommendations. This paper is the first of a two-part review series. The second part reviews the role of satellite remote sensing in water security, wherein we discuss the aspects of water quality and quantity along with extremes (floods and droughts).",
        "DOI": "10.1016/j.jhydrol.2020.124905",
        "paper_author": "Karthikeyan L.",
        "affiliation_name": "Indian Institute of Technology Bombay",
        "affiliation_city": "Mumbai",
        "affiliation_country": "India",
        "affiliation_id": "60014153",
        "affiliation_state": "MH"
    },
    {
        "paper_title": "BAT: Deep Learning Methods on Network Intrusion Detection Using NSL-KDD Dataset",
        "publication": "IEEE Access",
        "citied_by": "322",
        "cover_date": "2020-01-01",
        "Abstract": "Intrusion detection can identify unknown attacks from network traffics and has been an effective means of network security. Nowadays, existing methods for network anomaly detection are usually based on traditional machine learning models, such as KNN, SVM, etc. Although these methods can obtain some outstanding features, they get a relatively low accuracy and rely heavily on manual design of traffic features, which has been obsolete in the age of big data. To solve the problems of low accuracy and feature engineering in intrusion detection, a traffic anomaly detection model BAT is proposed. The BAT model combines BLSTM (Bidirectional Long Short-term memory) and attention mechanism. Attention mechanism is used to screen the network flow vector composed of packet vectors generated by the BLSTM model, which can obtain the key features for network traffic classification. In addition, we adopt multiple convolutional layers to capture the local features of traffic data. As multiple convolutional layers are used to process data samples, we refer BAT model as BAT-MC. The softmax classifier is used for network traffic classification. The proposed end-to-end model does not use any feature engineering skills and can automatically learn the key features of the hierarchy. It can well describe the network traffic behavior and improve the ability of anomaly detection effectively. We test our model on a public benchmark dataset, and the experimental results demonstrate our model has better performance than other comparison methods.",
        "DOI": "10.1109/ACCESS.2020.2972627",
        "paper_author": "Su T.",
        "affiliation_name": "Tianjin Normal University",
        "affiliation_city": "Tianjin",
        "affiliation_country": "China",
        "affiliation_id": "60022149",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Deep learning in the construction industry: A review of present status and future innovations",
        "publication": "Journal of Building Engineering",
        "citied_by": "320",
        "cover_date": "2020-11-01",
        "Abstract": "The construction industry is known to be overwhelmed with resource planning, risk management and logistic challenges which often result in design defects, project delivery delays, cost overruns and contractual disputes. These challenges have instigated research in the application of advanced machine learning algorithms such as deep learning to help with diagnostic and prescriptive analysis of causes and preventive measures. However, the publicity created by tech firms like Google, Facebook and Amazon about Artificial Intelligence and applications to unstructured data is not the end of the field. There abound many applications of deep learning, particularly within the construction sector in areas such as site planning and management, health and safety and construction cost prediction, which are yet to be explored. The overall aim of this article was to review existing studies that have applied deep learning to prevalent construction challenges like structural health monitoring, construction site safety, building occupancy modelling and energy demand prediction. To the best of our knowledge, there is currently no extensive survey of the applications of deep learning techniques within the construction industry. This review would inspire future research into how best to apply image processing, computer vision, natural language processing techniques of deep learning to numerous challenges in the industry. Limitations of deep learning such as the black box challenge, ethics and GDPR, cybersecurity and cost, that can be expected by construction researchers and practitioners when adopting some of these techniques were also discussed.",
        "DOI": "10.1016/j.jobe.2020.101827",
        "paper_author": "Akinosho T.D.",
        "affiliation_name": "Bristol Business School",
        "affiliation_city": "Bristol",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60114346",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Event-Triggered Consensus Control for Multi-Agent Systems against False Data-Injection Attacks",
        "publication": "IEEE Transactions on Cybernetics",
        "citied_by": "320",
        "cover_date": "2020-05-01",
        "Abstract": "In this article, the event-triggered security consensus problem is studied for time-varying multiagent systems (MASs) against false data-injection attacks (FDIAs) and parameter uncertainties over a given finite horizon. In the process of information transmission, the malicious attacker tries to inject false signals to destroy consensus by compromising the integrity of measurements and control signals. The randomly occurring stealthy FDIAs on sensors and actuators are modeled by the Bernoulli processes. In order to reduce the unnecessary utilization of communication resources, an event-triggered control mechanism with state-dependent threshold is adopted to update the control input signal. The main objective of this article is to design a controller such that, under randomly occurring FDIAs and admissible parameter uncertainties, the MASs achieve consensus. By utilizing stochastic analysis method, two sufficient criteria are derived to ensure that the prescribed H∞ consensus performance can be achieved. Then, the desired controller gains are derived by solving recursive linear matrix inequalities. Simulation results are presented to illustrate the effectiveness and applicability of the proposed control method.",
        "DOI": "10.1109/TCYB.2019.2937951",
        "paper_author": "Li X.M.",
        "affiliation_name": "Guangdong University of Technology",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60007155",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Healthcare data breaches: Insights and implications",
        "publication": "Healthcare (Switzerland)",
        "citied_by": "319",
        "cover_date": "2020-06-01",
        "Abstract": "The Internet of Medical Things, Smart Devices, Information Systems, and Cloud Services have led to a digital transformation of the healthcare industry. Digital healthcare services have paved the way for easier and more accessible treatment, thus making our lives far more comfortable. However, the present day healthcare industry has also become the main victim of external as well as internal attacks. Data breaches are not just a concern and complication for security experts; they also affect clients, stakeholders, organizations, and businesses. Though the data breaches are of different types, their impact is almost always the same. This study provides insights into the various categories of data breaches faced by different organizations. The main objective is to do an in-depth analysis of healthcare data breaches and draw inferences from them, thereby using the findings to improve healthcare data confidentiality. The study found that hacking/IT incidents are the most prevalent forms of attack behind healthcare data breaches, followed by unauthorized internal disclosures. The frequency of healthcare data breaches, magnitude of exposed records, and financial losses due to breached records are increasing rapidly. Data from the healthcare industry is regarded as being highly valuable. This has become a major lure for the misappropriation and pilferage of healthcare data. Addressing this anomaly, the present study employs the simple moving average method and the simple exponential soothing method of time series analysis to examine the trend of healthcare data breaches and their cost. Of the two methods, the simple moving average method provided more reliable forecasting results.",
        "DOI": "10.3390/healthcare8020133",
        "paper_author": "Seh A.H.",
        "affiliation_name": "Babasaheb Bhimrao Ambedkar University",
        "affiliation_city": "Lucknow",
        "affiliation_country": "India",
        "affiliation_id": "60021084",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Blockchain in healthcare: A systematic literature review, synthesizing framework and future research agenda",
        "publication": "Computers in Industry",
        "citied_by": "319",
        "cover_date": "2020-11-01",
        "Abstract": "This study presents a systematic literature review (SLR) of research on blockchain applications in the healthcare domain. The review incorporated 42 articles presenting state-of-the-art knowledge on the current implications and gaps pertaining to the use of blockchain technology for improving healthcare processes. The SLR findings indicate that blockchain is being used to develop novel and advanced interventions to improve the prevalent standards of handling, sharing, and processing of medical data and personal health records. The application of blockchain technology is undergoing a conceptual evolution in the healthcare industry where it has added significant value through improved efficiency, access control, technological advancement, privacy protection, and security of data management processes. The findings also suggest that the extant limitations primarily pertain to model performance, as well as the constraints and costs associated with implementation. An integrated framework is presented to address potential areas wherein future researchers can contribute significant value, including addressing concerns regarding regulatory compliance, system architecture, and data protection. Finally, the SLR suggests that future research can facilitate the widespread deployment of blockchain applications to address critical issues related to medical diagnostics, legal compliance, avoiding fraud, and improving patient care in cases of remote monitoring or emergencies.",
        "DOI": "10.1016/j.compind.2020.103290",
        "paper_author": "Tandon A.",
        "affiliation_name": "Turun Kauppakorkeakoulu",
        "affiliation_city": "Turku",
        "affiliation_country": "Finland",
        "affiliation_id": "60033393",
        "affiliation_state": "Southwest Finland"
    },
    {
        "paper_title": "Contributions and risks of artificial intelligence (AI) in building smarter cities: Insights from a systematic review of the literature",
        "publication": "Energies",
        "citied_by": "317",
        "cover_date": "2020-01-01",
        "Abstract": "Artificial intelligence (AI) is one of the most disruptive technologies of our time. Interest in the use of AI for urban innovation continues to grow. Particularly, the rise of smart cities—urban locations that are enabled by community, technology, and policy to deliver productivity, innovation, livability, wellbeing, sustainability, accessibility, good governance, and good planning—has increased the demand for AI-enabled innovations. There is, nevertheless, no scholarly work that provides a comprehensive review on the topic. This paper generates insights into how AI can contribute to the development of smarter cities. A systematic review of the literature is selected as the methodologic approach. Results are categorized under the main smart city development dimensions, i.e., economy, society, environment, and governance. The findings of the systematic review containing 93 articles disclose that: (a) AI in the context of smart cities is an emerging field of research and practice. (b) The central focus of the literature is on AI technologies, algorithms, and their current and prospective applications. (c) AI applications in the context of smart cities mainly concentrate on business efficiency, data analytics, education, energy, environmental sustainability, health, land use, security, transport, and urban management areas. (d) There is limited scholarly research investigating the risks of wider AI utilization. (e) Upcoming disruptions of AI in cities and societies have not been adequately examined. Current and potential contributions of AI to the development of smarter cities are outlined in this paper to inform scholars of prospective areas for further research.",
        "DOI": "10.3390/en13061473",
        "paper_author": "Yigitcanlar T.",
        "affiliation_name": "Queensland University of Technology",
        "affiliation_city": "Brisbane",
        "affiliation_country": "Australia",
        "affiliation_id": "60011019",
        "affiliation_state": "QLD"
    },
    {
        "paper_title": "Passban IDS: An Intelligent Anomaly-Based Intrusion Detection System for IoT Edge Devices",
        "publication": "IEEE Internet of Things Journal",
        "citied_by": "314",
        "cover_date": "2020-08-01",
        "Abstract": "Cyber-threat protection is today's one of the most challenging research branches of information technology, while the exponentially increasing number of tiny, connected devices able to push personal data to the Internet is doing nothing but exacerbating the battle between the involved parties. Thus, this protection becomes crucial with a typical Internet-of-Things (IoT) setup, as it usually involves several IoT-based data sources interacting with the physical world within various application domains, such as agriculture, health care, home automation, critical industrial processes, etc. Unfortunately, contemporary IoT devices often offer very limited security features, laying themselves open to always new and more sophisticated attacks and also inhibiting the expected global adoption of IoT technologies, not to mention millions of IoT devices already deployed without any hardware security support. In this context, it is crucial to develop tools able to detect such cyber threats. In this article, we present Passban, an intelligent intrusion detection system (IDS) able to protect the IoT devices that are directly connected to it. The peculiarity of the proposed solution is that it can be deployed directly on very cheap IoT gateways (e.g., single-board PCs currently costing few tens of U.S. dollars), hence taking full advantage of the edge computing paradigm to detect cyber threats as close as possible to the corresponding data sources. We will demonstrate that Passban is able to detect various types of malicious traffic, including Port Scanning, HTTP and SSH Brute Force, and SYN Flood attacks with very low false positive rates and satisfactory accuracies.",
        "DOI": "10.1109/JIOT.2020.2970501",
        "paper_author": "Eskandari M.",
        "affiliation_name": "Center for REsearch And Telecommunication Experimentation for NETworked communities",
        "affiliation_city": "Trento",
        "affiliation_country": "Italy",
        "affiliation_id": "60103308",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Wireless sensor network for structural health monitoring: A contemporary review of technologies, challenges, and future direction",
        "publication": "Structural Health Monitoring",
        "citied_by": "307",
        "cover_date": "2020-05-01",
        "Abstract": "The importance of wireless sensor networks in structural health monitoring is unceasingly growing, because of the increasing demand for both safety and security in the cities. The speedy growth of wireless technologies has considerably developed the progress of structural monitoring systems with the combination of wireless sensor network technology. Wireless sensor network–based structural health monitoring system introduces a novel technology with compelling advantages in comparison to traditional wired system, which has the benefits of reducing installation and maintenance costs of structural health monitoring systems. However, structural health monitoring has brought an additional complex challenges in network design to wireless sensor networks. This article presents a contemporary review of collective experience the researchers have gained from the application of wireless sensor networks for structural health monitoring. Technologies of wired and wireless sensor systems are investigated along with wireless sensor node architecture, functionality, communication technologies, and its popular operating systems. Then, comprehensive summaries for the state-of-the-art academic and commercial wireless platform technologies used in laboratory testbeds and field test deployments for structural health monitoring applications are reviewed and tabulated. Following that, classification taxonomy of the key challenges associated with wireless sensor networks for structural health monitoring to assist the researchers in understanding the obstacles and the suitability of implementing wireless technology for structural health monitoring applications are deeply discussed with available research efforts in order to overcome these challenges. Finally, open research issues in wireless sensor networks for structural health monitoring are explored.",
        "DOI": "10.1177/1475921719854528",
        "paper_author": "Abdulkarem M.",
        "affiliation_name": "Universiti Putra Malaysia",
        "affiliation_city": "Serdang",
        "affiliation_country": "Malaysia",
        "affiliation_id": "60025577",
        "affiliation_state": "Selangor"
    },
    {
        "paper_title": "Blockchain: case studies in food supply chain visibility",
        "publication": "Supply Chain Management",
        "citied_by": "306",
        "cover_date": "2020-06-16",
        "Abstract": "Purpose: This paper aims to investigate how blockchain has moved beyond cryptocurrencies and is being deployed to enhance visibility and trust in supply chains, their limitations and potential impact. Design/methodology/approach: Qualitative analysis are undertaken via case studies drawn from food companies using semi-structured interviews. Findings: Blockchain is demonstrated as an enabler of visibility in supply chains. Applications at scale are most likely for products where the end consumer is prepared to pay the premium currently required to fund the technology, e.g. baby food. Challenges remain in four areas: trust of the technology, human error and fraud at the boundaries, governance, consumer data access and willingness to pay. Research limitations/implications: The paper shows that blockchain can be utilised as part of a system generating visibility and trust in supply chains. Research directs academic attention to issues that remain to be addressed. The challenges pertaining to the technology itself we believe to be generalisable; those specific to the food industry may not hold elsewhere. Practical implications: From live case studies, we provide empirical evidence that blockchain provides visibility of exchanges and reliable data in fully digitised supply chains. This provides provenance and guards against counterfeit goods. However, firms will need to work to gain consumer buy-in for the technology following repeated past claims of trustworthiness. Originality/value: This paper provides primary evidence from blockchain use cases “in the wild”. The exploratory case studies examine application of blockchain for supply chain visibility.",
        "DOI": "10.1108/SCM-08-2019-0300",
        "paper_author": "Rogerson M.",
        "affiliation_name": "University of Bath, School of Management",
        "affiliation_city": "Bath",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60116562",
        "affiliation_state": "Somerset"
    },
    {
        "paper_title": "Machine learning driven smart electric power systems: Current trends and new perspectives",
        "publication": "Applied Energy",
        "citied_by": "305",
        "cover_date": "2020-08-15",
        "Abstract": "The current power systems are undergoing a rapid transition towards their more active, flexible, and intelligent counterpart smart grid, which brings about tremendous challenges in many domains, e.g., integration of various distributed renewable energy sources, cyberspace security, demand-side management, and decision-making of system planning and operation. The fulfillment of advanced functionalities in the smart grid firmly relies on the underlying information and communication infrastructure, and the efficient handling of a massive amount of data generated from various sources, e.g., smart meters, phasor measurement units, and various forms of sensors. In this paper, a comprehensive survey of over 200 recent publications is conducted to review the state-of-the-art practices and proposals of machine learning techniques and discuss the trend in a wide range of smart grid application domains. This study demonstrates the increasing interest and rapid expansion in the use of machine learning techniques to successfully address the technical challenges of the smart grid from various aspects. It is also revealed that some issues still remain open and worth further research efforts, such as the high-performance data processing and analysis for intelligent decision-making in large-scale complex multi-energy systems, lightweight machine learning-based solutions, and so forth. Moreover, the future perspectives of utilizing advanced computing and communication technologies, e.g., edge computing, ubiquitous internet of things and 5G wireless networks, in the smart grid are also highlighted. To the best of our knowledge, this is the first review of machine learning-driven solutions covering almost all the smart grid application domains. Machine learning will be one of the major drivers of future smart electric power systems, and this study can provide a preliminary foundation for further exploration and development of related knowledge and insights.",
        "DOI": "10.1016/j.apenergy.2020.115237",
        "paper_author": "Ibrahim M.S.",
        "affiliation_name": "Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60003970",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Food insecurity and mental health: A systematic review and meta-analysis",
        "publication": "Public Health Nutrition",
        "citied_by": "304",
        "cover_date": "2020-07-01",
        "Abstract": "Objective: Food security has been suggested to be a risk factor for depression, stress and anxiety. We therefore undertook a systematic review and meta-analysis of available publications to examine these associations further.Design: Relevant studies were identified by searching Web of Science, Embase, Scopus and PubMed databases up to January 2019.Setting: OR was pooled using a random-effects model. Standard methods were used for assessment of heterogeneity and publication bias.Participants: Data were available from nineteen studies with 372 143 individual participants from ten different countries that were pooled for the meta-analysis.Results: The results showed there was a positive relationship between food insecurity (FI) and risk of depression (OR = 1·40; 95 % CI: 1·30, 1·58) and stress (OR = 1·34; 95 % CI: 1·24, 1·44) but not anxiety. Subgroup analysis by age showed that subjects older than ≥65 years exhibited a higher risk of depression (OR = 1·75; 95 % CI: 1·20, 2·56) than younger participants (OR = 1·34; 95 % CI: 1·20, 1·50), as well as a greater risk of depression in men (OR = 1·42; 95 % CI: 1·17, 1·72) than women (OR = 1·30; 95 % CI: 1·16, 1·46). Finally, subgroup analysis according to geographical location illustrated that food insecure households living in North America had the highest risk of stress and anxiety.Conclusions: The evidence from this meta-analysis suggests that FI has a significant effect on the likelihood of being stressed or depressed. This indicates that health care services, which alleviate FI, would also promote holistic well-being in adults.",
        "DOI": "10.1017/S136898001900435X",
        "paper_author": "Pourmotabbed A.",
        "affiliation_name": "Kermanshah University of Medical Sciences",
        "affiliation_city": "Kermanshah",
        "affiliation_country": "Iran",
        "affiliation_id": "60009057",
        "affiliation_state": "Kermanshah"
    },
    {
        "paper_title": "5G network-based Internet of Things for demand response in smart grid: A survey on application potential",
        "publication": "Applied Energy",
        "citied_by": "304",
        "cover_date": "2020-01-01",
        "Abstract": "Demand response (DR) has been widely regarded as an effective way to provide regulation services for smart grids by controlling demand-side resources via new and improved information and communication technologies. Emerging 5G networks and 5G-based Internet of Things (IoTs) can doubtless provide better infrastructure for DR, owing to 5G's advantages of fast transfer speed, high reliability, robust security, low power consumption, and massive number of connections. However, nearly none of the existing studies have applied 5G technology to DR, which will be the subject surveyed in this paper. First, the concept of DR and recent practical advances are investigated, especially the application of communication technologies to DR. Then, a comprehensive review of the cyber security, consumer privacy, and reliability of DR is presented. These topics received little attention in the past, but they will be among the most crucial factors in the future. In addition, the essential features and typical application scenarios of 5G communication are investigated. On this basis, the advantages, methods, recent advances, and implementation planning of 5G on DR are studied. Finally, the future work that must urgently be conducted in order to achieve the application of 5G to DR is discussed. This paper's application survey of 5G on DR is carried out before 5G technology enters the large-scale commercial stage, so as to provide references and guidelines for developing future 5G networks in the smart grid paradigm.",
        "DOI": "10.1016/j.apenergy.2019.113972",
        "paper_author": "Hui H.",
        "affiliation_name": "College of Electrical Engineering, Zhejiang University",
        "affiliation_city": "Hangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117834",
        "affiliation_state": "Zhejiang"
    },
    {
        "paper_title": "Machine Learning Adoption in Blockchain-Based Smart Applications: The Challenges, and a Way Forward",
        "publication": "IEEE Access",
        "citied_by": "301",
        "cover_date": "2020-01-01",
        "Abstract": "In recent years, the emergence of blockchain technology (BT) has become a unique, most disruptive, and trending technology. The decentralized database in BT emphasizes data security and privacy. Also, the consensus mechanism in it makes sure that data is secured and legitimate. Still, it raises new security issues such as majority attack and double-spending. To handle the aforementioned issues, data analytics is required on blockchain based secure data. Analytics on these data raises the importance of arisen technology Machine Learning (ML). ML involves the rational amount of data to make precise decisions. Data reliability and its sharing are very crucial in ML to improve the accuracy of results. The combination of these two technologies (ML and BT) can provide highly precise results. In this paper, we present a detailed study on ML adoption for making BT-based smart applications more resilient against attacks. There are various traditional ML techniques, for instance, Support Vector Machines (SVM), clustering, bagging, and Deep Learning (DL) algorithms such as Convolutional Neural Network (CNN) and Long short-Term memory (LSTM) can be used to analyse the attacks on a blockchain-based network. Further, we include how both the technologies can be applied in several smart applications such as Unmanned Aerial Vehicle (UAV), Smart Grid (SG), healthcare, and smart cities. Then, future research issues and challenges are explored. At last, a case study is presented with a conclusion.",
        "DOI": "10.1109/ACCESS.2019.2961372",
        "paper_author": "Tanwar S.",
        "affiliation_name": "Nirma University, Institute of Technology",
        "affiliation_city": "Ahmedabad",
        "affiliation_country": "India",
        "affiliation_id": "60115002",
        "affiliation_state": "GJ"
    }
]