[
    {
        "paper_title": "The impact of e-learning and social parameters on students' academic performance",
        "paper_author": "Petrusevich D.A.",
        "publication": "Science for Education Today",
        "citied_by": "5",
        "cover_date": "2020-12-31",
        "Abstract": "Introduction. The article examines the problem of assessing students' academic performance in the current situation. The purpose of the paper is to evaluate the influence of e-learning and some social and behavioral parameters on students' academic performance. Materials and Methods. The author employed the machine learning procedures in order to identify and assess the current problems of the educational system, students' behavior, and universities' policy. Methods of mathematical analysis and statistics as well as ensemble methods (gradient boosting and the random forest algorithms) were used in order to achieve high accuracy of the research. Results. The author conducted the analysis of the following datasets devoted to academic performance at higher and secondary educational institutions in a number of countries: Students' Performance in Portugal, E-learning Student Reactions and Students' Academic Performance. The purposes of the current study were to identify statistical correlations between social parameters of students and the level of their academic performance and to understand how academic performance is determined by the implementation of online learning and blended learning. The research findings suggest that mathematical statistics and data analysis methods allow to identify correlations between students' performance data and reveal hidden relationships which can be important for university staff. Conclusions. In conclusion, the author summarizes the results of evaluating the impact of the introduction of e-learning elements and some social parameters on students' academic performance.",
        "DOI": "10.15293/2658-6762.2006.08",
        "affiliation_name": "MIREA - Russian Technological University (RTU MIREA)",
        "affiliation_city": "Moscow",
        "affiliation_country": "Russian Federation",
        "affiliation_id": "60096204",
        "affiliation_state": "Moscow Oblast"
    },
    {
        "paper_title": "Learning method for autonomous air combat based on experience transfer",
        "paper_author": "Zhou K.",
        "publication": "Hangkong Xuebao/Acta Aeronautica et Astronautica Sinica",
        "citied_by": "2",
        "cover_date": "2020-12-25",
        "Abstract": "Most of the existing machine learning methods are in interactive learning mode, whose training process relies heavily on the interactive data with the environment. Air combat is a training mission with sparse rewards, with the system usually exploring for a long period of time to find actions that can obtain rewards during the beginning stage of learning. Retraining for every new mission wastes the computing resources. Therefore, a learning method based on experience transfer is designed in this paper, enabling the trained agent to share knowledge with the new agent and thereby improving its learning efficiency in the new task. First of all, a learning model based on experience transfer is constructed by referring to the phenomenon that mankind can learn rapidly through experiences. Secondly, considering both the knowledge sharing and characteristics of the new task, the connotation of experience is defined, and a cognitive mode of \"knowledge + task → experience\" is established. Thirdly, a reference learning method is designed, combining external experience with the task to further transform it into knowledge of the new agent. Finally, using experience applicability as the screening index, we analyze the influence of experience applicability on the reference learning efficiency, determining the screening boundary of implementing the reference learning. The new agent can therefore obtain preliminary knowledge about the new mission by reference learning and find action policies that can obtain reward so as to improve the learning speed in the new learning mission.",
        "DOI": "10.7527/S1000-6893.2020.24285",
        "affiliation_name": "Air Force Engineering University China",
        "affiliation_city": "Xi'an",
        "affiliation_country": "China",
        "affiliation_id": "60069720",
        "affiliation_state": "Shaanxi"
    },
    {
        "paper_title": "Proceedings of 2020 7th International Conference on Networking, Systems and Security, NSysS 2020",
        "paper_author": "NA",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "0",
        "cover_date": "2020-12-22",
        "Abstract": "The proceedings contain 15 papers. The topics discussed include: can COVID-19 change the Big5 personality traits of healthcare workers?; attacks on health workers during COVID-19 pandemic - data exploration and news article detection using NLP and GRU model; application of machine learning based hospital up-gradation policy for Bangladesh; a benchmark study on machine learning methods using several feature extraction techniques for news genre detection from Bangla news articles & titles; machine learning based malware detection on encrypted traffic: a comprehensive performance study; efficient feature selection for detecting botnets based on network traffic and behavior analysis; and solving the maze of diagnosing Parkinson’s disease based on portable EEG sensing to be adaptable to go in-the-wild.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of Machine Learning Based Hospital Up-gradation Policy for Bangladesh",
        "paper_author": "Shuvo S.S.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "4",
        "cover_date": "2020-12-22",
        "Abstract": "Hospital beds are an essential part of delivering medical services to the patients. Due to the hospital bed demand's stochastic nature, it is hard to predict future needs and devise an appropriate augmentation scheme. In this work, we consider Bangladesh as a test case where hospital beds are inadequate, and a sudden surge in demand can cause a massive loss of lives and wealth. We propose a deep reinforcement learning (RL) based policy for hospital capacity up-gradation schedule. The deep RL agent monitors population growth and current bed capacity and recommends the optimal number of beds for future inclusion. We utilize the state-of-the-art machine learning (ML) algorithm, Advantage Actor-Critic (A2C), to minimize the cumulative cost. This policy outperforms the straight forward strategies: Fixed upgrade and complain based upgrade.",
        "DOI": "10.1145/3428363.3428364",
        "affiliation_name": "Gono Bishwabidyalay",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60109914",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Social media security threats investigation and mitigation methods: A preliminary review",
        "paper_author": "Singh M.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "4",
        "cover_date": "2020-12-22",
        "Abstract": "Recent advancement of data collection and coupled statistics, big data became a significant issue in various research areas like: Machine learning, data mining, social networks, artificial intelligence, etc. Social networking is used as a platform for various applications like: government, business, educational, political, dating and matrimonial, etc. Like each and every platform, social networking too has its own set of pros and cons. We examine the types of posting on social media websites and influence of posting data and privacy concerns of Facebook and twitter users. This study indicates the different concerns of users regarding posting information and its influences of user voiced privacy concerns. It is beneficial in fields like: education, advertisements, online shopping but people get addicted to social networking, its time consuming in various issues and can be misused for cybercrimes. We've discussed the e-government objectives of using social media. Social networking is also vulnerable at different stages and attacked in several ways that includes evil twin attack, virus attack, phishing attack, account hijacking, data breach attack, fraud and scams. Site monitoring, developing security policies, educating users and training programs, updating software, archiving, media contents are several mitigation techniques are used to reduce the effects of cyber-attacks.",
        "DOI": "10.1088/1742-6596/1706/1/012142",
        "affiliation_name": "Chandigarh Group of Colleges Jhanjeri",
        "affiliation_city": "Mohali",
        "affiliation_country": "India",
        "affiliation_id": "60280932",
        "affiliation_state": "PB"
    },
    {
        "paper_title": "Gender and ethnic differences in publication of BMJ letters to the editor: An observational study using machine learning",
        "paper_author": "Zeina M.",
        "publication": "BMJ Open",
        "citied_by": "10",
        "cover_date": "2020-12-21",
        "Abstract": "Objectives To analyse the relationship between first author's gender and ethnicity (estimated from first name and surname), and chance of publication of rapid responses in the British Medical Journal (BMJ). To analyse whether other features of the rapid response account for any gender or ethnic differences, including the presence of multiple authors, declaration of conflicts of interests, the presence of Twitter handle, word count, reading ease, spelling and grammatical mistakes, and the presence of references. Design A retrospective observational study. Setting Website of the BMJ (BMJ.com). Participants Publicly available rapid responses submitted to BMJ.com between 1998 and 2018. Main outcome measures Publication of a rapid response as a letter to the editor in the BMJ. Results We analysed 113 265 rapid responses, of which 8415 were published as letters to the editor (7.4%). Statistically significant univariate correlations were found between odds of publication and first author estimated gender and ethnicity, multiple authors, declaration of conflicts of interest, the presence of Twitter handle, word count, reading ease, spelling and grammatical mistakes, and the presence of references. Multivariate analysis showed that first author estimated gender and ethnicity predicted publication after taking into account the other factors. Compared to white authors, black authors were 26% less likely to be published (OR: 0.74, CI: 0.57-0.96), Asian and Pacific Islander authors were 46% less likely to be published (OR: 0.54, CI: 0.49-0.59) and Hispanic authors were 49% less likely to be published (OR: 0.51, CI: 0.41-0.64). Female authors were 10% less likely to be published (OR: 0.90, CI: 0.85-0.96) than male authors. Conclusion Ethnic and gender differences in rapid response publication remained after accounting for a broad range of features, themselves all predictive of publication. This suggests that the reasons for the differences of these groups lies elsewhere.",
        "DOI": "10.1136/bmjopen-2020-037269",
        "affiliation_name": "Barts Health NHS Trust",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60159931",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Log-based malicious activity detection using machine and deep learning",
        "paper_author": "Tarnowska K.A.",
        "publication": "Malware Analysis Using Artificial Intelligence and Deep Learning",
        "citied_by": "0",
        "cover_date": "2020-12-20",
        "Abstract": "This chapter describes the application of intelligent computational techniques to the problem of malicious activity detection. It is proposed to embed machine and deep learning models for malicious activity detection into the framework of a log-based decision support system (DSS) for information security administrators. It is expected that such a solution will enable organizational-wide protection of informational assets, by providing accurate and comprehensive real-time insights into violations of information security policies. In this work, we present experiments and results on database systems' log analysis using traditional machine learning (ML) methods and deep learning (DL) on the synthetic log dataset simulating user activity in a hypothetical company.",
        "DOI": "10.1007/978-3-030-62582-5_23",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Multi-Agent Reinforcement Learning using the Deep Distributed Distributional Deterministic Policy Gradients Algorithm",
        "paper_author": "Farag W.",
        "publication": "2020 International Conference on Innovation and Intelligence for Informatics, Computing and Technologies, 3ICT 2020",
        "citied_by": "9",
        "cover_date": "2020-12-20",
        "Abstract": "In this paper, the Deep Distributed Distributional Deterministic Policy Gradients (D4PG) reinforcement learning algorithm is adopted to train a multi-agent action in a cooperative game environment. The algorithm is experimented on training the agents to play a game of tennis against each other. The architectures of the actor and cretic networks are meticulously designed and the D4PG hyperparameters are carefully tuned. The trained agents are successfully tested in the Unity Machine Learning Agents environment. The testing shows the powerful performance of the D4PG algorithm in training multi-agents in complex environments.",
        "DOI": "10.1109/3ICT51146.2020.9311945",
        "affiliation_name": "American University of the Middle East",
        "affiliation_city": "Al Ahmadi",
        "affiliation_country": "Kuwait",
        "affiliation_id": "60105846",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Assessment of machine learning, time series, response surface methodology and empirical models in prediction of global solar radiation",
        "paper_author": "Gürel A.E.",
        "publication": "Journal of Cleaner Production",
        "citied_by": "117",
        "cover_date": "2020-12-20",
        "Abstract": "Solar radiation (SR) knowledge plays a vital role in the design, modelling, and operation of solar energy conversion systems and future energy investment policies of the governments. However, these data are not measured for all regions due to the non-availability of SR measurement equipment at the weather stations. Therefore, SR has to be accurately predicted using various prediction models. In this research, four models from different classes are being used to predict monthly average daily global SR data. The models used in this study are based on a machine-learning algorithm (feed-forward neural network), empirical models (3 Angstrom-type models), time series (Holt-Winters), and mathematical model (RSM). As the prediction locations, four provinces (Ankara, Karaman, Kilis, and Şırnak) in Turkey are selected. The dataset including pressure, relative humidity, wind speed, ambient temperature, and sunshine duration is supplied from the Turkish State Meteorological Service and it covers the years 2008–2018. In the study, monthly average daily global SR data for the year 2018 is being predicted, and the performance success of the models is discussed in terms of the following benchmarks R2, MBE, RMSE, MAPE, and t-stat. In the results, R2 value for all models is varying between 0.952 and 0.993 and MAPE and RMSE value for all models is smaller than 10% and 2 MJ/m2-day, respectively. Evaluation in terms of t-stat value, no models exceed the t-critic limit. Considering all the models together, ANN has presented the best results with an average R2, MBE, RMSE, MAPE, and t-stat of 0.9911, 0.1323 MJ/m2-day, 0.78 MJ/m2-day, 4.9263%, and 0.582, respectively. Then Holt-Winters, RSM, and empirical models closely followed it, respectively.",
        "DOI": "10.1016/j.jclepro.2020.122353",
        "affiliation_name": "Düzce Üniversitesi",
        "affiliation_city": "Duzce",
        "affiliation_country": "Turkey",
        "affiliation_id": "60024371",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Vision-Based Deep Learning Inference Approach of Biker Safety Hat Detection System",
        "paper_author": "MacAlisang J.",
        "publication": "7th IEEE International Conference on Engineering Technologies and Applied Sciences, ICETAS 2020",
        "citied_by": "0",
        "cover_date": "2020-12-18",
        "Abstract": "In the Philippines road accidents were prevalent among motorcycle riders. The motorcyclist was required to wear their helmet when on the road. Some motorcyclists didn't follow the rules on wearing a helmet as safety precautions on the road. To address this, policymakers are focusing on enforcing safe and law-abiding behavior in traffic. There is, however, a lack of comprehensive data on the safety-critical behavioral metric of the use of motorcycle helmets, especially in developing countries where the main mode of transport is the motorcycle. Targeted enforcement and safety campaigns that are critical for accident reduction are prohibited by this shortage of knowledge. Hence, The researchers developed an algorithm for detecting the helmet that was worn by the motorcyclist, by using a deep learning approach the object detection was done successfully. Based on the annotated images, frames of video, and live feed data that was collected, To detect active bikes, the researchers taught the algorithm to use their helmets. An overview of the algorithm's success on an annotated research data set and a study of available data on the use of human-registered helmets indicate that our approach is extremely reliable.",
        "DOI": "10.1109/ICETAS51660.2020.9484194",
        "affiliation_name": "Don Mariano Marcos Memorial State University",
        "affiliation_city": "Bacnotan",
        "affiliation_country": "Philippines",
        "affiliation_id": "60279751",
        "affiliation_state": "La Union"
    },
    {
        "paper_title": "An evaluation of neural machine translation and pre-trained word embeddings in multilingual neural sentiment analysis",
        "paper_author": "Manias G.",
        "publication": "Proceedings of 2020 IEEE International Conference on Progress in Informatics and Computing, PIC 2020",
        "citied_by": "8",
        "cover_date": "2020-12-18",
        "Abstract": "One of the main elements in several application domains, such as policy making, addresses the scope of public opinion analysis. The latter is recently realized through sentiment analysis and Natural Language Processing, for identifying and extracting subjective information from raw texts. An additional challenge refers to the exploitation and correlation of data from different languages, in order to analyse sentiments by considering all available information in a holistic way. This paper investigates the impact of Neural Machine Translation in sentiment analysis, based on the translation of text for which neural sentiment analysis in English has been already applied and is applied again on the translated German and Greek texts. The latter is performed through the same Neural Network models that were used in the original language, in order to analyse the differences between the performed neural sentiment analysis on the source and the target languages. The outcomes of the proposed approach have a twofold interpretation. While, it is concluded that modern Neural Machine Translation tools are mature enough to provide high accuracy translations and have minor impact on multilingual sentiment analysis, on the other hand it is shown that additional research should be performed on the multilingualism that pre-trained Word Embeddings can provide.",
        "DOI": "10.1109/PIC50277.2020.9350849",
        "affiliation_name": "University of Piraeus",
        "affiliation_city": "Piraeus",
        "affiliation_country": "Greece",
        "affiliation_id": "60010667",
        "affiliation_state": "Attica"
    },
    {
        "paper_title": "Verhealth Vetting medical voice applications through policy enforcement",
        "paper_author": "Shezan F.H.",
        "publication": "Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies",
        "citied_by": "18",
        "cover_date": "2020-12-17",
        "Abstract": "Healthcare applications on Voice Personal Assistant System (e.g., Amazon Alexa), have shown a great promise to deliver personalized health services via a conversational interface. However, concerns are also raised about privacy, safety, and service quality. In this paper, we propose VerHealth, to systematically assess health-related applications on Alexa for how well they comply with existing privacy and safety policies. VerHealth contains a static module and a dynamic module based on machine learning that can trigger and detect violation behaviors hidden deep in the interaction threads. We use VerHealth to analyze 813 health-related applications on Alexa by sending over 855,000 probing questions and analyzing 863,000 responses. We also consult with three medical school students (domain experts) to confirm and assess the potential violations. We show that violations are quite common, e.g., 86.36% of them miss disclaimers when providing medical information; 30.23% of them store user physical or mental health data without approval. Domain experts believe that the applications' medical suggestions are often factually-correct but are of poor relevance, and applications should have asked more questions before providing suggestions for over half of the cases. Finally, we use our results to discuss possible directions for improvements.",
        "DOI": "10.1145/3432233",
        "affiliation_name": "Virginia Polytechnic Institute and State University",
        "affiliation_city": "Blacksburg",
        "affiliation_country": "United States",
        "affiliation_id": "60027090",
        "affiliation_state": "VA"
    },
    {
        "paper_title": "Machine-learned models for the performance of six different solar PV technologies under the tropical environment",
        "paper_author": "Yassin H.",
        "publication": "2020 IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2020",
        "citied_by": "4",
        "cover_date": "2020-12-16",
        "Abstract": "Due to the recent environmental concerns and long-term challenges in energy security, the Global energy scenarios are shifting more towards sustainable and renewable energy resources. Brunei has planned to increase the use of cleaner energy technologies by contributing 10 percent or 954 GWh of renewable energy in its power generation mix by 2035. Out of the available renewable options, solar is the most promising one for Brunei, for example, the daily average solar installation is around 5kWh per day [1]. Though solar energy is an abundant resource, for optimally designing and successfully managing solar power projects, its availability in different time scales are to be analyzed and understood in a local context. In this paper, we present models for estimating the output of six different solar PV technologies using machine learning methods Performance data from the solar PV systems installed at the Tenaga Suria PV plant in Brunei are used to develop the models. Influence of relevant environmental parameters, such as irradiance, relative humidity, ambient temperature and wind speed on the power output has been analyzed for optimal feature selection. Performance models based on Support Vector Machine (SVM) and K-Nearest Neighbour (KNN) were developed and tested for predicting the PV system performance. Both the models could estimate the system performance with reasonably high level of accuracy.",
        "DOI": "10.1109/CSDE50874.2020.9411543",
        "affiliation_name": "Universitetet i Agder",
        "affiliation_city": "Kristiansand",
        "affiliation_country": "Norway",
        "affiliation_id": "60080184",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Portfolio Optimization with 2D Relative-Attentional Gated Transformer",
        "paper_author": "Kim T.W.",
        "publication": "2020 IEEE Asia-Pacific Conference on Computer Science and Data Engineering, CSDE 2020",
        "citied_by": "7",
        "cover_date": "2020-12-16",
        "Abstract": "Portfolio optimization is one of the most attentive fields that have been researched with machine learning approaches. Many researchers attempted to solve this problem using deep reinforcement learning due to its efficient inherence that can handle the property of financial markets. However, most of them can hardly be applicable to real-world trading since they ignore or extremely simplify the realistic constraints such as transaction costs or slippage. These constraints have a significantly negative impact on portfolio profitability. In this paper a conservative level of transaction fees and slippage are considered for the realistic experiment. To enhance the performance under those constraints, we propose a novel Deterministic Policy Gradient with 2D Relative-attentional Gated Transformer (DPGRGT) model. Applying learnable relative positional embeddings for the time and assets axes, the model better understands the peculiar structure of the financial data in the portfolio optimization domain. Also, gating layers and layer reordering are employed for stable convergence of Transformers in reinforcement learning. In our experiment using U.S. stock market data of 20 years, our model outperformed baseline models and demonstrated its effectiveness.",
        "DOI": "10.1109/CSDE50874.2020.9411635",
        "affiliation_name": "School of Computer Science",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60099659",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "The value–complexity trade-off for reinforcement learning based brain–computer interfaces",
        "paper_author": "Levi-Aharoni H.",
        "publication": "Journal of Neural Engineering",
        "citied_by": "1",
        "cover_date": "2020-12-16",
        "Abstract": "Objective. One of the recent developments in the field of brain–computer interfaces (BCI) is the reinforcement learning (RL) based BCI paradigm, which uses neural error responses as the reward feedback on the agent’s action. While having several advantages over motor imagery based BCI, the reliability of RL-BCI is critically dependent on the decoding accuracy of noisy neural error signals. A principled method is needed to optimally handle this inherent noise under general conditions. Approach. By determining a trade-off between the expected value and the informational cost of policies, the info-RL (IRL) algorithm provides optimal low-complexity policies, which are robust under noisy reward conditions and achieve the maximal obtainable value. In this work we utilize the IRL algorithm to characterize the maximal obtainable value under different noise levels, which in turn is used to extract the optimal robust policy for each noise level. Main results. Our simulation results of a setting with Gaussian noise show that the complexity level of the optimal policy is dependent on the reward magnitude but not on the reward variance, whereas the variance determines whether a lower complexity solution is favorable or not. We show how this analysis can be utilized to select optimal robust policies for an RL-BCI and demonstrate its use on EEG data. Significance. We propose here a principled method to determine the optimal policy complexity of an RL problem with a noisy reward, which we argue is particularly useful for RL-based BCI paradigms. This framework may be used to minimize initial training time and allow for a more dynamic and robust shared control between the agent and the operator under different conditions.",
        "DOI": "10.1088/1741-2552/abc8d8",
        "affiliation_name": "Hebrew University of Jerusalem",
        "affiliation_city": "Jerusalem",
        "affiliation_country": "Israel",
        "affiliation_id": "60007903",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Research on COVID-19 Global Forecast based on SIR Model-ML regression",
        "paper_author": "Wei H.",
        "publication": "Journal of Physics: Conference Series",
        "citied_by": "0",
        "cover_date": "2020-12-16",
        "Abstract": "Under the background of the global COVID-19 pandemic, the global COVID-19 epidemic spread was modeled and analyzed, and its future trend was predicted. The dataset covers 163 countries and almost 2 full months from 2020, which is enough data to get some clues about the pandemic. The epidemic situation was predicted by the fusion of SIR model and ML regression, and the results showed that the model analysis was basically consistent with the real performance of the epidemic development. Finally, the development stage and trend of the epidemic situation are evaluated to provide a basis for the government to formulate relevant epidemic prevention policies.",
        "DOI": "10.1088/1742-6596/1693/1/012065",
        "affiliation_name": "Beijing Institute of Graphic Communication",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60073441",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Spatially explicit calculation and simulation of estimating housing land consolidation potential in rural areas",
        "paper_author": "Zou L.",
        "publication": "Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering",
        "citied_by": "8",
        "cover_date": "2020-12-15",
        "Abstract": "Modeling of farmers' willingness to consolidation of abandoned homesteads plays an essential role in the prediction of regional land consolidation potential. Previous prediction models on land consolidation potential still have some limitations in the simulation of farmers' consolidation willingness and the spatial explicit prediction. The complex system modeling and machine learning provide effective tools for the behaviors simulation of land-use stakeholders. Land consolidation potential depends mainly on the farmers' willingness to consolidation, as well as the policies and land use planning. It is difficult to obtain enough negative training samples from the non-reclaimed area where farmers are opposed to the consolidation. There is a balance on the training samples, meaning that most training samples are positive. One-class classification approach has provided a good solution for the classification of imbalanced samples, due to only positive samples is selected to complete the training of classifiers. Hence, one-class classification can be used to solve the negative samples in the modeling of farmers' willingness to land consolidation. Therefore, an one class support vector machine (OCSVM) was selected to simulate the decision-making behaviors of the farmers. The OCSVM has been widely used as a type of one-class classification in image recognition and abnormal detection. A geographic information system (GIS) was used to build the model, in order to predict the land consolidation potential in a spatially explicit way. Furthermore, high-resolution remote sensing images were used to identify the abandoned homesteads in the study region. Pingtang was selected as the study area to evaluate the accuracy of model, where a mountainous and poverty town located in western Guangdong province, China. 4 449 positive samples were obtained, where the farmers would like to confer from the historical land consolidation project data in the study area. Another 141 negative samples were randomly selected from the non-reclaimed areas to evaluate the accuracy of model. Thus, a total of 4 590 unlabeled samples were obtained to train the model. The experimental results showed that the overall accuracy of model reached 96.36%, the prediction accuracy of positive sample was 96.88%, and the accuracy of negative samples was 80.14%, indicating that the performance of model was reliable for the potential prediction of land consolidation. The model was used to predict the land consolidation potential in the whole study area. The total area of abandoned homesteads identified by high-resolution remote sensing images was about 103.96 hm2, whereas, the predicted potential obtained by the model was about 94.74 hm2. However, there were many small spots in the study area that were too fragmented to be reclaimed. According to the land consolidation of Pingtang, the abandoned homesteads that can be reclaimed was only 36.02 hm2, accounting for 34.65% of the total areas. Consequently, terrain factors were also essential to affect the consolidation potential in mountainous and hilly areas. The model can be expected to better support the decision-making of land use planning, regional land remediation planning, and site selection in land remediation project.",
        "DOI": "10.11975/j.issn.1002-6819.2020.24.029",
        "affiliation_name": "Wuhan University",
        "affiliation_city": "Wuhan",
        "affiliation_country": "China",
        "affiliation_id": "60029306",
        "affiliation_state": "Hubei"
    },
    {
        "paper_title": "Impact of Urban Expansion and in Situ Greenery on Community-Wide Carbon Emissions: Method Development and Insights from 11 US Cities",
        "paper_author": "Milnar M.",
        "publication": "Environmental Science and Technology",
        "citied_by": "23",
        "cover_date": "2020-12-15",
        "Abstract": "Biogenic CO2 emissions in cities are shaped by urban land cover change which can release carbon stocks, and, carbon sequestration by in situ vegetation. To date, these two processes have not been studied together and compared with transboundary fossil fuel-based CO2 emissions of urban energy use. We leverage remote sensing and machine learning to quantify biogenic CO2 emissions between 2006 and 2012, across 11 U.S cities, including central and suburban cities, in different climate zones. Results indicate that in situ carbon sequestration by greenery varied moderately across cities (-2.1 to -0.87 Mg CO2 ha-1 yr-1), while emissions from the carbon stock change due to land conversion varied much more (-3.4 to 9.8 Mg CO2 ha-1 yr-1), indicating that the latter dominates biogenic CO2 emissions. Net biogenic CO2 emissions were negative (carbon sink) in four cities, while large net positive emissions were present in rapidly growing suburbs. As a ratio of community-wide energy use for travel and buildings, biogenic CO2 emissions were a small proportion in the core cities Denver (0.17%) and Minneapolis (0.33%) and as high as 38.2% in growing exurban communities. These results show that land cover change and greenery will be important policy levers in zero-carbon city planning.",
        "DOI": "10.1021/acs.est.0c02723",
        "affiliation_name": "School of Engineering and Applied Science",
        "affiliation_city": "Princeton",
        "affiliation_country": "United States",
        "affiliation_id": "60141284",
        "affiliation_state": "NJ"
    },
    {
        "paper_title": "Satellite-based assessment of the long-term efficacy of PM<inf>2.5</inf> pollution control policies across the Taiwan Strait",
        "paper_author": "Wang L.",
        "publication": "Remote Sensing of Environment",
        "citied_by": "24",
        "cover_date": "2020-12-15",
        "Abstract": "Evaluating the efficacy of air pollution control policies is an essential part of the decision-making process to develop new policies and improve existing measures. Since 2005, Fujian Province of Mainland China and Taiwan across the Taiwan Strait have both implemented aggressive air pollution control policies designed based on different principles, but a comprehensive evaluation of these control policies on PM2.5pollution levels is still lacking. In the current study, we assessed the effects of these policies in the Taiwan Strait Region from 2005 to 2018 using full-coverage, high-resolution PM2.5generated by a satellite-driven machine learning model. A ten-fold cross-validation for our prediction model showed an R2value of 0.89, demonstrating that these predictions can be used for policy evaluation. During the 14-year period, PM2.5levels in all areas of Fujian and Taiwan underwent a significant decrease. Separate regression models for policy evaluation in Taiwan and Fujian showed that all considered policies have mitigated PM2.5pollution to various degrees. The Clean Air Action Plans (CAAP) is the most effective control policy in Taiwan, while the Action Plan of Air Pollution Prevention and Control (APPC-AP) and Three-year Action Plan for Blue Skies (3YAP-BS) as well as their provincial implementation plans are the most successful in Fujian. The effectiveness of control policies, however, varies by land-use types especially for Taiwan.",
        "DOI": "10.1016/j.rse.2020.112067",
        "affiliation_name": "University of Chinese Academy of Sciences",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60027363",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Regional Electricity Sales Forecasting Research Based on Big Data Application Service Platform",
        "paper_author": "Qi C.",
        "publication": "2020 IEEE 3rd International Conference on Electronics and Communication Engineering, ICECE 2020",
        "citied_by": "4",
        "cover_date": "2020-12-14",
        "Abstract": "Regional monthly electricity sales forecast is an important basis for regional power grid planning and construction, evaluation of regional economic development and operation, and protection of residents' lives. It is also an important work of regional power regulation and management, decision-making of power generation and purchase, improvement of power supply equipment utilization rate and deepening of power system reform. Based on the current situation of power supply enterprise information development, distribution network business status and characteristics, this paper analyzes the factors affecting electricity sales. According to the characteristics of annual changes in electricity sales and data quality factors, the recurrent neural network model is selected based on the big data application service platform. The long short term memory neural network model performs multi-step multivariate prediction on time series, and uses the attention mechanism to combine two independent models for prediction. Experiments conducted on the historical electricity sales data set of a power supply company show that compared with traditional machine learning methods, this method has advantages in accuracy and efficiency.",
        "DOI": "10.1109/ICECE51594.2020.9352886",
        "affiliation_name": "State Grid Corporation of China",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60004246",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Forecasting of Electricity Generation for Hydro Power Plants",
        "paper_author": "Javed U.",
        "publication": "HONET 2020 - IEEE 17th International Conference on Smart Communities: Improving Quality of Life using ICT, IoT and AI",
        "citied_by": "3",
        "cover_date": "2020-12-14",
        "Abstract": "In today's world of modern technology and rapid increasing demand of electronics, electricity has become an essential and a vital part of our daily life. The under-developed or developing countries face several different challenges in order to manage demand and supply of electricity. The gap between demand and supply of electricity has a very strong effect on the economic growth. The forecasting of energy will play an important role for the policy makers to timely identify the sudden change in demand of electricity under given conditions. To this end, we developed a model for forecasting of electricity generation from hydro-power plants. Besides the parameters from hydropower plant, the forecasting model incorporates the temperature and rainfall in the catchment area of the dam. In this research work we analyzed the data for the energy generation trends on live data of Tarbela Dam, which consist of daily electricity generation for the last five years augmented with the temperature and rainfall data of the dam catchment area. Moreover, we have applied different supervised machine learning and time-series based models to forecast the energy production. The proposed solution is based on future forecasting of energy generation for hydro power plant, which can assist the policy makers in better decision making. The proposed research work will help in minimizing the increasing gap between energy demand and production considering weather conditions of the area. It can also help the power plant management to detect any anomaly or a failure in the electricity production of electricity by studying the deviation from the predicted trend. Our proposed method can forecast the production of electricity generation with Mean Absolute Error of 2.47 only.",
        "DOI": "10.1109/HONET50430.2020.9322841",
        "affiliation_name": "National University of Sciences and Technology",
        "affiliation_city": "Islamabad",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60059937",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "2020 7th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2020",
        "paper_author": "NA",
        "publication": "2020 7th International Conference on Internet of Things: Systems, Management and Security, IOTSMS 2020",
        "citied_by": "0",
        "cover_date": "2020-12-14",
        "Abstract": "The proceedings contain 42 papers. The topics discussed include: adopting machine learning to support the detection of malicious domain names; securing industrial control systems using physical device fingerprinting; a novel gateway selection protocol for three-layers integrated wireless networks; reliable abnormal event detection from IoT surveillance systems; a data generator for cloud-edge vehicle communication in multi domain cellular networks; a novel approach based on blockchain to enhance security with dynamic policy updating; scalable IoT architecture for balancing performance and security in mobile crowdsensing systems; investigating the potential of MFCC features in classifying respiratory diseases; and WSNB: wearable sensors with neural networks located in a base station for IoT environment.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "2020 59th IEEE Conference on Decision and Control, CDC 2020",
        "paper_author": "NA",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "0",
        "cover_date": "2020-12-14",
        "Abstract": "The proceedings contain 768 papers. The topics discussed include: a minimum energy filter for localization of an unmanned aerial vehicle; chance constrained covariance control for linear stochastic systems with output feedback; distributed composite adaptive synchronization of multiple uncertain Euler-Lagrange systems using cooperative initial excitation; online learning for job scheduling on heterogeneous machines; policy optimization for linear-quadratic zero-sum mean-field type games; on integral input-to-output stability properties; flexible regularization approaches for fairness in deep learning; information disclosure and network formation in news subscription services; performance analysis of stochastic model predictive control with direct and indirect feedback; distributed kalman filter for 3-D moving object tracking over sensor networks; and event-triggered control in presence of measurement noise: a space-regularization approach.",
        "DOI": "NA",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Learning Feedforward Control of a Hydraulic Clutch Actuation Path Based on Policy Gradients",
        "paper_author": "Mesmer F.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "0",
        "cover_date": "2020-12-14",
        "Abstract": "The hydraulic clutch actuation path used in heavy duty transmissions often shows a lot of variability due to manufacturing tolerances and ageing effects. Reason for this are in particular varying friction coefficients in the spools and external factors such as compliance with the specified service intervals or the choice of hydraulic fluid. As a direct consequence, the shift quality typically varies from one transmission to the next. To resolve this problem, this paper presents a machine learning algorithm for the feedforward control of the hydraulic clutch actuation path, a model-based and a data-based feedforward approach. The two approaches are evaluated and compared with each other in simulations with a high-fidelity model. As it turns out, the model-based version is to be preferred and therefore used in a real world evaluation on an embedded controller and a 16 tons wheel loader.",
        "DOI": "10.1109/CDC42340.2020.9303981",
        "affiliation_name": "ZF Friedrichshafen AG",
        "affiliation_city": "Friedrichshafen",
        "affiliation_country": "Germany",
        "affiliation_id": "60072206",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Adaptive Control for Linearizable Systems Using On-Policy Reinforcement Learning",
        "paper_author": "Westenbroek T.",
        "publication": "Proceedings of the IEEE Conference on Decision and Control",
        "citied_by": "6",
        "cover_date": "2020-12-14",
        "Abstract": "This paper proposes a framework for adaptively learning a feedback linearization-based tracking controller for an unknown system using discrete-time model-free policy-gradient parameter update rules. The primary advantage of the scheme over standard model-reference adaptive control techniques is that it does not require the learned inverse model to be invertible at all instances of time. This enables the use of general function approximators to approximate the linearizing controller for the system without having to worry about singularities. The overall learning system is stochastic, due to the random nature of the policy gradient updates, thus we combine analysis techniques commonly employed in the machine learning literature alongside stability arguments from adaptive control to demonstrate that with high probability the tracking and parameter errors concentrate near zero, under a standard persistency of excitation condition. A simulated example of a double pendulum demonstrates the utility of the proposed theory.",
        "DOI": "10.1109/CDC42340.2020.9304242",
        "affiliation_name": "University of California, Berkeley",
        "affiliation_city": "Berkeley",
        "affiliation_country": "United States",
        "affiliation_id": "60025038",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "An Attention Based Deep Reinforcement Learning Method for Virtual Network Function Placement",
        "paper_author": "Li S.",
        "publication": "2020 IEEE 6th International Conference on Computer and Communications, ICCC 2020",
        "citied_by": "4",
        "cover_date": "2020-12-11",
        "Abstract": "Network Function Virtualization (NFV) decouples network functions from the dedicated hardware and produces Virtual Network Functions (VNFs) in software. The VNFs are placed on hardware and are linked together to build a service chain. The design of an efficient VNF placement algorithm is crucial. The rapid development of machine learning, especially Deep Reinforcement Learning (Deep RL), allows us to address this problem. In this paper, we present an attention based sequence to sequence Deep RL method for VNF placement. Our approach is a policy based method optimized by REINFORCE with baseline. Our model receives physical hosts and service chain as input and produces the output sequence step by step with attention encoder and decoder. We demonstrate that our method outperforms the existing learning method and greedy heuristic.",
        "DOI": "10.1109/ICCC51575.2020.9345041",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022281",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "An Improved Q-Learning for System Power Optimization with Temperature, Performance and Energy Constraint Modeling",
        "paper_author": "Li L.",
        "publication": "2020 IEEE Conference on Telecommunications, Optics and Computer Science, TOCS 2020",
        "citied_by": "0",
        "cover_date": "2020-12-11",
        "Abstract": "Power management of embedded systems based on machine learning have drawn more and more attention. High-level software power management and optimization have gradually become important technologies for controlling the computer system power dissipation. In paper, we have employed an improved power optimization management technique which employ Q-learning algorithm based on temperature, performance and energy. The improved Q-learning has been employed to control the uncertain states of the running system and can effectively make decisions to select a rational policy with multiple parameter constraints. As running hardware and application data can be effectively collected and modeled, the power management framework can easily explore an ideal policy by value function of Q-learning algorithm.",
        "DOI": "10.1109/TOCS50858.2020.9339699",
        "affiliation_name": "National Computer Network Emergency Response Technical Team",
        "affiliation_city": "Harbin",
        "affiliation_country": "China",
        "affiliation_id": "112126690",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A Machine Learning-Aided Global Diagnostic and Comparative Tool to Assess Effect of Quarantine Control in COVID-19 Spread",
        "paper_author": "Dandekar R.",
        "publication": "Patterns",
        "citied_by": "35",
        "cover_date": "2020-12-11",
        "Abstract": "We have developed a globally applicable diagnostic COVID-19 model by augmenting the classical SIR epidemiological model with a neural network module. Our model does not rely upon previous epidemics like SARS/MERS and all parameters are optimized via machine learning algorithms used on publicly available COVID-19 data. The model decomposes the contributions to the infection time series to analyze and compare the role of quarantine control policies used in highly affected regions of Europe, North America, South America, and Asia in controlling the spread of the virus. For all continents considered, our results show a generally strong correlation between strengthening of the quarantine controls as learnt by the model and actions taken by the regions' respective governments. In addition, we have hosted our quarantine diagnosis results for the top 70 affected countries worldwide, on a public platform. As we enter the fifth month in the fight against COVID-19, it is evident that the government response to the COVID-19 pandemic has been spatially and temporally diverse. As such, the role played by the varying quarantine measures in different countries in shaping the infection growth curve is still not clear. To address this need, we have developed a novel model which lies at the intersection of the fields of epidemiology and machine learning and allows us to analyze and compare the role of quarantine control policies globally, across the continents of Europe, North America, South America and Asia (results hosted at https://covid19ml.org/). Such a robust, publicly available tool can be of significant value for studies looking at the correlation between the quarantine strength evolution in a particular region with a wide range of metrics spanning from mortality rate to socio-economic landscape impact of COVID-19 in that region. There is an urgent need to quantify the role played by quarantine policies implemented in various regions globally to curtail the spread of COVID-19. A model lying at the intersection of machine learning and epidemiology is shown to be powerful in diagnosing the quarantine policy evolution, which mimics well the real-time, on-ground situation seen in that region. The model, applied to 70 countries globally, is hosted publicly, making it a robust, useful tool in the fight against COVID-19.",
        "DOI": "10.1016/j.patter.2020.100145",
        "affiliation_name": "MIT School of Engineering",
        "affiliation_city": "Cambridge",
        "affiliation_country": "United States",
        "affiliation_id": "60140949",
        "affiliation_state": "MA"
    },
    {
        "paper_title": "Predicting Skill Shortages in Labor Markets: A Machine Learning Approach",
        "paper_author": "Dawson N.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "5",
        "cover_date": "2020-12-10",
        "Abstract": "Skill shortages are a drain on society. They hamper economic opportunities for individuals, slow growth for firms, and impede labor productivity in aggregate. Therefore, the ability to understand and predict skill shortages in advance is critical for policy-makers and educators to help alleviate their adverse effects. This research implements a high-performing Machine Learning approach to predict occupational skill shortages. In addition, we demonstrate methods to analyze the underlying skill demands of occupations in shortage and the most important features for predicting skill shortages. For this work, we compile a unique dataset of both Labor Demand and Labor Supply occupational data in Australia from 2012 to 2018. This includes data from 7.7 million job advertisements (ads) and 20 official labor force measures. We use these data as explanatory variables and leverage the XGBoost classifier to predict yearly skills shortage classifications for 132 standardized occupations. The models we construct achieve macro-F1 average performance scores of up to 83 per cent. Our results show that job ads data and employment statistics were the highest performing feature sets for predicting year-to-year skills shortage changes for occupations. We also find that features such as 'Hours Worked', years of 'Education', years of 'Experience', and median 'Salary' are highly important features for predicting occupational skill shortages. This research provides a robust data-driven approach for predicting and analyzing skill shortages, which can assist policy-makers, educators, and businesses to prepare for the future of work.",
        "DOI": "10.1109/BigData50022.2020.9377773",
        "affiliation_name": "University of Technology Sydney",
        "affiliation_city": "Sydney",
        "affiliation_country": "Australia",
        "affiliation_id": "60023932",
        "affiliation_state": "NSW"
    },
    {
        "paper_title": "Sketch and Scale Geo-distributed tSNE and UMAP",
        "paper_author": "Wei V.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "4",
        "cover_date": "2020-12-10",
        "Abstract": "Running machine learning analytics over geographically distributed datasets is a rapidly arising problem in the world of data management policies ensuring privacy and data security. Visualizing high dimensional data using tools such as t-distributed Stochastic Neighbor Embedding (tSNE) and Uniform Manifold Approximation and Projection (UMAP) became a common practice for data scientists. Both tools scale poorly in time and memory. While recent optimizations showed successful handling of 10,000 data points, scaling beyond million points is still challenging. We introduce a novel framework: Sketch and Scale (SnS). It leverages a Count Sketch data structure to compress the data on the edge nodes, aggregates the reduced size sketches on the master node, and runs vanilla tSNE or UMAP on the summary, representing the densest areas, extracted from the aggregated sketch.We show this technique to be fully parallel, scale linearly in time, logarithmically in memory and communication, making it possible to analyze datasets with many millions, potentially billions of data points, spread across several data centers around the globe. We demonstrate the power of our method on two mid-size datasets: cancer data with 52 million 35-band pixels from multiplex images of tumor biopsies; and astrophysics data of 100 million stars with multi-color photometry from the Sloan Digital Sky Survey (SDSS).",
        "DOI": "10.1109/BigData50022.2020.9377843",
        "affiliation_name": "Johns Hopkins University",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60005248",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Privacy Preserving Proxy for Machine Learning as a Service",
        "paper_author": "Kasichainula K.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "3",
        "cover_date": "2020-12-10",
        "Abstract": "In this paper, we propose a new framework called Privacy Preserving Proxy (PPP) to protect the online models. PPP is designed like a gateway to work on behalf of the users when requesting service, potentially masking the true origin of the online model from client. Instead of connecting directly to the machine learning-as-a-service(MLaaS) the clients submit the request to the PPP, which evaluates the request and executes some functions to maximize the safety of the models. PPP can potentially host a wide range of functions or triggers to control the complexity of the request or provide additional benefits such as privacy and security. We propose two different methods including Random Model Assignment and Intelligent Rounding Policy which can function inside PPP to protect the privacy of online models. To test the PPP we test TL-GAN based face reconstruction attack as a sophisticated approach which can reveal inefficiency of rounding policy as countermeasure. Our experiments show that, PPP can potentially nullify such complicated attacks in the future.",
        "DOI": "10.1109/BigData50022.2020.9378377",
        "affiliation_name": "University of Houston",
        "affiliation_city": "Houston",
        "affiliation_country": "United States",
        "affiliation_id": "60005837",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "A Deep Recurrent Neural Network to Support Guidelines and Decision Making of Social Distancing",
        "paper_author": "Aledhari M.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "2",
        "cover_date": "2020-12-10",
        "Abstract": "The recent Covid-19 pandemic instigated many changes in our way of life within the United States, and slowly but surely we are working towards mitigating the virus. Due to Covid-19, there are higher demands for models to accurately forecast the number of Covid-19 cases that factor mandated guidelines such as social-distancing. Many scholarly and corporate research entities are investigating ways to achieve this goal preemptively; Unfortunately, current models are not yet able to accurately model future Covid-19 cases that factor in various guidelines; What is lacking with these models is an understanding of crucial factors affecting spread, accuracy, availability of reported cases on a small scale, and quantifiable metrics for how social distancing and quarantine efforts mitigate the spread. Therefore, the goal of this study is to produce a mathematical model to directly aid policy decisions by comparing predicted models of various decisions and social distancing protocols. This model can be applied on top of existing models to factor in more imminent data and produce predictive curves, indicating troughs and peaks of new daily Covid-19 cases with comparatively high accuracy, which can aid in analysis. These predictive curves can, therefore, be generated using data corresponding to projected responses to proposed guidelines and compared to each other to choose the optimal solution for 'flattening the curve' of the Covid19 infection rate. We use an LSTM-RNN model with ANN Regression in an attempt to predict future Covid-19 cases. Our model achieved comparable results, but further improvements could be implemented for more optimal results.",
        "DOI": "10.1109/BigData50022.2020.9377800",
        "affiliation_name": "Kennesaw State University",
        "affiliation_city": "Kennesaw",
        "affiliation_country": "United States",
        "affiliation_id": "60019740",
        "affiliation_state": "GA"
    },
    {
        "paper_title": "A Novel Lasso Regression Model for Sector Rotation Trading Strategies with Economy-Policy Cycles",
        "paper_author": "Wang X.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "1",
        "cover_date": "2020-12-10",
        "Abstract": "A variety of machine learning methods such as decision trees, support vector machines, neural networks, and natural language processing are demonstrating their utilities in the Financial Investing field. In this article, we use a novel and innovative Lasso Regression model called Post-Lasso to construct a profitable sector rotation trading strategy for the Chinese stock market. On the basis of the machine learning model, we further identify and analyze the Economy-Policy cycles, which represent a broader environment of the economy. Through combining two megatrends - macroeconomy and artificial intelligence, we develop an interpretable, reliable, and trustworthy trading system which applies well to more practical situations.",
        "DOI": "10.1109/BigData50022.2020.9377759",
        "affiliation_name": "China Asset Management Co. Ltd.",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "114022347",
        "affiliation_state": "Beijing"
    },
    {
        "paper_title": "Towards Green Query Processing - Auditing Power before Deploying",
        "paper_author": "Dembele S.P.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "11",
        "cover_date": "2020-12-10",
        "Abstract": "Nowadays, energy reduction has become a critical and urgent issue for the database community. A lot of initiatives have been launched on energy-efficiency for intensive-workload computation covering individual hardware components, system software, to applications. This computation is mainly ensured by query optimizers. Their current versions minimize inputs-outputs operations and try to exploit RAM as much as possible, by ignoring energy. A couple of studies proposed the integration of energy into query optimizers that can be classified into hardware and software solutions. Several researchers have the idea that the operating systems and firmware manage energy and put software solutions in the second plan. This does not distinguish between tasks of operating systems and DBMSs. In this paper, we claim that building from scratch a green query processors and revisiting existing ones pass through 4-steps procedure: (1) establishment of a deep audit that allows understanding the query processor functioning, (2) identification of relevant energy-sensitive parameters belonging to hardware and software components, (3) elaboration of mathematical cost models estimating consumed energy when executing a query on a target DBMS and (4) setting of values of the energy-sensitive parameters using a nonlinear regression technique. To show the effectiveness of this procedure, we apply it on two open-source DBMSs with different functioning policies: PostgreSQL and MonetDB and compared them using the dataset and the workload of the TPC-H benchmark.",
        "DOI": "10.1109/BigData50022.2020.9377819",
        "affiliation_name": "ISAE-ENSMA",
        "affiliation_city": "Chasseneuil du Poitou",
        "affiliation_country": "France",
        "affiliation_id": "60009701",
        "affiliation_state": "Nouvelle-Aquitaine"
    },
    {
        "paper_title": "Machine Learning and OLAP on Big COVID-19 Data",
        "paper_author": "Leung C.K.",
        "publication": "Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020",
        "citied_by": "61",
        "cover_date": "2020-12-10",
        "Abstract": "In the current technological era, huge amounts of big data are generated and collected from a wide variety of rich data sources. These big data can be of different levels of veracity in the sense that some of them are precise while some others are imprecise and uncertain. Embedded in these big data are useful information and valuable knowledge to be discovered. An example of these big data is healthcare and epidemiological data such as data related to patients who suffered from epidemic diseases like the coronavirus disease 2019 (COVID-19). Knowledge discovered from these epidemiological data - via data science techniques such as machine learning, data mining, and online analytical processing (OLAP) - helps researchers, epidemiologists and policy makers to get a better understanding of the disease, which may inspire them to come up ways to detect, control and combat the disease. In this paper, we present a machine learning and big data analytic tool for processing and analyzing COVID-19 epidemiological data. Specifically, the tool makes good use of taxonomy and OLAP to generalize some specific attributes into some generalized attributes for effective big data analytics. Instead of ignoring unknown or unstated values of some attributes, the tool provides users with flexibility of including or excluding these values, depending on their preference and applications. Moreover, the tool discovers frequent patterns and their related patterns, which help reveal some useful knowledge such as absolute and relative frequency of the patterns. Furthermore, the tool learns from the patterns discovered from historical data and predicts useful information such as clinical outcomes for future data. As such, the tool helps users to get a better understanding of information about the confirmed cases of COVID-19. Although this tool is designed for machine learning and analytics of big epidemiological data, it would be applicable to machine learning and analytics of big data in many other real-life applications and services.",
        "DOI": "10.1109/BigData50022.2020.9378407",
        "affiliation_name": "Università della Calabria",
        "affiliation_city": "Rende",
        "affiliation_country": "Italy",
        "affiliation_id": "60020261",
        "affiliation_state": "CS"
    },
    {
        "paper_title": "A network science-based approach for an optimal microservice governance",
        "paper_author": "Siriwardhana G.S.",
        "publication": "ICAC 2020 - 2nd International Conference on Advancements in Computing, Proceedings",
        "citied_by": "2",
        "cover_date": "2020-12-10",
        "Abstract": "In today's world of software application development, Kubernetes has emerged as one of the most effective microservice deployment technologies presently available due to its exceptional ability to deploy and orchestrate containerized microservices. However, a common issue faced in such orchestration technologies is the employment of vast arrays of disjoint monitoring solutions that fail to portray a holistic perspective on the state of microservice deployments, which consequently inhibit the creation of more optimized deployment policies. In response to this issue, this publication proposes the use of a network science-based approach to facilitate the creation of a microservice governance model that incorporates the use of dependency analysis, load prediction, centrality analysis, and resilience evaluation to effectively construct a more holistic perspective on a given microservice deployment. Furthermore, through analysis of the factors mentioned above, the research conducted, then proceeds to create an optimized deployment strategy for the deployment with the aid of a developed optimization algorithm. Analysis of results revealed the developed governance model aided through the utilization of the developed optimization algorithm proposed in this publication, proved to be quite effective in the generation of optimized microservice deployment policies.",
        "DOI": "10.1109/ICAC51239.2020.9357232",
        "affiliation_name": "Sri Lanka Institute of Information Technology",
        "affiliation_city": "Colombo",
        "affiliation_country": "Sri Lanka",
        "affiliation_id": "60104431",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "COVID-19 Chest X-Ray Classification Using Convolutional Neural Network Architectures",
        "paper_author": "Nurtiyasari D.",
        "publication": "2020 3rd International Seminar on Research of Information Technology and Intelligent Systems, ISRITI 2020",
        "citied_by": "8",
        "cover_date": "2020-12-10",
        "Abstract": "World Health Organizations declared that Coronavirus Disease 2019 (COVID-19) outbreak pandemic in March 2020. Countries around the world are stepping up effort to halt the spread of this pandemic. Some countries are scrambling to tackle this virus by applying lockdown policy. As of 10 August 2020, there have been confirmed 19.718.030 total cases and 728.013 total deaths of COVID-19 [2]. COVID-19 detection is vital to decide the subsequent step in handling the patients. One strategy that may be applied for COVID-19 detection is classification approach primarily based totally on chest x-ray of the patients. Convolutional neural network has been successfully applied in practical applications. It is a type of machine learning which the model is designed to learn classification tasks directly from an image. It recognizes patterns directly from image pixel. These patterns are used to classify images and to eliminate the need of manual feature extraction. The classification provides outcomes with recall, precision, and accuracy had been respectively 94.99%, 95%, and 95.47% for model 1 and 97.73%, 95%, and 96.59% for model 2.",
        "DOI": "10.1109/ISRITI51436.2020.9315499",
        "affiliation_name": "Universitas Gadjah Mada",
        "affiliation_city": "Yogyakarta",
        "affiliation_country": "Indonesia",
        "affiliation_id": "60069380",
        "affiliation_state": "Yogyakarta"
    },
    {
        "paper_title": "An Advanced Policy Gradient Based Vector Control of PMSM for EV Application",
        "paper_author": "Bhattacharjee S.",
        "publication": "2020 10th International Electric Drives Production Conference, EDPC 2020 - Proceedings",
        "citied_by": "15",
        "cover_date": "2020-12-08",
        "Abstract": "Traditional proportional-integral (PI) based control has proven to be an influential control technique due to its advantage of easy implementation and robust performance for EV application. However, these controls are sensitive to plant parameters since the motor parameters change over time resulting in reduced performance and efficiency. This paper proposes a new vector control in permanent magnet synchronous motor (PMSM) with deep reinforcement learning (DRL) based controller in EV application. An advanced policy gradient algorithm is used to develop the DRL-based vector controller to overcome non-linearity in machine parameters and mitigate the decoupling inaccuracy issues in conventional control schemes. This contribution further evaluates the adaptive and dynamic performance against the conventional PI-based control and the research outlook is presented in the subsequent sections of this paper.",
        "DOI": "10.1109/EDPC51184.2020.9388187",
        "affiliation_name": "Magna Donnelly",
        "affiliation_city": "Holland",
        "affiliation_country": "United States",
        "affiliation_id": "60028473",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "Expanding dimensions: A new source in the bibliometrician's toolbox",
        "paper_author": "Wastl J.",
        "publication": "Handbook Bibliometrics",
        "citied_by": "2",
        "cover_date": "2020-12-07",
        "Abstract": "Developed by Digital Science in collaboration with over 100 leading research organisations around the world, Dimensions is a unique platform combining data about publications, data sets, grants, patents, clinical trials, and policy documents. This database spans the broader global scientific landscape to enable individual researchers as well as research funders, research organizations, and publishers to discover, analyse, and understand multiple aspects of the research life cycle. This chapter introduces the development and deployment of the Dimensions platform and describes the breadth of available functionality with focus on bibliometric applications and question sets that can be applied to the academic and broader outcomes of research, and gather insights to inform future strategy.",
        "DOI": "10.1515/9783110646610-039",
        "affiliation_name": "Digital Science",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "117499655",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Functional Analysis of the 2020 U.S. Elections on Twitter and Facebook using Machine Learning",
        "paper_author": "Alashri S.",
        "publication": "Proceedings of the 2020 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2020",
        "citied_by": "1",
        "cover_date": "2020-12-07",
        "Abstract": "Social Networking Sites (SNS), such as Facebook and Twitter, are important tools for political campaigns. A line of related work analyzed political campaigns online. The initial efforts in analyzing campaign discourse functions relied on human analysis, which is time consuming and does not scale well with big data. To address these gaps, we propose a model to detect the type of campaign topics: Policy vs. Character, and how the public (commentators) responded to these messages. The proposed model yielded an accuracy of 78% (F-measure) in detecting post type. Moreover, experimental results show the analysis of commentators linguistic and psychological characteristics.",
        "DOI": "10.1109/ASONAM49781.2020.9381302",
        "affiliation_name": "King Abdulaziz City for Science and Technology",
        "affiliation_city": "Riyadh",
        "affiliation_country": "Saudi Arabia",
        "affiliation_id": "60033126",
        "affiliation_state": "Ar Riyad"
    },
    {
        "paper_title": "Anticipating future learning affects current control decisions: A comparison between passive and active adaptive management in an epidemiological setting",
        "paper_author": "Atkins B.D.",
        "publication": "Journal of Theoretical Biology",
        "citied_by": "7",
        "cover_date": "2020-12-07",
        "Abstract": "Infectious disease epidemics present a difficult task for policymakers, requiring the implementation of control strategies under significant time constraints and uncertainty. Mathematical models can be used to predict the outcome of control interventions, providing useful information to policymakers in the event of such an epidemic. However, these models suffer in the early stages of an outbreak from a lack of accurate, relevant information regarding the dynamics and spread of the disease and the efficacy of control. As such, recommendations provided by these models are often incorporated in an ad hoc fashion, as and when more reliable information becomes available. In this work, we show that such trial-and-error-type approaches to management, which do not formally take into account the resolution of uncertainty and how control actions affect this, can lead to sub-optimal management outcomes. We compare three approaches to managing a theoretical epidemic: a non-adaptive management (AM) approach that does not use real-time outbreak information to adapt control, a passive AM approach that incorporates real-time information if and when it becomes available, and an active AM approach that explicitly incorporates the future resolution of uncertainty through gathering real-time information into its initial recommendations. The structured framework of active AM encourages the specification of quantifiable objectives, models of system behaviour and possible control and monitoring actions, followed by an iterative learning and control phase that is able to employ complex control optimisations and resolve system uncertainty. The result is a management framework that is able to provide dynamic, long-term projections to help policymakers meet the objectives of management. We investigate in detail the effect of different methods of incorporating up-to-date outbreak information. We find that, even in a highly simplified system, the method of incorporating new data can lead to different results that may influence initial policy decisions, with an active AM approach to management providing better information that can lead to more desirable outcomes from an epidemic.",
        "DOI": "10.1016/j.jtbi.2020.110380",
        "affiliation_name": "Lancaster Medical School",
        "affiliation_city": "Lancaster",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60117765",
        "affiliation_state": "Lancashire"
    },
    {
        "paper_title": "Screening of Murabaha business process through Quran and hadith: a text mining analysis",
        "paper_author": "Tlemsani I.",
        "publication": "Journal of Islamic Accounting and Business Research",
        "citied_by": "13",
        "cover_date": "2020-12-06",
        "Abstract": "Purpose: This paper revolves around the usage of data analytics in the Qur’an and Hadith through a new text mining technique to answer the main research question of whether the activities and the data flows of the Murabaha financing contract is compatible with Sharia law. The purpose of this paper is to provide a thorough and comprehensive database that will be used to examine existing practices in Islamic banks’ and improve compliancy with Islamic financial law (Sharia). Design/methodology/approach: To design a Sharia-compliant Murabaha business process originated on text mining, the authors start by identifying the factors deemed necessary in their text mining techniques of both texts; using a four-step strategy to analyze those text mining analytics; then, they list the three basic approaches in text mining used for new knowledge discovery in databases: the co-occurrence approach based on the recursive co-occurrence algorithm; the machine learning or statistical-based; and the knowledge-based. They identify any variation and association between the Murabaha business processes produced using text mining against the one developed through data collection. Findings: The main finding attained in this paper is to confirm the compatibility of all activities and the data flows in the Murabaha financing contract produced using data analytics of the Quran and Hadith texts against the Murabaha business process that was developed based on data collection. Another key finding is revealing some shortcomings regarding Islamic banks business process compliance with Sharia law. Practical implications: Given Murabaha as the most popular mode of Islamic financing with more than 75% in total transactions, this research has managed to touch-base on an area that is interesting to the vast majority of those dealing with Islamic finance instruments. By reaching findings that could improve the existing Islamic Murabaha business process and concluding on Sharia compliance of the existing Murabaha business process, this research is quite relevant and could be used in practice as well as in influencing public policy. In fact, Islamic Sharia law experts, Islamic finance professionals and Islamic banks may find the results of this study very useful in improving at least one aspect of the Islamic finance transactions. Originality/value: By using a novel, fresh text mining methods built on recursive occurrence of synonym words from the Qur’an and Hadith to enrich Islamic finance, this research study can claim to have been the first of its kind in using machine learning to mine the Quran, Hadith and in extracting valuable knowledge to support and consolidate the Islamic financial business processes and make them more compliant with the i.",
        "DOI": "10.1108/JIABR-05-2020-0159",
        "affiliation_name": "IE Business School",
        "affiliation_city": "Madrid",
        "affiliation_country": "Spain",
        "affiliation_id": "60108973",
        "affiliation_state": "Madrid"
    },
    {
        "paper_title": "Bank loan prediction system using machine learning",
        "paper_author": "Gupta A.",
        "publication": "Proceedings of the 2020 9th International Conference on System Modeling and Advancement in Research Trends, SMART 2020",
        "citied_by": "35",
        "cover_date": "2020-12-04",
        "Abstract": "With the advancement in technology, there are so many enhancements in the banking sector also. The number of applications is increasing every day for loan approval. There are some bank policies that they have to consider while selecting an applicant for loan approval. Based on some parameters, the bank has to decide which one is best for approval. It is tough and risky to check out manually every person and then recommended for loan approval. In this work, we use a machine learning technique that will predict the person who is reliable for a loan, based on the previous record of the person whom the loan amount is accredited before. This work's primary objective is to predict whether the loan approval to a specific individual is safe or not.",
        "DOI": "10.1109/SMART50582.2020.9336801",
        "affiliation_name": "Teerthanker Mahaveer University, Moradabad",
        "affiliation_city": "Moradabad",
        "affiliation_country": "India",
        "affiliation_id": "60113718",
        "affiliation_state": "UP"
    },
    {
        "paper_title": "Making Cyberspace towards Sustainability A Scientometric Review for a Cyberspace that Enables Green and Digital Transformation",
        "paper_author": "Wang Z.",
        "publication": "ACM International Conference Proceeding Series",
        "citied_by": "6",
        "cover_date": "2020-12-04",
        "Abstract": "Green and Digital Transformation, using digital technologies for green and inclusive development, has become the main agenda for both policy-makers and researchers. European Union (EU), for instance, has targeted the twin transition towards a green and digital economy by proposing a European Green Deal, guiding its investment and planning on the industrial applications using digital technologies such as artificial intelligence, big data, cloud and Internet of Things. While some work has been conducted to examine the digital transformation of different industries, no systematic review has been conducted to analyze the research fronts on the topic of green and digital transformation. With the purpose to layout an overall roadmap for industries and research, a scientometric study was conducted to map out the evolution, main journals, authors and keywords, thereby providing policy and research suggestions for science and technology innovations. This scientometric report on green and digital transformation, with its core value in summarizing scientific literature data using data science and machine learning techniques, provides timely accessible visualization for policy-makers, innovators and researchers evidence-based insights to make better decisions. Future research can build upon the preliminary findings here for the methodological, information and research need for tracking the development of green and digital transformation, so as to produce better strategic foresight.",
        "DOI": "10.1145/3444370.3444603",
        "affiliation_name": "Nanfang College of Sun Yet-sen University",
        "affiliation_city": "Guangzhou",
        "affiliation_country": "China",
        "affiliation_id": "60117185",
        "affiliation_state": "Guangdong"
    },
    {
        "paper_title": "Healthcare Management System with Sales Analytics using Autoregressive Integrated Moving Average and Google Vision",
        "paper_author": "Madrid M.C.R.",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "4",
        "cover_date": "2020-12-03",
        "Abstract": "Digitalization of different industries led to new systems that provide accurate information that results in efficient and effective services. This information is vital for decision-making and on the larger scale, policymaking especially in the health sector. In the Philippines, some healthcare establishments have not adjusted to this digital change. This study aims to develop an enhanced model of healthcare management system that can perform digitization of data, predictive health analytics and sales trend analysis. The researchers identified these three features as the focus of the system because it improves data quality, accessibility, reliability, and autonomy. The system is based on prescriptive analytics - a type of analytics that uses machine learning to process historical and predictive data. The artificially intelligent management system caters to the needs of the healthcare sector in this digital age to improve its services to the people.",
        "DOI": "10.1109/HNICEM51456.2020.9400035",
        "affiliation_name": "FEU Institute of Technology",
        "affiliation_city": "Manila",
        "affiliation_country": "Philippines",
        "affiliation_id": "60110905",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Development of Waste Management System using the Concept of 'Basura Advantage Points' through Artificial Neural Network",
        "paper_author": "Castro R.C.C.",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "9",
        "cover_date": "2020-12-03",
        "Abstract": "One of the most pressing problems of the world is the growing solid waste pollution. With current demands for sustainable development, the researchers developed a waste segregator machine that satisfies efficient segregation and introduces the concept of reward system to motivate people to throw their waste into the machine. In this paper, the researchers created an automatic segregating machine that uses Artificial Neural Network (ANN) as an algorithm for machine learning and embedded with the concept of 'Basura Advantage Points'. The ANN acts as the brain of the machine for sorting out the plastic bottles as one category and other waste materials for the other category. The 'Basura Advantage Points' is a novel concept wherein whenever people throw a garbage into the segregating machine, they can earn points which can then be used to redeem awards set by policy makers. Survey results show that the machine is appealing to the public. Based on the sample wastes, the accuracy of the machine is around 80 percent. From positive feedbacks to successful evaluation, the study highlighted a good model to decrease improper waste disposal and encourage people to participate in proper waste segregation.",
        "DOI": "10.1109/HNICEM51456.2020.9400123",
        "affiliation_name": "Bulacan State University",
        "affiliation_city": "Malolos",
        "affiliation_country": "Philippines",
        "affiliation_id": "60108105",
        "affiliation_state": "Bulacan"
    },
    {
        "paper_title": "Motorcycle Rider Helmet Detection for Riding Safety and Compliance Using Convolutional Neural Networks",
        "paper_author": "Giron N.N.F.",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "8",
        "cover_date": "2020-12-03",
        "Abstract": "Traffic violation apprehension is one of the traffic problems here in the Philippines. One example is the No Helmet No Ride Law that is implemented but many motorists still choose to ignore. To alleviate the problem the government has offered many solutions, one of which is the No Contact Traffic Apprehension Policy that uses CCTV Monitoring. To further enhance this solution the government has partnered with the De La Salle University to use artificial intelligence in the system. Computer Vision tasks like image classification and object detection can help automate the traffic apprehension system. Image classification and object detection are technologies which are used in computer vision in defining an image or coordinates of an object in an image. In this work, a novel approach to classifying motorcycle riders between wearing a helmet or not will be developed. It will be demonstrated using deep machine learning, specifically convolutional neural network and by utilizing different pre-trained models to a gathered dataset.",
        "DOI": "10.1109/HNICEM51456.2020.9400149",
        "affiliation_name": "Bulacan State University",
        "affiliation_city": "Malolos",
        "affiliation_country": "Philippines",
        "affiliation_id": "60108105",
        "affiliation_state": "Bulacan"
    },
    {
        "paper_title": "Classification between Pedestrians and Motorcycles using FasterRCNN Inception and SSD MobileNetv2",
        "paper_author": "Giron N.N.F.",
        "publication": "2020 IEEE 12th International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment, and Management, HNICEM 2020",
        "citied_by": "8",
        "cover_date": "2020-12-03",
        "Abstract": "Philippines is on the list of the top ten fastest growing economy in the world. One of its developments is in its traffic law enforcement. Today, the government is continuously finding ways on how to alleviate the problem on its roads with the use of technology. The Metro Manila Development Authority (MMDA) has offered a solution which is the No Contact Traffic Apprehension Policy, that utilizes Closed-Circuit Television (CCTV) Monitoring to apprehend vehicles violating traffic laws, rules and regulations by capturing videos and images. To further enhance this, the government has partnered with the De La Salle University to use artificial intelligence in the system with the project 'CATCH-ALL'. With the use of CCTVs and artificial intelligence system, it can help the system detect traffic violations using an automated process. But some tasks are not that easy to execute by the computer like differentiating a pedestrian and a motorcycle. In this study, a novel approach to classifying a pedestrian and a motorcycle with the use of object detection will be developed. It will be demonstrated using deep machine learning, specifically convolutional neural network and by utilizing different pre-trained models to a gathered dataset.",
        "DOI": "10.1109/HNICEM51456.2020.9400113",
        "affiliation_name": "Bulacan State University",
        "affiliation_city": "Malolos",
        "affiliation_country": "Philippines",
        "affiliation_id": "60108105",
        "affiliation_state": "Bulacan"
    },
    {
        "paper_title": "A Machine-Learning Based Approach for Zoning Urban Area in Consolidation Schemes Context",
        "paper_author": "Ouadi J.E.",
        "publication": "2020 13th International Colloquium of Logistics and Supply Chain Management, LOGISTIQUA 2020",
        "citied_by": "11",
        "cover_date": "2020-12-02",
        "Abstract": "Private freight transportation has many advantages, including speed, comfort and affordability. However, it is not often efficient to shorten longer commute times, as it is unable to keep-up with logistics demand during peak hours. Integrative policies, in flow terms, could fill this gap when supported through freight consolidation. Yet, a key issue that emerges in the implementation of consolidation-based transportation systems is that of logistics demand for reducing uncertainties about whether it will be met. The main target of this article is to include demand volatility to carry out a longterm urban land splitting that serve in building consolidation network. To that end, we propose a hybrid machine-learning framework combining several algorithms that are thought robust according to the literature and the achieved accuracy benchmarks. Based upon simulated system, some analytical outlooks are provided below.",
        "DOI": "10.1109/LOGISTIQUA49782.2020.9353901",
        "affiliation_name": "Université de Bordeaux",
        "affiliation_city": "Bordeaux",
        "affiliation_country": "France",
        "affiliation_id": "60102125",
        "affiliation_state": "Nouvelle-Aquitaine"
    },
    {
        "paper_title": "Prediction of Absenteeism at Work using Data Mining Techniques",
        "paper_author": "Skorikov M.",
        "publication": "Proceedings of ICITR 2020 - 5th International Conference on Information Technology Research: Towards the New Digital Enlightenment",
        "citied_by": "7",
        "cover_date": "2020-12-02",
        "Abstract": "High absenteeism among employees can be detrimental to an organization as it can result in productivity and economic loss. This paper looks into a case of absenteeism in a courier company in Brazil. Machine learning techniques have been employed to understand and predict absenteeism. Understanding this would provide human resource managers an excellent decision aid to create policies that can aim to reduce absenteeism. Data has been preprocessed, and several machine learning classification algorithms (such as zeroR, tree-based J48, naive Bayes, and KNN) have been applied. The paper reports models that can predict absenteeism with an accuracy of over 92%. Furthermore, from an initial of 20 attributes, disciplinary failure turns out to be a very prominent feature in predicting absenteeism.",
        "DOI": "10.1109/ICITR51448.2020.9310913",
        "affiliation_name": "North South University",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60028220",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Mapping coastal wetlands of the Bohai Rim at a spatial resolution of 10 M using multiple open-access satellite data and terrain indices",
        "paper_author": "Sun S.",
        "publication": "Remote Sensing",
        "citied_by": "23",
        "cover_date": "2020-12-02",
        "Abstract": "Coastal wetlands provide essential ecosystem services and are closely related to human welfare. However, they can experience substantial degradation, especially in regions in which there is intense human activity. To control these increasingly severe problems and to develop corresponding management policies in coastal wetlands, it is critical to accurately map coastal wetlands. Although remote sensing is the most efficient way to monitor coastal wetlands at a regional scale, it traditionally involves a large amount of work, high cost, and low spatial resolution when mapping coastal wetlands at a large scale. In this study, we developed a workflow for rapidly mapping coastal wetlands at a 10 m spatial resolution, based on the recently emergent Google Earth Engine platform, using a machine learning algorithm, open-access Synthetic Aperture Radar (SAR) and optical images from the Sentinel satellites, and two terrain indices. We then generated a coastal wetland map of the Bohai Rim (BRCW10) based on the workflow. It has a producer accuracy of 82.7%, according to validation using 150 wetland samples. The BRCW10 data reflected finer information when compared to wetland maps derived from two sets of global high-spatial-resolution land cover data, due to the fusion of multiple data sources. The study highlights the benefits of simultaneously merging SAR and optical remote sensing images when mapping coastal wetlands.",
        "DOI": "10.3390/rs12244114",
        "affiliation_name": "First Institute of Oceanography, Ministry of Natural Resources",
        "affiliation_city": "Qingdao",
        "affiliation_country": "China",
        "affiliation_id": "60088460",
        "affiliation_state": "Shandong"
    },
    {
        "paper_title": "Development of a self-harm monitoring system for victoria",
        "paper_author": "Robinson J.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "13",
        "cover_date": "2020-12-02",
        "Abstract": "The prevention of suicide and suicide-related behaviour are key policy priorities in Australia and internationally. The World Health Organization has recommended that member states develop self-harm surveillance systems as part of their suicide prevention efforts. This is also a priority under Australia’s Fifth National Mental Health and Suicide Prevention Plan. The aim of this paper is to describe the development of a state-based self-harm monitoring system in Victoria, Australia. In this system, data on all self-harm presentations are collected from eight hospital emergency departments in Victoria. A natural language processing classifier that uses machine learning to identify episodes of self-harm is currently being developed. This uses the free-text triage case notes, together with certain structured data fields, contained within the metadata of the incoming records. Post-processing is undertaken to identify primary mechanism of injury, substances consumed (including alcohol, illicit drugs and pharmaceutical preparations) and presence of psychiatric disorders. This system will ultimately leverage routinely collected data in combination with advanced artificial intelligence methods to support robust community-wide monitoring of self-harm. Once fully operational, this system will provide accurate and timely information on all presentations to participating emergency departments for self-harm, thereby providing a useful indicator for Australia’s suicide prevention efforts.",
        "DOI": "10.3390/ijerph17249385",
        "affiliation_name": "School of Computing and Information Systems",
        "affiliation_city": "Melbourne",
        "affiliation_country": "Australia",
        "affiliation_id": "60118847",
        "affiliation_state": "VIC"
    },
    {
        "paper_title": "Roadside air quality forecasting in shanghai with a novel sequence-to-sequence model",
        "paper_author": "Wang D.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "13",
        "cover_date": "2020-12-02",
        "Abstract": "The establishment of an effective roadside air quality forecasting model provides important information for proper traffic management to mitigate severe pollution, and for alerting resident’s outdoor plans to minimize exposure. Current deterministic models rely on numerical simulation and the tuning of parameters, and empirical models present powerful learning ability but have not fully considered the temporal periodicity of air pollutants. In order to take the periodicity of pollutants into empirical air quality forecasting models, this study evaluates the temporal variations of air pollutants and develops a novel sequence to sequence model with weekly periodicity to forecast air quality. Two-year observation data from Shanghai roadside air quality monitoring stations are employed to support analyzing and modeling. The results conclude that the fine particulate matter (PM2.5) and carbon monoxide (CO) concentrations show obvious daily and weekly variations, and the temporal patterns are nearly consistent with the periodicity of traffic flow in Shanghai. Compared with PM2.5, the CO concentrations are more affected by traffic variation. The proposed model outperforms the baseline model in terms of accuracy, and presents a higher linear consistency in PM2.5 prediction and lower errors in CO prediction. This study could assist environmental researchers to further improve the technologies for urban air quality forecasting, and serve as tools for supporting policymakers to implement related traffic management and emission control policies.",
        "DOI": "10.3390/ijerph17249471",
        "affiliation_name": "USC Viterbi School of Engineering",
        "affiliation_city": "Los Angeles",
        "affiliation_country": "United States",
        "affiliation_id": "60143535",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "A parametric study of a deep reinforcement learning control system applied to the swing-up problem of the cart-pole",
        "paper_author": "Escobar C.A.M.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "48",
        "cover_date": "2020-12-02",
        "Abstract": "In this investigation, the nonlinear swing-up problem associated with the cart-pole system modeled as a multibody dynamical system is solved by developing a deep Reinforcement Learning (RL) controller. Furthermore, the sensitivity analysis of the deep RL controller applied to the cart-pole swing-up problem is carried out. To this end, the influence of modifying the physical properties of the system and the presence of dry friction forces are analyzed employing the cumulative reward during the task. Extreme limits for the modifications of the parameters are determined to prove that the neural network architecture employed in this work features enough learning capability to handle the task under modifications as high as 90% on the pendulum mass, as well as a 100% increment on the cart mass. As expected, the presence of dry friction greatly affects the performance of the controller. However, a post-training of the agent in the modified environment takes only thirty-nine episodes to find the optimal control policy, resulting in a promising path for further developments of robust controllers.",
        "DOI": "10.3390/app10249013",
        "affiliation_name": "Università degli Studi di Salerno",
        "affiliation_city": "Salerno",
        "affiliation_country": "Italy",
        "affiliation_id": "60007061",
        "affiliation_state": "SA"
    },
    {
        "paper_title": "Effects of low-dose hydrocortisone and hydrocortisone plus fludrocortisone in adults with septic shock: A protocol for a systematic review and meta-analysis of individual participant data",
        "paper_author": "Annane D.",
        "publication": "BMJ Open",
        "citied_by": "2",
        "cover_date": "2020-12-02",
        "Abstract": "Introduction The benefits and risks of low-dose hydrocortisone in patients with septic shock have been investigated in numerous randomised controlled trials and trial-level meta-analyses. Yet, the routine use of this treatment remains controversial. To overcome the limitations of previous meta-analyses inherent to the use of aggregate data, we will perform an individual patient data meta-analysis (IPDMA) on the effect of hydrocortisone with or without fludrocortisone compared with placebo or usual care on 90-day mortality and other outcomes in patients with septic shock. Methods and analysis To assess the benefits and risks of hydrocortisone, with or without fludrocortisone for adults with septic shock, we will search major electronic databases from inception to September 2020 (Cochrane Central Register of Controlled Trials, MEDLINE, EMBASE and Latin American Caribbean Health Sciences Literature), complimented by a search for unpublished trials. The primary analysis will compare hydrocortisone with or without fludrocortisone to placebo or no treatment in adult patients with septic shock. Secondary analyses will compare hydrocortisone to placebo (or usual care), hydrocortisone plus fludrocortisone to placebo (or usual care), and hydrocortisone versus hydrocortisone plus fludrocortisone. The primary outcome will be all cause mortality at 90 days. We will conduct both one-stage IPDMA using mixed-effect models and machine learning with targeted maximum likelihood analyses. We will assess the risk of bias related to unshared data and related to the quality of individual trial. Ethics and dissemination This IPDMA will use existing data from completed randomised clinical trials and will comply with the ethical and regulatory requirements regarding data sharing for each of the component trials. The findings of this study will be submitted for publication in a peer-review journal with straightforward policy for open access.",
        "DOI": "10.1136/bmjopen-2020-040931",
        "affiliation_name": "Université Paris-Saclay",
        "affiliation_city": "Gif-sur-Yvette",
        "affiliation_country": "France",
        "affiliation_id": "60106017",
        "affiliation_state": "Ile-de-France"
    },
    {
        "paper_title": "Who Wants Peace? Predicting Civilian Preferences in Conflict Negotiations",
        "paper_author": "Montoya A.M.",
        "publication": "Journal of Politics in Latin America",
        "citied_by": "3",
        "cover_date": "2020-12-01",
        "Abstract": "Efforts to end civil wars via negotiations often generate sharp divisions in public opinion. A large, quantitative literature has found evidence for numerous variables serving as potential drivers of public support of and opposition to conflict negotiations. Yet the formation of policy preferences is a complex process, and while many factors might make small contributions to an individual’s conflict termination preferences, we lack a sense of which factors matter most or how to adjudicate among competing explanations. In this article, we leverage a large amount of nationally representative survey data from Colombia (2004–2015) and use machine learning tools to systematically explore which variables are the strongest predictors of public support for negotiations with Fuerzas Armadas Revolucionarias de Colombia (FARC). We find that certain aspects of conflict exposure, individual values bearing on justice and punishment, and belief in the efficacy of the state are among the strongest predictors of negotiation preferences, while many conventionally important variables in the literature have little predictive power. The results have implications for scholars seeking to understand broad drivers of (dis)satisfaction with negotiations and shed light on the polarising Colombian peace process.",
        "DOI": "10.1177/1866802X20960281",
        "affiliation_name": "University of South Carolina",
        "affiliation_city": "Columbia",
        "affiliation_country": "United States",
        "affiliation_id": "60018179",
        "affiliation_state": "SC"
    },
    {
        "paper_title": "Socio monitoring framework (SMF): Efficient sentiment analysis through informal and native terms",
        "paper_author": "Javed M.",
        "publication": "International Journal of Advanced and Applied Sciences",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Prediction and analysis of public expression is the trending topic of the current research arena. Opinion mining (a.k.a. Sentiment Analysis) is the automated orientation of public sentiments, views, suggestions, and opinions. It assists in estimating the popularity of products, events, services, and even political policies via user-generated content. Machine learning based supervised, semi-supervised, and unsupervised lexicon oriented techniques are applicable in the semantic orientation of public opinions about numerous real world entities. It is observed that socio channels contain real-time contents, which sometimes face the intricacy of informality, Slangs, Vernacular (Native terms), and sarcasm; however, these indicators provide high visibility of sentiments and opinions in terms of orientation. Unfortunately, the unclear perceptiveness of such contents lack in optimized orientation, and supervised machine learning systems are inappropriate where the Lexicon based opinion mining methods are preferred over learning based ones when training data is not adequate. In this paper, we seek to improve the performance of lexicon-based sentiment analysis by incorporating novel linguistic features such as vernaculars, slangs, and sarcasm for monitoring the social media contents up to a more realistic level. The core contributions are sarcasm detection and identification of vernacular terms. The performance of the proposed unsupervised lexicon-based framework over native, informal, and sarcastic opinion bearing terms is assessed via numerous experiments. For this, we utilized tweets relevant to two key domains, including Product and Politics. Experimental outcomes revealed that the proposed system outperformed the existing supervised and semi-supervised systems as 84.24%, and 82.35% of accuracies are achieved over informal and sarcastic contents for product and politics domains, respectively. The average accuracy for both domains is 83.29%.",
        "DOI": "10.21833/ijaas.2020.12.013",
        "affiliation_name": "Kohat University of Science and Technology (KUST)",
        "affiliation_city": "Kohat",
        "affiliation_country": "Pakistan",
        "affiliation_id": "60070620",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Evaluating machine learning models for the fast identification of contingency cases",
        "paper_author": "Schäfer F.",
        "publication": "Applied AI Letters",
        "citied_by": "3",
        "cover_date": "2020-12-01",
        "Abstract": "Fast approximations of power flow results are beneficial in power system planning and live operation. In planning, millions of power flow calculations are necessary if multiple years, different control strategies, or contingency policies are to be considered. In live operation, grid operators must assess if grid states comply with contingency requirements in a short time. In this paper, we compare regression and classification methods to either predict multivariable results, for example, bus voltage magnitudes and line loadings, or binary classifications of time steps to identify critical loading situations. We test the methods on three realistic power systems based on time series in 15 and 5 minutes resolution of 1 year. We compare different machine learning models, such as multilayer perceptrons (MLPs), decision trees, k-nearest neighbors, gradient boosting, and evaluate the required training time and prediction times as well as the prediction errors. We additionally determine the amount of training data needed for each method and show results, including the approximation of untrained curtailment of generation. Regarding the compared methods, we identified the MLPs as most suitable for the task. The MLP-based models can predict critical situations with an accuracy of 97% to 98% and a very low number of false negative predictions of 0.0% to 0.64%.",
        "DOI": "10.1002/ail2.19",
        "affiliation_name": "Fraunhofer Institute for Energy Economics and Energy System Technology IEE",
        "affiliation_city": "Kassel",
        "affiliation_country": "Germany",
        "affiliation_id": "60111826",
        "affiliation_state": "Hessen"
    },
    {
        "paper_title": "Who Is the Agent of Change?",
        "paper_author": "Nishikawa K.",
        "publication": "South Asian Journal of Business and Management Cases",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "The benefits of working in a large company are better infrastructure, well-defined policies, training and learning opportunities, job security and gradual growth. Slow decision-making due to the bureaucratic structure is a major drawback. The unique character of small firms offers agile structure, quick response, family-like atmosphere, opportunity to wear many hats as advantages, and lower compensation and restricted growth as disincentives to joining. However, if employees get their human relationships to energize, the size of the firm will be inconsequential for their success. That is, small firms can only offer a congenial atmosphere as a big firm never. Therefore, understanding what gives us energy and how we utilize it is critical for the leaders in small firms. This case study focuses on the CEO of a small family-owned firm (Nishio Glass and Mirror) whose decision to usher in positive organizational scholarship with the help of consultants set the firm on a successful journey. Even though statistics show that most change efforts fail irrespective of the size of the firm, in this case, it succeeded. This case study informs us that workplaces can be a community for people to amplify positive energy unleashing virtuous circles of growth. Research Questions: What is positive organizational scholarship? How can it be implemented in a small firm? Theory: Positive organizational scholarship and agents of change. Type of the Case: Study of a phenomenon. Basis of the Case: Phenomenon. Protagonist: Present, the CEO of the firm. Findings for Phenomenon-based Research Case: An organization is not a machine to transform resources into material properties. It is a community where people share the agentic roles with one another to let them transform. In a trustful community, people can examine the experience of ‘pregnant void’ to open a virtuous mindset; moreover, people can give suffering for others as an agent to embody the meaning of virtues. Discussions for Phenomenon-based Research Case: To manage a chaotic situation, which approach should be applied: crisis management or a proper management system? In this case, even a management system failed and dumped the CEO in psychological chaos. Which is that process that an external OD consultant can adopt to transform an organization by setting its employees on the path of self-transformation? If we apply hedonic happiness to the case, it seems to be fit for the past situation where people in the case wanted to have materialistic and short-term success. Discuss the alternative that can be applied.",
        "DOI": "10.1177/2277977920957959",
        "affiliation_name": "Konan University",
        "affiliation_city": "Kobe",
        "affiliation_country": "Japan",
        "affiliation_id": "60029341",
        "affiliation_state": "Hyogo"
    },
    {
        "paper_title": "Deep reinforcement learning based worker selection for distributed machine learning enhanced edge intelligence in internet of vehicles",
        "paper_author": "Dong J.",
        "publication": "Intelligent and Converged Networks",
        "citied_by": "31",
        "cover_date": "2020-12-01",
        "Abstract": "Nowadays, Edge Information System (EIS) has received a lot of attentions. In EIS, Distributed Machine Learning (DML), which requires fewer computing resources, can implement many artificial intelligent applications efficiently. However, due to the dynamical network topology and the fluctuating transmission quality at the edge, work node selection affects the performance of DML a lot. In this paper, we focus on the Internet of Vehicles (IoV), one of the typical scenarios of EIS, and consider the DML-based High Definition (HD) mapping and intelligent driving decision model as the example. The worker selection problem is modeled as a Markov Decision Process (MDP), maximizing the DML model aggregate performance related to the timeliness of the local model, the transmission quality of model parameters uploading, and the effective sensing area of the worker. A Deep Reinforcement Learning (DRL) based solution is proposed, called the Worker Selection based on Policy Gradient (PG-WS) algorithm. The policy mapping from the system state to the worker selection action is represented by a deep neural network. The episodic simulations are built and the REINFORCE algorithm with baseline is used to train the policy network. Results show that the proposed PG-WS algorithm outperforms other comparation methods.",
        "DOI": "10.23919/ICN.2020.0015",
        "affiliation_name": "Beijing University of Technology",
        "affiliation_city": "Beijing",
        "affiliation_country": "China",
        "affiliation_id": "60022281",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Efficiency of Buffer Caching in Computing-Intensive Workloads",
        "paper_author": "Bahn H.",
        "publication": "Proceedings - 2020 7th International Conference on Information Science and Control Engineering, ICISCE 2020",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "With the recent advent of the fourth industrial revolution, computing-intensive workloads such as big data and machine learning emerge every day. Even though the workloads are computation-intensive, there are file I/Os to access storage, and we need to improve the I/O performance by using buffer caching. This paper analyzes the efficiency of the buffer caching in the emerging computing-intensive workloads, and observes some peculiar I/O patterns, which degrades the performance of the buffer caching significantly. To relieve this problem, we present a new buffer caching scheme for improving the I/O performance of computing-intensive workloads. Simulation experiments with real-world traces show that the proposed buffer caching scheme improves the cache miss rate against the well-known LRU buffer caching policy by 35.2% on average and up to 81.6%.",
        "DOI": "10.1109/ICISCE50968.2020.00120",
        "affiliation_name": "Ewha Womans University",
        "affiliation_city": "Seoul",
        "affiliation_country": "South Korea",
        "affiliation_id": "60001018",
        "affiliation_state": "Seoul"
    },
    {
        "paper_title": "PrivacyCheck's machine learning to digest privacy policies: Competitor analysis and usage patterns",
        "paper_author": "Zaeem R.N.",
        "publication": "Proceedings - 2020 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology, WI-IAT 2020",
        "citied_by": "4",
        "cover_date": "2020-12-01",
        "Abstract": "Online privacy policies are lengthy and hard to comprehend. To address this problem, researchers have utilized machine learning (ML) to devise tools that automatically summarize online privacy policies for web users. One such tool is our free and publicly available browser extension, PrivacyCheck. In this paper, we enhance PrivacyCheck by adding a competitor analysis component-a part of PrivacyCheck that recommends other organizations in the same market sector with better privacy policies. We also monitored the usage patterns of about a thousand actual PrivacyCheck users, the first work to track the usage and traffic of an ML-based privacy analysis tool. Results show: (1) there is a good number of privacy policy URLs checked repeatedly by the user base; (2) the users are particularly interested in privacy policies of software services; and (3) PrivacyCheck increased the number of times a user consults privacy policies by 80%. Our work demonstrates the potential of ML-based privacy analysis tools and also sheds light on how these tools are used in practice to give users actionable knowledge they can use to pro-actively protect their privacy.",
        "DOI": "10.1109/WIIAT50758.2020.00042",
        "affiliation_name": "Cockrell School of Engineering",
        "affiliation_city": "Austin",
        "affiliation_country": "United States",
        "affiliation_id": "60150401",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "The study for utilizing data of cut-slope management system by using logistic regression",
        "paper_author": "Woo Y.",
        "publication": "Journal of Engineering Geology",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Cut-slope management system (CSMS) has been investigated all slopes on the road of the whole country to evaluate risk rating of each slope. Based on this evaluation, the decision-making for maintenance can be conducted, and this procedure will be helpful to establish a consistent and efficient policy of safe road. CSMS has updated the database of all slopes annually, and this database is constructed based on a basic and detailed investigation. In the database, there are two type of data: first one is an objective data such as slopes’ location, height, width, length, and information about underground and bedrock, etc; second one is subjective data, which is decided by experts based on those objective data, e.g., degree of emergency and risk, maintenance solution, etc. The purpose of this study is identifying an data application plan to utilize those CSMS data. For this purpose, logistic regression, which is a basic machine-learning method to construct a prediction model, is performed to predict a judging-type variable (i.e., subjective data) based on objective data. The constructed logistic model shows the accurate prediction, and this model can be used to judge a priority of slopes for detailed investigation. Also, it is anticipated that the prediction model can filter unusual data by comparing with a prediction value.",
        "DOI": "10.9720/kseg.2020.4.649",
        "affiliation_name": "Korea Institute of Civil Engineering and Building Technology (KICT)",
        "affiliation_city": "Goyang",
        "affiliation_country": "South Korea",
        "affiliation_id": "60121523",
        "affiliation_state": "Gyeonggi-do"
    },
    {
        "paper_title": "Exploring the attractiveness of residential areas for human activities based on shared e-bike trajectory data",
        "paper_author": "Cheng X.",
        "publication": "ISPRS International Journal of Geo-Information",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "Human activities generate diverse and sophisticated functional areas and may impact the existing planning of functional areas. Understanding the relationship between human activities and functional areas is key to identifying the real-time urban functional areas based on trajectories. Few previous studies have analyzed the interactive information on humans and regions for functional area identification. The relationship between human activities and residential areas is the most representative for urban functional areas because residential areas cover a wide range and are closely connected with human life. The aim of this paper is to propose the CARA (Commuting Activity and Residential Area) model to quantify the correlation between human activities and urban residential areas. In this model, human activities are represented by hot spots extracted by the Gaussian Mixture Model algorithm while residential areas are represented by POI (point of interest) data. The model shows that human activities and residential areas present a logarithmic relationship. The CARA model is further assessed by retrieving urban residential areas in Tengzhou City from shared e-bike trajectories. Compared with the actual map, the accuracy reaches 83.3%, thus demonstrating the model’s reliability and feasibility. This study provides a new method for functional areas identification based on trajectory data, which is helpful for formulating the urban people-oriented policies.",
        "DOI": "10.3390/ijgi9120742",
        "affiliation_name": "Xinjiang Institute of Ecology and Geography Chinese Academy of Sciences",
        "affiliation_city": "Urumqi",
        "affiliation_country": "China",
        "affiliation_id": "60117377",
        "affiliation_state": "Xinjiang"
    },
    {
        "paper_title": "Identifying unfamiliar callers' professions from privacy-preserving mobile phone data",
        "paper_author": "Zhang J.",
        "publication": "Proceedings - 2020 16th International Conference on Mobility, Sensing and Networking, MSN 2020",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "Identifying an unfamiliar caller's profession is important to protect citizens' personal safety and property. Due to limited data protection of many popular online services in some countries such as taxi hailing or takeouts ordering, many users encounter an increasing number of phone calls from strangers. This may aggravate the situation that criminals pretend to be delivery staff or taxi drivers, bringing threats to the society. Additionally, many people nowadays suffer from excessive digital marketing and fraud phone calls because of personal information leakage. However, previous works on malicious call detection only focused on binary classification, and do not work for identification of multiple professions. We observed that web service requests issued from users' mobile phones which may show their Apps preferences, spatial and temporal patterns, and other profession related information. This offers us a hint to identify unfamiliar callers. In fact, some previous works already leveraged raw data from mobile phones (which includes sensitive information) for personality studies. However, accessing users' mobile phone raw data may violate the more and more strict private data protection policies or regulations (e.g. GDPR 71). Using appropriate statistical methods to eliminate private information and preserve personal characteristics, provides a way to identify mobile phone callers without privacy concern. In this paper, we exploit privacy-preserving mobile data to develop a model which can automatically identify the callers who are divided into four categories of users: normal users (other professions), taxi drivers, delivery and takeouts staffs, telemarketers and fraudsters. The validation results over an anonymized dataset of 1, 282 users with a period of 3 months in Shanghai City prove that the proposed model could achieve an accuracy of 75+%.",
        "DOI": "10.1109/MSN50589.2020.00088",
        "affiliation_name": "Georg-August-Universität Göttingen",
        "affiliation_city": "Gottingen",
        "affiliation_country": "Germany",
        "affiliation_id": "60031514",
        "affiliation_state": "Niedersachsen"
    },
    {
        "paper_title": "Vehicular multi-slice optimization in 5G: Dynamic preference policy using reinforcement learning",
        "paper_author": "Zhang C.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "5",
        "cover_date": "2020-12-01",
        "Abstract": "Network slicing, as an effective way of using heterogeneous network resources, is widely used in today's radio access network (RAN). However, because of the greater randomness of equipment capacity and mobility, the existing allocation schemes of network slicing do not make use of existing resources effectively. In this regard, this paper studies how to improve the efficiency of network slicing utilization in one base station (BS) area through deep Q-learning's allocation strategy. First, we propose an allocation strategy that uses the preference matrix to prioritize all network slices. Then, with low coupling, a realtime updating Q-learning model is developed to calculate the preference matrix. Finally, we demonstrate through simulation that our proposal can improve the efficiency of service delivery in a heterogeneous wireless network region.",
        "DOI": "10.1109/GLOBECOM42002.2020.9348132",
        "affiliation_name": "Advanced Institute of Industrial Technology",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60103937",
        "affiliation_state": "Tokyo"
    },
    {
        "paper_title": "The Digital and Assistive Technologies for Ageing initiative: learning from the GATE initiative",
        "paper_author": "Khasnabis C.",
        "publication": "The Lancet Healthy Longevity",
        "citied_by": "15",
        "cover_date": "2020-12-01",
        "Abstract": "NA",
        "DOI": "10.1016/S2666-7568(20)30049-0",
        "affiliation_name": "Organisation Mondiale de la Santé",
        "affiliation_city": "Geneva",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60027142",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Bayesian Sampler: Fairness in Sampling",
        "paper_author": "Chakraborty I.",
        "publication": "Proceedings - 19th IEEE International Conference on Machine Learning and Applications, ICMLA 2020",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "We reinterpret the concept of Bayesian balance from Yang Liu [26] to find connection between fairness of algorithms and class imbalance in latent clusters of training data. We argue that the degree of class imbalance in the latent clusters of some training data is manifested in the lack of fairness of an algorithm trained on that data. A novel algorithm is proposed in this paper which decides an optimal policy to draw a balanced data sample from clustered raw data with class imbalance. The proposed Bayesian network model trades off accuracy with redefined Bayesian balance to find the optimal policy. We claim that a novel application of this sampling technique would be sampling a fair training set for recommender systems. To illustrate, we present experimental results on two real world recommender systems raw data sets and one synthetic data-set.",
        "DOI": "10.1109/ICMLA51294.2020.00048",
        "affiliation_name": "Baskin School of Engineering",
        "affiliation_city": "Santa Cruz",
        "affiliation_country": "United States",
        "affiliation_id": "60137794",
        "affiliation_state": "CA"
    },
    {
        "paper_title": "Bearicade: Secure access gateway to high performance computing systems",
        "paper_author": "Al-Jody T.",
        "publication": "Proceedings - 2020 IEEE 19th International Conference on Trust, Security and Privacy in Computing and Communications, TrustCom 2020",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Cyber security is becoming a vital part of many information technologies and computing systems. Increasingly, High-Performance Computing systems are used in scientific research, academia and industry. High-Performance Computing applications are specifically designed to take advantage of the parallel nature of High-Performance Computing systems. Current research into High-Performance Computing systems focuses on the improvements in software development, parallel algorithms and computer systems architecture. However, there are no significant efforts in developing common High-Performance Computing security standards. Security of the High-Performance Computing resources is often an add-on to existing varied institutional policies that do not take into account additional requirements for High-Performance Computing security. Also, the users' terminals or portals used to access the High-Performance Computing resources are frequently insecure or they are being used in unprotected networks. In this paper we present Bearicade - a Data-driven Security Orchestration Automation and Response system. Bearicade collects data from the HPC systems and its users, enabling the use of Machine Learning based solutions to address current security issues in the High-Performance Computing systems. The system security is achieved through monitoring, analysis and interpretation of data such as users' activity, server requests, devices used and geographic locations. Any anomaly in users' behaviour is detected using machine learning algorithms, and would be visible to system administrators to help mediate the threats. The system was tested on a university campus grid system by administrators and users. Two case studies, Anomaly detection of user behaviour and Classification of Malicious Linux Terminal Command, have demonstrated machine learning approaches in identifying potential security threats. Bearicade's data was used in the experiments. The results demonstrated that detailed information is provided to the HPC administrators to detect possible security attacks and to act promptly.",
        "DOI": "10.1109/TrustCom50675.2020.00191",
        "affiliation_name": "University of Huddersfield",
        "affiliation_city": "Huddersfield",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60032343",
        "affiliation_state": "West Yorkshire"
    },
    {
        "paper_title": "Resource Allocation in IRSs Aided MISO-NOMA Networks: A Machine Learning Approach",
        "paper_author": "Gao X.",
        "publication": "Proceedings - IEEE Global Communications Conference, GLOBECOM",
        "citied_by": "13",
        "cover_date": "2020-12-01",
        "Abstract": "A novel framework of intelligent reflecting surface (IRS)-aided multiple-input single-output (MISO) non-orthogonal multiple access (NOMA) network is proposed, where a base station (BS) serves multiple clusters with unfixed number of users in each cluster. The goal is to maximize the sum rate of all users by jointly optimizing the passive beamforming vector at the IRS, decoding order and power allocation coefficient vector, subject to the rate requirements of users. In order to tackle the formulated problem, a three-step approach is proposed. More particularly, a long short-term memory (LSTM) based algorithm is first adopted for predicting the mobility of users. Secondly, a K-means based Gaussian mixture model (K-GMM) algorithm is proposed for user clustering. Thirdly, a deep Q-network (DQN) based algorithm is invoked for jointly determining the phase shift matrix and power allocation policy. Simulation results are provided for demonstrating that the proposed algorithm outperforms the benchmarks, while the performance of IRS-NOMA system is better than IRS-OMA system.",
        "DOI": "10.1109/GLOBECOM42002.2020.9348009",
        "affiliation_name": "Queen Mary University of London",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60022109",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence and hybrid imaging: the best match for personalized medicine in oncology",
        "paper_author": "Sollini M.",
        "publication": "European Journal of Hybrid Imaging",
        "citied_by": "37",
        "cover_date": "2020-12-01",
        "Abstract": "Artificial intelligence (AI) refers to a field of computer science aimed to perform tasks typically requiring human intelligence. Currently, AI is recognized in the broader technology radar within the five key technologies which emerge for their wide-ranging applications and impact in communities, companies, business, and value chain framework alike. However, AI in medical imaging is at an early phase of development, and there are still hurdles to take related to reliability, user confidence, and adoption. The present narrative review aimed to provide an overview on AI-based approaches (distributed learning, statistical learning, computer-aided diagnosis and detection systems, fully automated image analysis tool, natural language processing) in oncological hybrid medical imaging with respect to clinical tasks (detection, contouring and segmentation, prediction of histology and tumor stage, prediction of mutational status and molecular therapies targets, prediction of treatment response, and outcome). Particularly, AI-based approaches have been briefly described according to their purpose and, finally lung cancer—being one of the most extensively malignancy studied by hybrid medical imaging—has been used as illustrative scenario. Finally, we discussed clinical challenges and open issues including ethics, validation strategies, effective data-sharing methods, regulatory hurdles, educational resources, and strategy to facilitate the interaction among different stakeholders. Some of the major changes in medical imaging will come from the application of AI to workflow and protocols, eventually resulting in improved patient management and quality of life. Overall, several time-consuming tasks could be automatized. Machine learning algorithms and neural networks will permit sophisticated analysis resulting not only in major improvements in disease characterization through imaging, but also in the integration of multiple-omics data (i.e., derived from pathology, genomic, proteomics, and demographics) for multi-dimensional disease featuring. Nevertheless, to accelerate the transition of the theory to practice a sustainable development plan considering the multi-dimensional interactions between professionals, technology, industry, markets, policy, culture, and civil society directed by a mindset which will allow talents to thrive is necessary.",
        "DOI": "10.1186/s41824-020-00094-8",
        "affiliation_name": "Humanitas University",
        "affiliation_city": "Pieve Emanuele",
        "affiliation_country": "Italy",
        "affiliation_id": "60107210",
        "affiliation_state": "MI"
    },
    {
        "paper_title": "On packet classification using a decision-tree ensemble",
        "paper_author": "Ezeh D.",
        "publication": "CoNEXT Student Workshop 2020 - Proceedings of the 2020 Student Workshop, Part of CoNEXT 2020",
        "citied_by": "1",
        "cover_date": "2020-12-01",
        "Abstract": "Different traffic flows get treated differently at routers, depending on the descriptions they fit as well as rules set by network administrators. Today's routers have their work cut out having to categorize these incoming flows based on preconfigured administrative policies. Purely hardware-based traffic classification solutions are expensive, of low capacity and consume a lot of power. This paper proposes the use of machine learning techniques to classify these flows for appropriate action in Software-Defined Networks.",
        "DOI": "10.1145/3426746.3434054",
        "affiliation_name": "Drexel University College of Engineering",
        "affiliation_city": "Philadelphia",
        "affiliation_country": "United States",
        "affiliation_id": "60139971",
        "affiliation_state": "PA"
    },
    {
        "paper_title": "Forecasting S&amp;P 500 spikes: an SVM approach",
        "paper_author": "Papadimitriou T.",
        "publication": "Digital Finance",
        "citied_by": "4",
        "cover_date": "2020-12-01",
        "Abstract": "In this study, we focus on forecasting long-tail events of the S&P 500 stock returns. The S&P 500 is widely considered as a bellwether for the overall US economy as it encompasses some of the largest—in terms of capitalization—corporations from both the NYSE and the NASDAQ stock exchanges. A timely and efficient forecast of such extreme changes is of great importance to market participants and policy makers, since they may trigger large scale selling or buying strategies that may significantly impact the specific market and the overall economy. We define as “spikes” the events where we have extreme upward or downward changes of the S&P 500 index; in our case, we use the returns that fall outside a two-standard deviations band. However, instead of simply using the unconditional overall standard deviation, in this paper we employ a GARCH (p,q) model to derive the conditional standard deviation of the returns. This is a more appropriate measure of immediate risk to market participants than the overall series’ unconditional standard deviation. Traditional forecasting models that rely on statistical analysis and traditional econometrics, assume that the returns follow some typical underlying distribution. These models usually fail to successfully and efficiently accommodate price spikes especially when it comes to forecasting. In our study, we use the atheoretical and data-driven Support Vector Machines methodology from the area of Machine Learning. This forecasting approach does not require any initial assumptions on the distribution of the data but rather exploits patterns that may be inhibited in the initial data space. These patterns may become more apparent and exploitable in the resulting feature space. We use 1860 daily observations from 01/01/2009 to 22/01/2017. Our overall optimum forecasting model achieved a 70.69% forecasting accuracy for the spikes and 73.25% for non-spikes.",
        "DOI": "10.1007/s42521-020-00024-0",
        "affiliation_name": "Democritus University of Thrace",
        "affiliation_city": "Komotini",
        "affiliation_country": "Greece",
        "affiliation_id": "60030988",
        "affiliation_state": "Eastern Macedonia and Thrace"
    },
    {
        "paper_title": "Path Optimization of a Single Surveillance Drone Based on Reinforcement Learning",
        "paper_author": "Lee D.",
        "publication": "International Journal of Mechanical Engineering and Robotics Research",
        "citied_by": "9",
        "cover_date": "2020-12-01",
        "Abstract": "A surveillance drone supervises designated area or sites against dangerous situation. In recent years, it is required to perform autonomous flight to achieve the supervision with path optimization based on minimization of the time lag. In this paper, we propose the reinforcement learning algorithm to optimize path for autonomous flight of surveillance drones. We present a simulation result of a single surveillance drone, which has reinforcement learning algorithm in an unknown grid area. A single surveillance drone finds the optimized path autonomously with minimization of the time lag. This paper provides the following two main contributions for autonomous flight of the surveillance drone. First, the surveillance drone finds the optimized path autonomously using proposed the reinforcement learning algorithm. Second, the traditional reinforcement learning was improved with parameter optimization including learning rate coefficient, convergence criteria, and adaptive error convergence detection for ε-greedy policy process.",
        "DOI": "10.18178/IJMERR.9.12.1541-1547",
        "affiliation_name": "Korea Aerospace Research Institute",
        "affiliation_city": "Daejeon",
        "affiliation_country": "South Korea",
        "affiliation_id": "60068719",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Revisiting Determinants of Investor Sentiment in the FX Option Market by Machine Learning Approaches",
        "paper_author": "Washimi K.",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "While FX option transactions are known to reflect risk perceptions of market participants, the over-the-counter nature of the FX option market has limited data availability on counterparty information, posing challenges to analyzing what factors could affect investor sentiment and how they may differ across investor types. With novel, granular FX option data based on the reporting from trade repositories and financial institutions in Japan, this paper employs machine learning approaches (Random Forest and XGBoost) to exploring the determinants of investor sentiment for USD/JPY by a different investor category, measured by the positioning of 'long call and short put (bullish for USD/JPY)' minus 'long put and short call (bearish for USD/JPY)'. The analysis shows that the uncertainty over the US trade policy is one of the most important variables for the sentiment of non-financial corporates, while the US yield curve appears to affect the sentiment of both non-financial corporates and institutional investors. The results imply that the recent increase in hedging behavior for a sharp fall of the dollar against the yen could be attributable to the US-China trade tensions and an inversion of the US yield curve which suggests a slowdown of global economy.",
        "DOI": "10.1109/SSCI47803.2020.9308341",
        "affiliation_name": "Bank of Japan",
        "affiliation_city": "Tokyo",
        "affiliation_country": "Japan",
        "affiliation_id": "60112314",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Application of data-based prediction methods in newsvendor problems subject to purchase price uncertainty",
        "paper_author": "Guimaraes M.S.",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "Poor procurement decisions, especially involving perishable or short life-cycled products, which will have to be disposed of, can cost companies large portions of their profits. The newsvendor problem addresses inventory decisions to assist retailers in deciding just the right order quantity while still subject to uncertainty. Efficient time series forecasting techniques, including the use of machine learning models, have helped reduce uncertainty and improve financial results by offering insight on future outcome-based decisions. This work proposes a hybrid model, exploring linear and nonlinear modeling capabilities of classic, modern and machine learning models which are applied to a financial time series in order to anticipate fluctuations in the price of supplies purchased by the newsvendor. This information is used to aid the decision-maker in an optimization problem involving both the decision on the order quantity and the best moment for the one-time per cycle newsvendor replenishment in situations where the purchase price fluctuates in time. The proposed model outperformed both SARIMA and Prophet models as efficient pointers to the best moment to place an order. A case study of a Brazilian supermarket chain which must place weekly orders of perishable goods, specifically of meat products, was chosen to illustrate the methodology.",
        "DOI": "10.1109/SSCI47803.2020.9308495",
        "affiliation_name": "Universidade Federal de Pernambuco",
        "affiliation_city": "Recife",
        "affiliation_country": "Brazil",
        "affiliation_id": "60031482",
        "affiliation_state": "PE"
    },
    {
        "paper_title": "Consumer Behavior Analysis using EEG Signals for Neuromarketing Application",
        "paper_author": "Amin C.R.",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "20",
        "cover_date": "2020-12-01",
        "Abstract": "Neuromarketing is applying neuropsychology in marketing research studying consumer sensory-motor actions such as cognitive and affective responses to marketing stimuli with the help of modern technologies. It is one of the most recent marketing research strategies and may become the future of marketing research. Many research works have been carried out in this area to obtain better outcomes. However, literature shows that there is an opportunity for further improvement. Hence, in this study, a model is presented using data mining and machine learning algorithms for consumer behavior analysis from EEG signals. Time-frequency distribution features are extracted from EEG signals on which different classification algorithms are applied. Consumer's responses toward marketing strategies and their behavior towards purchasing or selecting goods can be studied and analyzed to understand the producer-consumer relationship. EEG signals from 25 people are collected where the participants varied in age and gender for a better understanding of consumer behavior towards a marketing policy. By analyzing the data, the reason behind how and why they like certain marketing policies was uncovered. The performance of our proposed model with an existing technique is compared. The accuracy of our model on the dataset is 95%, whereas the accuracy of the existing technique on the same dataset is 70%. We also evaluated whether neuropsychological measures can capture differences in consumer's actions according to different marketing stimuli. The experimental results on our model indicate that studies in this field can bring a change and improve marketing strategies for the betterment of both the producer and the consumer, resulting in an eventual mutual benefit.",
        "DOI": "10.1109/SSCI47803.2020.9308358",
        "affiliation_name": "Bangladesh University of Health Sciences",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60106979",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Interpretable Machine Learning Tools: A Survey",
        "paper_author": "Agarwal N.",
        "publication": "2020 IEEE Symposium Series on Computational Intelligence, SSCI 2020",
        "citied_by": "53",
        "cover_date": "2020-12-01",
        "Abstract": "In recent years machine learning (ML) systems have been deployed extensively in various domains. But most MLbased frameworks lack transparency. To believe in ML models, an individual needs to understand the reasons behind the ML predictions. In this paper, we provide a survey of open-source software tools that help explore and understand the behavior of the ML models. Also, these tools include a variety of interpretable machine learning methods that assist people with understanding the connection between input and output variables through interpretation, validate the decision of a predictive model to enable lucidity, accountability, and fairness in the algorithmic decision making policies. Furthermore, we provide the state-of-the-art of interpretable machine learning (IML) tools, along with a comparison and a brief discussion of the implementation of those IML tools in various programming languages.",
        "DOI": "10.1109/SSCI47803.2020.9308260",
        "affiliation_name": "Department of Computer Science",
        "affiliation_city": "Memphis",
        "affiliation_country": "United States",
        "affiliation_id": "60280401",
        "affiliation_state": "TN"
    },
    {
        "paper_title": "Dynamic Behavior Predictions for Fast and Efficient Hybrid STT-MRAM Caches",
        "paper_author": "Sayed N.",
        "publication": "ACM Journal on Emerging Technologies in Computing Systems",
        "citied_by": "8",
        "cover_date": "2020-12-01",
        "Abstract": "Spin Transfer Torque Magnetic Random Access Memory (STT-MRAM) is a promising candidate as a universal on-chip memory technology due to its non-volatility, high density, and scalability. However, high write energy and latency are its major shortcomings, particularly for fast cache applications. High write costs can efficiently be reduced by relaxing the STT-MRAM non-volatility requirements at the expense of significant increase in retention failure and read disturb rates resulting in data corruption. Hybrid STT-MRAM architecture combining non-volatile (NVM) and semi-volatile (SVM) STT-MRAM blocks has been proposed recently, which provides energy-efficiency, high storage capacity, better performance, and high reliability. However, a key and challenging requirement is efficient data mapping and migration between NVM and SVM sub-arrays to maximize the benefits of such hybrid caches. On-the-fly data migration decisions usually depend on the last seen data behavior, as it is assumed to be identical to the next one, which has very limited accuracy for rapidly varying workload behavior. In this article, we propose a simple but effective on-the-fly data management policy, which mainly relies on the supervised learning data-pattern classification for quick and highly accurate prediction of the data behavior in the oncoming execution time. Three prediction approaches are proposed and compared for a maximum and average achieved accuracy of 86% and 75%, respectively. Our data management policies aim to optimally leverage the specific features of NVM (high reliability) and SVM blocks (fast and energy-efficient write) of hybrid STT-MRAM memory with minimal migration costs (i.e., energy and performance overheads). Our experimental evaluation reports that for a hybrid STT-MRAM cache with the proposed prediction techniques, the total energy consumption can be reduced around 10.5%, on average, in comparison to the state-of-the-art.",
        "DOI": "10.1145/3423135",
        "affiliation_name": "Karlsruher Institut für Technologie",
        "affiliation_city": "Karlsruhe",
        "affiliation_country": "Germany",
        "affiliation_id": "60102538",
        "affiliation_state": "Baden-Wurttemberg"
    },
    {
        "paper_title": "Big data and actuarial science",
        "paper_author": "Hassani H.",
        "publication": "Big Data and Cognitive Computing",
        "citied_by": "22",
        "cover_date": "2020-12-01",
        "Abstract": "This article investigates the impact of big data on the actuarial sector. The growing fields of applications of data analytics and data mining raise the ability for insurance companies to conduct more accurate policy pricing by incorporating a broader variety of data due to increased data availability. The analyzed areas of this paper span from automobile insurance policy pricing, mortality and healthcare modeling to estimation of harvest-, climate-and cyber risk as well as assessment of catastrophe risk such as storms, hurricanes, tornadoes, geomagnetic events, earthquakes, floods, and fires. We evaluate the current use of big data in these contexts and how the utilization of data analytics and data mining contribute to the prediction capabilities and accuracy of policy premium pricing of insurance companies. We find a high penetration of insurance policy pricing in almost all actuarial fields except in the modeling and pricing of cyber security risk due to lack of data in this area and prevailing data asymmetries, for which we identify the application of artificial intelligence, in particular machine learning techniques, as a possible solution to improve policy pricing accuracy and results.",
        "DOI": "10.3390/bdcc4040040",
        "affiliation_name": "Department of Tourism, Ionian University",
        "affiliation_city": "Corfu",
        "affiliation_country": "Greece",
        "affiliation_id": "60281541",
        "affiliation_state": "Ionian Islands"
    },
    {
        "paper_title": "A model to rate strategies for managing disease due to COVID-19 infection",
        "paper_author": "Wang S.",
        "publication": "Scientific Reports",
        "citied_by": "2",
        "cover_date": "2020-12-01",
        "Abstract": "Considering looming fatality and economic recession, effective policy making based on ongoing COVID-19 pandemic is an urgent and standing issue. Numerous issues for controlling infection have arisen from public discussion led by medical professionals. Yet understanding of these factors has been necessarily qualitative and control measures to correct unfavorable trends specific to an infection area have been lacking. The logical implement for control is a large scale stochastic model with countless parameters lacking robustness and requiring enormous data. This paper presents a remedy for this vexing problem by proposing an alternative approach. Machine learning has come to play a widely circulated role in the study of complex data in recent times. We demonstrate that when machine learning is employed together with the mechanistic framework of a mathematical model, there can be a considerably enhanced understanding of complex systems. A mathematical model describing the viral infection dynamics reveals two transmissibility parameters influenced by the management strategies in the area for the control of the current pandemic. Both parameters readily yield the peak infection rate and means for flattening the curve, which is correlated to different management strategies by employing machine learning, enabling comparison of different strategies and suggesting timely alterations. Treatment of population data with the model shows that restricted non-essential business closure, school closing and strictures on mass gathering influence the spread of infection. While a rational strategy for initiation of an economic reboot would call for a wider perspective of the local economics, the model can speculate on its timing based on the status of the infection as reflected by its potential for an unacceptably renewed viral onslaught.",
        "DOI": "10.1038/s41598-020-79817-7",
        "affiliation_name": "Purdue University",
        "affiliation_city": "West Lafayette",
        "affiliation_country": "United States",
        "affiliation_id": "60009254",
        "affiliation_state": "IN"
    },
    {
        "paper_title": "Addressing health disparities in the Food and Drug Administration’s artificial intelligence and machine learning regulatory framework",
        "paper_author": "Ferryman K.",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "41",
        "cover_date": "2020-12-01",
        "Abstract": "The exponential growth of health data from devices, health applications, and electronic health records coupled with the development of data analysis tools such as machine learning offer opportunities to leverage these data to mitigate health disparities. However, these tools have also been shown to exacerbate inequities faced by marginalized groups. Focusing on health disparities should be part of good machine learning practice and regulatory oversight of software as medical devices. Using the Food and Drug Administration (FDA)’s proposed framework for regulating machine learning tools in medicine, I show that addressing health disparities during the premarket and postmarket stages of review can help anticipate and mitigate group harms.",
        "DOI": "10.1093/jamia/ocaa133",
        "affiliation_name": "NYU Tandon School of Engineering",
        "affiliation_city": "New York",
        "affiliation_country": "United States",
        "affiliation_id": "60108318",
        "affiliation_state": "NY"
    },
    {
        "paper_title": "Electronic health record–based disease surveillance systems: A systematic literature review on challenges and solutions",
        "paper_author": "Aliabadi A.",
        "publication": "Journal of the American Medical Informatics Association",
        "citied_by": "29",
        "cover_date": "2020-12-01",
        "Abstract": "Objective: Disease surveillance systems are expanding using electronic health records (EHRs). However, there are many challenges in this regard. In the present study, the solutions and challenges of implementing EHR-based disease surveillance systems (EHR-DS) have been reviewed. Materials and Methods: We searched the related keywords in ProQuest, PubMed, Web of Science, Cochrane Library, Embase, and Scopus. Then, we assessed and selected articles using the inclusion and exclusion criteria and, finally, classified the identified solutions and challenges. Results: Finally, 50 studies were included, and 52 unique solutions and 47 challenges were organized into 6 main themes (policy and regulatory, technical, management, standardization, financial, and data quality). The results indicate that due to the multifaceted nature of the challenges, the implementation of EHR-DS is not low cost and easy to implement and requires a variety of interventions. On the one hand, the most common challenges include the need to invest significant time and resources; the poor data quality in EHRs; difficulty in analyzing, cleaning, and accessing unstructured data; data privacy and security; and the lack of interoperability standards. On the other hand, the most common solutions are the use of natural language processing and machine learning algorithms for unstructured data; the use of appropriate technical solutions for data retrieval, extraction, identification, and visualization; the collaboration of health and clinical departments to access data; standardizing EHR content for public health; and using a unique health identifier for individuals. Conclusions: EHR systems have an important role in modernizing disease surveillance systems. However, there are many problems and challenges facing the development and implementation of EHR-DS that need to be appropriately addressed.",
        "DOI": "10.1093/jamia/ocaa186",
        "affiliation_name": "IUMS Health Management and Economics Research Center",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60159438",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "Why to buy insurance? An explainable artificial intelligence approach",
        "paper_author": "Gramegna A.",
        "publication": "Risks",
        "citied_by": "37",
        "cover_date": "2020-12-01",
        "Abstract": "We propose an Explainable AI model that can be employed in order to explain why a customer buys or abandons a non-life insurance coverage. The method consists in applying similarity clustering to the Shapley values that were obtained from a highly accurate XGBoost predictive classification algorithm. Our proposed method can be embedded into a technologically-based insurance service (Insurtech), allowing to understand, in real time, the factors that most contribute to customers’ decisions, thereby gaining proactive insights on their needs. We prove the validity of our model with an empirical analysis that was conducted on data regarding purchases of insurance micro-policies. Two aspects are investigated: the propensity to buy an insurance policy and the risk of churn of an existing customer. The results from the analysis reveal that customers can be effectively and quickly grouped according to a similar set of characteristics, which can predict their buying or churn behaviour well.",
        "DOI": "10.3390/risks8040137",
        "affiliation_name": "Università degli Studi di Pavia",
        "affiliation_city": "Pavia",
        "affiliation_country": "Italy",
        "affiliation_id": "60015197",
        "affiliation_state": "PV"
    },
    {
        "paper_title": "How can social media analytics assist authorities in pandemic-related policy decisions? Insights from Australian states and territories",
        "paper_author": "Yigitcanlar T.",
        "publication": "Health Information Science and Systems",
        "citied_by": "47",
        "cover_date": "2020-12-01",
        "Abstract": "Background and objectives: Due to COVID-19, various countries introduced lockdowns and limited citizen movements. These restrictions triggered an increased use of digital technologies and platforms by the public. This provides an opportunity for the authorities to capture public perceptions on COVID-19 from social media channels to make informed decisions. The use of social media analytics during pandemics for decision-making, however, is an understudied area of research. Thus, this study aims to generate insights into how social media analytics can assist authorities in pandemic-related policy decisions. Methods: This study involved a social media analysis approach—i.e., systematic geo-Twitter analysis—that contains descriptive, content, sentiment, and spatial analyses. Australian states and territories are selected as the case study context for the empirical investigation. This study collected 96,666 geotagged tweets (originated from Australia between 1 January and 4 May 2020), and analysed 35,969 of them after data cleaning. Results: The findings disclose that: (a) Social media analytics is an efficient approach to capture the attitudes and perceptions of the public during a pandemic; (b) Crowdsourced social media data can guide interventions and decisions of the authorities during a pandemic, and; (c) Effective use of government social media channels can help the public to follow the introduced measures/restrictions. Conclusion: The findings are invaluable for authorities to understand community perceptions and identify communities in needs and demands in a pandemic situation, where authorities are not in a position to conduct direct and lengthily public consultations.",
        "DOI": "10.1007/s13755-020-00121-9",
        "affiliation_name": "Islamic Azad University",
        "affiliation_city": "Tehran",
        "affiliation_country": "Iran",
        "affiliation_id": "60031777",
        "affiliation_state": "Tehran"
    },
    {
        "paper_title": "PipeArch: Generic and context-switch capable data processing on fpgas",
        "paper_author": "Kara K.",
        "publication": "ACM Transactions on Reconfigurable Technology and Systems",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "Data processing systems based on FPGAs offer high performance and energy efficiency for a variety of applications. However, these advantages are achieved through highly specialized designs. The high degree of specialization leads to accelerators with narrow functionality and designs adhering to a rigid execution flow. For multi-tenant systems this limits the scope of applicability of FPGA-based accelerators, because, first, supporting a single operation is unlikely to have any significant impact on the overall performance of the system, and, second, serving multiple users satisfactorily is difficult due to simplistic scheduling policies enforced when using the accelerator. Standard operating system and database management system features that would help address these limitations, such as context-switching, preemptive scheduling, and thread migration are practically non-existent in current FPGA accelerator efforts. In this work, we propose PipeArch, an open-source project1 for developing FPGA-based accelerators that combine the high efficiency of specialized hardware designs with the generality and functionality known from conventional CPU threads. PipeArch provides programmability and extensibility in the accelerator without losing the advantages of SIMD-parallelism and deep pipelining. PipeArch supports context-switching and thread migration, thereby enabling for the first time new capabilities such as preemptive scheduling in FPGA accelerators within a high-performance data processing setting. We have used PipeArch to implement a variety of machine learning methods for generalized linear model training and recommender systems showing empirically their advantages over a high-end CPU and even over fully specialized FPGA designs.",
        "DOI": "10.1145/3418465",
        "affiliation_name": "ETH Zürich",
        "affiliation_city": "Zurich",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60025858",
        "affiliation_state": "ZH"
    },
    {
        "paper_title": "Learning from urban form to predict building heights",
        "paper_author": "Milojevic-Dupont N.",
        "publication": "PLoS ONE",
        "citied_by": "45",
        "cover_date": "2020-12-01",
        "Abstract": "Understanding cities as complex systems, sustainable urban planning depends on reliable high-resolution data, for example of the building stock to upscale region-wide retrofit policies. For some cities and regions, these data exist in detailed 3D models based on real-world measurements. However, they are still expensive to build and maintain, a significant challenge, especially for small and medium-sized cities that are home to the majority of the European population. New methods are needed to estimate relevant building stock characteristics reliably and cost-effectively. Here, we present a machine learning based method for predicting building heights, which is based only on open-access geospatial data on urban form, such as building footprints and street networks. The method allows to predict building heights for regions where no dedicated 3D models exist currently. We train our model using building data from four European countries (France, Italy, the Netherlands, and Germany) and find that the morphology of the urban fabric surrounding a given building is highly predictive of the height of the building. A test on the German state of Brandenburg shows that our model predicts building heights with an average error well below the typical floor height (about 2.5 m), without having access to training data from Germany. Furthermore, we show that even a small amount of local height data obtained by citizens substantially improves the prediction accuracy. Our results illustrate the possibility of predicting missing data on urban infrastructure; they also underline the value of open government data and volunteered geographic information for scientific applications, such as contextual but scalable strategies to mitigate climate change.",
        "DOI": "10.1371/journal.pone.0242010",
        "affiliation_name": "Mercator Research Institute on Global Commons and Climate Change",
        "affiliation_city": "Berlin",
        "affiliation_country": "Germany",
        "affiliation_id": "60159447",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Exploring optimal control of epidemic spread using reinforcement learning",
        "paper_author": "Ohi A.Q.",
        "publication": "Scientific Reports",
        "citied_by": "33",
        "cover_date": "2020-12-01",
        "Abstract": "Pandemic defines the global outbreak of a disease having a high transmission rate. The impact of a pandemic situation can be lessened by restricting the movement of the mass. However, one of its concomitant circumstances is an economic crisis. In this article, we demonstrate what actions an agent (trained using reinforcement learning) may take in different possible scenarios of a pandemic depending on the spread of disease and economic factors. To train the agent, we design a virtual pandemic scenario closely related to the present COVID-19 crisis. Then, we apply reinforcement learning, a branch of artificial intelligence, that deals with how an individual (human/machine) should interact on an environment (real/virtual) to achieve the cherished goal. Finally, we demonstrate what optimal actions the agent perform to reduce the spread of disease while considering the economic factors. In our experiment, we let the agent find an optimal solution without providing any prior knowledge. After training, we observed that the agent places a long length lockdown to reduce the first surge of a disease. Furthermore, the agent places a combination of cyclic lockdowns and short length lockdowns to halt the resurgence of the disease. Analyzing the agent’s performed actions, we discover that the agent decides movement restrictions not only based on the number of the infectious population but also considering the reproduction rate of the disease. The estimation and policy of the agent may improve the human-strategy of placing lockdown so that an economic crisis may be avoided while mitigating an infectious disease.",
        "DOI": "10.1038/s41598-020-79147-8",
        "affiliation_name": "Bangladesh University of Business and Technology",
        "affiliation_city": "Dhaka",
        "affiliation_country": "Bangladesh",
        "affiliation_id": "60170531",
        "affiliation_state": "Dhaka"
    },
    {
        "paper_title": "Editors Introduction: An Update on the Status of the Journal",
        "paper_author": "NA",
        "publication": "Ultrasound Quarterly",
        "citied_by": "0",
        "cover_date": "2020-12-01",
        "Abstract": "NA",
        "DOI": "10.1097/RUQ.0000000000000551",
        "affiliation_name": "NA",
        "affiliation_city": "NA",
        "affiliation_country": "NA",
        "affiliation_id": "NA",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "A social engineering model for poverty alleviation",
        "paper_author": "Chattopadhyay A.K.",
        "publication": "Nature Communications",
        "citied_by": "7",
        "cover_date": "2020-12-01",
        "Abstract": "Poverty, the quintessential denominator of a developing nation, has been traditionally defined against an arbitrary poverty line; individuals (or countries) below this line are deemed poor and those above it, not so! This has two pitfalls. First, absolute reliance on a single poverty line, based on basic food consumption, and not on total consumption distribution, is only a partial poverty index at best. Second, a single expense descriptor is an exogenous quantity that does not evolve from income-expenditure statistics. Using extensive income-expenditure statistics from India, here we show how a self-consistent endogenous poverty line can be derived from an agent-based stochastic model of market exchange, combining all expenditure modes (basic food, other food and non-food), whose parameters are probabilistically estimated using advanced Machine Learning tools. Our mathematical study establishes a consumption based poverty measure that combines labor, commodity, and asset market outcomes, delivering an excellent tool for economic policy formulation.",
        "DOI": "10.1038/s41467-020-20201-4",
        "affiliation_name": "Birmingham City University",
        "affiliation_city": "Birmingham",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60100434",
        "affiliation_state": "West Midlands"
    },
    {
        "paper_title": "Comorbidity patterns of older lung cancer patients in Northeast China: An association rules analysis based on electronic medical records",
        "paper_author": "Feng J.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "16",
        "cover_date": "2020-12-01",
        "Abstract": "Purposes: This study aims to identify the comorbidity patterns of older men with lung cancer in China. Methods: We analyzed the electronic medical records (EMRs) of lung cancer patients over age 65 in the Jilin Province of China. The data studied were obtained from 20 hospitals of Jilin Province in 2018. In total, 1510 patients were identified. We conducted a rank–frequency analysis and social network analysis to identify the predominant comorbidities and comorbidity networks. We applied the association rules to mine the comorbidity combination with the values of confidence and lift. A heatmap was utilized to visualize the rules. Results: Our analyses discovered that (1) there were 31 additional medical conditions in older patients with lung cancer. The most frequent comorbidities were pneumonia, cerebral infarction, and hypertension. (2) The networkbased analysis revealed seven subnetworks. (3) The association rules analysis provided 41 interesting rules. The results revealed that hypertension, ischemic cardiomyopathy, and pneumonia are the most frequent comorbid combinations. Heart failure may not have a strong implicating role in these comorbidity patterns. Cerebral infarction was rarely combined with other diseases. In addition, glycoprotein metabolism disorder comorbid with hyponatremia or hypokalemia increased the risk of anemia by more than eight times in older lung cancer patients. Conclusions: This study provides evidence on the comorbidity patterns of older men with lung cancer in China. Understanding the comorbidity patterns of older patients with lung cancer can assist clinicians in their diagnoses and contribute to developing healthcare policies, as well as allocating resources.",
        "DOI": "10.3390/ijerph17239119",
        "affiliation_name": "Jilin University",
        "affiliation_city": "Changchun",
        "affiliation_country": "China",
        "affiliation_id": "60007711",
        "affiliation_state": "Jilin"
    },
    {
        "paper_title": "Ticket sales prediction and dynamic pricing strategies in public transport",
        "paper_author": "Branda F.",
        "publication": "Big Data and Cognitive Computing",
        "citied_by": "24",
        "cover_date": "2020-12-01",
        "Abstract": "In recent years, the demand for collective mobility services registered significant growth. In particular, the long-distance coach market underwent an important change in Europe, since FlixBus adopted a dynamic pricing strategy, providing low-cost transport services and an efficient and fast information system. This paper presents a methodology, called DA4PT (Data Analytics for Public Transport), for discovering the factors that influence travelers in booking and purchasing bus tickets. Starting from a set of 3.23 million user-generated event logs of a bus ticketing platform, the methodology shows the correlation rules between booking factors and purchase of tickets. Such rules are then used to train machine learning models for predicting whether a user will buy or not a ticket. The rules are also used to define various dynamic pricing strategies with the purpose of increasing the number of tickets sales on the platform and the related amount of revenues. The methodology reaches an accuracy of 95% in forecasting the purchase of a ticket and a low variance in results. Exploiting a dynamic pricing strategy, DA4PT is able to increase the number of purchased tickets by 6% and the total revenue by 9% by showing the effectiveness of the proposed approach.",
        "DOI": "10.3390/bdcc4040036",
        "affiliation_name": "Università della Calabria",
        "affiliation_city": "Rende",
        "affiliation_country": "Italy",
        "affiliation_id": "60020261",
        "affiliation_state": "CS"
    },
    {
        "paper_title": "Assessing mediterranean diet adherence with the smartphone: The medipiatto project",
        "paper_author": "Vasiloglou M.F.",
        "publication": "Nutrients",
        "citied_by": "12",
        "cover_date": "2020-12-01",
        "Abstract": "The Mediterranean diet (MD) is regarded as a healthy eating pattern with beneficial effects both for the decrease of the risk for non-communicable diseases and also for body weight reduction. In the current manuscript, we propose an automated smartphone application which monitors and evaluates the user’s adherence to MD using images of the food and drinks that they consume. We define a set of rules for automatic adherence estimation, which focuses on the main MD food groups. We use a combination of a convolutional neural network (CNN) and a graph convolutional network to detect the types of foods and quantities from the users’ food images and the defined set of rules to evaluate the adherence to MD. Our experiments show that our system outperforms a basic CNN in terms of recognizing food items and estimating quantity and yields comparable results as experienced dietitians when it comes to overall MD adherence estimation. As the system is novel, these results are promising; however, there is room for improvement of the accuracy by gathering and training with more data and certain refinements can be performed such as re-defining the set of rules to also be able to be used for sub-groups of MD (e.g., vegetarian type of MD).",
        "DOI": "10.3390/nu12123763",
        "affiliation_name": "University of Bern, Faculty of Medicine",
        "affiliation_city": "Bern",
        "affiliation_country": "Switzerland",
        "affiliation_id": "60026476",
        "affiliation_state": "BE"
    },
    {
        "paper_title": "KNN prototyping schemes for embedded human activity recognition with online learning",
        "paper_author": "Ferreira P.J.S.",
        "publication": "Computers",
        "citied_by": "24",
        "cover_date": "2020-12-01",
        "Abstract": "The kNN machine learning method is widely used as a classifier in Human Activity Recognition (HAR) systems. Although the kNN algorithm works similarly both online and in offline mode, the use of all training instances is much more critical online than offline due to time and memory restrictions in the online mode. Some methods propose decreasing the high computational costs of kNN by focusing, e.g., on approximate kNN solutions such as the ones relying on Locality-Sensitive Hashing (LSH). However, embedded kNN implementations also need to address the target device’s memory constraints, especially as the use of online classification needs to cope with those constraints to be practical. This paper discusses online approaches to reduce the number of training instances stored in the kNN search space. To address practical implementations of HAR systems using kNN, this paper presents simple, energy/computationally efficient, and real-time feasible schemes to maintain at runtime a maximum number of training instances stored by kNN. The proposed schemes include policies for substituting the training instances, maintaining the search space to a maximum size. Experiments in the context of HAR datasets show the efficiency of our best schemes.",
        "DOI": "10.3390/computers9040096",
        "affiliation_name": "Institute for Systems and Computer Engineering, Technology and Science",
        "affiliation_city": "Porto",
        "affiliation_country": "Portugal",
        "affiliation_id": "60020432",
        "affiliation_state": "Porto"
    },
    {
        "paper_title": "Fast reinforcement learning with generalized policy updates",
        "paper_author": "Barreto A.",
        "publication": "Proceedings of the National Academy of Sciences of the United States of America",
        "citied_by": "76",
        "cover_date": "2020-12-01",
        "Abstract": "The combination of reinforcement learning with deep learning is a promising approach to tackle important sequential decision-making problems that are currently intractable. One obstacle to overcome is the amount of data needed by learning systems of this type. In this article, we propose to address this issue through a divide-and-conquer approach. We argue that complex decision problems can be naturally decomposed into multiple tasks that unfold in sequence or in parallel. By associating each task with a reward function, this problem decomposition can be seamlessly accommodated within the standard reinforcement-learning formalism. The specific way we do so is through a generalization of two fundamental operations in reinforcement learning: policy improvement and policy evaluation. The generalized version of these operations allow one to leverage the solution of some tasks to speed up the solution of others. If the reward function of a task can be well approximated as a linear combination of the reward functions of tasks previously solved, we can reduce a reinforcement-learning problem to a simpler linear regression. When this is not the case, the agent can still exploit the task solutions by using them to interact with and learn about the environment. Both strategies considerably reduce the amount of data needed to solve a reinforcement-learning problem.",
        "DOI": "10.1073/pnas.1907370117",
        "affiliation_name": "DeepMind Technologies Limited",
        "affiliation_city": "London",
        "affiliation_country": "United Kingdom",
        "affiliation_id": "60111161",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Adaptive Optimal Control for Stochastic Multiplayer Differential Games Using On-Policy and Off-Policy Reinforcement Learning",
        "paper_author": "Liu M.",
        "publication": "IEEE Transactions on Neural Networks and Learning Systems",
        "citied_by": "54",
        "cover_date": "2020-12-01",
        "Abstract": "Control-theoretic differential games have been used to solve optimal control problems in multiplayer systems. Most existing studies on differential games either assume deterministic dynamics or dynamics corrupted with additive noise. In realistic environments, multidimensional environmental uncertainties often modulate system dynamics in a more complicated fashion. In this article, we study stochastic multiplayer differential games, where the players' dynamics are modulated by randomly time-varying parameters. We first formulate two differential games for systems of general uncertain linear dynamics, including the two-player zero-sum and multiplayer nonzero-sum games. We then show that optimal control policies, which constitute the Nash equilibrium solutions, can be derived from the corresponding Hamiltonian functions. Stability is proven using the Lyapunov type of analysis. In order to solve the stochastic differential games online, we integrate reinforcement learning (RL) and an effective uncertainty sampling method called the multivariate probabilistic collocation method (MPCM). Two learning algorithms, including the on-policy integral RL (IRL) and off-policy IRL, are designed for the formulated games, respectively. We show that the proposed learning algorithms can effectively find the Nash equilibrium solutions for the stochastic multiplayer differential games.",
        "DOI": "10.1109/TNNLS.2020.2969215",
        "affiliation_name": "College of Engineering",
        "affiliation_city": "Arlington",
        "affiliation_country": "United States",
        "affiliation_id": "60137461",
        "affiliation_state": "TX"
    },
    {
        "paper_title": "Shifting the paradigm: The dress-cov telegram bot as a tool for participatory medicine",
        "paper_author": "Franchini M.",
        "publication": "International Journal of Environmental Research and Public Health",
        "citied_by": "12",
        "cover_date": "2020-12-01",
        "Abstract": "Severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) pandemic management is limited by great uncertainty, for both health systems and citizens. Facing this information gap requires a paradigm shift from traditional approaches to healthcare to the participatory model of improving health. This work describes the design and function of the Doing Risk sElf-assessment and Social health Support for COVID (Dress-COV) system. It aims to establish a lasting link between the user and the tool; thus, enabling modeling of the data to assess individual risk of infection, or developing complications, to improve the individual’s self-empowerment. The system uses bot technology of the Telegram application. The risk assessment includes the collection of user responses and the modeling of data by machine learning models, with increasing appropriateness based on the number of users who join the system. The main results reflect: (a) the individual’s compliance with the tool; (b) the security and versatility of the architecture; (c) support and promotion of self-management of behavior to accommodate surveillance system delays; (d) the potential to support territorial health providers, e.g., the daily efforts of general practitioners (during this pandemic, as well as in their routine practices). These results are unique to Dress-COV and distinguish our system from classical surveillance applications.",
        "DOI": "10.3390/ijerph17238786",
        "affiliation_name": "Gabriele Monasterio Foundation",
        "affiliation_city": "Pisa",
        "affiliation_country": "Italy",
        "affiliation_id": "60103331",
        "affiliation_state": "NA"
    },
    {
        "paper_title": "Artificial intelligence-based radiotherapy machine parameter optimization using reinforcement learning",
        "paper_author": "Hrinivich W.T.",
        "publication": "Medical Physics",
        "citied_by": "27",
        "cover_date": "2020-12-01",
        "Abstract": "Purpose: To develop and evaluate a volumetric modulated arc therapy (VMAT) machine parameter optimization (MPO) approach based on deep-Q reinforcement learning (RL) capable of finding an optimal machine control policy using previous prostate cancer patient CT scans and contours, and applying the policy to new cases to rapidly produce deliverable VMAT plans in a simplified beam model. Methods: A convolutional deep-Q network was employed to control the dose rate and multileaf collimator of a C-arm linear accelerator model using the current dose distribution and machine parameter state as input. A Q-value was defined as the discounted cumulative cost based on dose objectives, and experience-replay RL was performed to determine a policy to minimize the Q-value. A two-dimensional network design was employed which optimized each opposing leaf pair independently while monitoring the corresponding dose plane blocked by those leaves. This RL approach was applied to CT and contours from 40 retrospective prostate cancer patients. The dataset was split into training (15 patients) and validation (5 patients) groups to optimize the network, and its performance was tested in an independent cohort of 20 patients by comparing RL-based dose distributions to conformal arcs and clinical intensity modulated radiotherapy (IMRT) delivering a prescription dose of 78 Gy in 40 fractions. Results: Mean ± SD execution time of the RL VMAT optimization was 1.5 ± 0.2 s per slice. In the test cohort, mean ± SD (P-value) planning target volume (PTV), bladder, and rectum dose were 80.5 ± 2.0 Gy (P < 0.001), 44.2 ± 14.6 Gy (P < 0.001), and 43.7 ± 11.1 Gy (P < 0.001) for RL VMAT compared to 81.6 ± 1.1 Gy, 51.6 ± 12.9 Gy, and 36.0 ± 12.3 Gy for clinical IMRT. Conclusions: RL was applied to VMAT MPO using clinical patient contours without independently optimized treatment plans for training and achieved comparable target and normal tissue dose to clinical plans despite the application of a relatively simple network design originally developed for video-game control. These results suggest that extending a RL approach to a full three-dimensional beam model could enable rapid artificial intelligence-based optimization of deliverable treatment plans, reducing the time required for radiotherapy planning without requiring previous plans for training.",
        "DOI": "10.1002/mp.14544",
        "affiliation_name": "Johns Hopkins University School of Medicine",
        "affiliation_city": "Baltimore",
        "affiliation_country": "United States",
        "affiliation_id": "60001117",
        "affiliation_state": "MD"
    },
    {
        "paper_title": "Using the lstm network to forecast the demand for electricity in poland",
        "paper_author": "Manowska A.",
        "publication": "Applied Sciences (Switzerland)",
        "citied_by": "31",
        "cover_date": "2020-12-01",
        "Abstract": "The impact of environmental regulations introduced by the European Union is of key importance for electricity generation systems. The Polish fuel structure of electricity production is based on solid fuels. Moreover, the generating base is outdated and must gradually be withdrawn from the power system. In this context, Poland’s energy policy is undergoing a transformation as climate and environmental regulations are becoming increasingly stringent for the energy sector based on solid fuels (hard coal and lignite). However, the transformation process must be adapted to market demands, because the overriding goal is to ensure energy security by maintaining the continuity of energy supplies and an acceptable electricity price. This directly contributes to the development of the entire economy and the standard of living of the society, in accordance with the European Agreement establishing an association between the Republic of Poland and the European Communities and their Member States, signed on 16 December 1991, and the European Energy Charter, signed on 17 December 1991. Ensuring energy security is the most important goal of the energy policy. Therefore, energy companies must forecast the demand. The main goal of this article is to develop a mathematical model of electricity consumption by 2040 by all sectors of the economy: industry, transport, residential, commercial and public services, agriculture, forestry, and fishing. In order to achieve the intended goal, a model was developed by using Long Short-Term Memory (LSTM) artificial neural networks, which belong to deep learning techniques and reflect long-term relationships in time series for a small set of statistical data. The results show that the proposed model can significantly improve the accuracy of forecasts (1–3% of mean absolute percentage error (MAPE) for the analyzed sectors of the economy).",
        "DOI": "10.3390/app10238455",
        "affiliation_name": "Silesian University of Technology",
        "affiliation_city": "Gliwice",
        "affiliation_country": "Poland",
        "affiliation_id": "60009081",
        "affiliation_state": "Silesian"
    },
    {
        "paper_title": "The ironies of autonomy",
        "paper_author": "Ganesh M.I.",
        "publication": "Humanities and Social Sciences Communications",
        "citied_by": "28",
        "cover_date": "2020-12-01",
        "Abstract": "Current research on autonomous vehicles tends to focus on making them safer through policies to manage innovation, and integration into existing urban and mobility systems. This article takes social, cultural and philosophical approaches instead, critically appraising how human subjectivity, and human-machine relations, are shifting and changing through the application of big data and algorithmic techniques to the automation of driving. 20th century approaches to safety engineering and automation—be it in an airplane or automobile-have sought to either erase the human because she is error-prone and inefficient; have design compensate for the limits of the human; or at least mould human into machine through an assessment of the complementary competencies of each. The ‘irony of automation’ is an observation of the tensions emerging therein; for example, that the computationally superior and efficient machine actually needs human operators to ensure that it is working effectively; and that the human is inevitably held accountable for errors, even if the machine is more efficient or accurate. With the emergence of the autonomous vehicle (AV) as simultaneously AI/ ‘robot’, and automobile, and distributed, big data infrastructural platform, these beliefs about human and machine are dissolving into what I refer to as the ironies of autonomy. For example, recent AV crashes suggest that human operators cannot intervene in the statistical operations underlying automated decision-making in machine learning, but are expected to. And that while AVs promise ‘freedom’, human time, work, and bodies are threaded into, and surveilled by, data infrastructures, and re-shaped by its information flows. The shift that occurs is that human subjectivity has socio-economic and legal implications and is not about fixed attributes of human and machine fitting into each other. Drawing on Postphenomenological concepts of embodiment and instrumentation, and excerpts from fieldwork, this article argues that the emergence of AVs in society prompts a rethinking of the multiple relationalities that constitute humanity through machines.",
        "DOI": "10.1057/s41599-020-00646-0",
        "affiliation_name": "Leuphana Universität Lüneburg",
        "affiliation_city": "Luneburg",
        "affiliation_country": "Germany",
        "affiliation_id": "60072202",
        "affiliation_state": "Niedersachsen"
    }
]